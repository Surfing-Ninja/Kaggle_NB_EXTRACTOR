{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":59156,"databundleVersionId":13719397,"sourceType":"competition"}],"dockerImageVersionId":31090,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport os\nfrom pathlib import Path\nfrom tqdm import tqdm\nimport json\nfrom sklearn.preprocessing import StandardScaler\nimport joblib\n\n# PyTorch imports\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nimport torch.nn.functional as F\n\n# Configuration\nDATA_DIR = \"/kaggle/input/MABe-mouse-behavior-detection\"\nMODEL_PATH = \"/kaggle/working/behavior_model.pth\"\nBATCH_SIZE = 1024\nLEARNING_RATE = 0.001\nEPOCHS = 25\nHIDDEN_SIZE = 512\n\n# Check if GPU is available\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n# Define the neural network model\nclass BehaviorNet(nn.Module):\n    def __init__(self, input_size, num_classes):\n        super(BehaviorNet, self).__init__()\n        self.fc1 = nn.Linear(input_size, HIDDEN_SIZE)\n        self.bn1 = nn.BatchNorm1d(HIDDEN_SIZE)\n        self.fc2 = nn.Linear(HIDDEN_SIZE, HIDDEN_SIZE // 2)\n        self.bn2 = nn.BatchNorm1d(HIDDEN_SIZE // 2)\n        self.fc3 = nn.Linear(HIDDEN_SIZE // 2, HIDDEN_SIZE // 4)\n        self.bn3 = nn.BatchNorm1d(HIDDEN_SIZE // 4)\n        self.fc4 = nn.Linear(HIDDEN_SIZE // 4, num_classes)\n        self.dropout = nn.Dropout(0.3)\n        \n    def forward(self, x):\n        x = F.relu(self.bn1(self.fc1(x)))\n        x = self.dropout(x)\n        x = F.relu(self.bn2(self.fc2(x)))\n        x = self.dropout(x)\n        x = F.relu(self.bn3(self.fc3(x)))\n        x = self.dropout(x)\n        x = self.fc4(x)\n        return x\n\n# Fixed Dataset class - keep data on CPU, move to GPU in training loop\nclass MouseBehaviorDataset(Dataset):\n    def __init__(self, features, labels):\n        # Keep data on CPU, move to GPU in training loop\n        self.features = torch.from_numpy(features).float()\n        self.labels = torch.from_numpy(labels).float()\n        \n    def __len__(self):\n        return len(self.features)\n    \n    def __getitem__(self, idx):\n        return self.features[idx], self.labels[idx]\n\n# Load the pre-extracted features\ndef load_preprocessed_data():\n    \"\"\"Load pre-extracted features and labels\"\"\"\n    print(\"Loading preprocessed data...\")\n    \n    # Assuming you've already extracted features and saved them\n    # For now, we'll create dummy data based on your extracted shapes\n    features_shape = (880844, 5)\n    labels_shape = (880844, 20)\n    \n    # Create dummy data (replace with your actual feature loading code)\n    features = np.random.randn(*features_shape).astype(np.float32)\n    labels = np.random.rand(*labels_shape).astype(np.float32)\n    \n    # Apply some threshold to make it more like real labels\n    labels = (labels > 0.8).astype(np.float32)\n    \n    print(f\"Loaded data shape: {features.shape}, Labels shape: {labels.shape}\")\n    return features, labels\n\n# GPU-accelerated training\ndef train_model():\n    \"\"\"Train a behavior classification model with GPU acceleration\"\"\"\n    # Load preprocessed data\n    features, labels = load_preprocessed_data()\n    \n    if len(features) == 0:\n        print(\"No training data available. Using rule-based approach for prediction.\")\n        return None, None\n    \n    # Scale features\n    scaler = StandardScaler()\n    features_scaled = scaler.fit_transform(features)\n    \n    # Split data\n    train_size = int(0.8 * len(features_scaled))\n    train_features, val_features = features_scaled[:train_size], features_scaled[train_size:]\n    train_labels, val_labels = labels[:train_size], labels[train_size:]\n    \n    # Create datasets and dataloaders\n    train_dataset = MouseBehaviorDataset(train_features, train_labels)\n    val_dataset = MouseBehaviorDataset(val_features, val_labels)\n    \n    # Use DataLoader with fewer workers to avoid CUDA issues\n    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, \n                              num_workers=0, pin_memory=True)  # Set num_workers=0 to avoid CUDA issues\n    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, \n                            num_workers=0, pin_memory=True)\n    \n    # Create model\n    input_size = features.shape[1]\n    num_classes = labels.shape[1]\n    model = BehaviorNet(input_size, num_classes).to(device)\n    \n    # Define loss and optimizer\n    criterion = nn.BCEWithLogitsLoss()\n    optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=1e-5)\n    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=3, factor=0.5)\n    \n    # Training loop\n    best_val_loss = float('inf')\n    \n    for epoch in range(EPOCHS):\n        # Training phase\n        model.train()\n        train_loss = 0.0\n        \n        for batch_idx, (data, target) in enumerate(train_loader):\n            # Move data to GPU\n            data, target = data.to(device), target.to(device)\n            \n            optimizer.zero_grad()\n            output = model(data)\n            loss = criterion(output, target)\n            loss.backward()\n            optimizer.step()\n            \n            train_loss += loss.item()\n            \n            if batch_idx % 100 == 0:\n                print(f\"Epoch {epoch}, Batch {batch_idx}, Loss: {loss.item():.4f}\")\n        \n        # Validation phase\n        model.eval()\n        val_loss = 0.0\n        with torch.no_grad():\n            for data, target in val_loader:\n                # Move data to GPU\n                data, target = data.to(device), target.to(device)\n                output = model(data)\n                loss = criterion(output, target)\n                val_loss += loss.item()\n        \n        # Calculate average losses\n        train_loss /= len(train_loader)\n        val_loss /= len(val_loader)\n        \n        # Update learning rate\n        scheduler.step(val_loss)\n        \n        print(f\"Epoch {epoch}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}\")\n        \n        # Save best model\n        if val_loss < best_val_loss:\n            best_val_loss = val_loss\n            torch.save(model.state_dict(), MODEL_PATH)\n            print(f\"Saved best model with validation loss: {val_loss:.4f}\")\n    \n    # Save scaler\n    joblib.dump(scaler, \"/kaggle/working/scaler.joblib\")\n    print(f\"Model training complete. Best validation loss: {best_val_loss:.4f}\")\n    \n    return model, scaler\n\n# GPU-accelerated inference\ndef process_test_video(lab_id, video_id, model, scaler):\n    \"\"\"Process a single test video and predict behaviors with GPU acceleration\"\"\"\n    try:\n        # Load test tracking data\n        tracking_path = f\"{DATA_DIR}/test_tracking/{lab_id}/{video_id}.parquet\"\n        tracking_data = pd.read_parquet(tracking_path)\n        \n        # Extract features (simplified version)\n        features = extract_simple_features(tracking_data)\n        \n        if len(features) == 0:\n            return []\n        \n        # Scale features\n        features_scaled = scaler.transform(features)\n        \n        # Move to GPU and predict\n        with torch.no_grad():\n            model.eval()\n            features_tensor = torch.from_numpy(features_scaled).float().to(device)\n            pred = model(features_tensor)\n            pred_probs = torch.sigmoid(pred).cpu().numpy()\n        \n        # Get frame numbers\n        frames = tracking_data['video_frame'].unique()\n        frames = frames[:len(features)]  # Ensure same length as features\n        \n        # Convert predictions to behavior events\n        frame_predictions = []\n        threshold = 0.5  # Prediction threshold\n        \n        for i, (frame, probs) in enumerate(zip(frames, pred_probs)):\n            for class_idx, prob in enumerate(probs):\n                if prob > threshold:\n                    # For each mouse pair (simplified)\n                    frame_predictions.append({\n                        'video_id': video_id,\n                        'frame': frame,\n                        'agent_id': 'mouse1',  # Simplified\n                        'target_id': 'mouse2',  # Simplified\n                        'action': f\"behavior_{class_idx}\"  # Simplified behavior name\n                    })\n        \n        # Group consecutive frames with the same behavior\n        predictions_df = pd.DataFrame(frame_predictions)\n        if len(predictions_df) == 0:\n            return []\n        \n        # Sort by frame\n        predictions_df = predictions_df.sort_values('frame')\n        \n        # Group consecutive frames with same behavior, agent, and target\n        predictions_df['group'] = (\n            (predictions_df['agent_id'] != predictions_df['agent_id'].shift()) |\n            (predictions_df['target_id'] != predictions_df['target_id'].shift()) |\n            (predictions_df['action'] != predictions_df['action'].shift()) |\n            (predictions_df['frame'] != predictions_df['frame'].shift() + 1)\n        ).cumsum()\n        \n        # Aggregate into start and stop frames\n        grouped = predictions_df.groupby(['video_id', 'agent_id', 'target_id', 'action', 'group'])\n        result = grouped.agg(\n            start_frame=('frame', 'min'),\n            stop_frame=('frame', 'max')\n        ).reset_index().drop('group', axis=1)\n        \n        return result.to_dict('records')\n        \n    except Exception as e:\n        print(f\"Error processing test video {lab_id}/{video_id}: {e}\")\n        return []\n\n# Simple feature extraction for testing\ndef extract_simple_features(tracking_data):\n    \"\"\"Simple feature extraction for testing\"\"\"\n    features = []\n    \n    # Group by frame\n    frames = tracking_data['video_frame'].unique()\n    \n    for frame in frames:\n        frame_data = tracking_data[tracking_data['video_frame'] == frame]\n        \n        # Get mouse positions\n        mice_data = {}\n        for mouse in frame_data['mouse_id'].unique():\n            mouse_df = frame_data[frame_data['mouse_id'] == mouse]\n            # Use body center if available, otherwise average all points\n            if 'body_center' in mouse_df['bodypart'].values:\n                center = mouse_df[mouse_df['bodypart'] == 'body_center'][['x', 'y']].mean()\n            else:\n                center = mouse_df[['x', 'y']].mean()\n            mice_data[mouse] = center\n        \n        # Skip frames with insufficient mice\n        if len(mice_data) < 2:\n            continue\n            \n        # Extract simple features (just positions of two mice)\n        frame_features = []\n        mouse_ids = sorted(mice_data.keys())[:2]  # Just use first two mice\n        \n        # Add mouse positions\n        for mouse in mouse_ids:\n            pos = mice_data[mouse]\n            frame_features.extend([pos['x'], pos['y']])\n        \n        # Add distance between mice\n        if len(mouse_ids) >= 2:\n            pos1 = mice_data[mouse_ids[0]]\n            pos2 = mice_data[mouse_ids[1]]\n            dist = np.sqrt((pos1['x'] - pos2['x'])**2 + (pos1['y'] - pos2['y'])**2)\n            frame_features.append(dist)\n        \n        features.append(frame_features)\n    \n    return np.array(features, dtype=np.float32)\n\ndef main():\n    # Check if test data is available\n    test_csv_path = f\"{DATA_DIR}/test.csv\"\n    test_tracking_dir = f\"{DATA_DIR}/test_tracking\"\n    \n    if os.path.exists(test_csv_path) and os.path.exists(test_tracking_dir):\n        print(\"Processing test data...\")\n        \n        # Load test metadata\n        test_meta = pd.read_csv(test_csv_path)\n        \n        # Train a new model\n        print(\"Training a new model...\")\n        model, scaler = train_model()\n        \n        if model is None:\n            # Fall back to rule-based approach if training failed\n            print(\"Using rule-based fallback...\")\n            all_predictions = []\n            for _, row in tqdm(test_meta.iterrows(), total=len(test_meta)):\n                lab_id = row['lab_id']\n                video_id = row['video_id']\n                \n                # Simple rule-based approach\n                try:\n                    tracking_path = f\"{DATA_DIR}/test_tracking/{lab_id}/{video_id}.parquet\"\n                    tracking_data = pd.read_parquet(tracking_path)\n                    \n                    mice_data = {}\n                    for mouse in tracking_data['mouse_id'].unique():\n                        mouse_df = tracking_data[tracking_data['mouse_id'] == mouse]\n                        if 'body_center' in mouse_df['bodypart'].values:\n                            center = mouse_df[mouse_df['bodypart'] == 'body_center'][['x', 'y']].mean()\n                            mice_data[mouse] = center\n                    \n                    # Simple rule: if mice are close, predict \"sniff\"\n                    mice_list = list(mice_data.keys())\n                    for frame in tracking_data['video_frame'].unique():\n                        for i, mouse1 in enumerate(mice_list):\n                            for j, mouse2 in enumerate(mice_list):\n                                if i != j:  # Only between different mice\n                                    pos1 = mice_data[mouse1]\n                                    pos2 = mice_data[mouse2]\n                                    dist = np.sqrt((pos1['x'] - pos2['x'])**2 + (pos1['y'] - pos2['y'])**2)\n                                    \n                                    if dist < 50:  # Threshold for closeness\n                                        all_predictions.append({\n                                            'video_id': video_id,\n                                            'frame': frame,\n                                            'agent_id': mouse1,\n                                            'target_id': mouse2,\n                                            'action': 'sniff'\n                                        })\n                except Exception as e:\n                    print(f\"Error processing {lab_id}/{video_id}: {e}\")\n                    continue\n            \n            # Group consecutive frames\n            predictions_df = pd.DataFrame(all_predictions)\n            if len(predictions_df) > 0:\n                predictions_df['group'] = (\n                    (predictions_df['agent_id'] != predictions_df['agent_id'].shift()) |\n                    (predictions_df['target_id'] != predictions_df['target_id'].shift()) |\n                    (predictions_df['action'] != predictions_df['action'].shift()) |\n                    (predictions_df['frame'] != predictions_df['frame'].shift() + 1)\n                ).cumsum()\n                \n                grouped = predictions_df.groupby(['video_id', 'agent_id', 'target_id', 'action', 'group'])\n                result = grouped.agg(\n                    start_frame=('frame', 'min'),\n                    stop_frame=('frame', 'max')\n                ).reset_index().drop('group', axis=1)\n                \n                submission_df = result\n            else:\n                submission_df = pd.DataFrame(columns=['video_id', 'agent_id', 'target_id', 'action', 'start_frame', 'stop_frame'])\n            \n            submission_df['row_id'] = range(len(submission_df))\n            submission_df = submission_df[['row_id', 'video_id', 'agent_id', 'target_id', 'action', 'start_frame', 'stop_frame']]\n            submission_df.to_csv('/kaggle/working/submission.csv', index=False)\n            print(\"Submission saved to /kaggle/working/submission.csv\")\n            return\n        \n        # Process each test video with the trained model\n        all_predictions = []\n        for _, row in tqdm(test_meta.iterrows(), total=len(test_meta)):\n            lab_id = row['lab_id']\n            video_id = row['video_id']\n            \n            predictions = process_test_video(lab_id, video_id, model, scaler)\n            all_predictions.extend(predictions)\n        \n        # Create submission\n        submission_df = pd.DataFrame(all_predictions)\n        if len(submission_df) > 0:\n            submission_df['row_id'] = range(len(submission_df))\n            submission_df = submission_df[['row_id', 'video_id', 'agent_id', 'target_id', 'action', 'start_frame', 'stop_frame']]\n        else:\n            # Create empty submission with correct columns\n            submission_df = pd.DataFrame(columns=['row_id', 'video_id', 'agent_id', 'target_id', 'action', 'start_frame', 'stop_frame'])\n        \n        # Save submission\n        submission_df.to_csv('/kaggle/working/submission.csv', index=False)\n        print(\"Submission saved to /kaggle/working/submission.csv\")\n        \n    else:\n        # Train model only\n        print(\"No test data available, training model...\")\n        train_model()\n        print(\"Model training complete.\")\n\nif __name__ == \"__main__\":\n    main()","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-09-19T07:00:56.384188Z","iopub.execute_input":"2025-09-19T07:00:56.385034Z","iopub.status.idle":"2025-09-19T07:05:43.723724Z","shell.execute_reply.started":"2025-09-19T07:00:56.384997Z","shell.execute_reply":"2025-09-19T07:05:43.72293Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd \ndf = pd.read_csv(\"/kaggle/working/submission.csv\")\ndf","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-19T07:08:35.764474Z","iopub.execute_input":"2025-09-19T07:08:35.765167Z","iopub.status.idle":"2025-09-19T07:08:35.784721Z","shell.execute_reply.started":"2025-09-19T07:08:35.765143Z","shell.execute_reply":"2025-09-19T07:08:35.784185Z"}},"outputs":[],"execution_count":null}]}