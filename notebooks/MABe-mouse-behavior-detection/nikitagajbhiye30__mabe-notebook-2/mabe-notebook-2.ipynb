{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":59156,"databundleVersionId":13719397,"isSourceIdPinned":false,"sourceType":"competition"}],"dockerImageVersionId":31089,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-09-22T14:26:38.881728Z","iopub.execute_input":"2025-09-22T14:26:38.882119Z","iopub.status.idle":"2025-09-22T14:26:48.670527Z","shell.execute_reply.started":"2025-09-22T14:26:38.88209Z","shell.execute_reply":"2025-09-22T14:26:48.669356Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\"\"\"\nMABe Challenge - Fixed Hybrid Approach\n======================================\nProperly handles MultiIndex data structure and edge cases\n\"\"\"\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm\nimport itertools\nimport warnings\nimport json\nimport os\nimport gc\nfrom collections import defaultdict\n\nfrom sklearn.base import ClassifierMixin, BaseEstimator, clone\nfrom sklearn.model_selection import cross_val_predict, GroupKFold\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\nfrom sklearn.metrics import f1_score\nimport polars as pl\n\nwarnings.filterwarnings('ignore')\n\n# =============================================\n# CONFIGURATION\n# =============================================\n\nvalidate_or_submit = 'submit'\nverbose = True\n\nprint(\"=\"*60)\nprint(\"MABe Challenge - Fixed Hybrid Approach\")\nprint(\"=\"*60)\nprint(f\"Mode: {validate_or_submit}\")\nprint(\"=\"*60)\n\n# =============================================\n# CUSTOM CLASSES\n# =============================================\n\nclass TrainOnSubsetClassifier(ClassifierMixin, BaseEstimator):\n    \"\"\"Fit estimator to a subset of the training data.\"\"\"\n    def __init__(self, estimator, n_samples):\n        self.estimator = estimator\n        self.n_samples = n_samples\n\n    def fit(self, X, y):\n        downsample = max(1, len(X) // self.n_samples)\n        self.estimator.fit(np.array(X, copy=False)[::downsample],\n                          np.array(y, copy=False)[::downsample])\n        self.classes_ = self.estimator.classes_\n        return self\n\n    def predict_proba(self, X):\n        return self.estimator.predict_proba(np.array(X))\n        \n    def predict(self, X):\n        return self.estimator.predict(np.array(X))\n\n# =============================================\n# SCORING FUNCTIONS  \n# =============================================\n\nclass HostVisibleError(Exception):\n    pass\n\ndef single_lab_f1(lab_solution: pl.DataFrame, lab_submission: pl.DataFrame, beta: float = 1) -> float:\n    label_frames = defaultdict(set)\n    prediction_frames = defaultdict(set)\n    \n    for row in lab_solution.to_dicts():\n        label_frames[row['label_key']].update(range(row['start_frame'], row['stop_frame']))\n\n    for video in lab_solution['video_id'].unique():\n        active_labels = lab_solution.filter(pl.col('video_id') == video)['behaviors_labeled'].first()\n        active_labels = set(json.loads(active_labels))\n        predicted_mouse_pairs = defaultdict(set)\n\n        for row in lab_submission.filter(pl.col('video_id') == video).to_dicts():\n            if ','.join([str(row['agent_id']), str(row['target_id']), row['action']]) not in active_labels:\n                continue\n           \n            new_frames = set(range(row['start_frame'], row['stop_frame']))\n            new_frames = new_frames.difference(prediction_frames[row['prediction_key']])\n            prediction_pair = ','.join([str(row['agent_id']), str(row['target_id'])])\n            \n            if predicted_mouse_pairs[prediction_pair].intersection(new_frames):\n                raise HostVisibleError('Multiple predictions for the same frame')\n            \n            prediction_frames[row['prediction_key']].update(new_frames)\n            predicted_mouse_pairs[prediction_pair].update(new_frames)\n\n    tps = defaultdict(int)\n    fns = defaultdict(int)\n    fps = defaultdict(int)\n    \n    for key, pred_frames in prediction_frames.items():\n        action = key.split('_')[-1]\n        matched_label_frames = label_frames[key]\n        tps[action] += len(pred_frames.intersection(matched_label_frames))\n        fns[action] += len(matched_label_frames.difference(pred_frames))\n        fps[action] += len(pred_frames.difference(matched_label_frames))\n\n    distinct_actions = set()\n    for key, frames in label_frames.items():\n        action = key.split('_')[-1]\n        distinct_actions.add(action)\n        if key not in prediction_frames:\n            fns[action] += len(frames)\n\n    action_f1s = []\n    for action in distinct_actions:\n        if tps[action] + fns[action] + fps[action] == 0:\n            action_f1s.append(0)\n        else:\n            action_f1s.append((1 + beta**2) * tps[action] / \n                            ((1 + beta**2) * tps[action] + beta**2 * fns[action] + fps[action]))\n    \n    return sum(action_f1s) / len(action_f1s)\n\ndef mouse_fbeta(solution: pd.DataFrame, submission: pd.DataFrame, beta: float = 1) -> float:\n    if len(solution) == 0 or len(submission) == 0:\n        raise ValueError('Missing solution or submission data')\n\n    expected_cols = ['video_id', 'agent_id', 'target_id', 'action', 'start_frame', 'stop_frame']\n    \n    for col in expected_cols:\n        if col not in solution.columns:\n            raise ValueError(f'Solution is missing column {col}')\n        if col not in submission.columns:\n            raise ValueError(f'Submission is missing column {col}')\n\n    solution = pl.DataFrame(solution)\n    submission = pl.DataFrame(submission)\n    \n    assert (solution['start_frame'] <= solution['stop_frame']).all()\n    assert (submission['start_frame'] <= submission['stop_frame']).all()\n    \n    solution_videos = set(solution['video_id'].unique())\n    submission = submission.filter(pl.col('video_id').is_in(solution_videos))\n\n    solution = solution.with_columns(\n        pl.concat_str([\n            pl.col('video_id').cast(pl.Utf8),\n            pl.col('agent_id').cast(pl.Utf8),\n            pl.col('target_id').cast(pl.Utf8),\n            pl.col('action'),\n        ], separator='_').alias('label_key'),\n    )\n    \n    submission = submission.with_columns(\n        pl.concat_str([\n            pl.col('video_id').cast(pl.Utf8),\n            pl.col('agent_id').cast(pl.Utf8),\n            pl.col('target_id').cast(pl.Utf8),\n            pl.col('action'),\n        ], separator='_').alias('prediction_key'),\n    )\n\n    lab_scores = []\n    for lab in solution['lab_id'].unique():\n        lab_solution = solution.filter(pl.col('lab_id') == lab).clone()\n        lab_videos = set(lab_solution['video_id'].unique())\n        lab_submission = submission.filter(pl.col('video_id').is_in(lab_videos)).clone()\n        lab_scores.append(single_lab_f1(lab_solution, lab_submission, beta=beta))\n\n    return sum(lab_scores) / len(lab_scores)\n\ndef score(solution: pd.DataFrame, submission: pd.DataFrame, row_id_column_name: str, beta: float = 1) -> float:\n    solution = solution.drop(row_id_column_name, axis='columns', errors='ignore')\n    submission = submission.drop(row_id_column_name, axis='columns', errors='ignore')\n    return mouse_fbeta(solution, submission, beta=beta)\n\n# =============================================\n# DATA LOADING\n# =============================================\n\nprint(\"\\nðŸ“ Loading data...\")\ntrain = pd.read_csv('/kaggle/input/MABe-mouse-behavior-detection/train.csv')\ntrain['n_mice'] = 4 - train[['mouse1_strain', 'mouse2_strain', 'mouse3_strain', 'mouse4_strain']].isna().sum(axis=1)\ntrain_without_mabe22 = train.query(\"~ lab_id.str.startswith('MABe22_')\")\n\ntest = pd.read_csv('/kaggle/input/MABe-mouse-behavior-detection/test.csv')\nbody_parts_tracked_list = list(np.unique(train.body_parts_tracked))\n\nprint(f\"âœ… Loaded {len(train)} training videos\")\nprint(f\"âœ… Found {len(body_parts_tracked_list)} body part configurations\")\n\n# =============================================\n# SOLUTION CREATION\n# =============================================\n\ndef create_solution_df(dataset):\n    solution = []\n    for _, row in tqdm(dataset.iterrows(), total=len(dataset)):\n        lab_id = row['lab_id']\n        if lab_id.startswith('MABe22'): \n            continue\n        video_id = row['video_id']\n        path = f\"/kaggle/input/MABe-mouse-behavior-detection/train_annotation/{lab_id}/{video_id}.parquet\"\n        try:\n            annot = pd.read_parquet(path)\n        except FileNotFoundError:\n            if verbose: \n                print(f\"No annotations for {path}\")\n            continue\n        \n        annot['lab_id'] = lab_id\n        annot['video_id'] = video_id\n        annot['behaviors_labeled'] = row['behaviors_labeled']\n        annot['target_id'] = np.where(annot.target_id != annot.agent_id, \n                                     annot['target_id'].apply(lambda s: f\"mouse{s}\"), 'self')\n        annot['agent_id'] = annot['agent_id'].apply(lambda s: f\"mouse{s}\")\n        solution.append(annot)\n    \n    solution = pd.concat(solution)\n    return solution\n\nif validate_or_submit == 'validate':\n    solution = create_solution_df(train_without_mabe22)\n\n# =============================================\n# DATA GENERATION\n# =============================================\n\ndef generate_mouse_data(dataset, traintest, traintest_directory=None, generate_single=True, generate_pair=True):\n    assert traintest in ['train', 'test']\n    if traintest_directory is None:\n        traintest_directory = f\"/kaggle/input/MABe-mouse-behavior-detection/{traintest}_tracking\"\n    \n    for _, row in dataset.iterrows():\n        lab_id = row.lab_id\n        if lab_id.startswith('MABe22'): \n            continue\n        video_id = row.video_id\n        path = f\"{traintest_directory}/{lab_id}/{video_id}.parquet\"\n        \n        try:\n            vid = pd.read_parquet(path)\n            pvid = vid.pivot(columns=['mouse_id', 'bodypart'], index='video_frame', values=['x', 'y'])\n            \n            if pvid.isna().any().any():\n                if verbose and traintest == 'test': \n                    print(f'Video {video_id}: missing values, {len(vid)} frames')\n            else:\n                if verbose and traintest == 'test': \n                    print(f'Video {video_id}: complete, {len(vid)} frames')\n            \n            del vid\n            pvid = pvid.reorder_levels([1, 2, 0], axis=1).T.sort_index().T  # mouse_id, body_part, xy\n            pvid /= row.pix_per_cm_approx  # Convert to cm\n            \n            vid_behaviors = json.loads(row.behaviors_labeled)\n            vid_behaviors = sorted(list({b.replace(\"'\", \"\") for b in vid_behaviors}))\n            vid_behaviors = [b.split(',') for b in vid_behaviors]\n            vid_behaviors = pd.DataFrame(vid_behaviors, columns=['agent', 'target', 'action'])\n            \n            if traintest == 'train':\n                try:\n                    annot = pd.read_parquet(path.replace('train_tracking', 'train_annotation'))\n                except FileNotFoundError:\n                    continue\n            \n            # Generate single mouse data\n            if generate_single:\n                vid_behaviors_subset = vid_behaviors.query(\"target == 'self'\")\n                for mouse_id_str in np.unique(vid_behaviors_subset.agent):\n                    try:\n                        mouse_id = int(mouse_id_str[-1])\n                        vid_agent_actions = np.unique(vid_behaviors_subset.query(\"agent == @mouse_id_str\").action)\n                        single_mouse = pvid.loc[:, mouse_id]\n                        assert len(single_mouse) == len(pvid)\n                        \n                        single_mouse_meta = pd.DataFrame({\n                            'video_id': video_id,\n                            'agent_id': mouse_id_str,\n                            'target_id': 'self',\n                            'video_frame': single_mouse.index\n                        })\n                        \n                        if traintest == 'train':\n                            single_mouse_label = pd.DataFrame(0.0, columns=vid_agent_actions, index=single_mouse.index)\n                            annot_subset = annot.query(\"(agent_id == @mouse_id) & (target_id == @mouse_id)\")\n                            for i in range(len(annot_subset)):\n                                annot_row = annot_subset.iloc[i]\n                                single_mouse_label.loc[annot_row['start_frame']:annot_row['stop_frame'], \n                                                     annot_row.action] = 1.0\n                            yield 'single', single_mouse, single_mouse_meta, single_mouse_label\n                        else:\n                            if verbose: \n                                print(f'  Processing single mouse {mouse_id}')\n                            yield 'single', single_mouse, single_mouse_meta, vid_agent_actions\n                    except KeyError:\n                        pass\n            \n            # Generate pair data\n            if generate_pair:\n                vid_behaviors_subset = vid_behaviors.query(\"target != 'self'\")\n                if len(vid_behaviors_subset) > 0:\n                    for agent, target in itertools.permutations(np.unique(pvid.columns.get_level_values('mouse_id')), 2):\n                        agent_str = f\"mouse{agent}\"\n                        target_str = f\"mouse{target}\"\n                        vid_agent_actions = np.unique(vid_behaviors_subset.query(\n                            \"(agent == @agent_str) & (target == @target_str)\").action)\n                        \n                        try:\n                            mouse_pair = pd.concat([pvid[agent], pvid[target]], axis=1, keys=['A', 'B'])\n                            assert len(mouse_pair) == len(pvid)\n                            \n                            mouse_pair_meta = pd.DataFrame({\n                                'video_id': video_id,\n                                'agent_id': agent_str,\n                                'target_id': target_str,\n                                'video_frame': mouse_pair.index\n                            })\n                            \n                            if traintest == 'train':\n                                mouse_pair_label = pd.DataFrame(0.0, columns=vid_agent_actions, index=mouse_pair.index)\n                                annot_subset = annot.query(\"(agent_id == @agent) & (target_id == @target)\")\n                                for i in range(len(annot_subset)):\n                                    annot_row = annot_subset.iloc[i]\n                                    mouse_pair_label.loc[annot_row['start_frame']:annot_row['stop_frame'], \n                                                       annot_row.action] = 1.0\n                                yield 'pair', mouse_pair, mouse_pair_meta, mouse_pair_label\n                            else:\n                                if verbose: \n                                    print(f'  Processing pair {agent} -> {target}')\n                                yield 'pair', mouse_pair, mouse_pair_meta, vid_agent_actions\n                        except KeyError:\n                            pass\n                            \n        except Exception as e:\n            if verbose:\n                print(f\"Error processing {video_id}: {e}\")\n            continue\n\n# =============================================\n# FEATURE ENGINEERING (FIXED)\n# =============================================\n\ndef transform_single(single_mouse, body_parts_tracked):\n    \"\"\"Transform from cartesian coordinates to distance representation.\n    Fixed to handle MultiIndex properly.\"\"\"\n    try:\n        X = pd.DataFrame({\n            f\"{part1}+{part2}\": np.square(single_mouse[part1] - single_mouse[part2]).sum(axis=1, skipna=False)\n            for part1, part2 in itertools.combinations(body_parts_tracked, 2)\n        })\n        \n        # Add temporal features if key body parts exist\n        if 'ear_left' in single_mouse.columns and 'ear_right' in single_mouse.columns:\n            if 'tail_base' in single_mouse.columns:\n                shifted = single_mouse[['ear_left', 'ear_right', 'tail_base']].shift(10)\n                X = pd.concat([\n                    X, \n                    pd.DataFrame({\n                        'speed_left': np.square(single_mouse['ear_left'] - shifted['ear_left']).sum(axis=1, skipna=False),\n                        'speed_right': np.square(single_mouse['ear_right'] - shifted['ear_right']).sum(axis=1, skipna=False),\n                        'speed_left2': np.square(single_mouse['ear_left'] - shifted['tail_base']).sum(axis=1, skipna=False),\n                        'speed_right2': np.square(single_mouse['ear_right'] - shifted['tail_base']).sum(axis=1, skipna=False),\n                    })\n                ], axis=1)\n            else:\n                # Without tail_base, just use ear speeds\n                shifted = single_mouse[['ear_left', 'ear_right']].shift(10)\n                X = pd.concat([\n                    X,\n                    pd.DataFrame({\n                        'speed_left': np.square(single_mouse['ear_left'] - shifted['ear_left']).sum(axis=1, skipna=False),\n                        'speed_right': np.square(single_mouse['ear_right'] - shifted['ear_right']).sum(axis=1, skipna=False),\n                    })\n                ], axis=1)\n        \n        return X\n        \n    except Exception as e:\n        if verbose:\n            print(f\"    Transform error: {e}\")\n        # Return minimal features on error\n        return pd.DataFrame(index=single_mouse.index)\n\ndef transform_pair(mouse_pair, body_parts_tracked):\n    \"\"\"Transform from cartesian coordinates to distance representation for pairs.\n    Fixed to handle MultiIndex properly.\"\"\"\n    try:\n        drop_body_parts = ['ear_left', 'ear_right', 'headpiece_bottombackleft', \n                          'headpiece_bottombackright', 'headpiece_bottomfrontleft',\n                          'headpiece_bottomfrontright', 'headpiece_topbackleft',\n                          'headpiece_topbackright', 'headpiece_topfrontleft',\n                          'headpiece_topfrontright', 'tail_midpoint']\n        \n        if len(body_parts_tracked) > 5:\n            body_parts_tracked = [b for b in body_parts_tracked if b not in drop_body_parts]\n        \n        X = pd.DataFrame({\n            f\"12+{part1}+{part2}\": np.square(mouse_pair['A'][part1] - mouse_pair['B'][part2]).sum(axis=1, skipna=False)\n            for part1, part2 in itertools.product(body_parts_tracked, repeat=2)\n        })\n        \n        # Add temporal features if available\n        if ('A', 'ear_left') in mouse_pair.columns and ('B', 'ear_left') in mouse_pair.columns:\n            shifted_A = mouse_pair['A']['ear_left'].shift(10)\n            shifted_B = mouse_pair['B']['ear_left'].shift(10)\n            X = pd.concat([\n                X,\n                pd.DataFrame({\n                    'speed_left_A': np.square(mouse_pair['A']['ear_left'] - shifted_A).sum(axis=1, skipna=False),\n                    'speed_left_AB': np.square(mouse_pair['A']['ear_left'] - shifted_B).sum(axis=1, skipna=False),\n                    'speed_left_B': np.square(mouse_pair['B']['ear_left'] - shifted_B).sum(axis=1, skipna=False),\n                })\n            ], axis=1)\n        \n        return X\n        \n    except Exception as e:\n        if verbose:\n            print(f\"    Transform error: {e}\")\n        # Return minimal features on error\n        return pd.DataFrame(index=mouse_pair.index)\n\n# =============================================\n# PREDICTION\n# =============================================\n\nthreshold = 0.27\n\ndef predict_multiclass(pred, meta):\n    \"\"\"Derive multiclass predictions from binary predictions.\"\"\"\n    ama = np.argmax(pred, axis=1)\n    ama = np.where(pred.max(axis=1) >= threshold, ama, -1)\n    ama = pd.Series(ama, index=meta.video_frame)\n    \n    changes_mask = (ama != ama.shift(1)).values\n    ama_changes = ama[changes_mask]\n    meta_changes = meta[changes_mask]\n    \n    mask = ama_changes.values >= 0\n    mask[-1] = False\n    \n    submission_part = pd.DataFrame({\n        'video_id': meta_changes['video_id'][mask].values,\n        'agent_id': meta_changes['agent_id'][mask].values,\n        'target_id': meta_changes['target_id'][mask].values,\n        'action': pred.columns[ama_changes[mask].values],\n        'start_frame': ama_changes.index[mask],\n        'stop_frame': ama_changes.index[1:][mask[:-1]]\n    })\n    \n    stop_video_id = meta_changes['video_id'][1:][mask[:-1]].values\n    stop_agent_id = meta_changes['agent_id'][1:][mask[:-1]].values\n    stop_target_id = meta_changes['target_id'][1:][mask[:-1]].values\n    \n    for i in range(len(submission_part)):\n        video_id = submission_part.video_id.iloc[i]\n        agent_id = submission_part.agent_id.iloc[i]\n        target_id = submission_part.target_id.iloc[i]\n        \n        if i >= len(stop_video_id) or stop_video_id[i] != video_id or \\\n           stop_agent_id[i] != agent_id or stop_target_id[i] != target_id:\n            new_stop_frame = meta.query(\"(video_id == @video_id)\").video_frame.max() + 1\n            submission_part.iat[i, submission_part.columns.get_loc('stop_frame')] = new_stop_frame\n    \n    assert (submission_part.stop_frame > submission_part.start_frame).all(), 'stop <= start'\n    if verbose: \n        print(f'  Actions found: {len(submission_part)}')\n    \n    return submission_part\n\n# =============================================\n# CROSS-VALIDATION\n# =============================================\n\ndef cross_validate_classifier(binary_classifier, X, label, meta):\n    global f1_list, submission_list\n    \n    oof = pd.DataFrame(index=meta.video_frame)\n    \n    for action in label.columns:\n        action_mask = ~label[action].isna().values\n        X_action = X[action_mask]\n        y_action = label[action][action_mask].values.astype(int)\n        p = y_action.mean()\n        baseline_score = p / (1 + p) if p > 0 else 0\n        groups_action = meta.video_id[action_mask]\n        \n        if len(np.unique(groups_action)) < 5:\n            continue\n        \n        if not (y_action == 0).all():\n            with warnings.catch_warnings():\n                warnings.filterwarnings('ignore', category=RuntimeWarning)\n                oof_action = cross_val_predict(binary_classifier, X_action, y_action, \n                                             groups=groups_action, cv=GroupKFold(), \n                                             method='predict_proba')\n            oof_action = oof_action[:, 1]\n        else:\n            oof_action = np.zeros(len(y_action))\n        \n        f1 = f1_score(y_action, (oof_action >= threshold), zero_division=0)\n        ch = '>' if f1 > baseline_score else '=' if f1 == baseline_score else '<'\n        print(f\"F1: {f1:.3f} {ch} ({baseline_score:.3f}) {action}\")\n        f1_list.append((body_parts_tracked_str, action, f1))\n        \n        oof_column = np.zeros(len(label))\n        oof_column[action_mask] = oof_action\n        oof[action] = oof_column\n    \n    submission_part = predict_multiclass(oof, meta)\n    submission_list.append(submission_part)\n\n# =============================================\n# SUBMISSION (FIXED)\n# =============================================\n\ndef submit(body_parts_tracked_str, switch_tr, binary_classifier, X_tr, label, meta):\n    global submission_list\n    \n    model_list = []\n    \n    for action in label.columns:\n        action_mask = ~label[action].isna().values\n        y_action = label[action][action_mask].values.astype(int)\n        \n        if not (y_action == 0).all():\n            model = clone(binary_classifier)\n            model.fit(X_tr[action_mask], y_action)\n            assert len(model.classes_) == 2\n            model_list.append((action, model))\n    \n    body_parts_tracked = json.loads(body_parts_tracked_str)\n    test_subset = test[test.body_parts_tracked == body_parts_tracked_str]\n    \n    if len(test_subset) == 0:\n        if verbose:\n            print(f\"  No test videos for this configuration\")\n        return\n    \n    generator = generate_mouse_data(test_subset, 'test',\n                                  generate_single=(switch_tr == 'single'), \n                                  generate_pair=(switch_tr == 'pair'))\n    \n    if verbose: \n        print(f\"  Processing {len(test_subset)} test videos\")\n    \n    for switch_te, data_te, meta_te, actions_te in generator:\n        assert switch_te == switch_tr\n        try:\n            if switch_te == 'single':\n                X_te = transform_single(data_te, body_parts_tracked)\n            else:\n                X_te = transform_pair(data_te, body_parts_tracked)\n            \n            # Skip if transform failed\n            if X_te.empty or len(X_te.columns) == 0:\n                if verbose:\n                    print(\"  Skipping due to transform failure\")\n                continue\n            \n            del data_te\n            \n            pred = pd.DataFrame(index=meta_te.video_frame)\n            for action, model in model_list:\n                if action in actions_te:\n                    try:\n                        pred[action] = model.predict_proba(X_te)[:, 1]\n                    except:\n                        pass\n            \n            del X_te\n            \n            if pred.shape[1] != 0:\n                submission_part = predict_multiclass(pred, meta_te)\n                submission_list.append(submission_part)\n                    \n        except Exception as e:\n            if verbose: \n                print(f'  Error during prediction: {e}')\n            if 'data_te' in locals():\n                del data_te\n\n# =============================================\n# ROBUSTIFY (FIXED)\n# =============================================\n\ndef robustify(submission, dataset, traintest, traintest_directory=None):\n    if traintest_directory is None:\n        traintest_directory = f\"/kaggle/input/MABe-mouse-behavior-detection/{traintest}_tracking\"\n    \n    # Handle empty submission\n    if submission is None or len(submission) == 0:\n        submission = pd.DataFrame(columns=['video_id', 'agent_id', 'target_id', \n                                          'action', 'start_frame', 'stop_frame'])\n    \n    # Rule 1: Ensure start_frame < stop_frame\n    if len(submission) > 0 and 'start_frame' in submission.columns and 'stop_frame' in submission.columns:\n        old_len = len(submission)\n        submission = submission[submission.start_frame < submission.stop_frame]\n        if len(submission) != old_len:\n            print(\"  Cleaned: Dropped frames with start >= stop\")\n    \n    # Rule 2: Avoid multiple predictions\n    if len(submission) > 0:\n        group_list = []\n        for _, group in submission.groupby(['video_id', 'agent_id', 'target_id']):\n            group = group.sort_values('start_frame')\n            mask = np.ones(len(group), dtype=bool)\n            last_stop_frame = 0\n            for i, (_, row) in enumerate(group.iterrows()):\n                if row['start_frame'] < last_stop_frame:\n                    mask[i] = False\n                else:\n                    last_stop_frame = row['stop_frame']\n            group_list.append(group[mask])\n        \n        if group_list:\n            submission = pd.concat(group_list)\n    \n    # Rule 3: Submit something for every video\n    s_list = []\n    for idx, row in dataset.iterrows():\n        lab_id = row['lab_id']\n        if lab_id.startswith('MABe22'):\n            continue\n        video_id = row['video_id']\n        \n        if len(submission) == 0 or not (submission.video_id == video_id).any():\n            if verbose: \n                print(f\"  Filling video {video_id} with default predictions\")\n            \n            try:\n                path = f\"{traintest_directory}/{lab_id}/{video_id}.parquet\"\n                vid = pd.read_parquet(path)\n                \n                vid_behaviors = eval(row['behaviors_labeled'])\n                vid_behaviors = sorted(list({b.replace(\"'\", \"\") for b in vid_behaviors}))\n                vid_behaviors = [b.split(',') for b in vid_behaviors]\n                vid_behaviors = pd.DataFrame(vid_behaviors, columns=['agent', 'target', 'action'])\n                \n                start_frame = int(vid.video_frame.min())\n                stop_frame = int(vid.video_frame.max() + 1)\n                \n                for (agent, target), actions in vid_behaviors.groupby(['agent', 'target']):\n                    batch_length = int(np.ceil((stop_frame - start_frame) / len(actions)))\n                    for i, (_, action_row) in enumerate(actions.iterrows()):\n                        batch_start = start_frame + i * batch_length\n                        batch_stop = min(batch_start + batch_length, stop_frame)\n                        s_list.append((video_id, agent, target, action_row['action'], \n                                     batch_start, batch_stop))\n            except:\n                # Minimal fallback\n                s_list.append((video_id, 'mouse1', 'self', 'rear', 0, 50))\n    \n    if len(s_list) > 0:\n        new_df = pd.DataFrame(s_list, columns=['video_id', 'agent_id', 'target_id', \n                                               'action', 'start_frame', 'stop_frame'])\n        if len(submission) > 0:\n            submission = pd.concat([submission, new_df], ignore_index=True)\n        else:\n            submission = new_df\n        print(\"  Filled empty videos\")\n    \n    submission = submission.reset_index(drop=True)\n    return submission\n\n# =============================================\n# MAIN PROCESSING LOOP\n# =============================================\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"STARTING MAIN PROCESSING\")\nprint(\"=\"*60)\n\nf1_list = []\nsubmission_list = []\n\n# Process each body part configuration\nfor section in range(1, len(body_parts_tracked_list)):\n    body_parts_tracked_str = body_parts_tracked_list[section]\n    \n    try:\n        body_parts_tracked = json.loads(body_parts_tracked_str)\n        print(f\"\\n{section}. Processing videos with {len(body_parts_tracked)} body parts\")\n        \n        train_subset = train[train.body_parts_tracked == body_parts_tracked_str]\n        \n        if len(train_subset) == 0:\n            print(\"  No training data for this configuration\")\n            continue\n        \n        single_mouse_list = []\n        single_mouse_label_list = []\n        single_mouse_meta_list = []\n        mouse_pair_list = []\n        mouse_pair_label_list = []\n        mouse_pair_meta_list = []\n        \n        # Collect training data\n        for switch, data, meta, label in generate_mouse_data(train_subset, 'train'):\n            if switch == 'single':\n                single_mouse_list.append(data)\n                single_mouse_meta_list.append(meta)\n                single_mouse_label_list.append(label)\n            else:\n                mouse_pair_list.append(data)\n                mouse_pair_meta_list.append(meta)\n                mouse_pair_label_list.append(label)\n        \n        # Create classifier\n        binary_classifier = make_pipeline(\n            SimpleImputer(),\n            StandardScaler(),\n            TrainOnSubsetClassifier(KNeighborsClassifier(n_neighbors=11), 20000)\n        )\n        \n        # Process single mouse actions\n        if len(single_mouse_list) > 0:\n            try:\n                print(f\"  Processing {len(single_mouse_list)} single mouse batches\")\n                \n                single_mouse = pd.concat(single_mouse_list)\n                single_mouse_label = pd.concat(single_mouse_label_list)\n                single_mouse_meta = pd.concat(single_mouse_meta_list)\n                \n                del single_mouse_list, single_mouse_label_list, single_mouse_meta_list\n                \n                X_tr = transform_single(single_mouse, body_parts_tracked)\n                \n                # Check if transform succeeded\n                if not X_tr.empty and len(X_tr.columns) > 0:\n                    del single_mouse\n                    print(f\"  Features shape: {X_tr.shape}\")\n                    \n                    if validate_or_submit == 'validate':\n                        cross_validate_classifier(binary_classifier, X_tr, single_mouse_label, \n                                                single_mouse_meta)\n                    else:\n                        submit(body_parts_tracked_str, 'single', binary_classifier, X_tr, \n                              single_mouse_label, single_mouse_meta)\n                    \n                    del X_tr\n                else:\n                    print(\"  Transform failed for single mouse\")\n                    del single_mouse\n                    \n                gc.collect()\n                \n            except Exception as e:\n                print(f\"  Exception in single mouse: {e}\")\n        \n        # Process mouse pair actions\n        if len(mouse_pair_list) > 0:\n            try:\n                print(f\"  Processing {len(mouse_pair_list)} mouse pair batches\")\n                \n                mouse_pair = pd.concat(mouse_pair_list)\n                mouse_pair_label = pd.concat(mouse_pair_label_list)\n                mouse_pair_meta = pd.concat(mouse_pair_meta_list)\n                \n                del mouse_pair_list, mouse_pair_label_list, mouse_pair_meta_list\n                \n                X_tr = transform_pair(mouse_pair, body_parts_tracked)\n                \n                # Check if transform succeeded\n                if not X_tr.empty and len(X_tr.columns) > 0:\n                    del mouse_pair\n                    print(f\"  Features shape: {X_tr.shape}\")\n                    \n                    if validate_or_submit == 'validate':\n                        cross_validate_classifier(binary_classifier, X_tr, mouse_pair_label, \n                                                mouse_pair_meta)\n                    else:\n                        submit(body_parts_tracked_str, 'pair', binary_classifier, X_tr, \n                              mouse_pair_label, mouse_pair_meta)\n                    \n                    del X_tr\n                else:\n                    print(\"  Transform failed for mouse pair\")\n                    del mouse_pair\n                    \n                gc.collect()\n                \n            except Exception as e:\n                print(f\"  Exception in mouse pair: {e}\")\n            \n    except Exception as e:\n        print(f\"  Exception in section {section}: {e}\")\n        continue\n    \n    print()\n\n# =============================================\n# FINALIZE SUBMISSION\n# =============================================\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"FINALIZING SUBMISSION\")\nprint(\"=\"*60)\n\nif validate_or_submit == 'validate' and submission_list:\n    submission = pd.concat(submission_list)\n    submission_robust = robustify(submission, train, 'train')\n    print(f\"\\nâœ… OOF score: {score(solution, submission_robust, ''):.4f}\")\n    \n    if f1_list:\n        f1_df = pd.DataFrame(f1_list, columns=['body_parts', 'action', 'f1_score'])\n        print(f\"âœ… Average binary F1: {f1_df['f1_score'].mean():.4f}\")\n\nelif validate_or_submit == 'submit':\n    if submission_list:\n        submission = pd.concat(submission_list)\n        print(f\"\\nGenerated {len(submission)} predictions from models\")\n    else:\n        submission = pd.DataFrame()\n        print(\"\\nNo predictions generated from models\")\n    \n    submission_robust = robustify(submission, test, 'test')\n    submission_robust.index.name = 'row_id'\n    submission_robust.to_csv('submission.csv')\n    \n    print(f\"\\nâœ… Final submission: {len(submission_robust)} rows\")\n    print(\"âœ… Saved to submission.csv\")\n    \n    # Show sample\n    print(\"\\nFirst 10 rows:\")\n    print(submission_robust.head(10))\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"COMPLETE\")\nprint(\"=\"*60)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-22T21:07:01.466537Z","iopub.execute_input":"2025-09-22T21:07:01.466844Z","iopub.status.idle":"2025-09-22T21:07:03.944025Z","shell.execute_reply.started":"2025-09-22T21:07:01.466817Z","shell.execute_reply":"2025-09-22T21:07:03.94323Z"}},"outputs":[],"execution_count":null}]}