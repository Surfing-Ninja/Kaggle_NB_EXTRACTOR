{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":59156,"databundleVersionId":13874099,"sourceType":"competition"},{"sourceId":13188459,"sourceType":"datasetVersion","datasetId":8357725}],"dockerImageVersionId":31089,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"%%writefile baseline.py\n\nfrom __future__ import annotations\n\nimport argparse\nimport json\nimport logging\nimport os\nimport warnings\nfrom dataclasses import dataclass\nfrom pathlib import Path\nfrom typing import Dict, Iterable, List, Optional, Set, Tuple, Any\nfrom collections import defaultdict\nimport joblib\nimport numpy as np\nimport polars as pl\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report\nfrom xgboost import XGBClassifier\nfrom tqdm.auto import tqdm\n\n# ========================\n# Config\n# ========================\nALLOWED_AGENT = {f\"mouse{i}\" for i in range(1, 5)}\nALLOWED_TARGET = {f\"mouse{i}\" for i in range(1, 5)} | {\"self\"}\n\n@dataclass(frozen=True)\nclass Config:\n    data_root: Path = Path(os.getenv(\"MABE_DATA_ROOT\", \"/kaggle/input/MABe-mouse-behavior-detection\"))\n    submission_file: str = os.getenv(\"MABe_SUBMISSION\", \"submission.csv\")\n    row_id_col: str = os.getenv(\"MABe_ROW_ID_COL\", \"row_id\")\n\n    @property\n    def train_csv(self) -> Path: return self.data_root / \"train.csv\"\n    @property\n    def test_csv(self) -> Path: return self.data_root / \"test.csv\"\n    @property\n    def train_annot_dir(self) -> Path: return self.data_root / \"train_annotation\"\n    @property\n    def train_track_dir(self) -> Path: return self.data_root / \"train_tracking\"\n    @property\n    def test_track_dir(self) -> Path: return self.data_root / \"test_tracking\"\n\n    @property\n    def submission_schema(self) -> Dict[str, pl.DataType]:\n        return {\n            \"video_id\": pl.Int64, \"agent_id\": pl.Utf8, \"target_id\": pl.Utf8,\n            \"action\": pl.Utf8, \"start_frame\": pl.Int64, \"stop_frame\": pl.Int64,\n        }\n\n    @property\n    def solution_schema(self) -> Dict[str, pl.DataType]:\n        return {\n            \"video_id\": pl.Int64, \"agent_id\": pl.Utf8, \"target_id\": pl.Utf8,\n            \"action\": pl.Utf8, \"start_frame\": pl.Int64, \"stop_frame\": pl.Int64,\n            \"lab_id\": pl.Utf8, \"behaviors_labeled\": pl.Utf8,\n        }\n\nlogger = logging.getLogger(__name__)\n\nclass HostVisibleError(Exception): pass\n\ndef setup_logging(verbosity: int = 1) -> None:\n    level = logging.WARNING if verbosity <= 0 else logging.INFO if verbosity == 1 else logging.DEBUG\n    logging.basicConfig(level=level, format=\"%(asctime)s | %(levelname)s | %(name)s | %(message)s\", force=True)\n\n# ========================\n# Utils & Validators\n# ========================\n\ndef safe_json_loads(s: Optional[str]) -> List[str]:\n    if s is None: return []\n    if isinstance(s, list): return [str(x) for x in s]\n    if not isinstance(s, str): return []\n    s = s.strip()\n    if not s: return []\n    try:\n        return json.loads(s)\n    except Exception:\n        try: return json.loads(s.replace(\"'\", '\"'))\n        except Exception: return []\n\ndef validate_schema(df: pl.DataFrame, schema: Dict[str, pl.DataType], name: str) -> pl.DataFrame:\n    missing = set(schema.keys()) - set(df.columns)\n    if missing: raise ValueError(f\"{name} is missing columns: {missing}\")\n    casts = [pl.col(col).cast(dtype) for col, dtype in schema.items() if df[col].dtype != dtype]\n    return df.with_columns(casts) if casts else df\n\ndef validate_frame_ranges(df: pl.DataFrame, name: str) -> None:\n    if not (df[\"start_frame\"] <= df[\"stop_frame\"]).all():\n        raise ValueError(f\"{name}: start_frame > stop_frame detected\")\n\ndef _norm_mouse_id(x: str | int) -> str:\n    s = str(x)\n    return s if s.startswith(\"mouse\") else f\"mouse{s}\"\n\ndef _norm_triplet(agent: str | int, target: str | int, action: str) -> str:\n    return f\"{_norm_mouse_id(agent)},{_norm_mouse_id(target)},{action}\"\n\ndef _range_frames(start: int, stop: int) -> Iterable[int]:\n    return range(start, stop)  # [start, stop)\n\ndef merge_intervals(intervals: List[Tuple[int,int]]) -> List[Tuple[int,int]]:\n    if not intervals: return []\n    intervals = sorted(intervals)\n    merged = [intervals[0]]\n    for s,e in intervals[1:]:\n        ps,pe = merged[-1]\n        if s <= pe: merged[-1] = (ps, max(pe, e))\n        else: merged.append((s,e))\n    return merged\n\ndef split_interval(s: int, e: int, parts: int) -> List[Tuple[int,int]]:\n    if parts <= 1: return [(s,e)]\n    L = e - s\n    step = L // parts\n    rem = L % parts\n    out = []\n    cur = s\n    for i in range(parts):\n        extra = 1 if i < rem else 0\n        nxt = cur + step + extra\n        out.append((cur, min(nxt, e)))\n        cur = nxt\n    return out\n\ndef largest_remainder_allocation(total: int, weights: List[float]) -> List[int]:\n    if total <= 0 or not weights: return [0]*len(weights)\n    s = sum(weights) or 1.0\n    w = [x/s for x in weights]\n    raw = [total*x for x in w]\n    base = [int(v) for v in raw]\n    remainder = total - sum(base)\n    if remainder > 0:\n        fr = sorted([(i, raw[i]-base[i]) for i in range(len(w))], key=lambda x: x[1], reverse=True)\n        for i in range(remainder):\n            base[fr[i % len(w)][0]] += 1\n    return base\n\n# ========================\n# Metrics (F-beta)\n# ========================\n\ndef single_lab_f1(lab_solution: pl.DataFrame, lab_submission: pl.DataFrame, beta: float = 1.0) -> float:\n    label_frames: Dict[str, Set[int]] = defaultdict(set)\n    for row in lab_solution.to_dicts():\n        label_frames[row[\"label_key\"]].update(_range_frames(row[\"start_frame\"], row[\"stop_frame\"]))\n\n    active_by_video: Dict[int, Set[str]] = {}\n    for row in lab_solution.select([\"video_id\", \"behaviors_labeled\"]).unique().to_dicts():\n        s: Set[str] = set()\n        for item in safe_json_loads(row[\"behaviors_labeled\"]):\n            parts = [p.strip() for p in str(item).replace(\"'\", \"\").split(\",\")]\n            if len(parts) == 3:\n                a, t, act = parts\n                s.add(_norm_triplet(a, t, act))\n        active_by_video[int(row[\"video_id\"])] = s\n\n    prediction_frames: Dict[str, Set[int]] = defaultdict(set)\n    for video_id in lab_solution[\"video_id\"].unique():\n        active = active_by_video.get(int(video_id), set())\n        predicted_mouse_pairs: Dict[str, Set[int]] = defaultdict(set)\n        for row in lab_submission.filter(pl.col(\"video_id\") == video_id).to_dicts():\n            triple_norm = _norm_triplet(row[\"agent_id\"], row[\"target_id\"], row[\"action\"])\n            if triple_norm not in active:\n                continue\n            pred_key = row[\"prediction_key\"]\n            agent_target = f\"{row['agent_id']},{row['target_id']}\"\n            new_frames = set(_range_frames(row[\"start_frame\"], row[\"stop_frame\"]))\n            new_frames -= prediction_frames[pred_key]\n            if predicted_mouse_pairs[agent_target] & new_frames:\n                raise HostVisibleError(\"Multiple predictions for the same frame from one agent/target pair\")\n            prediction_frames[pred_key].update(new_frames)\n            predicted_mouse_pairs[agent_target].update(new_frames)\n\n    tps: Dict[str, int] = defaultdict(int)\n    fns: Dict[str, int] = defaultdict(int)\n    fps: Dict[str, int] = defaultdict(int)\n    distinct_actions: Set[str] = set()\n\n    for key, pred_frames in prediction_frames.items():\n        action = key.split(\"_\")[-1]\n        distinct_actions.add(action)\n        gt_frames = label_frames.get(key, set())\n        tps[action] += len(pred_frames & gt_frames)\n        fns[action] += len(gt_frames - pred_frames)\n        fps[action] += len(pred_frames - gt_frames)\n\n    for key, gt_frames in label_frames.items():\n        action = key.split(\"_\")[-1]\n        distinct_actions.add(action)\n        if key not in prediction_frames:\n            fns[action] += len(gt_frames)\n\n    if not distinct_actions:\n        return 0.0\n\n    beta2 = beta * beta\n    f_scores: List[float] = []\n    for action in distinct_actions:\n        tp, fn, fp = tps[action], fns[action], fps[action]\n        denom = (1 + beta2) * tp + beta2 * fn + fp\n        f_scores.append(0.0 if denom == 0 else (1 + beta2) * tp / denom)\n    return sum(f_scores) / len(f_scores)\n\ndef mouse_fbeta(solution: pl.DataFrame, submission: pl.DataFrame, beta: float = 1.0, cfg: Optional[Config] = None) -> float:\n    cfg = cfg or Config()\n    solution = validate_schema(solution, cfg.solution_schema, \"Solution\")\n    submission = validate_schema(submission, cfg.submission_schema, \"Submission\")\n    validate_frame_ranges(solution, \"Solution\")\n    validate_frame_ranges(submission, \"Submission\")\n\n    solution_videos = solution[\"video_id\"].unique()\n    submission = submission.filter(pl.col(\"video_id\").is_in(solution_videos))\n\n    def add_key(df: pl.DataFrame, col_name: str) -> pl.DataFrame:\n        return df.with_columns(\n            pl.concat_str(\n                [\n                    pl.col(\"video_id\").cast(pl.Utf8),\n                    pl.col(\"agent_id\").cast(pl.Utf8),\n                    pl.col(\"target_id\").cast(pl.Utf8),\n                    pl.col(\"action\"),\n                ],\n                separator=\"_\",\n            ).alias(col_name)\n        )\n\n    solution = add_key(solution, \"label_key\")\n    submission = add_key(submission, \"prediction_key\")\n\n    lab_scores: List[float] = []\n    for lab_id in solution[\"lab_id\"].unique():\n        lab_solution = solution.filter(pl.col(\"lab_id\") == lab_id)\n        lab_videos = lab_solution[\"video_id\"].unique()\n        lab_submission = submission.filter(pl.col(\"video_id\").is_in(lab_videos))\n        lab_scores.append(single_lab_f1(lab_solution, lab_submission, beta=beta))\n\n    return sum(lab_scores) / len(lab_scores) if lab_scores else 0.0\n\ndef score(solution: pl.DataFrame, submission: pl.DataFrame, row_id_column_name: str = \"\", beta: float = 1.0, cfg: Optional[Config] = None) -> float:\n    if row_id_column_name:\n        solution = solution.drop(row_id_column_name, strict=False)\n        submission = submission.drop(row_id_column_name, strict=False)\n    return mouse_fbeta(solution, submission, beta=beta, cfg=cfg)\n\n# ========================\n# Build solution + video spans\n# ========================\n\ndef create_solution_df(dataset: pl.DataFrame, cfg: Optional[Config] = None) -> pl.DataFrame:\n    cfg = cfg or Config()\n    records: List[pl.DataFrame] = []\n    for row in tqdm(dataset.to_dicts(), total=len(dataset), desc=\"Building solution\"):\n        lab_id: str = row[\"lab_id\"]\n        if lab_id.startswith(\"MABe22\"): continue\n        video_id: int = row[\"video_id\"]\n        annot_path = cfg.train_annot_dir / lab_id / f\"{video_id}.parquet\"\n        if not annot_path.exists():\n            logger.warning(\"No annotations for %s\", annot_path)\n            continue\n        try:\n            annot = pl.read_parquet(annot_path).with_columns(\n                [\n                    pl.lit(lab_id).alias(\"lab_id\"),\n                    pl.lit(video_id).alias(\"video_id\"),\n                    pl.lit(row[\"behaviors_labeled\"]).alias(\"behaviors_labeled\"),\n                    pl.concat_str([pl.lit(\"mouse\"), pl.col(\"agent_id\").cast(pl.Utf8)]).alias(\"agent_id\"),\n                    pl.concat_str([pl.lit(\"mouse\"), pl.col(\"target_id\").cast(pl.Utf8)]).alias(\"target_id\"),\n                ]\n            )\n            for col, dtype in (cfg.solution_schema).items():\n                if col in annot.columns and annot[col].dtype != dtype:\n                    annot = annot.with_columns(pl.col(col).cast(dtype))\n            annot = annot.select([c for c in cfg.solution_schema.keys() if c in annot.columns])\n            records.append(annot)\n        except Exception as e:\n            logger.error(\"Failed to load %s: %s\", annot_path, e)\n            continue\n    if not records: raise ValueError(\"No annotation files loaded.\")\n    solution = pl.concat(records, how=\"vertical\")\n    solution = validate_schema(solution, cfg.solution_schema, \"Solution\")\n    return solution\n\ndef build_video_spans(dataset: pl.DataFrame, split: str, cfg: Optional[Config] = None) -> Dict[int, Tuple[int,int]]:\n    \"\"\"\n    Map video_id -> (min_frame, max_frame+1).\n    \"\"\"\n    cfg = cfg or Config()\n    track_dir = cfg.train_track_dir if split == \"train\" else cfg.test_track_dir\n    spans: Dict[int, Tuple[int,int]] = {}\n    for row in tqdm(dataset.to_dicts(), total=len(dataset), desc=\"Scanning spans\"):\n        lab_id = row[\"lab_id\"]\n        if lab_id.startswith(\"MABe22\"): continue\n        vid = row[\"video_id\"]\n        path = track_dir / lab_id / f\"{vid}.parquet\"\n        if not path.exists(): continue\n        try:\n            df = pl.read_parquet(path).select([\"video_frame\"])\n            s = int(df[\"video_frame\"].min())\n            e = int(df[\"video_frame\"].max()) + 1\n            spans[int(vid)] = (s,e)\n        except Exception as e:\n            logger.warning(\"Span read failed for %s: %s\", path, e)\n    return spans\n\n# ========================\n# Priors (duration & timing)\n# ========================\n\ndef compute_action_priors(solution: pl.DataFrame, eps: float = 1.0) -> Tuple[Dict[str, Dict[str, float]], Dict[str, float], Dict[str, Dict[str, int]], Dict[str, int]]:\n    \"\"\"\n    Returns:\n      per_lab_weight: {lab: {action: weight_share}}\n      global_weight: {action: weight_share}\n      per_lab_med_dur: {lab: {action: median_duration_frames}}\n      global_med_dur: {action: median_duration_frames}\n    \"\"\"\n    sol = solution.with_columns((pl.col(\"stop_frame\") - pl.col(\"start_frame\")).alias(\"dur\"))\n    # shares\n    by_lab = sol.group_by([\"lab_id\", \"action\"]).agg(pl.col(\"dur\").sum().alias(\"dur_sum\"))\n    global_ = sol.group_by([\"action\"]).agg(pl.col(\"dur\").sum().alias(\"dur_sum\"))\n    actions = set(global_[\"action\"].to_list())\n\n    per_lab_weight: Dict[str, Dict[str, float]] = defaultdict(dict)\n    for lab in by_lab[\"lab_id\"].unique():\n        sub = by_lab.filter(pl.col(\"lab_id\") == lab)\n        dmap = {r[\"action\"]: float(r[\"dur_sum\"]) for r in sub.to_dicts()}\n        for a in actions: dmap[a] = dmap.get(a, 0.0) + eps\n        total = sum(dmap.values()) or 1.0\n        per_lab_weight[str(lab)] = {a: dmap[a]/total for a in actions}\n\n    gmap = {r[\"action\"]: float(r[\"dur_sum\"]) for r in global_.to_dicts()}\n    for a in actions: gmap[a] = gmap.get(a, 0.0) + eps\n    gtotal = sum(gmap.values()) or 1.0\n    global_weight = {a: gmap[a]/gtotal for a in actions}\n\n    # median durations\n    med_by_lab = sol.group_by([\"lab_id\", \"action\"]).median().select([\"lab_id\",\"action\",\"dur\"])\n    per_lab_med_dur: Dict[str, Dict[str, int]] = defaultdict(dict)\n    for r in med_by_lab.to_dicts():\n        per_lab_med_dur[str(r[\"lab_id\"])][str(r[\"action\"])] = int(r[\"dur\"])\n    med_global = sol.group_by([\"action\"]).median().select([\"action\",\"dur\"])\n    global_med_dur: Dict[str, int] = {r[\"action\"]: int(r[\"dur\"]) for r in med_global.to_dicts()}\n\n    return per_lab_weight, global_weight, per_lab_med_dur, global_med_dur\n\ndef compute_timing_priors(solution: pl.DataFrame, video_spans: Dict[int, Tuple[int,int]]) -> Tuple[Dict[str, Dict[str, float]], Dict[str, float]]:\n    \"\"\"\n    Median start percentile per (lab, action) and global.\n    start_pct = (start_frame - video_start)/(video_stop - video_start)\n    \"\"\"\n    # attach start_pct\n    def start_pct_func(row) -> float:\n        vid = int(row[\"video_id\"])\n        if vid not in video_spans: return 0.5\n        s,e = video_spans[vid]\n        denom = max(1, e - s)\n        return float(max(0, min(1, (int(row[\"start_frame\"]) - s) / denom)))\n\n    rows = []\n    for r in solution.select([\"lab_id\",\"action\",\"video_id\",\"start_frame\"]).to_dicts():\n        rows.append({\"lab_id\": r[\"lab_id\"], \"action\": r[\"action\"], \"start_pct\": start_pct_func(r)})\n    df = pl.DataFrame(rows)\n    by_lab = df.group_by([\"lab_id\",\"action\"]).median().select([\"lab_id\",\"action\",\"start_pct\"])\n    per_lab: Dict[str, Dict[str, float]] = defaultdict(dict)\n    for r in by_lab.to_dicts():\n        per_lab[str(r[\"lab_id\"])][str(r[\"action\"])] = float(r[\"start_pct\"])\n    g = df.group_by([\"action\"]).median().select([\"action\",\"start_pct\"])\n    global_: Dict[str, float] = {r[\"action\"]: float(r[\"start_pct\"]) for r in g.to_dicts()}\n    return per_lab, global_\n\n# ========================\n# Tracking features → windows (TỐI ƯU HIỆU NĂNG - KHÔNG DÙNG PANDAS)\n# ========================\n\ndef _strip_mouse_prefix(s: str | int) -> str:\n    s = str(s)\n    return s[5:] if s.startswith(\"mouse\") else s\n\ndef _pair_features(df: pl.DataFrame, agent_raw: str, target_raw: str, downsample: int = 1) -> Optional[pl.DataFrame]:\n    \"\"\"\n    Extract pairwise features between agent and target.\n    Automatically handles different tracking schemas (with/without bodypart).\n    \"\"\"\n    # Candidate column names — prioritize centroid-based names\n    frame_candidates = [\"video_frame\", \"frame\", \"frame_idx\"]\n    id_candidates    = [\"mouse_id\", \"id\", \"track_id\", \"agent_id\"]\n    x_candidates     = [\"centroid_x\", \"cx\", \"x\", \"x_pos\", \"x_position\", \"x_mm\"]\n    y_candidates     = [\"centroid_y\", \"cy\", \"y\", \"y_pos\", \"y_position\", \"y_mm\"]\n\n    cols = set(df.columns)\n    frame_col = next((c for c in frame_candidates if c in cols), None)\n    id_col    = next((c for c in id_candidates    if c in cols), None)\n    x_col     = next((c for c in x_candidates     if c in cols), None)\n    y_col     = next((c for c in y_candidates     if c in cols), None)\n\n    if not all([frame_col, id_col, x_col, y_col]):\n        logger.warning(f\"Schema detection failed. Available: {list(cols)} | Required: frame, id, x, y\")\n        return None\n\n    a_id = _strip_mouse_prefix(agent_raw)\n    t_id = _strip_mouse_prefix(target_raw)\n\n    # Xử lý bodypart — nếu có, lấy body_center hoặc trung bình\n    if \"bodypart\" in cols:\n        # Ưu tiên bodypart trung tâm\n        preferred_parts = [\"body_center\", \"centroid\", \"center\", \"torso\", \"hip_center\", \"mid\"]\n        bodypart_col = \"bodypart\"\n\n        # Lọc các bodypart mong muốn\n        available_parts = df.select(bodypart_col).unique().to_series().to_list()\n        chosen_parts = [bp for bp in preferred_parts if bp in available_parts]\n\n        if not chosen_parts and available_parts:\n            # Nếu không có preferred → lấy tất cả\n            chosen_parts = available_parts[:3]  # giới hạn để tránh noise\n\n        if chosen_parts:\n            df = df.filter(pl.col(bodypart_col).is_in(chosen_parts))\n            # Group by frame, mouse_id → lấy trung bình x,y\n            df = df.group_by([frame_col, id_col]).agg([\n                pl.col(x_col).mean().alias(x_col),\n                pl.col(y_col).mean().alias(y_col)\n            ])\n        else:\n            logger.warning(\"bodypart exists but no valid parts found. Using all.\")\n            df = df.group_by([frame_col, id_col]).agg([\n                pl.col(x_col).mean().alias(x_col),\n                pl.col(y_col).mean().alias(y_col)\n            ])\n\n    # Chuẩn hoá ID → ép về string, loại bỏ prefix nếu cần\n    try:\n        df = df.with_columns([\n            pl.col(id_col).cast(pl.Utf8).str.replace(\"mouse\", \"\").str.strip_chars().alias(id_col)\n        ])\n    except Exception as e:\n        logger.warning(f\"ID normalization failed: {e}. Proceeding with raw IDs.\")\n\n    # Lọc dữ liệu agent và target\n    a_df = df.filter(pl.col(id_col) == a_id).sort(frame_col).unique(subset=[frame_col], keep=\"first\")\n    b_df = df.filter(pl.col(id_col) == t_id).sort(frame_col).unique(subset=[frame_col], keep=\"first\")\n\n    if a_df.is_empty() or b_df.is_empty():\n        logger.warning(f\"Agent {a_id} or target {t_id} not found in tracking data.\")\n        return None\n\n    # Gộp theo frame\n    merged = a_df.join(b_df, on=frame_col, how=\"inner\", suffix=\"_b\")\n\n    # Downsample\n    if downsample > 1:\n        merged = merged.filter(pl.int_range(0, pl.count()).over(frame_col) % downsample == 0)\n\n    if merged.is_empty():\n        return None\n\n    try:\n        # Tính toán features — fill null để tránh lỗi\n        feat = merged.with_columns([\n            ((pl.col(x_col) - pl.col(f\"{x_col}_b\"))**2 + (pl.col(y_col) - pl.col(f\"{y_col}_b\"))**2).sqrt().alias(\"dist\"),\n\n            # Vận tốc — dùng diff, fill null\n            ((pl.col(x_col).diff().fill_null(0))**2 + (pl.col(y_col).diff().fill_null(0))**2).sqrt().alias(\"speed_a\"),\n            ((pl.col(f\"{x_col}_b\").diff().fill_null(0))**2 + (pl.col(f\"{y_col}_b\").diff().fill_null(0))**2).sqrt().alias(\"speed_b\"),\n        ]).with_columns([\n            (pl.col(\"speed_a\") - pl.col(\"speed_b\")).alias(\"rel_speed\"),\n            (pl.col(\"speed_a\").diff().fill_null(0) - pl.col(\"speed_b\").diff().fill_null(0)).alias(\"rel_acc\"),\n            (pl.col(\"dist\").diff().fill_null(0)).alias(\"ddist\"),\n            pl.arctan2(pl.col(y_col) - pl.col(f\"{y_col}_b\"), pl.col(x_col) - pl.col(f\"{x_col}_b\")).alias(\"angle\"),\n            pl.arctan2(pl.col(y_col) - pl.col(f\"{y_col}_b\"), pl.col(x_col) - pl.col(f\"{x_col}_b\")).diff().fill_null(0).alias(\"dangle\"),\n\n            # Radial velocity — an toàn\n            (\n                (pl.col(x_col) - pl.col(f\"{x_col}_b\")) * pl.col(x_col).diff().fill_null(0) +\n                (pl.col(y_col) - pl.col(f\"{y_col}_b\")) * pl.col(y_col).diff().fill_null(0)\n            ).alias(\"radial_vel_numerator\"),\n            (pl.col(\"dist\") + 1e-8).alias(\"dist_safe\"),\n        ]).with_columns([\n            (pl.col(\"radial_vel_numerator\") / pl.col(\"dist_safe\")).alias(\"radial_vel\")\n        ]).select([\n            frame_col,\n            \"dist\", \"rel_speed\", \"rel_acc\", \"ddist\", \"angle\", \"dangle\", \"radial_vel\"\n        ]).rename({frame_col: \"frame\"}).sort(\"frame\")\n\n        return feat\n\n    except Exception as e:\n        logger.error(f\"Feature computation failed: {type(e).__name__}: {e}\")\n        return None\n\ndef _make_windows(\n    feat: pl.DataFrame,\n    min_len: int,\n    q_dist: float = 0.40,\n    q_rel: float = 0.60,\n    q_ddist: float = 0.40\n) -> List[Tuple[int, int]]:\n    if len(feat) == 0:\n        return []\n\n    # nếu self-like (dist==0 toàn đoạn) và có speed_a -> gate theo speed_a\n    is_self_like = (\"speed_a\" in feat.columns) and (float(feat[\"dist\"].max()) == 0.0)\n    if is_self_like:\n        qs = float(feat[\"speed_a\"].quantile(0.70))  # hoạt động mạnh của chính agent\n        cond = (pl.col(\"speed_a\") >= qs)\n    else:\n        qd  = float(feat[\"dist\"].quantile(q_dist))\n        qr  = float(feat[\"rel_speed\"].quantile(q_rel))\n        qdd = float(feat[\"ddist\"].quantile(q_ddist))\n        cond = (pl.col(\"dist\") <= qd) | ((pl.col(\"rel_speed\") >= qr) & (pl.col(\"ddist\") <= qdd))\n\n    mask = feat.select(cond.alias(\"m\")).to_series().to_list()\n    frames = feat[\"frame\"].to_list()\n\n    windows: List[Tuple[int,int]] = []\n    run: Optional[List[int]] = None\n    for i, flag in enumerate(mask):\n        if flag and run is None:\n            run = [frames[i], frames[i]]\n        elif flag and run is not None:\n            run[1] = frames[i]\n        elif (not flag) and run is not None:\n            s, e = run[0], run[1] + 1\n            if e - s >= min_len:\n                windows.append((s, e))\n            run = None\n    if run is not None:\n        s, e = run[0], run[1] + 1\n        if e - s >= min_len:\n            windows.append((s, e))\n\n    return merge_intervals(windows)\n\ndef _intervals_by_action_for_pair(annot_pair_df: pl.DataFrame) -> Dict[str, List[Tuple[int,int]]]:\n    \"\"\"\n    Tạo dict: action -> list[(start, stop)) cho ĐÚNG cặp (agent,target).\n    \"\"\"\n    out = defaultdict(list)\n    for r in annot_pair_df.select([\"action\",\"start_frame\",\"stop_frame\"]).to_dicts():\n        s = int(r[\"start_frame\"]); e = int(r[\"stop_frame\"])\n        if s < e:\n            out[str(r[\"action\"])].append((s, e))\n    # sắp theo start để overlop check nhanh hơn\n    for a in out.keys():\n        out[a].sort(key=lambda x: x[0])\n    return out\n\ndef _actions_in_window(intervals_by_action: Dict[str, List[Tuple[int,int]]], ws: int, we: int) -> Set[str]:\n    \"\"\"\n    Trả về tập action có overlap với cửa sổ [ws,we) cho cặp hiện tại.\n    \"\"\"\n    hits = set()\n    for a, ivs in intervals_by_action.items():\n        # nhánh nhanh: vì đã sort theo start, break sớm\n        for s, e in ivs:\n            if s >= we:  # các interval sau càng về sau, không overlap\n                break\n            if e > ws and s < we:  # overlap\n                hits.add(a); break\n    return hits\n\ndef extract_features_and_labels(\n    dataset: pl.DataFrame,\n    cfg: Config,\n    window_size: int = 15,\n    step_size: int = 15,\n    downsample: int = 10,\n) -> Tuple[Dict[str, List[np.ndarray]], List[Tuple[int, str, str, int, int]]]:\n    \"\"\"\n    PAIR-AWARE + SELF-AWARE:\n      - Với target='self' trong annotation (hoặc agent_id == target_id), coi là cặp self.\n      - Tạo features cho self bằng agent vs agent (dist=0, dùng speed_a,...).\n      - Gắn nhãn cửa sổ theo overlap giữa [ws,we) và các interval của ĐÚNG cặp đó.\n    \"\"\"\n    X_action = defaultdict(list)\n    metadata = []\n\n    for row in tqdm(dataset.to_dicts(), total=len(dataset), desc=\"Extracting features & labels (pair-aware)\"):\n        lab_id: str = row[\"lab_id\"]\n        if str(lab_id).startswith(\"MABe22\"):\n            continue\n        video_id: int = row[\"video_id\"]\n        annot_path = cfg.train_annot_dir / lab_id / f\"{video_id}.parquet\"\n        track_path = cfg.train_track_dir / lab_id / f\"{video_id}.parquet\"\n        if not annot_path.exists() or not track_path.exists():\n            continue\n\n        try:\n            trk_agg = _prepare_tracking_minimal(track_path)\n            if trk_agg is None or trk_agg.is_empty():\n                continue\n\n            # Đọc annotation và chuẩn hoá 'self'\n            annot_raw = pl.read_parquet(annot_path)\n            annot = annot_raw.with_columns(\n                pl.concat_str([pl.lit(\"mouse\"), pl.col(\"agent_id\").cast(pl.Utf8)]).alias(\"agent_id\"),\n                pl.when(pl.col(\"agent_id\") == pl.col(\"target_id\"))\n                  .then(pl.lit(\"self\"))\n                  .otherwise(pl.concat_str([pl.lit(\"mouse\"), pl.col(\"target_id\").cast(pl.Utf8)]))\n                  .alias(\"target_id\"),\n            ).select([\"agent_id\",\"target_id\",\"action\",\"start_frame\",\"stop_frame\"])\n\n            if annot.is_empty():\n                continue\n\n            # Duyệt theo từng CẶP trong annotation (đã bao gồm self nếu có)\n            for (agent, target), ann_pair in annot.group_by([\"agent_id\",\"target_id\"]):\n                agent = str(agent); target = str(target)\n                # target dùng cho feature: nếu 'self' thì dùng chính agent\n                target_for_feat = agent if target.lower() == \"self\" else target\n\n                feat_df = _pair_features_from_agg(trk_agg, agent, target_for_feat, downsample=downsample)\n                if feat_df is None or feat_df.height < window_size:\n                    continue\n\n                # intervals cho đúng cặp\n                intervals_by_action = _intervals_by_action_for_pair(ann_pair)\n\n                frames = feat_df[\"frame\"].to_numpy()\n                if len(frames) < window_size:\n                    continue\n\n                cols = [\"dist\",\"rel_speed\",\"rel_acc\",\"ddist\",\"angle\",\"dangle\",\"radial_vel\"]\n                arrs = {c: feat_df[c].to_numpy() for c in cols}\n\n                for start_idx in range(0, len(frames) - window_size + 1, step_size):\n                    ws = int(frames[start_idx])\n                    we = int(frames[start_idx + window_size - 1]) + 1\n                    feats = []\n                    for c in cols:\n                        arr = arrs[c][start_idx:start_idx+window_size]\n                        feats.extend([\n                            float(arr.mean()), float(arr.std()),\n                            float(arr.min()), float(arr.max()),\n                            float(np.median(arr)), float(arr.max() - arr.min()),\n                            float(arr[-1] - arr[0]),\n                        ])\n\n                    # NHÃN: action xảy ra trong cửa sổ của CHÍNH cặp này\n                    acts = _actions_in_window(intervals_by_action, ws, we)\n                    if not acts:\n                        continue\n                    for a in acts:\n                        X_action[a].append(np.asarray(feats, dtype=np.float32))\n                    metadata.append((video_id, agent, target, ws, we))\n\n        except Exception as e:\n            logger.error(f\"Error processing video {video_id} (lab {lab_id}): {type(e).__name__}: {e}\")\n            continue\n\n    logger.info(f\"Extracted pair-aware windows for {len(X_action)} actions.\")\n    return X_action, metadata\n\n# ========================\n# Advanced baseline prediction\n# ========================\n\ndef _order_actions_by_timing(actions: List[str], lab_id: str,\n                             timing_lab: Dict[str, Dict[str, float]],\n                             timing_global: Dict[str, float],\n                             canonical: Dict[str,int]) -> List[str]:\n    def score(a: str) -> float:\n        if lab_id in timing_lab and a in timing_lab[lab_id]:\n            return timing_lab[lab_id][a]\n        return timing_global.get(a, 0.5)\n    return sorted(actions, key=lambda a: (score(a), canonical.get(a, 99)))\n\ndef _clip_rare_actions(weights_map: Dict[str,float], actions: List[str], p_min: float, cap: float) -> Dict[str,float]:\n    w = {a: max(0.0, float(weights_map.get(a, 0.0))) for a in actions}\n    for a in actions:\n        if w[a] < p_min:\n            w[a] = min(w[a], cap)\n    s = sum(w.values()) or 1.0\n    return {a: w[a]/s for a in actions}\n\ndef _allocate_segments_in_windows(windows: List[Tuple[int,int]],\n                                  ordered_actions: List[str],\n                                  weights: Dict[str,float],\n                                  med_dur: Dict[str,int],\n                                  total_frames: int) -> List[Tuple[str,int,int]]:\n    win_idx = 0\n    cur_s, cur_e = (windows[0] if windows else (0,0))\n    remain = sum(e-s for s,e in windows)\n    out: List[Tuple[str,int,int]] = []\n\n    for a in ordered_actions:\n        if remain <= 0: break\n        want = int(weights.get(a, 0.0) * total_frames)\n        want = max(want, int(med_dur.get(a, 0) or 0))\n        want = min(want, remain)\n        got = 0\n        while got < want and win_idx < len(windows):\n            s,e = cur_s, cur_e\n            if s >= e:\n                win_idx += 1\n                if win_idx >= len(windows): break\n                cur_s, cur_e = windows[win_idx]\n                continue\n            take = min(want - got, e - s)\n            out.append((a, s, s+take))\n            got += take\n            remain -= take\n            cur_s = s + take\n            if cur_s >= e and win_idx < len(windows):\n                win_idx += 1\n                if win_idx < len(windows):\n                    cur_s, cur_e = windows[win_idx]\n    return out\n\ndef _smooth_segments(segments: List[Tuple[str,int,int]], min_len: int, gap_close: int) -> List[Tuple[str,int,int]]:\n    if not segments: return []\n    segments = sorted(segments, key=lambda x: (x[1], x[2], x[0]))\n    segments = [seg for seg in segments if seg[2] - seg[1] >= min_len]\n    if not segments: return []\n    out = [segments[0]]\n    for a,s,e in segments[1:]:\n        pa,ps,pe = out[-1]\n        if a == pa and s - pe <= gap_close:\n            out[-1] = (a, ps, e)\n        else:\n            out.append((a,s,e))\n    return out\n\ndef predict_without_ml(dataset: pl.DataFrame, data_split: str, cfg: Optional[Config] = None,\n                       priors_per_lab: Optional[Dict[str, Dict[str, float]]] = None,\n                       priors_global: Optional[Dict[str, float]] = None,\n                       meddur_per_lab: Optional[Dict[str, Dict[str, int]]] = None,\n                       meddur_global: Optional[Dict[str, int]] = None,\n                       timing_lab: Optional[Dict[str, Dict[str, float]]] = None,\n                       timing_global: Optional[Dict[str, float]] = None,\n                       prior_scope: str = \"mixed\",\n                       use_windows: bool = True,\n                       min_len: int = 10,\n                       gap_close: int = 5,\n                       p_min: float = 0.03,\n                       cap: float = 0.02) -> pl.DataFrame:\n    cfg = cfg or Config()\n    track_dir = cfg.test_track_dir if data_split == \"test\" else cfg.train_track_dir\n    records: List[Tuple[int, str, str, str, int, int]] = []\n    canonical = {\"approach\": 0, \"avoid\": 1, \"chase\": 2, \"chaseattack\": 3, \"attack\": 4, \"mount\": 5, \"submit\": 6}\n\n    for row in tqdm(dataset.to_dicts(), total=len(dataset), desc=f\"Predicting ({data_split})\"):\n        lab_id: str = row[\"lab_id\"]\n        if lab_id.startswith(\"MABe22\"): continue\n        video_id: int = row[\"video_id\"]\n        path = track_dir / lab_id / f\"{video_id}.parquet\"\n        if not path.exists():\n            logger.warning(\"Tracking file not found: %s\", path)\n            continue\n\n        try:\n            trk = pl.read_parquet(path)\n            start_frame = int(trk[\"video_frame\"].min())\n            stop_frame = int(trk[\"video_frame\"].max()) + 1\n            video_frames = stop_frame - start_frame\n            if video_frames <= 0: continue\n\n            raw_list = safe_json_loads(row[\"behaviors_labeled\"])\n            triples: List[List[str]] = []\n            for b in raw_list:\n                parts = [p.strip() for p in str(b).replace(\"'\", \"\").split(\",\")]\n                if len(parts) == 3:\n                    triples.append(parts)\n            if not triples:\n                continue\n\n            beh_df = pl.DataFrame(triples, schema=[\"agent\",\"target\",\"action\"], orient=\"row\").with_columns(\n                [pl.col(\"agent\").cast(pl.Utf8), pl.col(\"target\").cast(pl.Utf8), pl.col(\"action\").cast(pl.Utf8)]\n            )\n\n            for (agent, target), group in beh_df.group_by([\"agent\",\"target\"]):\n                actions = sorted(list(set(group[\"action\"].to_list())), key=lambda a: canonical.get(a, 99))\n                if not actions: continue\n\n                if prior_scope == \"lab\" and priors_per_lab is not None:\n                    w_map = priors_per_lab.get(str(lab_id), {})\n                    md_map = meddur_per_lab.get(str(lab_id), {}) if meddur_per_lab else {}\n                elif prior_scope == \"global\" and priors_global is not None:\n                    w_map = priors_global\n                    md_map = meddur_global or {}\n                else:\n                    w_map = (priors_per_lab or {}).get(str(lab_id), {}) or (priors_global or {})\n                    md_map = (meddur_per_lab or {}).get(str(lab_id), {}) or (meddur_global or {})\n\n                weights = _clip_rare_actions(w_map, actions, p_min=p_min, cap=cap)\n                ordered_actions = _order_actions_by_timing(\n                    actions, str(lab_id), timing_lab or {}, timing_global or {}, canonical\n                )\n\n                windows: List[Tuple[int,int]]\n                if use_windows:\n                    feat = _pair_features(trk, _norm_mouse_id(agent), _norm_mouse_id(target))\n                    if feat is None:\n                        windows = [(start_frame, stop_frame)]\n                    else:\n                        windows = _make_windows(feat, min_len=min_len)\n                        if not windows:\n                            windows = [(start_frame, stop_frame)]\n                else:\n                    windows = [(start_frame, stop_frame)]\n\n                windows = merge_intervals(windows)\n                allowed_total = sum(e - s for s,e in windows)\n                if allowed_total <= 0:\n                    continue\n\n                segs = _allocate_segments_in_windows(\n                    windows=windows,\n                    ordered_actions=ordered_actions,\n                    weights=weights,\n                    med_dur=md_map,\n                    total_frames=allowed_total\n                )\n\n                segs = _smooth_segments(segs, min_len=min_len, gap_close=gap_close)\n\n                for a, s, e in segs:\n                    if e > s:\n                        records.append((\n                            video_id,\n                            _norm_mouse_id(agent), _norm_mouse_id(target),\n                            a, int(s), int(e)\n                        ))\n\n        except Exception as e:\n            logger.error(\"Error processing %s: %s\", path, e)\n            continue\n\n    if not records:\n        raise ValueError(\"No predictions generated.\")\n\n    df = pl.DataFrame(\n        records,\n        schema={\n            \"video_id\": pl.Int64, \"agent_id\": pl.Utf8, \"target_id\": pl.Utf8,\n            \"action\": pl.Utf8, \"start_frame\": pl.Int64, \"stop_frame\": pl.Int64,\n        },\n        orient=\"row\",\n    )\n    df = validate_schema(df, cfg.submission_schema, \"Submission\")\n    validate_frame_ranges(df, \"Submission\")\n    return df\n# ========================\n# Helpers (NEW)\n# ========================\n\ndef parse_behaviors_labeled(raw: Any) -> pl.DataFrame:\n    \"\"\"\n    Chuẩn hóa behaviors_labeled thành DataFrame (agent,target,action),\n    cho phép 'self' ở target. Không đổi 'self' khi xuất submission.\n    \"\"\"\n    triples = []\n    for b in safe_json_loads(raw):\n        parts = [p.strip() for p in str(b).replace(\"'\", \"\").split(\",\")]\n        if len(parts) == 3:\n            a, t, act = parts\n            if t.lower() == \"self\":\n                # target='self' giữ nguyên 'self' (không thêm prefix)\n                pass\n            else:\n                if not str(t).startswith(\"mouse\"):\n                    t = f\"mouse{t}\"\n            if not str(a).startswith(\"mouse\"):\n                a = f\"mouse{a}\"\n            triples.append([a, t, act])\n    if not triples:\n        return pl.DataFrame(schema={\"agent\": pl.Utf8, \"target\": pl.Utf8, \"action\": pl.Utf8})\n    return pl.DataFrame(triples, schema=[\"agent\", \"target\", \"action\"], orient=\"row\")\n\n\ndef _prepare_tracking_minimal(path: Path) -> Optional[pl.DataFrame]:\n    \"\"\"\n    Đọc parquet tracking, chỉ giữ (frame,id,x,y), gộp bodyparts nếu có.\n    Thực hiện MỘT LẦN cho mỗi video để tái sử dụng cho mọi cặp.\n    \"\"\"\n    if not path.exists():\n        return None\n    try:\n        df = pl.read_parquet(\n            path,\n            columns=[\"video_frame\", \"mouse_id\", \"centroid_x\", \"centroid_y\", \"x\", \"y\", \"bodypart\"],\n            ignore_errors=True,\n        )\n    except Exception:\n        df = pl.read_parquet(path)\n\n    cols = set(df.columns)\n    frame_col = \"video_frame\" if \"video_frame\" in cols else (\"frame\" if \"frame\" in cols else \"frame_idx\")\n    id_col    = \"mouse_id\"    if \"mouse_id\"    in cols else (\"id\"    if \"id\"    in cols else \"track_id\")\n    x_col     = \"centroid_x\"  if \"centroid_x\"  in cols else \"x\"\n    y_col     = \"centroid_y\"  if \"centroid_y\"  in cols else \"y\"\n\n    req = [frame_col, id_col, x_col, y_col]\n    if any(c not in df.columns for c in req):\n        logger.warning(f\"Tracking schema thiếu cột tối thiểu: {df.columns}\")\n        return None\n\n    if \"bodypart\" in cols:\n        preferred = [\"body_center\", \"centroid\", \"center\", \"torso\", \"hip_center\", \"mid\"]\n        parts = df.select(\"bodypart\").unique().to_series().to_list()\n        chosen = [p for p in preferred if p in parts] or (parts[:3] if parts else [])\n        if chosen:\n            df = df.filter(pl.col(\"bodypart\").is_in(chosen))\n        df = df.group_by([frame_col, id_col]).agg([\n            pl.col(x_col).mean().alias(x_col),\n            pl.col(y_col).mean().alias(y_col),\n        ])\n\n    # chuẩn hoá id (bỏ prefix 'mouse' để join)\n    df = df.with_columns([\n        pl.col(id_col).cast(pl.Utf8).str.replace(\"mouse\", \"\").str.strip_chars().alias(id_col)\n    ])\n\n    out = df.select([\n        pl.col(frame_col).alias(\"frame\"),\n        pl.col(id_col).alias(\"id\"),\n        pl.col(x_col).alias(\"x\"),\n        pl.col(y_col).alias(\"y\"),\n    ]).sort([\"frame\", \"id\"]).unique(subset=[\"frame\", \"id\"], keep=\"first\")\n\n    return out\n\n\ndef _pair_features_from_agg(agg_df: pl.DataFrame, agent_raw: str, target_raw: str, downsample: int = 1) -> Optional[pl.DataFrame]:\n    \"\"\"\n    Tạo feature cặp từ DF đã _prepare_tracking_minimal.\n    Giữ thêm 'speed_a' để gating tựa-self.\n    \"\"\"\n    a_id = _strip_mouse_prefix(agent_raw)\n    t_id = _strip_mouse_prefix(target_raw)\n    a_df = agg_df.filter(pl.col(\"id\") == a_id)\n    b_df = agg_df.filter(pl.col(\"id\") == t_id)\n    if a_df.is_empty() or b_df.is_empty():\n        return None\n\n    merged = a_df.join(b_df.rename({\"x\": \"x_b\", \"y\": \"y_b\"}), on=\"frame\", how=\"inner\")\n\n    if downsample > 1:\n        merged = merged.with_row_index(\"_i\").filter(pl.col(\"_i\") % downsample == 0).drop(\"_i\")\n\n    if merged.is_empty():\n        return None\n\n    feat = merged.with_columns([\n        ((pl.col(\"x\") - pl.col(\"x_b\"))**2 + (pl.col(\"y\") - pl.col(\"y_b\"))**2).sqrt().alias(\"dist\"),\n        ((pl.col(\"x\").diff().fill_null(0))**2 + (pl.col(\"y\").diff().fill_null(0))**2).sqrt().alias(\"speed_a\"),\n        ((pl.col(\"x_b\").diff().fill_null(0))**2 + (pl.col(\"y_b\").diff().fill_null(0))**2).sqrt().alias(\"speed_b\"),\n    ]).with_columns([\n        (pl.col(\"speed_a\") - pl.col(\"speed_b\")).alias(\"rel_speed\"),\n        (pl.col(\"speed_a\").diff().fill_null(0) - pl.col(\"speed_b\").diff().fill_null(0)).alias(\"rel_acc\"),\n        (pl.col(\"dist\").diff().fill_null(0)).alias(\"ddist\"),\n        pl.arctan2(pl.col(\"y\") - pl.col(\"y_b\"), pl.col(\"x\") - pl.col(\"x_b\")).alias(\"angle\"),\n        pl.arctan2(pl.col(\"y\") - pl.col(\"y_b\"), pl.col(\"x\") - pl.col(\"x_b\")).diff().fill_null(0).alias(\"dangle\"),\n        (\n            (pl.col(\"x\") - pl.col(\"x_b\")) * pl.col(\"x\").diff().fill_null(0) +\n            (pl.col(\"y\") - pl.col(\"y_b\")) * pl.col(\"y\").diff().fill_null(0)\n        ).alias(\"rv_num\"),\n    ]).with_columns([\n        (pl.col(\"rv_num\") / (pl.col(\"dist\") + 1e-8)).alias(\"radial_vel\")\n    ]).select([\n        \"frame\", \"dist\", \"rel_speed\", \"rel_acc\", \"ddist\", \"angle\", \"dangle\", \"radial_vel\", \"speed_a\"  # giữ speed_a\n    ]).sort(\"frame\")\n\n    return feat\n\n# ========================\n# MACHINE LEARNING TRAINING \n# ========================\n# ========================\n# Submission hardening (NEW)\n# ========================\n\nALLOWED_AGENT  = {f\"mouse{i}\" for i in range(1, 5)}\nALLOWED_TARGET = ALLOWED_AGENT | {\"self\"}\n\ndef _resolve_non_overlap(group: pl.DataFrame) -> pl.DataFrame:\n    \"\"\"\n    Biến các segment chồng lấp trong *cùng một cặp* thành không chồng lấp,\n    ưu tiên giữ đoạn xuất hiện trước (theo start_frame), gộp nếu cùng action liền kề.\n    \"\"\"\n    rows = group.select([\"action\", \"start_frame\", \"stop_frame\"]).to_dicts()\n    rows.sort(key=lambda r: (int(r[\"start_frame\"]), int(r[\"stop_frame\"]), str(r[\"action\"])))\n    out: List[Tuple[str, int, int]] = []\n    cur_end = -10**12\n\n    for r in rows:\n        a = str(r[\"action\"])\n        s = int(r[\"start_frame\"])\n        e = int(r[\"stop_frame\"])\n        if s >= e:\n            continue\n        # cắt phần chồng lấp với đoạn đã nhận\n        if s < cur_end:\n            s = cur_end\n        if s >= e:\n            continue\n        if out and out[-1][0] == a and s <= out[-1][2]:\n            out[-1] = (a, out[-1][1], max(out[-1][2], e))\n        else:\n            out.append((a, s, e))\n        cur_end = out[-1][2]\n\n    if not out:\n        return group.head(0)\n\n    return pl.DataFrame(out, schema={\"action\": pl.Utf8, \"start_frame\": pl.Int64, \"stop_frame\": pl.Int64})\n\n\nALLOWED_AGENT  = {f\"mouse{i}\" for i in range(1, 5)}\nALLOWED_TARGET = ALLOWED_AGENT | {\"self\"}\n\ndef _resolve_non_overlap(group: pl.DataFrame) -> pl.DataFrame:\n    \"\"\"\n    Biến các segment chồng lấp trong *cùng một cặp* thành không chồng lấp,\n    ưu tiên giữ đoạn xuất hiện trước (theo start_frame), gộp nếu cùng action liền kề.\n    \"\"\"\n    rows = group.select([\"action\", \"start_frame\", \"stop_frame\"]).to_dicts()\n    rows.sort(key=lambda r: (int(r[\"start_frame\"]), int(r[\"stop_frame\"]), str(r[\"action\"])))\n    out: List[Tuple[str, int, int]] = []\n    cur_end = -10**12\n\n    for r in rows:\n        a = str(r[\"action\"])\n        s = int(r[\"start_frame\"])\n        e = int(r[\"stop_frame\"])\n        if s >= e:\n            continue\n        # cắt phần chồng lấp với đoạn đã nhận\n        if s < cur_end:\n            s = cur_end\n        if s >= e:\n            continue\n        if out and out[-1][0] == a and s <= out[-1][2]:\n            out[-1] = (a, out[-1][1], max(out[-1][2], e))\n        else:\n            out.append((a, s, e))\n        cur_end = out[-1][2]\n\n    if not out:\n        return group.head(0)\n\n    return pl.DataFrame(out, schema={\"action\": pl.Utf8, \"start_frame\": pl.Int64, \"stop_frame\": pl.Int64})\n\n\ndef _finalize_and_validate_submission(\n    sub: pl.DataFrame,\n    meta_df: pl.DataFrame,\n    cfg: Config,\n    allowed_actions: Optional[Set[str]] = None,\n    split: str = \"test\",  # \"train\" | \"test\"\n) -> pl.DataFrame:\n    \"\"\"\n    - Cast/strip; filter id/action (target cho phép 'self')\n    - Clip theo span video, sau đó SHIFT về 0-based theo từng video\n    - Khử overlap per (video_id, agent_id, target_id)\n    - Sort theo (video, agent, target, start, stop), thêm row_id ở cột đầu\n    \"\"\"\n    # 0) Cast & strip\n    sub = validate_schema(sub, cfg.submission_schema, \"Submission\")\n    sub = sub.with_columns([\n        pl.col(\"agent_id\").cast(pl.Utf8).str.strip_chars(),\n        pl.col(\"target_id\").cast(pl.Utf8).str.strip_chars(),\n        pl.col(\"action\").cast(pl.Utf8).str.strip_chars(),\n    ])\n\n    # 1) Filter ids/actions\n    sub = sub.filter(\n        pl.col(\"agent_id\").is_in(ALLOWED_AGENT) &\n        pl.col(\"target_id\").is_in(ALLOWED_TARGET)\n    )\n    if allowed_actions:\n        sub = sub.filter(pl.col(\"action\").is_in(sorted(list(allowed_actions))))\n\n    # 2) Build spans & clip\n    spans = build_video_spans(meta_df, split, cfg)  # {vid: (min_frame, max_frame+1)}\n    if not spans:\n        raise HostVisibleError(\"Cannot build spans for clipping/validation.\")\n    spdf = pl.DataFrame({\n        \"video_id\": list(spans.keys()),\n        \"vmin\":    [spans[v][0] for v in spans.keys()],\n        \"vmaxp1\":  [spans[v][1] for v in spans.keys()],\n    })\n    sub = sub.join(spdf, on=\"video_id\", how=\"inner\").with_columns([\n        # clip vào [vmin, vmaxp1]\n        pl.when(pl.col(\"start_frame\") < pl.col(\"vmin\")).then(pl.col(\"vmin\")).otherwise(pl.col(\"start_frame\")).alias(\"start_frame\"),\n        pl.when(pl.col(\"stop_frame\")  > pl.col(\"vmaxp1\")).then(pl.col(\"vmaxp1\")).otherwise(pl.col(\"stop_frame\")).alias(\"stop_frame\"),\n    ])\n\n    # 3) SHIFT về 0-based theo từng video\n    sub = sub.with_columns([\n        (pl.col(\"start_frame\") - pl.col(\"vmin\")).cast(pl.Int64).alias(\"start_frame\"),\n        (pl.col(\"stop_frame\")  - pl.col(\"vmin\")).cast(pl.Int64).alias(\"stop_frame\"),\n        (pl.col(\"vmaxp1\") - pl.col(\"vmin\")).cast(pl.Int64).alias(\"_vlen\"),\n    ]).drop([\"vmin\", \"vmaxp1\"])\n\n    # 4) Drop invalid/empty, dedup exact\n    sub = sub.filter((pl.col(\"start_frame\") >= 0) & (pl.col(\"stop_frame\") <= pl.col(\"_vlen\")))\n    sub = sub.filter(pl.col(\"start_frame\") < pl.col(\"stop_frame\")).unique()\n\n    # 5) Enforce NON-OVERLAP per pair\n    groups = []\n    for (vid, ag, tg), g in sub.group_by([\"video_id\", \"agent_id\", \"target_id\"]):\n        fixed = _resolve_non_overlap(g)\n        if not fixed.is_empty():\n            fixed = fixed.with_columns([\n                pl.lit(int(vid)).alias(\"video_id\"),\n                pl.lit(str(ag)).alias(\"agent_id\"),\n                pl.lit(str(tg)).alias(\"target_id\"),\n            ]).select([\"video_id\",\"agent_id\",\"target_id\",\"action\",\"start_frame\",\"stop_frame\"])\n            groups.append(fixed)\n    sub = pl.concat(groups, how=\"vertical\") if groups else sub.head(0)\n\n    # 6) Final order + sort + row_id\n    sub = validate_schema(sub, cfg.submission_schema, \"Final Submission\")\n    sub = sub.sort([\"video_id\",\"agent_id\",\"target_id\",\"start_frame\",\"stop_frame\"]) \\\n             .select([\"video_id\",\"agent_id\",\"target_id\",\"action\",\"start_frame\",\"stop_frame\"]) \\\n             .with_row_index(cfg.row_id_col)\n\n    # 7) Hard checks\n    if set(sub.columns) != {cfg.row_id_col, *cfg.submission_schema.keys()}:\n        raise HostVisibleError(f\"Columns mismatch: {sub.columns}\")\n    if sub.height == 0:\n        raise HostVisibleError(\"Empty submission after hardening.\")\n    if sub.select([(pl.col(\"start_frame\") >= pl.col(\"stop_frame\")).any().alias(\"bad\")])[\"bad\"][0]:\n        raise HostVisibleError(\"Found start_frame >= stop_frame after hardening.\")\n    if sub.select([pl.any_horizontal([pl.col(c).is_null() for c in sub.columns]).alias(\"has_null\")])[\"has_null\"][0]:\n        raise HostVisibleError(\"Found NULL values.\")\n    bad_ids = sub.filter(~pl.col(\"agent_id\").is_in(ALLOWED_AGENT) | ~pl.col(\"target_id\").is_in(ALLOWED_TARGET))\n    if bad_ids.height > 0:\n        raise HostVisibleError(f\"Found invalid ids, e.g.: {bad_ids.head(3).to_dicts()}\")\n    if allowed_actions:\n        bad_act = sub.filter(~pl.col(\"action\").is_in(sorted(list(allowed_actions))))\n        if bad_act.height > 0:\n            raise HostVisibleError(f\"Found invalid actions, e.g.: {bad_act.head(3).to_dicts()}\")\n\n    return sub\n\n    \ndef _zero_base_solution(solution: pl.DataFrame, meta_df: pl.DataFrame, cfg: Config) -> pl.DataFrame:\n    \"\"\"\n    Dịch solution về 0-based theo từng video (dùng spans của TRAIN).\n    \"\"\"\n    spans = build_video_spans(meta_df, \"train\", cfg)\n    if not spans:\n        raise HostVisibleError(\"Cannot build train spans for solution zero-basing.\")\n    spdf = pl.DataFrame({\n        \"video_id\": list(spans.keys()),\n        \"vmin\":    [spans[v][0] for v in spans.keys()],\n        \"vmaxp1\":  [spans[v][1] for v in spans.keys()],\n    })\n    sol = solution.join(spdf, on=\"video_id\", how=\"inner\").with_columns([\n        (pl.col(\"start_frame\") - pl.col(\"vmin\")).cast(pl.Int64).alias(\"start_frame\"),\n        (pl.col(\"stop_frame\")  - pl.col(\"vmin\")).cast(pl.Int64).alias(\"stop_frame\"),\n    ]).drop([\"vmin\",\"vmaxp1\"])\n    validate_frame_ranges(sol, \"Zero-based Solution\")\n    return sol\n\n\ndef build_behavioral_graph(solution: pl.DataFrame, max_gap: int = 1, min_count: int = 2, min_freq: float = 0.005) -> Dict[str, Set[str]]:\n    from collections import defaultdict\n    transitions_raw = defaultdict(set)\n    transition_counts = defaultdict(int)\n\n    for key, group in solution.group_by([\"video_id\", \"agent_id\", \"target_id\"]):\n        sorted_group = group.sort(\"start_frame\")\n        rows = sorted_group.to_dicts()\n        for row in rows:\n            action = row[\"action\"]\n            transitions_raw[action].add(action)\n            transition_counts[(action, action)] += 1\n        for i in range(len(rows) - 1):\n            curr = rows[i]\n            next_ = rows[i + 1]\n            gap = next_[\"start_frame\"] - curr[\"stop_frame\"]\n            if gap <= max_gap:\n                a, b = curr[\"action\"], next_[\"action\"]\n                transitions_raw[a].add(b)\n                transition_counts[(a, b)] += 1\n\n    total_trans = sum(transition_counts.values())\n    min_threshold = max(min_count, int(min_freq * total_trans))\n    final_transitions = defaultdict(set)\n    for (a, b), cnt in transition_counts.items():\n        if cnt >= min_threshold:\n            final_transitions[a].add(b)\n\n    all_actions = set(solution[\"action\"].unique())\n    for a in all_actions:\n        if a not in final_transitions:\n            final_transitions[a] = {a}\n        elif a not in final_transitions[a]:\n            final_transitions[a].add(a)\n\n    return {k: v for k, v in final_transitions.items()}\n    \ndef extract_features_and_labels(\n    dataset: pl.DataFrame,\n    cfg: Config,\n    window_size: int = 15,\n    step_size: int = 15,\n    downsample: int = 10,\n) -> Tuple[Dict[str, List[np.ndarray]], List[Tuple[int, str, str, int, int]]]:\n\n    X_action = defaultdict(list)\n    metadata = []\n    all_actions = set()\n\n    for row in tqdm(dataset.to_dicts(), total=len(dataset), desc=\"Extracting features & labels (WSTAL)\"):\n        lab_id: str = row[\"lab_id\"]\n        if lab_id.startswith(\"MABe22\"): continue\n        video_id: int = row[\"video_id\"]\n        annot_path = cfg.train_annot_dir / lab_id / f\"{video_id}.parquet\"\n        track_path = cfg.train_track_dir / lab_id / f\"{video_id}.parquet\"\n        if not annot_path.exists() or not track_path.exists():\n            continue\n        try:\n            trk = pl.read_parquet(track_path)\n            annot = pl.read_parquet(annot_path).with_columns(\n                pl.concat_str([pl.lit(\"mouse\"), pl.col(\"agent_id\").cast(pl.Utf8)]).alias(\"agent_id\"),\n                pl.concat_str([pl.lit(\"mouse\"), pl.col(\"target_id\").cast(pl.Utf8)]).alias(\"target_id\"),\n            )\n            behavior_pairs = annot.select([\"agent_id\", \"target_id\"]).unique().to_dicts()\n            # Build frame_actions: frame -> set of actions\n            frame_actions = defaultdict(set)\n            for ann_row in annot.to_dicts():\n                action = ann_row[\"action\"]\n                all_actions.add(action)\n                for f in range(ann_row[\"start_frame\"], ann_row[\"stop_frame\"]):\n                    frame_actions[f].add(action)\n\n            for bp in behavior_pairs:\n                agent = bp[\"agent_id\"]\n                target = bp[\"target_id\"]\n                feat_df = _pair_features(trk, agent, target, downsample=downsample)\n                if feat_df is None or len(feat_df) == 0:\n                    continue\n                frames = feat_df[\"frame\"].to_numpy()\n                if len(frames) < window_size:\n                    continue\n                for start_idx in range(0, len(frames) - window_size + 1, step_size):\n                    win_start_frame = int(frames[start_idx])\n                    win_end_frame = int(frames[start_idx + window_size - 1]) + 1\n                    win_feat = feat_df.slice(start_idx, window_size)\n                    if len(win_feat) < window_size:\n                        continue\n                    features = []\n                    for col in [\"dist\", \"rel_speed\", \"rel_acc\", \"ddist\", \"angle\", \"dangle\", \"radial_vel\"]:\n                        arr = win_feat[col].to_numpy()\n                        features.extend([\n                            np.mean(arr), np.std(arr), np.min(arr), np.max(arr),\n                            np.median(arr), np.max(arr) - np.min(arr), arr[-1] - arr[0],\n                        ])\n                    # Weak labeling: window is positive for every action that appears in it\n                    window_actions = set()\n                    for f in range(win_start_frame, win_end_frame):\n                        window_actions.update(frame_actions[f])\n                    if window_actions:\n                        for action in window_actions:\n                            X_action[action].append(features)\n                        metadata.append((video_id, agent, target, win_start_frame, win_end_frame))\n        except Exception as e:\n            logger.error(f\"Error processing video {video_id} for lab {lab_id}: {type(e).__name__}: {e}\")\n            continue\n\n    logger.info(f\"Extracted data for {len(X_action)} actions.\")\n    return X_action, metadata\n\nimport numpy as np\nimport joblib\n\nPROCESSED_DATA_PATH = \"processed_mouse_data.npz\"\n# MODEL_PATH = \"mouse_behavior_model.joblib\" # train\nMODEL_PATH = \"/kaggle/input/mabexa/mouse_behavior_model (1).joblib\" # infer\n\ndef train_ml_model(cfg: Config, window_size: int = 15, step_size: int = 15, downsample: int = 10) -> None:\n    logger.info(\"Loading train data for ML training...\")\n    train = pl.read_csv(cfg.train_csv)\n    train_subset = train.filter(~pl.col(\"lab_id\").str.starts_with(\"MABe22\"))\n\n    if os.path.exists(PROCESSED_DATA_PATH):\n        logger.info(f\"Loading preprocessed data from {PROCESSED_DATA_PATH}\")\n        data = np.load(PROCESSED_DATA_PATH, allow_pickle=True)\n        X_action = {k: v.tolist() for k, v in data.items() if k != 'metadata'}\n        metadata = data['metadata']\n    else:\n        logger.info(\"Extracting features and labels (PAIR-AWARE + SELF-AWARE)...\")\n        X_action, metadata = extract_features_and_labels(\n            train_subset, cfg,\n            window_size=window_size,\n            step_size=step_size,\n            downsample=downsample,\n        )\n        save_dict = {action: np.array(feats) for action, feats in X_action.items()}\n        save_dict['metadata'] = np.array(metadata, dtype=object)\n        np.savez_compressed(PROCESSED_DATA_PATH, **save_dict)\n        logger.info(\"Preprocessed data saved.\")\n\n    # Train per-action binary models\n    models: Dict[str, Any] = {}\n    rng = np.random.default_rng(42)\n    for action, X_pos in X_action.items():\n        X_pos = np.array(X_pos, dtype=np.float32)\n        if len(X_pos) == 0:\n            logger.warning(f\"Skip action {action}: no positive samples.\")\n            continue\n\n        # Negative sampling từ các action khác\n        neg_pool = []\n        for other_act, feats in X_action.items():\n            if other_act != action:\n                neg_pool.extend(feats)\n        if not neg_pool:\n            neg_pool = X_pos  # fallback an toàn\n        neg_pool = np.array(neg_pool, dtype=np.float32)\n        n_neg = int(min(len(neg_pool), 5 * len(X_pos)))\n        neg_indices = rng.choice(len(neg_pool), size=n_neg, replace=False)\n        X_neg = neg_pool[neg_indices]\n\n        X = np.vstack([X_pos, X_neg])\n        y = np.hstack([np.ones(len(X_pos), dtype=np.int32), np.zeros(len(X_neg), dtype=np.int32)])\n\n        model = XGBClassifier(\n            n_estimators=300,\n            max_depth=7,\n            learning_rate=0.1,\n            subsample=0.8,\n            colsample_bytree=0.8,\n            scale_pos_weight=(len(X_neg) / max(1, len(X_pos))),\n            random_state=42,\n            n_jobs=-1,\n            verbosity=0,\n        )\n        model.fit(X, y)\n        models[action] = model\n        logger.info(f\"Trained action [{action}]: pos={len(X_pos)}, neg={len(X_neg)}\")\n\n    # Behavioral graph từ solution train (không đổi)\n    solution = create_solution_df(train_subset, cfg)\n    behavioral_graph = build_behavioral_graph(solution)\n\n    joblib.dump({\n        \"models\": models,\n        \"window_size\": window_size,\n        \"actions\": list(models.keys()),  # có thể gồm 'rear', 'attack', ...\n        \"behavioral_graph\": behavioral_graph\n    }, MODEL_PATH)\n    logger.info(f\"Per-action models saved to {MODEL_PATH}\")\n\n\ndef merge_consecutive_segments(segments: List[Tuple[int,int,str]], max_gap: int = 5, min_duration: int = 15) -> List[Tuple[int,int,str]]:\n    if not segments:\n        return []\n    segments = sorted(segments, key=lambda x: x[0])\n    merged = [segments[0]]\n    for s, e, lbl in segments[1:]:\n        ps, pe, plbl = merged[-1]\n        if lbl == plbl and s - pe <= max_gap:\n            merged[-1] = (ps, max(pe, e), lbl)\n        else:\n            merged.append((s, e, lbl))\n    return [(s, e, lbl) for s, e, lbl in merged if e - s >= min_duration]\n\ndef predict_with_ml(\n    dataset: pl.DataFrame,\n    cfg: Config,\n    model_path: str = MODEL_PATH,\n    min_len: int = 15,\n    gap_close: int = 5,\n) -> pl.DataFrame:\n    logger.info(f\"Loading ML model from {model_path}\")\n    saved = joblib.load(model_path)\n    models: Dict[str, Any] = saved[\"models\"]\n    window_size: int = int(saved[\"window_size\"])\n    behavioral_graph: Dict[str, Set[str]] = saved.get(\"behavioral_graph\", {})\n    actions_sorted = sorted(models.keys())\n\n    records: List[Tuple[int, str, str, str, int, int]] = []\n\n    for row in tqdm(dataset.to_dicts(), total=len(dataset), desc=\"Predicting with ML (per-action, fast)\"):\n        lab_id: str = row[\"lab_id\"]\n        if str(lab_id).startswith(\"MABe22\"):\n            continue\n        video_id: int = row[\"video_id\"]\n        track_path = cfg.test_track_dir / lab_id / f\"{video_id}.parquet\"\n        if not track_path.exists():\n            logger.warning(\"Tracking file not found: %s\", track_path)\n            continue\n\n        beh_df = parse_behaviors_labeled(row.get(\"behaviors_labeled\"))\n        if beh_df.is_empty():\n            continue\n\n        trk_agg = _prepare_tracking_minimal(track_path)\n        if trk_agg is None or trk_agg.is_empty():\n            logger.warning(\"Empty tracking after prepare for %s\", track_path)\n            continue\n\n        for (agent, target), _grp in beh_df.group_by([\"agent\", \"target\"]):\n            # target 'self' -> dùng chính agent cho feature, nhưng giữ 'self' khi xuất\n            orig_target = str(target)\n            pair_target_for_feat = agent if orig_target.lower() == \"self\" else target\n\n            feat_df = _pair_features_from_agg(trk_agg, agent, pair_target_for_feat, downsample=10)\n            if feat_df is None or feat_df.height < window_size:\n                continue\n\n            # Gating nhanh\n            gate_windows = _make_windows(feat_df, min_len=min_len)\n            if not gate_windows:\n                fmin = int(feat_df[\"frame\"].min())\n                fmax = int(feat_df[\"frame\"].max()) + 1\n                gate_windows = [(fmin, fmax)]\n\n            cols = [\"dist\", \"rel_speed\", \"rel_acc\", \"ddist\", \"angle\", \"dangle\", \"radial_vel\", \"speed_a\"]\n            arrays = {c: (feat_df[c].to_numpy() if c in feat_df.columns else None) for c in cols}\n            frames = feat_df[\"frame\"].to_numpy()\n            f2i = {int(f): i for i, f in enumerate(frames)}\n\n            step = max(1, window_size // 2)\n            X_batch: List[np.ndarray] = []\n            W_bounds: List[Tuple[int, int]] = []\n\n            for (ws, we) in gate_windows:\n                # map gần đúng từ frame -> index\n                start_idx = next((i for i, f in enumerate(frames) if f >= ws), None)\n                end_idx   = next((i for i, f in enumerate(frames[::-1]) if f < we), None)\n                if end_idx is not None:\n                    end_idx = len(frames) - 1 - end_idx\n                if start_idx is None or end_idx is None or end_idx - start_idx + 1 < window_size:\n                    continue\n\n                for si in range(start_idx, end_idx - window_size + 2, step):\n                    ei = si + window_size\n                    feats = []\n                    for c in [\"dist\", \"rel_speed\", \"rel_acc\", \"ddist\", \"angle\", \"dangle\", \"radial_vel\"]:\n                        arr = arrays[c][si:ei]\n                        feats.extend([\n                            float(arr.mean()),\n                            float(arr.std()),\n                            float(arr.min()),\n                            float(arr.max()),\n                            float(np.median(arr)),\n                            float(arr.max() - arr.min()),\n                            float(arr[-1] - arr[0]),\n                        ])\n                    X_batch.append(np.asarray(feats, dtype=np.float32))\n                    W_bounds.append((int(frames[si]), int(frames[ei-1]) + 1))\n\n            if not X_batch:\n                continue\n\n            X_batch = np.stack(X_batch, axis=0)\n\n            # Batch predict cho tất cả actions\n            action_probs: Dict[str, np.ndarray] = {}\n            for act in actions_sorted:\n                model = models[act]\n                p = model.predict_proba(X_batch)[:, 1]\n                action_probs[act] = p\n\n            # Greedy với behavioral graph\n            segments: List[Tuple[int, int, str]] = []\n            prev_action = \"background\"\n            last_end = -10**9\n\n            for idx, (s, e) in enumerate(W_bounds):\n                best_act, best_p = None, 0.0\n                for act in actions_sorted:\n                    p = float(action_probs[act][idx])\n                    allowed = behavioral_graph.get(prev_action, {act})\n                    if act not in allowed:\n                        p *= 0.1\n                    if p > best_p:\n                        best_p, best_act = p, act\n                if best_act is not None and best_p >= 0.25:\n                    if s - last_end > 30:\n                        prev_action = \"background\"\n                    segments.append((s, e, best_act))\n                    prev_action = best_act\n                    last_end = e\n\n            if not segments:\n                continue\n\n            merged = merge_consecutive_segments(segments, max_gap=gap_close, min_duration=min_len)\n            for s, e, lbl in merged:\n                records.append((\n                    video_id,\n                    _norm_mouse_id(agent),\n                    (\"self\" if orig_target.lower() == \"self\" else _norm_mouse_id(target)),\n                    lbl, int(s), int(e)\n                ))\n\n    if not records:\n        logger.warning(\"No ML predictions → falling back to heuristic\")\n        return predict_without_ml(dataset, \"test\", cfg, use_windows=True, min_len=min_len, gap_close=gap_close)\n\n    df = pl.DataFrame(\n        records,\n        schema={\n            \"video_id\": pl.Int64, \"agent_id\": pl.Utf8, \"target_id\": pl.Utf8,\n            \"action\": pl.Utf8, \"start_frame\": pl.Int64, \"stop_frame\": pl.Int64,\n        },\n        orient=\"row\",\n    )\n    df = validate_schema(df, cfg.submission_schema, \"ML Submission\")\n    validate_frame_ranges(df, \"ML Submission\")\n    return df\n\n\ndef run_train_ml(cfg: Config, window_size: int, step_size: int, downsample: int) -> None:\n    train_ml_model(cfg, window_size=window_size, step_size=step_size, downsample=downsample)\n\ndef run_submit_ml(cfg: Config, min_len: int, gap_close: int) -> None:\n    test = pl.read_csv(cfg.test_csv)\n    raw_sub = predict_with_ml(test, cfg, min_len=min_len, gap_close=gap_close)\n\n    saved = joblib.load(MODEL_PATH)\n    allowed_actions = set(saved.get(\"actions\", list(saved[\"models\"].keys())))\n\n    sub = _finalize_and_validate_submission(raw_sub, test, cfg, allowed_actions, split=\"test\")\n\n    ordered = [cfg.row_id_col, \"video_id\", \"agent_id\", \"target_id\", \"action\", \"start_frame\", \"stop_frame\"]\n    sub = sub.select(ordered)\n\n    sub.write_csv(cfg.submission_file)\n    logger.info(f\"ML submission saved to {cfg.submission_file}\")\n\n\n# ========================\n# CLI / Main\n# ========================\n\ndef run_validate(cfg: Config, beta: float, prior_scope: str, eps: float,\n                 use_windows: bool, min_len: int, gap_close: int, p_min: float, cap: float) -> float:\n    logger.info(\"Loading train data for validation: %s\", cfg.train_csv)\n    train = pl.read_csv(cfg.train_csv)\n    train_subset = train.filter(~pl.col(\"lab_id\").str.starts_with(\"MABe22\"))\n\n    logger.info(\"Building solution dataframe & spans...\")\n    solution = create_solution_df(train_subset, cfg)\n\n    # Zero-base solution theo spans train\n    solution = _zero_base_solution(solution, train_subset, cfg)\n\n    logger.info(\"Computing priors (eps=%.2f) & timing...\", eps)\n    spans = build_video_spans(train_subset, \"train\", cfg)\n    per_lab, global_w, med_lab, med_glob = compute_action_priors(solution, eps=eps)\n    timing_lab, timing_glob = compute_timing_priors(solution, spans)\n\n    logger.info(\"Generating predictions (advanced)...\")\n    submission_train = predict_without_ml(\n        train_subset, \"train\", cfg,\n        priors_per_lab=per_lab, priors_global=global_w,\n        meddur_per_lab=med_lab, meddur_global=med_glob,\n        timing_lab=timing_lab, timing_global=timing_glob,\n        prior_scope=prior_scope,\n        use_windows=use_windows, min_len=min_len, gap_close=gap_close,\n        p_min=p_min, cap=cap\n    )\n\n    # Harden + zero-base submission_train theo spans train\n    allowed_actions = set(solution[\"action\"].unique())\n    submission_train = _finalize_and_validate_submission(\n        submission_train, train_subset, cfg, allowed_actions, split=\"train\"\n    )\n\n    logger.info(\"Scoring (beta=%.3f)...\", beta)\n    val_score = score(solution, submission_train, cfg.row_id_col, beta=beta, cfg=cfg)\n    print(f\"[RESULT] Validation F1: {val_score:.6f}\")\n    return val_score\n\n\ndef run_submit_ml(cfg: Config, min_len: int, gap_close: int) -> None:\n    test = pl.read_csv(cfg.test_csv)\n    raw_sub = predict_with_ml(test, cfg, min_len=min_len, gap_close=gap_close)\n\n    saved = joblib.load(MODEL_PATH)\n    allowed_actions = set(saved.get(\"actions\", list(saved[\"models\"].keys())))\n\n    sub = _finalize_and_validate_submission(raw_sub, test, cfg, allowed_actions, split=\"test\")\n\n    ordered = [cfg.row_id_col, \"video_id\", \"agent_id\", \"target_id\", \"action\", \"start_frame\", \"stop_frame\"]\n    sub = sub.select(ordered)\n\n    sub.write_csv(cfg.submission_file)\n    logger.info(f\"ML submission saved to {cfg.submission_file}\")\n\n\ndef main() -> None:\n    parser = argparse.ArgumentParser(description=\"MABe Mouse Behavior: ML Baseline (F1-optimized + FAST)\")\n    parser.add_argument(\"--data-root\", type=str, default=None, help=\"Dataset root directory\")\n    parser.add_argument(\"--beta\", type=float, default=1.0, help=\"F-beta value\")\n    parser.add_argument(\"--mode\", choices=[\"validate\", \"submit\", \"all\", \"train-ml\", \"submit-ml\"], default=\"all\", help=\"Run mode\")\n    parser.add_argument(\"--submission\", type=str, default=None, help=\"Submission CSV output path\")\n    parser.add_argument(\"--prior-scope\", choices=[\"lab\", \"global\", \"mixed\"], default=\"mixed\",\n                        help=\"Use lab-level priors, global priors, or per-lab with global fallback (default)\")\n    parser.add_argument(\"--eps\", type=float, default=1.0, help=\"Laplace smoothing (frame units) for priors\")\n    parser.add_argument(\"--no-windows\", action=\"store_true\", help=\"Disable proximity windows (use full video)\")\n    parser.add_argument(\"--min-len\", type=int, default=15, help=\"Minimum segment/window length (frames)\")\n    parser.add_argument(\"--gap-close\", type=int, default=3, help=\"Merge same-action gaps up to this many frames\")\n    parser.add_argument(\"--p-min\", type=float, default=0.05, help=\"Rare-action min prior threshold\")\n    parser.add_argument(\"--cap\", type=float, default=0.05, help=\"Rare-action maximum share if below p-min\")\n    parser.add_argument(\"-v\", \"--verbose\", action=\"count\", default=1, help=\"Increase verbosity (-v, -vv)\")\n    args = parser.parse_args()\n\n    setup_logging(args.verbose)\n    warnings.filterwarnings(\"ignore\")\n\n    cfg = Config(\n        data_root=Path(args.data_root) if args.data_root else Config().data_root,\n        submission_file=args.submission if args.submission else Config().submission_file,\n        row_id_col=Config().row_id_col,\n    )\n\n    if args.mode == \"train-ml\":\n        run_train_ml(cfg, window_size=15, step_size=15, downsample=10)\n    elif args.mode == \"submit-ml\":\n        run_submit_ml(cfg, min_len=args.min_len, gap_close=args.gap_close)\n    else:\n        val = None\n        if args.mode in (\"validate\", \"all\"):\n            val = run_validate(cfg, beta=args.beta, prior_scope=args.prior_scope, eps=args.eps,\n                               use_windows=not args.no_windows, min_len=args.min_len, gap_close=args.gap_close,\n                               p_min=args.p_min, cap=args.cap)\n            logger.info(\"Validation F1: %.6f\", val)\n        if args.mode in (\"submit\", \"all\"):\n            run_submit(cfg, prior_scope=args.prior_scope, eps=args.eps,\n                       use_windows=not args.no_windows, min_len=args.min_len, gap_close=args.gap_close,\n                       p_min=args.p_min, cap=args.cap)\n\nif __name__ == \"__main__\":\n    main()","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-09-28T17:29:00.792745Z","iopub.execute_input":"2025-09-28T17:29:00.793109Z","iopub.status.idle":"2025-09-28T17:29:00.837696Z","shell.execute_reply.started":"2025-09-28T17:29:00.793083Z","shell.execute_reply":"2025-09-28T17:29:00.836591Z"},"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# !python baseline.py --mode train-ml -vv","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-27T11:04:33.607449Z","iopub.execute_input":"2025-09-27T11:04:33.607756Z","iopub.status.idle":"2025-09-27T11:45:27.713196Z","shell.execute_reply.started":"2025-09-27T11:04:33.607732Z","shell.execute_reply":"2025-09-27T11:45:27.712077Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!python baseline.py --mode submit-ml --min-len 15 --gap-close 5 -vv","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-28T17:29:05.751867Z","iopub.execute_input":"2025-09-28T17:29:05.752247Z","iopub.status.idle":"2025-09-28T17:29:12.082032Z","shell.execute_reply.started":"2025-09-28T17:29:05.752219Z","shell.execute_reply":"2025-09-28T17:29:12.080791Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import joblib\nsaved = joblib.load('/kaggle/input/mabexa/mouse_behavior_model (1).joblib')\nprint(sorted(saved.get(\"actions\", list(saved[\"models\"].keys()))))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-28T17:36:35.431898Z","iopub.execute_input":"2025-09-28T17:36:35.432203Z","iopub.status.idle":"2025-09-28T17:36:36.697051Z","shell.execute_reply.started":"2025-09-28T17:36:35.432183Z","shell.execute_reply":"2025-09-28T17:36:36.695259Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd \n\ndf = pd.read_csv('submission.csv')\nprint(df.head(10))\nprint(df.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-28T17:29:13.019591Z","iopub.execute_input":"2025-09-28T17:29:13.020005Z","iopub.status.idle":"2025-09-28T17:29:13.034549Z","shell.execute_reply.started":"2025-09-28T17:29:13.019964Z","shell.execute_reply":"2025-09-28T17:29:13.033587Z"}},"outputs":[],"execution_count":null}]}