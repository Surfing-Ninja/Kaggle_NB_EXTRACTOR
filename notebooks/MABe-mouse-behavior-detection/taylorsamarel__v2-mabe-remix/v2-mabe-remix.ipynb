{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":59156,"databundleVersionId":13874099,"sourceType":"competition"}],"dockerImageVersionId":31089,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# MABe Challenge - Advanced Ensemble with Comprehensive Enhanced Visualizations\n# Complete working code with publication-quality visualizations\n# ENHANCED WITH SPATIAL HISTORY FEATURES\n\nvalidate_or_submit = 'submit'\nverbose = True\n\nimport pandas as pd\nimport numpy as np\nfrom tqdm import tqdm\nimport itertools\nimport warnings\nimport json\nimport os\nimport gc\nimport lightgbm\nfrom collections import defaultdict, Counter\nimport polars as pl\nfrom scipy import signal, stats\nfrom scipy.spatial import cKDTree\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom matplotlib.gridspec import GridSpec\nfrom matplotlib.patches import Rectangle\nimport matplotlib.patches as mpatches\n\nfrom sklearn.base import ClassifierMixin, BaseEstimator, clone\nfrom sklearn.model_selection import cross_val_predict, GroupKFold, StratifiedKFold\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.metrics import f1_score, confusion_matrix\n\nwarnings.filterwarnings('ignore')\nplt.style.use('seaborn-v0_8-whitegrid')\nsns.set_palette(\"husl\")\n\n# Create output directory for visualizations\nos.makedirs('/kaggle/working/visualizations', exist_ok=True)\n\n# Try importing additional models\ntry:\n    from xgboost import XGBClassifier\n    XGBOOST_AVAILABLE = True\nexcept:\n    XGBOOST_AVAILABLE = False\n    \ntry:\n    from catboost import CatBoostClassifier\n    CATBOOST_AVAILABLE = True\nexcept:\n    CATBOOST_AVAILABLE = False\n\ntry:\n    from gandalf import GANDALF\n    GANDALF_AVAILABLE = True\nexcept:\n    GANDALF_AVAILABLE = False\n\n# ==================== ENHANCED VISUALIZATION FUNCTIONS ====================\n\ndef plot_comprehensive_dataset_overview(train, test):\n    \"\"\"Enhanced dataset overview with more details\"\"\"\n    fig = plt.figure(figsize=(24, 16))\n    gs = GridSpec(4, 4, figure=fig, hspace=0.35, wspace=0.35)\n    \n    # Color schemes\n    colors_primary = ['#2E86AB', '#A23B72', '#F18F01', '#C73E1D', '#6A994E']\n    colors_secondary = ['#5E548E', '#BE95C4', '#E0B1CB', '#F4ACB7', '#FFD6E0']\n    \n    # 1. Videos per lab (enhanced)\n    ax1 = fig.add_subplot(gs[0, 0])\n    lab_counts = train.groupby('lab_id').size().sort_values(ascending=False)\n    bars = ax1.barh(range(len(lab_counts)), lab_counts.values, color=colors_primary[0], edgecolor='black', linewidth=0.5)\n    ax1.set_yticks(range(len(lab_counts)))\n    ax1.set_yticklabels(lab_counts.index, fontsize=8)\n    ax1.set_title('Videos per Lab (Training)', fontsize=13, fontweight='bold', pad=10)\n    ax1.set_xlabel('Number of Videos', fontsize=10)\n    ax1.grid(axis='x', alpha=0.3, linestyle='--')\n    for i, (bar, val) in enumerate(zip(bars, lab_counts.values)):\n        ax1.text(val + 1, i, str(val), va='center', fontsize=8, fontweight='bold')\n    \n    # 2. Number of mice distribution with statistics\n    ax2 = fig.add_subplot(gs[0, 1])\n    mice_counts = train['n_mice'].value_counts().sort_index()\n    bars = ax2.bar(mice_counts.index, mice_counts.values, color=colors_primary[1], \n                   edgecolor='black', linewidth=1.5, alpha=0.8)\n    ax2.set_title('Distribution of Mice Count', fontsize=13, fontweight='bold', pad=10)\n    ax2.set_xlabel('Number of Mice', fontsize=10)\n    ax2.set_ylabel('Number of Videos', fontsize=10)\n    ax2.grid(axis='y', alpha=0.3, linestyle='--')\n    for bar, val in zip(bars, mice_counts.values):\n        height = bar.get_height()\n        ax2.text(bar.get_x() + bar.get_width()/2., height,\n                f'{val}\\n({val/len(train)*100:.1f}%)',\n                ha='center', va='bottom', fontsize=9, fontweight='bold')\n    \n    # 3. Video duration with detailed statistics\n    ax3 = fig.add_subplot(gs[0, 2])\n    durations = train['video_duration_sec']\n    ax3.hist(durations, bins=50, color=colors_primary[2], edgecolor='black', alpha=0.7)\n    ax3.axvline(durations.mean(), color='red', linestyle='--', linewidth=2.5, label=f'Mean: {durations.mean():.0f}s')\n    ax3.axvline(durations.median(), color='blue', linestyle='--', linewidth=2.5, label=f'Median: {durations.median():.0f}s')\n    ax3.set_title('Video Duration Distribution', fontsize=13, fontweight='bold', pad=10)\n    ax3.set_xlabel('Duration (seconds)', fontsize=10)\n    ax3.set_ylabel('Frequency', fontsize=10)\n    ax3.legend(fontsize=9, frameon=True, shadow=True)\n    ax3.grid(alpha=0.3)\n    \n    # 4. FPS distribution enhanced\n    ax4 = fig.add_subplot(gs[0, 3])\n    fps_counts = train['frames_per_second'].value_counts().sort_index()\n    bars = ax4.bar(range(len(fps_counts)), fps_counts.values, color=colors_primary[3], \n                   edgecolor='black', linewidth=1, alpha=0.8)\n    ax4.set_xticks(range(len(fps_counts)))\n    ax4.set_xticklabels(fps_counts.index, fontsize=9)\n    ax4.set_title('Frames Per Second Distribution', fontsize=13, fontweight='bold', pad=10)\n    ax4.set_xlabel('FPS', fontsize=10)\n    ax4.set_ylabel('Number of Videos', fontsize=10)\n    ax4.grid(axis='y', alpha=0.3)\n    for bar, val in zip(bars, fps_counts.values):\n        height = bar.get_height()\n        ax4.text(bar.get_x() + bar.get_width()/2., height, str(val),\n                ha='center', va='bottom', fontsize=9, fontweight='bold')\n    \n    # 5. Body parts tracked detailed\n    ax5 = fig.add_subplot(gs[1, 0])\n    body_parts_count = train['body_parts_tracked'].apply(lambda x: len(json.loads(x)))\n    bp_counts = body_parts_count.value_counts().sort_index()\n    bars = ax5.bar(bp_counts.index, bp_counts.values, color=colors_primary[4], \n                   edgecolor='black', linewidth=1, alpha=0.8)\n    ax5.set_title('Number of Body Parts Tracked', fontsize=13, fontweight='bold', pad=10)\n    ax5.set_xlabel('Number of Body Parts', fontsize=10)\n    ax5.set_ylabel('Number of Videos', fontsize=10)\n    ax5.grid(axis='y', alpha=0.3)\n    for bar, val in zip(bars, bp_counts.values):\n        height = bar.get_height()\n        ax5.text(bar.get_x() + bar.get_width()/2., height, str(val),\n                ha='center', va='bottom', fontsize=9, fontweight='bold')\n    \n    # 6. Arena shape with better visualization\n    ax6 = fig.add_subplot(gs[1, 1])\n    arena_counts = train['arena_shape'].value_counts()\n    wedges, texts, autotexts = ax6.pie(arena_counts.values, labels=arena_counts.index, \n                                         autopct='%1.1f%%', startangle=90,\n                                         colors=colors_secondary, explode=[0.05]*len(arena_counts),\n                                         shadow=True, textprops={'fontsize': 10, 'fontweight': 'bold'})\n    ax6.set_title('Arena Shape Distribution', fontsize=13, fontweight='bold', pad=10)\n    \n    # 7. Tracking method enhanced\n    ax7 = fig.add_subplot(gs[1, 2:])\n    tracking_counts = train['tracking_method'].value_counts().head(10)\n    bars = ax7.barh(range(len(tracking_counts)), tracking_counts.values, color=colors_primary[0], \n                    edgecolor='black', linewidth=0.5, alpha=0.8)\n    ax7.set_yticks(range(len(tracking_counts)))\n    ax7.set_yticklabels(tracking_counts.index, fontsize=9)\n    ax7.set_title('Tracking Method Distribution (Top 10)', fontsize=13, fontweight='bold', pad=10)\n    ax7.set_xlabel('Number of Videos', fontsize=10)\n    ax7.grid(axis='x', alpha=0.3)\n    for i, (bar, val) in enumerate(zip(bars, tracking_counts.values)):\n        ax7.text(val + 1, i, str(val), va='center', fontsize=9, fontweight='bold')\n    \n    # 8. Train vs Test comparison\n    ax8 = fig.add_subplot(gs[2, 0])\n    dataset_sizes = pd.Series({'Train': len(train), 'Test': len(test)})\n    bars = ax8.bar(range(len(dataset_sizes)), dataset_sizes.values, \n                   color=[colors_primary[0], colors_primary[1]], \n                   edgecolor='black', linewidth=2, alpha=0.8)\n    ax8.set_xticks(range(len(dataset_sizes)))\n    ax8.set_xticklabels(dataset_sizes.index, fontsize=11, fontweight='bold')\n    ax8.set_title('Train vs Test Dataset Size', fontsize=13, fontweight='bold', pad=10)\n    ax8.set_ylabel('Number of Videos', fontsize=10)\n    ax8.grid(axis='y', alpha=0.3)\n    for i, (bar, val) in enumerate(zip(bars, dataset_sizes.values)):\n        height = bar.get_height()\n        ax8.text(i, height, f'{val}\\nvideos', ha='center', va='bottom', \n                fontsize=11, fontweight='bold')\n    \n    # 9. Mouse strains diversity\n    ax9 = fig.add_subplot(gs[2, 1:3])\n    all_strains = pd.concat([train['mouse1_strain'], train['mouse2_strain'], \n                             train['mouse3_strain'], train['mouse4_strain']]).dropna()\n    strain_counts = all_strains.value_counts().head(15)\n    bars = ax9.barh(range(len(strain_counts)), strain_counts.values, \n                    color=colors_primary[2], edgecolor='black', linewidth=0.5, alpha=0.8)\n    ax9.set_yticks(range(len(strain_counts)))\n    ax9.set_yticklabels(strain_counts.index, fontsize=9)\n    ax9.set_title('Top 15 Mouse Strains', fontsize=13, fontweight='bold', pad=10)\n    ax9.set_xlabel('Frequency', fontsize=10)\n    ax9.grid(axis='x', alpha=0.3)\n    for i, (bar, val) in enumerate(zip(bars, strain_counts.values)):\n        ax9.text(val + 5, i, str(val), va='center', fontsize=8, fontweight='bold')\n    \n    # 10. Sex distribution\n    ax10 = fig.add_subplot(gs[2, 3])\n    all_sex = pd.concat([train['mouse1_sex'], train['mouse2_sex'], \n                         train['mouse3_sex'], train['mouse4_sex']]).dropna()\n    sex_counts = all_sex.value_counts()\n    wedges, texts, autotexts = ax10.pie(sex_counts.values, labels=sex_counts.index,\n                                          autopct='%1.1f%%', startangle=90,\n                                          colors=['#FF6B9D', '#4ECDC4', '#95E1D3'],\n                                          explode=[0.05]*len(sex_counts), shadow=True,\n                                          textprops={'fontsize': 10, 'fontweight': 'bold'})\n    ax10.set_title('Mouse Sex Distribution', fontsize=13, fontweight='bold', pad=10)\n    \n    # 11. Total frames statistics\n    ax11 = fig.add_subplot(gs[3, 0])\n    train['total_frames'] = train['video_duration_sec'] * train['frames_per_second']\n    total_frames_dist = train['total_frames']\n    ax11.hist(total_frames_dist, bins=50, color=colors_primary[3], \n              edgecolor='black', alpha=0.7)\n    ax11.axvline(total_frames_dist.mean(), color='red', linestyle='--', linewidth=2,\n                label=f'Mean: {total_frames_dist.mean():.0f}')\n    ax11.set_title('Total Frames per Video', fontsize=13, fontweight='bold', pad=10)\n    ax11.set_xlabel('Total Frames', fontsize=10)\n    ax11.set_ylabel('Frequency', fontsize=10)\n    ax11.legend(fontsize=9)\n    ax11.grid(alpha=0.3)\n    \n    # 12. Arena size distribution\n    ax12 = fig.add_subplot(gs[3, 1])\n    train['arena_area'] = train['arena_width_cm'] * train['arena_height_cm']\n    arena_area = train['arena_area'].dropna()\n    ax12.hist(arena_area, bins=40, color=colors_primary[4], \n              edgecolor='black', alpha=0.7)\n    ax12.axvline(arena_area.median(), color='blue', linestyle='--', linewidth=2,\n                label=f'Median: {arena_area.median():.0f} cm²')\n    ax12.set_title('Arena Area Distribution', fontsize=13, fontweight='bold', pad=10)\n    ax12.set_xlabel('Area (cm²)', fontsize=10)\n    ax12.set_ylabel('Frequency', fontsize=10)\n    ax12.legend(fontsize=9)\n    ax12.grid(alpha=0.3)\n    \n    # 13. Pixel density\n    ax13 = fig.add_subplot(gs[3, 2])\n    pixel_density = train['pix_per_cm_approx'].dropna()\n    ax13.hist(pixel_density, bins=40, color=colors_primary[0], \n              edgecolor='black', alpha=0.7)\n    ax13.axvline(pixel_density.mean(), color='red', linestyle='--', linewidth=2,\n                label=f'Mean: {pixel_density.mean():.2f}')\n    ax13.set_title('Pixel Density Distribution', fontsize=13, fontweight='bold', pad=10)\n    ax13.set_xlabel('Pixels per cm', fontsize=10)\n    ax13.set_ylabel('Frequency', fontsize=10)\n    ax13.legend(fontsize=9)\n    ax13.grid(alpha=0.3)\n    \n    # 14. Summary statistics table\n    ax14 = fig.add_subplot(gs[3, 3])\n    ax14.axis('off')\n    summary_stats = [\n        ['Metric', 'Train', 'Test'],\n        ['Total Videos', f'{len(train)}', f'{len(test)}'],\n        ['Avg Duration (s)', f'{train[\"video_duration_sec\"].mean():.0f}', \n         f'{test[\"video_duration_sec\"].mean():.0f}' if \"video_duration_sec\" in test.columns else 'N/A'],\n        ['Total Labs', f'{train[\"lab_id\"].nunique()}', f'{test[\"lab_id\"].nunique()}'],\n        ['Unique Strains', f'{all_strains.nunique()}', 'N/A'],\n        ['Avg Mice/Video', f'{train[\"n_mice\"].mean():.2f}', 'N/A']\n    ]\n    table = ax14.table(cellText=summary_stats, cellLoc='center', loc='center',\n                       colWidths=[0.4, 0.3, 0.3])\n    table.auto_set_font_size(False)\n    table.set_fontsize(9)\n    table.scale(1, 2)\n    for i in range(len(summary_stats)):\n        for j in range(len(summary_stats[0])):\n            cell = table[(i, j)]\n            if i == 0:\n                cell.set_facecolor('#2E86AB')\n                cell.set_text_props(weight='bold', color='white')\n            else:\n                cell.set_facecolor('#E8F4F8' if i % 2 == 0 else 'white')\n            cell.set_edgecolor('#2E86AB')\n            cell.set_linewidth(2)\n    ax14.set_title('Summary Statistics', fontsize=13, fontweight='bold', pad=20)\n    \n    plt.suptitle('Comprehensive Dataset Overview', fontsize=18, fontweight='bold', y=0.995)\n    plt.savefig('/kaggle/working/visualizations/01_dataset_overview_enhanced.png', \n                dpi=150, bbox_inches='tight', facecolor='white')\n    print(\"✓ Saved: 01_dataset_overview_enhanced.png\")\n    plt.show()\n    plt.close()\n\ndef plot_advanced_behavior_analysis(train):\n    \"\"\"Advanced behavior analysis with co-occurrence and transitions\"\"\"\n    fig = plt.figure(figsize=(24, 16))\n    gs = GridSpec(3, 3, figure=fig, hspace=0.3, wspace=0.3)\n    \n    # Extract all behaviors\n    all_behaviors = []\n    behavior_lab_map = defaultdict(set)\n    behavior_video_map = defaultdict(list)\n    self_behaviors = []\n    paired_behaviors = []\n    \n    for _, row in train.iterrows():\n        if isinstance(row['behaviors_labeled'], str):\n            behaviors = json.loads(row['behaviors_labeled'])\n            for b in behaviors:\n                b_clean = b.replace(\"'\", \"\")\n                parts = b_clean.split(',')\n                if len(parts) >= 3:\n                    action = parts[2]\n                    all_behaviors.append(action)\n                    behavior_lab_map[action].add(row['lab_id'])\n                    behavior_video_map[action].append(row['video_id'])\n                    \n                    if len(parts) >= 2 and parts[1] == 'self':\n                        self_behaviors.append(action)\n                    else:\n                        paired_behaviors.append(action)\n    \n    # 1. Top 25 behaviors with count\n    ax1 = fig.add_subplot(gs[0, :2])\n    behavior_counts = pd.Series(all_behaviors).value_counts().head(25)\n    colors = plt.cm.viridis(np.linspace(0, 1, len(behavior_counts)))\n    bars = ax1.barh(range(len(behavior_counts)), behavior_counts.values, color=colors, \n                    edgecolor='black', linewidth=0.5)\n    ax1.set_yticks(range(len(behavior_counts)))\n    ax1.set_yticklabels(behavior_counts.index, fontsize=9)\n    ax1.set_title('Top 25 Most Common Behaviors', fontsize=14, fontweight='bold', pad=10)\n    ax1.set_xlabel('Frequency', fontsize=11)\n    ax1.grid(axis='x', alpha=0.3, linestyle='--')\n    for i, (bar, val) in enumerate(zip(bars, behavior_counts.values)):\n        ax1.text(val + max(behavior_counts.values)*0.01, i, f'{val:,}', \n                va='center', fontsize=8, fontweight='bold')\n    \n    # 2. Behavior frequency distribution\n    ax2 = fig.add_subplot(gs[0, 2])\n    behavior_freq = pd.Series(all_behaviors).value_counts()\n    ax2.hist(behavior_freq.values, bins=50, color='#FF6B9D', edgecolor='black', alpha=0.7)\n    ax2.set_title('Behavior Frequency Distribution', fontsize=14, fontweight='bold', pad=10)\n    ax2.set_xlabel('Frequency', fontsize=11)\n    ax2.set_ylabel('Number of Behaviors', fontsize=11)\n    ax2.axvline(behavior_freq.median(), color='red', linestyle='--', linewidth=2,\n               label=f'Median: {behavior_freq.median():.0f}')\n    ax2.set_yscale('log')\n    ax2.legend(fontsize=9)\n    ax2.grid(alpha=0.3)\n    \n    # 3. Behaviors per video distribution\n    ax3 = fig.add_subplot(gs[1, 0])\n    behaviors_per_video = []\n    for _, row in train.iterrows():\n        if isinstance(row['behaviors_labeled'], str):\n            behaviors = json.loads(row['behaviors_labeled'])\n            behaviors_per_video.append(len(behaviors))\n    \n    ax3.hist(behaviors_per_video, bins=50, color='#4ECDC4', edgecolor='black', alpha=0.7)\n    ax3.set_title('Behaviors Per Video', fontsize=14, fontweight='bold', pad=10)\n    ax3.set_xlabel('Number of Behaviors', fontsize=11)\n    ax3.set_ylabel('Frequency', fontsize=11)\n    ax3.axvline(np.mean(behaviors_per_video), color='red', linestyle='--', linewidth=2,\n               label=f'Mean: {np.mean(behaviors_per_video):.1f}')\n    ax3.axvline(np.median(behaviors_per_video), color='blue', linestyle='--', linewidth=2,\n               label=f'Median: {np.median(behaviors_per_video):.0f}')\n    ax3.legend(fontsize=9)\n    ax3.grid(alpha=0.3)\n    \n    # 4. Unique behaviors per lab\n    ax4 = fig.add_subplot(gs[1, 1])\n    lab_unique_behaviors = {}\n    for _, row in train.iterrows():\n        lab = row['lab_id']\n        if isinstance(row['behaviors_labeled'], str):\n            if lab not in lab_unique_behaviors:\n                lab_unique_behaviors[lab] = set()\n            behaviors = json.loads(row['behaviors_labeled'])\n            for b in behaviors:\n                b_clean = b.replace(\"'\", \"\")\n                parts = b_clean.split(',')\n                if len(parts) >= 3:\n                    lab_unique_behaviors[lab].add(parts[2])\n    \n    lab_diversity = pd.Series({k: len(v) for k, v in lab_unique_behaviors.items()}).sort_values(ascending=False).head(15)\n    colors = plt.cm.plasma(np.linspace(0, 1, len(lab_diversity)))\n    bars = ax4.barh(range(len(lab_diversity)), lab_diversity.values, color=colors,\n                    edgecolor='black', linewidth=0.5)\n    ax4.set_yticks(range(len(lab_diversity)))\n    ax4.set_yticklabels(lab_diversity.index, fontsize=9)\n    ax4.set_title('Unique Behaviors per Lab (Top 15)', fontsize=14, fontweight='bold', pad=10)\n    ax4.set_xlabel('Number of Unique Behaviors', fontsize=11)\n    ax4.grid(axis='x', alpha=0.3)\n    for i, (bar, val) in enumerate(zip(bars, lab_diversity.values)):\n        ax4.text(val + 0.5, i, str(val), va='center', fontsize=9, fontweight='bold')\n    \n    # 5. Self vs Paired behaviors enhanced\n    ax5 = fig.add_subplot(gs[1, 2])\n    self_count = len(self_behaviors)\n    paired_count = len(paired_behaviors)\n    behavior_types = pd.Series({'Self-directed': self_count, 'Social/Paired': paired_count})\n    colors_pie = ['#FF6B9D', '#4ECDC4']\n    wedges, texts, autotexts = ax5.pie(behavior_types.values, labels=behavior_types.index,\n                                         autopct=lambda pct: f'{pct:.1f}%\\n({int(pct/100*sum(behavior_types.values)):,})',\n                                         startangle=90, colors=colors_pie, explode=(0.05, 0.05),\n                                         shadow=True, textprops={'fontsize': 10, 'fontweight': 'bold'})\n    ax5.set_title('Self vs Paired Behaviors', fontsize=14, fontweight='bold', pad=10)\n    \n    # 6. Top self-directed behaviors\n    ax6 = fig.add_subplot(gs[2, 0])\n    self_behavior_counts = pd.Series(self_behaviors).value_counts().head(10)\n    bars = ax6.barh(range(len(self_behavior_counts)), self_behavior_counts.values,\n                    color='#FF6B9D', edgecolor='black', linewidth=0.5, alpha=0.8)\n    ax6.set_yticks(range(len(self_behavior_counts)))\n    ax6.set_yticklabels(self_behavior_counts.index, fontsize=9)\n    ax6.set_title('Top 10 Self-Directed Behaviors', fontsize=14, fontweight='bold', pad=10)\n    ax6.set_xlabel('Frequency', fontsize=11)\n    ax6.grid(axis='x', alpha=0.3)\n    for i, (bar, val) in enumerate(zip(bars, self_behavior_counts.values)):\n        ax6.text(val + max(self_behavior_counts.values)*0.01, i, f'{val:,}',\n                va='center', fontsize=8, fontweight='bold')\n    \n    # 7. Top paired behaviors\n    ax7 = fig.add_subplot(gs[2, 1])\n    paired_behavior_counts = pd.Series(paired_behaviors).value_counts().head(10)\n    bars = ax7.barh(range(len(paired_behavior_counts)), paired_behavior_counts.values,\n                    color='#4ECDC4', edgecolor='black', linewidth=0.5, alpha=0.8)\n    ax7.set_yticks(range(len(paired_behavior_counts)))\n    ax7.set_yticklabels(paired_behavior_counts.index, fontsize=9)\n    ax7.set_title('Top 10 Social/Paired Behaviors', fontsize=14, fontweight='bold', pad=10)\n    ax7.set_xlabel('Frequency', fontsize=11)\n    ax7.grid(axis='x', alpha=0.3)\n    for i, (bar, val) in enumerate(zip(bars, paired_behavior_counts.values)):\n        ax7.text(val + max(paired_behavior_counts.values)*0.01, i, f'{val:,}',\n                va='center', fontsize=8, fontweight='bold')\n    \n    # 8. Behavior rarity analysis\n    ax8 = fig.add_subplot(gs[2, 2])\n    behavior_counts_all = pd.Series(all_behaviors).value_counts()\n    rare_behaviors = (behavior_counts_all <= 100).sum()\n    common_behaviors = ((behavior_counts_all > 100) & (behavior_counts_all <= 1000)).sum()\n    frequent_behaviors = (behavior_counts_all > 1000).sum()\n    \n    rarity_data = pd.Series({\n        f'Rare\\n(≤100)': rare_behaviors,\n        f'Common\\n(100-1000)': common_behaviors,\n        f'Frequent\\n(>1000)': frequent_behaviors\n    })\n    colors_bar = ['#FF6B9D', '#FFD93D', '#6BCF7F']\n    bars = ax8.bar(range(len(rarity_data)), rarity_data.values, color=colors_bar,\n                   edgecolor='black', linewidth=2, alpha=0.8)\n    ax8.set_xticks(range(len(rarity_data)))\n    ax8.set_xticklabels(rarity_data.index, fontsize=10, fontweight='bold')\n    ax8.set_title('Behavior Rarity Classification', fontsize=14, fontweight='bold', pad=10)\n    ax8.set_ylabel('Number of Unique Behaviors', fontsize=11)\n    ax8.grid(axis='y', alpha=0.3)\n    for bar, val in zip(bars, rarity_data.values):\n        height = bar.get_height()\n        ax8.text(bar.get_x() + bar.get_width()/2., height,\n                f'{val}\\n({val/len(behavior_counts_all)*100:.1f}%)',\n                ha='center', va='bottom', fontsize=10, fontweight='bold')\n    \n    plt.suptitle('Advanced Behavior Analysis', fontsize=18, fontweight='bold', y=0.995)\n    plt.savefig('/kaggle/working/visualizations/02_behavior_analysis_enhanced.png',\n                dpi=150, bbox_inches='tight', facecolor='white')\n    print(\"✓ Saved: 02_behavior_analysis_enhanced.png\")\n    plt.show()\n    plt.close()\n\ndef plot_feature_analysis(X_sample, feature_type='single'):\n    \"\"\"Comprehensive feature analysis with correlations and distributions\"\"\"\n    sample_size = min(50000, len(X_sample))\n    X_plot = X_sample.sample(n=sample_size, random_state=42) if len(X_sample) > sample_size else X_sample\n    \n    fig = plt.figure(figsize=(24, 16))\n    gs = GridSpec(3, 3, figure=fig, hspace=0.3, wspace=0.3)\n    \n    # Select feature categories\n    feature_cols = X_plot.columns.tolist()\n    speed_features = [c for c in feature_cols if any(x in c for x in ['sp_', 'disp', 'act'])][:12]\n    position_features = [c for c in feature_cols if any(x in c for x in ['cx_', 'cy_', 'x_', 'y_'])][:12]\n    distance_features = [c for c in feature_cols if '+' in c][:12]\n    temporal_features = [c for c in feature_cols if any(x in c for x in ['_m', '_s', 'pct', 'rng'])][:12]\n    \n    # 1-3. Speed feature distributions\n    for idx in range(min(3, len(speed_features))):\n        ax = fig.add_subplot(gs[0, idx])\n        feature = speed_features[idx]\n        data = X_plot[feature].dropna()\n        ax.hist(data, bins=60, color='#2E86AB', edgecolor='black', alpha=0.7)\n        ax.axvline(data.mean(), color='red', linestyle='--', linewidth=2, \n                   label=f'μ={data.mean():.2f}')\n        ax.axvline(data.median(), color='orange', linestyle='--', linewidth=2,\n                   label=f'M={data.median():.2f}')\n        ax.set_title(f'{feature}', fontsize=11, fontweight='bold')\n        ax.set_xlabel('Value', fontsize=9)\n        ax.set_ylabel('Frequency', fontsize=9)\n        ax.legend(fontsize=8)\n        ax.grid(alpha=0.3)\n    \n    # 4-6. Position feature distributions\n    for idx in range(min(3, len(position_features))):\n        ax = fig.add_subplot(gs[1, idx])\n        feature = position_features[idx]\n        data = X_plot[feature].dropna()\n        ax.hist(data, bins=60, color='#A23B72', edgecolor='black', alpha=0.7)\n        ax.axvline(data.mean(), color='red', linestyle='--', linewidth=2,\n                   label=f'μ={data.mean():.2f}')\n        ax.set_title(f'{feature}', fontsize=11, fontweight='bold')\n        ax.set_xlabel('Value', fontsize=9)\n        ax.set_ylabel('Frequency', fontsize=9)\n        ax.legend(fontsize=8)\n        ax.grid(alpha=0.3)\n    \n    # 7-9. Distance/temporal feature distributions\n    combined_features = (distance_features + temporal_features)[:3]\n    for idx in range(min(3, len(combined_features))):\n        ax = fig.add_subplot(gs[2, idx])\n        feature = combined_features[idx]\n        data = X_plot[feature].dropna()\n        ax.hist(data, bins=60, color='#F18F01', edgecolor='black', alpha=0.7)\n        ax.axvline(data.mean(), color='red', linestyle='--', linewidth=2,\n                   label=f'μ={data.mean():.2f}')\n        ax.set_title(f'{feature[:30]}...', fontsize=11, fontweight='bold')\n        ax.set_xlabel('Value', fontsize=9)\n        ax.set_ylabel('Frequency', fontsize=9)\n        ax.legend(fontsize=8)\n        ax.grid(alpha=0.3)\n    \n    plt.suptitle(f'Feature Distribution Analysis ({feature_type.capitalize()})', \n                 fontsize=18, fontweight='bold', y=0.995)\n    plt.savefig(f'/kaggle/working/visualizations/03_feature_distributions_{feature_type}.png',\n                dpi=150, bbox_inches='tight', facecolor='white')\n    print(f\"✓ Saved: 03_feature_distributions_{feature_type}.png\")\n    plt.show()\n    plt.close()\n\ndef plot_feature_correlation_heatmap(X_sample, feature_type='single'):\n    \"\"\"Feature correlation heatmap\"\"\"\n    sample_size = min(10000, len(X_sample))\n    X_plot = X_sample.sample(n=sample_size, random_state=42) if len(X_sample) > sample_size else X_sample\n    \n    # Select subset of interesting features\n    feature_cols = X_plot.columns.tolist()\n    selected_features = []\n    \n    for keyword in ['sp_', 'cx_', 'cy_', 'disp', 'act', 'd_m', 'curv']:\n        matching = [c for c in feature_cols if keyword in c]\n        selected_features.extend(matching[:2])\n    \n    selected_features = list(set(selected_features))[:20]\n    \n    if len(selected_features) > 0:\n        correlation_matrix = X_plot[selected_features].corr()\n        \n        fig, ax = plt.subplots(figsize=(14, 12))\n        sns.heatmap(correlation_matrix, annot=True, fmt='.2f', cmap='RdYlBu_r',\n                   center=0, square=True, linewidths=0.5, cbar_kws={\"shrink\": 0.8},\n                   ax=ax, annot_kws={'size': 7})\n        ax.set_title(f'Feature Correlation Heatmap ({feature_type.capitalize()})',\n                    fontsize=16, fontweight='bold', pad=20)\n        plt.xticks(rotation=45, ha='right', fontsize=9)\n        plt.yticks(rotation=0, fontsize=9)\n        plt.tight_layout()\n        plt.savefig(f'/kaggle/working/visualizations/04_correlation_heatmap_{feature_type}.png',\n                   dpi=150, bbox_inches='tight', facecolor='white')\n        print(f\"✓ Saved: 04_correlation_heatmap_{feature_type}.png\")\n        plt.show()\n        plt.close()\n\ndef plot_temporal_patterns_detailed(X_sample, feature_type='single'):\n    \"\"\"Detailed temporal pattern analysis\"\"\"\n    sample_size = min(5000, len(X_sample))\n    X_plot = X_sample.iloc[:sample_size]\n    \n    fig = plt.figure(figsize=(24, 12))\n    gs = GridSpec(2, 3, figure=fig, hspace=0.3, wspace=0.3)\n    \n    temporal_cols = [c for c in X_plot.columns if any(x in c for x in ['_m', '_s', 'disp', 'act'])][:6]\n    \n    for idx, col in enumerate(temporal_cols):\n        if idx < 6 and col in X_plot.columns:\n            ax = fig.add_subplot(gs[idx // 3, idx % 3])\n            \n            # Plot time series\n            data = X_plot[col].values\n            ax.plot(data, linewidth=0.8, alpha=0.7, color='#2E86AB')\n            \n            # Add rolling mean\n            window = min(100, len(data) // 10)\n            if window > 1:\n                rolling_mean = pd.Series(data).rolling(window=window, center=True).mean()\n                ax.plot(rolling_mean, linewidth=2, color='#FF6B9D', label=f'Rolling Mean (w={window})')\n            \n            ax.set_title(f'{col}', fontsize=12, fontweight='bold')\n            ax.set_xlabel('Frame', fontsize=10)\n            ax.set_ylabel('Value', fontsize=10)\n            ax.grid(alpha=0.3, linestyle='--')\n            ax.legend(fontsize=9)\n            \n            # Add statistics box\n            textstr = f'μ={np.nanmean(data):.2f}\\nσ={np.nanstd(data):.2f}'\n            props = dict(boxstyle='round', facecolor='wheat', alpha=0.8)\n            ax.text(0.95, 0.95, textstr, transform=ax.transAxes, fontsize=9,\n                   verticalalignment='top', horizontalalignment='right', bbox=props)\n    \n    plt.suptitle(f'Temporal Pattern Analysis ({feature_type.capitalize()})',\n                fontsize=18, fontweight='bold', y=0.995)\n    plt.savefig(f'/kaggle/working/visualizations/05_temporal_patterns_{feature_type}.png',\n               dpi=150, bbox_inches='tight', facecolor='white')\n    print(f\"✓ Saved: 05_temporal_patterns_{feature_type}.png\")\n    plt.show()\n    plt.close()\n\ndef plot_training_progress_detailed(section_results):\n    \"\"\"Detailed training progress visualization\"\"\"\n    fig = plt.figure(figsize=(20, 12))\n    gs = GridSpec(2, 3, figure=fig, hspace=0.3, wspace=0.3)\n    \n    sections = list(section_results.keys())\n    \n    # 1. Features per section (stacked)\n    ax1 = fig.add_subplot(gs[0, 0])\n    single_features = [section_results[s].get('single_features', 0) for s in sections]\n    pair_features = [section_results[s].get('pair_features', 0) for s in sections]\n    \n    x = np.arange(len(sections))\n    width = 0.6\n    \n    ax1.bar(x, single_features, width, label='Single', color='#2E86AB', edgecolor='black')\n    ax1.bar(x, pair_features, width, bottom=single_features, label='Pair', \n           color='#A23B72', edgecolor='black')\n    \n    ax1.set_xlabel('Section', fontsize=11, fontweight='bold')\n    ax1.set_ylabel('Number of Features', fontsize=11, fontweight='bold')\n    ax1.set_title('Features Generated per Section', fontsize=13, fontweight='bold', pad=10)\n    ax1.set_xticks(x)\n    ax1.set_xticklabels([f'S{s}' for s in sections], fontsize=9)\n    ax1.legend(fontsize=10, frameon=True, shadow=True)\n    ax1.grid(axis='y', alpha=0.3)\n    \n    # Add total on top of bars\n    for i, (sf, pf) in enumerate(zip(single_features, pair_features)):\n        total = sf + pf\n        if total > 0:\n            ax1.text(i, total, str(total), ha='center', va='bottom', \n                    fontsize=9, fontweight='bold')\n    \n    # 2. Predictions per section\n    ax2 = fig.add_subplot(gs[0, 1])\n    predictions = [section_results[s].get('predictions', 0) for s in sections]\n    \n    colors = plt.cm.viridis(np.linspace(0, 1, len(predictions)))\n    bars = ax2.bar(range(len(predictions)), predictions, color=colors, \n                   edgecolor='black', linewidth=1.5)\n    ax2.set_xlabel('Section', fontsize=11, fontweight='bold')\n    ax2.set_ylabel('Number of Predictions', fontsize=11, fontweight='bold')\n    ax2.set_title('Predictions Generated per Section', fontsize=13, fontweight='bold', pad=10)\n    ax2.set_xticks(range(len(sections)))\n    ax2.set_xticklabels([f'S{s}' for s in sections], fontsize=9)\n    ax2.grid(axis='y', alpha=0.3)\n    \n    for bar, val in zip(bars, predictions):\n        if val > 0:\n            height = bar.get_height()\n            ax2.text(bar.get_x() + bar.get_width()/2., height, str(val),\n                    ha='center', va='bottom', fontsize=9, fontweight='bold')\n    \n    # 3. Models used\n    ax3 = fig.add_subplot(gs[0, 2])\n    models_used = [section_results[s].get('models', 0) for s in sections]\n    \n    bars = ax3.bar(range(len(models_used)), models_used, color='#F18F01',\n                   edgecolor='black', linewidth=1.5, alpha=0.8)\n    ax3.set_xlabel('Section', fontsize=11, fontweight='bold')\n    ax3.set_ylabel('Number of Models', fontsize=11, fontweight='bold')\n    ax3.set_title('Models Used per Section', fontsize=13, fontweight='bold', pad=10)\n    ax3.set_xticks(range(len(sections)))\n    ax3.set_xticklabels([f'S{s}' for s in sections], fontsize=9)\n    ax3.grid(axis='y', alpha=0.3)\n    ax3.set_ylim([0, max(models_used) + 1 if max(models_used) > 0 else 6])\n    \n    for bar, val in zip(bars, models_used):\n        if val > 0:\n            height = bar.get_height()\n            ax3.text(bar.get_x() + bar.get_width()/2., height, str(val),\n                    ha='center', va='bottom', fontsize=9, fontweight='bold')\n    \n    # 4. Cumulative predictions\n    ax4 = fig.add_subplot(gs[1, 0])\n    valid_preds = [section_results[s].get('predictions', 0) for s in sections]\n    cumulative_preds = np.cumsum(valid_preds)\n    \n    ax4.plot(range(len(cumulative_preds)), cumulative_preds, marker='o', \n            linewidth=3, markersize=10, color='#2E86AB', markerfacecolor='#FF6B9D',\n            markeredgecolor='black', markeredgewidth=2)\n    ax4.fill_between(range(len(cumulative_preds)), cumulative_preds, alpha=0.3, color='#2E86AB')\n    ax4.set_xlabel('Section', fontsize=11, fontweight='bold')\n    ax4.set_ylabel('Cumulative Predictions', fontsize=11, fontweight='bold')\n    ax4.set_title('Cumulative Predictions Growth', fontsize=13, fontweight='bold', pad=10)\n    ax4.set_xticks(range(len(sections)))\n    ax4.set_xticklabels([f'S{s}' for s in sections], fontsize=9)\n    ax4.grid(alpha=0.3)\n    \n    for i, val in enumerate(cumulative_preds):\n        if val > 0:\n            ax4.annotate(f'{val}', (i, val), textcoords=\"offset points\", \n                        xytext=(0,10), ha='center', fontsize=9, fontweight='bold',\n                        bbox=dict(boxstyle='round,pad=0.3', facecolor='yellow', alpha=0.7))\n    \n    # 5. Feature generation efficiency\n    ax5 = fig.add_subplot(gs[1, 1])\n    total_features = [sf + pf for sf, pf in zip(single_features, pair_features)]\n    efficiency = [p/f if f > 0 else 0 for p, f in zip(predictions, total_features)]\n    \n    bars = ax5.bar(range(len(efficiency)), efficiency, color='#6BCF7F',\n                   edgecolor='black', linewidth=1.5, alpha=0.8)\n    ax5.set_xlabel('Section', fontsize=11, fontweight='bold')\n    ax5.set_ylabel('Predictions / Features', fontsize=11, fontweight='bold')\n    ax5.set_title('Feature Efficiency', fontsize=13, fontweight='bold', pad=10)\n    ax5.set_xticks(range(len(sections)))\n    ax5.set_xticklabels([f'S{s}' for s in sections], fontsize=9)\n    ax5.grid(axis='y', alpha=0.3)\n    \n    for bar, val in zip(bars, efficiency):\n        if val > 0:\n            height = bar.get_height()\n            ax5.text(bar.get_x() + bar.get_width()/2., height, f'{val:.2f}',\n                    ha='center', va='bottom', fontsize=9, fontweight='bold')\n    \n    # 6. Summary statistics table\n    ax6 = fig.add_subplot(gs[1, 2])\n    ax6.axis('off')\n    \n    total_single = sum(single_features)\n    total_pair = sum(pair_features)\n    total_preds = sum(predictions)\n    avg_models = np.mean([m for m in models_used if m > 0]) if any(models_used) else 0\n    \n    summary_data = [\n        ['Metric', 'Value'],\n        ['Total Sections', f'{len(sections)}'],\n        ['Single Features', f'{total_single:,}'],\n        ['Pair Features', f'{total_pair:,}'],\n        ['Total Predictions', f'{total_preds:,}'],\n        ['Avg Models/Section', f'{avg_models:.1f}']\n    ]\n    \n    table = ax6.table(cellText=summary_data, cellLoc='center', loc='center',\n                     colWidths=[0.6, 0.4])\n    table.auto_set_font_size(False)\n    table.set_fontsize(11)\n    table.scale(1, 3)\n    \n    for i in range(len(summary_data)):\n        for j in range(len(summary_data[0])):\n            cell = table[(i, j)]\n            if i == 0:\n                cell.set_facecolor('#2E86AB')\n                cell.set_text_props(weight='bold', color='white', size=12)\n            else:\n                cell.set_facecolor('#E8F4F8' if i % 2 == 0 else 'white')\n            cell.set_edgecolor('#2E86AB')\n            cell.set_linewidth(2)\n    \n    ax6.set_title('Training Summary', fontsize=13, fontweight='bold', pad=20)\n    \n    plt.suptitle('Training Progress Overview', fontsize=18, fontweight='bold', y=0.995)\n    plt.savefig('/kaggle/working/visualizations/06_training_progress_detailed.png',\n               dpi=150, bbox_inches='tight', facecolor='white')\n    print(\"✓ Saved: 06_training_progress_detailed.png\")\n    plt.show()\n    plt.close()\n\ndef plot_comprehensive_submission_analysis(submission, train):\n    \"\"\"Comprehensive submission analysis with train comparison\"\"\"\n    fig = plt.figure(figsize=(24, 18))\n    gs = GridSpec(4, 3, figure=fig, hspace=0.35, wspace=0.35)\n    \n    # Calculate duration\n    submission['duration'] = submission['stop_frame'] - submission['start_frame']\n    \n    # Extract train behaviors for comparison\n    train_actions = []\n    train_durations = []\n    train_self_count = 0\n    train_paired_count = 0\n    \n    for _, row in train.iterrows():\n        if isinstance(row['behaviors_labeled'], str):\n            behaviors = json.loads(row['behaviors_labeled'])\n            for b in behaviors:\n                b_clean = b.replace(\"'\", \"\")\n                parts = b_clean.split(',')\n                if len(parts) >= 3:\n                    train_actions.append(parts[2])\n                    if len(parts) >= 2:\n                        if parts[1] == 'self':\n                            train_self_count += 1\n                        else:\n                            train_paired_count += 1\n    \n    # 1. Top actions comparison (Train vs Prediction)\n    ax1 = fig.add_subplot(gs[0, :2])\n    \n    pred_action_counts = submission['action'].value_counts().head(15)\n    train_action_counts = pd.Series(train_actions).value_counts()\n    \n    # Align both series\n    common_actions = pred_action_counts.index\n    train_aligned = train_action_counts.reindex(common_actions, fill_value=0)\n    \n    x = np.arange(len(common_actions))\n    width = 0.35\n    \n    bars1 = ax1.bar(x - width/2, train_aligned.values, width, label='Train',\n                   color='#2E86AB', edgecolor='black', alpha=0.8)\n    bars2 = ax1.bar(x + width/2, pred_action_counts.values, width, label='Predictions',\n                   color='#FF6B9D', edgecolor='black', alpha=0.8)\n    \n    ax1.set_xlabel('Action', fontsize=11, fontweight='bold')\n    ax1.set_ylabel('Frequency', fontsize=11, fontweight='bold')\n    ax1.set_title('Top 15 Actions: Train vs Predictions Comparison', \n                 fontsize=14, fontweight='bold', pad=10)\n    ax1.set_xticks(x)\n    ax1.set_xticklabels(common_actions, rotation=45, ha='right', fontsize=9)\n    ax1.legend(fontsize=11, frameon=True, shadow=True)\n    ax1.grid(axis='y', alpha=0.3)\n    ax1.set_yscale('log')\n    \n    # 2. Event duration distribution\n    ax2 = fig.add_subplot(gs[0, 2])\n    ax2.hist(submission['duration'], bins=50, color='#F18F01', \n            edgecolor='black', alpha=0.7)\n    ax2.axvline(submission['duration'].mean(), color='red', linestyle='--', \n               linewidth=2, label=f'Mean: {submission[\"duration\"].mean():.0f}')\n    ax2.axvline(submission['duration'].median(), color='blue', linestyle='--',\n               linewidth=2, label=f'Median: {submission[\"duration\"].median():.0f}')\n    ax2.set_title('Event Duration Distribution', fontsize=14, fontweight='bold', pad=10)\n    ax2.set_xlabel('Duration (frames)', fontsize=11)\n    ax2.set_ylabel('Frequency', fontsize=11)\n    ax2.legend(fontsize=10)\n    ax2.grid(alpha=0.3)\n    \n    # 3. Predictions per agent\n    ax3 = fig.add_subplot(gs[1, 0])\n    agent_counts = submission['agent_id'].value_counts()\n    colors = plt.cm.Set3(np.linspace(0, 1, len(agent_counts)))\n    bars = ax3.bar(range(len(agent_counts)), agent_counts.values, color=colors,\n                  edgecolor='black', linewidth=1.5)\n    ax3.set_xticks(range(len(agent_counts)))\n    ax3.set_xticklabels(agent_counts.index, fontsize=10, fontweight='bold')\n    ax3.set_title('Predictions per Agent', fontsize=14, fontweight='bold', pad=10)\n    ax3.set_xlabel('Agent ID', fontsize=11)\n    ax3.set_ylabel('Count', fontsize=11)\n    ax3.grid(axis='y', alpha=0.3)\n    \n    for bar, val in zip(bars, agent_counts.values):\n        height = bar.get_height()\n        ax3.text(bar.get_x() + bar.get_width()/2., height, str(val),\n                ha='center', va='bottom', fontsize=10, fontweight='bold')\n    \n    # 4. Self vs Paired (Train vs Prediction)\n    ax4 = fig.add_subplot(gs[1, 1])\n    \n    pred_self = (submission['target_id'] == 'self').sum()\n    pred_paired = (submission['target_id'] != 'self').sum()\n    \n    x_pos = np.arange(2)\n    width = 0.35\n    \n    train_vals = [train_self_count, train_paired_count]\n    pred_vals = [pred_self, pred_paired]\n    \n    # Normalize to percentages\n    train_total = sum(train_vals)\n    pred_total = sum(pred_vals)\n    train_pct = [v/train_total*100 for v in train_vals]\n    pred_pct = [v/pred_total*100 for v in pred_vals]\n    \n    bars1 = ax4.bar(x_pos - width/2, train_pct, width, label='Train',\n                   color='#2E86AB', edgecolor='black', alpha=0.8)\n    bars2 = ax4.bar(x_pos + width/2, pred_pct, width, label='Predictions',\n                   color='#FF6B9D', edgecolor='black', alpha=0.8)\n    \n    ax4.set_ylabel('Percentage (%)', fontsize=11, fontweight='bold')\n    ax4.set_title('Self vs Paired: Train vs Predictions', \n                 fontsize=14, fontweight='bold', pad=10)\n    ax4.set_xticks(x_pos)\n    ax4.set_xticklabels(['Self-directed', 'Paired'], fontsize=11, fontweight='bold')\n    ax4.legend(fontsize=11, frameon=True, shadow=True)\n    ax4.grid(axis='y', alpha=0.3)\n    \n    # Add percentage labels\n    for bars in [bars1, bars2]:\n        for bar in bars:\n            height = bar.get_height()\n            ax4.text(bar.get_x() + bar.get_width()/2., height,\n                    f'{height:.1f}%', ha='center', va='bottom', \n                    fontsize=10, fontweight='bold')\n    \n    # 5. Predictions per video\n    ax5 = fig.add_subplot(gs[1, 2])\n    video_counts = submission['video_id'].value_counts()\n    colors = plt.cm.plasma(np.linspace(0, 1, len(video_counts)))\n    bars = ax5.bar(range(len(video_counts)), video_counts.values, color=colors,\n                  edgecolor='black', linewidth=1)\n    ax5.set_title('Predictions per Video', fontsize=14, fontweight='bold', pad=10)\n    ax5.set_xlabel('Video Index', fontsize=11)\n    ax5.set_ylabel('Count', fontsize=11)\n    ax5.grid(axis='y', alpha=0.3)\n    \n    # 6. Duration by action (top 10)\n    ax6 = fig.add_subplot(gs[2, :])\n    top_actions = submission['action'].value_counts().head(10).index\n    duration_stats = submission[submission['action'].isin(top_actions)].groupby('action')['duration'].agg(['mean', 'std', 'median'])\n    duration_stats = duration_stats.sort_values('mean')\n    \n    x_pos = np.arange(len(duration_stats))\n    ax6.barh(x_pos, duration_stats['mean'].values, xerr=duration_stats['std'].values,\n            color='#6BCF7F', edgecolor='black', linewidth=1, alpha=0.8,\n            error_kw={'linewidth': 2, 'ecolor': 'red', 'capsize': 5})\n    ax6.set_yticks(x_pos)\n    ax6.set_yticklabels(duration_stats.index, fontsize=10)\n    ax6.set_title('Average Duration by Action (Top 10) with Standard Deviation',\n                 fontsize=14, fontweight='bold', pad=10)\n    ax6.set_xlabel('Average Duration (frames)', fontsize=11)\n    ax6.grid(axis='x', alpha=0.3)\n    \n    for i, (mean, std) in enumerate(zip(duration_stats['mean'], duration_stats['std'])):\n        ax6.text(mean + std + 5, i, f'{mean:.0f}±{std:.0f}',\n                va='center', fontsize=9, fontweight='bold')\n    \n    # 7. Action frequency distribution\n    ax7 = fig.add_subplot(gs[3, 0])\n    action_freq = submission['action'].value_counts()\n    ax7.hist(action_freq.values, bins=30, color='#A23B72', \n            edgecolor='black', alpha=0.7)\n    ax7.set_title('Action Frequency Distribution', fontsize=14, fontweight='bold', pad=10)\n    ax7.set_xlabel('Frequency per Action', fontsize=11)\n    ax7.set_ylabel('Number of Actions', fontsize=11)\n    ax7.axvline(action_freq.mean(), color='red', linestyle='--', linewidth=2,\n               label=f'Mean: {action_freq.mean():.1f}')\n    ax7.set_yscale('log')\n    ax7.legend(fontsize=10)\n    ax7.grid(alpha=0.3)\n    \n    # 8. Duration statistics by category\n    ax8 = fig.add_subplot(gs[3, 1])\n    \n    short_events = (submission['duration'] <= 30).sum()\n    medium_events = ((submission['duration'] > 30) & (submission['duration'] <= 120)).sum()\n    long_events = (submission['duration'] > 120).sum()\n    \n    categories = ['Short\\n(≤30)', 'Medium\\n(30-120)', 'Long\\n(>120)']\n    values = [short_events, medium_events, long_events]\n    colors_cat = ['#FF6B9D', '#FFD93D', '#6BCF7F']\n    \n    bars = ax8.bar(range(len(categories)), values, color=colors_cat,\n                  edgecolor='black', linewidth=2, alpha=0.8)\n    ax8.set_xticks(range(len(categories)))\n    ax8.set_xticklabels(categories, fontsize=11, fontweight='bold')\n    ax8.set_title('Event Duration Categories', fontsize=14, fontweight='bold', pad=10)\n    ax8.set_ylabel('Number of Events', fontsize=11)\n    ax8.grid(axis='y', alpha=0.3)\n    \n    for bar, val in zip(bars, values):\n        height = bar.get_height()\n        ax8.text(bar.get_x() + bar.get_width()/2., height,\n                f'{val}\\n({val/len(submission)*100:.1f}%)',\n                ha='center', va='bottom', fontsize=10, fontweight='bold')\n    \n    # 9. Summary statistics table\n    ax9 = fig.add_subplot(gs[3, 2])\n    ax9.axis('off')\n    \n    unique_actions = submission['action'].nunique()\n    unique_videos = submission['video_id'].nunique()\n    unique_agents = submission['agent_id'].nunique()\n    avg_duration = submission['duration'].mean()\n    median_duration = submission['duration'].median()\n    \n    summary_data = [\n        ['Metric', 'Value'],\n        ['Total Predictions', f'{len(submission):,}'],\n        ['Unique Actions', f'{unique_actions}'],\n        ['Unique Videos', f'{unique_videos}'],\n        ['Unique Agents', f'{unique_agents}'],\n        ['Avg Duration', f'{avg_duration:.1f}'],\n        ['Median Duration', f'{median_duration:.0f}']\n    ]\n    \n    table = ax9.table(cellText=summary_data, cellLoc='center', loc='center',\n                     colWidths=[0.6, 0.4])\n    table.auto_set_font_size(False)\n    table.set_fontsize(11)\n    table.scale(1, 2.5)\n    \n    for i in range(len(summary_data)):\n        for j in range(len(summary_data[0])):\n            cell = table[(i, j)]\n            if i == 0:\n                cell.set_facecolor('#2E86AB')\n                cell.set_text_props(weight='bold', color='white', size=12)\n            else:\n                cell.set_facecolor('#E8F4F8' if i % 2 == 0 else 'white')\n            cell.set_edgecolor('#2E86AB')\n            cell.set_linewidth(2)\n    \n    ax9.set_title('Prediction Summary', fontsize=13, fontweight='bold', pad=20)\n    \n    plt.suptitle(f'Comprehensive Submission Analysis ({len(submission):,} predictions)',\n                fontsize=18, fontweight='bold', y=0.995)\n    plt.savefig('/kaggle/working/visualizations/07_submission_comprehensive.png',\n               dpi=150, bbox_inches='tight', facecolor='white')\n    print(\"✓ Saved: 07_submission_comprehensive.png\")\n    plt.show()\n    plt.close()\n\ndef plot_action_distribution_comparison(submission, train):\n    \"\"\"Detailed action distribution comparison\"\"\"\n    # Extract train actions\n    train_actions = []\n    for _, row in train.iterrows():\n        if isinstance(row['behaviors_labeled'], str):\n            behaviors = json.loads(row['behaviors_labeled'])\n            for b in behaviors:\n                b_clean = b.replace(\"'\", \"\")\n                parts = b_clean.split(',')\n                if len(parts) >= 3:\n                    train_actions.append(parts[2])\n    \n    train_action_counts = pd.Series(train_actions).value_counts()\n    pred_action_counts = submission['action'].value_counts()\n    \n    # Get all unique actions\n    all_actions = set(list(train_action_counts.index) + list(pred_action_counts.index))\n    \n    # Create comparison dataframe\n    comparison_df = pd.DataFrame({\n        'train': train_action_counts,\n        'prediction': pred_action_counts\n    }).fillna(0)\n    \n    # Take top 20 by train frequency\n    comparison_df = comparison_df.nlargest(20, 'train')\n    \n    fig, axes = plt.subplots(2, 2, figsize=(20, 14))\n    \n    # 1. Side-by-side comparison\n    ax1 = axes[0, 0]\n    x = np.arange(len(comparison_df))\n    width = 0.35\n    \n    bars1 = ax1.barh(x - width/2, comparison_df['train'].values, width,\n                    label='Train', color='#2E86AB', edgecolor='black', alpha=0.8)\n    bars2 = ax1.barh(x + width/2, comparison_df['prediction'].values, width,\n                    label='Predictions', color='#FF6B9D', edgecolor='black', alpha=0.8)\n    \n    ax1.set_yticks(x)\n    ax1.set_yticklabels(comparison_df.index, fontsize=9)\n    ax1.set_xlabel('Frequency', fontsize=11, fontweight='bold')\n    ax1.set_title('Top 20 Actions: Train vs Predictions', \n                 fontsize=14, fontweight='bold', pad=10)\n    ax1.legend(fontsize=11)\n    ax1.set_xscale('log')\n    ax1.grid(axis='x', alpha=0.3)\n    \n    # 2. Ratio plot (Prediction / Train)\n    ax2 = axes[0, 1]\n    comparison_df['ratio'] = comparison_df['prediction'] / (comparison_df['train'] + 1)\n    comparison_sorted = comparison_df.sort_values('ratio')\n    \n    colors = ['#FF6B9D' if r < 1 else '#6BCF7F' for r in comparison_sorted['ratio']]\n    bars = ax2.barh(range(len(comparison_sorted)), comparison_sorted['ratio'].values,\n                   color=colors, edgecolor='black', linewidth=0.5, alpha=0.8)\n    ax2.axvline(1, color='red', linestyle='--', linewidth=2, label='Equal (ratio=1)')\n    ax2.set_yticks(range(len(comparison_sorted)))\n    ax2.set_yticklabels(comparison_sorted.index, fontsize=9)\n    ax2.set_xlabel('Prediction / Train Ratio', fontsize=11, fontweight='bold')\n    ax2.set_title('Action Prediction Ratio', fontsize=14, fontweight='bold', pad=10)\n    ax2.legend(fontsize=10)\n    ax2.grid(axis='x', alpha=0.3)\n    \n    # 3. Normalized distributions\n    ax3 = axes[1, 0]\n    comparison_df['train_norm'] = comparison_df['train'] / comparison_df['train'].sum() * 100\n    comparison_df['pred_norm'] = comparison_df['prediction'] / comparison_df['prediction'].sum() * 100\n    comparison_sorted_norm = comparison_df.sort_values('train_norm', ascending=False)\n    \n    x = np.arange(len(comparison_sorted_norm))\n    width = 0.35\n    \n    ax3.bar(x - width/2, comparison_sorted_norm['train_norm'].values, width,\n           label='Train', color='#2E86AB', edgecolor='black', alpha=0.8)\n    ax3.bar(x + width/2, comparison_sorted_norm['pred_norm'].values, width,\n           label='Predictions', color='#FF6B9D', edgecolor='black', alpha=0.8)\n    \n    ax3.set_xticks(x)\n    ax3.set_xticklabels(comparison_sorted_norm.index, rotation=45, ha='right', fontsize=8)\n    ax3.set_ylabel('Percentage (%)', fontsize=11, fontweight='bold')\n    ax3.set_title('Normalized Action Distribution', fontsize=14, fontweight='bold', pad=10)\n    ax3.legend(fontsize=11)\n    ax3.grid(axis='y', alpha=0.3)\n    \n    # 4. Scatter plot (Train vs Prediction)\n    ax4 = axes[1, 1]\n    ax4.scatter(comparison_df['train'], comparison_df['prediction'], \n               s=100, alpha=0.6, c=range(len(comparison_df)), cmap='viridis',\n               edgecolors='black', linewidth=1.5)\n    \n    # Add diagonal line (perfect match)\n    max_val = max(comparison_df['train'].max(), comparison_df['prediction'].max())\n    ax4.plot([0, max_val], [0, max_val], 'r--', linewidth=2, \n            label='Perfect Match', alpha=0.7)\n    \n    ax4.set_xlabel('Train Frequency', fontsize=11, fontweight='bold')\n    ax4.set_ylabel('Prediction Frequency', fontsize=11, fontweight='bold')\n    ax4.set_title('Train vs Prediction Correlation', fontsize=14, fontweight='bold', pad=10)\n    ax4.legend(fontsize=11)\n    ax4.set_xscale('log')\n    ax4.set_yscale('log')\n    ax4.grid(alpha=0.3)\n    \n    # Annotate some points\n    for idx in comparison_df.index[:5]:\n        ax4.annotate(idx, (comparison_df.loc[idx, 'train'], \n                          comparison_df.loc[idx, 'prediction']),\n                    fontsize=8, alpha=0.7)\n    \n    plt.suptitle('Action Distribution Comparison: Train vs Predictions',\n                fontsize=16, fontweight='bold', y=0.995)\n    plt.tight_layout()\n    plt.savefig('/kaggle/working/visualizations/08_action_comparison_detailed.png',\n               dpi=150, bbox_inches='tight', facecolor='white')\n    print(\"✓ Saved: 08_action_comparison_detailed.png\")\n    plt.show()\n    plt.close()\n\ndef plot_model_ensemble_analysis(submission):\n    \"\"\"Analyze ensemble predictions and model behavior\"\"\"\n    fig = plt.figure(figsize=(20, 12))\n    gs = GridSpec(2, 3, figure=fig, hspace=0.3, wspace=0.3)\n    \n    # 1. Prediction confidence simulation (based on duration as proxy)\n    ax1 = fig.add_subplot(gs[0, 0])\n    \n    # Longer events might indicate higher confidence\n    submission['conf_proxy'] = np.clip(submission['duration'] / 100, 0, 1)\n    \n    ax1.hist(submission['conf_proxy'], bins=50, color='#2E86AB',\n            edgecolor='black', alpha=0.7)\n    ax1.set_title('Prediction Confidence Proxy\\n(Duration-based)', \n                 fontsize=13, fontweight='bold', pad=10)\n    ax1.set_xlabel('Confidence Proxy', fontsize=11)\n    ax1.set_ylabel('Frequency', fontsize=11)\n    ax1.axvline(submission['conf_proxy'].mean(), color='red', linestyle='--',\n               linewidth=2, label=f'Mean: {submission[\"conf_proxy\"].mean():.2f}')\n    ax1.legend(fontsize=10)\n    ax1.grid(alpha=0.3)\n    \n    # 2. Event timing distribution\n    ax2 = fig.add_subplot(gs[0, 1])\n    ax2.hist(submission['start_frame'], bins=50, color='#A23B72',\n            edgecolor='black', alpha=0.7, label='Start Frame')\n    ax2.set_title('Event Start Frame Distribution', fontsize=13, fontweight='bold', pad=10)\n    ax2.set_xlabel('Frame Number', fontsize=11)\n    ax2.set_ylabel('Frequency', fontsize=11)\n    ax2.legend(fontsize=10)\n    ax2.grid(alpha=0.3)\n    \n    # 3. Predictions over time (cumulative)\n    ax3 = fig.add_subplot(gs[0, 2])\n    submission_sorted = submission.sort_values('start_frame')\n    cumulative_counts = np.arange(1, len(submission_sorted) + 1)\n    \n    ax3.plot(submission_sorted['start_frame'].values, cumulative_counts,\n            linewidth=2, color='#F18F01')\n    ax3.fill_between(submission_sorted['start_frame'].values, cumulative_counts,\n                    alpha=0.3, color='#F18F01')\n    ax3.set_title('Cumulative Predictions over Time', fontsize=13, fontweight='bold', pad=10)\n    ax3.set_xlabel('Frame Number', fontsize=11)\n    ax3.set_ylabel('Cumulative Predictions', fontsize=11)\n    ax3.grid(alpha=0.3)\n    \n    # 4. Agent-target interaction matrix\n    ax4 = fig.add_subplot(gs[1, 0])\n    \n    # Create interaction matrix\n    agent_target_pairs = submission.groupby(['agent_id', 'target_id']).size().unstack(fill_value=0)\n    \n    sns.heatmap(agent_target_pairs, annot=True, fmt='d', cmap='YlOrRd',\n               cbar_kws={'label': 'Number of Predictions'}, ax=ax4,\n               linewidths=0.5, linecolor='black')\n    ax4.set_title('Agent-Target Interaction Matrix', fontsize=13, fontweight='bold', pad=10)\n    ax4.set_xlabel('Target ID', fontsize=11, fontweight='bold')\n    ax4.set_ylabel('Agent ID', fontsize=11, fontweight='bold')\n    \n    # 5. Duration vs action count\n    ax5 = fig.add_subplot(gs[1, 1])\n    \n    action_stats = submission.groupby('action').agg({\n        'duration': 'mean',\n        'action': 'count'\n    }).rename(columns={'action': 'count'})\n    action_stats = action_stats.nlargest(20, 'count')\n    \n    scatter = ax5.scatter(action_stats['count'], action_stats['duration'],\n                         s=action_stats['count']*2, alpha=0.6,\n                         c=range(len(action_stats)), cmap='viridis',\n                         edgecolors='black', linewidth=1)\n    \n    ax5.set_xlabel('Action Count', fontsize=11, fontweight='bold')\n    ax5.set_ylabel('Average Duration', fontsize=11, fontweight='bold')\n    ax5.set_title('Action Frequency vs Duration', fontsize=13, fontweight='bold', pad=10)\n    ax5.set_xscale('log')\n    ax5.grid(alpha=0.3)\n    \n    # Annotate top actions\n    for idx in action_stats.index[:5]:\n        ax5.annotate(idx, (action_stats.loc[idx, 'count'],\n                          action_stats.loc[idx, 'duration']),\n                    fontsize=8, alpha=0.7)\n    \n    # 6. Event length categories by action\n    ax6 = fig.add_subplot(gs[1, 2])\n    \n    top_actions_for_length = submission['action'].value_counts().head(10).index\n    submission_subset = submission[submission['action'].isin(top_actions_for_length)]\n    \n    duration_categories = pd.cut(submission_subset['duration'],\n                                bins=[0, 30, 120, np.inf],\n                                labels=['Short', 'Medium', 'Long'])\n    \n    category_by_action = pd.crosstab(submission_subset['action'], duration_categories,\n                                    normalize='index') * 100\n    \n    category_by_action.plot(kind='barh', stacked=True, ax=ax6,\n                           color=['#FF6B9D', '#FFD93D', '#6BCF7F'],\n                           edgecolor='black', linewidth=0.5)\n    ax6.set_xlabel('Percentage (%)', fontsize=11, fontweight='bold')\n    ax6.set_ylabel('Action', fontsize=11, fontweight='bold')\n    ax6.set_title('Duration Categories by Action (Top 10)', \n                 fontsize=13, fontweight='bold', pad=10)\n    ax6.legend(title='Duration', fontsize=9, title_fontsize=10)\n    ax6.grid(axis='x', alpha=0.3)\n    \n    plt.suptitle('Model Ensemble & Prediction Analysis', fontsize=16, fontweight='bold', y=0.995)\n    plt.savefig('/kaggle/working/visualizations/09_model_ensemble_analysis.png',\n               dpi=150, bbox_inches='tight', facecolor='white')\n    print(\"✓ Saved: 09_model_ensemble_analysis.png\")\n    plt.show()\n    plt.close()\n\n# ==================== EXISTING CODE (CLASSIFIERS, SCORING, ETC.) ====================\n\nclass StratifiedSubsetClassifier(ClassifierMixin, BaseEstimator):\n    \"\"\"Fit estimator with stratified sampling to maintain class balance\"\"\"\n    def __init__(self, estimator, n_samples):\n        self.estimator = estimator\n        self.n_samples = n_samples\n\n    def fit(self, X, y):\n        if len(X) <= self.n_samples:\n            self.estimator.fit(np.array(X, copy=False), np.array(y, copy=False))\n        else:\n            from sklearn.model_selection import StratifiedShuffleSplit\n            sss = StratifiedShuffleSplit(n_splits=1, train_size=min(self.n_samples, len(X)), random_state=42)\n            try:\n                for train_idx, _ in sss.split(X, y):\n                    self.estimator.fit(np.array(X, copy=False)[train_idx], np.array(y, copy=False)[train_idx])\n            except:\n                downsample = len(X) // self.n_samples\n                downsample = max(downsample, 1)\n                self.estimator.fit(np.array(X, copy=False)[::downsample], np.array(y, copy=False)[::downsample])\n        \n        self.classes_ = self.estimator.classes_\n        return self\n\n    def predict_proba(self, X):\n        if len(self.classes_) == 1:\n            return np.full((len(X), 1), 1.0)\n        probs = self.estimator.predict_proba(np.array(X))\n        return probs\n        \n    def predict(self, X):\n        return self.estimator.predict(np.array(X))\n\nclass HostVisibleError(Exception):\n    pass\n\ndef single_lab_f1(lab_solution: pl.DataFrame, lab_submission: pl.DataFrame, beta: float = 1) -> float:\n    label_frames: defaultdict[str, set[int]] = defaultdict(set)\n    prediction_frames: defaultdict[str, set[int]] = defaultdict(set)\n\n    for row in lab_solution.to_dicts():\n        label_frames[row['label_key']].update(range(row['start_frame'], row['stop_frame']))\n\n    for video in lab_solution['video_id'].unique():\n        active_labels: str = lab_solution.filter(pl.col('video_id') == video)['behaviors_labeled'].first()\n        active_labels: set[str] = set(json.loads(active_labels))\n        predicted_mouse_pairs: defaultdict[str, set[int]] = defaultdict(set)\n\n        for row in lab_submission.filter(pl.col('video_id') == video).to_dicts():\n            if ','.join([str(row['agent_id']), str(row['target_id']), row['action']]) not in active_labels:\n                continue\n           \n            new_frames = set(range(row['start_frame'], row['stop_frame']))\n            new_frames = new_frames.difference(prediction_frames[row['prediction_key']])\n            prediction_pair = ','.join([str(row['agent_id']), str(row['target_id'])])\n            if predicted_mouse_pairs[prediction_pair].intersection(new_frames):\n                raise HostVisibleError('Multiple predictions for the same frame from one agent/target pair')\n            prediction_frames[row['prediction_key']].update(new_frames)\n            predicted_mouse_pairs[prediction_pair].update(new_frames)\n\n    tps = defaultdict(int)\n    fns = defaultdict(int)\n    fps = defaultdict(int)\n    for key, pred_frames in prediction_frames.items():\n        action = key.split('_')[-1]\n        matched_label_frames = label_frames[key]\n        tps[action] += len(pred_frames.intersection(matched_label_frames))\n        fns[action] += len(matched_label_frames.difference(pred_frames))\n        fps[action] += len(pred_frames.difference(matched_label_frames))\n\n    distinct_actions = set()\n    for key, frames in label_frames.items():\n        action = key.split('_')[-1]\n        distinct_actions.add(action)\n        if key not in prediction_frames:\n            fns[action] += len(frames)\n\n    action_f1s = []\n    for action in distinct_actions:\n        if tps[action] + fns[action] + fps[action] == 0:\n            action_f1s.append(0)\n        else:\n            action_f1s.append((1 + beta**2) * tps[action] / ((1 + beta**2) * tps[action] + beta**2 * fns[action] + fps[action]))\n    return sum(action_f1s) / len(action_f1s)\n\ndef mouse_fbeta(solution: pd.DataFrame, submission: pd.DataFrame, beta: float = 1) -> float:\n    if len(solution) == 0 or len(submission) == 0:\n        raise ValueError('Missing solution or submission data')\n\n    expected_cols = ['video_id', 'agent_id', 'target_id', 'action', 'start_frame', 'stop_frame']\n\n    for col in expected_cols:\n        if col not in solution.columns:\n            raise ValueError(f'Solution is missing column {col}')\n        if col not in submission.columns:\n            raise ValueError(f'Submission is missing column {col}')\n\n    solution: pl.DataFrame = pl.DataFrame(solution)\n    submission: pl.DataFrame = pl.DataFrame(submission)\n    assert (solution['start_frame'] <= solution['stop_frame']).all()\n    assert (submission['start_frame'] <= submission['stop_frame']).all()\n    solution_videos = set(solution['video_id'].unique())\n    submission = submission.filter(pl.col('video_id').is_in(solution_videos))\n\n    solution = solution.with_columns(\n        pl.concat_str(\n            [\n                pl.col('video_id').cast(pl.Utf8),\n                pl.col('agent_id').cast(pl.Utf8),\n                pl.col('target_id').cast(pl.Utf8),\n                pl.col('action'),\n            ],\n            separator='_',\n        ).alias('label_key'),\n    )\n    submission = submission.with_columns(\n        pl.concat_str(\n            [\n                pl.col('video_id').cast(pl.Utf8),\n                pl.col('agent_id').cast(pl.Utf8),\n                pl.col('target_id').cast(pl.Utf8),\n                pl.col('action'),\n            ],\n            separator='_',\n        ).alias('prediction_key'),\n    )\n\n    lab_scores = []\n    for lab in solution['lab_id'].unique():\n        lab_solution = solution.filter(pl.col('lab_id') == lab).clone()\n        lab_videos = set(lab_solution['video_id'].unique())\n        lab_submission = submission.filter(pl.col('video_id').is_in(lab_videos)).clone()\n        lab_scores.append(single_lab_f1(lab_solution, lab_submission, beta=beta))\n\n    return sum(lab_scores) / len(lab_scores)\n\ndef score(solution: pd.DataFrame, submission: pd.DataFrame, row_id_column_name: str, beta: float = 1) -> float:\n    solution = solution.drop(row_id_column_name, axis='columns', errors='ignore')\n    submission = submission.drop(row_id_column_name, axis='columns', errors='ignore')\n    return mouse_fbeta(solution, submission, beta=beta)\n\n# ==================== DATA LOADING ====================\n\nprint(\"=\"*80)\nprint(\"MABe Mouse Behavior Detection Challenge\")\nprint(\"Advanced Ensemble with Enhanced Comprehensive Visualizations\")\nprint(\"WITH SPATIAL HISTORY FEATURES\")\nprint(\"=\"*80)\n\ntrain = pd.read_csv('/kaggle/input/MABe-mouse-behavior-detection/train.csv')\ntrain['n_mice'] = 4 - train[['mouse1_strain', 'mouse2_strain', 'mouse3_strain', 'mouse4_strain']].isna().sum(axis=1)\ntrain_without_mabe22 = train.query(\"~ lab_id.str.startswith('MABe22_')\")\n\ntest = pd.read_csv('/kaggle/input/MABe-mouse-behavior-detection/test.csv')\nbody_parts_tracked_list = list(np.unique(train.body_parts_tracked))\n\nprint(f\"\\n📊 Dataset loaded: {len(train)} train videos, {len(test)} test videos\")\n\nprint(\"\\n\" + \"=\"*80)\nprint(\"GENERATING ENHANCED VISUALIZATIONS\")\nprint(\"=\"*80)\n\nplot_comprehensive_dataset_overview(train, test)\nplot_advanced_behavior_analysis(train)\n\ndrop_body_parts = ['headpiece_bottombackleft', 'headpiece_bottombackright', 'headpiece_bottomfrontleft', 'headpiece_bottomfrontright', \n                   'headpiece_topbackleft', 'headpiece_topbackright', 'headpiece_topfrontleft', 'headpiece_topfrontright', \n                   'spine_1', 'spine_2', 'tail_middle_1', 'tail_middle_2', 'tail_midpoint']\n\ndef generate_mouse_data(dataset, traintest, traintest_directory=None, generate_single=True, generate_pair=True):\n    assert traintest in ['train', 'test']\n    if traintest_directory is None:\n        traintest_directory = f\"/kaggle/input/MABe-mouse-behavior-detection/{traintest}_tracking\"\n    for _, row in dataset.iterrows():\n        \n        lab_id = row.lab_id\n        if lab_id.startswith('MABe22'): continue\n        video_id = row.video_id\n\n        if type(row.behaviors_labeled) != str:\n            if verbose: print('No labeled behaviors:', lab_id, video_id)\n            continue\n\n        path = f\"{traintest_directory}/{lab_id}/{video_id}.parquet\"\n        vid = pd.read_parquet(path)\n        if len(np.unique(vid.bodypart)) > 5:\n            vid = vid.query(\"~ bodypart.isin(@drop_body_parts)\")\n        pvid = vid.pivot(columns=['mouse_id', 'bodypart'], index='video_frame', values=['x', 'y'])\n        if pvid.isna().any().any():\n            if verbose and traintest == 'test': print('video with missing values', video_id, traintest, len(vid), 'frames')\n        else:\n            if verbose and traintest == 'test': print('video with all values', video_id, traintest, len(vid), 'frames')\n        del vid\n        pvid = pvid.reorder_levels([1, 2, 0], axis=1).T.sort_index().T\n        pvid /= row.pix_per_cm_approx\n\n        vid_behaviors = json.loads(row.behaviors_labeled)\n        vid_behaviors = sorted(list({b.replace(\"'\", \"\") for b in vid_behaviors}))\n        vid_behaviors = [b.split(',') for b in vid_behaviors]\n        vid_behaviors = pd.DataFrame(vid_behaviors, columns=['agent', 'target', 'action'])\n        \n        if traintest == 'train':\n            try:\n                annot = pd.read_parquet(path.replace('train_tracking', 'train_annotation'))\n            except FileNotFoundError:\n                continue\n\n        if generate_single:\n            vid_behaviors_subset = vid_behaviors.query(\"target == 'self'\")\n            for mouse_id_str in np.unique(vid_behaviors_subset.agent):\n                try:\n                    mouse_id = int(mouse_id_str[-1])\n                    vid_agent_actions = np.unique(vid_behaviors_subset.query(\"agent == @mouse_id_str\").action)\n                    single_mouse = pvid.loc[:, mouse_id]\n                    assert len(single_mouse) == len(pvid)\n                    single_mouse_meta = pd.DataFrame({\n                        'video_id': video_id,\n                        'agent_id': mouse_id_str,\n                        'target_id': 'self',\n                        'video_frame': single_mouse.index\n                    })\n                    if traintest == 'train':\n                        single_mouse_label = pd.DataFrame(0.0, columns=vid_agent_actions, index=single_mouse.index)\n                        annot_subset = annot.query(\"(agent_id == @mouse_id) & (target_id == @mouse_id)\")\n                        for i in range(len(annot_subset)):\n                            annot_row = annot_subset.iloc[i]\n                            single_mouse_label.loc[annot_row['start_frame']:annot_row['stop_frame'], annot_row.action] = 1.0\n                        yield 'single', single_mouse, single_mouse_meta, single_mouse_label, pvid\n                    else:\n                        if verbose: print('- test single', video_id, mouse_id)\n                        yield 'single', single_mouse, single_mouse_meta, vid_agent_actions, pvid\n                except KeyError:\n                    pass\n\n        if generate_pair:\n            vid_behaviors_subset = vid_behaviors.query(\"target != 'self'\")\n            if len(vid_behaviors_subset) > 0:\n                for agent, target in itertools.permutations(np.unique(pvid.columns.get_level_values('mouse_id')), 2):\n                    agent_str = f\"mouse{agent}\"\n                    target_str = f\"mouse{target}\"\n                    vid_agent_actions = np.unique(vid_behaviors_subset.query(\"(agent == @agent_str) & (target == @target_str)\").action)\n                    mouse_pair = pd.concat([pvid[agent], pvid[target]], axis=1, keys=['A', 'B'])\n                    assert len(mouse_pair) == len(pvid)\n                    mouse_pair_meta = pd.DataFrame({\n                        'video_id': video_id,\n                        'agent_id': agent_str,\n                        'target_id': target_str,\n                        'video_frame': mouse_pair.index\n                    })\n                    if traintest == 'train':\n                        mouse_pair_label = pd.DataFrame(0.0, columns=vid_agent_actions, index=mouse_pair.index)\n                        annot_subset = annot.query(\"(agent_id == @agent) & (target_id == @target)\")\n                        for i in range(len(annot_subset)):\n                            annot_row = annot_subset.iloc[i]\n                            mouse_pair_label.loc[annot_row['start_frame']:annot_row['stop_frame'], annot_row.action] = 1.0\n                        yield 'pair', mouse_pair, mouse_pair_meta, mouse_pair_label, pvid\n                    else:\n                        if verbose: print('- test pair', video_id, agent, target)\n                        yield 'pair', mouse_pair, mouse_pair_meta, vid_agent_actions, pvid\n\naction_thresholds = defaultdict(lambda: 0.27)\n\ndef predict_multiclass_adaptive(pred, meta, action_thresholds):\n    \"\"\"Adaptive thresholding per action + temporal smoothing\"\"\"\n    pred_smoothed = pred.rolling(window=5, min_periods=1, center=True).mean()\n    \n    ama = np.argmax(pred_smoothed, axis=1)\n    \n    max_probs = pred_smoothed.max(axis=1)\n    threshold_mask = np.zeros(len(pred_smoothed), dtype=bool)\n    for i, action in enumerate(pred_smoothed.columns):\n        action_mask = (ama == i)\n        threshold = action_thresholds.get(action, 0.27)\n        threshold_mask |= (action_mask & (max_probs >= threshold))\n    \n    ama = np.where(threshold_mask, ama, -1)\n    ama = pd.Series(ama, index=meta.video_frame)\n    \n    changes_mask = (ama != ama.shift(1)).values\n    ama_changes = ama[changes_mask]\n    meta_changes = meta[changes_mask]\n    mask = ama_changes.values >= 0\n    mask[-1] = False\n    \n    submission_part = pd.DataFrame({\n        'video_id': meta_changes['video_id'][mask].values,\n        'agent_id': meta_changes['agent_id'][mask].values,\n        'target_id': meta_changes['target_id'][mask].values,\n        'action': pred.columns[ama_changes[mask].values],\n        'start_frame': ama_changes.index[mask],\n        'stop_frame': ama_changes.index[1:][mask[:-1]]\n    })\n    \n    stop_video_id = meta_changes['video_id'][1:][mask[:-1]].values\n    stop_agent_id = meta_changes['agent_id'][1:][mask[:-1]].values\n    stop_target_id = meta_changes['target_id'][1:][mask[:-1]].values\n    \n    for i in range(len(submission_part)):\n        video_id = submission_part.video_id.iloc[i]\n        agent_id = submission_part.agent_id.iloc[i]\n        target_id = submission_part.target_id.iloc[i]\n        if i < len(stop_video_id):\n            if stop_video_id[i] != video_id or stop_agent_id[i] != agent_id or stop_target_id[i] != target_id:\n                new_stop_frame = meta.query(\"(video_id == @video_id)\").video_frame.max() + 1\n                submission_part.iat[i, submission_part.columns.get_loc('stop_frame')] = new_stop_frame\n        else:\n            new_stop_frame = meta.query(\"(video_id == @video_id)\").video_frame.max() + 1\n            submission_part.iat[i, submission_part.columns.get_loc('stop_frame')] = new_stop_frame\n    \n    duration = submission_part.stop_frame - submission_part.start_frame\n    submission_part = submission_part[duration >= 3].reset_index(drop=True)\n    \n    if len(submission_part) > 0:\n        assert (submission_part.stop_frame > submission_part.start_frame).all(), 'stop <= start'\n    \n    if verbose: print(f'  actions found: {len(submission_part)}')\n    return submission_part\n\n# ==================== NEW SPATIAL HISTORY FEATURES ====================\n\ndef add_spatial_history_features(X, center_x, center_y, pvid, current_mouse_id=None):\n    \"\"\"\n    Add features related to whether mouse is in locations previously visited by itself or other mice.\n    \n    Two key features:\n    1. self_location_revisit: Is the mouse in a location where it spent time previously?\n    2. other_location_visit: Is the mouse in a location where other mice spent time?\n    \"\"\"\n    \n    if 'body_center' not in pvid.columns.get_level_values(1):\n        # No body_center available, return without adding features\n        X['self_loc_revisit_5cm'] = 0\n        X['other_loc_visit_5cm'] = 0\n        return X\n    \n    # Define spatial radius for \"same location\" (in cm)\n    spatial_radius = 5.0\n    \n    # Get current positions\n    current_positions = np.column_stack([center_x.values, center_y.values])\n    \n    # Feature 1: Self location revisit\n    # Build a history of where this mouse has been (using temporal windowing)\n    history_window = 300  # Look back 300 frames (~10 seconds at 30fps)\n    self_loc_revisit = np.zeros(len(current_positions))\n    \n    for i in range(len(current_positions)):\n        if i < history_window:\n            continue\n        \n        # Get historical positions (excluding very recent to avoid trivial matches)\n        lookback_start = max(0, i - history_window)\n        lookback_end = max(0, i - 30)  # Exclude last 30 frames\n        \n        if lookback_end <= lookback_start:\n            continue\n            \n        historical_positions = current_positions[lookback_start:lookback_end]\n        current_pos = current_positions[i]\n        \n        # Check if current position is close to any historical position\n        if not (np.isnan(current_pos).any() or np.isnan(historical_positions).any().any()):\n            distances = np.sqrt(np.sum((historical_positions - current_pos)**2, axis=1))\n            # If any historical position is within radius, mark as revisit\n            if np.any(distances < spatial_radius):\n                self_loc_revisit[i] = 1.0\n    \n    X['self_loc_revisit_5cm'] = self_loc_revisit\n    \n    # Feature 2: Other mice location visit\n    # Check if current mouse is in locations where OTHER mice have been\n    other_loc_visit = np.zeros(len(current_positions))\n    \n    # Get all mice in the video\n    all_mice = pvid.columns.get_level_values('mouse_id').unique()\n    \n    if current_mouse_id is not None and len(all_mice) > 1:\n        # For each frame, check if current position overlaps with other mice's recent positions\n        for i in range(len(current_positions)):\n            current_pos = current_positions[i]\n            \n            if np.isnan(current_pos).any():\n                continue\n            \n            # Look at other mice's positions in recent history\n            for other_mouse in all_mice:\n                if other_mouse == current_mouse_id:\n                    continue\n                \n                try:\n                    other_x = pvid[other_mouse]['body_center']['x'].values\n                    other_y = pvid[other_mouse]['body_center']['y'].values\n                    \n                    # Check recent history of other mouse\n                    lookback_start = max(0, i - history_window)\n                    lookback_end = i\n                    \n                    other_positions = np.column_stack([\n                        other_x[lookback_start:lookback_end],\n                        other_y[lookback_start:lookback_end]\n                    ])\n                    \n                    # Remove nan values\n                    valid_mask = ~np.isnan(other_positions).any(axis=1)\n                    other_positions = other_positions[valid_mask]\n                    \n                    if len(other_positions) > 0:\n                        distances = np.sqrt(np.sum((other_positions - current_pos)**2, axis=1))\n                        if np.any(distances < spatial_radius):\n                            other_loc_visit[i] = 1.0\n                            break  # Found overlap with at least one other mouse\n                except (KeyError, IndexError):\n                    continue\n    \n    X['other_loc_visit_5cm'] = other_loc_visit\n    \n    # Add smoothed versions (proportion of time in visited locations)\n    smooth_window = 60\n    X['self_loc_revisit_pct60'] = pd.Series(self_loc_revisit).rolling(smooth_window, min_periods=1).mean()\n    X['other_loc_visit_pct60'] = pd.Series(other_loc_visit).rolling(smooth_window, min_periods=1).mean()\n    \n    return X\n\n# ==================== FEATURE ENGINEERING (UPDATED WITH SPATIAL HISTORY) ====================\n\ndef add_curvature_features(X, center_x, center_y):\n    vel_x = center_x.diff()\n    vel_y = center_y.diff()\n    acc_x = vel_x.diff()\n    acc_y = vel_y.diff()\n    cross_prod = vel_x * acc_y - vel_y * acc_x\n    vel_mag = np.sqrt(vel_x**2 + vel_y**2)\n    curvature = np.abs(cross_prod) / (vel_mag**3 + 1e-6)\n    for window in [30, 60]:\n        X[f'curv_mean_{window}'] = curvature.rolling(window, min_periods=5).mean()\n    angle = np.arctan2(vel_y, vel_x)\n    angle_change = np.abs(angle.diff())\n    X['turn_rate_30'] = angle_change.rolling(30, min_periods=5).sum()\n    return X\n\ndef add_multiscale_features(X, center_x, center_y):\n    speed = np.sqrt(center_x.diff()**2 + center_y.diff()**2)\n    scales = [10, 40, 160]\n    for scale in scales:\n        if len(speed) >= scale:\n            X[f'sp_m{scale}'] = speed.rolling(scale, min_periods=max(1, scale//4)).mean()\n            X[f'sp_s{scale}'] = speed.rolling(scale, min_periods=max(1, scale//4)).std()\n    if len(scales) >= 2 and f'sp_m{scales[0]}' in X.columns and f'sp_m{scales[-1]}' in X.columns:\n        X['sp_ratio'] = X[f'sp_m{scales[0]}'] / (X[f'sp_m{scales[-1]}'] + 1e-6)\n    return X\n\ndef add_state_features(X, center_x, center_y):\n    speed = np.sqrt(center_x.diff()**2 + center_y.diff()**2)\n    speed_ma = speed.rolling(15, min_periods=5).mean()\n    try:\n        speed_states = pd.cut(speed_ma, bins=[-np.inf, 0.5, 2.0, 5.0, np.inf], labels=[0, 1, 2, 3]).astype(float)\n        for window in [60, 120]:\n            if len(speed_states) >= window:\n                for state in [0, 1, 2, 3]:\n                    X[f's{state}_{window}'] = (speed_states == state).astype(float).rolling(window, min_periods=10).mean()\n                state_changes = (speed_states != speed_states.shift(1)).astype(float)\n                X[f'trans_{window}'] = state_changes.rolling(window, min_periods=10).sum()\n    except:\n        pass\n    return X\n\ndef add_longrange_features(X, center_x, center_y):\n    for window in [120, 240]:\n        if len(center_x) >= window:\n            X[f'x_ml{window}'] = center_x.rolling(window, min_periods=20).mean()\n            X[f'y_ml{window}'] = center_y.rolling(window, min_periods=20).mean()\n    for span in [60, 120]:\n        X[f'x_e{span}'] = center_x.ewm(span=span, min_periods=1).mean()\n        X[f'y_e{span}'] = center_y.ewm(span=span, min_periods=1).mean()\n    speed = np.sqrt(center_x.diff()**2 + center_y.diff()**2)\n    for window in [60, 120]:\n        if len(speed) >= window:\n            X[f'sp_pct{window}'] = speed.rolling(window, min_periods=20).rank(pct=True)\n    return X\n\ndef add_interaction_features(X, mouse_pair, avail_A, avail_B):\n    if 'body_center' not in avail_A or 'body_center' not in avail_B:\n        return X\n    rel_x = mouse_pair['A']['body_center']['x'] - mouse_pair['B']['body_center']['x']\n    rel_y = mouse_pair['A']['body_center']['y'] - mouse_pair['B']['body_center']['y']\n    rel_dist = np.sqrt(rel_x**2 + rel_y**2)\n    A_vx = mouse_pair['A']['body_center']['x'].diff()\n    A_vy = mouse_pair['A']['body_center']['y'].diff()\n    B_vx = mouse_pair['B']['body_center']['x'].diff()\n    B_vy = mouse_pair['B']['body_center']['y'].diff()\n    A_lead = (A_vx * rel_x + A_vy * rel_y) / (np.sqrt(A_vx**2 + A_vy**2) * rel_dist + 1e-6)\n    B_lead = (B_vx * (-rel_x) + B_vy * (-rel_y)) / (np.sqrt(B_vx**2 + B_vy**2) * rel_dist + 1e-6)\n    for window in [30, 60]:\n        X[f'A_ld{window}'] = A_lead.rolling(window, min_periods=5).mean()\n        X[f'B_ld{window}'] = B_lead.rolling(window, min_periods=5).mean()\n    approach = -rel_dist.diff()\n    chase = approach * B_lead\n    X['chase_30'] = chase.rolling(30, min_periods=5).mean()\n    for window in [60, 120]:\n        A_sp = np.sqrt(A_vx**2 + A_vy**2)\n        B_sp = np.sqrt(B_vx**2 + B_vy**2)\n        X[f'sp_cor{window}'] = A_sp.rolling(window, min_periods=10).corr(B_sp)\n    return X\n\ndef transform_single(single_mouse, body_parts_tracked, pvid=None, mouse_id=None):\n    available_body_parts = single_mouse.columns.get_level_values(0)\n    X = pd.DataFrame({\n        f\"{p1}+{p2}\": np.square(single_mouse[p1] - single_mouse[p2]).sum(axis=1, skipna=False)\n        for p1, p2 in itertools.combinations(body_parts_tracked, 2) \n        if p1 in available_body_parts and p2 in available_body_parts\n    })\n    X = X.reindex(columns=[f\"{p1}+{p2}\" for p1, p2 in itertools.combinations(body_parts_tracked, 2)], copy=False)\n\n    if all(p in single_mouse.columns for p in ['ear_left', 'ear_right', 'tail_base']):\n        shifted = single_mouse[['ear_left', 'ear_right', 'tail_base']].shift(10)\n        speeds = pd.DataFrame({\n            'sp_lf': np.square(single_mouse['ear_left'] - shifted['ear_left']).sum(axis=1, skipna=False),\n            'sp_rt': np.square(single_mouse['ear_right'] - shifted['ear_right']).sum(axis=1, skipna=False),\n            'sp_lf2': np.square(single_mouse['ear_left'] - shifted['tail_base']).sum(axis=1, skipna=False),\n            'sp_rt2': np.square(single_mouse['ear_right'] - shifted['tail_base']).sum(axis=1, skipna=False),\n        })\n        X = pd.concat([X, speeds], axis=1)\n    \n    if 'nose+tail_base' in X.columns and 'ear_left+ear_right' in X.columns:\n        X['elong'] = X['nose+tail_base'] / (X['ear_left+ear_right'] + 1e-6)\n    \n    if all(p in available_body_parts for p in ['nose', 'body_center', 'tail_base']):\n        v1 = single_mouse['nose'] - single_mouse['body_center']\n        v2 = single_mouse['tail_base'] - single_mouse['body_center']\n        X['body_ang'] = (v1['x'] * v2['x'] + v1['y'] * v2['y']) / (\n            np.sqrt(v1['x']**2 + v1['y']**2) * np.sqrt(v2['x']**2 + v2['y']**2) + 1e-6)\n    \n    if 'body_center' in available_body_parts:\n        cx = single_mouse['body_center']['x']\n        cy = single_mouse['body_center']['y']\n        \n        for w in [5, 15, 30, 60]:\n            X[f'cx_m{w}'] = cx.rolling(w, min_periods=1, center=True).mean()\n            X[f'cy_m{w}'] = cy.rolling(w, min_periods=1, center=True).mean()\n            X[f'cx_s{w}'] = cx.rolling(w, min_periods=1, center=True).std()\n            X[f'cy_s{w}'] = cy.rolling(w, min_periods=1, center=True).std()\n            X[f'x_rng{w}'] = cx.rolling(w, min_periods=1, center=True).max() - cx.rolling(w, min_periods=1, center=True).min()\n            X[f'y_rng{w}'] = cy.rolling(w, min_periods=1, center=True).max() - cy.rolling(w, min_periods=1, center=True).min()\n            X[f'disp{w}'] = np.sqrt(cx.diff().rolling(w, min_periods=1).sum()**2 + cy.diff().rolling(w, min_periods=1).sum()**2)\n            X[f'act{w}'] = np.sqrt(cx.diff().rolling(w, min_periods=1).var() + cy.diff().rolling(w, min_periods=1).var())\n        \n        X = add_curvature_features(X, cx, cy)\n        X = add_multiscale_features(X, cx, cy)\n        X = add_state_features(X, cx, cy)\n        X = add_longrange_features(X, cx, cy)\n        \n        # NEW: Add spatial history features\n        if pvid is not None:\n            X = add_spatial_history_features(X, cx, cy, pvid, current_mouse_id=mouse_id)\n        \n        speed = np.sqrt(cx.diff()**2 + cy.diff()**2)\n        high_speed_threshold = speed.quantile(0.75)\n        recent_high_activity = (speed > high_speed_threshold).astype(float).rolling(100, min_periods=1).max()\n        X['recent_active_100'] = recent_high_activity\n        \n        angle = np.arctan2(cy.diff(), cx.diff())\n        angle_diff = angle.diff()\n        angle_diff_wrapped = np.arctan2(np.sin(angle_diff), np.cos(angle_diff))\n        significant_turn = (np.abs(angle_diff_wrapped) > 0.5).astype(float)\n        turn_count_200 = significant_turn.rolling(200, min_periods=1).sum()\n        X['turn_count_200'] = turn_count_200\n        \n        high_speed_events = (speed > high_speed_threshold).astype(float)\n        event_indices = pd.Series(np.arange(len(speed)), index=speed.index)\n        event_indices = event_indices.where(high_speed_events == 1).ffill().fillna(-500)\n        current_indices = pd.Series(np.arange(len(speed)), index=speed.index)\n        frames_since_active = (current_indices - event_indices).clip(lower=0, upper=500)\n        X['frames_since_active'] = frames_since_active\n    \n    if all(p in available_body_parts for p in ['nose', 'tail_base']):\n        nt_dist = np.sqrt((single_mouse['nose']['x'] - single_mouse['tail_base']['x'])**2 + \n                         (single_mouse['nose']['y'] - single_mouse['tail_base']['y'])**2)\n        for lag in [10, 20, 40]:\n            X[f'nt_lg{lag}'] = nt_dist.shift(lag)\n            X[f'nt_df{lag}'] = nt_dist - nt_dist.shift(lag)\n    \n    if all(p in available_body_parts for p in ['ear_left', 'ear_right']):\n        ear_d = np.sqrt((single_mouse['ear_left']['x'] - single_mouse['ear_right']['x'])**2 + \n                       (single_mouse['ear_left']['y'] - single_mouse['ear_right']['y'])**2)\n        for off in [-20, -10, 10, 20]:\n            X[f'ear_o{off}'] = ear_d.shift(-off)\n        X['ear_con'] = ear_d.rolling(30, min_periods=1, center=True).std() / (ear_d.rolling(30, min_periods=1, center=True).mean() + 1e-6)\n    \n    return X\n\ndef transform_pair(mouse_pair, body_parts_tracked, pvid=None, agent_id=None):\n    avail_A = mouse_pair['A'].columns.get_level_values(0)\n    avail_B = mouse_pair['B'].columns.get_level_values(0)\n    \n    X = pd.DataFrame({\n        f\"12+{p1}+{p2}\": np.square(mouse_pair['A'][p1] - mouse_pair['B'][p2]).sum(axis=1, skipna=False)\n        for p1, p2 in itertools.product(body_parts_tracked, repeat=2) \n        if p1 in avail_A and p2 in avail_B\n    })\n    X = X.reindex(columns=[f\"12+{p1}+{p2}\" for p1, p2 in itertools.product(body_parts_tracked, repeat=2)], copy=False)\n\n    if ('A', 'ear_left') in mouse_pair.columns and ('B', 'ear_left') in mouse_pair.columns:\n        shA = mouse_pair['A']['ear_left'].shift(10)\n        shB = mouse_pair['B']['ear_left'].shift(10)\n        speeds = pd.DataFrame({\n            'sp_A': np.square(mouse_pair['A']['ear_left'] - shA).sum(axis=1, skipna=False),\n            'sp_AB': np.square(mouse_pair['A']['ear_left'] - shB).sum(axis=1, skipna=False),\n            'sp_B': np.square(mouse_pair['B']['ear_left'] - shB).sum(axis=1, skipna=False),\n        })\n        X = pd.concat([X, speeds], axis=1)\n    \n    if 'nose+tail_base' in X.columns and 'ear_left+ear_right' in X.columns:\n        X['elong'] = X['nose+tail_base'] / (X['ear_left+ear_right'] + 1e-6)\n    \n    if all(p in avail_A for p in ['nose', 'tail_base']) and all(p in avail_B for p in ['nose', 'tail_base']):\n        dir_A = mouse_pair['A']['nose'] - mouse_pair['A']['tail_base']\n        dir_B = mouse_pair['B']['nose'] - mouse_pair['B']['tail_base']\n        X['rel_ori'] = (dir_A['x'] * dir_B['x'] + dir_A['y'] * dir_B['y']) / (\n            np.sqrt(dir_A['x']**2 + dir_A['y']**2) * np.sqrt(dir_B['x']**2 + dir_B['y']**2) + 1e-6)\n    \n    if all(p in avail_A for p in ['nose']) and all(p in avail_B for p in ['nose']):\n        cur = np.square(mouse_pair['A']['nose'] - mouse_pair['B']['nose']).sum(axis=1, skipna=False)\n        shA_n = mouse_pair['A']['nose'].shift(10)\n        shB_n = mouse_pair['B']['nose'].shift(10)\n        past = np.square(shA_n - shB_n).sum(axis=1, skipna=False)\n        X['appr'] = cur - past\n    \n    if 'body_center' in avail_A and 'body_center' in avail_B:\n        cd = np.sqrt((mouse_pair['A']['body_center']['x'] - mouse_pair['B']['body_center']['x'])**2 +\n                    (mouse_pair['A']['body_center']['y'] - mouse_pair['B']['body_center']['y'])**2)\n        X['v_cls'] = (cd < 5.0).astype(float)\n        X['cls'] = ((cd >= 5.0) & (cd < 15.0)).astype(float)\n        X['med'] = ((cd >= 15.0) & (cd < 30.0)).astype(float)\n        X['far'] = (cd >= 30.0).astype(float)\n    \n    if 'body_center' in avail_A and 'body_center' in avail_B:\n        cd_full = np.square(mouse_pair['A']['body_center'] - mouse_pair['B']['body_center']).sum(axis=1, skipna=False)\n        \n        for w in [5, 15, 30, 60]:\n            X[f'd_m{w}'] = cd_full.rolling(w, min_periods=1, center=True).mean()\n            X[f'd_s{w}'] = cd_full.rolling(w, min_periods=1, center=True).std()\n            X[f'd_mn{w}'] = cd_full.rolling(w, min_periods=1, center=True).min()\n            X[f'd_mx{w}'] = cd_full.rolling(w, min_periods=1, center=True).max()\n            \n            d_var = cd_full.rolling(w, min_periods=1, center=True).var()\n            X[f'int{w}'] = 1 / (1 + d_var)\n            \n            Axd = mouse_pair['A']['body_center']['x'].diff()\n            Ayd = mouse_pair['A']['body_center']['y'].diff()\n            Bxd = mouse_pair['B']['body_center']['x'].diff()\n            Byd = mouse_pair['B']['body_center']['y'].diff()\n            coord = Axd * Bxd + Ayd * Byd\n            X[f'co_m{w}'] = coord.rolling(w, min_periods=1, center=True).mean()\n            X[f'co_s{w}'] = coord.rolling(w, min_periods=1, center=True).std()\n        \n        # NEW: Add spatial history features for agent mouse in pair context\n        if pvid is not None and agent_id is not None:\n            cx = mouse_pair['A']['body_center']['x']\n            cy = mouse_pair['A']['body_center']['y']\n            X = add_spatial_history_features(X, cx, cy, pvid, current_mouse_id=agent_id)\n        \n        close_proximity = (cd < 10.0).astype(float)\n        recent_close = close_proximity.rolling(100, min_periods=1).max()\n        X['recent_close_100'] = recent_close\n        \n        dist_change = cd.diff()\n        approach_event = (dist_change < -0.5).astype(float)\n        avoid_event = (dist_change > 0.5).astype(float)\n        interaction_change = (approach_event.diff().abs() + avoid_event.diff().abs()).clip(upper=1)\n        cycle_count_200 = interaction_change.rolling(200, min_periods=1).sum()\n        X['cycle_count_200'] = cycle_count_200\n        \n        close_events = (cd < 15.0).astype(float)\n        event_indices = pd.Series(np.arange(len(cd)), index=cd.index)\n        event_indices = event_indices.where(close_events == 1).ffill().fillna(-500)\n        current_indices = pd.Series(np.arange(len(cd)), index=cd.index)\n        frames_since_close = (current_indices - event_indices).clip(lower=0, upper=500)\n        X['frames_since_close'] = frames_since_close\n    \n    if 'nose' in avail_A and 'nose' in avail_B:\n        nn = np.sqrt((mouse_pair['A']['nose']['x'] - mouse_pair['B']['nose']['x'])**2 +\n                    (mouse_pair['A']['nose']['y'] - mouse_pair['B']['nose']['y'])**2)\n        for lag in [10, 20, 40]:\n            X[f'nn_lg{lag}'] = nn.shift(lag)\n            X[f'nn_ch{lag}'] = nn - nn.shift(lag)\n            is_cl = (nn < 10.0).astype(float)\n            X[f'cl_ps{lag}'] = is_cl.rolling(lag, min_periods=1).mean()\n    \n    if 'body_center' in avail_A and 'body_center' in avail_B:\n        Avx = mouse_pair['A']['body_center']['x'].diff()\n        Avy = mouse_pair['A']['body_center']['y'].diff()\n        Bvx = mouse_pair['B']['body_center']['x'].diff()\n        Bvy = mouse_pair['B']['body_center']['y'].diff()\n        val = (Avx * Bvx + Avy * Bvy) / (np.sqrt(Avx**2 + Avy**2) * np.sqrt(Bvx**2 + Bvy**2) + 1e-6)\n        \n        for off in [-20, -10, 0, 10, 20]:\n            X[f'va_{off}'] = val.shift(-off)\n        \n        X['int_con'] = cd_full.rolling(30, min_periods=1, center=True).std() / (cd_full.rolling(30, min_periods=1, center=True).mean() + 1e-6)\n        \n        X = add_interaction_features(X, mouse_pair, avail_A, avail_B)\n    \n    return X\n\n# ==================== ENSEMBLE TRAINING ====================\n\ndef submit_ensemble(body_parts_tracked_str, switch_tr, X_tr, label, meta):\n    models = []\n    \n    models.append(make_pipeline(\n        SimpleImputer(),\n        StratifiedSubsetClassifier(\n            lightgbm.LGBMClassifier(\n                n_estimators=225, learning_rate=0.07, min_child_samples=40,\n                num_leaves=31, subsample=0.8, colsample_bytree=0.8, verbose=-1),\n            100000)\n    ))\n    \n    models.append(make_pipeline(\n        SimpleImputer(),\n        StratifiedSubsetClassifier(\n            lightgbm.LGBMClassifier(\n                n_estimators=150, learning_rate=0.1, min_child_samples=20,\n                num_leaves=63, max_depth=8, subsample=0.7, colsample_bytree=0.9,\n                reg_alpha=0.1, reg_lambda=0.1, verbose=-1),\n            80000)\n    ))\n    \n    models.append(make_pipeline(\n        SimpleImputer(),\n        StratifiedSubsetClassifier(\n            lightgbm.LGBMClassifier(\n                n_estimators=100, learning_rate=0.05, min_child_samples=30,\n                num_leaves=127, max_depth=10, subsample=0.75, verbose=-1),\n            60000)\n    ))\n    \n    if XGBOOST_AVAILABLE:\n        models.append(make_pipeline(\n            SimpleImputer(),\n            StratifiedSubsetClassifier(\n                XGBClassifier(\n                    n_estimators=180, learning_rate=0.08, max_depth=6,\n                    min_child_weight=5, subsample=0.8, colsample_bytree=0.8,\n                    tree_method='hist', verbosity=0),\n                85000)\n        ))\n    \n    if CATBOOST_AVAILABLE:\n        models.append(make_pipeline(\n            SimpleImputer(),\n            StratifiedSubsetClassifier(\n                CatBoostClassifier(\n                    iterations=120, learning_rate=0.1, depth=6,\n                    verbose=False, allow_writing_files=False),\n                70000)\n        ))\n    \n    if GANDALF_AVAILABLE:\n        models.append(make_pipeline(\n            SimpleImputer(),\n            StratifiedSubsetClassifier(\n                GANDALF(\n                    n_estimators=150,\n                    learning_rate=0.01,\n                    max_depth=6,\n                    dropout=0.1,\n                    random_state=42\n                ),\n                75000)\n        ))\n    \n    model_list = []\n    for action in label.columns:\n        action_mask = ~ label[action].isna().values\n        y_action = label[action][action_mask].values.astype(int)\n\n        if not (y_action == 0).all() and y_action.sum() >= 5:\n            trained = []\n            for m in models:\n                m_clone = clone(m)\n                m_clone.fit(X_tr[action_mask], y_action)\n                trained.append(m_clone)\n            model_list.append((action, trained))\n    \n    del X_tr\n    gc.collect()\n\n    body_parts_tracked = json.loads(body_parts_tracked_str)\n    if len(body_parts_tracked) > 5:\n        body_parts_tracked = [b for b in body_parts_tracked if b not in drop_body_parts]\n    \n    test_subset = test[test.body_parts_tracked == body_parts_tracked_str]\n    generator = generate_mouse_data(test_subset, 'test',\n                                    generate_single=(switch_tr == 'single'), \n                                    generate_pair=(switch_tr == 'pair'))\n    \n    if verbose: print(f\"n_videos: {len(test_subset)}, n_models: {len(models)}\")\n    \n    for result in generator:\n        switch_te, data_te, meta_te, actions_te, pvid_te = result\n        assert switch_te == switch_tr\n        try:\n            if switch_te == 'single':\n                # Extract mouse_id from meta\n                mouse_id_str = meta_te['agent_id'].iloc[0] if len(meta_te) > 0 else None\n                mouse_id = int(mouse_id_str[-1]) if mouse_id_str else None\n                X_te = transform_single(data_te, body_parts_tracked, pvid=pvid_te, mouse_id=mouse_id)\n            else:\n                # Extract agent_id for pair\n                agent_id_str = meta_te['agent_id'].iloc[0] if len(meta_te) > 0 else None\n                agent_id = int(agent_id_str[-1]) if agent_id_str else None\n                X_te = transform_pair(data_te, body_parts_tracked, pvid=pvid_te, agent_id=agent_id)\n            \n            if verbose and len(X_te) == 0: print(\"ERROR: X_te empty\")\n            del data_te\n            del pvid_te\n    \n            pred = pd.DataFrame(index=meta_te.video_frame)\n            for action, trained in model_list:\n                if action in actions_te:\n                    probs = [m.predict_proba(X_te)[:, 1] for m in trained]\n                    pred[action] = np.mean(probs, axis=0)\n            \n            del X_te\n            gc.collect()\n            \n            if pred.shape[1] != 0:\n                sub_part = predict_multiclass_adaptive(pred, meta_te, action_thresholds)\n                submission_list.append(sub_part)\n            else:\n                if verbose: print(f\"  ERROR: no training data\")\n        except Exception as e:\n            if verbose: print(f'  ERROR: {str(e)[:50]}')\n            try:\n                del data_te\n            except:\n                pass\n            try:\n                del pvid_te\n            except:\n                pass\n            gc.collect()\n\ndef robustify(submission, dataset, traintest, traintest_directory=None):\n    if traintest_directory is None:\n        traintest_directory = f\"/kaggle/input/MABe-mouse-behavior-detection/{traintest}_tracking\"\n\n    submission = submission[submission.start_frame < submission.stop_frame]\n    \n    group_list = []\n    for _, group in submission.groupby(['video_id', 'agent_id', 'target_id']):\n        group = group.sort_values('start_frame')\n        mask = np.ones(len(group), dtype=bool)\n        last_stop = 0\n        for i, (_, row) in enumerate(group.iterrows()):\n            if row['start_frame'] < last_stop:\n                mask[i] = False\n            else:\n                last_stop = row['stop_frame']\n        group_list.append(group[mask])\n    submission = pd.concat(group_list) if group_list else submission\n\n    s_list = []\n    for idx, row in dataset.iterrows():\n        lab_id = row['lab_id']\n        if lab_id.startswith('MABe22'):\n            continue\n        video_id = row['video_id']\n        if (submission.video_id == video_id).any():\n            continue\n\n        if verbose: print(f\"Video {video_id} has no predictions\")\n        \n        path = f\"{traintest_directory}/{lab_id}/{video_id}.parquet\"\n        vid = pd.read_parquet(path)\n    \n        vid_behaviors = eval(row['behaviors_labeled'])\n        vid_behaviors = sorted(list({b.replace(\"'\", \"\") for b in vid_behaviors}))\n        vid_behaviors = [b.split(',') for b in vid_behaviors]\n        vid_behaviors = pd.DataFrame(vid_behaviors, columns=['agent', 'target', 'action'])\n    \n        start_frame = vid.video_frame.min()\n        stop_frame = vid.video_frame.max() + 1\n    \n        for (agent, target), actions in vid_behaviors.groupby(['agent', 'target']):\n            batch_len = int(np.ceil((stop_frame - start_frame) / len(actions)))\n            for i, (_, action_row) in enumerate(actions.iterrows()):\n                batch_start = start_frame + i * batch_len\n                batch_stop = min(batch_start + batch_len, stop_frame)\n                s_list.append((video_id, agent, target, action_row['action'], batch_start, batch_stop))\n\n    if len(s_list) > 0:\n        submission = pd.concat([\n            submission,\n            pd.DataFrame(s_list, columns=['video_id', 'agent_id', 'target_id', 'action', 'start_frame', 'stop_frame'])\n        ])\n\n    submission = submission.reset_index(drop=True)\n    return submission\n\n# ==================== MAIN LOOP ====================\n\nsubmission_list = []\nsection_results = {}\n\nprint(f\"\\n🤖 Models: XGBoost={XGBOOST_AVAILABLE}, CatBoost={CATBOOST_AVAILABLE}, GANDALF={GANDALF_AVAILABLE}\\n\")\nprint(\"=\"*80)\nprint(\"TRAINING MODELS\")\nprint(\"=\"*80)\n\nfirst_single_viz = True\nfirst_pair_viz = True\n\nfor section in range(1, len(body_parts_tracked_list)):\n    body_parts_tracked_str = body_parts_tracked_list[section]\n    section_results[section] = {'predictions': 0, 'models': 0, 'single_features': 0, 'pair_features': 0}\n    \n    try:\n        body_parts_tracked = json.loads(body_parts_tracked_str)\n        print(f\"\\n{section}. Processing: {len(body_parts_tracked)} body parts\")\n        if len(body_parts_tracked) > 5:\n            body_parts_tracked = [b for b in body_parts_tracked if b not in drop_body_parts]\n    \n        train_subset = train[train.body_parts_tracked == body_parts_tracked_str]\n        single_list, single_label_list, single_meta_list = [], [], []\n        pair_list, pair_label_list, pair_meta_list = [], [], []\n    \n        for result in generate_mouse_data(train_subset, 'train'):\n            switch, data, meta, label, pvid = result\n            if switch == 'single':\n                single_list.append(data)\n                single_meta_list.append(meta)\n                single_label_list.append(label)\n            else:\n                pair_list.append(data)\n                pair_meta_list.append(meta)\n                pair_label_list.append(label)\n    \n        if len(single_list) > 0:\n            single_mouse = pd.concat(single_list)\n            single_label = pd.concat(single_label_list)\n            single_meta = pd.concat(single_meta_list)\n            del single_list, single_label_list, single_meta_list\n            gc.collect()\n            \n            # Use first pvid for spatial features\n            first_pvid = None\n            for result in generate_mouse_data(train_subset, 'train', generate_pair=False):\n                _, _, _, _, first_pvid = result\n                break\n            \n            mouse_id_sample = int(single_meta['agent_id'].iloc[0][-1]) if len(single_meta) > 0 else None\n            X_tr = transform_single(single_mouse, body_parts_tracked, pvid=first_pvid, mouse_id=mouse_id_sample)\n            del single_mouse\n            print(f\"  Single: {X_tr.shape}\")\n            section_results[section]['single_features'] = X_tr.shape[1]\n            \n            if first_single_viz and section == 1:\n                plot_feature_analysis(X_tr, 'single')\n                plot_feature_correlation_heatmap(X_tr, 'single')\n                plot_temporal_patterns_detailed(X_tr, 'single')\n                first_single_viz = False\n            \n            submit_ensemble(body_parts_tracked_str, 'single', X_tr, single_label, single_meta)\n                \n        if len(pair_list) > 0:\n            mouse_pair = pd.concat(pair_list)\n            pair_label = pd.concat(pair_label_list)\n            pair_meta = pd.concat(pair_meta_list)\n            del pair_list, pair_label_list, pair_meta_list\n            gc.collect()\n        \n            # Use first pvid for spatial features\n            first_pvid = None\n            for result in generate_mouse_data(train_subset, 'train', generate_single=False):\n                _, _, _, _, first_pvid = result\n                break\n            \n            agent_id_sample = int(pair_meta['agent_id'].iloc[0][-1]) if len(pair_meta) > 0 else None\n            X_tr = transform_pair(mouse_pair, body_parts_tracked, pvid=first_pvid, agent_id=agent_id_sample)\n            del mouse_pair\n            print(f\"  Pair: {X_tr.shape}\")\n            section_results[section]['pair_features'] = X_tr.shape[1]\n            \n            if first_pair_viz and section == 1:\n                plot_feature_analysis(X_tr, 'pair')\n                plot_feature_correlation_heatmap(X_tr, 'pair')\n                plot_temporal_patterns_detailed(X_tr, 'pair')\n                first_pair_viz = False\n            \n            submit_ensemble(body_parts_tracked_str, 'pair', X_tr, pair_label, pair_meta)\n        \n        if len(submission_list) > 0:\n            section_results[section]['predictions'] = len(submission_list[-1]) if submission_list else 0\n            section_results[section]['models'] = 5\n                \n    except Exception as e:\n        print(f'***Exception*** {str(e)[:100]}')\n    \n    gc.collect()\n\nprint(\"\\n\" + \"=\"*80)\nprint(\"FINALIZING SUBMISSION\")\nprint(\"=\"*80)\n\nif len(submission_list) > 0:\n    submission = pd.concat(submission_list)\nelse:\n    submission = pd.DataFrame({\n        'video_id': [438887472],\n        'agent_id': ['mouse1'],\n        'target_id': ['self'],\n        'action': ['rear'],\n        'start_frame': [278],\n        'stop_frame': [500]\n    })\n\nsubmission_robust = robustify(submission, test, 'test')\nsubmission_robust.index.name = 'row_id'\nsubmission_robust.to_csv('submission.csv')\nprint(f\"\\n✅ Submission created: {len(submission_robust)} predictions\")\n\nprint(\"\\n\" + \"=\"*80)\nprint(\"GENERATING FINAL VISUALIZATIONS\")\nprint(\"=\"*80)\n\nplot_training_progress_detailed(section_results)\nplot_comprehensive_submission_analysis(submission_robust, train)\nplot_action_distribution_comparison(submission_robust, train)\nplot_model_ensemble_analysis(submission_robust)\n\nprint(\"\\n\" + \"=\"*80)\nprint(\"ALL VISUALIZATIONS COMPLETED\")\nprint(\"=\"*80)\nprint(\"\\n📊 Visualization files:\")\nviz_files = sorted([f for f in os.listdir('/kaggle/working/visualizations') if f.endswith('.png')])\nfor i, f in enumerate(viz_files, 1):\n    print(f\"   {i:2d}. {f}\")\n\nprint(\"\\n\" + \"=\"*80)\nprint(\"COMPETITION COMPLETE!\")\nprint(\"=\"*80)\nprint(f\"✅ Submission: submission.csv ({len(submission_robust):,} predictions)\")\nprint(f\"📊 Visualizations: {len(viz_files)} publication-quality figures\")\nprint(f\"🆕 NEW FEATURES: Spatial history features added!\")\nprint(\"   - self_loc_revisit_5cm: Mouse in previously visited location\")\nprint(\"   - other_loc_visit_5cm: Mouse in location where other mice were\")\nprint(\"   - self_loc_revisit_pct60: Smoothed percentage version\")\nprint(\"   - other_loc_visit_pct60: Smoothed percentage version\")\nprint(\"=\"*80)","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}