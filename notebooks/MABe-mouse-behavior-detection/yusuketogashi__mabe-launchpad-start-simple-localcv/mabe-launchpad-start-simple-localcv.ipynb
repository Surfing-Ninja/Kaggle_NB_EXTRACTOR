{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":59156,"databundleVersionId":13719397,"sourceType":"competition"}],"dockerImageVersionId":31089,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#!/usr/bin/env python3\n# MABe: Rule-based baseline+++ (Priors + Windows + Timing + Opportunity + Dilation + Deconflict + Fallback)\n# - Kaggle-ready: submission.csv\n# - LocalCV: GroupKFold over valid videos\n# - Key fixes:\n#   * Exclude only \"MABe22_\" labs (duplicates)\n#   * Fallback: ensure >=1 segment per (video, agent, target) when allowed_total>0\n#   * Scorer uses safe_json_loads() for active labels\n\nimport os, json, warnings\nfrom pathlib import Path\nfrom typing import Dict, List, Tuple, Optional, Set\nfrom collections import defaultdict\n\nimport numpy as np\nimport polars as pl\nfrom tqdm.auto import tqdm\n\nwarnings.filterwarnings(\"ignore\")\n\n# ========================\n# User knobs\n# ========================\nDO_CV        = True\nDO_SUBMIT    = True\nN_SPLITS     = 5\nBETA         = 1.0\nMAX_VIDEOS_PER_FOLD = 100   # None for all; 80-120で安定&高速化\n\n# Stable params (≈0.12狙いの安定域)\nEXCLUDE_PREFIXES = (\"MABe22_\",)  # ← 重要: 重複ラボのみ除外\nLAPLACE_EPS      = 20.0\nMIN_LEN          = 10\nGAP_CLOSE        = 8\nRARE_P_MIN       = 0.02\nRARE_CAP         = 0.05\nUSE_WINDOWS      = True\nOPP_GAMMA        = 0.60          # opp reweight for sniff/chase/follow\nDILATE_BY        = 4\n\n# ========================\n# Config & schemas\n# ========================\nclass Config:\n    def __init__(self,\n                 data_root: Path = Path(\"/kaggle/input/MABe-mouse-behavior-detection\"),\n                 submission_file: str = \"submission.csv\"):\n        self.data_root = data_root\n        self.submission_file = submission_file\n        self.train_csv = self.data_root / \"train.csv\"\n        self.test_csv  = self.data_root / \"test.csv\"\n        self.train_annot_dir = self.data_root / \"train_annotation\"\n        self.train_track_dir = self.data_root / \"train_tracking\"\n        self.test_track_dir  = self.data_root / \"test_tracking\"\n        self.solution_schema = {\n            \"video_id\": pl.Int64, \"agent_id\": pl.Utf8, \"target_id\": pl.Utf8,\n            \"action\": pl.Utf8, \"start_frame\": pl.Int64, \"stop_frame\": pl.Int64,\n            \"lab_id\": pl.Utf8, \"behaviors_labeled\": pl.Utf8,\n        }\n        self.submission_schema = {\n            \"video_id\": pl.Int64, \"agent_id\": pl.Utf8, \"target_id\": pl.Utf8,\n            \"action\": pl.Utf8, \"start_frame\": pl.Int64, \"stop_frame\": pl.Int64,\n        }\n\ncfg = Config()\n\n# ========================\n# Utils\n# ========================\ndef is_excluded_lab(lab: str) -> bool:\n    return any(lab.startswith(p) for p in EXCLUDE_PREFIXES)\n\ndef safe_json_loads(s) -> List[str]:\n    if s is None: return []\n    if isinstance(s, list): return [str(x) for x in s]\n    if not isinstance(s, str): return []\n    t = s.strip()\n    if not t: return []\n    try:\n        arr = json.loads(t)\n        return [str(x) for x in arr] if isinstance(arr, list) else []\n    except Exception:\n        try:\n            arr = json.loads(t.replace(\"'\", '\"'))\n            return [str(x) for x in arr] if isinstance(arr, list) else []\n        except Exception:\n            return []\n\ndef _norm_mouse(x) -> str:\n    s = str(x)\n    return s if s.startswith(\"mouse\") else f\"mouse{s}\"\n\ndef _strip_mouse(s) -> str:\n    s=str(s); return s[5:] if s.startswith(\"mouse\") else s\n\ndef validate_schema(df: pl.DataFrame, schema: Dict[str, pl.DataType], name: str) -> pl.DataFrame:\n    for col, dtype in schema.items():\n        if col not in df.columns:\n            df = df.with_columns(pl.lit(None).cast(dtype).alias(col))\n    casts = [pl.col(col).cast(dtype) for col, dtype in schema.items() if df[col].dtype != dtype]\n    if casts: df = df.with_columns(casts)\n    return df\n\n# ========================\n# Solution & spans\n# ========================\ndef create_solution_df(meta: pl.DataFrame, cfg: Config) -> pl.DataFrame:\n    recs: List[pl.DataFrame] = []\n\n    def _pack(annot: pl.DataFrame, lab: str, vid: int, bl: str) -> pl.DataFrame:\n        a = annot\n        if \"agent_id\" in a.columns:\n            a = a.with_columns(pl.concat_str([pl.lit(\"mouse\"), pl.col(\"agent_id\").cast(pl.Utf8)]).alias(\"agent_id\"))\n        if \"target_id\" in a.columns:\n            a = a.with_columns(pl.concat_str([pl.lit(\"mouse\"), pl.col(\"target_id\").cast(pl.Utf8)]).alias(\"target_id\"))\n        a = a.with_columns(\n            pl.lit(lab).alias(\"lab_id\"),\n            pl.lit(int(vid)).alias(\"video_id\"),\n            pl.lit(bl if isinstance(bl, str) else json.dumps(bl)).alias(\"behaviors_labeled\"),\n        )\n        a = a.select([c for c in [\"video_id\",\"agent_id\",\"target_id\",\"action\",\"start_frame\",\"stop_frame\",\"lab_id\",\"behaviors_labeled\"] if c in a.columns])\n        a = validate_schema(a, cfg.solution_schema, \"Solution(part)\")\n        return a\n\n    for row in meta.to_dicts():\n        lab = str(row[\"lab_id\"])\n        if is_excluded_lab(lab): \n            continue\n        vid = int(row[\"video_id\"])\n        p = cfg.train_annot_dir / lab / f\"{vid}.parquet\"\n        if not p.exists(): \n            continue\n        try:\n            annot = pl.read_parquet(p)\n            recs.append(_pack(annot, lab, vid, row.get(\"behaviors_labeled\",\"\")))\n        except Exception:\n            continue\n\n    if not recs:\n        raise ValueError(\"No annotations loaded (check dataset paths).\")\n    sol = pl.concat(recs, how=\"vertical\", parallel=True, rechunk=True)\n    sol = validate_schema(sol, cfg.solution_schema, \"Solution\")\n    if not (sol[\"start_frame\"] <= sol[\"stop_frame\"]).all():\n        raise ValueError(\"start_frame > stop_frame exists.\")\n    return sol\n\ndef build_spans(meta: pl.DataFrame, split: str, cfg: Config) -> Dict[int, Tuple[int,int]]:\n    track_dir = cfg.train_track_dir if split==\"train\" else cfg.test_track_dir\n    out: Dict[int, Tuple[int,int]] = {}\n    for r in meta.to_dicts():\n        lab = str(r[\"lab_id\"])\n        if is_excluded_lab(lab): \n            continue\n        vid = int(r[\"video_id\"])\n        p = track_dir / lab / f\"{vid}.parquet\"\n        if not p.exists(): continue\n        try:\n            df = pl.read_parquet(p)\n            frame_col = next((c for c in [\"video_frame\",\"frame\",\"frame_idx\"] if c in df.columns), None)\n            if frame_col is None: \n                continue\n            s = int(df[frame_col].min()); e = int(df[frame_col].max()) + 1\n            if e > s:\n                out[vid] = (s,e)\n        except Exception:\n            continue\n    return out\n\n# ========================\n# Priors & timing\n# ========================\ndef compute_action_priors(solution: pl.DataFrame, eps: float = LAPLACE_EPS):\n    sol = solution.with_columns((pl.col(\"stop_frame\") - pl.col(\"start_frame\")).alias(\"dur\"))\n    by_lab = sol.group_by([\"lab_id\",\"action\"]).agg(pl.col(\"dur\").sum().alias(\"dur_sum\"))\n    global_ = sol.group_by([\"action\"]).agg(pl.col(\"dur\").sum().alias(\"dur_sum\"))\n\n    actions = set(global_[\"action\"].to_list())\n\n    per_lab_weight: Dict[str, Dict[str, float]] = defaultdict(dict)\n    for lab in by_lab[\"lab_id\"].unique().to_list():\n        sub = by_lab.filter(pl.col(\"lab_id\")==lab)\n        m = {r[\"action\"]: float(r[\"dur_sum\"]) for r in sub.to_dicts()}\n        for a in actions: m[a] = m.get(a, 0.0) + eps\n        tot = sum(m.values()) or 1.0\n        per_lab_weight[str(lab)] = {a: m[a]/tot for a in actions}\n\n    gm = {r[\"action\"]: float(r[\"dur_sum\"]) for r in global_.to_dicts()}\n    for a in actions: gm[a] = gm.get(a, 0.0) + eps\n    gtot = sum(gm.values()) or 1.0\n    global_weight = {a: gm[a]/gtot for a in actions}\n\n    med_lab_df = sol.group_by([\"lab_id\",\"action\"]).median().select([\"lab_id\",\"action\",\"dur\"])\n    med_glob_df= sol.group_by([\"action\"]).median().select([\"action\",\"dur\"])\n    med_lab: Dict[str, Dict[str,int]] = defaultdict(dict)\n    for r in med_lab_df.to_dicts():\n        med_lab[str(r[\"lab_id\"])][str(r[\"action\"])] = int(r[\"dur\"])\n    med_glob = {r[\"action\"]: int(r[\"dur\"]) for r in med_glob_df.to_dicts()}\n    return per_lab_weight, global_weight, med_lab, med_glob\n\ndef compute_timing_priors(solution: pl.DataFrame, spans: Dict[int, Tuple[int,int]]):\n    def _start_pct(row) -> float:\n        vid = int(row[\"video_id\"]); s,e = spans.get(vid, (0,1))\n        denom = max(1, e - s)\n        return float(max(0, min(1, (int(row[\"start_frame\"]) - s)/denom)))\n    rows=[]\n    for r in solution.select([\"lab_id\",\"action\",\"video_id\",\"start_frame\"]).to_dicts():\n        rows.append({\"lab_id\": r[\"lab_id\"], \"action\": r[\"action\"], \"start_pct\": _start_pct(r)})\n    df = pl.DataFrame(rows)\n    lab_med = df.group_by([\"lab_id\",\"action\"]).median().select([\"lab_id\",\"action\",\"start_pct\"])\n    per_lab: Dict[str, Dict[str,float]] = defaultdict(dict)\n    for r in lab_med.to_dicts():\n        per_lab[str(r[\"lab_id\"])][str(r[\"action\"])] = float(r[\"start_pct\"])\n    g = df.group_by([\"action\"]).median().select([\"action\",\"start_pct\"])\n    glob = {r[\"action\"]: float(r[\"start_pct\"]) for r in g.to_dicts()}\n    return per_lab, glob\n\n# ========================\n# Tracking features → windows & opportunity\n# ========================\ndef _pair_features(df: pl.DataFrame, agent: str, target: str, downsample: int = 1) -> Optional[pl.DataFrame]:\n    frame_candidates = [\"video_frame\",\"frame\",\"frame_idx\"]\n    id_candidates    = [\"mouse_id\",\"id\",\"track_id\",\"agent_id\"]\n    x_candidates     = [\"x\",\"x_pos\",\"x_position\",\"x_mm\",\"centroid_x\",\"cx\"]\n    y_candidates     = [\"y\",\"y_pos\",\"y_position\",\"y_mm\",\"centroid_y\",\"cy\"]\n    cols=set(df.columns)\n    frame_col = next((c for c in frame_candidates if c in cols), None)\n    id_col    = next((c for c in id_candidates if c in cols), None)\n    x_col     = next((c for c in x_candidates if c in cols), None)\n    y_col     = next((c for c in y_candidates if c in cols), None)\n    if not all([frame_col,id_col,x_col,y_col]): \n        return None\n\n    a_id = _strip_mouse(agent); t_id = _strip_mouse(target)\n    pdf = df.select([frame_col,id_col,x_col,y_col]).to_pandas()\n    pdf[frame_col] = pdf[frame_col].astype(np.int64, copy=False)\n    pdf[id_col]    = pdf[id_col].astype(str, copy=False)\n\n    A = pdf[pdf[id_col]==a_id].copy(); B = pdf[pdf[id_col]==t_id].copy()\n    if A.empty or B.empty: \n        return None\n    A.drop_duplicates(subset=[frame_col], keep=\"first\", inplace=True)\n    B.drop_duplicates(subset=[frame_col], keep=\"first\", inplace=True)\n\n    M = A.merge(B, on=frame_col, how=\"inner\", suffixes=(\"_a\",\"_b\"))\n    if M.empty:\n        return None\n    M.sort_values(frame_col, inplace=True)\n\n    ax = M[f\"{x_col}_a\"].to_numpy(np.float64, copy=False)\n    ay = M[f\"{y_col}_a\"].to_numpy(np.float64, copy=False)\n    bx = M[f\"{x_col}_b\"].to_numpy(np.float64, copy=False)\n    by = M[f\"{y_col}_b\"].to_numpy(np.float64, copy=False)\n    fr = M[frame_col].to_numpy(np.int64, copy=False)\n\n    if downsample>1:\n        sl = slice(0, None, int(downsample))\n        ax,ay,bx,by,fr = ax[sl], ay[sl], bx[sl], by[sl], fr[sl]\n        if ax.size==0: return None\n\n    dx = ax - bx; dy = ay - by\n    dist = np.sqrt(dx*dx + dy*dy)\n\n    dax = np.diff(ax, prepend=ax[0]); day = np.diff(ay, prepend=ay[0])\n    dbx = np.diff(bx, prepend=bx[0]); dby = np.diff(by, prepend=by[0])\n    speed_a = np.sqrt(dax*dax + day*day)\n    speed_b = np.sqrt(dbx*dbx + dby*dby)\n\n    rel_speed = speed_a - speed_b\n    ddist = np.diff(dist, prepend=dist[0])\n\n    return pl.DataFrame({\"frame\": fr, \"dist\": dist, \"rel_speed\": rel_speed, \"ddist\": ddist}).sort(\"frame\")\n\ndef _merge_intervals(iv: List[Tuple[int,int]]) -> List[Tuple[int,int]]:\n    if not iv: return []\n    iv = sorted(iv)\n    out=[iv[0]]\n    for s,e in iv[1:]:\n        ps,pe = out[-1]\n        if s<=pe: out[-1]=(ps, max(pe,e))\n        else: out.append((s,e))\n    return out\n\ndef make_windows(feat: pl.DataFrame, min_len: int,\n                 q_dist: float=0.40, q_rel: float=0.60, q_ddist: float=0.40) -> List[Tuple[int,int]]:\n    if feat is None or len(feat)==0: return []\n    qd  = float(feat[\"dist\"].quantile(q_dist))\n    qr  = float(feat[\"rel_speed\"].quantile(q_rel))\n    qdd = float(feat[\"ddist\"].quantile(q_ddist))\n    cond = (pl.col(\"dist\") <= qd) | ((pl.col(\"rel_speed\") >= qr) & (pl.col(\"ddist\") <= qdd))\n    mask = feat.select(cond.alias(\"m\")).to_series().to_list()\n    frames = feat[\"frame\"].to_list()\n    win=[]; run=None\n    for i,flag in enumerate(mask):\n        if flag and run is None:\n            run=[frames[i], frames[i]]\n        elif flag and run is not None:\n            run[1]=frames[i]\n        elif (not flag) and run is not None:\n            s,e=run[0], run[1]+1\n            if e-s>=min_len: win.append((s,e))\n            run=None\n    if run is not None:\n        s,e=run[0], run[1]+1\n        if e-s>=min_len: win.append((s,e))\n    return _merge_intervals(win)\n\ndef action_opportunity_weights(\n    feat: Optional[pl.DataFrame],\n    q_sniff_dist: float = 0.35,\n    q_chase_rel: float = 0.70,\n    q_chase_ddist: float = 0.35,\n    q_follow_mid_low: float = 0.30,\n    q_follow_mid_high: float = 0.70,\n    q_follow_rel: float = 0.40,\n) -> Dict[str, float]:\n    if feat is None or len(feat) == 0:\n        return {\"sniff\": 1e-3, \"chase\": 1e-3, \"follow\": 1e-3}\n    n = int(len(feat))\n    qd_sniff = float(feat[\"dist\"].quantile(q_sniff_dist))\n    qr_chase = float(feat[\"rel_speed\"].quantile(q_chase_rel))\n    qd_chase = float(feat[\"ddist\"].quantile(q_chase_ddist))\n    qd_low  = float(feat[\"dist\"].quantile(q_follow_mid_low))\n    qd_high = float(feat[\"dist\"].quantile(q_follow_mid_high))\n    qrel_small = float(feat[\"rel_speed\"].abs().quantile(q_follow_rel))\n    sniff_mask  = (feat[\"dist\"] <= qd_sniff)\n    chase_mask  = (feat[\"rel_speed\"] >= qr_chase) & (feat[\"ddist\"] <= qd_chase)\n    follow_mask = (feat[\"dist\"] >= qd_low) & (feat[\"dist\"] <= qd_high) & (feat[\"rel_speed\"].abs() <= qrel_small)\n    sniff_p  = float(sniff_mask.sum())  / max(1, n)\n    chase_p  = float(chase_mask.sum())  / max(1, n)\n    follow_p = float(follow_mask.sum()) / max(1, n)\n    eps = 1e-3\n    return {\"sniff\": sniff_p + eps, \"chase\": chase_p + eps, \"follow\": follow_p + eps}\n\n# ========================\n# Allocation (no ML)\n# ========================\ndef order_by_timing(actions: List[str], lab_id: str,\n                    timing_lab: Dict[str, Dict[str,float]],\n                    timing_glob: Dict[str,float],\n                    tiebreak: Dict[str,int]) -> List[str]:\n    def s(a: str) -> Tuple[float,int]:\n        t = timing_lab.get(lab_id, {}).get(a, timing_glob.get(a, 0.5))\n        return (t, tiebreak.get(a, 99))\n    return sorted(actions, key=s)\n\ndef clip_rare(weights: Dict[str,float], actions: List[str], p_min: float, cap: float) -> Dict[str,float]:\n    w = {a: max(0.0, float(weights.get(a, 0.0))) for a in actions}\n    for a in actions:\n        if w[a] < p_min:\n            w[a] = min(w[a], cap)\n    s = sum(w.values()) or 1.0\n    return {a: w[a]/s for a in actions}\n\ndef allocate_in_windows(windows: List[Tuple[int,int]],\n                        ordered_actions: List[str],\n                        weights: Dict[str,float],\n                        med_dur: Dict[str,int],\n                        total_frames: int) -> List[Tuple[str,int,int]]:\n    remain = sum(e-s for s,e in windows)\n    if remain<=0: return []\n    out=[]\n    idx=0\n    cur_s, cur_e = windows[0]\n    for a in ordered_actions:\n        if remain<=0: break\n        want = int(weights.get(a,0)*total_frames)\n        want = max(want, int(med_dur.get(a,0) or 0))\n        want = min(want, remain)\n        got=0\n        while got<want and idx < len(windows):\n            s,e = cur_s, cur_e\n            if s>=e:\n                idx+=1\n                if idx>=len(windows): break\n                cur_s, cur_e = windows[idx]\n                continue\n            take = min(want-got, e-s)\n            out.append((a, s, s+take))\n            got += take\n            remain -= take\n            cur_s = s + take\n            if cur_s >= e and idx < len(windows):\n                idx += 1\n                if idx < len(windows):\n                    cur_s, cur_e = windows[idx]\n    return out\n\ndef smooth_segments(segs: List[Tuple[str,int,int]], min_len: int, gap_close: int) -> List[Tuple[str,int,int]]:\n    if not segs: return []\n    segs = sorted(segs, key=lambda x:(x[1],x[2],x[0]))\n    segs = [s for s in segs if s[2]-s[1] >= min_len]\n    if not segs: return []\n    out=[segs[0]]\n    for a,s,e in segs[1:]:\n        pa,ps,pe = out[-1]\n        if a==pa and s-pe <= gap_close:\n            out[-1]=(a, ps, e)\n        else:\n            out.append((a,s,e))\n    return out\n\n# Deconflict within same (agent,target): no overlapping frames\ndef subtract_interval(interval: Tuple[int,int], occ: List[Tuple[int,int]]) -> List[Tuple[int,int]]:\n    s,e = interval\n    if s>=e: return []\n    free = [(s,e)]\n    for os,oe in occ:\n        new_free=[]\n        for fs,fe in free:\n            if oe<=fs or fe<=os:\n                new_free.append((fs,fe))\n            else:\n                if fs < os:\n                    new_free.append((fs, os))\n                if oe < fe:\n                    new_free.append((oe, fe))\n        free = new_free\n        if not free: break\n    return free\n\ndef add_interval(occ: List[Tuple[int,int]], interval: Tuple[int,int]) -> List[Tuple[int,int]]:\n    occ.append(interval)\n    occ.sort()\n    merged=[]\n    for s,e in occ:\n        if not merged or s>merged[-1][1]:\n            merged.append([s,e])\n        else:\n            merged[-1][1] = max(merged[-1][1], e)\n    return [(s,e) for s,e in merged]\n\ndef deconflict_segments(segs: List[Tuple[str,int,int]],\n                        priority: Dict[str,float],\n                        min_len: int) -> List[Tuple[str,int,int]]:\n    if not segs: return []\n    segs_sorted = sorted(segs, key=lambda x: (-priority.get(x[0], 0.0), x[1], x[2]))\n    occ: List[Tuple[int,int]] = []\n    kept: List[Tuple[str,int,int]] = []\n    for a,s,e in segs_sorted:\n        for fs,fe in subtract_interval((s,e), occ):\n            if fe - fs >= min_len:\n                kept.append((a, fs, fe))\n                occ = add_interval(occ, (fs,fe))\n    kept.sort(key=lambda x:(x[1], x[2], x[0]))\n    return kept\n\n# ========================\n# Predict\n# ========================\ndef predict_without_ml(dataset: pl.DataFrame, split: str, cfg: Config,\n                       priors_per_lab, priors_global,\n                       meddur_per_lab, meddur_global,\n                       timing_lab, timing_global,\n                       use_windows: bool = USE_WINDOWS,\n                       min_len: int = MIN_LEN, gap_close: int = GAP_CLOSE,\n                       p_min: float = RARE_P_MIN, cap: float = RARE_CAP,\n                       opp_gamma: float = OPP_GAMMA,\n                       dilate_by: int = DILATE_BY) -> pl.DataFrame:\n    track_dir = cfg.test_track_dir if split==\"test\" else cfg.train_track_dir\n    rows=[]\n    canonical = {\"chase\":0,\"chaseattack\":1,\"attack\":2,\"approach\":3,\"avoid\":4,\"mount\":5,\"submit\":6,\"sniff\":7,\"follow\":8}\n\n    for r in tqdm(dataset.to_dicts(), total=len(dataset), desc=f\"Predict {split}\"):\n        lab = str(r[\"lab_id\"])\n        if is_excluded_lab(lab): \n            continue\n        vid = int(r[\"video_id\"])\n        p = track_dir / lab / f\"{vid}.parquet\"\n        if not p.exists():\n            continue\n        try:\n            trk = pl.read_parquet(p)\n            frame_col = next((c for c in [\"video_frame\",\"frame\",\"frame_idx\"] if c in trk.columns), None)\n            if frame_col is None: \n                continue\n            s0 = int(trk[frame_col].min()); e0 = int(trk[frame_col].max())+1\n            total = e0 - s0\n            if total<=0: \n                continue\n\n            raw = safe_json_loads(r.get(\"behaviors_labeled\",\"\"))\n            triples=[]\n            for t in raw:\n                parts=[pp.strip() for pp in str(t).replace(\"'\",\"\").split(\",\")]\n                if len(parts)==3:\n                    triples.append(parts)\n            if not triples: \n                continue\n            beh = pl.DataFrame(triples, schema=[\"agent\",\"target\",\"action\"], orient=\"row\")\n\n            for (agent, target), g in beh.group_by([\"agent\",\"target\"]):\n                actions = sorted(list(set(g[\"action\"].to_list())), key=lambda a: canonical.get(a,99))\n                if not actions: \n                    continue\n\n                w_map = priors_per_lab.get(lab, {}) or priors_global\n                md_map= meddur_per_lab.get(lab, {}) or meddur_global\n                weights = clip_rare(w_map, actions, p_min=p_min, cap=cap)\n                ordered = order_by_timing(actions, lab, timing_lab, timing_global, canonical)\n\n                if use_windows:\n                    feat = _pair_features(trk, _norm_mouse(agent), _norm_mouse(target), downsample=1)\n                    wins = make_windows(feat, min_len=min_len) if feat is not None else [(s0,e0)]\n                    if not wins: wins=[(s0,e0)]\n                else:\n                    feat = None\n                    wins=[(s0,e0)]\n                wins = _merge_intervals(wins)\n                allowed_total = sum(e-s for s,e in wins)\n                if allowed_total<=0: \n                    continue\n\n                # opportunity reweight (sniff/chase/followのみ)\n                if opp_gamma > 0.0:\n                    opp = action_opportunity_weights(feat) if (use_windows and feat is not None) else {\"sniff\":1e-3,\"chase\":1e-3,\"follow\":1e-3}\n                    TARGET = {\"sniff\",\"chase\",\"follow\"}\n                    w_adj = {}\n                    for a in actions:\n                        base = float(weights.get(a, 0.0))\n                        mult = (float(opp.get(a, 1e-3)) ** opp_gamma) if a in TARGET else 1.0\n                        w_adj[a] = base * mult\n                    s_w = sum(w_adj.values()) or 1.0\n                    weights = {a: w_adj[a]/s_w for a in actions}\n\n                segs = allocate_in_windows(wins, ordered, weights, md_map, allowed_total)\n                segs = smooth_segments(segs, min_len=min_len, gap_close=gap_close)\n\n                # --- Fallback: if still empty, force one short seg (prevents zero score) ---\n                if not segs and allowed_total > 0:\n                    best_a = max(actions, key=lambda a: (weights.get(a,0.0), -canonical.get(a,99)))\n                    fs, fe = wins[0]\n                    fe = min(fe, fs + max(min_len, int((sum(meddur_per_lab.get(lab,{}).values()) or 0) / max(1,len(actions)))))\n                    if fe > fs:\n                        segs = [(best_a, fs, fe)]\n\n                # dilation\n                if dilate_by and dilate_by > 0 and segs:\n                    dil = []\n                    for a, s, e in segs:\n                        ss = max(s0, s - dilate_by)\n                        ee = min(e0, e + dilate_by)\n                        if ee > ss:\n                            dil.append((a, ss, ee))\n                    segs = smooth_segments(dil, min_len=min_len, gap_close=gap_close)\n\n                # deconflict within pair\n                if segs:\n                    pri = {a: float(weights.get(a, 0.0)) + 1e-9*(1.0/(1+canonical.get(a,99))) for a in actions}\n                    segs = deconflict_segments(segs, pri, min_len=min_len)\n\n                for a, s, e in segs:\n                    if e>s:\n                        rows.append((vid, _norm_mouse(agent), _norm_mouse(target), a, int(s), int(e)))\n        except Exception:\n            continue\n\n    if not rows:\n        if split == \"train\":\n            return pl.DataFrame([], schema=cfg.submission_schema)\n        raise ValueError(\"No predictions generated.\")\n    sub = pl.DataFrame(rows, schema=cfg.submission_schema, orient=\"row\")\n    sub = validate_schema(sub, cfg.submission_schema, \"Submission\")\n    return sub\n\n# ========================\n# Scorer (official-compatible, robust active labels)\n# ========================\nclass HostVisibleError(Exception): pass\n\ndef single_lab_f1(lab_solution: pl.DataFrame, lab_submission: pl.DataFrame, beta: float = 1.0) -> float:\n    label_frames: Dict[str, Set[int]] = defaultdict(set)\n    for row in lab_solution.to_dicts():\n        label_frames[row[\"label_key\"]].update(range(int(row[\"start_frame\"]), int(row[\"stop_frame\"])))\n\n    active_by_video: Dict[int, Set[str]] = {}\n    for row in lab_solution.select([\"video_id\", \"behaviors_labeled\"]).unique().to_dicts():\n        s: Set[str] = set()\n        for item in safe_json_loads(row[\"behaviors_labeled\"]):  # ← robust parse\n            parts = [p.strip() for p in str(item).replace(\"'\", \"\").split(\",\")]\n            if len(parts) == 3:\n                a, t, act = parts\n                s.add(f\"{_norm_mouse(a)},{_norm_mouse(t)},{act}\")\n        active_by_video[int(row[\"video_id\"])] = s\n\n    prediction_frames: Dict[str, Set[int]] = defaultdict(set)\n    for video_id in lab_solution[\"video_id\"].unique():\n        vid = int(video_id)\n        active = active_by_video.get(vid, set())\n        predicted_mouse_pairs: Dict[str, Set[int]] = defaultdict(set)\n        for row in lab_submission.filter(pl.col(\"video_id\") == vid).to_dicts():\n            triple_norm = f\"{_norm_mouse(row['agent_id'])},{_norm_mouse(row['target_id'])},{row['action']}\"\n            if triple_norm not in active:\n                continue\n            pred_key = row[\"prediction_key\"]\n            agent_target = f\"{_norm_mouse(row['agent_id'])},{_norm_mouse(row['target_id'])}\"\n            new_frames = set(range(int(row[\"start_frame\"]), int(row[\"stop_frame\"])))\n            new_frames -= prediction_frames[pred_key]\n            if predicted_mouse_pairs[agent_target] & new_frames:\n                raise HostVisibleError(\"Multiple predictions for the same frame from one agent/target pair\")\n            prediction_frames[pred_key].update(new_frames)\n            predicted_mouse_pairs[agent_target].update(new_frames)\n\n    tps: Dict[str, int] = defaultdict(int)\n    fns: Dict[str, int] = defaultdict(int)\n    fps: Dict[str, int] = defaultdict(int)\n    distinct_actions: Set[str] = set()\n\n    for key, pred_frames in prediction_frames.items():\n        action = key.split(\"_\")[-1]\n        distinct_actions.add(action)\n        gt_frames = label_frames.get(key, set())\n        tps[action] += len(pred_frames & gt_frames)\n        fns[action] += len(gt_frames - pred_frames)\n        fps[action] += len(pred_frames - gt_frames)\n\n    for key, gt_frames in label_frames.items():\n        action = key.split(\"_\")[-1]\n        distinct_actions.add(action)\n        if key not in prediction_frames:\n            fns[action] += len(gt_frames)\n\n    if not distinct_actions:\n        return 0.0\n\n    beta2 = beta * beta\n    f_scores: List[float] = []\n    for action in distinct_actions:\n        tp, fn, fp = tps[action], fns[action], fps[action]\n        denom = (1 + beta2) * tp + beta2 * fn + fp\n        f_scores.append(0.0 if denom == 0 else (1 + beta2) * tp / denom)\n    return sum(f_scores) / len(f_scores)\n\ndef mouse_fbeta(solution: pl.DataFrame, submission: pl.DataFrame, beta: float = 1.0) -> float:\n    solution = solution.select([\"video_id\",\"agent_id\",\"target_id\",\"action\",\"start_frame\",\"stop_frame\",\"lab_id\",\"behaviors_labeled\"])\n    submission = submission.select([\"video_id\",\"agent_id\",\"target_id\",\"action\",\"start_frame\",\"stop_frame\"])\n    solution = validate_schema(solution, {\n        \"video_id\": pl.Int64,\"agent_id\": pl.Utf8,\"target_id\": pl.Utf8,\"action\": pl.Utf8,\n        \"start_frame\": pl.Int64,\"stop_frame\": pl.Int64,\"lab_id\": pl.Utf8,\"behaviors_labeled\": pl.Utf8\n    }, \"Solution\")\n    submission = validate_schema(submission, {\n        \"video_id\": pl.Int64,\"agent_id\": pl.Utf8,\"target_id\": pl.Utf8,\"action\": pl.Utf8,\n        \"start_frame\": pl.Int64,\"stop_frame\": pl.Int64\n    }, \"Submission\")\n    if not (solution[\"start_frame\"] <= solution[\"stop_frame\"]).all():\n        raise ValueError(\"Solution has start>stop\")\n    if not (submission[\"start_frame\"] <= submission[\"stop_frame\"]).all():\n        raise ValueError(\"Submission has start>stop\")\n\n    vids = solution[\"video_id\"].unique()\n    submission = submission.filter(pl.col(\"video_id\").is_in(vids))\n\n    def add_key(df: pl.DataFrame, col_name: str) -> pl.DataFrame:\n        return df.with_columns(\n            pl.concat_str(\n                [\n                    pl.col(\"video_id\").cast(pl.Utf8),\n                    pl.col(\"agent_id\").cast(pl.Utf8),\n                    pl.col(\"target_id\").cast(pl.Utf8),\n                    pl.col(\"action\"),\n                ],\n                separator=\"_\",\n            ).alias(col_name)\n        )\n\n    solution = add_key(solution, \"label_key\")\n    submission = add_key(submission, \"prediction_key\")\n\n    lab_scores: List[float] = []\n    for lab_id in solution[\"lab_id\"].unique():\n        lab_solution = solution.filter(pl.col(\"lab_id\") == lab_id)\n        lab_videos = lab_solution[\"video_id\"].unique()\n        lab_submission = submission.filter(pl.col(\"video_id\").is_in(lab_videos))\n        lab_scores.append(single_lab_f1(lab_solution, lab_submission, beta=beta))\n    return sum(lab_scores) / len(lab_scores) if lab_scores else 0.0\n\n# ========================\n# Valid video filtering & folds\n# ========================\ndef is_valid_row(r: dict, split: str, cfg: Config) -> bool:\n    lab = str(r[\"lab_id\"])\n    if is_excluded_lab(lab): \n        return False\n    vid = int(r[\"video_id\"])\n    track_dir = cfg.train_track_dir if split==\"train\" else cfg.test_track_dir\n    p = track_dir / lab / f\"{vid}.parquet\"\n    if not p.exists():\n        return False\n    raw = safe_json_loads(r.get(\"behaviors_labeled\",\"\"))\n    if not any(len(str(t).split(\",\")) >= 3 for t in raw):\n        return False\n    return True\n\ndef valid_meta_only(meta: pl.DataFrame, split: str, cfg: Config) -> pl.DataFrame:\n    keep = [r for r in meta.to_dicts() if is_valid_row(r, split, cfg)]\n    return pl.DataFrame(keep, schema=meta.schema) if keep else meta.head(0)\n\ndef limit_videos(meta: pl.DataFrame, n: Optional[int], seed: int = 42) -> pl.DataFrame:\n    if (n is None) or (n <= 0) or (len(meta) <= n):\n        return meta\n    vids = meta[\"video_id\"].unique().to_list()\n    rng = np.random.RandomState(seed)\n    pick = set(rng.choice(vids, size=n, replace=False).tolist())\n    return meta.filter(pl.col(\"video_id\").is_in(pick))\n\ndef build_folds_on_valid(valid_meta: pl.DataFrame, n_splits: int = 5) -> List[Tuple[np.ndarray, np.ndarray]]:\n    from sklearn.model_selection import GroupKFold\n    pdf = valid_meta.select([\"video_id\",\"lab_id\"]).to_pandas()\n    idx = np.arange(len(pdf))\n    gkf = GroupKFold(n_splits=n_splits)\n    return [(tr, va) for tr, va in gkf.split(idx, groups=pdf[\"lab_id\"].values)]\n\ndef run_local_cv(train_meta: pl.DataFrame,\n                 n_splits: int = 5, beta: float = 1.0,\n                 max_videos_per_fold: Optional[int] = MAX_VIDEOS_PER_FOLD,\n                 use_windows: bool = USE_WINDOWS, min_len: int = MIN_LEN, gap_close: int = GAP_CLOSE,\n                 p_min: float = RARE_P_MIN, cap: float = RARE_CAP,\n                 opp_gamma: float = OPP_GAMMA, dilate_by: int = DILATE_BY) -> List[float]:\n\n    valid_train = valid_meta_only(train_meta, \"train\", cfg)\n    if len(valid_train) == 0:\n        print(\"[CV] No valid videos in train.\")\n        return [0.0]*n_splits\n\n    folds = build_folds_on_valid(valid_train, n_splits=n_splits)\n    scores=[]\n    for i, (tr_idx, va_idx) in enumerate(folds, 1):\n        tr_labs = set(valid_train[tr_idx.tolist()][\"lab_id\"].unique().to_list())\n        va_labs = set(valid_train[va_idx.tolist()][\"lab_id\"].unique().to_list())\n\n        tr_meta = train_meta.filter(pl.col(\"lab_id\").is_in(list(tr_labs)))\n        val_meta_valid = valid_train.filter(pl.col(\"lab_id\").is_in(list(va_labs)))\n        val_meta_valid = limit_videos(val_meta_valid, max_videos_per_fold, seed=100+i)\n\n        if len(val_meta_valid) == 0:\n            print(f\"[Fold {i}] no valid videos -> score=0.000000\")\n            scores.append(0.0)\n            continue\n\n        solution_tr = create_solution_df(tr_meta, cfg)\n        spans_tr    = build_spans(tr_meta, \"train\", cfg)\n        per_lab, global_w, med_lab, med_glob = compute_action_priors(solution_tr, eps=LAPLACE_EPS)\n        time_lab, time_glob = compute_timing_priors(solution_tr, spans_tr)\n\n        pred_val = predict_without_ml(\n            val_meta_valid, \"train\", cfg,\n            priors_per_lab=per_lab, priors_global=global_w,\n            meddur_per_lab=med_lab, meddur_global=med_glob,\n            timing_lab=time_lab, timing_global=time_glob,\n            use_windows=use_windows, min_len=min_len, gap_close=gap_close,\n            p_min=p_min, cap=cap, opp_gamma=opp_gamma, dilate_by=dilate_by\n        )\n\n        solution_val = create_solution_df(val_meta_valid, cfg)\n\n        try:\n            sc = mouse_fbeta(solution_val, pred_val, beta=beta)\n        except HostVisibleError as e:\n            print(f\"[Fold {i}] HostVisibleError: {e} -> 0.0\")\n            sc = 0.0\n        print(f\"[Fold {i}] videos={val_meta_valid['video_id'].n_unique()} labs={len(va_labs)} score={sc:.6f}\")\n        scores.append(sc)\n\n    print(f\"[LocalCV] mean={np.mean(scores):.6f}  std={np.std(scores):.6f}\")\n    return scores\n\n# ========================\n# Main\n# ========================\nprint(\"[1/3] Load metadata ...\")\ntrain = pl.read_csv(cfg.train_csv)\ntest  = pl.read_csv(cfg.test_csv)\n\nif DO_CV:\n    print(\"\\n[2/3] LocalCV ...\")\n    _ = run_local_cv(train,\n                     n_splits=N_SPLITS, beta=BETA,\n                     max_videos_per_fold=MAX_VIDEOS_PER_FOLD,\n                     use_windows=USE_WINDOWS, min_len=MIN_LEN, gap_close=GAP_CLOSE,\n                     p_min=RARE_P_MIN, cap=RARE_CAP,\n                     opp_gamma=OPP_GAMMA, dilate_by=DILATE_BY)\n\nif DO_SUBMIT:\n    print(\"\\n[3/3] Predict test (build priors from full train) ...\")\n    solution_all = create_solution_df(train, cfg)\n    spans_all    = build_spans(train, \"train\", cfg)\n    per_lab, global_w, med_lab, med_glob = compute_action_priors(solution_all, eps=LAPLACE_EPS)\n    time_lab, time_glob = compute_timing_priors(solution_all, spans_all)\n\n    submission = predict_without_ml(\n        test, \"test\", cfg,\n        priors_per_lab=per_lab, priors_global=global_w,\n        meddur_per_lab=med_lab, meddur_global=med_glob,\n        timing_lab=time_lab, timing_global=time_glob,\n        use_windows=USE_WINDOWS, min_len=MIN_LEN, gap_close=GAP_CLOSE,\n        p_min=RARE_P_MIN, cap=RARE_CAP, opp_gamma=OPP_GAMMA, dilate_by=DILATE_BY\n    )\n\n    submission = submission.select([\"video_id\",\"agent_id\",\"target_id\",\"action\",\"start_frame\",\"stop_frame\"]).with_row_index(\"row_id\")\n    submission.write_csv(cfg.submission_file)\n    print(\"Saved:\", cfg.submission_file)\n    try:\n        print(submission.head())\n    except Exception:\n        pass\n","metadata":{"_uuid":"cb8ac2eb-d93c-4e94-9844-38f1c5af0f67","_cell_guid":"fb122bab-df16-4790-80f6-e7b881018586","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-09-24T12:42:30.945805Z","iopub.execute_input":"2025-09-24T12:42:30.946145Z","iopub.status.idle":"2025-09-24T12:48:45.408583Z","shell.execute_reply.started":"2025-09-24T12:42:30.94612Z","shell.execute_reply":"2025-09-24T12:48:45.407125Z"}},"outputs":[],"execution_count":null}]}