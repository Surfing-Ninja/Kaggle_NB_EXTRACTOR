{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":116062,"databundleVersionId":14084779,"sourceType":"competition"}],"dockerImageVersionId":31154,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install bio > /dev/null","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-16T15:29:33.667695Z","iopub.execute_input":"2025-10-16T15:29:33.668019Z","iopub.status.idle":"2025-10-16T15:29:39.225386Z","shell.execute_reply.started":"2025-10-16T15:29:33.667988Z","shell.execute_reply":"2025-10-16T15:29:39.223838Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import gc\nimport numpy as np\nimport pandas as pd\n\nfrom Bio import SeqIO\nfrom collections import *\nfrom sklearn.neighbors import NearestNeighbors","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-16T15:29:39.227726Z","iopub.execute_input":"2025-10-16T15:29:39.228379Z","iopub.status.idle":"2025-10-16T15:29:39.235577Z","shell.execute_reply.started":"2025-10-16T15:29:39.228299Z","shell.execute_reply":"2025-10-16T15:29:39.233966Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train = pd.read_csv(\"/kaggle/input/cafa-6-protein-function-prediction/Train/train_terms.tsv\", \n                   sep='\\t', names=['p','t','o'], dtype={'p': 'category', 't': 'category'})\n\nterm_freq = Counter(train['t'])\nMIN_TERM_FREQ = 10\nfiltered_terms = {t for t, cnt in term_freq.items() if cnt >= MIN_TERM_FREQ}\n\nprot2terms = defaultdict(set)\nfor _, r in train.iterrows():\n    if r['t'] in filtered_terms:\n        prot2terms[r['p']].add(r['t'])\n\ndel train\ngc.collect()\n\ndef load_fasta(f, max_seqs=None):\n    seqs = {}\n    count = 0\n    \n    for r in SeqIO.parse(f, 'fasta'):\n        \n        if max_seqs and count >= max_seqs:\n            break\n        \n        parts = r.id.split('|')\n        pid = parts[1] if len(parts) >= 2 else parts[0]\n        seqs[pid] = str(r.seq)\n        count += 1\n    \n    return seqs\n\ntrain_fasta = load_fasta(\"/kaggle/input/cafa-6-protein-function-prediction/Train/train_sequences.fasta\")\ntrain_fasta = {k: v for k, v in train_fasta.items() if k in prot2terms}\n\ntest_fasta = load_fasta(\"/kaggle/input/cafa-6-protein-function-prediction/Test/testsuperset.fasta\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-16T15:29:39.236668Z","iopub.execute_input":"2025-10-16T15:29:39.236979Z","iopub.status.idle":"2025-10-16T15:30:18.605004Z","shell.execute_reply.started":"2025-10-16T15:29:39.236955Z","shell.execute_reply":"2025-10-16T15:30:18.603878Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def kmer_vocab(sequences, top_k=500, k_sizes=[3, 4]):\n    kmer_counter = Counter()\n    \n    for seq in sequences:\n        for k_size in k_sizes:\n            for i in range(len(seq) - k_size + 1):\n                kmer = seq[i:i + k_size]\n                kmer_counter[kmer] += 1\n                \n    return [k for k, _ in kmer_counter.most_common(top_k)]\n\n\nkmers = kmer_vocab(train_fasta.values(), top_k=500, k_sizes=[3, 4])\nvocab = kmers\nk2i = {k: i for i, k in enumerate(vocab)}\n\ndef vec(s):\n    if len(s) == 0:\n        return np.zeros(len(vocab) + 6, dtype=np.float32)\n    \n    v = np.zeros(len(vocab) + 6, dtype=np.float32)\n    total_kmers = 0\n    \n    for i in range(len(s) - 2):\n        kmer3 = s[i:i+3]\n        if kmer3 in k2i:\n            v[k2i[kmer3]] += 1\n            total_kmers += 1\n    \n    for i in range(len(s) - 3):\n        kmer4 = s[i:i+4] \n        if kmer4 in k2i:\n            v[k2i[kmer4]] += 1\n            total_kmers += 1\n            \n    if total_kmers > 0:\n        v[:len(vocab)] /= total_kmers\n        \n    if len(s) > 0:\n        # Hydrophobicity (A, I, L, M, F, W, Y, V)\n        hydrophobic = sum(a in 'AILMFWYV' for a in s) / len(s)\n        \n        # Charged amino acids (D, E, K, R, H)\n        charged = sum(a in 'DEKRH' for a in s) / len(s)\n        \n        # Polar Amino Acids (N, Q, S, T, C)\n        polar = sum(a in 'NQSTC' for a in s) / len(s)\n        \n        # Molecular weight (approximate proportion)\n        weight_aa = 'GASPTCDNEQHKRMILFVWY'\n        weight_contrib = sum(a in 'ILFVWYMR' for a in s) / len(s)\n        \n        # N-terminal properties (first 15 aa)\n        n_term = s[:15] if len(s) >= 15 else s\n        n_hydrophobic = sum(a in 'AILMFWYV' for a in n_term) / len(n_term)\n        \n        # C-terminal properties (last 15 aa)\n        c_term = s[-15:] if len(s) >= 15 else s\n        c_hydrophobic = sum(a in 'AILMFWYV' for a in c_term) / len(c_term)\n        \n        v[-6:] = [hydrophobic, charged, polar, weight_contrib, n_hydrophobic, c_hydrophobic]\n    \n    # L2 normalization\n    norm = np.linalg.norm(v)\n    if norm > 0:\n        v /= norm\n    \n    return v\n\ndef build_matrix_batch(sequences, batch_size=2000):\n    n_samples = len(sequences)\n    n_features = len(vocab) + 6\n    matrix = np.zeros((n_samples, n_features), dtype=np.float32)\n    \n    seqs_list = list(sequences.values())\n    \n    for i in range(0, n_samples, batch_size):\n        end_idx = min(i + batch_size, n_samples)\n        batch = seqs_list[i:end_idx]\n        \n        for j, seq in enumerate(batch):\n            matrix[i + j] = vec(seq)\n    \n    return matrix\n\nX_train = build_matrix_batch(train_fasta)\ntrain_pids = list(train_fasta.keys())\n\nX_test = build_matrix_batch(test_fasta)  \ntest_pids = list(test_fasta.keys())\n\ndel train_fasta, test_fasta\ngc.collect()\n\nneighbors = 25\nSIMILARITY_THRESHOLD = 0.3\n\nprint(f\"Fitting KNN with {neighbors} neighbors...\")\nknn = NearestNeighbors(n_neighbors=neighbors, metric='cosine', algorithm='brute', n_jobs=-1)\nknn.fit(X_train)\n\ndistances, I = knn.kneighbors(X_test)\nsimilarities = 1 - distances  # cosine similarity","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-16T15:30:18.60675Z","iopub.execute_input":"2025-10-16T15:30:18.607112Z","iopub.status.idle":"2025-10-16T15:47:10.007849Z","shell.execute_reply.started":"2025-10-16T15:30:18.607085Z","shell.execute_reply":"2025-10-16T15:47:10.005768Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"submission = []\nfor i, pid in enumerate(test_pids):\n    term_scores = {}\n    neighbor_weights = []\n    \n    for j in range(neighbors):\n        sim = similarities[i][j]\n        if sim < SIMILARITY_THRESHOLD:\n            continue\n            \n        neighbor_pid = train_pids[I[i][j]]\n        neighbor_terms = prot2terms.get(neighbor_pid, set())\n        \n        for term in neighbor_terms:\n            current_score = term_scores.get(term, 0)\n            term_scores[term] = max(current_score, sim)\n    \n    if term_scores:\n        max_score = max(term_scores.values())\n        min_score = min(term_scores.values())\n        \n        if max_score > min_score:\n            for term, score in term_scores.items():\n                normalized_score = 0.1 + 0.9 * (score - min_score) / (max_score - min_score)\n                submission.append(f\"{pid}\\t{term}\\t{normalized_score:.3f}\\n\")\n        else:\n            for term, score in term_scores.items():\n                submission.append(f\"{pid}\\t{term}\\t{0.5:.3f}\\n\")\n\nMAX_TERMS_PER_PROTEIN = 400\n\nres = defaultdict(list)\nfor line in submission:\n    p, t, s = line.strip().split('\\t')\n    res[p].append((t, float(s)))\n\nfinal = []\nfor p, items in res.items():\n    items.sort(key=lambda x: x[1], reverse=True)\n    final.extend([f\"{p}\\t{t}\\t{s:.3f}\\n\" for t, s in items[:MAX_TERMS_PER_PROTEIN]])\n\nwith open('/kaggle/working/submission.tsv', 'w') as f:\n    f.writelines(final)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-10-16T15:49:43.430011Z","iopub.execute_input":"2025-10-16T15:49:43.430563Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"submission = pd.read_csv(\"submission.tsv\", sep='\\t', names=['p','t','o'])\nsubmission.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-16T15:47:10.305829Z","iopub.status.idle":"2025-10-16T15:47:10.306439Z","shell.execute_reply.started":"2025-10-16T15:47:10.306216Z","shell.execute_reply":"2025-10-16T15:47:10.30624Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"submission.tail()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-16T15:47:10.308317Z","iopub.status.idle":"2025-10-16T15:47:10.308769Z","shell.execute_reply.started":"2025-10-16T15:47:10.308545Z","shell.execute_reply":"2025-10-16T15:47:10.308564Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"submission.sample(50)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-16T15:47:10.310836Z","iopub.status.idle":"2025-10-16T15:47:10.311324Z","shell.execute_reply.started":"2025-10-16T15:47:10.31109Z","shell.execute_reply":"2025-10-16T15:47:10.311113Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}