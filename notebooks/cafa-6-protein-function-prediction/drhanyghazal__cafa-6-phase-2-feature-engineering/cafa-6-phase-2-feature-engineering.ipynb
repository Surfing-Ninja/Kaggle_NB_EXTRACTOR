{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":116062,"databundleVersionId":14084779,"sourceType":"competition"}],"dockerImageVersionId":31153,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# CAFA 6 - Phase 2: Comprehensive Feature Engineering\n- Author: Dr. Hany Ghazal (PhD)\n- Date: 19 October 2025\n\nThis module implements all feature engineering methods for protein function prediction:\n1. Basic Sequence Features\n2. K-mer Features\n3. Physicochemical Properties\n4. Positional Features\n5. Composition Features\n6. Structure-based Features\n7. GO Hierarchy Features","metadata":{}},{"cell_type":"code","source":"!pip install biopython","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-23T08:29:46.278103Z","iopub.execute_input":"2025-10-23T08:29:46.278665Z","iopub.status.idle":"2025-10-23T08:29:51.729227Z","shell.execute_reply.started":"2025-10-23T08:29:46.278642Z","shell.execute_reply":"2025-10-23T08:29:51.728376Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from Bio import SeqIO\nimport pandas as pd\nimport numpy as np\nfrom collections import Counter\nfrom typing import Dict, List, Tuple, Optional\nimport warnings\nwarnings.filterwarnings('ignore')\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-10-23T08:29:51.730682Z","iopub.execute_input":"2025-10-23T08:29:51.731049Z","iopub.status.idle":"2025-10-23T08:29:52.057965Z","shell.execute_reply.started":"2025-10-23T08:29:51.731027Z","shell.execute_reply":"2025-10-23T08:29:52.057258Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ============================================================================\n# 1. AMINO ACID PROPERTIES\n# ============================================================================\n\nclass AminoAcidProperties:\n    \"\"\"Database of amino acid physicochemical properties.\"\"\"\n    \n    # Molecular weights (Da)\n    MOLECULAR_WEIGHT = {\n        'A': 89.1, 'C': 121.2, 'D': 133.1, 'E': 147.1, 'F': 165.2,\n        'G': 75.1, 'H': 155.2, 'I': 131.2, 'K': 146.2, 'L': 131.2,\n        'M': 149.2, 'N': 132.1, 'P': 115.1, 'Q': 146.2, 'R': 174.2,\n        'S': 105.1, 'T': 119.1, 'V': 117.1, 'W': 204.2, 'Y': 181.2\n    }\n    \n    # Hydrophobicity (Kyte-Doolittle scale)\n    HYDROPHOBICITY = {\n        'A': 1.8, 'C': 2.5, 'D': -3.5, 'E': -3.5, 'F': 2.8,\n        'G': -0.4, 'H': -3.2, 'I': 4.5, 'K': -3.9, 'L': 3.8,\n        'M': 1.9, 'N': -3.5, 'P': -1.6, 'Q': -3.5, 'R': -4.5,\n        'S': -0.8, 'T': -0.7, 'V': 4.2, 'W': -0.9, 'Y': -1.3\n    }\n    \n    # Charge at pH 7\n    CHARGE = {\n        'A': 0, 'C': 0, 'D': -1, 'E': -1, 'F': 0,\n        'G': 0, 'H': 0.1, 'I': 0, 'K': 1, 'L': 0,\n        'M': 0, 'N': 0, 'P': 0, 'Q': 0, 'R': 1,\n        'S': 0, 'T': 0, 'V': 0, 'W': 0, 'Y': 0\n    }\n    \n    # Polarity\n    POLARITY = {\n        'A': 0, 'C': 1, 'D': 1, 'E': 1, 'F': 0,\n        'G': 0, 'H': 1, 'I': 0, 'K': 1, 'L': 0,\n        'M': 0, 'N': 1, 'P': 0, 'Q': 1, 'R': 1,\n        'S': 1, 'T': 1, 'V': 0, 'W': 0, 'Y': 1\n    }\n    \n    # Van der Waals volume\n    VOLUME = {\n        'A': 67, 'C': 86, 'D': 91, 'E': 109, 'F': 135,\n        'G': 48, 'H': 118, 'I': 124, 'K': 135, 'L': 124,\n        'M': 124, 'N': 96, 'P': 90, 'Q': 114, 'R': 148,\n        'S': 73, 'T': 93, 'V': 105, 'W': 163, 'Y': 141\n    }\n    \n    # Aromaticity (0 or 1)\n    AROMATIC = {\n        'A': 0, 'C': 0, 'D': 0, 'E': 0, 'F': 1,\n        'G': 0, 'H': 1, 'I': 0, 'K': 0, 'L': 0,\n        'M': 0, 'N': 0, 'P': 0, 'Q': 0, 'R': 0,\n        'S': 0, 'T': 0, 'V': 0, 'W': 1, 'Y': 1\n    }\n    \n    # Amino acid groups\n    GROUPS = {\n        'aliphatic': ['A', 'V', 'L', 'I', 'M'],\n        'aromatic': ['F', 'Y', 'W'],\n        'polar': ['S', 'T', 'N', 'Q'],\n        'charged': ['K', 'R', 'H', 'D', 'E'],\n        'positive': ['K', 'R', 'H'],\n        'negative': ['D', 'E'],\n        'small': ['A', 'G', 'S'],\n        'tiny': ['G', 'A', 'S'],\n        'sulfur': ['C', 'M']\n    }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-23T08:29:52.058884Z","iopub.execute_input":"2025-10-23T08:29:52.059274Z","iopub.status.idle":"2025-10-23T08:29:52.068905Z","shell.execute_reply.started":"2025-10-23T08:29:52.059256Z","shell.execute_reply":"2025-10-23T08:29:52.06835Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ============================================================================\n# 2. BASIC SEQUENCE FEATURES\n# ============================================================================\n\nclass BasicSequenceFeatures:\n    \"\"\"Extract basic features from protein sequences.\"\"\"\n    \n    @staticmethod\n    def extract_length_features(sequence: str) -> Dict[str, float]:\n        \"\"\"Extract sequence length-based features.\"\"\"\n        length = len(sequence)\n        return {\n            'seq_length': length,\n            'log_length': np.log1p(length),\n            'sqrt_length': np.sqrt(length)\n        }\n    \n    @staticmethod\n    def extract_molecular_weight(sequence: str) -> Dict[str, float]:\n        \"\"\"Calculate molecular weight of protein.\"\"\"\n        weight = sum(AminoAcidProperties.MOLECULAR_WEIGHT.get(aa, 0) for aa in sequence)\n        # Subtract water molecules formed in peptide bonds\n        weight -= (len(sequence) - 1) * 18.015\n        \n        return {\n            'molecular_weight': weight,\n            'molecular_weight_per_aa': weight / len(sequence) if len(sequence) > 0 else 0\n        }\n    \n    @staticmethod\n    def extract_composition(sequence: str) -> Dict[str, float]:\n        \"\"\"Calculate amino acid composition (frequency of each AA).\"\"\"\n        length = len(sequence)\n        if length == 0:\n            return {f'comp_{aa}': 0.0 for aa in AminoAcidProperties.MOLECULAR_WEIGHT.keys()}\n        \n        counter = Counter(sequence)\n        return {\n            f'comp_{aa}': counter.get(aa, 0) / length\n            for aa in AminoAcidProperties.MOLECULAR_WEIGHT.keys()\n        }\n    \n    @staticmethod\n    def extract_group_composition(sequence: str) -> Dict[str, float]:\n        \"\"\"Calculate composition of amino acid groups.\"\"\"\n        length = len(sequence)\n        if length == 0:\n            return {f'group_{name}': 0.0 for name in AminoAcidProperties.GROUPS.keys()}\n        \n        features = {}\n        for group_name, group_aas in AminoAcidProperties.GROUPS.items():\n            count = sum(1 for aa in sequence if aa in group_aas)\n            features[f'group_{group_name}'] = count / length\n        \n        return features","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-23T08:29:52.070152Z","iopub.execute_input":"2025-10-23T08:29:52.070376Z","iopub.status.idle":"2025-10-23T08:29:52.088754Z","shell.execute_reply.started":"2025-10-23T08:29:52.070357Z","shell.execute_reply":"2025-10-23T08:29:52.088218Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ============================================================================\n# 3. PHYSICOCHEMICAL PROPERTIES\n# ============================================================================\n\nclass PhysicochemicalFeatures:\n    \"\"\"Extract physicochemical property-based features.\"\"\"\n    \n    @staticmethod\n    def extract_property_statistics(sequence: str, property_dict: Dict[str, float], \n                                   property_name: str) -> Dict[str, float]:\n        \"\"\"Calculate statistics for a given property.\"\"\"\n        if len(sequence) == 0:\n            return {\n                f'{property_name}_mean': 0.0,\n                f'{property_name}_std': 0.0,\n                f'{property_name}_min': 0.0,\n                f'{property_name}_max': 0.0\n            }\n        \n        values = [property_dict.get(aa, 0) for aa in sequence]\n        \n        return {\n            f'{property_name}_mean': np.mean(values),\n            f'{property_name}_std': np.std(values),\n            f'{property_name}_min': np.min(values),\n            f'{property_name}_max': np.max(values)\n        }\n    \n    @staticmethod\n    def extract_all_properties(sequence: str) -> Dict[str, float]:\n        \"\"\" Extract all physicochemical property features.\"\"\"\n        features = {}\n        \n        # Hydrophobicity\n        features.update(PhysicochemicalFeatures.extract_property_statistics(\n            sequence, AminoAcidProperties.HYDROPHOBICITY, 'hydrophobicity'))\n        \n        # Charge\n        features.update(PhysicochemicalFeatures.extract_property_statistics(\n            sequence, AminoAcidProperties.CHARGE, 'charge'))\n        \n        # Volume\n        features.update(PhysicochemicalFeatures.extract_property_statistics(\n            sequence, AminoAcidProperties.VOLUME, 'volume'))\n        \n        # Polarity\n        features.update(PhysicochemicalFeatures.extract_property_statistics(\n            sequence, AminoAcidProperties.POLARITY, 'polarity'))\n        \n        # Aromaticity\n        if len(sequence) > 0:\n            aromatic_count = sum(AminoAcidProperties.AROMATIC.get(aa, 0) for aa in sequence)\n            features['aromaticity'] = aromatic_count / len(sequence)\n        else:\n            features['aromaticity'] = 0.0\n        \n        # Net charge\n        if len(sequence) > 0:\n            net_charge = sum(AminoAcidProperties.CHARGE.get(aa, 0) for aa in sequence)\n            features['net_charge'] = net_charge\n            features['charge_density'] = net_charge / len(sequence)\n        else:\n            features['net_charge'] = 0.0\n            features['charge_density'] = 0.0\n        \n        return features\n    \n    @staticmethod\n    def extract_isoelectric_point(sequence: str) -> Dict[str, float]:\n        \"\"\"Estimate isoelectric point (pI) - simplified calculation.\"\"\"\n        if len(sequence) == 0:\n            return {'isoelectric_point': 7.0}\n        \n        # Count charged residues\n        positive = sum(1 for aa in sequence if aa in ['K', 'R', 'H'])\n        negative = sum(1 for aa in sequence if aa in ['D', 'E'])\n        \n        # Simplified pI estimation\n        if positive + negative == 0:\n            pI = 7.0\n        else:\n            pI = 6.5 + 0.5 * (positive - negative) / len(sequence) * 10\n            pI = max(3.0, min(11.0, pI))  # Clamp between 3 and 11\n        \n        return {'isoelectric_point': pI}\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-23T08:29:52.08942Z","iopub.execute_input":"2025-10-23T08:29:52.08958Z","iopub.status.idle":"2025-10-23T08:29:52.100901Z","shell.execute_reply.started":"2025-10-23T08:29:52.089567Z","shell.execute_reply":"2025-10-23T08:29:52.100271Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ============================================================================\n# 4. K-MER FEATURES\n# ============================================================================\n\nclass KmerFeatures:\n    \"\"\"Extract k-mer frequency features.\"\"\"\n    \n    @staticmethod\n    def generate_kmers(k: int) -> List[str]:\n        \"\"\"Generate all possible k-mers.\"\"\"\n        amino_acids = list(AminoAcidProperties.MOLECULAR_WEIGHT.keys())\n        \n        if k == 1:\n            return amino_acids\n        \n        kmers = amino_acids.copy()\n        for _ in range(k - 1):\n            new_kmers = []\n            for kmer in kmers:\n                for aa in amino_acids:\n                    new_kmers.append(kmer + aa)\n            kmers = new_kmers\n        \n        return kmers\n    \n    @staticmethod\n    def extract_kmer_frequencies(sequence: str, k: int, \n                                 normalize: bool = True) -> Dict[str, float]:\n        \"\"\"Extract k-mer frequencies from sequence.\"\"\"\n        if len(sequence) < k:\n            kmers = KmerFeatures.generate_kmers(k)\n            return {f'kmer_{k}_{kmer}': 0.0 for kmer in kmers}\n        \n        # Count k-mers\n        kmer_counts = Counter()\n        for i in range(len(sequence) - k + 1):\n            kmer = sequence[i:i+k]\n            if all(aa in AminoAcidProperties.MOLECULAR_WEIGHT for aa in kmer):\n                kmer_counts[kmer] += 1\n        \n        # Normalize\n        total = sum(kmer_counts.values())\n        if normalize and total > 0:\n            kmer_counts = {k: v/total for k, v in kmer_counts.items()}\n        \n        # Get all possible k-mers\n        all_kmers = KmerFeatures.generate_kmers(k)\n        \n        return {\n            f'kmer_{k}_{kmer}': kmer_counts.get(kmer, 0.0)\n            for kmer in all_kmers\n        }\n    \n    @staticmethod\n    def extract_dipeptide_composition(sequence: str) -> Dict[str, float]:\n        \"\"\"Extract dipeptide (2-mer) composition - 400 features.\"\"\"\n        return KmerFeatures.extract_kmer_frequencies(sequence, k=2, normalize=True)\n    \n    @staticmethod\n    def extract_tripeptide_composition(sequence: str, top_n: int = 100) -> Dict[str, float]:\n        \"\"\"Extract top N most common tripeptides - reduced from 8000 features.\"\"\"\n        if len(sequence) < 3:\n            return {f'kmer_3_top_{i}': 0.0 for i in range(top_n)}\n        \n        # Count all tripeptides\n        tripeptide_counts = Counter()\n        for i in range(len(sequence) - 2):\n            tripeptide = sequence[i:i+3]\n            if all(aa in AminoAcidProperties.MOLECULAR_WEIGHT for aa in tripeptide):\n                tripeptide_counts[tripeptide] += 1\n        \n        # Get top N\n        total = sum(tripeptide_counts.values())\n        top_tripeptides = tripeptide_counts.most_common(top_n)\n        \n        features = {}\n        for i, (tripeptide, count) in enumerate(top_tripeptides):\n            features[f'kmer_3_{tripeptide}'] = count / total if total > 0 else 0.0\n        \n        # Fill remaining with zeros\n        for i in range(len(top_tripeptides), top_n):\n            features[f'kmer_3_top_{i}'] = 0.0\n        \n        return features\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-23T08:29:52.101567Z","iopub.execute_input":"2025-10-23T08:29:52.101864Z","iopub.status.idle":"2025-10-23T08:29:52.122522Z","shell.execute_reply.started":"2025-10-23T08:29:52.101838Z","shell.execute_reply":"2025-10-23T08:29:52.121818Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ============================================================================\n# 5. POSITIONAL FEATURES\n# ============================================================================\n\nclass PositionalFeatures:\n    \"\"\"Extract position-specific features.\"\"\"\n    \n    @staticmethod\n    def extract_terminal_composition(sequence: str, n: int = 25) -> Dict[str, float]:\n        \"\"\"Extract amino acid composition of N-terminal and C-terminal regions.\"\"\"\n        features = {}\n        \n        # N-terminal\n        n_term = sequence[:n] if len(sequence) >= n else sequence\n        n_term_counter = Counter(n_term)\n        n_term_length = len(n_term)\n        \n        for aa in AminoAcidProperties.MOLECULAR_WEIGHT.keys():\n            features[f'n_term_{aa}'] = n_term_counter.get(aa, 0) / n_term_length if n_term_length > 0 else 0.0\n        \n        # C-terminal\n        c_term = sequence[-n:] if len(sequence) >= n else sequence\n        c_term_counter = Counter(c_term)\n        c_term_length = len(c_term)\n        \n        for aa in AminoAcidProperties.MOLECULAR_WEIGHT.keys():\n            features[f'c_term_{aa}'] = c_term_counter.get(aa, 0) / c_term_length if c_term_length > 0 else 0.0\n        \n        return features\n    \n    @staticmethod\n    def extract_region_properties(sequence: str, n_regions: int = 5) -> Dict[str, float]:\n        \"\"\"Divide sequence into regions and extract properties.\"\"\"\n        features = {}\n        \n        if len(sequence) == 0:\n            return features\n        \n        region_size = len(sequence) // n_regions\n        \n        for i in range(n_regions):\n            start = i * region_size\n            end = start + region_size if i < n_regions - 1 else len(sequence)\n            region = sequence[start:end]\n            \n            if len(region) > 0:\n                # Hydrophobicity\n                hydro = np.mean([AminoAcidProperties.HYDROPHOBICITY.get(aa, 0) for aa in region])\n                features[f'region_{i}_hydrophobicity'] = hydro\n                \n                # Charge\n                charge = np.mean([AminoAcidProperties.CHARGE.get(aa, 0) for aa in region])\n                features[f'region_{i}_charge'] = charge\n        \n        return features\n    \n    @staticmethod\n    def extract_position_specific_scoring(sequence: str, window: int = 5) -> Dict[str, float]:\n        \"\"\"Calculate position-specific scoring features using sliding window.\"\"\"\n        features = {}\n        \n        if len(sequence) < window:\n            return {\n                'pssm_hydro_mean': 0.0,\n                'pssm_hydro_std': 0.0,\n                'pssm_charge_mean': 0.0,\n                'pssm_charge_std': 0.0\n            }\n        \n        hydro_scores = []\n        charge_scores = []\n        \n        for i in range(len(sequence) - window + 1):\n            window_seq = sequence[i:i+window]\n            \n            hydro = np.mean([AminoAcidProperties.HYDROPHOBICITY.get(aa, 0) for aa in window_seq])\n            charge = np.sum([AminoAcidProperties.CHARGE.get(aa, 0) for aa in window_seq])\n            \n            hydro_scores.append(hydro)\n            charge_scores.append(charge)\n        \n        features['pssm_hydro_mean'] = np.mean(hydro_scores)\n        features['pssm_hydro_std'] = np.std(hydro_scores)\n        features['pssm_charge_mean'] = np.mean(charge_scores)\n        features['pssm_charge_std'] = np.std(charge_scores)\n        \n        return features","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-23T08:29:52.123275Z","iopub.execute_input":"2025-10-23T08:29:52.123511Z","iopub.status.idle":"2025-10-23T08:29:52.139843Z","shell.execute_reply.started":"2025-10-23T08:29:52.123491Z","shell.execute_reply":"2025-10-23T08:29:52.139156Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ============================================================================\n# 6. SEQUENCE PATTERNS\n# ============================================================================\n\nclass SequencePatterns:\n    \"\"\"Extract sequence pattern features.\"\"\"\n    \n    @staticmethod\n    def extract_repeats(sequence: str, min_length: int = 3, max_length: int = 6) -> Dict[str, float]:\n        \"\"\"Detect repeating patterns.\"\"\"\n        features = {}\n        \n        for length in range(min_length, max_length + 1):\n            repeat_count = 0\n            seen_patterns = set()\n            \n            for i in range(len(sequence) - length):\n                pattern = sequence[i:i+length]\n                # Check if pattern repeats immediately\n                if i + 2*length <= len(sequence):\n                    next_pattern = sequence[i+length:i+2*length]\n                    if pattern == next_pattern and pattern not in seen_patterns:\n                        repeat_count += 1\n                        seen_patterns.add(pattern)\n            \n            features[f'repeats_len_{length}'] = repeat_count\n        \n        features['total_repeats'] = sum(v for k, v in features.items() if k.startswith('repeats_len'))\n        \n        return features\n    \n    @staticmethod\n    def extract_motifs(sequence: str) -> Dict[str, int]:\n        \"\"\"Detect common protein motifs (simplified).\"\"\"\n        motifs = {\n            'signal_peptide': 0,  # Simplified: high hydrophobicity in N-term\n            'transmembrane': 0,   # Long hydrophobic stretch\n            'nuclear_localization': 0,  # K/R rich region\n            'glycosylation_site': 0  # N-X-S/T\n        }\n        \n        # Signal peptide (first 30 AA, high hydrophobicity)\n        if len(sequence) >= 30:\n            n_term = sequence[:30]\n            hydro_score = np.mean([AminoAcidProperties.HYDROPHOBICITY.get(aa, 0) for aa in n_term])\n            motifs['signal_peptide'] = 1 if hydro_score > 1.5 else 0\n        \n        # Transmembrane (20+ consecutive hydrophobic AA)\n        hydrophobic = ['A', 'V', 'L', 'I', 'M', 'F', 'W', 'P']\n        max_hydrophobic_stretch = 0\n        current_stretch = 0\n        \n        for aa in sequence:\n            if aa in hydrophobic:\n                current_stretch += 1\n                max_hydrophobic_stretch = max(max_hydrophobic_stretch, current_stretch)\n            else:\n                current_stretch = 0\n        \n        motifs['transmembrane'] = 1 if max_hydrophobic_stretch >= 20 else 0\n        \n        # Nuclear localization signal (K/R rich)\n        for i in range(len(sequence) - 4):\n            window = sequence[i:i+5]\n            kr_count = sum(1 for aa in window if aa in ['K', 'R'])\n            if kr_count >= 4:\n                motifs['nuclear_localization'] = 1\n                break\n        \n        # N-glycosylation site (N-X-S/T where X is not P)\n        for i in range(len(sequence) - 2):\n            if sequence[i] == 'N' and sequence[i+1] != 'P' and sequence[i+2] in ['S', 'T']:\n                motifs['glycosylation_site'] += 1\n        \n        return motifs\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-23T08:29:52.140473Z","iopub.execute_input":"2025-10-23T08:29:52.140735Z","iopub.status.idle":"2025-10-23T08:29:52.157832Z","shell.execute_reply.started":"2025-10-23T08:29:52.140718Z","shell.execute_reply":"2025-10-23T08:29:52.157163Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ============================================================================\n# 7. MAIN FEATURE EXTRACTOR\n# ============================================================================\n\nclass ProteinFeatureExtractor:\n    \"\"\"Main class for extracting all protein features.\"\"\"\n    \n    def __init__(self, include_dipeptides: bool = True, \n                 include_tripeptides: bool = False,\n                 tripeptide_top_n: int = 100):\n        \"\"\"\n        Initialize feature extractor.\n        \n        Args:\n            include_dipeptides: Whether to include dipeptide features (400 features)\n            include_tripeptides: Whether to include tripeptide features (can be many)\n            tripeptide_top_n: Number of top tripeptides to include\n        \"\"\"\n        self.include_dipeptides = include_dipeptides\n        self.include_tripeptides = include_tripeptides\n        self.tripeptide_top_n = tripeptide_top_n\n    \n    def extract_sequence_features(self, sequence: str) -> Dict[str, float]:\n        \"\"\"\n        Extract all features from a single protein sequence.\n        \n        Args:\n            sequence: Protein sequence string\n            \n        Returns:\n            Dictionary of features\n        \"\"\"\n        features = {}\n        \n        # 1. Basic features\n        features.update(BasicSequenceFeatures.extract_length_features(sequence))\n        features.update(BasicSequenceFeatures.extract_molecular_weight(sequence))\n        features.update(BasicSequenceFeatures.extract_composition(sequence))\n        features.update(BasicSequenceFeatures.extract_group_composition(sequence))\n        \n        # 2. Physicochemical properties\n        features.update(PhysicochemicalFeatures.extract_all_properties(sequence))\n        features.update(PhysicochemicalFeatures.extract_isoelectric_point(sequence))\n        \n        # 3. K-mers (optional, can be large)\n        if self.include_dipeptides:\n            features.update(KmerFeatures.extract_dipeptide_composition(sequence))\n        \n        if self.include_tripeptides:\n            features.update(KmerFeatures.extract_tripeptide_composition(\n                sequence, top_n=self.tripeptide_top_n))\n        \n        # 4. Positional features\n        features.update(PositionalFeatures.extract_terminal_composition(sequence, n=25))\n        features.update(PositionalFeatures.extract_region_properties(sequence, n_regions=5))\n        features.update(PositionalFeatures.extract_position_specific_scoring(sequence))\n        \n        # 5. Sequence patterns\n        features.update(SequencePatterns.extract_repeats(sequence))\n        features.update(SequencePatterns.extract_motifs(sequence))\n        \n        return features\n    \n    def extract_batch_features(self, sequences: Dict[str, str],  \n                              verbose: bool = True) -> pd.DataFrame:\n        \"\"\"\n        Extract features for multiple sequences.\n        \n        Args:\n            sequences: Dictionary mapping protein_id to sequence\n            verbose: Whether to print progress\n            \n        Returns:\n            DataFrame with protein_id as index and features as columns\n        \"\"\"\n        if verbose:\n            print(f\"Extracting features for {len(sequences):,} sequences...\")\n        \n        features_list = []\n        protein_ids = []\n        \n        for i, (protein_id, sequence) in enumerate(sequences.items()):\n            if verbose and (i + 1) % 10000 == 0:\n                print(f\"  Processed {i+1:,} / {len(sequences):,} sequences...\")\n            \n            try:\n                features = self.extract_sequence_features(sequence)\n                features_list.append(features)\n                protein_ids.append(protein_id)\n            except Exception as e:\n                if verbose:\n                    print(f\"  Error processing {protein_id}: {str(e)}\")\n                continue\n        \n        df = pd.DataFrame(features_list, index=protein_ids)\n        \n        if verbose:\n            print(f\"✓ Feature extraction complete!\")\n            print(f\"  Total proteins: {len(df):,}\")\n            print(f\"  Total features: {len(df.columns):,}\")\n            print(f\"  Feature types:\")\n            self._print_feature_summary(df)\n        \n        return df\n    \n    def _print_feature_summary(self, df: pd.DataFrame):\n        \"\"\"Print summary of extracted features.\"\"\"\n        feature_types = {\n            'length': sum(1 for c in df.columns if 'length' in c),\n            'composition': sum(1 for c in df.columns if 'comp_' in c),\n            'group': sum(1 for c in df.columns if 'group_' in c),\n            'physicochemical': sum(1 for c in df.columns if any(x in c for x in ['hydro', 'charge', 'volume', 'polar', 'aromatic'])),\n            'kmer': sum(1 for c in df.columns if 'kmer_' in c),\n            'terminal': sum(1 for c in df.columns if '_term_' in c),\n            'regional': sum(1 for c in df.columns if 'region_' in c),\n            'pattern': sum(1 for c in df.columns if any(x in c for x in ['repeat', 'signal', 'transmembrane', 'nuclear', 'glycosylation'])),\n            'other': 0\n        }\n        \n        feature_types['other'] = len(df.columns) - sum(feature_types.values())\n        \n        for feat_type, count in feature_types.items():\n            if count > 0:\n                print(f\"    {feat_type.capitalize()}: {count}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-23T08:29:52.158548Z","iopub.execute_input":"2025-10-23T08:29:52.158864Z","iopub.status.idle":"2025-10-23T08:29:52.226415Z","shell.execute_reply.started":"2025-10-23T08:29:52.158842Z","shell.execute_reply":"2025-10-23T08:29:52.225771Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom typing import Dict, List, Optional\nfrom sklearn.decomposition import PCA\nfrom sklearn.manifold import TSNE\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Set style\nsns.set_style(\"whitegrid\")\nplt.rcParams['figure.figsize'] = (14, 6)\n\n\n# ============================================================================\n# FEATURE VISUALIZATION CLASS\n# ============================================================================\n\nclass FeatureVisualizer:\n    \"\"\"Visualize feature engineering results.\"\"\"\n    \n    def __init__(self):\n        \"\"\"Initialize feature visualizer.\"\"\"\n        self.feature_types = {\n            'length': 'Length Features',\n            'comp_': 'Composition Features',\n            'group_': 'Group Composition',\n            'hydro': 'Hydrophobicity',\n            'charge': 'Charge',\n            'volume': 'Volume',\n            'polar': 'Polarity',\n            'aromatic': 'Aromaticity',\n            'kmer_2_': 'Dipeptides',\n            'kmer_3_': 'Tripeptides',\n            'n_term_': 'N-terminal',\n            'c_term_': 'C-terminal',\n            'region_': 'Regional',\n            'pssm_': 'PSSM',\n            'repeat': 'Repeats',\n            'go_': 'GO Features',\n            'esm': 'ESM Embeddings',\n            'prot': 'ProtT5 Embeddings'\n        }\n    \n    def categorize_features(self, feature_names: List[str]) -> Dict[str, List[str]]:\n        \"\"\"Categorize features by type.\"\"\"\n        categories = {name: [] for name in self.feature_types.values()}\n        categories['Other'] = []\n        \n        for feature in feature_names:\n            categorized = False\n            for pattern, category in self.feature_types.items():\n                if pattern in feature:\n                    categories[category].append(feature)\n                    categorized = True\n                    break\n            \n            if not categorized:\n                categories['Other'].append(feature)\n        \n        # Remove empty categories\n        return {k: v for k, v in categories.items() if len(v) > 0}\n    \n    def plot_feature_category_breakdown(self, features_df: pd.DataFrame,\n                                       save_path: str = None):\n        \"\"\"\n        Plot breakdown of features by category.\n        \n        Args:\n            features_df: DataFrame with extracted features\n            save_path: Optional path to save figure\n        \"\"\"\n        categories = self.categorize_features(features_df.columns.tolist())\n        \n        # Count features per category\n        category_counts = {k: len(v) for k, v in categories.items()}\n        sorted_categories = sorted(category_counts.items(), \n                                  key=lambda x: x[1], reverse=True)\n        \n        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n        \n        # Bar chart\n        names, counts = zip(*sorted_categories)\n        colors = plt.cm.Set3(np.linspace(0, 1, len(names)))\n        \n        bars = ax1.bar(range(len(names)), counts, color=colors, \n                      alpha=0.8, edgecolor='black')\n        ax1.set_xticks(range(len(names)))\n        ax1.set_xticklabels(names, rotation=45, ha='right')\n        ax1.set_ylabel('Number of Features', fontsize=12, fontweight='bold')\n        ax1.set_title('Feature Count by Category', fontsize=14, fontweight='bold')\n        ax1.grid(axis='y', alpha=0.3)\n        \n        # Add value labels\n        for bar, count in zip(bars, counts):\n            height = bar.get_height()\n            ax1.text(bar.get_x() + bar.get_width()/2., height,\n                    f'{count}', ha='center', va='bottom', fontweight='bold')\n        \n        # Pie chart\n        ax2.pie(counts, labels=names, autopct='%1.1f%%', \n               colors=colors, startangle=90)\n        ax2.set_title('Feature Distribution', fontsize=14, fontweight='bold')\n        \n        plt.tight_layout()\n        \n        if save_path:\n            plt.savefig(save_path, dpi=300, bbox_inches='tight')\n        \n        plt.show()\n        \n        # Print summary\n        print(f\"\\n{'='*60}\")\n        print(f\"FEATURE CATEGORY BREAKDOWN\")\n        print(f\"{'='*60}\")\n        print(f\"Total features: {len(features_df.columns):,}\")\n        for name, count in sorted_categories:\n            print(f\"  {name}: {count:,} ({count/len(features_df.columns)*100:.1f}%)\")\n        print(f\"{'='*60}\\n\")\n    \n    def plot_feature_distributions(self, features_df: pd.DataFrame,\n                                  sample_features: int = 16,\n                                  save_path: str = None):\n        \"\"\"\n        Plot distribution of sample features.\n        \n        Args:\n            features_df: DataFrame with features\n            sample_features: Number of features to visualize\n            save_path: Optional path to save figure\n        \"\"\"\n        # Sample features from different categories\n        categories = self.categorize_features(features_df.columns.tolist())\n        sampled_features = []\n        \n        features_per_category = max(1, sample_features // len(categories))\n        \n        for category, feature_list in categories.items():\n            n_sample = min(features_per_category, len(feature_list))\n            sampled_features.extend(np.random.choice(feature_list, n_sample, replace=False))\n        \n        sampled_features = sampled_features[:sample_features]\n        \n        # Create subplots\n        n_cols = 4\n        n_rows = (len(sampled_features) + n_cols - 1) // n_cols\n        \n        fig, axes = plt.subplots(n_rows, n_cols, figsize=(16, n_rows * 3))\n        axes = axes.flatten() if n_rows > 1 else [axes] if n_cols == 1 else axes\n        \n        for idx, feature in enumerate(sampled_features):\n            ax = axes[idx]\n            \n            data = features_df[feature].dropna()\n            \n            # Plot histogram\n            ax.hist(data, bins=30, color='steelblue', alpha=0.7, edgecolor='black')\n            \n            # Add mean line\n            mean_val = data.mean()\n            ax.axvline(mean_val, color='red', linestyle='--', linewidth=2,\n                      label=f'Mean: {mean_val:.3f}')\n            \n            # Formatting\n            ax.set_title(feature[:30] + '...' if len(feature) > 30 else feature,\n                        fontsize=9, fontweight='bold')\n            ax.set_xlabel('Value', fontsize=8)\n            ax.set_ylabel('Frequency', fontsize=8)\n            ax.legend(fontsize=7)\n            ax.grid(alpha=0.3)\n        \n        # Hide unused subplots\n        for idx in range(len(sampled_features), len(axes)):\n            axes[idx].axis('off')\n        \n        plt.suptitle('Sample Feature Distributions', fontsize=16, fontweight='bold', y=1.00)\n        plt.tight_layout()\n        \n        if save_path:\n            plt.savefig(save_path, dpi=300, bbox_inches='tight')\n        \n        plt.show()\n    \n    def plot_feature_correlation(self, features_df: pd.DataFrame,\n                                sample_size: int = 50,\n                                method: str = 'pearson',\n                                save_path: str = None):\n        \"\"\"\n        Plot correlation heatmap for sample of features.\n        \n        Args:\n            features_df: DataFrame with features\n            sample_size: Number of features to include in correlation\n            method: Correlation method ('pearson', 'spearman')\n            save_path: Optional path to save figure\n        \"\"\"\n        # Ensure we only have numeric columns\n        numeric_features = features_df.select_dtypes(include=[np.number])\n        \n        if len(numeric_features.columns) == 0:\n            print(\"⚠️  No numeric features found for correlation analysis\")\n            return\n        \n        # Sample features\n        if len(numeric_features.columns) > sample_size:\n            # Sample from different categories\n            categories = self.categorize_features(numeric_features.columns.tolist())\n            sampled_features = []\n            \n            features_per_category = max(1, sample_size // len(categories))\n            \n            for category, feature_list in categories.items():\n                n_sample = min(features_per_category, len(feature_list))\n                sampled_features.extend(np.random.choice(feature_list, n_sample, replace=False))\n            \n            sampled_features = sampled_features[:sample_size]\n            features_subset = numeric_features[sampled_features]\n        else:\n            features_subset = numeric_features\n        \n        # Remove any remaining non-numeric or handle NaN\n        features_subset = features_subset.fillna(0)\n        \n        # Calculate correlation\n        corr_matrix = features_subset.corr(method=method)\n        \n        # Plot\n        fig, ax = plt.subplots(figsize=(14, 12))\n        \n        # Create mask for upper triangle\n        mask = np.triu(np.ones_like(corr_matrix, dtype=bool), k=1)\n        \n        # Plot heatmap\n        sns.heatmap(corr_matrix, mask=mask, cmap='RdBu_r', center=0,\n                   square=True, linewidths=0.5, cbar_kws={\"shrink\": 0.8},\n                   vmin=-1, vmax=1, ax=ax)\n        \n        ax.set_title(f'Feature Correlation Heatmap ({method.capitalize()})\\n'\n                    f'Sample of {len(features_subset.columns)} features',\n                    fontsize=14, fontweight='bold', pad=20)\n        \n        plt.tight_layout()\n        \n        if save_path:\n            plt.savefig(save_path, dpi=300, bbox_inches='tight')\n        \n        plt.show()\n        \n        # Print high correlations\n        print(f\"\\n{'='*60}\")\n        print(f\"HIGH CORRELATIONS (|r| > 0.8)\")\n        print(f\"{'='*60}\")\n        \n        high_corr = []\n        for i in range(len(corr_matrix.columns)):\n            for j in range(i+1, len(corr_matrix.columns)):\n                if abs(corr_matrix.iloc[i, j]) > 0.8:\n                    high_corr.append((\n                        corr_matrix.columns[i],\n                        corr_matrix.columns[j],\n                        corr_matrix.iloc[i, j]\n                    ))\n        \n        if high_corr:\n            high_corr.sort(key=lambda x: abs(x[2]), reverse=True)\n            for feat1, feat2, corr_val in high_corr[:10]:\n                print(f\"  {feat1[:30]:<30} ↔ {feat2[:30]:<30}: {corr_val:>6.3f}\")\n        else:\n            print(\"  No high correlations found in sample\")\n        print(f\"{'='*60}\\n\")\n    \n    def plot_feature_statistics(self, features_df: pd.DataFrame,\n                               save_path: str = None):\n        \"\"\"\n        Plot summary statistics for features.\n        \n        Args:\n            features_df: DataFrame with features\n            save_path: Optional path to save figure\n        \"\"\"\n        # Select only numeric columns\n        numeric_features = features_df.select_dtypes(include=[np.number])\n        \n        if len(numeric_features.columns) == 0:\n            print(\"⚠️  No numeric features found for statistics\")\n            return\n        \n        # Calculate statistics\n        stats = pd.DataFrame({\n            'mean': numeric_features.mean(),\n            'std': numeric_features.std(),\n            'min': numeric_features.min(),\n            'max': numeric_features.max(),\n            'variance': numeric_features.var(),\n            'zeros': (numeric_features == 0).sum() / len(numeric_features)\n        })\n        \n        # Create subplots (2x3 = 6 plots)\n        fig, axes = plt.subplots(2, 3, figsize=(16, 10))\n        axes = axes.flatten()\n        \n        # Plot each statistic (only first 6)\n        for idx, (stat_name, stat_data) in enumerate(stats.items()):\n            if idx >= 6:  # Only plot first 6 statistics\n                break\n                \n            ax = axes[idx]\n            \n            # Remove outliers for better visualization\n            q1, q3 = stat_data.quantile([0.25, 0.75])\n            iqr = q3 - q1\n            lower = q1 - 1.5 * iqr\n            upper = q3 + 1.5 * iqr\n            filtered_data = stat_data[(stat_data >= lower) & (stat_data <= upper)]\n            \n            if len(filtered_data) > 0:\n                ax.hist(filtered_data, bins=30, color='steelblue', \n                       alpha=0.7, edgecolor='black')\n                ax.axvline(stat_data.median(), color='red', linestyle='--',\n                          linewidth=2, label=f'Median: {stat_data.median():.3f}')\n            \n            ax.set_title(f'Feature {stat_name.capitalize()}', \n                        fontsize=12, fontweight='bold')\n            ax.set_xlabel('Value', fontsize=10)\n            ax.set_ylabel('Number of Features', fontsize=10)\n            ax.legend(fontsize=9)\n            ax.grid(alpha=0.3)\n        \n        plt.suptitle('Feature Statistics Distribution', \n                    fontsize=16, fontweight='bold')\n        plt.tight_layout()\n        \n        if save_path:\n            plt.savefig(save_path, dpi=300, bbox_inches='tight')\n        \n        plt.show()\n        \n        # Calculate missing values separately for summary\n        missing_stats = numeric_features.isnull().sum() / len(numeric_features)\n        \n        # Print summary\n        print(f\"\\n{'='*60}\")\n        print(f\"FEATURE STATISTICS SUMMARY\")\n        print(f\"{'='*60}\")\n        print(f\"Total features: {len(numeric_features.columns):,}\")\n        print(f\"Total proteins: {len(numeric_features):,}\")\n        print(f\"\\nFeature Statistics:\")\n        print(f\"  Mean of means: {stats['mean'].mean():.4f}\")\n        print(f\"  Mean of std devs: {stats['std'].mean():.4f}\")\n        print(f\"  Features with >50% zeros: {(stats['zeros'] > 0.5).sum()}\")\n        print(f\"  Features with missing values: {(missing_stats > 0).sum()}\")\n        \n        # Low variance features\n        low_var = (stats['variance'] < 0.01).sum()\n        print(f\"  Low variance features (<0.01): {low_var}\")\n        print(f\"{'='*60}\\n\")\n    \n    def plot_dimensionality_reduction(self, features_df: pd.DataFrame,\n                                     labels: Optional[pd.Series] = None,\n                                     method: str = 'pca',\n                                     n_samples: int = 5000,\n                                     save_path: str = None):\n        \"\"\"\n        Visualize features in 2D using dimensionality reduction.\n        \n        Args:\n            features_df: DataFrame with features\n            labels: Optional labels for coloring (e.g., number of GO terms)\n            method: 'pca' or 'tsne'\n            n_samples: Number of samples to plot (for performance)\n            save_path: Optional path to save figure\n        \"\"\"\n        # Select only numeric columns\n        numeric_features = features_df.select_dtypes(include=[np.number])\n        \n        if len(numeric_features.columns) == 0:\n            print(\"⚠️  No numeric features found for dimensionality reduction\")\n            return\n        \n        # Sample if too many proteins\n        if len(numeric_features) > n_samples:\n            sample_idx = np.random.choice(len(numeric_features), n_samples, replace=False)\n            features_sample = numeric_features.iloc[sample_idx]\n            labels_sample = labels.iloc[sample_idx] if labels is not None else None\n        else:\n            features_sample = numeric_features\n            labels_sample = labels\n        \n        # Handle missing values\n        features_clean = features_sample.fillna(0)\n        \n        # Check for infinite values\n        features_clean = features_clean.replace([np.inf, -np.inf], 0)\n        \n        # Apply dimensionality reduction\n        if method.lower() == 'pca':\n            reducer = PCA(n_components=2, random_state=42)\n            reduced = reducer.fit_transform(features_clean)\n            title = f'PCA Visualization of Features\\n' \\\n                   f'Explained Variance: {reducer.explained_variance_ratio_.sum():.2%}'\n        else:  # tsne\n            reducer = TSNE(n_components=2, random_state=42, perplexity=30)\n            reduced = reducer.fit_transform(features_clean)\n            title = 't-SNE Visualization of Features'\n        \n        # Plot\n        fig, ax = plt.subplots(figsize=(12, 10))\n        \n        if labels_sample is not None:\n            scatter = ax.scatter(reduced[:, 0], reduced[:, 1],\n                               c=labels_sample, cmap='viridis',\n                               alpha=0.6, s=30, edgecolors='black', linewidth=0.5)\n            cbar = plt.colorbar(scatter, ax=ax)\n            cbar.set_label('Label Value', rotation=270, labelpad=20, fontsize=11)\n        else:\n            ax.scatter(reduced[:, 0], reduced[:, 1],\n                      alpha=0.6, s=30, color='steelblue',\n                      edgecolors='black', linewidth=0.5)\n        \n        ax.set_xlabel(f'Component 1', fontsize=12, fontweight='bold')\n        ax.set_ylabel(f'Component 2', fontsize=12, fontweight='bold')\n        ax.set_title(title, fontsize=14, fontweight='bold', pad=20)\n        ax.grid(alpha=0.3)\n        \n        plt.tight_layout()\n        \n        if save_path:\n            plt.savefig(save_path, dpi=300, bbox_inches='tight')\n        \n        plt.show()\n        \n        if method.lower() == 'pca':\n            print(f\"\\n{'='*60}\")\n            print(f\"PCA ANALYSIS\")\n            print(f\"{'='*60}\")\n            print(f\"Explained variance ratio:\")\n            print(f\"  PC1: {reducer.explained_variance_ratio_[0]:.4f}\")\n            print(f\"  PC2: {reducer.explained_variance_ratio_[1]:.4f}\")\n            print(f\"  Total: {reducer.explained_variance_ratio_.sum():.4f}\")\n            print(f\"{'='*60}\\n\")\n    \n    def plot_feature_importance(self, features_df: pd.DataFrame,\n                               importance_values: np.ndarray,\n                               top_n: int = 20,\n                               save_path: str = None):\n        \"\"\"\n        Plot feature importance from a trained model.\n        \n        Args:\n            features_df: DataFrame with features\n            importance_values: Array of importance values from model\n            top_n: Number of top features to show\n            save_path: Optional path to save figure\n        \"\"\"\n        # Create importance DataFrame\n        importance_df = pd.DataFrame({\n            'feature': features_df.columns,\n            'importance': importance_values\n        }).sort_values('importance', ascending=False)\n        \n        # Get top features\n        top_features = importance_df.head(top_n)\n        \n        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 8))\n        \n        # Horizontal bar chart\n        colors = plt.cm.viridis(np.linspace(0, 1, len(top_features)))\n        \n        y_pos = np.arange(len(top_features))\n        ax1.barh(y_pos, top_features['importance'], color=colors,\n                alpha=0.8, edgecolor='black')\n        ax1.set_yticks(y_pos)\n        ax1.set_yticklabels(top_features['feature'], fontsize=9)\n        ax1.set_xlabel('Importance', fontsize=12, fontweight='bold')\n        ax1.set_title(f'Top {top_n} Most Important Features',\n                     fontsize=14, fontweight='bold')\n        ax1.invert_yaxis()\n        ax1.grid(axis='x', alpha=0.3)\n        \n        # Cumulative importance\n        ax2.plot(range(1, len(importance_df) + 1),\n                np.cumsum(importance_df['importance']) / importance_df['importance'].sum(),\n                linewidth=2, color='steelblue')\n        ax2.axhline(0.8, color='red', linestyle='--', linewidth=2,\n                   label='80% cumulative importance')\n        ax2.axhline(0.95, color='orange', linestyle='--', linewidth=2,\n                   label='95% cumulative importance')\n        \n        ax2.set_xlabel('Number of Features', fontsize=12, fontweight='bold')\n        ax2.set_ylabel('Cumulative Importance', fontsize=12, fontweight='bold')\n        ax2.set_title('Cumulative Feature Importance',\n                     fontsize=14, fontweight='bold')\n        ax2.legend(fontsize=10)\n        ax2.grid(alpha=0.3)\n        \n        plt.tight_layout()\n        \n        if save_path:\n            plt.savefig(save_path, dpi=300, bbox_inches='tight')\n        \n        plt.show()\n        \n        # Print summary\n        n_80 = np.where(np.cumsum(importance_df['importance']) / \n                       importance_df['importance'].sum() >= 0.8)[0][0] + 1\n        n_95 = np.where(np.cumsum(importance_df['importance']) / \n                       importance_df['importance'].sum() >= 0.95)[0][0] + 1\n        \n        print(f\"\\n{'='*60}\")\n        print(f\"FEATURE IMPORTANCE ANALYSIS\")\n        print(f\"{'='*60}\")\n        print(f\"Total features: {len(features_df.columns):,}\")\n        print(f\"Features for 80% importance: {n_80:,}\")\n        print(f\"Features for 95% importance: {n_95:,}\")\n        print(f\"\\nTop 10 Features:\")\n        for i, row in importance_df.head(10).iterrows():\n            print(f\"  {row['feature'][:50]:<50}: {row['importance']:.6f}\")\n        print(f\"{'='*60}\\n\")\n    \n    def plot_all_feature_analysis(self, features_df: pd.DataFrame,\n                                  labels: Optional[pd.Series] = None,\n                                  importance_values: Optional[np.ndarray] = None,\n                                  save_dir: str = None):\n        \"\"\"\n        Generate all feature engineering visualizations.\n        \n        Args:\n            features_df: DataFrame with all features\n            labels: Optional labels for dimensionality reduction\n            importance_values: Optional feature importance from model\n            save_dir: Optional directory to save all figures\n        \"\"\"\n        import os\n        \n        if save_dir:\n            os.makedirs(save_dir, exist_ok=True)\n        \n        print(\"\\n\" + \"=\"*70)\n        print(\" \"*15 + \"FEATURE ENGINEERING VISUALIZATIONS\")\n        print(\"=\"*70 + \"\\n\")\n        \n        # 1. Feature category breakdown\n        print(\"1️⃣  Generating feature category breakdown...\")\n        self.plot_feature_category_breakdown(\n            features_df,\n            save_path=f\"{save_dir}/01_feature_categories.png\" if save_dir else None\n        )\n        \n        # 2. Feature distributions\n        print(\"\\n2️⃣  Generating feature distributions...\")\n        self.plot_feature_distributions(\n            features_df,\n            sample_features=16,\n            save_path=f\"{save_dir}/02_feature_distributions.png\" if save_dir else None\n        )\n        \n        # 3. Feature correlation\n        print(\"\\n3️⃣  Generating correlation heatmap...\")\n        self.plot_feature_correlation(\n            features_df,\n            sample_size=50,\n            save_path=f\"{save_dir}/03_feature_correlation.png\" if save_dir else None\n        )\n        \n        # 4. Feature statistics\n        print(\"\\n4️⃣  Generating feature statistics...\")\n        self.plot_feature_statistics(\n            features_df,\n            save_path=f\"{save_dir}/04_feature_statistics.png\" if save_dir else None\n        )\n        \n        # 5. Dimensionality reduction\n        print(\"\\n5️⃣  Generating dimensionality reduction visualization...\")\n        self.plot_dimensionality_reduction(\n            features_df,\n            labels=labels,\n            method='pca',\n            save_path=f\"{save_dir}/05_pca_visualization.png\" if save_dir else None\n        )\n        \n        # 6. Feature importance (if provided)\n        if importance_values is not None:\n            print(\"\\n6️⃣  Generating feature importance analysis...\")\n            self.plot_feature_importance(\n                features_df,\n                importance_values,\n                save_path=f\"{save_dir}/06_feature_importance.png\" if save_dir else None\n            )\n        \n        print(\"\\n\" + \"=\"*70)\n        print(\" \"*20 + \"✓ ALL VISUALIZATIONS COMPLETE\")\n        if save_dir:\n            print(f\" \"*20 + f\"Saved to: {save_dir}/\")\n        print(\"=\"*70 + \"\\n\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-23T08:29:52.228613Z","iopub.execute_input":"2025-10-23T08:29:52.228849Z","iopub.status.idle":"2025-10-23T08:29:53.423551Z","shell.execute_reply.started":"2025-10-23T08:29:52.228827Z","shell.execute_reply":"2025-10-23T08:29:53.422703Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ============================================================================\n# 8. USAGE\n# ============================================================================\n\nif __name__ == \"__main__\":    \n    # Load sequences\n    sequences = {}\n    for record in SeqIO.parse('/kaggle/input/cafa-6-protein-function-prediction/Train/train_sequences.fasta', 'fasta'):\n        protein_id = record.id.split('|')[1]\n        sequences[protein_id] = str(record.seq)\n    \n    # Extract features\n    extractor = ProteinFeatureExtractor(\n        include_dipeptides=True,\n        include_tripeptides=False\n    )\n    \n    features_df = extractor.extract_batch_features(sequences, verbose=True)\n    \n    # Save features\n    features_df.to_csv('/kaggle/working/protein_features.csv')\n    \n   \n    # # Extract features for single sequence\n    # single_features = extractor.extract_sequence_features('MTKPTQVLVRLEQVM')\n    # print(f\"Extracted {len(single_features)} features\")\n    \n    ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-23T08:29:53.424372Z","iopub.execute_input":"2025-10-23T08:29:53.424742Z","iopub.status.idle":"2025-10-23T08:45:44.048211Z","shell.execute_reply.started":"2025-10-23T08:29:53.424719Z","shell.execute_reply":"2025-10-23T08:45:44.047604Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Load features\nfeatures_df = pd.read_csv('/kaggle/working/protein_features.csv', index_col=0)\n\n# Initialize visualizer\nviz = FeatureVisualizer()\n\n# Generate all visualizations\nviz.plot_all_feature_analysis(\n    features_df,\n    labels=None,  # or provide labels for coloring\n    importance_values=None,  # or provide from trained model\n    save_dir='/kaggle/working/feature_visualizations'\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-23T08:45:44.048955Z","iopub.execute_input":"2025-10-23T08:45:44.049203Z","iopub.status.idle":"2025-10-23T08:46:08.963009Z","shell.execute_reply.started":"2025-10-23T08:45:44.049181Z","shell.execute_reply":"2025-10-23T08:46:08.962217Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}