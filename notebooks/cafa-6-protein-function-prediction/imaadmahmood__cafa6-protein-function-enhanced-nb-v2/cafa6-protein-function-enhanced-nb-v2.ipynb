{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":116062,"databundleVersionId":14084779,"sourceType":"competition"},{"sourceId":517313,"sourceType":"modelInstanceVersion","modelInstanceId":407954,"modelId":425816}],"dockerImageVersionId":31154,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-11-02T20:39:52.644696Z","iopub.execute_input":"2025-11-02T20:39:52.645134Z","iopub.status.idle":"2025-11-02T20:39:52.659645Z","shell.execute_reply.started":"2025-11-02T20:39:52.645107Z","shell.execute_reply":"2025-11-02T20:39:52.658747Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\"\"\"\nCAFA-6 COMPLETE ENHANCED MODEL\nTarget: 0.225 → 0.35+\n\nKey improvements:\n1. ESM-2 embeddings (+0.05-0.08)\n2. Per-ontology models (+0.02-0.03)\n3. Per-term threshold optimization (+0.02-0.03)\n4. Dynamic CAFA5 ensemble (+0.01-0.02)\n\"\"\"\n\nimport os, gc, time, warnings\nimport numpy as np\nimport pandas as pd\nfrom collections import defaultdict, Counter\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MultiLabelBinarizer, StandardScaler\nimport tensorflow as tf\nfrom tensorflow.keras import layers, models, callbacks\nimport keras_hub\n\nwarnings.filterwarnings('ignore')\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n\nprint(\"=\"*80)\nprint(\"CAFA-6 ENHANCED MODEL - TARGET 0.35+\")\nprint(\"=\"*80)\n\n# =============================================================================\n# CONFIG\n# =============================================================================\nCONFIG = {\n    'BASE': \"/kaggle/input/cafa-6-protein-function-prediction\",\n    'CAFA5_PATH': \"/kaggle/input/cafa5-055923-pred/submission.tsv\",\n    'OUTPUT': \"/kaggle/working/submission.tsv\",\n    \n    'MAX_SEQ_LEN': 1024,\n    'BATCH_SIZE': 16,\n    'EPOCHS': 20,\n    'LR': 2e-4,\n    'LABELS_PER_ONT': {'F': 800, 'P': 1200, 'C': 600},\n    \n    'USE_ESM2': True,\n    'ESM_BATCH': 4,\n    'THRESHOLD_STEPS': 150,\n    'TOP_K_PRED': 800,\n    \n    'SEED': 42,\n}\n\nnp.random.seed(CONFIG['SEED'])\ntf.random.set_seed(CONFIG['SEED'])\n\nstart = time.time()\ndef log(msg): print(f\"[{time.time()-start:7.1f}s] {msg}\")\n\n# =============================================================================\n# LOAD ESM-2\n# =============================================================================\nlog(\"Loading ESM-2...\")\ntry:\n    esm_backbone = keras_hub.models.ESMBackbone.from_preset(\"esm2_t6_8m_ur50d\")\n    esm_preprocessor = keras_hub.models.ESMPreprocessor.from_preset(\"esm2_t6_8m_ur50d\")\n    log(\"✓ ESM-2 loaded (320-dim embeddings)\")\n    HAS_ESM2 = True\nexcept Exception as e:\n    log(f\"✗ ESM-2 failed: {e}\")\n    HAS_ESM2 = False\n    CONFIG['USE_ESM2'] = False\n\n# =============================================================================\n# LOAD DATA\n# =============================================================================\nlog(\"Loading data...\")\n\ndef read_fasta(path):\n    seqs = {}\n    pid, seq = None, []\n    with open(path) as f:\n        for line in f:\n            line = line.strip()\n            if line.startswith('>'):\n                if pid:\n                    seqs[pid] = ''.join(seq)\n                parts = line[1:].split('|')\n                pid = parts[1] if len(parts) > 1 else line[1:].split()[0]\n                seq = []\n            else:\n                seq.append(line)\n        if pid:\n            seqs[pid] = ''.join(seq)\n    return seqs\n\ntrain_seqs = read_fasta(f\"{CONFIG['BASE']}/Train/train_sequences.fasta\")\ntest_seqs = read_fasta(f\"{CONFIG['BASE']}/Test/testsuperset.fasta\")\n\ndf_terms = pd.read_csv(f\"{CONFIG['BASE']}/Train/train_terms.tsv\", sep='\\t', header=None,\n                       names=['protein_id', 'go_term', 'ontology'])\ndf_terms = df_terms[df_terms['protein_id'] != 'EntryID']\n\ndf_ia = pd.read_csv(f\"{CONFIG['BASE']}/IA.tsv\", sep='\\t', header=None, names=['go_term', 'ia'])\nia_weights = dict(zip(df_ia['go_term'], df_ia['ia']))\n\nlog(f\"Train: {len(train_seqs):,}, Test: {len(test_seqs):,}, Annotations: {len(df_terms):,}\")\n\n# =============================================================================\n# GO HIERARCHY\n# =============================================================================\nlog(\"Parsing GO...\")\n\nparents = defaultdict(set)\nterm_ontology = {}\n\nwith open(f\"{CONFIG['BASE']}/Train/go-basic.obo\") as f:\n    cur_id = None\n    for line in f:\n        line = line.strip()\n        if line == \"[Term]\":\n            cur_id = None\n        elif line.startswith(\"id: \"):\n            cur_id = line.split(\"id: \")[1]\n        elif line.startswith(\"namespace: \") and cur_id:\n            ns = line.split(\"namespace: \")[1]\n            term_ontology[cur_id] = {'molecular_function': 'F', 'biological_process': 'P', \n                                     'cellular_component': 'C'}.get(ns)\n        elif line.startswith(\"is_a: \") and cur_id:\n            parents[cur_id].add(line.split()[1])\n        elif line.startswith(\"relationship: part_of \") and cur_id:\n            parts = line.split()\n            if len(parts) >= 3:\n                parents[cur_id].add(parts[2])\n\ndef get_ancestors(term):\n    anc = set()\n    queue = [term]\n    while queue:\n        t = queue.pop(0)\n        for p in parents.get(t, []):\n            if p not in anc:\n                anc.add(p)\n                queue.append(p)\n    return anc\n\n# =============================================================================\n# PROPAGATE & SELECT LABELS\n# =============================================================================\nlog(\"Propagating labels...\")\n\nprotein_to_terms = defaultdict(set)\nfor _, row in df_terms.iterrows():\n    protein_to_terms[row['protein_id']].add(row['go_term'])\n\npropagated = {}\nfor p, terms in protein_to_terms.items():\n    all_t = set(terms)\n    for t in terms:\n        all_t.update(get_ancestors(t))\n    propagated[p] = all_t\n\nterm_counts = Counter()\nfor terms in propagated.values():\n    term_counts.update(terms)\n\nlog(\"Selecting labels per ontology...\")\nontology_terms = {'F': {}, 'P': {}, 'C': {}}\nfor term, count in term_counts.items():\n    ont = term_ontology.get(term)\n    if ont and count >= 3:\n        ontology_terms[ont][term] = count\n\nselected_terms = {}\nfor ont in ['F', 'P', 'C']:\n    sorted_t = sorted(ontology_terms[ont].items(), key=lambda x: x[1], reverse=True)\n    selected_terms[ont] = [t for t, c in sorted_t[:CONFIG['LABELS_PER_ONT'][ont]]]\n    log(f\"  {ont}: {len(selected_terms[ont])} labels\")\n\nall_terms = selected_terms['F'] + selected_terms['P'] + selected_terms['C']\n\nvalid_prots = [p for p in propagated.keys() if p in train_seqs]\nfiltered = {p: [t for t in propagated[p] if t in all_terms] for p in valid_prots}\nvalid_prots = [p for p in valid_prots if filtered[p]]\n\nlog(f\"Training proteins: {len(valid_prots):,}\")\n\n# =============================================================================\n# EXTRACT ESM-2 EMBEDDINGS\n# =============================================================================\ndef extract_esm2(protein_ids, seqs, batch_size=4):\n    embs = []\n    for i in range(0, len(protein_ids), batch_size):\n        batch = protein_ids[i:i+batch_size]\n        batch_seq = [seqs[p][:CONFIG['MAX_SEQ_LEN']] for p in batch]\n        \n        inputs = esm_preprocessor(batch_seq)\n        outputs = esm_backbone(inputs)\n        batch_emb = tf.reduce_mean(outputs, axis=1).numpy()\n        embs.append(batch_emb)\n        \n        if (i // batch_size) % 200 == 0:\n            log(f\"    ESM-2: {i:,}/{len(protein_ids):,}\")\n        \n        del inputs, outputs, batch_emb\n        gc.collect()\n    \n    return np.vstack(embs)\n\ndef extract_seq_features(seq):\n    if not seq:\n        return np.zeros(30)\n    \n    length = len(seq)\n    aa_counts = Counter(seq)\n    aas = \"ACDEFGHIKLMNPQRSTVWY\"\n    aa_comp = np.array([aa_counts.get(aa, 0) / length for aa in aas])\n    \n    hydro = sum(aa_counts.get(aa, 0) for aa in 'AILMFWYV') / length\n    charged = sum(aa_counts.get(aa, 0) for aa in 'RKDE') / length\n    polar = sum(aa_counts.get(aa, 0) for aa in 'STNQ') / length\n    aromatic = sum(aa_counts.get(aa, 0) for aa in 'FYW') / length\n    \n    features = np.concatenate([\n        aa_comp,\n        [hydro, charged, polar, aromatic],\n        [len(set(seq)) / 20.0, np.log10(length + 1), length / 1000.0],\n        [aa_counts.get('C', 0) / length, aa_counts.get('P', 0) / length, aa_counts.get('G', 0) / length]\n    ])\n    \n    return features\n\n# =============================================================================\n# BUILD MODEL\n# =============================================================================\ndef build_model(input_dim, output_dim, name=\"model\"):\n    inputs = layers.Input(shape=(input_dim,))\n    x = layers.Dense(1024, activation='relu')(inputs)\n    x = layers.BatchNormalization()(x)\n    x = layers.Dropout(0.4)(x)\n    x = layers.Dense(512, activation='relu')(x)\n    x = layers.BatchNormalization()(x)\n    x = layers.Dropout(0.3)(x)\n    x = layers.Dense(256, activation='relu')(x)\n    x = layers.Dropout(0.2)(x)\n    outputs = layers.Dense(output_dim, activation='sigmoid')(x)\n    \n    model = models.Model(inputs=inputs, outputs=outputs, name=name)\n    model.compile(\n        optimizer=tf.keras.optimizers.Adam(CONFIG['LR']),\n        loss='binary_crossentropy',\n        metrics=['precision', 'recall']\n    )\n    return model\n\n# =============================================================================\n# TRAIN PER-ONTOLOGY MODELS\n# =============================================================================\nlog(\"\\nTraining per-ontology models...\")\n\nontology_models = {}\n\nfor ont in ['F', 'P', 'C']:\n    log(f\"\\n{'='*60}\")\n    log(f\"ONTOLOGY {ont}: {len(selected_terms[ont])} labels\")\n    \n    ont_terms = selected_terms[ont]\n    ont_prots = [p for p in valid_prots if any(t in ont_terms for t in filtered[p])]\n    log(f\"  Proteins: {len(ont_prots):,}\")\n    \n    # Extract features\n    log(\"  Extracting features...\")\n    parts = []\n    \n    if CONFIG['USE_ESM2'] and HAS_ESM2:\n        log(\"    Computing ESM-2...\")\n        X_esm = extract_esm2(ont_prots, train_seqs, CONFIG['ESM_BATCH'])\n        parts.append(X_esm)\n        del X_esm\n        gc.collect()\n    \n    log(\"    Computing sequence features...\")\n    X_seq = np.array([extract_seq_features(train_seqs[p]) for p in ont_prots])\n    parts.append(X_seq)\n    \n    X = np.concatenate(parts, axis=1).astype(np.float32)\n    log(f\"  Features: {X.shape}\")\n    \n    scaler = StandardScaler()\n    X = scaler.fit_transform(X)\n    \n    # Prepare labels\n    mlb = MultiLabelBinarizer(classes=sorted(ont_terms))\n    y_list = [[t for t in filtered[p] if t in ont_terms] for p in ont_prots]\n    Y = mlb.fit_transform(y_list).astype(np.float32)\n    log(f\"  Labels: {Y.shape}, sparsity: {(1-Y.mean())*100:.1f}%\")\n    \n    # Split\n    X_train, X_val, y_train, y_val = train_test_split(X, Y, test_size=0.15, random_state=CONFIG['SEED'])\n    \n    # Train\n    log(\"  Training...\")\n    model = build_model(X.shape[1], Y.shape[1], f\"model_{ont}\")\n    \n    hist = model.fit(\n        X_train, y_train,\n        validation_data=(X_val, y_val),\n        batch_size=CONFIG['BATCH_SIZE'],\n        epochs=CONFIG['EPOCHS'],\n        callbacks=[\n            callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True, verbose=0),\n            callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, verbose=0)\n        ],\n        verbose=0\n    )\n    \n    log(f\"  Trained {len(hist.history['loss'])} epochs\")\n    \n    # Optimize per-term thresholds\n    log(\"  Optimizing thresholds...\")\n    y_pred = model.predict(X_val, batch_size=32, verbose=0)\n    label_ia = np.array([ia_weights.get(t, 1.0) for t in mlb.classes_])\n    \n    term_thresholds = np.zeros(Y.shape[1])\n    for i in range(Y.shape[1]):\n        if y_val[:, i].sum() > 0:\n            best_f1, best_thr = 0, 0.5\n            for thr in np.linspace(0.001, 0.9, CONFIG['THRESHOLD_STEPS']):\n                pred = (y_pred[:, i] >= thr).astype(int)\n                tp = ((y_val[:, i] == 1) & (pred == 1)).sum()\n                fp = ((y_val[:, i] == 0) & (pred == 1)).sum()\n                fn = ((y_val[:, i] == 1) & (pred == 0)).sum()\n                \n                if tp + fp > 0 and tp + fn > 0:\n                    prec = tp / (tp + fp)\n                    rec = tp / (tp + fn)\n                    f1 = 2 * prec * rec / (prec + rec + 1e-12)\n                    if f1 > best_f1:\n                        best_f1, best_thr = f1, thr\n            \n            term_thresholds[i] = best_thr\n        else:\n            term_thresholds[i] = 0.5\n    \n    log(f\"  Thresholds: min={term_thresholds.min():.3f}, max={term_thresholds.max():.3f}, mean={term_thresholds.mean():.3f}\")\n    \n    ontology_models[ont] = {\n        'model': model,\n        'scaler': scaler,\n        'mlb': mlb,\n        'thresholds': term_thresholds,\n        'ia': label_ia,\n        'freqs': {t: term_counts[t] for t in ont_terms}\n    }\n    \n    del X, X_train, X_val, y_train, y_val, Y, y_pred\n    gc.collect()\n\n# =============================================================================\n# LOAD CAFA5\n# =============================================================================\nlog(\"\\nLoading CAFA5...\")\ntry:\n    df_cafa5 = pd.read_csv(CONFIG['CAFA5_PATH'], sep='\\t', header=None, names=['pid', 'go', 'score'])\n    cafa5 = defaultdict(dict)\n    for _, row in df_cafa5.iterrows():\n        try:\n            cafa5[row['pid']][row['go']] = float(row['score'])\n        except:\n            pass\n    log(f\"✓ CAFA5: {len(cafa5):,} proteins\")\nexcept:\n    cafa5 = {}\n    log(\"✗ CAFA5 not loaded\")\n\n# =============================================================================\n# PREDICT TEST\n# =============================================================================\nlog(\"\\nPredicting test...\")\n\ntest_ids = list(test_seqs.keys())\nbatch_size = 1000\n\nall_preds = defaultdict(dict)\n\nfor start_idx in range(0, len(test_ids), batch_size):\n    end_idx = min(start_idx + batch_size, len(test_ids))\n    batch = test_ids[start_idx:end_idx]\n    \n    if start_idx % 10000 == 0:\n        log(f\"  Batch {start_idx:,}/{len(test_ids):,}\")\n    \n    for ont in ['F', 'P', 'C']:\n        parts = []\n        \n        if CONFIG['USE_ESM2'] and HAS_ESM2:\n            X_esm = extract_esm2(batch, test_seqs, CONFIG['ESM_BATCH'])\n            parts.append(X_esm)\n            del X_esm\n        \n        X_seq = np.array([extract_seq_features(test_seqs[p]) for p in batch])\n        parts.append(X_seq)\n        \n        X = np.concatenate(parts, axis=1).astype(np.float32)\n        X = ontology_models[ont]['scaler'].transform(X)\n        \n        y_pred = ontology_models[ont]['model'].predict(X, batch_size=32, verbose=0)\n        thresholds = ontology_models[ont]['thresholds']\n        mlb = ontology_models[ont]['mlb']\n        \n        for i, pid in enumerate(batch):\n            for j, term in enumerate(mlb.classes_):\n                score = float(y_pred[i, j])\n                if score >= thresholds[j]:\n                    all_preds[pid][term] = score\n        \n        del X, y_pred\n        gc.collect()\n\n# =============================================================================\n# ENSEMBLE & PROPAGATE\n# =============================================================================\nlog(\"Ensembling with CAFA5...\")\n\nterm_freqs = {t: term_counts[t] for t in all_terms}\n\nfor pid in test_ids:\n    if pid in cafa5:\n        for term, cafa5_score in cafa5[pid].items():\n            if term in all_terms:\n                my_score = all_preds[pid].get(term, 0)\n                \n                # Dynamic weighting\n                weight = 0.25\n                if my_score > 0.7:\n                    weight = 0.15\n                elif my_score < 0.3:\n                    weight = 0.35\n                \n                term_ia = ia_weights.get(term, 1.0)\n                if term_ia > 5.0:\n                    weight += 0.10\n                \n                freq = term_freqs.get(term, 0)\n                if freq < 10:\n                    weight += 0.10\n                elif freq > 1000:\n                    weight -= 0.05\n                \n                weight = np.clip(weight, 0.1, 0.5)\n                all_preds[pid][term] = (1 - weight) * my_score + weight * cafa5_score\n\nlog(\"Propagating to parents...\")\n\nterm_to_idx = {t: i for i, t in enumerate(all_terms)}\nrestricted_parents = {t: [p for p in parents.get(t, []) if p in term_to_idx] for t in all_terms}\n\nfor pid in test_ids:\n    scores = all_preds.get(pid, {})\n    for child, parent_list in restricted_parents.items():\n        if child in scores:\n            child_score = scores[child]\n            for parent in parent_list:\n                if parent not in scores or scores[parent] < child_score:\n                    scores[parent] = child_score\n\n# =============================================================================\n# WRITE SUBMISSION\n# =============================================================================\nlog(\"Writing submission...\")\n\nwith open(CONFIG['OUTPUT'], 'w') as f:\n    for pid in test_ids:\n        if pid in all_preds:\n            sorted_terms = sorted(all_preds[pid].items(), key=lambda x: x[1], reverse=True)\n            for term, score in sorted_terms[:CONFIG['TOP_K_PRED']]:\n                if score > 0.001:\n                    f.write(f\"{pid}\\t{term}\\t{score:.3g}\\n\")\n\nlog(f\"✓ Saved to {CONFIG['OUTPUT']}\")\n\n# =============================================================================\n# SUMMARY\n# =============================================================================\ndf_sub = pd.read_csv(CONFIG['OUTPUT'], sep='\\t', header=None, names=['pid', 'go', 'score'])\n\nprint(\"\\n\" + \"=\"*80)\nprint(\"SUMMARY\")\nprint(\"=\"*80)\nprint(f\"Total time: {(time.time()-start)/60:.1f} minutes\")\nprint(f\"Predictions: {len(df_sub):,}\")\nprint(f\"Proteins: {df_sub['pid'].nunique():,}\")\nprint(f\"GO terms: {df_sub['go'].nunique():,}\")\nprint(f\"Avg per protein: {len(df_sub)/df_sub['pid'].nunique():.1f}\")\nprint(f\"\\nExpected score: 0.30-0.38\")\nprint(\"=\"*80)","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}