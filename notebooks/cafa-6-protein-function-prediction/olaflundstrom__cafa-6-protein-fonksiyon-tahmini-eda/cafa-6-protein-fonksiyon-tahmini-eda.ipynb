{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":116062,"databundleVersionId":14084779,"sourceType":"competition"}],"dockerImageVersionId":31153,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **CAFA 6 Protein Fonksiyon Tahmini - Öğretici ve Zenginleştirilmiş Keşifsel Veri Analizi (EDA)**\n\n### **Team:**\n**DTU Proteomics Core**\n\n### **Author:**\n**Olaf Yunus Laitinen Imanov**  \n*Data Scientist in Proteomics*  \nDTU Proteomics Core  \nDTU Bioengineering, Department of Biotechnology and Biomedicine  \nTechnical University of Denmark (Danmarks Tekniske Universitet)  \nSøltofts Plads, Building 224, Room 017, 2800 Kgs. Lyngby  \nolyulaim@dtu.dk  \n+46 76 236 80 88  \n\n---\n\n### **Giriş: Proteinlerin Gizemli Dünyasına Yolculuk**\n\nBu notebook, **CAFA 6 Protein Fonksiyon Tahmini** yarışmasının veri setini analiz etmekle kalmayıp, aynı zamanda biyoinformatik ve proteomik dünyasına bir giriş yapmayı amaçlamaktadır. Amacımız, bir proteinin amino asit diziliminden yola çıkarak onun biyolojik görevini nasıl tahmin edebileceğimizi anlamak ve bu süreçte kullanılan temel kavramları ve veri bilimi tekniklerini açıklamaktır.\n\n**Neden Protein Fonksiyonu Tahmini?**\n\nGenom projeleri sayesinde elimizde milyonlarca proteinin amino asit dizilimi bilgisi var. Ancak bu proteinlerin büyük bir kısmının ne iş yaptığı, yani \"fonksiyonu\" hala bilinmiyor. Bu fonksiyonları laboratuvarda deneysel olarak belirlemek zaman alıcı ve maliyetlidir. İşte bu noktada **biyoinformatik** ve **makine öğrenmesi** devreye giriyor. Hesaplamalı yöntemler kullanarak, bir proteinin diziliminden onun fonksiyonunu tahmin etmek, biyolojik araştırmaları hızlandırabilir, hastalıkların mekanizmalarını aydınlatabilir ve yeni ilaç hedeflerinin keşfedilmesine olanak tanıyabilir. Bu yarışma, tam da bu önemli bilimsel probleme odaklanmaktadır.\n\n---\n\n### **Analiz Planı:**\n\n1.  **Bölüm 1: Hazırlık ve Kavramsal Temeller**\n    *   Gerekli Python kütüphanelerinin yüklenmesi.\n    *   **Kavram Köşesi:** Protein, Amino Asit, Gene Ontology (GO) ve Taksonomi nedir?\n2.  **Bölüm 2: Veri Setini Tanıyalım**\n    *   Yarışma dosyalarına genel bir bakış ve görevimizin tanımı.\n3.  **Bölüm 3: Protein Sekansları Analizi (`train_sequences.fasta`)**\n    *   **Bilgi:** Proteinler neden farklı uzunluklardadır? Amino asit dağılımı bize ne anlatır?\n    *   Sekans uzunlukları, amino asit frekansları ve bunların biyolojik anlamları.\n4.  **Bölüm 4: Fonksiyonel Etiketler Analizi (`train_terms.tsv`)**\n    *   **Bilgi:** \"Çok etiketli sınıflandırma\" nedir? \"Etiket dengesizliği\" modelimizi nasıl etkiler?\n    *   GO terimlerinin dağılımı ve istatistiksel analizi.\n5.  **Bölüm 5: Taksonomi Analizi (`train_taxonomy.tsv`)**\n    *   **Bilgi:** Model organizmalar neden önemlidir? Evrimsel bilgi fonksiyon tahmininde nasıl kullanılır?\n    *   Proteinlerin ait olduğu canlı türlerinin incelenmesi.\n6.  **Bölüm 6: Gene Ontology (GO) Hiyerarşisi (`go-basic.obo`)**\n    *   **Bilgi:** Yönlendirilmiş Döngüsüz Graf (DAG) nedir? Fonksiyonlar arasındaki \"is_a\" ilişkisi ne anlama gelir?\n    *   GO grafının yapısı, terim derinliği ve Bilgi Birikimi (IA) arasındaki ilişki.\n7.  **Bölüm 7: Bütünsel Bakış ve Karşılaştırmalar**\n    *   Eğitim ve test setleri arasındaki benzerliklerin önemi: \"Dağılım Kayması (Domain Shift)\" kavramı.\n8.  **Bölüm 8: İleri Düzey Görselleştirmeler**\n    *   En popüler GO terimleri arasındaki hiyerarşik ilişkinin interaktif bir ağ grafiği ile görselleştirilmesi.\n9.  **Bölüm 9: Sonuç ve Modelleme Stratejileri**\n    *   Analizden elde edilen bulguların özetlenmesi ve başarılı bir model geliştirmek için yol haritası.\n\n---\n\n### **1. Hazırlık: Kütüphanelerin Yüklenmesi ve Kavramsal Temeller**\n\n#### **1.1 Gerekli Kütüphanelerin Yüklenmesi**\n\nHer veri bilimi projesinde olduğu gibi, ilk adımımız analiz için gerekli araçları (kütüphaneleri) çalışma ortamımıza dahil etmektir.","metadata":{}},{"cell_type":"code","source":"# Bu hücre, eksik kütüphaneleri Kaggle ortamına yükleyecektir.\n# Yükleme işlemi internet bağlantınıza bağlı olarak birkaç dakika sürebilir.\n!pip install biopython\n!pip install obonet\n!pip install networkx\n!pip install wordcloud\n\n# Veri işleme ve analiz için temel kütüphaneler\nimport pandas as pd\nimport numpy as np\n\n# Görselleştirme kütüphaneleri\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly.express as px\nimport plotly.graph_objects as go\nfrom wordcloud import WordCloud\n\n# Biyoinformatik ve özel dosya formatları için kütüphaneler\nfrom Bio import SeqIO  # FASTA dosyalarını okumak için\nimport obonet         # OBO (Gene Ontology) dosyalarını okumak için\nimport networkx as nx # Graf (ağ) yapıları ile çalışmak için\n\n# Yardımcı kütüphaneler\nfrom tqdm.notebook import tqdm\nimport collections\nimport warnings\n\n# Kod çıktılarının daha temiz görünmesi için uyarıları gizleyelim.\nwarnings.filterwarnings('ignore')\n# Görselleştirmeler için varsayılan stili ayarlayalım.\nsns.set_style('whitegrid')\n# Grafiklerimizin varsayılan boyutunu ayarlayalım.\nplt.rcParams['figure.figsize'] = (12, 6)\n\nprint(\"Tüm kütüphaneler başarıyla yüklendi ve import edildi. Analize başlayabilirsiniz.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-19T11:18:22.123019Z","iopub.execute_input":"2025-10-19T11:18:22.123491Z","iopub.status.idle":"2025-10-19T11:18:37.564217Z","shell.execute_reply.started":"2025-10-19T11:18:22.123462Z","shell.execute_reply":"2025-10-19T11:18:37.562736Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### **1.2 Kavram Köşesi: Biyoinformatik Dünyasına Giriş**\n\nBu analizi daha iyi anlamak için bazı temel biyolojik ve hesaplamalı kavramları tanıyalım.\n\n*   **Protein ve Amino Asitler:** Proteinler, DNA'da kodlanan genetik bilginin işlevsel ürünleridir. Canlılığın devamı için gerekli olan reaksiyonları katalizler, hücrelere yapısal destek sağlarlar ve sinyal iletiminde rol alırlar. Proteinler, **amino asit** adı verilen 20 farklı kimyasal yapı taşının belirli bir sırada bir araya gelmesiyle oluşan polimerlerdir. Bu sıralamaya **protein sekansı** denir. Bu sekans, proteinin üç boyutlu katlanmasını ve dolayısıyla biyolojik fonksiyonunu belirleyen en temel bilgidir. Yarışmadaki ana girdimiz de bu sekans bilgisidir.\n\n*   **Gene Ontology (GO - Gen Ontolojisi):** Binlerce farklı protein ve fonksiyonu üzerine yapılan araştırmaları standartlaştırmak ve bilgisayarlar tarafından anlaşılabilir kılmak için geliştirilmiş bir sistemdir. GO, fonksiyonları üç ana alanda hiyerarşik olarak düzenler:\n    *   **Moleküler Fonksiyon (MFO):** Bir proteinin moleküler seviyedeki aktivitesi. Örneğin, \"ATP bağlama\" (ATP binding) veya \"kinaz aktivitesi\" (kinase activity).\n    *   **Biyolojik Süreç (BPO):** Bir proteinin dahil olduğu daha büyük biyolojik olaylar dizisi. Örneğin, \"hücre döngüsü\" (cell cycle) veya \"glikoliz\" (glycolysis).\n    *   **Hücresel Bileşen (CCO):** Bir proteinin hücre içinde bulunduğu konum. Örneğin, \"çekirdek\" (nucleus) veya \"mitokondri\" (mitochondrion).\n    Bu hiyerarşik yapı, fonksiyonlar arasında \"bir türüdür\" (is_a) veya \"bir parçasıdır\" (part_of) gibi ilişkiler kurar. Modelimizin tahmin etmesi gereken çıktılar bu GO terimleridir.\n\n*   **Taksonomi:** Canlıların evrimsel ilişkilerine göre sınıflandırılması bilimidir. Her canlı türünün benzersiz bir **taksonomi ID**'si vardır. Örneğin, *Homo sapiens* (insan) için bu ID `9606`'dır. Protein fonksiyonları genellikle türler arasında korunur. Örneğin, insandaki bir metabolik enzimin benzeri genellikle farede veya mayada da bulunur. Bu evrimsel bilgi, fonksiyon tahmininde güçlü bir ipucu olabilir.\n\n---\n\n### **2. Veri Setini Tanıyalım**\n\nAnalize başlamadan önce, yarışma tarafından sağlanan tüm dosyaları ve yollarını tanımlayalım.","metadata":{}},{"cell_type":"code","source":"# Veri dosyalarının bulunduğu ana dizin\ndata_path = '/kaggle/input/cafa-6-protein-function-prediction/'\n\n# Dosya yolları\ntrain_seq_path = f'{data_path}Train/train_sequences.fasta'\ntrain_terms_path = f'{data_path}Train/train_terms.tsv'\ntrain_tax_path = f'{data_path}Train/train_taxonomy.tsv'\ntest_seq_path = f'{data_path}Test/testsuperset.fasta'\ngo_obo_path = f'{data_path}Train/go-basic.obo'\nia_path = f'{data_path}IA.tsv'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-19T11:18:57.273929Z","iopub.execute_input":"2025-10-19T11:18:57.274381Z","iopub.status.idle":"2025-10-19T11:18:57.280864Z","shell.execute_reply.started":"2025-10-19T11:18:57.274347Z","shell.execute_reply":"2025-10-19T11:18:57.279747Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"| Dosya Adı | Açıklama |\n| :--- | :--- |\n| `train_sequences.fasta` | Eğitim setindeki proteinlerin amino asit dizilimleri. Modelimizin **girdi (input)** verisi. |\n| `train_terms.tsv` | Eğitim setindeki proteinlerin atandığı GO terimleri. Modelimizin öğrenmesi gereken **hedef (target)** etiketleri. |\n| `train_taxonomy.tsv` | Eğitim setindeki proteinlerin ait olduğu türlerin taksonomik ID'leri. Modele ek bilgi olarak sunulabilir. |\n| `go-basic.obo` | Gene Ontology'nin hiyerarşik yapısını tanımlayan graf dosyası. Etiketler arasındaki ilişkileri içerir. |\n| `testsuperset.fasta` | Fonksiyonunu tahmin etmemiz istenen test proteinlerinin dizilimleri. |\n| `IA.tsv` | Her bir GO teriminin **Bilgi Birikimi (IA)** ağırlığı. Yarışma değerlendirme metriğinde kullanılır ve nadir fonksiyonların doğru tahminini ödüllendirir. |\n\n---\n\n### **3. Protein Sekansları Analizi (`train_sequences.fasta`)**\n\nModelimizin temel girdisi olan protein sekanslarının özelliklerini inceleyerek başlayalım.","metadata":{}},{"cell_type":"code","source":"# FASTA dosyasını okumak için boş listeler oluşturalım.\nprotein_ids = []\nseq_lengths = []\n# Tüm amino asitleri saymak için bir Counter nesnesi oluşturalım.\namino_acid_counts = collections.Counter()\n\n# SeqIO.parse ile FASTA dosyasını satır satır okuyalım.\n# tqdm, döngünün ilerlemesini gösteren bir ilerleme çubuğu ekler.\nfor record in tqdm(SeqIO.parse(train_seq_path, \"fasta\"), desc=\"Eğitim Sekansları Okunuyor\"):\n    # Her bir proteinin ID'sini (örn: P9WHI7) başlık satırından alalım.\n    protein_ids.append(record.id.split('|')[1])\n    # Protein sekansının uzunluğunu (amino asit sayısı) listeye ekleyelim.\n    seq_lengths.append(len(record.seq))\n    # Sekanstaki her bir amino asidi sayalım.\n    amino_acid_counts.update(record.seq)\n\n# Protein ID'leri ve uzunluklarından bir pandas DataFrame'i oluşturalım.\ntrain_seq_df = pd.DataFrame({\n    'ProteinID': protein_ids,\n    'Length': seq_lengths\n})\n\n# Temel istatistikleri yazdıralım.\nprint(f\"Toplam eğitim proteini sayısı: {len(train_seq_df)}\")\nprint(\"\\nSekans Uzunluk İstatistikleri:\")\n# describe() fonksiyonu, bir sütunun temel istatistiksel özetini verir.\nprint(train_seq_df['Length'].describe())\n\n# Sekans uzunluklarının dağılımını görselleştirelim.\n# İki grafik (histogram ve kutu grafiği) oluşturmak için subplots kullanalım.\nfig, axes = plt.subplots(2, 1, figsize=(16, 10), sharex=True)\n# Histogram, verinin belirli aralıklara ne sıklıkla düştüğünü gösterir.\nsns.histplot(data=train_seq_df, x='Length', bins=100, ax=axes[0])\naxes[0].set_title('Eğitim Seti Protein Sekans Uzunluk Dağılımı (Histogram)', fontsize=16)\naxes[0].set_xlabel('')\naxes[0].set_ylabel('Protein Sayısı')\n# Dağılım çok geniş bir aralıkta olduğu için logaritmik ölçek kullanalım.\naxes[0].set_xscale('log')\n\n# Kutu grafiği, verinin çeyrekliklerini, medyanını ve aykırı değerlerini gösterir.\nsns.boxplot(data=train_seq_df, x='Length', ax=axes[1])\naxes[1].set_title('Eğitim Seti Protein Sekans Uzunluk Dağılımı (Boxplot)', fontsize=16)\naxes[1].set_xlabel('Sekans Uzunluğu (Log Ölçek)', fontsize=12)\naxes[1].set_xscale('log')\n\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-19T11:19:49.414519Z","iopub.execute_input":"2025-10-19T11:19:49.415339Z","iopub.status.idle":"2025-10-19T11:19:54.150909Z","shell.execute_reply.started":"2025-10-19T11:19:49.415306Z","shell.execute_reply":"2025-10-19T11:19:54.14984Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Analiz ve Bulgular:**\n*   Veri setinde **82,404** adet eğitim proteini bulunmaktadır.\n*   Proteinlerin ortalama uzunluğu yaklaşık **526** amino asit. Ancak, standart sapmanın (521) çok yüksek olması ve maksimum uzunluğun **35,213**'e (Titin gibi devasa bir kas proteini olabilir) ulaşması, uzunluk dağılımının çok geniş bir aralıkta olduğunu gösteriyor. Proteinlerin farklı fonksiyonları yerine getirmek için farklı boyutlarda ve karmaşıklıkta olması gerektiğinden bu durum biyolojik olarak beklenir.\n*   Grafikler, dağılımın **sağa çarpık (uzun kuyruklu)** olduğunu doğruluyor. Bu, proteinlerin büyük bir kısmının görece kısa olduğunu, ancak çok az sayıda aşırı uzun proteinin bulunduğunu gösterir.\n*   **Modelleme İçin Anlamı:** Makine öğrenmesi modelleri, özellikle Transformer tabanlı olanlar, genellikle sabit uzunlukta girdilerle çalışır. Bu aşırı uzun sekansları nasıl işleyeceğimiz (örneğin, sekansı kesmek, parçalara ayırmak veya bu uzunluk değişkenliğini yönetebilen RNN/CNN gibi modeller kullanmak) önemli bir modelleme kararıdır.\n\n#### **Amino Asit Frekansları**\n\nŞimdi de tüm eğitim setindeki 20 temel amino asidin genel dağılımına bakalım.","metadata":{}},{"cell_type":"code","source":"# Amino asit sayılarını bir DataFrame'e dönüştürelim ve sıklığa göre sıralayalım.\naa_freq_df = pd.DataFrame(amino_acid_counts.items(), columns=['AminoAcid', 'Count']).sort_values('Count', ascending=False)\n\n# Sıklığı bir çubuk grafiği ile görselleştirelim.\nplt.figure(figsize=(16, 8))\nsns.barplot(data=aa_freq_df, x='AminoAcid', y='Count', palette='viridis')\nplt.title('Eğitim Setindeki Toplam Amino Asit Sıklığı', fontsize=16)\nplt.xlabel('Amino Asit (Tek Harf Kodu)', fontsize=12)\nplt.ylabel('Toplam Sayı', fontsize=12)\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-19T11:20:13.138438Z","iopub.execute_input":"2025-10-19T11:20:13.138839Z","iopub.status.idle":"2025-10-19T11:20:13.574462Z","shell.execute_reply.started":"2025-10-19T11:20:13.138811Z","shell.execute_reply":"2025-10-19T11:20:13.573559Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Analiz ve Bulgular:**\n*   En sık rastlanan amino asitler Lösin (L), Serin (S) ve Alanin (A) gibi küçük veya hidrofobik amino asitlerdir.\n*   En nadir amino asitler ise Triptofan (W) ve Sistein (C) gibi daha karmaşık veya kimyasal olarak reaktif olanlardır.\n*   Bu dağılım, bilinen tüm proteomlardaki genel amino asit dağılımı ile tutarlıdır. Bu, veri setimizin biyolojik olarak geçerli ve yüksek kalitede olduğuna dair bir başka kanıttır.","metadata":{}},{"cell_type":"markdown","source":"---\n\n### **4. Fonksiyonel Etiketler Analizi (`train_terms.tsv`)**\n\nBu bölümde, modelimizin neyi tahmin etmesi gerektiğini, yani proteinlerin fonksiyonel \"etiketlerini\" inceleyeceğiz. Bu analiz, yarışma probleminin yapısını anlamak için kritik öneme sahiptir.","metadata":{}},{"cell_type":"code","source":"# Eğitim etiketleri dosyasını (train_terms.tsv) bir pandas DataFrame'i olarak okuyalım.\ntrain_terms_df = pd.read_csv(train_terms_path, sep='\\t')\n\n# Veri setindeki temel sayıları yazdıralım.\nprint(f\"Toplam etiket ataması sayısı: {len(train_terms_df)}\")\nprint(f\"Etiketlenmiş benzersiz protein sayısı: {train_terms_df['EntryID'].nunique()}\")\nprint(f\"Benzersiz GO terimi (etiket) sayısı: {train_terms_df['term'].nunique()}\")\nprint(\"\\nVeri Örneği:\")\nprint(train_terms_df.head())\n\n# Üç ana GO ontolojisine (P, C, F) göre etiketlerin dağılımını sayalım.\n# Daha anlaşılır olması için kısaltmaları uzun isimleriyle eşleştirelim.\nontology_mapping = {'P': 'Biyolojik Süreç (BPO)', 'C': 'Hücresel Bileşen (CCO)', 'F': 'Moleküler Fonksiyon (MFO)'}\ntrain_terms_df['aspect_long'] = train_terms_df['aspect'].map(ontology_mapping)\nontology_counts = train_terms_df['aspect_long'].value_counts()\n\n# Pasta grafiği ile ontoloji dağılımını görselleştirelim.\nfig = px.pie(ontology_counts, values=ontology_counts.values, names=ontology_counts.index,\n             title='GO Ontoloji Sınıflarına Göre Etiket Dağılımı',\n             color_discrete_sequence=px.colors.sequential.RdBu)\n# Grafik dilimlerinin içine yüzde ve etiket adını yazdıralım.\nfig.update_traces(textposition='inside', textinfo='percent+label')\nfig.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-19T11:20:48.100858Z","iopub.execute_input":"2025-10-19T11:20:48.101332Z","iopub.status.idle":"2025-10-19T11:20:48.633555Z","shell.execute_reply.started":"2025-10-19T11:20:48.101304Z","shell.execute_reply":"2025-10-19T11:20:48.632688Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Analiz ve Bulgular:**\n*   Veri setinde toplam **537,027** fonksiyon ataması (etiket) bulunmaktadır. Bu atamalar **82,404** benzersiz proteine yapılmıştır.\n*   Bu etiketler **26,125** benzersiz GO terimine aittir. Bu, tahmin edilecek etiket sayısının çok yüksek olduğunu ve problemin yüksek boyutlu bir sınıflandırma görevi olduğunu gösterir.\n*   Etiketlerin çoğunluğu (%46.7) **Biyolojik Süreç (BPO)** ontolojisine aittir. Bu genellikle en karmaşık ve en çok terim içeren daldır. Bunu **Hücresel Bileşen (CCO)** (%29.4) ve **Moleküler Fonksiyon (MFO)** (%23.9) takip eder. Bu dağılım, modelimizin her bir ontoloji için farklı zorluklarla karşılaşabileceğini ve belki de her biri için farklı stratejiler gerektirebileceğini ima eder.\n\n#### **Etiket Dağılımları: Çok Etiketlilik ve Dengesizlik**\n\n**Kavram Köşesi:**\n*   **Çok Etiketli Sınıflandırma (Multi-label Classification):** Geleneksel sınıflandırma problemlerinde her örneğin tek bir etiketi vardır (kedi, köpek gibi). Ancak biyolojide bir protein aynı anda birden fazla göreve sahip olabilir. Örneğin, hem \"çekirdekte\" (CCO) bulunabilir hem de \"DNA'ya bağlanma\" (MFO) fonksiyonunu yerine getirebilir. Her bir örneğe birden fazla etiket atanabilen bu tür problemlere **çok etiketli sınıflandırma** denir.\n*   **Etiket Dengesizliği (Label Imbalance):** Veri setinde bazı etiketlerin çok sık, bazılarının ise çok nadir görülmesi durumudur. Bu, makine öğrenmesi modelleri için büyük bir zorluktur çünkü model, sık görülen etiketleri öğrenmeye odaklanıp nadir olanları göz ardı etme eğiliminde olur.\n\nŞimdi bu kavramların veri setimizde ne kadar belirgin olduğunu inceleyelim.","metadata":{}},{"cell_type":"code","source":"# Her bir protein için kaç tane etiket olduğunu sayalım.\nlabels_per_protein = train_terms_df.groupby('EntryID')['term'].count()\n\n# Protein başına etiket sayısının dağılımını histogram ile gösterelim.\nplt.figure(figsize=(16, 6))\n# Dikey eksende logaritmik ölçek kullanarak nadir durumları (çok fazla etiketi olan proteinler) daha iyi görelim.\nsns.histplot(labels_per_protein, bins=100, log_scale=(False, True))\nplt.title('Protein Başına Atanan GO Terimi Sayısı Dağılımı', fontsize=16)\nplt.xlabel('Bir Proteine Atanan Etiket Sayısı', fontsize=12)\nplt.ylabel('Protein Sayısı (Log Ölçek)', fontsize=12)\nplt.show()\nprint(\"\\nProtein Başına Etiket Sayısı İstatistikleri:\")\nprint(labels_per_protein.describe())\n\n# Her bir etiketin kaç farklı proteine atandığını sayalım (etiket popülerliği).\nproteins_per_label = train_terms_df.groupby('term')['EntryID'].count().sort_values(ascending=False)\n\n# Etiket popülerliğinin dağılımını histogram ile gösterelim.\nplt.figure(figsize=(16, 6))\n# Hem yatay hem dikey eksende logaritmik ölçek kullanalım, çünkü dağılım çok geniş bir aralıkta.\nsns.histplot(proteins_per_label, bins=100, log_scale=(True, True))\nplt.title('GO Terimi Başına Protein Sayısı Dağılımı (Etiket Popülerliği)', fontsize=16)\nplt.xlabel('Bir GO Teriminin Atandığı Protein Sayısı (Log Ölçek)', fontsize=12)\nplt.ylabel('GO Terimi Sayısı (Log Ölçek)', fontsize=12)\nplt.show()\nprint(\"\\nEn Popüler 10 GO Terimi:\")\nprint(proteins_per_label.head(10))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-19T11:21:25.423235Z","iopub.execute_input":"2025-10-19T11:21:25.423557Z","iopub.status.idle":"2025-10-19T11:21:27.323588Z","shell.execute_reply.started":"2025-10-19T11:21:25.423536Z","shell.execute_reply":"2025-10-19T11:21:27.322618Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Analiz ve Bulgular:**\n*   **Protein Başına Etiket Sayısı:** Bir proteine ortalama **6.5** etiket atanmış, ancak bazı proteinler **233**'e kadar etikete sahip. Bu durum, problemin kesinlikle **çok etiketli (multi-label)** bir sınıflandırma problemi olduğunu güçlü bir şekilde doğrular. Modelimiz, her protein için birden fazla \"evet\" cevabı verebilmelidir.\n*   **Etiket Popülerliği:** Bu grafik, yarışmanın en büyük zorluklarından birini gözler önüne seriyor: **aşırı etiket dengesizliği**. \"protein binding\" (GO:0005515) gibi çok genel ve GO hiyerarşisinin tepesine yakın terimler on binlerce proteine atanmışken, GO terimlerinin ezici çoğunluğu sadece birkaç proteine atanmıştır. Bu, modelin nadir fonksiyonları öğrenmesini zorlaştıracak ve özel kayıp fonksiyonları (weighted loss) veya örnekleme stratejileri (sampling strategies) gibi çözümler gerektirecektir.\n\n---\n\n### **5. Taksonomi Analizi (`train_taxonomy.tsv`)**\n\n**Kavram Köşesi:**\n*   **Model Organizmalar:** Biyolojik araştırmalarda, insan biyolojisini ve hastalıklarını anlamak için kullanılan, genetik olarak iyi karakterize edilmiş ve laboratuvarda çalışması kolay olan canlılardır (örn: fare, maya, meyve sineği). Proteomik veri tabanları genellikle bu organizmalardan gelen verilerle zengindir.\n*   **Homoloji ve Fonksiyon:** Evrimsel olarak ortak bir atadan gelen genlere (ve proteinlere) **homolog** denir. Homolog proteinler genellikle benzer fonksiyonlara sahiptir. Bu nedenle, bir proteinin hangi türden geldiği bilgisi, onun fonksiyonunu tahmin etmek için değerli bir ipucu olabilir.","metadata":{}},{"cell_type":"code","source":"# Taksonomi dosyasını okurken başlık satırı olmadığını ve sütun isimlerini manuel olarak belirtelim.\ntrain_tax_df = pd.read_csv(train_tax_path, sep='\\t', names=['ProteinID', 'taxonomyID'])\n\nprint(f\"Benzersiz takson ID sayısı: {train_tax_df['taxonomyID'].nunique()}\")\n\n# En sık görülen 20 türü bulalım.\ntop_20_species = train_tax_df['taxonomyID'].value_counts().nlargest(20)\n\n# Çubuk grafiği ile görselleştirelim.\nplt.figure(figsize=(16, 8))\n# Takson ID'leri sayısal olduğu için grafikte string olarak gösterelim ki kategorik algılansın.\nsns.barplot(x=top_20_species.index.astype(str), y=top_20_species.values, palette='magma')\nplt.title('Eğitim Setindeki En Yaygın 20 Tür (Takson ID)', fontsize=16)\nplt.xlabel('Taksonomi ID', fontsize=12)\nplt.ylabel('Protein Sayısı', fontsize=12)\nplt.xticks(rotation=45)\nplt.show()\n\nprint(\"\\nEn yaygın türler ve bilimsel adları:\")\nprint(\"9606: Homo sapiens (İnsan)\")\nprint(\"10090: Mus musculus (Fare)\")\nprint(\"10116: Rattus norvegicus (Sıçan)\")\nprint(\"4932: Saccharomyces cerevisiae (Maya)\")\nprint(\"7227: Drosophila melanogaster (Meyve Sineği)\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-19T11:21:55.868507Z","iopub.execute_input":"2025-10-19T11:21:55.868822Z","iopub.status.idle":"2025-10-19T11:21:56.324421Z","shell.execute_reply.started":"2025-10-19T11:21:55.8688Z","shell.execute_reply":"2025-10-19T11:21:56.323478Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Analiz ve Bulgular:**\n*   Veri setindeki proteinler **1,381** farklı canlı türüne aittir, bu da veri setinin taksonomik olarak çeşitli olduğunu gösterir.\n*   Ancak, grafikten de görüleceği gibi, veri seti **model organizmalar** üzerinde yoğunlaşmıştır. En baskın türler insan, fare, sıçan, maya ve meyve sineğidir.\n*   **Modelleme İçin Anlamı:** Modelimiz, bu sık görülen türler için daha iyi performans gösterebilir. Ancak, daha az temsil edilen türler için genelleme yapmakta zorlanabilir. Taksonomi bilgisini modele ek bir özellik olarak sunmak, bu genelleme yeteneğini artırabilir.\n\n---\n\n### **6. Gene Ontology (GO) Hiyerarşisi (`go-basic.obo`)**\n\n**Kavram Köşesi:**\n*   **Yönlendirilmiş Döngüsüz Graf (DAG - Directed Acyclic Graph):** GO hiyerarşisi bir ağaç gibi değildir, çünkü bir terimin birden fazla \"ebeveyni\" olabilir. Bu tür bir yapıya DAG denir. Bu yapı, fonksiyonlar arasında karmaşık ve çoklu ilişkiler kurulmasına olanak tanır.\n*   **Doğruluk Kuralı (True Path Rule):** GO'nun temel kurallarından biridir. Eğer bir protein, bir GO terimi ile etiketlenmişse, o terimin DAG üzerindeki tüm üst (ata) terimleri ile de otomatik olarak etiketlenmiş sayılır. Örneğin, \"pozitif transkripsiyon regülasyonu\" fonksiyonuna sahip bir protein, aynı zamanda \"transkripsiyon regülasyonu\" ve \"biyolojik regülasyon\" gibi daha genel fonksiyonlara da sahiptir.","metadata":{}},{"cell_type":"code","source":"# OBO dosyasını bir networkx grafiği olarak yükleyelim. Bu, terimler arasındaki ilişkileri analiz etmemizi sağlar.\ngo_graph = obonet.read_obo(go_obo_path)\n\nprint(f\"GO Grafiğindeki Düğüm (Terim) Sayısı: {go_graph.number_of_nodes()}\")\nprint(f\"GO Grafiğindeki Kenar (İlişki) Sayısı: {go_graph.number_of_edges()}\")\n\n# Örnek bir terimin (\"protein binding\") graf üzerindeki bilgilerini gösterelim.\nsample_term = 'GO:0005515'\nif go_graph.has_node(sample_term):\n    print(f\"\\nÖrnek Terim Bilgisi ({sample_term}):\")\n    # 'is_a' ilişkisi, bu terimin hangi daha genel terimin bir alt türü olduğunu gösterir.\n    print(go_graph.nodes[sample_term])\n\n# Üç ana ontolojinin kök düğümlerini tanımlayalım. Bu düğümler hiyerarşinin en tepesindedir.\nsubontology_roots = {\n    'BPO': 'GO:0008150', # biological_process\n    'CCO': 'GO:0005575', # cellular_component\n    'MFO': 'GO:0003674'  # molecular_function\n}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-19T11:22:31.876775Z","iopub.execute_input":"2025-10-19T11:22:31.877238Z","iopub.status.idle":"2025-10-19T11:22:38.8675Z","shell.execute_reply.started":"2025-10-19T11:22:31.87721Z","shell.execute_reply":"2025-10-19T11:22:38.866483Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"---\n\n#### **Terim Derinliği ve Bilgi Birikimi (IA) Analizi**\n\n**Kavram Köşesi:**\n*   **Terim Derinliği (Term Depth):** Bir GO teriminin, hiyerarşinin en tepesindeki kök terime olan en kısa yol uzunluğudur. Derinlik arttıkça, terim daha spesifik ve özelleşmiş bir fonksiyonu tanımlar. Örneğin, \"bağlanma\" (binding) terimi sığ bir terimken, \"insülin reseptörüne bağlanma\" (insulin receptor binding) çok daha derin ve spesifik bir terimdir.\n*   **Bilgi Birikimi (IA - Information Accretion):** Bu, yarışmanın değerlendirme metriğinde kullanılan özel bir ağırlıklandırma değeridir. Bir terimin IA değeri, o terimin bir veri tabanında ne kadar nadir görüldüğüne bağlıdır. Nadir görülen (dolayısıyla daha spesifik ve tahmin etmesi zor olan) terimlerin IA değeri daha yüksektir. Yarışmada başarılı olmak, sadece popüler terimleri değil, IA değeri yüksek olan nadir terimleri de doğru tahmin etmeyi gerektirir.\n\nŞimdi bu iki metrik arasındaki ilişkiyi inceleyelim. Beklentimiz, derinlik arttıkça IA değerinin de artması yönündedir.","metadata":{}},{"cell_type":"code","source":"# IA dosyasını yükleyip bir sözlük yapısına dönüştürelim. Bu, terim ID'si ile IA değerine hızlıca erişmemizi sağlar.\nia_df = pd.read_csv(ia_path, sep='\\t', names=['term', 'IA'])\nia_map = ia_df.set_index('term')['IA'].to_dict()\n\n# Her terimin derinliğini hesaplamak için boş bir sözlük oluşturalım.\ndepths = {}\n# Her bir ontoloji kökü (BPO, CCO, MFO) için döngü başlatalım.\nfor aspect, root in subontology_roots.items():\n    if go_graph.has_node(root):\n        # Kök düğümden erişilebilen tüm alt düğümleri (torunları) bulalım.\n        descendants = nx.ancestors(go_graph, root)\n        descendants.add(root)\n        # Sadece bu ontolojiye ait alt grafiği kullanarak derinliği hesaplayalım.\n        subgraph = go_graph.subgraph(descendants)\n        for node in subgraph.nodes():\n            try:\n                # networkx kütüphanesi ile köke olan en kısa yol uzunluğunu (derinliği) bulalım.\n                depths[node] = nx.shortest_path_length(subgraph, source=root, target=node)\n            except nx.NetworkXNoPath:\n                # Bazı düğümler (artık kullanılmayan eski terimler gibi) köke bağlı olmayabilir, onları atlayalım.\n                pass\n\n# Derinlik ve IA değerlerini bir DataFrame'de birleştirelim.\ndepth_ia_data = []\nfor term, depth in depths.items():\n    if term in ia_map: # Sadece IA değeri olan terimleri dahil edelim.\n        depth_ia_data.append({'term': term, 'depth': depth, 'IA': ia_map[term]})\ndepth_ia_df = pd.DataFrame(depth_ia_data)\n\n# Saçılım grafiği (scatterplot) ile Derinlik ve IA arasındaki ilişkiyi görselleştirelim.\nplt.figure(figsize=(12, 8))\nsns.scatterplot(data=depth_ia_df, x='depth', y='IA', alpha=0.5)\n# İlişkinin genel eğilimini görmek için bir regresyon çizgisi ekleyelim.\nsns.regplot(data=depth_ia_df, x='depth', y='IA', scatter=False, color='red', line_kws={'linewidth': 2})\nplt.title('GO Terim Derinliği ve Bilgi Birikimi (IA) İlişkisi', fontsize=16)\nplt.xlabel('Derinlik (Kökten Uzaklık)', fontsize=12)\nplt.ylabel('Bilgi Birikimi (IA)', fontsize=12)\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-19T11:24:55.322936Z","iopub.execute_input":"2025-10-19T11:24:55.32383Z","iopub.status.idle":"2025-10-19T11:24:56.380017Z","shell.execute_reply.started":"2025-10-19T11:24:55.323769Z","shell.execute_reply":"2025-10-19T11:24:56.379056Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Analiz ve Bulgular:**\n*   Grafik, beklentimizle uyumlu olarak, bir terimin derinliği arttıkça (yani daha spesifik hale geldikçe), IA değerinin de genel olarak arttığını gösteriyor. Bu, spesifik fonksiyonların daha nadir ve dolayısıyla daha \"bilgilendirici\" olduğu anlamına gelir.\n*   Ancak, bu ilişki mükemmel bir doğru değildir. Aynı derinlikte çok farklı IA değerlerine sahip birçok terim vardır. Bu durum, bazı biyolojik alanların diğerlerinden daha yoğun bir şekilde araştırıldığını ve etiketlendiğini gösterir. Örneğin, belirli bir sinyal yolundaki tüm proteinler benzer derinlikte olabilir, ancak bazıları çok daha nadir olduğu için daha yüksek IA değerine sahip olabilir.\n*   **Modelleme İçin Anlamı:** Modelimizin başarısı, IA değeri yüksek (nadir ve değerli) terimleri doğru tahmin etme yeteneğine bağlıdır. Bu nedenle, etiket dengesizliği sorununu ele alan ve nadir etiketlere daha fazla önem veren modelleme stratejileri (örneğin, ağırlıklı kayıp fonksiyonları) kullanmak kritik olacaktır.\n\n---\n\n### **7. Bütünsel Bakış: Eğitim ve Test Setlerinin Karşılaştırılması**\n\n**Kavram Köşesi:**\n*   **Dağılım Kayması (Domain Shift / Distribution Shift):** Bir makine öğrenmesi modelinin eğitildiği veri (eğitim seti) ile test edildiği verinin (test seti) istatistiksel özelliklerinin birbirinden farklı olması durumudur. Bu, modelin gerçek dünya performansının beklenenden düşük olmasına neden olan yaygın bir sorundur. Örneğin, sadece kısa proteinlerle eğitilmiş bir model, test setinde çok uzun proteinlerle karşılaştığında başarısız olabilir. Bu nedenle, eğitim ve test setlerinin ne kadar benzer olduğunu kontrol etmek önemlidir.","metadata":{}},{"cell_type":"code","source":"# Test setindeki sekansları okuyalım ve uzunluklarını bir listeye kaydedelim.\ntest_protein_ids = []\ntest_seq_lengths = []\n\n# tqdm ile ilerleme çubuğu ekleyerek test sekanslarını okuyalım.\nfor record in tqdm(SeqIO.parse(test_seq_path, \"fasta\"), desc=\"Test Sekansları Okunuyor\"):\n    test_protein_ids.append(record.id)\n    test_seq_lengths.append(len(record.seq))\n\n# Test sekanslarından bir DataFrame oluşturalım.\ntest_seq_df = pd.DataFrame({\n    'ProteinID': test_protein_ids,\n    'Length': test_seq_lengths\n})\n\nprint(f\"Toplam test proteini sayısı: {len(test_seq_df)}\")\n\n# Eğitim ve test setlerindeki protein uzunluk dağılımlarını karşılaştıralım.\n# Kernel Yoğunluk Tahmini (KDE) grafiği, verinin sürekli olasılık yoğunluğunu gösterir ve dağılımları karşılaştırmak için idealdir.\nplt.figure(figsize=(16, 8))\nsns.kdeplot(train_seq_df['Length'], label='Eğitim Seti', fill=True, color='blue')\nsns.kdeplot(test_seq_df['Length'], label='Test Seti', fill=True, color='red')\nplt.title('Eğitim ve Test Seti Protein Uzunluk Dağılımlarının Karşılaştırılması', fontsize=16)\nplt.xlabel('Sekans Uzunluğu (Log Ölçek)', fontsize=12)\nplt.ylabel('Yoğunluk', fontsize=12)\n# Uzun kuyruklu dağılımı daha iyi görmek için x ekseninde logaritmik ölçek kullanalım.\nplt.xscale('log')\nplt.legend()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-19T11:25:05.856527Z","iopub.execute_input":"2025-10-19T11:25:05.856997Z","iopub.status.idle":"2025-10-19T11:25:09.100043Z","shell.execute_reply.started":"2025-10-19T11:25:05.856964Z","shell.execute_reply":"2025-10-19T11:25:09.099143Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Analiz ve Bulgular:**\n*   Eğitim ve test setlerindeki protein uzunluk dağılımları görsel olarak birbirine **çok benziyor**.\n*   Bu, yarışma organizatörlerinin veri setlerini benzer özelliklere sahip olacak şekilde böldüğünü gösteren **çok olumlu bir bulgudur**. Bu durum, modelimizin eğitim verisinde öğrendiği sekans uzunluğuna bağlı özelliklerin, test verisi için de geçerli olacağı ve ciddi bir **dağılım kayması** sorunu yaşamayacağımız anlamına gelir. Modelimizin genelleme yeteneği konusunda bu bize güven verir.\n\n---\n\n### **8. İleri Düzey Görselleştirmeler: İnteraktif GO İlişki Ağı**\n\nŞimdi, en popüler 100 GO terimini ve aralarındaki hiyerarşik ilişkileri gösteren interaktif bir ağ grafiği oluşturalım. Bu görselleştirme, ontolojinin karmaşık yapısını ve fonksiyonların birbirleriyle nasıl kümelendiğini sezgisel olarak anlamamızı sağlayacak.","metadata":{}},{"cell_type":"code","source":"# Daha önce hesapladığımız etiket popülerliği listesinden en popüler 100 terimi alalım.\ntop_100_terms = proteins_per_label.head(100).index.tolist()\n\n# Bu terimleri ve onların tüm atalarını (üst terimlerini) içeren bir alt graf oluşturalım.\n# Ataları da dahil etmek, terimler arasındaki hiyerarşik yolları görmemizi sağlar.\nsubgraph_nodes = set(top_100_terms)\nfor term in top_100_terms:\n    if go_graph.has_node(term):\n        ancestors = nx.ancestors(go_graph, term)\n        subgraph_nodes.update(ancestors)\nsubgraph = go_graph.subgraph(list(subgraph_nodes))\n\n# Görselleştirmeyi daha temiz hale getirmek için sadece en popüler 100 terim arasındaki kenarları tutan yeni bir graf oluşturalım.\ndisplay_graph = nx.DiGraph()\ndisplay_graph.add_nodes_from(top_100_terms)\nfor u, v in subgraph.edges():\n    if u in top_100_terms and v in top_100_terms:\n        display_graph.add_edge(u, v)\n\n# Plotly kütüphanesi ile interaktif bir çizim yapalım.\nif not nx.is_empty(display_graph):\n    # Düğümlerin konumunu belirlemek için bir \"yay düzeni\" (spring layout) algoritması kullanalım.\n    # Bu algoritma, düğümleri birbirine bağlı olanları yakın, olmayanları uzak olacak şekilde yerleştirir.\n    pos = nx.spring_layout(display_graph, k=0.5, iterations=50)\n\n    # Kenarları (bağlantıları) çizmek için koordinatları hazırlayalım.\n    edge_x, edge_y = [], []\n    for edge in display_graph.edges():\n        x0, y0 = pos[edge[0]]\n        x1, y1 = pos[edge[1]]\n        edge_x.extend([x0, x1, None]) # 'None' eklemek, plotly'nin çizgileri ayırmasını sağlar.\n        edge_y.extend([y0, y1, None])\n    edge_trace = go.Scatter(x=edge_x, y=edge_y, line=dict(width=0.5, color='#888'), hoverinfo='none', mode='lines')\n\n    # Düğümleri (terimleri) çizmek için koordinatları ve diğer özellikleri hazırlayalım.\n    node_x, node_y, node_text, node_color, node_size = [], [], [], [], []\n    for node in display_graph.nodes():\n        x, y = pos[node]\n        node_x.append(x)\n        node_y.append(y)\n        \n        # Fare ile üzerine gelince gösterilecek bilgileri (isim, ID, protein sayısı, ontoloji) hazırlayalım.\n        term_name = go_graph.nodes.get(node, {}).get('name', node)\n        protein_count = proteins_per_label.get(node, 0)\n        term_aspect_code = train_terms_df[train_terms_df['term'] == node]['aspect'].iloc[0] if not train_terms_df[train_terms_df['term'] == node].empty else 'N/A'\n        term_aspect_long = ontology_mapping.get(term_aspect_code, 'N/A')\n        \n        node_text.append(f\"{term_name}<br>ID: {node}<br>Protein Sayısı: {protein_count}<br>Ontoloji: {term_aspect_long}\")\n        # Düğümün boyutu, popülerliğine (protein sayısı) logaritmik olarak bağlı olsun.\n        node_size.append(10 + np.log1p(protein_count))\n        \n        # Düğümün rengi, ait olduğu ontolojiye (BPO, CCO, MFO) bağlı olsun.\n        if term_aspect_code == 'P':\n            node_color.append('rgba(255, 127, 14, 0.8)') # Turuncu\n        elif term_aspect_code == 'F':\n            node_color.append('rgba(44, 160, 44, 0.8)') # Yeşil\n        elif term_aspect_code == 'C':\n            node_color.append('rgba(31, 119, 180, 0.8)') # Mavi\n        else:\n            node_color.append('rgba(127, 127, 127, 0.8)') # Gri\n    node_trace = go.Scatter(x=node_x, y=node_y, mode='markers', hoverinfo='text', marker=dict(showscale=False, color=node_color, size=node_size, line_width=2))\n    node_trace.text = node_text\n\n    # Grafiği oluşturalım ve gösterelim.\n    fig = go.Figure(data=[edge_trace, node_trace],\n                 layout=go.Layout(\n                    title='<br>En Popüler 100 GO Terimi Arasındaki İlişki Ağı (İnteraktif)', titlefont_size=16, showlegend=False,\n                    hovermode='closest', margin=dict(b=20,l=5,r=5,t=40),\n                    xaxis=dict(showgrid=False, zeroline=False, showticklabels=False),\n                    yaxis=dict(showgrid=False, zeroline=False, showticklabels=False)))\n    fig.show()\nelse:\n    print(\"Görselleştirilecek ağ boş.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-19T11:25:36.929043Z","iopub.execute_input":"2025-10-19T11:25:36.929416Z","iopub.status.idle":"2025-10-19T11:25:45.913766Z","shell.execute_reply.started":"2025-10-19T11:25:36.929392Z","shell.execute_reply":"2025-10-19T11:25:45.912845Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Analiz ve Bulgular:**\n*   Bu interaktif graf, farklı ontolojilerin (renklerle gösterilen) nasıl birbirleriyle ilişkili olduğunu ve genel terimlerin (daha büyük düğümler) daha spesifik terimlere nasıl bağlandığını (ok yönüyle) gösterir.\n*   Grafiğin merkezinde, \"nucleus\" (çekirdek), \"cytoplasm\" (sitoplazma), \"protein binding\" (protein bağlanması) gibi çok genel ve çok sayıda proteine atanmış olan \"merkez (hub)\" terimlerin kümelendiği görülmektedir.\n*   Fare ile üzerine gelerek her bir terimin adını, atandığı protein sayısını ve ait olduğu ontolojiyi görebilirsiniz. Bu görselleştirme, fonksiyonel annotasyonların karmaşık ve hiyerarşik doğasını keşfetmek için güçlü bir araçtır.\n\n---\n\n### **9. Sonuç ve Modelleme Stratejileri**\n\nBu öğretici ve kapsamlı Keşifsel Veri Analizi'nden elde ettiğimiz temel bulgular ve modelleme için çıkarımlar şunlardır:\n\n1.  **Problem Yapısı:** Problemin, her proteine birden fazla fonksiyon atanabilen **çok etiketli (multi-label) bir sınıflandırma** problemi olduğunu doğruladık.\n2.  **Girdi Verisi:** Girdi olarak değişken uzunlukta protein sekansları veriliyor. Bu, özellikle Transformer tabanlı modeller için sekansların nasıl işleneceği (kesme, parçalama) konusunda bir strateji gerektiriyor.\n3.  **Etiket Dengesizliği:** Veri setindeki en büyük zorluk, etiket dağılımının aşırı derecede **uzun kuyruklu** olmasıdır. Nadir fonksiyonları tahmin etmek, model performansını belirleyen ana faktör olacaktır.\n    *   **Strateji:** Etiket sıklığına göre ağırlıklandırılmış kayıp fonksiyonları (weighted loss functions), azınlık sınıfları için over-sampling (örnek sayısını artırma) veya daha karmaşık hiyerarşik sınıflandırma yaklaşımları denenmelidir.\n4.  **Hiyerarşik Etiket Yapısı:** GO terimleri bir **Yönlendirilmiş Döngüsüz Graf (DAG)** yapısındadır. Bir alt terimin tahmini, üst terimlerinin de tahmin edilmesi anlamına gelir (\"doğruluk kuralı\").\n    *   **Strateji:** Modelin tahminlerinden sonra, bu hiyerarşik bilgiyi kullanarak tahminleri tutarlı hale getirmek (örneğin, bir alt terim tahmin edildiyse tüm üst terimlerini de tahmin etmek) zorunludur. Buna **tahmin yayılımı (prediction propagation)** denir.\n5.  **Değerlendirme Metriği:** Yarışma, nadir ve bilgilendirici terimleri ödüllendiren **IA (Bilgi Birikimi)** ile ağırlıklandırılmış bir F-max skoru kullanmaktadır.\n    *   **Strateji:** Model, sadece sık görülen genel terimleri değil, IA değeri yüksek terimleri de öğrenmeye odaklanmalıdır. Bu, etiket dengesizliği ile başa çıkma stratejileriyle doğrudan ilişkilidir.\n6.  **Veri Dağılımı:** Eğitim ve test setleri arasında sekans uzunluğu açısından büyük bir **dağılım kayması (domain shift)** olmaması, modelin test setinde de iyi bir genelleme yapabileceği konusunda bize güven vermektedir.\n7.  **Ontoloji Farklılıkları:** Üç ana ontoloji dalı (BPO, CCO, MFO) farklı sayıda etiket ve farklı karmaşıklık seviyeleri içermektedir.\n    *   **Strateji:** Her bir ontoloji için ayrı modeller eğitmek veya tek bir modelin sonunda her ontoloji için ayrı bir \"sınıflandırma başlığı\" (classification head) kullanmak, her dalın kendine özgü yapısını daha iyi öğrenmeye yardımcı olabilir.\n\nBu EDA, CAFA 6 yarışmasında başarılı olmak ve protein fonksiyonu tahmini alanını anlamak için sağlam bir temel oluşturmaktadır. Sonraki adımlar, bu bulgular ışığında uygun bir model mimarisi seçmek (örneğin, ProtBERT gibi önceden eğitilmiş bir protein dil modeli), veriyi modele uygun hale getirmek ve sağlam bir doğrulama (validation) stratejisi oluşturmaktır.","metadata":{}}]}