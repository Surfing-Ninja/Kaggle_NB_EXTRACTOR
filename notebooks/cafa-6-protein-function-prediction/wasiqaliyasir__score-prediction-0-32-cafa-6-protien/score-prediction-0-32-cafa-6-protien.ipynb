{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":116062,"databundleVersionId":14084779,"isSourceIdPinned":false,"sourceType":"competition"},{"sourceId":269339911,"sourceType":"kernelVersion"},{"sourceId":270571028,"sourceType":"kernelVersion"},{"sourceId":270597770,"sourceType":"kernelVersion"},{"sourceId":271888783,"sourceType":"kernelVersion"}],"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.ensemble import StackingClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\n\ndef ensemble_submissions(file_paths, weights, output_path='submission.tsv'):\n    dfs = []\n    for i, path in enumerate(file_paths):\n        df = pd.read_csv(path, sep='\\t', header=None, names=['protein', 'go_term', 'score'])\n        df['key'] = df['protein'] + '_' + df['go_term']\n        df = df.rename(columns={'score': f'score_{i}'})\n        dfs.append(df)\n        print(f\"Loaded {len(df)} predictions from file {i+1}\")\n    \n    result = dfs[0][['protein', 'go_term', 'key', 'score_0']].copy()\n    for i in range(1, len(dfs)):\n        result = result.merge(dfs[i][['key', f'score_{i}']], on='key', how='outer')\n    \n    for i in range(len(dfs)):\n        result[f'score_{i}'] = result[f'score_{i}'].fillna(0)\n    \n    result['score'] = sum(weights[i] * result[f'score_{i}'] for i in range(len(dfs)))\n    result['protein'] = result['protein'].fillna(result['key'].str.split('_').str[0])\n    result['go_term'] = result['go_term'].fillna(result['key'].str.split('_').str[-1])\n    \n    result = result.sort_values('score', ascending=False)\n    result[['protein', 'go_term', 'score']].to_csv(\n        output_path,\n        sep='\\t',\n        index=False,\n        header=False\n    )\n    \n    print(f\"\\nSaved {len(result)} predictions to {output_path}\")\n    \n    return result\n\ndef stacking_model(file_paths, weights, output_path='submission.tsv'):\n    # Load the ensemble submission\n    result = ensemble_submissions(file_paths, weights, output_path)\n    \n    # Assume the 'protein' and 'go_term' are features\n    X = result[['score_0', 'score_1']]  # Example: if you have 2 models, extend as needed\n    y = result['score']  # Target is the final combined score\n    \n    # Split data into training and testing sets\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n    \n    # Define base models for stacking\n    base_learners = [\n        ('svm', SVC(kernel='linear', probability=True)),\n        ('logreg', LogisticRegression()),\n        ('rf', RandomForestClassifier(n_estimators=100))\n    ]\n    \n    # Define the meta-model (final model)\n    meta_model = LogisticRegression()\n    \n    # Create a stacking model\n    stacking_model = StackingClassifier(estimators=base_learners, final_estimator=meta_model)\n    \n    # Train the stacking model\n    stacking_model.fit(X_train, y_train)\n    \n    # Predict using the stacking model\n    y_pred = stacking_model.predict(X_test)\n    \n    # Calculate accuracy\n    accuracy = accuracy_score(y_test, y_pred)\n    print(f\"Stacking Model Accuracy: {accuracy * 100:.2f}%\")\n    \n    # Save the final predictions\n    result['stacking_score'] = stacking_model.predict(X)  # Apply model on all data\n    result[['protein', 'go_term', 'stacking_score']].to_csv(\n        output_path,\n        sep='\\t',\n        index=False,\n        header=False\n    )\n    \n    print(f\"\\nSaved stacked predictions to {output_path}\")\n    \n    return result\n\nif __name__ == \"__main__\":\n    file_paths = [\n        '/kaggle/input/gaf-submission/submission.tsv',\n        '/kaggle/input/cafa-6-predictions/submission.tsv'\n    ]\n    weights = [0.5, 0.5]\n    \n    # Run stacking model\n    stacking_model(file_paths, weights)","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}