{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":112509,"databundleVersionId":14254895,"sourceType":"competition"}],"dockerImageVersionId":31154,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<div style=\"border: 2px solid #4CAF50; border-radius: 10px; padding: 15px; background-color: #f9f9f9; text-align: left; font-family: Arial, sans-serif; width: 90%; max-width: 600px; margin: auto;\">\n  <h1 style=\"color: #2E7D32; text-align: center;\">üå± CSIRO Image2Biomass</h1>\n  \n  <h4 style=\"color: #2E7D32;\">üéØ Competition Goal</h4>\n  <p>Predict 5 biomass components from pasture images to help farmers optimize grazing decisions.</p>\n\n  <h4 style=\"color: #2E7D32;\">üõ† Solution</h4>\n  <ul>\n    <li><strong>Model:</strong> Custom CNN</li>\n    <li><strong>Training:</strong> 3-fold cross-validation</li>\n    <li><strong>Targets:</strong> Dry_Green_g, Dry_Dead_g, Dry_Clover_g, GDM_g, Dry_Total_g</li>\n    <li><strong>Evaluation:</strong> Weighted R¬≤ score</li>\n  </ul>\n\n  <h4 style=\"color: #2E7D32;\">‚úÖ Key Features</h4>\n  <ul>\n    <li>Multi-target regression</li>\n    <li>Competition-weighted loss</li>\n    <li>Ensemble predictions</li>\n    <li>Proper submission format</li>\n  </ul>\n\n  <div style=\"text-align: center; margin-top: 15px; padding: 10px; background: #E8F5E8; border-radius: 5px;\">\n    <strong></strong>\n  </div>\n</div>","metadata":{}},{"cell_type":"code","source":"import os\nimport pandas as pd\nimport numpy as np\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom PIL import Image\nimport torchvision.transforms as T\nimport random","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-29T17:47:18.375354Z","iopub.execute_input":"2025-10-29T17:47:18.375884Z","iopub.status.idle":"2025-10-29T17:47:18.380392Z","shell.execute_reply.started":"2025-10-29T17:47:18.375843Z","shell.execute_reply":"2025-10-29T17:47:18.379566Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Set random seeds for reproducibility\ndef set_seed(seed=42):\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n\nset_seed(42)\n\n# Configuration parameters\nIMAGE_SIZE = 224  \nBATCH_SIZE = 16\nEPOCHS = 5\nLEARNING_RATE = 1e-4\nFOLDS = 3\n\nTARGETS = ['Dry_Green_g', 'Dry_Dead_g', 'Dry_Clover_g', 'GDM_g', 'Dry_Total_g']\nWEIGHTS = [0.1, 0.1, 0.1, 0.2, 0.5]\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(f\"Using device: {device}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-29T17:47:18.400301Z","iopub.execute_input":"2025-10-29T17:47:18.400515Z","iopub.status.idle":"2025-10-29T17:47:18.407888Z","shell.execute_reply.started":"2025-10-29T17:47:18.4005Z","shell.execute_reply":"2025-10-29T17:47:18.407253Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_data = pd.read_csv('/kaggle/input/csiro-biomass/train.csv')\ntest_data = pd.read_csv('/kaggle/input/csiro-biomass/test.csv')\nsubmission_format = pd.read_csv('/kaggle/input/csiro-biomass/sample_submission.csv')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-29T17:47:18.414035Z","iopub.execute_input":"2025-10-29T17:47:18.414575Z","iopub.status.idle":"2025-10-29T17:47:18.43367Z","shell.execute_reply.started":"2025-10-29T17:47:18.41455Z","shell.execute_reply":"2025-10-29T17:47:18.432929Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(train_data.shape)\nprint(test_data.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-29T17:47:18.434669Z","iopub.execute_input":"2025-10-29T17:47:18.434948Z","iopub.status.idle":"2025-10-29T17:47:18.43928Z","shell.execute_reply.started":"2025-10-29T17:47:18.434933Z","shell.execute_reply":"2025-10-29T17:47:18.438414Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Clean file paths\ntrain_data['image_path'] = train_data['image_path'].str.replace('train/', '')\ntest_data['image_path'] = test_data['image_path'].str.replace('test/', '')\n\ndef extract_image_id(sample_id):\n    return str(sample_id).split('__')[0]\n\ntrain_data['image_id'] = train_data['sample_id'].apply(extract_image_id)\ntest_data['image_id'] = test_data['sample_id'].apply(extract_image_id)\n\nprint(f\"   Unique training images: {train_data['image_id'].nunique()}\")\nprint(f\"   Unique test images: {test_data['image_id'].nunique()}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-29T17:47:18.44434Z","iopub.execute_input":"2025-10-29T17:47:18.444751Z","iopub.status.idle":"2025-10-29T17:47:18.459067Z","shell.execute_reply.started":"2025-10-29T17:47:18.444733Z","shell.execute_reply":"2025-10-29T17:47:18.458303Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class BiomassTrainDataset(Dataset):\n    def __init__(self, dataframe, transform=None):\n        self.dataframe = dataframe\n        self.transform = transform\n        \n        # Group by image and create targets matrix\n        image_groups = dataframe.groupby('image_id').first().reset_index()\n        self.image_data = image_groups\n        self.target_values = []\n        \n        for img_id in self.image_data['image_id']:\n            image_targets = dataframe[dataframe['image_id'] == img_id].set_index('target_name')['target']\n            target_array = [image_targets.get(target, 0) for target in TARGETS]\n            self.target_values.append(target_array)\n        \n        self.target_values = np.array(self.target_values)\n\n    def __len__(self):\n        return len(self.image_data)\n\n    def __getitem__(self, index):\n        row = self.image_data.iloc[index]\n        image_path = os.path.join('/kaggle/input/csiro-biomass/train/', row['image_path'])\n        \n        try:\n            image = Image.open(image_path).convert('RGB')\n        except:\n            # Create placeholder if file missing\n            image = Image.new('RGB', (IMAGE_SIZE, IMAGE_SIZE), color=(100, 150, 100))\n        \n        if self.transform:\n            image = self.transform(image)\n            \n        targets = torch.FloatTensor(self.target_values[index])\n        return image, targets\n\nclass BiomassTestDataset(Dataset):\n    def __init__(self, dataframe, transform=None):\n        self.dataframe = dataframe\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.dataframe)\n\n    def __getitem__(self, index):\n        row = self.dataframe.iloc[index]\n        image_path = '/kaggle/input/csiro-biomass/test/' + row[\"image_path\"]\n        \n        try:\n            image = Image.open(image_path).convert(\"RGB\")\n        except:\n            image = Image.new('RGB', (IMAGE_SIZE, IMAGE_SIZE), color=(100, 150, 100))\n            \n        if self.transform:\n            image = self.transform(image)\n        return image\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-29T17:47:18.46048Z","iopub.execute_input":"2025-10-29T17:47:18.460744Z","iopub.status.idle":"2025-10-29T17:47:18.475919Z","shell.execute_reply.started":"2025-10-29T17:47:18.460718Z","shell.execute_reply":"2025-10-29T17:47:18.475175Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **Model Architecture**","metadata":{}},{"cell_type":"code","source":"\nclass CustomBiomassModel(nn.Module):\n    def __init__(self, outputs=5):\n        super().__init__()\n        \n        # Feature extractor\n        self.features = nn.Sequential(\n            # Block 1\n            nn.Conv2d(3, 32, 3, padding=1),\n            nn.BatchNorm2d(32),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(2),\n            \n            # Block 2\n            nn.Conv2d(32, 64, 3, padding=1),\n            nn.BatchNorm2d(64),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(2),\n            \n            # Block 3\n            nn.Conv2d(64, 128, 3, padding=1),\n            nn.BatchNorm2d(128),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(2),\n            \n            # Block 4\n            nn.Conv2d(128, 256, 3, padding=1),\n            nn.BatchNorm2d(256),\n            nn.ReLU(inplace=True),\n            nn.AdaptiveAvgPool2d((1, 1))\n        )\n        \n        # Regressor\n        self.regressor = nn.Sequential(\n            nn.Dropout(0.2),\n            nn.Linear(256, 128),\n            nn.ReLU(inplace=True),\n            nn.Dropout(0.1),\n            nn.Linear(128, 64),\n            nn.ReLU(inplace=True),\n            nn.Linear(64, outputs)\n        )\n        \n        self._initialize_weights()\n\n    def _initialize_weights(self):\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n                if m.bias is not None:\n                    nn.init.constant_(m.bias, 0)\n            elif isinstance(m, nn.BatchNorm2d):\n                nn.init.constant_(m.weight, 1)\n                nn.init.constant_(m.bias, 0)\n            elif isinstance(m, nn.Linear):\n                nn.init.normal_(m.weight, 0, 0.01)\n                nn.init.constant_(m.bias, 0)\n\n    def forward(self, x):\n        x = self.features(x)\n        x = x.view(x.size(0), -1)\n        x = self.regressor(x)\n        return x\n\nclass WeightedLoss(nn.Module):\n    def __init__(self, weights):\n        super().__init__()\n        self.weights = torch.tensor(weights)\n        \n    def forward(self, predictions, targets):\n        squared_errors = (predictions - targets) ** 2\n        weighted_errors = squared_errors * self.weights.to(predictions.device)\n        return weighted_errors.mean()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-29T17:47:18.478424Z","iopub.execute_input":"2025-10-29T17:47:18.478648Z","iopub.status.idle":"2025-10-29T17:47:18.494503Z","shell.execute_reply.started":"2025-10-29T17:47:18.478623Z","shell.execute_reply":"2025-10-29T17:47:18.49375Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **Data Transforms**","metadata":{}},{"cell_type":"code","source":"# Image transformations\ntrain_transforms = T.Compose([\n    T.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n    T.RandomHorizontalFlip(p=0.5),\n    T.RandomRotation(degrees=10),\n    T.ColorJitter(brightness=0.2, contrast=0.2),\n    T.ToTensor(),\n    T.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n])\n\nvalidation_transforms = T.Compose([\n    T.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n    T.ToTensor(),\n    T.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n])\n\ntest_transforms = T.Compose([\n    T.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n    T.ToTensor(),\n    T.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-29T17:47:18.495579Z","iopub.execute_input":"2025-10-29T17:47:18.495877Z","iopub.status.idle":"2025-10-29T17:47:18.509518Z","shell.execute_reply.started":"2025-10-29T17:47:18.495862Z","shell.execute_reply":"2025-10-29T17:47:18.50879Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **Cross-Validation Setup**","metadata":{}},{"cell_type":"code","source":"# Prepare cross-validation folds\nunique_image_ids = train_data['image_id'].unique()\nnp.random.shuffle(unique_image_ids)\nfold_mapping = {img_id: i % FOLDS for i, img_id in enumerate(unique_image_ids)}\ntrain_data['fold'] = train_data['image_id'].map(fold_mapping)\n\nprint(f\"   Created {FOLDS} folds for cross-validation\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-29T17:47:18.51065Z","iopub.execute_input":"2025-10-29T17:47:18.510882Z","iopub.status.idle":"2025-10-29T17:47:18.523202Z","shell.execute_reply.started":"2025-10-29T17:47:18.510856Z","shell.execute_reply":"2025-10-29T17:47:18.522584Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **Training Function**","metadata":{}},{"cell_type":"code","source":"def train_cv_fold(fold_number):\n    print(f\"  Training fold {fold_number + 1}/{FOLDS}\")\n    \n    # Split data\n    train_fold = train_data[train_data['fold'] != fold_number]\n    valid_fold = train_data[train_data['fold'] == fold_number]\n    \n    print(f\"    Training images: {len(train_fold['image_id'].unique())}\")\n    print(f\"    Validation images: {len(valid_fold['image_id'].unique())}\")\n    \n    # Create datasets\n    train_dataset = BiomassTrainDataset(train_fold, transform=train_transforms)\n    valid_dataset = BiomassTrainDataset(valid_fold, transform=validation_transforms)\n    \n    # Create data loaders\n    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n    valid_loader = DataLoader(valid_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n    \n    # Initialize model\n    model = CustomBiomassModel(outputs=len(TARGETS))\n    model.to(device)\n    \n    # Loss and optimizer\n    loss_function = WeightedLoss(WEIGHTS)\n    optimizer = torch.optim.AdamW(model.parameters(), lr=LEARNING_RATE, weight_decay=1e-4)\n    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=EPOCHS)\n    \n    best_loss = float('inf')\n    \n    # Training loop\n    for epoch in range(EPOCHS):\n        # Training phase\n        model.train()\n        epoch_train_loss = 0\n        for images, targets in train_loader:\n            images, targets = images.to(device), targets.to(device)\n            \n            optimizer.zero_grad()\n            outputs = model(images)\n            loss = loss_function(outputs, targets)\n            loss.backward()\n            optimizer.step()\n            \n            epoch_train_loss += loss.item()\n        \n        # Validation phase\n        model.eval()\n        epoch_val_loss = 0\n        with torch.no_grad():\n            for images, targets in valid_loader:\n                images, targets = images.to(device), targets.to(device)\n                outputs = model(images)\n                epoch_val_loss += loss_function(outputs, targets).item()\n        \n        # Calculate average losses\n        epoch_train_loss /= len(train_loader)\n        epoch_val_loss /= len(valid_loader)\n        \n        scheduler.step()\n        \n        print(f'    Epoch {epoch+1:02d}: Train Loss: {epoch_train_loss:.4f}, Val Loss: {epoch_val_loss:.4f}')\n        \n        # Save best model\n        if epoch_val_loss < best_loss:\n            best_loss = epoch_val_loss\n            torch.save(model.state_dict(), f'model_fold_{fold_number}.pth')\n            \n    \n    return best_loss\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-29T17:47:18.524101Z","iopub.execute_input":"2025-10-29T17:47:18.524376Z","iopub.status.idle":"2025-10-29T17:47:18.535602Z","shell.execute_reply.started":"2025-10-29T17:47:18.524353Z","shell.execute_reply":"2025-10-29T17:47:18.534973Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **Model Training**","metadata":{}},{"cell_type":"code","source":"fold_performance = []\n\nfor fold_idx in range(FOLDS):\n    fold_loss = train_cv_fold(fold_idx)\n    fold_performance.append(fold_loss)\n    print(f' Fold {fold_idx + 1} completed. Best validation loss: {fold_loss:.4f}')\n\nprint(f\" Average validation loss: {np.mean(fold_performance):.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-29T17:47:18.537309Z","iopub.execute_input":"2025-10-29T17:47:18.5379Z","iopub.status.idle":"2025-10-29T17:50:24.979036Z","shell.execute_reply.started":"2025-10-29T17:47:18.537882Z","shell.execute_reply":"2025-10-29T17:50:24.978049Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **Prediction & Inference**","metadata":{}},{"cell_type":"code","source":"# Prepare test data\ntest_data_unique = test_data[~test_data['image_path'].duplicated()][['sample_id', 'image_path']].reset_index(drop=True)\ntest_data_unique['sample_id'] = test_data_unique['sample_id'].apply(extract_image_id)\n\nprint(f\"   Test images for prediction: {len(test_data_unique)}\")\n\n# Create test dataset and loader\ntest_dataset = BiomassTestDataset(test_data_unique, transform=test_transforms)\ntest_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n\n# Simple inference function\ndef predict_batch(model, images):\n    with torch.no_grad():\n        predictions = model(images)\n    return predictions\n\n# Ensemble predictions from all folds\npredictions_by_fold = {}\n\nfor fold_idx in range(FOLDS):\n    print(f\"   Predicting with fold {fold_idx + 1}...\")\n    \n    model = CustomBiomassModel(outputs=len(TARGETS))\n    model.load_state_dict(torch.load(f'model_fold_{fold_idx}.pth', map_location=device))\n    model.eval()\n    model.to(device)\n    \n    fold_predictions = []\n    with torch.no_grad():\n        for batch in test_loader:\n            images = batch.to(device)\n            batch_predictions = predict_batch(model, images)\n            batch_predictions = batch_predictions.cpu().numpy()\n            fold_predictions.append(batch_predictions)\n    \n    predictions_by_fold[fold_idx] = np.concatenate(fold_predictions)\n\n# Combine predictions from all folds\nensemble_predictions = np.mean([predictions_by_fold[fold_idx] for fold_idx in range(FOLDS)], axis=0)\n\nprint(f\"   Final predictions shape: {ensemble_predictions.shape}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-29T17:50:24.980168Z","iopub.execute_input":"2025-10-29T17:50:24.980449Z","iopub.status.idle":"2025-10-29T17:50:25.560713Z","shell.execute_reply.started":"2025-10-29T17:50:24.980416Z","shell.execute_reply":"2025-10-29T17:50:25.559881Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **Submission File Creation**","metadata":{}},{"cell_type":"code","source":"# Calculate mean values for reference\ntarget_means = {}\nfor target in TARGETS:\n    target_data = train_data[train_data['target_name'] == target]['target']\n    target_means[target] = target_data.mean()\n    print(f\"   Training mean for {target}: {target_means[target]:.3f}\")\n\n# Create results dataframe\nresults_df = pd.DataFrame(\n    ensemble_predictions, \n    columns=TARGETS\n)\nresults_df['sample_id'] = test_data_unique['sample_id']\n\n# Convert to submission format using melt\nsubmission_df = pd.melt(\n    results_df, \n    id_vars='sample_id', \n    value_vars=TARGETS, \n    value_name='target',\n    var_name='target_name'\n)\n\n# Create correct sample_id format\nsubmission_df['sample_id'] = submission_df['sample_id'] + '__' + submission_df['target_name']\n\n# Ensure positive values and select columns\nsubmission_df['target'] = submission_df['target'].clip(0, None)\nsubmission_df = submission_df[['sample_id', 'target']].copy()\n\n# Validation\nprint(\"\\n  Submission Validation:\")\nprint(f\"   Rows: {submission_df.shape[0]}\")\nprint(f\"   Target range: {submission_df['target'].min():.3f} to {submission_df['target'].max():.3f}\")\nprint(f\"   Sample format: {submission_df['sample_id'].iloc[0]}\")\n\n# Verify row count\nexpected_rows = len(test_data)\nactual_rows = len(submission_df)\nprint(f\"   Expected rows: {expected_rows}, Generated rows: {actual_rows}\")\n\nif expected_rows == actual_rows:\n    print(\"   Row count correct\")\nelse:\n    print(\"   Row count mismatch\")\n\n# Save submission\nsubmission_df.to_csv('submission.csv', index=False)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-29T17:50:25.562412Z","iopub.execute_input":"2025-10-29T17:50:25.562664Z","iopub.status.idle":"2025-10-29T17:50:25.586682Z","shell.execute_reply.started":"2025-10-29T17:50:25.562644Z","shell.execute_reply":"2025-10-29T17:50:25.58607Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"submission_df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-29T17:50:25.587347Z","iopub.execute_input":"2025-10-29T17:50:25.587601Z","iopub.status.idle":"2025-10-29T17:50:25.606112Z","shell.execute_reply.started":"2025-10-29T17:50:25.587576Z","shell.execute_reply":"2025-10-29T17:50:25.6053Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<div style=\"border: 2px solid #FFA500; border-radius: 10px; padding: 10px; background-color: #FFF5E6; text-align: center; font-family: Arial, sans-serif; width: 80%; max-width: 600px; margin: auto;\">\n  <h3 style=\"color: #FFA500;\">üëç <strong>Enjoyed this guide?</strong></h3>\n  <p style=\"color: #333333;\">If you found this guide helpful, please consider giving it an upvote! Your support helps us continue to create valuable content and improve our resources.</p>\n  <p style=\"font-size: 16px; color: #FF8C00;\">Thank you! üòä</p>\n  <p style=\"color: #333333; margin-top: 10px;\">\n    <strong>Connect with me on linkedIn:</strong><br>\n    <a href=\"https://www.linkedin.com/in/abdullah0a7\" style=\"color: #0077B5; text-decoration: none; display: inline-flex; align-items: center; gap: 5px;\">\n      <svg width=\"20\" height=\"20\" viewBox=\"0 0 24 24\" fill=\"#0077B5\">\n        <path d=\"M20.447 20.452h-3.554v-5.569c0-1.328-.027-3.037-1.852-3.037-1.853 0-2.136 1.445-2.136 2.939v5.667H9.351V9h3.414v1.561h.046c.477-.9 1.637-1.85 3.37-1.85 3.601 0 4.267 2.37 4.267 5.455v6.286zM5.337 7.433c-1.144 0-2.063-.926-2.063-2.065 0-1.138.92-2.063 2.063-2.063 1.14 0 2.064.925 2.064 2.063 0 1.139-.925 2.065-2.064 2.065zm1.782 13.019H3.555V9h3.564v11.452zM22.225 0H1.771C.792 0 0 .774 0 1.729v20.542C0 23.227.792 24 1.771 24h20.451C23.2 24 24 23.227 24 22.271V1.729C24 .774 23.2 0 22.222 0h.003z\"/>\n      </svg>\n      M Abdullah\n    </a>\n  </p>\n</div>","metadata":{}}]}