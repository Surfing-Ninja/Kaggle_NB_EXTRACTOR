{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":112509,"databundleVersionId":14254895,"sourceType":"competition"}],"dockerImageVersionId":31153,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport torch\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport torch.nn as nn\nimport matplotlib.pyplot as plt\nimport torchvision.transforms as transforms\n\nfrom PIL import Image\nfrom collections import defaultdict\nfrom torchvision.models import resnet50\nfrom torch.utils.data import Dataset, DataLoader\nfrom sklearn.model_selection import train_test_split","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-29T00:31:57.70455Z","iopub.execute_input":"2025-10-29T00:31:57.705175Z","iopub.status.idle":"2025-10-29T00:32:07.449954Z","shell.execute_reply.started":"2025-10-29T00:31:57.70515Z","shell.execute_reply":"2025-10-29T00:32:07.449314Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def get_unique_sizes(directory):\n    size_counts = defaultdict(int)\n    for root, _, files in os.walk(directory):\n        for file in files:\n            if file.lower().endswith(('.png', '.jpg', '.jpeg', 'JPG')):\n                try:\n                    with Image.open(os.path.join(root, file)) as img:\n                        size = img.size\n                        size_counts[size] += 1\n                except Exception as e:\n                    print(f\"Error {file}: {e}\")\n\n    return size_counts\n\nfolders = [\n    \"/kaggle/input/csiro-biomass/train\",\n    \"/kaggle/input/csiro-biomass/test\",\n]\n\nfor folder in folders:\n    print(f\"\\nğŸ“‚ Folder: {folder}\")\n    sizes = get_unique_sizes(folder)\n\n    if not sizes:\n        print(\"No images or mistake in code\")\n        continue\n    \n    sorted_sizes = sorted(sizes.items(), key=lambda x: x[1], reverse=True)\n\n    print(\"â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\")\n    print(\"â”‚  Width (px)  â”‚ Height (px)  â”‚Quantityâ”‚\")\n    print(\"â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\")\n    for (w, h), count in sorted_sizes:\n        print(f\"â”‚ {w:<13} â”‚ {h:<13} â”‚ {count:<7} â”‚\")\n    print(\"â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-10-29T00:32:07.451925Z","iopub.execute_input":"2025-10-29T00:32:07.452274Z","iopub.status.idle":"2025-10-29T00:32:10.321735Z","shell.execute_reply.started":"2025-10-29T00:32:07.452254Z","shell.execute_reply":"2025-10-29T00:32:10.320898Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/csiro-biomass/train.csv')\ntrain.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-29T00:32:10.322527Z","iopub.execute_input":"2025-10-29T00:32:10.322791Z","iopub.status.idle":"2025-10-29T00:32:10.363941Z","shell.execute_reply.started":"2025-10-29T00:32:10.322775Z","shell.execute_reply":"2025-10-29T00:32:10.363205Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class DatasetCS(Dataset):\n    def __init__(self, df, images_dir, transform=None, is_test=False):\n        self.df = df\n        self.images_dir = images_dir\n        self.transform = transform\n        self.is_test = is_test\n        \n        if not is_test:\n            self.target_mapping = {\n                'Dry_Green_g': 0, 'Dry_Dead_g': 1, 'Dry_Clover_g': 2,\n                'GDM_g': 3, 'Dry_Total_g': 4\n            }\n    \n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self, idx):\n        row = self.df.iloc[idx]\n        image_path = os.path.join(self.images_dir, row['image_path'])\n        \n        image = Image.open(image_path).convert('RGB')\n        \n        if self.transform:\n            image = self.transform(image)\n        \n        if self.is_test:\n            return image, row['sample_id']\n        else:\n            target_value = row['target']\n            target_type = self.target_mapping[row['target_name']]\n            return image, torch.tensor(target_value, dtype=torch.float32), target_type\n\ntrain_transform = transforms.Compose([\n    transforms.Resize((500, 250)),\n    transforms.RandomHorizontalFlip(p=0.3),\n    transforms.ColorJitter(brightness=0.2, contrast=0.2),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n])\n\nval_transform = transforms.Compose([\n    transforms.Resize((500, 250)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-29T00:32:10.365454Z","iopub.execute_input":"2025-10-29T00:32:10.36566Z","iopub.status.idle":"2025-10-29T00:32:10.373603Z","shell.execute_reply.started":"2025-10-29T00:32:10.365644Z","shell.execute_reply":"2025-10-29T00:32:10.372946Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class ResNet34(nn.Module):\n    def __init__(self, num_targets=5):\n        super(ResNet34, self).__init__()\n        self.backbone = resnet50(weights=None)\n        self.backbone.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False)\n        \n        in_features = self.backbone.fc.in_features\n        self.backbone.fc = nn.Identity()\n        \n        self.shared_features = nn.Sequential(\n            nn.Linear(in_features, 512),\n            nn.BatchNorm1d(512),\n            nn.ReLU(inplace=True),\n            nn.Dropout(0.3),\n            nn.Linear(512, 256),\n            nn.BatchNorm1d(256),\n            nn.ReLU(inplace=True),\n        )\n        \n        self.heads = nn.ModuleList([\n            nn.Sequential(\n                nn.Dropout(0.2),\n                nn.Linear(256, 128),\n                nn.ReLU(inplace=True),\n                nn.Linear(128, 1)\n            ) for _ in range(num_targets)\n        ])\n        \n        self._initialize_weights()\n    \n    def _initialize_weights(self):\n        for m in self.modules():\n            if isinstance(m, nn.Linear):\n                nn.init.normal_(m.weight, 0, 0.01)\n                nn.init.constant_(m.bias, 0)\n    \n    def forward(self, x, target_type=None):\n        features = self.backbone(x)\n        shared_out = self.shared_features(features)\n        \n        if target_type is not None:\n            outputs = []\n            for i, t_type in enumerate(target_type):\n                outputs.append(self.heads[t_type](shared_out[i].unsqueeze(0)))\n            return torch.cat(outputs, dim=0)\n        else:\n            all_outputs = [head(shared_out) for head in self.heads]\n            return torch.cat(all_outputs, dim=1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-29T00:32:10.37454Z","iopub.execute_input":"2025-10-29T00:32:10.374878Z","iopub.status.idle":"2025-10-29T00:32:10.392913Z","shell.execute_reply.started":"2025-10-29T00:32:10.374836Z","shell.execute_reply":"2025-10-29T00:32:10.392385Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=15):\n    train_losses = []\n    val_losses = []\n    \n    for epoch in range(num_epochs):\n        model.train()\n        train_loss = 0.0\n        \n        for images, targets, target_types in train_loader:\n            images = images.to(device)\n            targets = targets.to(device)\n            target_types = target_types.to(device)\n            \n            optimizer.zero_grad()\n            outputs = model(images, target_types).squeeze()\n            loss = criterion(outputs, targets)\n            loss.backward()\n            optimizer.step()\n            \n            train_loss += loss.item()\n        \n        model.eval()\n        val_loss = 0.0\n        \n        with torch.no_grad():\n            for images, targets, target_types in val_loader:\n                images = images.to(device)\n                targets = targets.to(device)\n                target_types = target_types.to(device)\n                \n                outputs = model(images, target_types).squeeze()\n                loss = criterion(outputs, targets)\n                val_loss += loss.item()\n        \n        train_loss /= len(train_loader)\n        val_loss /= len(val_loader)\n        train_losses.append(train_loss)\n        val_losses.append(val_loss)\n        \n        print(f'Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}')\n    \n    return train_losses, val_losses","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-29T00:32:10.393668Z","iopub.execute_input":"2025-10-29T00:32:10.394374Z","iopub.status.idle":"2025-10-29T00:32:10.407835Z","shell.execute_reply.started":"2025-10-29T00:32:10.394327Z","shell.execute_reply":"2025-10-29T00:32:10.407101Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_indices, val_indices = train_test_split(\n    range(len(train)), \n    test_size=0.2, \n    random_state=42, \n    stratify=train['target_name']\n)\n\ntrain_subset = train.iloc[train_indices].reset_index(drop=True)\nval_subset = train.iloc[val_indices].reset_index(drop=True)\n\nprint(f\"train length: {len(train_subset)}\")\nprint(f\"val length: {len(val_subset)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-29T00:32:10.408629Z","iopub.execute_input":"2025-10-29T00:32:10.408911Z","iopub.status.idle":"2025-10-29T00:32:10.443634Z","shell.execute_reply.started":"2025-10-29T00:32:10.408888Z","shell.execute_reply":"2025-10-29T00:32:10.442895Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_dataset = DatasetCS(train_subset, '/kaggle/input/csiro-biomass', transform=train_transform)\nval_dataset = DatasetCS(val_subset, '/kaggle/input/csiro-biomass', transform=val_transform)\n\ntrain_loader = DataLoader(train_dataset, batch_size=16, shuffle=True, num_workers=2)\nval_loader = DataLoader(val_dataset, batch_size=16, shuffle=False, num_workers=2)\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\ndevice","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-29T00:32:10.444444Z","iopub.execute_input":"2025-10-29T00:32:10.444689Z","iopub.status.idle":"2025-10-29T00:32:10.53699Z","shell.execute_reply.started":"2025-10-29T00:32:10.444671Z","shell.execute_reply":"2025-10-29T00:32:10.536123Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model = ResNet34(num_targets=5).to(device)\n\ncriterion = nn.MSELoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=0.001)\nscheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=3, factor=0.5)\n\ntrain_losses, val_losses = train_model(\n    model,\n    train_loader,\n    val_loader,\n    criterion,\n    optimizer,\n    num_epochs=10\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-29T00:33:20.267834Z","iopub.execute_input":"2025-10-29T00:33:20.26841Z","iopub.status.idle":"2025-10-29T00:36:17.476282Z","shell.execute_reply.started":"2025-10-29T00:33:20.268371Z","shell.execute_reply":"2025-10-29T00:36:17.475396Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plt.figure(figsize=(10, 4))\n\nplt.plot(train_losses, label='Train Loss')\nplt.plot(val_losses, label='Val Loss')\n\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.title('Training History')\n\nplt.legend()\nplt.grid(True)\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-29T00:36:17.478142Z","iopub.execute_input":"2025-10-29T00:36:17.478506Z","iopub.status.idle":"2025-10-29T00:36:17.736289Z","shell.execute_reply.started":"2025-10-29T00:36:17.478484Z","shell.execute_reply":"2025-10-29T00:36:17.735486Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test = pd.read_csv('/kaggle/input/csiro-biomass/test.csv')\ntest_dataset = DatasetCS(test, '/kaggle/input/csiro-biomass', transform=val_transform, is_test=True)\ntest_loader = DataLoader(test_dataset, batch_size=16, shuffle=False, num_workers=2)\n\nmodel.eval()\npredictions = []\nsample_ids = []\n\ntarget_mapping = {\n    'Dry_Green_g': 0, 'Dry_Dead_g': 1, 'Dry_Clover_g': 2,\n    'GDM_g': 3, 'Dry_Total_g': 4\n}\n\nwith torch.no_grad():\n    for images, batch_sample_ids in test_loader:\n        images = images.to(device)\n        batch_outputs = model(images)\n        \n        for i, sample_id in enumerate(batch_sample_ids):\n            row = test[test['sample_id'] == sample_id].iloc[0]\n            target_idx = target_mapping[row['target_name']]\n            prediction = batch_outputs[i, target_idx].item()\n            predictions.append(prediction)\n            sample_ids.append(sample_id)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-29T00:37:01.698515Z","iopub.execute_input":"2025-10-29T00:37:01.699327Z","iopub.status.idle":"2025-10-29T00:37:02.154164Z","shell.execute_reply.started":"2025-10-29T00:37:01.699294Z","shell.execute_reply":"2025-10-29T00:37:02.153252Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"submission = pd.DataFrame({\n    'sample_id': sample_ids,\n    'target': predictions\n})\n\nsubmission.to_csv('submission.csv', index=False)\nsubmission","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-29T00:37:10.106526Z","iopub.execute_input":"2025-10-29T00:37:10.106812Z","iopub.status.idle":"2025-10-29T00:37:10.119069Z","shell.execute_reply.started":"2025-10-29T00:37:10.106791Z","shell.execute_reply":"2025-10-29T00:37:10.118389Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}