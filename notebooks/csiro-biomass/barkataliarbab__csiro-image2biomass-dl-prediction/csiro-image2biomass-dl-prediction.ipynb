{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":112509,"databundleVersionId":14254895,"isSourceIdPinned":false,"sourceType":"competition"},{"sourceId":13584133,"sourceType":"datasetVersion","datasetId":8630307},{"sourceId":13584180,"sourceType":"datasetVersion","datasetId":8630344},{"sourceId":13584233,"sourceType":"datasetVersion","datasetId":8630386},{"sourceId":13584298,"sourceType":"datasetVersion","datasetId":8630432},{"sourceId":272104372,"sourceType":"kernelVersion"}],"dockerImageVersionId":31154,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from IPython.display import Image, display\n\ndisplay(Image(filename='/kaggle/input/biomassds/dl.png', width=800))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-02T07:29:01.065945Z","iopub.execute_input":"2025-11-02T07:29:01.066216Z","iopub.status.idle":"2025-11-02T07:29:01.144572Z","shell.execute_reply.started":"2025-11-02T07:29:01.06619Z","shell.execute_reply":"2025-11-02T07:29:01.143891Z"},"_kg_hide-input":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from IPython.display import Image, display\n\ndisplay(Image(filename='/kaggle/input/summary12/Summary.png', width=800))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-02T07:31:58.470823Z","iopub.execute_input":"2025-11-02T07:31:58.47157Z","iopub.status.idle":"2025-11-02T07:31:58.523649Z","shell.execute_reply.started":"2025-11-02T07:31:58.471544Z","shell.execute_reply":"2025-11-02T07:31:58.522797Z"},"_kg_hide-input":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ============================================================\n# CSIRO Image2Biomass ‚Äî End-to-End Notebook (fixed & ready)\n# - Uses /kaggle/input/csiro-biomass/\n# - Handles long-format train.csv (sample_id, image_path, target_name, target)\n# - Pivots to one-row-per-image with 5 target columns\n# - Trains EfficientNet-B3 (torchvision weights API)\n# - Weighted MSE Loss using competition weights\n# - Outputs submission.csv in long format (sample_id,target)\n# ============================================================\n\nimport os\nimport gc\nimport numpy as np\nimport pandas as pd\nfrom PIL import Image\nfrom tqdm import tqdm\n\n# sklearn / torch\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import r2_score\n\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms\nfrom torchvision.models import efficientnet_b3, EfficientNet_B3_Weights\n\n# -------------------------\n# Config\n# -------------------------\nDATA_DIR = \"/kaggle/input/csiro-biomass\"\nTRAIN_CSV = os.path.join(DATA_DIR, \"train.csv\")\nTEST_CSV = os.path.join(DATA_DIR, \"test.csv\")\nSAMPLE_SUB = os.path.join(DATA_DIR, \"sample_submission.csv\")\nTRAIN_IMG_ROOT = os.path.join(DATA_DIR)  # image paths in CSV are relative like \"train/ID....jpg\"\nTEST_IMG_ROOT = os.path.join(DATA_DIR)\n\nDEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nSEED = 42\nBATCH_SIZE = 16\nEPOCHS = 6           # adjust to fit runtime\nIMG_SIZE = 384\nLR = 1e-4\nNUM_WORKERS = 2\n\nCOMP_WEIGHTS = {\n    \"Dry_Green_g\": 0.1,\n    \"Dry_Dead_g\": 0.1,\n    \"Dry_Clover_g\": 0.1,\n    \"GDM_g\": 0.2,\n    \"Dry_Total_g\": 0.5\n}\nTARGET_NAMES = [\"Dry_Green_g\", \"Dry_Dead_g\", \"Dry_Clover_g\", \"GDM_g\", \"Dry_Total_g\"]\n\ntorch.manual_seed(SEED)\nnp.random.seed(SEED)\n\n# -------------------------\n# Load CSVs\n# -------------------------\ntrain_long = pd.read_csv(TRAIN_CSV)\ntest_df = pd.read_csv(TEST_CSV)\nsample_sub = pd.read_csv(SAMPLE_SUB)\n\nprint(\"Train (long) shape:\", train_long.shape)\nprint(\"Test shape:\", test_df.shape)\nprint(\"Sample sub shape:\", sample_sub.shape)\ndisplay(train_long.head())\n\n# -------------------------\n# Pivot train (long -> wide)\n# Each image should become a single row with 5 target columns.\n# train_long columns include: sample_id, image_path, Sampling_Date, State,\n# Species, Pre_GSHH_NDVI, Height_Ave_cm, target_name, target\n# -------------------------\n# Create an image-level id column (extract filename) to make things simple\n# But dataset already has image_path like \"train/IDxxxx.jpg\" ‚Äî we'll use that directly.\n\n# Keep metadata columns (we'll use Pre_GSHH_NDVI and Height_Ave_cm optionally)\nmeta_cols = [\"image_path\", \"Sampling_Date\", \"State\", \"Species\", \"Pre_GSHH_NDVI\", \"Height_Ave_cm\"]\n\n# pivot:\npivot = train_long.pivot_table(index=meta_cols, columns=\"target_name\", values=\"target\").reset_index()\n# After pivot, columns are meta_cols + target names\nprint(\"Pivoted train shape (one row per image):\", pivot.shape)\ndisplay(pivot.head())\n\n# Some safety: ensure all TARGET_NAMES present\nmissing = [t for t in TARGET_NAMES if t not in pivot.columns]\nif missing:\n    raise RuntimeError(f\"Missing target columns after pivot: {missing}\")\n\n# Create an 'image_full_path' column that is absolute path (Kaggle)\ndef make_full_path(p):\n    if os.path.isabs(p):\n        return p\n    return os.path.join(DATA_DIR, p)\n\npivot[\"image_full_path\"] = pivot[\"image_path\"].apply(make_full_path)\npivot[\"image_id\"] = pivot[\"image_path\"].apply(lambda p: os.path.basename(p).split(\".\")[0])\n\n# Remove rows where image file missing (robustness)\nexists_mask = pivot[\"image_full_path\"].apply(os.path.exists)\nif not exists_mask.all():\n    missing_files = pivot.loc[~exists_mask, \"image_full_path\"].tolist()\n    print(f\"Warning: {len(missing_files)} missing image files (they will be dropped).\")\n    pivot = pivot.loc[exists_mask].reset_index(drop=True)\n\nprint(\"Final pivot shape:\", pivot.shape)\ndisplay(pivot.head())\n\n# -------------------------\n# Train / Validation split (grouped by image)\n# -------------------------\ntrain_imgs, val_imgs = train_test_split(pivot, test_size=0.20, random_state=SEED, shuffle=True)\ntrain_imgs = train_imgs.reset_index(drop=True)\nval_imgs = val_imgs.reset_index(drop=True)\n\nprint(\"Train images:\", train_imgs.shape, \"Val images:\", val_imgs.shape)\n\n# -------------------------\n# Dataset & Transforms\n# -------------------------\ntrain_tfm = transforms.Compose([\n    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n    transforms.RandomHorizontalFlip(),\n    transforms.RandomVerticalFlip(),\n    transforms.ColorJitter(brightness=0.15, contrast=0.15, saturation=0.1, hue=0.02),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                         std=[0.229, 0.224, 0.225]),\n])\n\nval_tfm = transforms.Compose([\n    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                         std=[0.229, 0.224, 0.225]),\n])\n\nclass BiomassImageDataset(Dataset):\n    \"\"\"\n    Dataset expects a dataframe with:\n      - image_full_path (absolute path to jpg)\n      - target columns (Dry_Green_g, Dry_Dead_g, Dry_Clover_g, GDM_g, Dry_Total_g)\n    For inference (test), pass targets=False and the df should contain image_full_path.\n    \"\"\"\n    def __init__(self, df, target_cols=None, transform=None, is_test=False):\n        self.df = df.reset_index(drop=True)\n        self.transform = transform\n        self.is_test = is_test\n        self.target_cols = target_cols if target_cols is not None else []\n    \n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self, idx):\n        row = self.df.iloc[idx]\n        img_path = row[\"image_full_path\"]\n        # Robust open\n        img = Image.open(img_path).convert(\"RGB\")\n        if self.transform:\n            img = self.transform(img)\n        if self.is_test:\n            # return image and image_id\n            return img, row[\"image_id\"]\n        else:\n            targets = row[self.target_cols].values.astype(np.float32)\n            return img, torch.tensor(targets, dtype=torch.float32)\n\n# Instantiate datasets & loaders\ntrain_ds = BiomassImageDataset(train_imgs, target_cols=TARGET_NAMES, transform=train_tfm, is_test=False)\nval_ds = BiomassImageDataset(val_imgs, target_cols=TARGET_NAMES, transform=val_tfm, is_test=False)\n\ntrain_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS, pin_memory=True)\nval_loader = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS, pin_memory=True)\n\n# -------------------------\n# Model definition (EfficientNet-B3) using new weights API\n# -------------------------\nclass BiomassModel(nn.Module):\n    def __init__(self, num_targets=len(TARGET_NAMES), pretrained_weights=True):\n        super().__init__()\n        weights = EfficientNet_B3_Weights.DEFAULT if pretrained_weights else None\n        self.backbone = efficientnet_b3(weights=weights)\n        # efficientnet_b3.classifier is (Dropout, Linear(in_features, num_classes))\n        in_features = self.backbone.classifier[1].in_features\n        # remove classifier\n        self.backbone.classifier = nn.Identity()\n        # head: simple MLP; optionally include NDVI/height later\n        self.head = nn.Sequential(\n            nn.Linear(in_features, 512),\n            nn.ReLU(),\n            nn.Dropout(0.3),\n            nn.Linear(512, num_targets)\n        )\n    \n    def forward(self, x):\n        feats = self.backbone(x)\n        out = self.head(feats)\n        return out\n\nmodel = BiomassModel(num_targets=len(TARGET_NAMES)).to(DEVICE)\n\n# -------------------------\n# Loss - Weighted MSE using competition weights\n# -------------------------\nweights_tensor = torch.tensor([COMP_WEIGHTS[t] for t in TARGET_NAMES], dtype=torch.float32).to(DEVICE)\n# We'll compute MSE per-target and weight manually\nmse_loss = nn.MSELoss(reduction=\"none\")  # we'll handle reduction\n\noptimizer = torch.optim.AdamW(model.parameters(), lr=LR)\n# optional scaler if using mixed precision\nscaler = torch.cuda.amp.GradScaler() if torch.cuda.is_available() else None\n\n# -------------------------\n# Training & Validation functions\n# -------------------------\ndef weighted_mse_loss(preds, targets, weights):\n    # preds, targets: (batch, n_targets)\n    loss_per_elem = mse_loss(preds, targets)  # shape (batch, n_targets)\n    # mean over batch then weight\n    mean_per_target = loss_per_elem.mean(dim=0)  # (n_targets,)\n    weighted = mean_per_target * weights\n    return weighted.sum()\n\ndef train_one_epoch(model, loader, optimizer, scaler=None):\n    model.train()\n    running_loss = 0.0\n    n = 0\n    for imgs, targets in tqdm(loader, desc=\"Train\", leave=False):\n        imgs = imgs.to(DEVICE, non_blocking=True)\n        targets = targets.to(DEVICE, non_blocking=True)\n        optimizer.zero_grad()\n        if scaler:\n            with torch.cuda.amp.autocast():\n                preds = model(imgs)\n                loss = weighted_mse_loss(preds, targets, weights_tensor)\n            scaler.scale(loss).backward()\n            scaler.step(optimizer)\n            scaler.update()\n        else:\n            preds = model(imgs)\n            loss = weighted_mse_loss(preds, targets, weights_tensor)\n            loss.backward()\n            optimizer.step()\n        running_loss += loss.item() * imgs.size(0)\n        n += imgs.size(0)\n    return running_loss / n\n\ndef validate(model, loader):\n    model.eval()\n    preds_list = []\n    trues_list = []\n    with torch.no_grad():\n        for imgs, targets in tqdm(loader, desc=\"Val\", leave=False):\n            imgs = imgs.to(DEVICE, non_blocking=True)\n            out = model(imgs)\n            preds_list.append(out.cpu().numpy())\n            trues_list.append(targets.numpy())\n    preds = np.vstack(preds_list)\n    trues = np.vstack(trues_list)\n    per_target_r2 = []\n    for i, tname in enumerate(TARGET_NAMES):\n        try:\n            r2 = r2_score(trues[:, i], preds[:, i])\n        except Exception:\n            r2 = float(\"nan\")\n        per_target_r2.append(r2)\n    # weighted R2\n    weighted_r2 = sum(per_target_r2[i] * COMP_WEIGHTS[TARGET_NAMES[i]] for i in range(len(TARGET_NAMES)))\n    return per_target_r2, weighted_r2, preds, trues\n\n# -------------------------\n# Training loop\n# -------------------------\nbest_w_r2 = -1e9\nsave_path = \"best_model.pth\"\n\nfor epoch in range(1, EPOCHS + 1):\n    train_loss = train_one_epoch(model, train_loader, optimizer, scaler=scaler)\n    per_r2, w_r2, _, _ = validate(model, val_loader)\n    print(f\"Epoch {epoch}/{EPOCHS} | Train Loss: {train_loss:.6f} | Weighted R2: {w_r2:.6f}\")\n    print(\"Per-target R2:\", dict(zip(TARGET_NAMES, [round(x,4) if not np.isnan(x) else x for x in per_r2])))\n    # save best\n    if w_r2 > best_w_r2:\n        best_w_r2 = w_r2\n        torch.save(model.state_dict(), save_path)\n        print(\"  -> New best model saved.\")\n    # free memory\n    gc.collect()\n\nprint(\"Training finished. Best weighted R2:\", best_w_r2)\n\n# -------------------------\n# Inference on test set\n# Build test dataframe: test.csv includes sample_id and image_path for each target row in long format.\n# We need to predict per image and output one row per (image, target) pair in long format.\n# -------------------------\n# Prepare test image-level dataframe:\ntest_long = pd.read_csv(TEST_CSV)  # long-format similar to train\n# extract unique image rows and create full path\ntest_imgs = test_long[[\"image_path\"]].drop_duplicates().reset_index(drop=True)\ntest_imgs[\"image_full_path\"] = test_imgs[\"image_path\"].apply(make_full_path)\ntest_imgs[\"image_id\"] = test_imgs[\"image_path\"].apply(lambda p: os.path.basename(p).split(\".\")[0])\n\n# Remove missing files if any\nexists_mask = test_imgs[\"image_full_path\"].apply(os.path.exists)\nif not exists_mask.all():\n    missing_files = test_imgs.loc[~exists_mask, \"image_full_path\"].tolist()\n    print(f\"Warning: {len(missing_files)} missing test images (they will be skipped):\", missing_files)\n    test_imgs = test_imgs.loc[exists_mask].reset_index(drop=True)\n\nprint(\"Test image count:\", len(test_imgs))\ndisplay(test_imgs.head())\n\n# create test dataset and loader\ntest_ds = BiomassImageDataset(test_imgs, target_cols=None, transform=val_tfm, is_test=True)\ntest_loader = DataLoader(test_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS)\n\n# load best model\nmodel.load_state_dict(torch.load(save_path, map_location=DEVICE))\nmodel.to(DEVICE)\nmodel.eval()\n\npreds_by_image = {}\nwith torch.no_grad():\n    for imgs, image_ids in tqdm(test_loader, desc=\"Test Predict\"):\n        imgs = imgs.to(DEVICE)\n        out = model(imgs).cpu().numpy()\n        for iid, preds in zip(image_ids, out):\n            preds_by_image[iid] = preds\n\n# Build submission (long format: sample_id,target)\nrows = []\nfor _, row in test_long.iterrows():\n    # row has sample_id like ID1001187975__Dry_Green_g and image_path\n    # Need image id (basename)\n    img_id = os.path.basename(row[\"image_path\"]).split(\".\")[0]\n    tname = row[\"target_name\"]\n    if img_id in preds_by_image:\n        pred_val = float(preds_by_image[img_id][TARGET_NAMES.index(tname)])\n    else:\n        # fallback if image missing: predict zero\n        pred_val = 0.0\n    rows.append({\"sample_id\": row[\"sample_id\"], \"target\": pred_val})\n\nsub_df = pd.DataFrame(rows)\n# Ensure correct ordering as sample_submission\nsub_df = sub_df.set_index(\"sample_id\").reindex(sample_sub[\"sample_id\"]).reset_index()\nsub_df.to_csv(\"submission.csv\", index=False)\nprint(\"submission.csv written, shape:\", sub_df.shape)\ndisplay(sub_df.head(10))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-02T07:35:38.02591Z","iopub.execute_input":"2025-11-02T07:35:38.026251Z","iopub.status.idle":"2025-11-02T07:37:20.077448Z","shell.execute_reply.started":"2025-11-02T07:35:38.026207Z","shell.execute_reply":"2025-11-02T07:37:20.076716Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from IPython.display import Image, display\n\ndisplay(Image(filename='/kaggle/input/visualization/dv.png', width=800))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-02T07:37:58.170814Z","iopub.execute_input":"2025-11-02T07:37:58.171602Z","iopub.status.idle":"2025-11-02T07:37:58.234352Z","shell.execute_reply.started":"2025-11-02T07:37:58.171569Z","shell.execute_reply":"2025-11-02T07:37:58.233581Z"},"_kg_hide-input":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":" # ===============================\n# üìä CSIRO Biomass Data Visualization (Full & Fixed)\n# ===============================\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport cv2\nimport random\nfrom IPython.display import display\n\n# -------------------------\n# 0Ô∏è‚É£ Load data\n# -------------------------\nDATA_PATH = \"/kaggle/input/csiro-biomass/\"\n\ntrain = pd.read_csv(f\"{DATA_PATH}train.csv\")\ntest = pd.read_csv(f\"{DATA_PATH}test.csv\")\n\nprint(f\"‚úÖ Data Loaded Successfully!\")\nprint(f\"Train shape: {train.shape}\")\nprint(f\"Test shape: {test.shape}\\n\")\n\n# -------------------------\n# 1Ô∏è‚É£ Dataset overview\n# -------------------------\nprint(\"Unique target types:\", train[\"target_name\"].unique())\nprint(\"Unique species:\", train[\"Species\"].unique())\nprint(f\"Date range: {train['Sampling_Date'].min()} to {train['Sampling_Date'].max()}\\n\")\n\n# -------------------------\n# 2Ô∏è‚É£ Basic statistics\n# -------------------------\ndisplay(train.describe())\n\n# -------------------------\n# 3Ô∏è‚É£ Count of samples per target\n# -------------------------\nsns.set(style=\"whitegrid\", palette=\"muted\", font_scale=1.1)\n\nplt.figure(figsize=(8, 4))\nsns.countplot(data=train, x=\"target_name\", order=train[\"target_name\"].value_counts().index)\nplt.title(\"Count of Samples per Target\", fontsize=14)\nplt.xlabel(\"Target Type\")\nplt.ylabel(\"Count\")\nplt.xticks(rotation=45)\nplt.tight_layout()\nplt.show()\n\n# -------------------------\n# 4Ô∏è‚É£ Average target value per species (grouped by target_name)\n# -------------------------\nplt.figure(figsize=(10, 6))\nsns.barplot(\n    data=train,\n    x=\"Species\",\n    y=\"target\",\n    hue=\"target_name\",\n    errorbar=None\n)\nplt.title(\"Average Target Value per Species\", fontsize=14)\nplt.xticks(rotation=90)\nplt.ylabel(\"Mean Target\")\nplt.tight_layout()\nplt.show()\n\n# -------------------------\n# 5Ô∏è‚É£ Relationship between NDVI, Height, and Target\n# -------------------------\nplt.figure(figsize=(8, 6))\nsns.scatterplot(\n    data=train,\n    x=\"Pre_GSHH_NDVI\",\n    y=\"target\",\n    hue=\"target_name\",\n    alpha=0.7\n)\nplt.title(\"NDVI vs Target by Target Type\", fontsize=14)\nplt.tight_layout()\nplt.show()\n\nplt.figure(figsize=(8, 6))\nsns.scatterplot(\n    data=train,\n    x=\"Height_Ave_cm\",\n    y=\"target\",\n    hue=\"target_name\",\n    alpha=0.7\n)\nplt.title(\"Height vs Target by Target Type\", fontsize=14)\nplt.tight_layout()\nplt.show()\n\n# -------------------------\n# 6Ô∏è‚É£ Correlation heatmap (per target type)\n# -------------------------\ncorr_list = []\n\nfor tname, group in train.groupby(\"target_name\"):\n    corr = group[[\"Pre_GSHH_NDVI\", \"Height_Ave_cm\", \"target\"]].corr()\n    corr_ndvi = corr.loc[\"Pre_GSHH_NDVI\", \"target\"]\n    corr_height = corr.loc[\"Height_Ave_cm\", \"target\"]\n    corr_list.append({\n        \"target_name\": tname,\n        \"Corr(NDVI, target)\": corr_ndvi,\n        \"Corr(Height, target)\": corr_height\n    })\n\ncorr_df = pd.DataFrame(corr_list).set_index(\"target_name\")\ndisplay(corr_df)\n\nplt.figure(figsize=(6, 4))\nsns.heatmap(corr_df, annot=True, cmap=\"coolwarm\", center=0)\nplt.title(\"Correlation of NDVI & Height with Targets\", fontsize=14)\nplt.tight_layout()\nplt.show()\n\n# -------------------------\n# 7Ô∏è‚É£ Show random training images\n# -------------------------\nsample_images = train[\"image_path\"].unique()\nplt.figure(figsize=(12, 8))\nfor i, img_path in enumerate(random.sample(list(sample_images), min(9, len(sample_images)))):\n    plt.subplot(3, 3, i+1)\n    img = cv2.imread(f\"{DATA_PATH}{img_path}\")\n    if img is not None:\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n        plt.imshow(img)\n        sid = img_path.split(\"/\")[-1].split(\".\")[0]\n        species = train.loc[train[\"image_path\"] == img_path, \"Species\"].values[0]\n        plt.title(f\"{sid}\\n{species}\", fontsize=8)\n    plt.axis(\"off\")\nplt.suptitle(\"Random Sample Training Images\", fontsize=14)\nplt.tight_layout()\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-02T07:39:18.843665Z","iopub.execute_input":"2025-11-02T07:39:18.844314Z","iopub.status.idle":"2025-11-02T07:39:24.602089Z","shell.execute_reply.started":"2025-11-02T07:39:18.844286Z","shell.execute_reply":"2025-11-02T07:39:24.600907Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from IPython.display import Image, display\n\ndisplay(Image(filename='/kaggle/input/conclusion344/Conclusion.png', width=800))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-02T07:44:37.69091Z","iopub.execute_input":"2025-11-02T07:44:37.691588Z","iopub.status.idle":"2025-11-02T07:44:37.72867Z","shell.execute_reply.started":"2025-11-02T07:44:37.691561Z","shell.execute_reply":"2025-11-02T07:44:37.727819Z"},"_kg_hide-input":true},"outputs":[],"execution_count":null}]}