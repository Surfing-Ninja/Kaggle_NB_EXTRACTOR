{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":112509,"databundleVersionId":14254895,"isSourceIdPinned":false,"sourceType":"competition"},{"sourceId":13682568,"sourceType":"datasetVersion","datasetId":8701170}],"dockerImageVersionId":31154,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Cellule 1 R√©vis√©e : Installation et Imports\n\n# Utiliser timm (PyTorch Image Models) qui est plus fiable et plus performant\n# Si timm n'est pas d√©j√† install√©, cette ligne l'installera.\n!pip install timm\n\nimport pandas as pd\nimport numpy as np\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms\nfrom PIL import Image\nimport os\nfrom sklearn.model_selection import KFold\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nimport torch.optim as optim\nimport timm # Nouvel import pour les mod√®les de vision\nimport math\n\n# --- Configuration des chemins et constantes ---\nDATA_ROOT = '/kaggle/input/csiro-biomass'\nTRAIN_IMG_DIR = os.path.join(DATA_ROOT, 'train')\nTEST_IMG_DIR = os.path.join(DATA_ROOT, 'test')\n\nDEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nTARGET_NAMES = ['Dry_Green_g', 'Dry_Dead_g', 'Dry_Clover_g', 'GDM_g', 'Dry_Total_g']\nTARGET_WEIGHTS = torch.tensor([0.1, 0.1, 0.1, 0.2, 0.5]).float()\n\nIMAGE_SIZE = 300 \nNUM_FOLDS = 5 \nBATCH_SIZE = 32\nLEARNING_RATE = 1e-4\nNUM_EPOCHS = 25","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-11-03T19:51:31.659677Z","iopub.execute_input":"2025-11-03T19:51:31.659959Z","iopub.status.idle":"2025-11-03T19:53:52.611022Z","shell.execute_reply.started":"2025-11-03T19:51:31.65993Z","shell.execute_reply":"2025-11-03T19:53:52.609877Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Cellule 2 CORRIG√âE : Pr√©paration des Donn√©es (Mode Image Seule)\n\nimport pandas as pd\nimport os\nfrom sklearn.model_selection import KFold\n# Suppression des imports du pr√©processeur (StandardScaler, OneHotEncoder, ColumnTransformer, Pipeline)\nfrom torch.utils.data import Dataset, DataLoader\nimport torch\nfrom torchvision import transforms\nfrom PIL import Image\nimport numpy as np\n\n# --- A. Chargement des CSV et Conversion du Format Long au Format Large ---\n# (Assurez-vous que DATA_ROOT est d√©fini)\ntrain_df_raw = pd.read_csv(os.path.join(DATA_ROOT, 'train.csv'))\ntest_df_raw = pd.read_csv(os.path.join(DATA_ROOT, 'test.csv'))\n\n# 1. Ajout du Chemin Complet de l'Image\ntrain_df_raw['full_image_path'] = train_df_raw['image_path'].apply(\n    lambda x: os.path.join(DATA_ROOT, x)\n)\ntest_df_raw['full_image_path'] = test_df_raw['image_path'].apply(\n    lambda x: os.path.join(DATA_ROOT, x)\n)\n\n# 2. Conversion du TRAIN au Format Large (Une ligne par image)\ntrain_df_raw['ImageID'] = train_df_raw['sample_id'].apply(lambda x: x.split('__')[0])\n\n# D√©finir uniquement les colonnes n√©cessaires (ImageID, chemin, et les cibles)\nMETADATA_COLS = ['ImageID', 'full_image_path']\ntrain_df_base = train_df_raw[METADATA_COLS].drop_duplicates().reset_index(drop=True)\n\n# Pivoter les cibles\ntrain_df_targets = train_df_raw.pivot(\n    index='ImageID', columns='target_name', values='target'\n).reset_index()\n\n# Joindre les m√©tadonn√©es et les cibles\ntrain_df = train_df_base.merge(train_df_targets, on='ImageID', how='left')\nTARGET_NAMES = train_df_targets.columns.drop('ImageID').tolist() # D√©finition des cibles\n\n# 3. Adaptation du TEST au Format Large (Uniquement l'Image et l'ID)\ntest_df = test_df_raw[['sample_id', 'full_image_path']].drop_duplicates(subset=['full_image_path']).reset_index(drop=True)\ntest_df['ImageID'] = test_df['sample_id'].apply(lambda x: x.split('__')[0])\n        \nprint(f\"‚úÖ DataFrames convertis au format large. TRAIN: {len(train_df)} images. TEST: {len(test_df)} images.\")\n\n# --- B. D√©finition de la Classe PyTorch Dataset (Image Seule) ---\n\nclass BiomassDataset(Dataset):\n    \"\"\"\n    Dataset pour charger uniquement les images et les cibles (mode Image Seule).\n    \"\"\"\n    # L'argument preprocessor a √©t√© retir√© de l'init\n    def __init__(self, df, target_names, transform=None, is_test=False): \n        self.df = df.reset_index(drop=True) \n        self.target_names = target_names\n        self.transform = transform\n        self.is_test = is_test\n        \n        if not is_test:\n            self.labels = torch.tensor(self.df[self.target_names].values, dtype=torch.float32)\n        else:\n            self.labels = None\n\n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        # 1. Image\n        img_path = self.df.loc[idx, 'full_image_path'] \n        image = Image.open(img_path).convert(\"RGB\")\n        \n        if self.transform:\n            image = self.transform(image)\n\n        # 2. R√©tour\n        # Pas de donn√©es tabulaires\n        if self.is_test:\n            return image\n        else:\n            label = self.labels[idx]\n            return image, label\n\n# --- C. D√©finition des Transformations d'Images (INCHANG√âE) ---\n\nNORM_MEAN = [0.485, 0.456, 0.406]\nNORM_STD = [0.229, 0.224, 0.225]\nIMAGE_SIZE = 224 # Variable globale n√©cessaire\n\n# Transformations pour l'entra√Ænement (avec augmentation de donn√©es)\ntrain_transform = transforms.Compose([\n    transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n    transforms.RandomHorizontalFlip(),\n    transforms.RandomVerticalFlip(),\n    transforms.RandomRotation(15),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=NORM_MEAN, std=NORM_STD)\n])\n\n# Transformations pour la validation/test (sans augmentation)\nvalid_test_transform = transforms.Compose([\n    transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=NORM_MEAN, std=NORM_STD)\n])\n\nprint(\"‚úÖ Classe BiomassDataset (Image Seule) et transformations d√©finies.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-03T19:56:20.331618Z","iopub.execute_input":"2025-11-03T19:56:20.332648Z","iopub.status.idle":"2025-11-03T19:56:20.429262Z","shell.execute_reply.started":"2025-11-03T19:56:20.332609Z","shell.execute_reply":"2025-11-03T19:56:20.428302Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Cellule 3 CORRIG√âE : K-Fold et DataLoaders (Mode Image Seule)\n\nfrom torch.utils.data import DataLoader\nfrom sklearn.model_selection import KFold\n\n# --- A. Initialisation du K-Fold et du DataLoader de Test ---\n\n# 1. K-Fold pour la Validation Crois√©e\nNUM_FOLDS = 5 # Variable globale n√©cessaire\nkf = KFold(n_splits=NUM_FOLDS, shuffle=True, random_state=42)\nprint(f\"‚úÖ Objet KFold cr√©√© avec {NUM_FOLDS} plis.\")\n\n# 2. DataLoader pour le jeu de Test\n# BATCH_SIZE est une variable globale n√©cessaire ici\nif 'BATCH_SIZE' not in locals() and 'BATCH_SIZE' not in globals():\n    BATCH_SIZE = 32\n\ntest_dataset = BiomassDataset(\n    df=test_df, \n    # Plus de pr√©processeur √† passer en argument\n    target_names=TARGET_NAMES, \n    transform=valid_test_transform, \n    is_test=True\n)\n\ntest_loader = DataLoader(\n    test_dataset, \n    batch_size=BATCH_SIZE, \n    shuffle=False, \n    num_workers=2, \n    pin_memory=True\n)\nprint(f\"‚úÖ DataLoader de Test cr√©√© (Taille: {len(test_dataset)}).\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-03T19:58:01.690982Z","iopub.execute_input":"2025-11-03T19:58:01.691355Z","iopub.status.idle":"2025-11-03T19:58:09.087076Z","shell.execute_reply.started":"2025-11-03T19:58:01.69133Z","shell.execute_reply":"2025-11-03T19:58:09.085702Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Cellule 4 CORRIG√âE : Feature Engineering - Calcul du Pourcentage de Vert et Sec\n\nimport cv2\nimport numpy as np\nimport pandas as pd\nimport os\nimport matplotlib.pyplot as plt # Maintenu pour la visualisation de test\n\n# Nous d√©finissons ici une variable globale pour le masque corrig√© afin d'√©viter la confusion\nMASK_COLOR_MAX = 255 # Valeur d'intensit√© pour le masque True (blanc)\n\ndef calculate_biomass_pct(image_path):\n    \"\"\"\n    Calcule le pourcentage de pixels 'verts' (RG-NDVI > 0.1) et 'secs/jaunes' (heuristique).\n    Retourne le masque vert en format uint8 pour la compatibilit√© OpenCV.\n    \"\"\"\n    try:\n        # Lire l'image en BGR (format OpenCV par d√©faut)\n        img_bgr = cv2.imread(image_path)\n        if img_bgr is None:\n            return np.nan, np.nan, None \n\n        # Convertir en float pour les op√©rations de division\n        img_float = img_bgr.astype(float)\n        \n        # S√©parer les canaux B, G, R\n        B = img_float[:, :, 0]\n        G = img_float[:, :, 1]\n        R = img_float[:, :, 2]\n        \n        # 1. Calcul de l'indice RG-NDVI simplifi√© \n        epsilon = 1e-6\n        rg_ndv = (G - R) / (G + R + epsilon)\n        \n        # 2. Seuil de Classification\n        \n        # Masque bool√©en du VERT (V√©g√©tation saine)\n        mask_green_bool = rg_ndv > 0.1 \n        \n        # üî• CORRECTION : Convertir le masque bool√©en en uint8 (0 ou 255) pour OpenCV\n        mask_green_uint8 = mask_green_bool.astype(np.uint8) * MASK_COLOR_MAX \n\n        # Masque du SEC/JAUNE\n        mask_dry = (rg_ndv <= 0.1) & (rg_ndv > -0.1) & (R > 50) \n        \n        # 3. Calcul des pourcentages\n        total_pixels = img_bgr.shape[0] * img_bgr.shape[1]\n        \n        # Les calculs de pourcentage utilisent la version bool√©enne car c'est plus direct (True = 1, False = 0)\n        pct_green = (np.sum(mask_green_bool) / total_pixels) * 100\n        pct_dry = (np.sum(mask_dry) / total_pixels) * 100\n        \n        # Retourne le masque uint8\n        return pct_green, pct_dry, mask_green_uint8\n\n    except Exception as e:\n        # print(f\"Erreur lors du traitement de {image_path}: {e}\")\n        return np.nan, np.nan, None\n\n# Mise √† jour de la fonction pour l'application (retourne uniquement les features)\ndef get_biomass_features(image_path):\n    # On ignore le masque uint8 lors de l'application aux DataFrames\n    pct_green, pct_dry, _ = calculate_biomass_pct(image_path) \n    return pd.Series([pct_green, pct_dry], index=['Pct_Green', 'Pct_Dry'])\n\nprint(\"‚úÖ Fonction de calcul de % Vert / % Sec (RG-NDVI) d√©finie et corrig√©e.\")\n\n# --- A. Test de Visualisation pour V√©rifier le Filtre (Utilisation de full_image_path) ---\nif len(train_df) > 0:\n    example_path = train_df.loc[0, 'full_image_path'] # Utiliser le chemin complet\n    \n    # pct_green_example, pct_dry_example, mask_green_uint8\n    pct_green_example, pct_dry_example, mask_green_uint8 = calculate_biomass_pct(example_path)\n    \n    # Utiliser le masque uint8 pour la visualisation\n    if mask_green_uint8 is not None: \n        img_bgr = cv2.imread(example_path)\n        img_rgb = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)\n        \n        print(f\"\\nPourcentage de vert (RG-NDVI) pour l'image exemple : {pct_green_example:.2f}%\")\n        print(f\"Pourcentage de sec estim√© : {pct_dry_example:.2f}%\")\n        \n        # Affichage des r√©sultats\n        plt.figure(figsize=(15, 5))\n        plt.subplot(1, 3, 1)\n        plt.imshow(img_rgb)\n        plt.title(\"Image Originale\")\n        plt.axis('off')\n        \n        plt.subplot(1, 3, 2)\n        # Affichage du masque (uint8 est le bon format pour matplotlib aussi)\n        plt.imshow(mask_green_uint8, cmap='gray')\n        plt.title(f\"Masque Binaire du Vert ({pct_green_example:.2f}%)\")\n        plt.axis('off')\n        \n        plt.subplot(1, 3, 3)\n        # üî• CORRECTION APPLIQU√âE ICI : Utilisation de mask=mask_green_uint8 üî•\n        masked_image = cv2.bitwise_and(img_bgr, img_bgr, mask=mask_green_uint8)\n        masked_image_rgb = cv2.cvtColor(masked_image, cv2.COLOR_BGR2RGB)\n        plt.imshow(masked_image_rgb)\n        plt.title(\"Vert Isol√©\")\n        plt.axis('off')\n        \n        plt.show()\n\n# --- B. Application du Calcul √† l'Ensemble du Dataset ---\n\nprint(\"\\nCalcul des pourcentages de biomasse pour le set d'entra√Ænement...\")\n# Utiliser la fonction apply avec la d√©composition en s√©ries pour cr√©er deux colonnes\ntrain_df[['Pct_Green', 'Pct_Dry']] = train_df['full_image_path'].apply(get_biomass_features)\n\nprint(\"Calcul des pourcentages de biomasse pour le set de test...\")\ntest_df[['Pct_Green', 'Pct_Dry']] = test_df['full_image_path'].apply(get_biomass_features)\n\n# 3. Nettoyer les NaN restants (Imputation par la moyenne)\nmean_pct_green = train_df['Pct_Green'].mean()\nmean_pct_dry = train_df['Pct_Dry'].mean()\n\ntrain_df['Pct_Green'] = train_df['Pct_Green'].fillna(mean_pct_green)\ntrain_df['Pct_Dry'] = train_df['Pct_Dry'].fillna(mean_pct_dry)\n\ntest_df['Pct_Green'] = test_df['Pct_Green'].fillna(mean_pct_green)\ntest_df['Pct_Dry'] = test_df['Pct_Dry'].fillna(mean_pct_dry)\n\n\nprint(f\"‚úÖ Colonnes 'Pct_Green' et 'Pct_Dry' ajout√©es aux DataFrames.\")\nprint(f\"Moyenne % Vert (Train): {mean_pct_green:.2f}%. Moyenne % Sec (Train): {mean_pct_dry:.2f}%\")\nprint(\"\\nAper√ßu des nouvelles features (Train) :\")\nprint(train_df[['Pct_Green', 'Pct_Dry'] + TARGET_NAMES].head())","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Cellule 5 : D√©finition du Mod√®le CNN Pur Multi-Cibles avec poids locaux\n\nimport torch\nimport torch.nn as nn\nimport timm\n\nclass CNNBiomassModel(nn.Module):\n    \"\"\"\n    Mod√®le CNN pour r√©gression multi-cibles.\n    Permet de charger des poids pr√©-entra√Æn√©s locaux pour ResNet-18.\n    \n    Correction : Le chargement des poids filtre les cl√©s de la couche fc\n    pour correspondre √† la structure sans t√™te de classification (num_classes=0).\n    \"\"\"\n    def __init__(self, num_targets, model_name='resnet18', pretrained_path=None):\n        super().__init__()\n        \n        # --- A. Mod√®le de Vision ---\n        # Charger le mod√®le sans la derni√®re couche (num_classes=0) pour utiliser les features\n        self.cnn_model = timm.create_model(model_name, pretrained=False, num_classes=0)\n        \n        # Si un chemin de poids est fourni, charger les poids locaux\n        if pretrained_path is not None:\n            # 1. Charger le dictionnaire d'√©tat complet\n            state_dict = torch.load(pretrained_path, map_location='cpu')\n            \n            # 2. D√©finir les cl√©s √† retirer (ce sont les poids de la couche fc standard de ResNet)\n            keys_to_remove = ['fc.weight', 'fc.bias']\n            \n            # 3. Filtrer les poids pr√©-entra√Æn√©s pour exclure les cl√©s probl√©matiques\n            pretrained_dict_filtered = {k: v for k, v in state_dict.items() if k not in keys_to_remove}\n            \n            # 4. Charger les poids filtr√©s dans le mod√®le\n            #    Utiliser strict=False pour ignorer toute autre cl√© manquante ou inattendue,\n            #    tout en chargeant la majorit√© des poids du ResNet.\n            missing_keys, unexpected_keys = self.cnn_model.load_state_dict(pretrained_dict_filtered, strict=False)\n            \n            if len(unexpected_keys) > 0:\n                 print(f\"‚ö†Ô∏è Avertissement : {len(unexpected_keys)} cl√©s inattendues ont √©t√© ignor√©es.\")\n            \n            print(f\"‚úÖ Poids pr√©-entra√Æn√©s charg√©s avec succ√®s (couche fc exclue) depuis : {pretrained_path}\")\n        \n        # Dimension du vecteur de features (sortie de ResNet apr√®s la couche d'AvgPool globale)\n        cnn_output_dim = self.cnn_model.num_features\n        \n        # --- B. T√™te de Pr√©diction (pour votre t√¢che de R√©gression Multi-Cibles) ---\n        self.prediction_head = nn.Sequential(\n            nn.Linear(cnn_output_dim, 256),\n            nn.ReLU(),\n            nn.Dropout(0.3),\n            nn.Linear(256, num_targets)\n        )\n        \n    def forward(self, images):\n        # Passage des images dans le CNN (jusqu'√† la couche d'AvgPool)\n        features = self.cnn_model(images)\n        # Passage des features dans la t√™te de pr√©diction\n        output = self.prediction_head(features)\n        return output\n\n# --- V√©rification du mod√®le ---\n# Assurez-vous que TARGET_NAMES est d√©fini dans une cellule pr√©c√©dente (sinon l'erreur NameError est lev√©e)\nif 'TARGET_NAMES' not in globals():\n    # D√©finition de substitution si n√©cessaire pour le test (√† enlever pour l'environnement Kaggle)\n    # TARGET_NAMES = ['target1', 'target2'] \n    raise NameError(\"TARGET_NAMES doit √™tre d√©finie (liste des noms de vos cibles de r√©gression).\")\n\nDEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# Initialisation du mod√®le avec les poids locaux\nmodel = CNNBiomassModel(\n    num_targets=len(TARGET_NAMES),\n    model_name='resnet18',\n    # V√©rifiez que ce chemin est correct dans votre environnement Kaggle\n    pretrained_path='/kaggle/input/restnet-weight/resnet18-f37072fd.pth' \n).to(DEVICE)\n\nprint(model)\n\n# V√©rification rapide avec un batch (n√©cessite que 'test_loader' soit d√©fini)\ntry:\n    sample_images = next(iter(test_loader))\n    if isinstance(sample_images, (list, tuple)):\n        # Assurez-vous de prendre le tensor d'images si le loader retourne (image, target)\n        sample_images = sample_images[0] \n    sample_images = sample_images.to(DEVICE)\n    sample_preds = model(sample_images)\n    print(\"Shape des pr√©dictions :\", sample_preds.shape)\nexcept NameError:\n    print(\"‚ö†Ô∏è Attention : 'test_loader' n'est pas d√©fini. Impossible d'effectuer la v√©rification rapide.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-04T07:32:16.015154Z","iopub.execute_input":"2025-11-04T07:32:16.015702Z","iopub.status.idle":"2025-11-04T07:32:18.781643Z","shell.execute_reply.started":"2025-11-04T07:32:16.015673Z","shell.execute_reply":"2025-11-04T07:32:18.780841Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Cellule 6 : Entra√Ænement et Validation K-Fold\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, Subset\nfrom sklearn.metrics import mean_squared_error\nfrom torch.optim.lr_scheduler import ReduceLROnPlateau\nimport numpy as np\nimport time\nimport timm \n# Assurez-vous que CNNBiomassModel est d√©finie (depuis Cellule 5)\n# Assurez-vous que train_df, kf, TARGET_NAMES, train_transform, valid_test_transform, DEVICE, BATCH_SIZE sont d√©finis\n\n# --- Hyperparam√®tres d'Entra√Ænement ---\nEPOCHS = 15              \nLEARNING_RATE = 1e-4     \nMODEL_NAME = 'resnet18' \n# üí• AJOUT : Chemin vers le poids pr√©-entra√Æn√© local üí•\nLOCAL_PRETRAINED_PATH = '/kaggle/input/restnet-weight/resnet18-f37072fd.pth'\n\n\n# --- 1. Fonction de Perte (Loss Function) ---\nloss_fn = nn.MSELoss() \n\ndef calculate_rmse(y_true, y_pred):\n    \"\"\"Calcule la Root Mean Squared Error (RMSE) pour l'ensemble des cibles.\"\"\"\n    if torch.is_tensor(y_true):\n        y_true = y_true.detach().cpu().numpy()\n        y_pred = y_pred.detach().cpu().numpy()\n        \n    rms = np.sqrt(mean_squared_error(y_true, y_pred))\n    return rms\n\n\n# --- 2. Boucle Principale K-Fold ---\n\nOOF_PREDS = np.zeros((len(train_df), len(TARGET_NAMES))) # Stockage des pr√©dictions Out-Of-Fold\noof_indices = train_df.index.values \ncv_results = {} \n\nprint(f\"D√©marrage de la Cross-Validation K-Fold ({kf.n_splits} plis) sur {len(TARGET_NAMES)} cibles...\")\n\n# Boucle sur les plis\nfor fold, (train_idx, val_idx) in enumerate(kf.split(train_df)):\n    print(f\"\\n{'='*20} PLI {fold+1}/{kf.n_splits} {'='*20}\")\n    start_time = time.time()\n    \n    # a. Cr√©ation des DataSets et DataLoaders pour le pli\n    full_dataset = BiomassDataset(\n        df=train_df,\n        target_names=TARGET_NAMES,\n        transform=None, \n        is_test=False\n    )\n    \n    train_subset = Subset(full_dataset, train_idx)\n    val_subset = Subset(full_dataset, val_idx)\n    \n    # Application des transformations (gestion d√©licate, on suppose que √ßa fonctionne)\n    train_subset.dataset.transform = train_transform\n    val_subset.dataset.transform = valid_test_transform\n    \n    train_loader = DataLoader(\n        train_subset,\n        batch_size=BATCH_SIZE,\n        shuffle=True,\n        num_workers=4,\n        pin_memory=True\n    )\n    val_loader = DataLoader(\n        val_subset,\n        batch_size=BATCH_SIZE,\n        shuffle=False,\n        num_workers=4,\n        pin_memory=True\n    )\n\n    # b. Initialisation du Mod√®le, de l'Optimiseur et du Scheduler\n    # üí• CORRECTION : Utiliser pretrained_path au lieu de pretrained=False üí•\n    model = CNNBiomassModel(\n        num_targets=len(TARGET_NAMES), \n        model_name=MODEL_NAME,\n        pretrained_path=LOCAL_PRETRAINED_PATH # <--- Correctif pour charger les poids locaux\n    ).to(DEVICE)\n    \n    optimizer = optim.AdamW(model.parameters(), lr=LEARNING_RATE)\n    \n    scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=3, verbose=True)\n    \n    best_val_rmse = float('inf')\n    \n    # c. Boucle d'Entra√Ænement\n    for epoch in range(EPOCHS):\n        # --- PHASE D'ENTRA√éNEMENT ---\n        model.train()\n        train_loss_sum = 0\n        \n        for images, targets in train_loader: \n            images, targets = images.to(DEVICE), targets.to(DEVICE)\n            \n            optimizer.zero_grad()\n            \n            predictions = model(images) \n            \n            loss = loss_fn(predictions, targets)\n            loss.backward()\n            optimizer.step()\n            \n            train_loss_sum += loss.item() * images.size(0)\n            \n        train_loss = train_loss_sum / len(train_subset)\n        \n        # --- PHASE DE VALIDATION ---\n        model.eval()\n        val_loss_sum = 0\n        all_val_targets = []\n        all_val_preds = []\n        \n        with torch.no_grad():\n            for images, targets in val_loader:\n                images, targets = images.to(DEVICE), targets.to(DEVICE)\n                \n                predictions = model(images)\n                loss = loss_fn(predictions, targets)\n                \n                val_loss_sum += loss.item() * images.size(0)\n                all_val_targets.append(targets)\n                all_val_preds.append(predictions)\n\n        val_loss = val_loss_sum / len(val_subset)\n        \n        # Calcul de la m√©trique RMSE\n        val_rmse = calculate_rmse(\n            torch.cat(all_val_targets), \n            torch.cat(all_val_preds)\n        )\n        \n        # Mise √† jour du Scheduler\n        scheduler.step(val_loss)\n\n        print(f\"√âpoque {epoch+1}/{EPOCHS} | Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f} | Val RMSE: {val_rmse:.4f}\")\n        \n        # Sauvegarde du meilleur mod√®le\n        if val_rmse < best_val_rmse:\n            best_val_rmse = val_rmse\n            # Sauvegarde de l'√©tat du mod√®le\n            torch.save(model.state_dict(), f\"best_cnn_model_fold_{fold+1}.pth\")\n            print(f\"    ‚û°Ô∏è Mod√®le sauvegard√© (RMSE: {best_val_rmse:.4f})\")\n\n    # d. Enregistrement des Pr√©dictions Out-of-Fold (OOF)\n    model.load_state_dict(torch.load(f\"best_cnn_model_fold_{fold+1}.pth\"))\n    model.eval()\n    \n    val_preds_list = []\n    with torch.no_grad():\n        for images, _ in val_loader:\n            images = images.to(DEVICE)\n            preds = model(images).cpu().numpy()\n            val_preds_list.append(preds)\n            \n    val_preds = np.concatenate(val_preds_list, axis=0)\n    \n    # Stockage dans le tableau OOF global\n    OOF_PREDS[val_idx, :] = val_preds\n    cv_results[f'fold_{fold+1}'] = best_val_rmse\n    \n    print(f\"Dur√©e du pli {fold+1}: {time.time() - start_time:.2f}s\")\n\n\n# --- 3. R√©sultats Finaux ---\n\nfinal_rmse = calculate_rmse(train_df[TARGET_NAMES].values, OOF_PREDS)\n\nprint(f\"\\n{'='*50}\")\nprint(\"‚úÖ Entra√Ænement K-Fold termin√©.\")\nprint(f\"R√©sultats par pli (RMSE): {cv_results}\")\nprint(f\"SCORE FINAL CV (RMSE OOF): {final_rmse:.4f}\")\nprint(f\"{'='*50}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-04T07:33:22.444467Z","iopub.execute_input":"2025-11-04T07:33:22.444782Z","iopub.status.idle":"2025-11-04T07:33:24.516291Z","shell.execute_reply.started":"2025-11-04T07:33:22.44476Z","shell.execute_reply":"2025-11-04T07:33:24.51557Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Cellule 7 : Extraction de Features CNN et Mod√®le k-NN de Stacking\n\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom torch.utils.data import DataLoader, Dataset\nimport torch\nimport numpy as np\nimport os\nimport pandas as pd\nimport timm\nfrom torch import nn \n\n\n# --- Variables Globales pour la Cellule ---\n# (Assur√©es d'√™tre d√©finies dans les cellules pr√©c√©dentes)\nMODEL_NAME = 'resnet18' \nBATCH_SIZE = 32 \nDEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") \n# Facteur de pond√©ration pour donner plus d'importance au Pct_Green\nGREEN_WEIGHT_FACTOR = 2.0 \n\n\n# --- AJOUT CRITIQUE : Assurer l'existence du Scaler des Cibles (TARGET_MEANS / TARGET_STDS) ---\n# Ceci corrige la NameError 'TARGET_MEANS' is not defined.\nif 'TARGET_MEANS' not in globals() or 'TARGET_STDS' not in globals():\n    try:\n        # Re-calcul des moyennes et √©carts-types exacts pour la standardisation\n        TARGET_MEANS = train_df[TARGET_NAMES].mean().values.astype(np.float32)\n        TARGET_STDS = train_df[TARGET_NAMES].std().values.astype(np.float32)\n        print(\"‚úÖ Scaler des cibles recalcul√© (TARGET_MEANS, TARGET_STDS).\")\n    except Exception as e:\n        # Ceci se d√©clenchera si train_df ou TARGET_NAMES n'est pas accessible\n        raise Exception(f\"üõë ERREUR : Impossible de calculer TARGET_MEANS/STDS. V√©rifiez l'ex√©cution des cellules 2 et 5. Erreur: {e}\")\n\n\n# --- 1. D√©finition du Mod√®le d'Extraction de Features ---\n# (Correct)\nclass FeatureExtractor(nn.Module):\n    \"\"\" Mod√®le qui utilise le backbone du CNN pour renvoyer le feature vector \"\"\"\n    def __init__(self, cnn_model_name):\n        super().__init__()\n        # Le mod√®le est cr√©√© sans t√™te de classification et sans poids pr√©-entra√Æn√©s (ils seront charg√©s plus tard)\n        self.cnn_model = timm.create_model(cnn_model_name, pretrained=False, num_classes=0)\n\n    def forward(self, x):\n        return self.cnn_model(x)\n\n# --- 2. Fonction d'Extraction G√©n√©rique (CORRIG√âE) ---\n\ndef extract_features(df, transform, model_path):\n    \"\"\"Charge le mod√®le, le met en mode √©valuation et extrait les features pour un DataFrame.\"\"\"\n    \n    feature_model = FeatureExtractor(MODEL_NAME).to(DEVICE)\n    \n    # a. Chargement et FILTRAGE des poids du meilleur mod√®le\n    try:\n        # 1. Charger le dictionnaire de poids complet\n        state_dict = torch.load(model_path, map_location=DEVICE)\n\n        # 2. Filtrer UNIQUEMENT la t√™te de pr√©diction. \n        filtered_state_dict = {\n            k: v for k, v in state_dict.items() \n            if not k.startswith('prediction_head.')\n        }\n        \n        # 3. Charger le dictionnaire de poids filtr√©\n        feature_model.load_state_dict(filtered_state_dict, strict=False)\n        \n    except FileNotFoundError:\n        print(f\"ATTENTION: Fichier mod√®le non trouv√© √† {model_path}. Extraction avec poids non entra√Æn√©s.\")\n    except Exception as e:\n        # Si une autre erreur se produit, on r√©essaie en mode non strict au cas o√π\n        print(f\"‚ö†Ô∏è Erreur de chargement des poids ({e}). Tentative de chargement en mode non strict (strict=False) appliqu√©e.\")\n        try:\n            state_dict = torch.load(model_path, map_location=DEVICE)\n            filtered_state_dict = {k: v for k, v in state_dict.items() if not k.startswith('prediction_head.')}\n            feature_model.load_state_dict(filtered_state_dict, strict=False)\n        except Exception as inner_e:\n            raise RuntimeError(f\"√âchec critique du chargement des features CNN : {inner_e}\")\n        \n    feature_model.eval()\n    \n    # b. Cr√©ation du DataLoader (le reste est inchang√©)\n    dataset = BiomassDataset(\n        df=df,\n        target_names=TARGET_NAMES,\n        transform=transform, \n        is_test=True \n    )\n    loader = DataLoader(\n        dataset,\n        batch_size=BATCH_SIZE,\n        shuffle=False,\n        num_workers=4,\n        pin_memory=True\n    )\n    \n    all_features = []\n    with torch.no_grad():\n        for images in loader:\n            if isinstance(images, (list, tuple)):\n                 images = images[0]\n                 \n            images = images.to(DEVICE)\n            features = feature_model(images)\n            all_features.append(features.cpu().numpy())\n            \n    return np.concatenate(all_features, axis=0)\n\n# -------------------------------------------------------------------------------------------------\n\n# --- 3. Ex√©cution de l'Extraction (Inchang√©e) ---\n\nBEST_MODEL_PATH = f\"best_cnn_model_fold_1.pth\" \n\nprint(f\"‚è≥ Extraction des features CNN du mod√®le : {BEST_MODEL_PATH}...\")\ntrain_cnn_features = extract_features(train_df, valid_test_transform, BEST_MODEL_PATH)\ntest_cnn_features = extract_features(test_df, valid_test_transform, BEST_MODEL_PATH)\n\nprint(f\"‚úÖ Features CNN TRAIN extraites. Shape: {train_cnn_features.shape}\")\nprint(f\"‚úÖ Features CNN TEST extraites. Shape: {test_cnn_features.shape}\")\n\n\n# -------------------------------------------------------------------------------------------------\n\n# --- 4. Combinaison des Features (CNN + Manuelles POND√âR√âES) ---\n\nmanual_features_cols = ['Pct_Green', 'Pct_Dry'] \ntrain_manual_features = train_df[manual_features_cols].copy()\ntest_manual_features = test_df[manual_features_cols].copy()\n\n# üî• POND√âRATION DU VERT üî•\nprint(f\"\\nAppliquer la pond√©ration GREEN_WEIGHT_FACTOR ({GREEN_WEIGHT_FACTOR:.1f}) sur Pct_Green...\")\ntrain_manual_features['Pct_Green'] *= GREEN_WEIGHT_FACTOR\ntest_manual_features['Pct_Green'] *= GREEN_WEIGHT_FACTOR\n\nX_train_manual = train_manual_features.values\nX_test_manual = test_manual_features.values\n\n# Concat√©nation des Features\nX_train_final = np.concatenate([train_cnn_features, X_train_manual], axis=1)\nX_test_final = np.concatenate([test_cnn_features, X_test_manual], axis=1)\n\n# üí• CORRECTION 2 : Standardisation des Cibles üí•\nY_train_raw = train_df[TARGET_NAMES].values\nY_train_scaled = (Y_train_raw - TARGET_MEANS) / TARGET_STDS \n\nprint(f\"\\nShape finale du Feature Set TRAIN : {X_train_final.shape}\")\nprint(f\"Shape finale du Feature Set TEST : {X_test_final.shape}\")\n\n\n# -------------------------------------------------------------------------------------------------\n\n# --- 5. Mod√©lisation k-NN (R√©gression Multi-Cibles) ---\n\nN_NEIGHBORS = 15 \nprint(f\"\\n‚è≥ Entra√Ænement du KNeighborsRegressor (k={N_NEIGHBORS}) sur le feature set combin√©...\")\n\nknn_model = KNeighborsRegressor(\n    n_neighbors=N_NEIGHBORS, \n    weights='distance', \n    metric='euclidean'\n)\n\n# Utilisation des cibles STANDARDIS√âES pour l'entra√Ænement du k-NN\nknn_model.fit(X_train_final, Y_train_scaled)\n\nprint(\"‚úÖ Mod√®le k-NN entra√Æn√©.\")\n\n\n# --- 6. Pr√©dictions Finales ---\n# Les pr√©dictions ici seront des valeurs STANDARDIS√âES !\nfinal_predictions_knn = knn_model.predict(X_test_final)\n\nprint(f\"\\nShape des pr√©dictions finales (TEST) : {final_predictions_knn.shape}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Cellule 8 CORRIG√âE (Finale) : D√©s-standardisation, Formatage et Soumission du Mod√®le k-NN\n\nimport pandas as pd\nimport numpy as np\n\n# Les variables suivantes doivent √™tre d√©finies √† partir des cellules pr√©c√©dentes :\n# - final_predictions_knn (pr√©dictions finales du k-NN - Cellule 7, VALEURS STANDARDIS√âES)\n# - test_df (DataFrame de test - Cellule 2)\n# - TARGET_NAMES (liste des cibles - Cellule 2)\n# - TARGET_MEANS et TARGET_STDS (scalers - Cellule 7)\n\n# --- 1. D√âS-STANDARDISATION des Pr√©dictions ---\nprint(f\"‚è≥ D√©s-standardisation des {final_predictions_knn.shape[0]} pr√©dictions...\")\nfinal_predictions_real = (final_predictions_knn * TARGET_STDS) + TARGET_MEANS\nprint(\"‚úÖ D√©s-standardisation termin√©e.\")\n\n\n# --- 2. Formatage et Application des Contraintes ---\n\nfinal_preds_list = []\n# CORRECTION MAJEURE : Remplacer 'ID' par 'ImageID' pour √©viter la KeyError\ntest_sample_ids = test_df['ImageID'].values \n\nprint(f\"‚è≥ Formatage des pr√©dictions pour la soumission...\")\n\n# Boucle principale\nfor i in range(final_predictions_real.shape[0]):\n    # Utilisation de l'ID pour la construction du sample_id\n    image_id_prefix = test_sample_ids[i]\n\n    for j, target_name in enumerate(TARGET_NAMES):\n        # R√©cup√©ration de la valeur pr√©dite (maintenant d√©s-standardis√©e)\n        value = final_predictions_real[i][j]\n        \n        # a) Contrainte Comp√©tition (>= 0.5) \n        # Application de la r√®gle sauvegard√©e : \"Le minimum de score requis... est de 0,5.\"\n        value = max(0.5, value) \n        \n        # Le sample_id final doit √™tre au format {ImageID}__{target_name}\n        submission_sample_id = f\"{image_id_prefix}__{target_name}\"\n        \n        final_preds_list.append({\n            \"sample_id\": submission_sample_id,\n            \"target\": value\n        })\n\n# --- 3. Cr√©ation du Fichier CSV ---\nsubmission_df = pd.DataFrame(final_preds_list)\n\n# CORRECTION CRUCIALE : Utilisation du nom de fichier requis par la comp√©tition\nsubmission_path = \"submission.csv\" \nsubmission_df.to_csv(submission_path, index=False)\n\nprint(f\"\\n‚úÖ Soumission g√©n√©r√©e (Nom de Fichier et ID Corrig√©s) : {submission_path} ({len(submission_df)} lignes)\")\nprint(\"Aper√ßu de la soumission :\")\nprint(submission_df.head(5))","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}