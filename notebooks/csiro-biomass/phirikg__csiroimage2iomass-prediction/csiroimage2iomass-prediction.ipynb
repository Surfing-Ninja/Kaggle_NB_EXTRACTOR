{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":112509,"databundleVersionId":14254895,"sourceType":"competition"}],"dockerImageVersionId":31153,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-11-07T20:20:55.020706Z","iopub.execute_input":"2025-11-07T20:20:55.021101Z","iopub.status.idle":"2025-11-07T20:20:56.242244Z","shell.execute_reply.started":"2025-11-07T20:20:55.021069Z","shell.execute_reply":"2025-11-07T20:20:56.24067Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# First, let's see what's available in the input directory\nimport os\nimport pandas as pd\n\n# List all directories in /kaggle/input\nprint(\"Contents of /kaggle/input:\")\ninput_dir = '/kaggle/input'\nif os.path.exists(input_dir):\n    for item in os.listdir(input_dir):\n        item_path = os.path.join(input_dir, item)\n        if os.path.isdir(item_path):\n            print(f\"üìÅ {item}\")\n            # List contents of this directory\n            try:\n                sub_items = os.listdir(item_path)\n                for sub_item in sub_items[:10]:  # Show first 10 items\n                    print(f\"   üìÑ {sub_item}\")\n                if len(sub_items) > 10:\n                    print(f\"   ... and {len(sub_items) - 10} more files\")\n            except PermissionError:\n                print(\"   üîí Permission denied\")\nelse:\n    print(\"‚ùå /kaggle/input directory not found\")\n\nprint(\"\\n\" + \"=\"*50)\n\n# Also check the current working directory\nprint(f\"Current working directory: {os.getcwd()}\")\nprint(\"Contents of current directory:\")\nfor item in os.listdir('.'):\n    print(f\"üìÑ {item}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-07T20:20:56.244098Z","iopub.execute_input":"2025-11-07T20:20:56.244656Z","iopub.status.idle":"2025-11-07T20:20:56.259083Z","shell.execute_reply.started":"2025-11-07T20:20:56.244628Z","shell.execute_reply":"2025-11-07T20:20:56.257602Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Check if data is now available\nimport os\nimport pandas as pd\n\nprint(\"Checking for competition data...\")\n\n# List all datasets in /kaggle/input\ninput_dir = '/kaggle/input'\ndatasets = [d for d in os.listdir(input_dir) if os.path.isdir(os.path.join(input_dir, d))]\nprint(\"Available datasets:\", datasets)\n\n# Look for biomass-related datasets\nbiomass_datasets = [d for d in datasets if 'biomass' in d.lower() or 'image' in d.lower()]\nprint(\"Biomass-related datasets:\", biomass_datasets)\n\nif biomass_datasets:\n    data_path = f'/kaggle/input/{biomass_datasets[0]}'\n    print(f\"üìÅ Using dataset: {data_path}\")\n    print(\"Files in this dataset:\")\n    for file in os.listdir(data_path):\n        print(f\"   üìÑ {file}\")\nelse:\n    print(\"‚ùå No biomass datasets found - please add the competition data\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-07T20:20:56.260311Z","iopub.execute_input":"2025-11-07T20:20:56.260753Z","iopub.status.idle":"2025-11-07T20:20:56.290586Z","shell.execute_reply.started":"2025-11-07T20:20:56.260701Z","shell.execute_reply":"2025-11-07T20:20:56.288633Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Sometimes the competition has a different exact name\n# Let's search more broadly\nimport os\n\ndef find_competition_data():\n    input_dir = '/kaggle/input'\n    if not os.path.exists(input_dir):\n        print(\"‚ùå /kaggle/input directory doesn't exist\")\n        return None\n    \n    all_datasets = os.listdir(input_dir)\n    print(\"All available datasets:\")\n    for dataset in all_datasets:\n        dataset_path = os.path.join(input_dir, dataset)\n        files = os.listdir(dataset_path)\n        print(f\"üìÅ {dataset}: {len(files)} files\")\n        for file in files[:5]:  # Show first 5 files\n            print(f\"   üìÑ {file}\")\n        if len(files) > 5:\n            print(f\"   ... and {len(files) - 5} more\")\n        print()\n    \n    return all_datasets\n\nfind_competition_data()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-07T20:20:56.293929Z","iopub.execute_input":"2025-11-07T20:20:56.295732Z","iopub.status.idle":"2025-11-07T20:20:56.331332Z","shell.execute_reply.started":"2025-11-07T20:20:56.295687Z","shell.execute_reply":"2025-11-07T20:20:56.330005Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Check for specific competition files we need\nrequired_files = ['train.csv', 'train_images', 'test_images', 'sample_submission.csv']\n\nfor dataset in os.listdir('/kaggle/input'):\n    dataset_path = f'/kaggle/input/{dataset}'\n    found_files = []\n    \n    for file in required_files:\n        if os.path.exists(os.path.join(dataset_path, file)):\n            found_files.append(file)\n    \n    if found_files:\n        print(f\"‚úÖ Found {len(found_files)} required files in '{dataset}':\")\n        for file in found_files:\n            print(f\"   ‚úì {file}\")\n        \n        # Try to load the data\n        try:\n            train_path = os.path.join(dataset_path, 'train.csv')\n            train_df = pd.read_csv(train_path)\n            print(f\"‚úÖ Successfully loaded training data: {len(train_df)} samples\")\n            break\n        except:\n            continue","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-07T20:20:56.333261Z","iopub.execute_input":"2025-11-07T20:20:56.333943Z","iopub.status.idle":"2025-11-07T20:20:56.388645Z","shell.execute_reply.started":"2025-11-07T20:20:56.333893Z","shell.execute_reply":"2025-11-07T20:20:56.387552Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Create a complete working environment with sample data\nimport pandas as pd\nimport numpy as np\nimport os\nfrom PIL import Image\n\ndef create_working_environment():\n    print(\"Setting up working environment with sample data...\")\n    \n    # Create directories\n    os.makedirs('/kaggle/working/train_images', exist_ok=True)\n    os.makedirs('/kaggle/working/test_images', exist_ok=True)\n    \n    # Create sample training data\n    train_data = {\n        'image_id': [f'train_{i:04d}' for i in range(200)],\n        'biomass': np.random.uniform(0.1, 25.0, 200)\n    }\n    train_df = pd.DataFrame(train_data)\n    train_df.to_csv('/kaggle/working/train.csv', index=False)\n    \n    # Create sample submission\n    sub_data = {\n        'image_id': [f'test_{i:04d}' for i in range(100)],\n        'biomass': [0.0] * 100\n    }\n    sub_df = pd.DataFrame(sub_data)\n    sub_df.to_csv('/kaggle/working/sample_submission.csv', index=False)\n    \n    # Create sample images (greenish images to simulate plants)\n    for img_id in train_data['image_id'] + sub_data['image_id']:\n        # Create green-dominant images\n        img_array = np.random.randint(50, 150, (256, 256, 3), dtype=np.uint8)\n        # Make it more green (boost green channel)\n        img_array[:, :, 1] = np.random.randint(100, 200, (256, 256))\n        \n        img = Image.fromarray(img_array)\n        if 'train' in img_id:\n            img.save(f'/kaggle/working/train_images/{img_id}.jpg')\n        else:\n            img.save(f'/kaggle/working/test_images/{img_id}.jpg')\n    \n    print(\"‚úÖ Sample environment created!\")\n    print(f\"Training samples: {len(train_df)}\")\n    print(f\"Test samples: {len(sub_df)}\")\n    \n    return train_df, sub_df\n\n# Use sample data if real data isn't available\ntry:\n    # Try one more time to find real data\n    for dataset in os.listdir('/kaggle/input'):\n        dataset_path = f'/kaggle/input/{dataset}'\n        if 'train.csv' in os.listdir(dataset_path):\n            train_df = pd.read_csv(f'{dataset_path}/train.csv')\n            print(f\"‚úÖ Found real competition data in '{dataset}'!\")\n            print(f\"Training samples: {len(train_df)}\")\n            break\n    else:\n        raise FileNotFoundError\nexcept:\n    print(\"‚ö†Ô∏è Using sample data - you can replace with real data later\")\n    train_df, sample_sub = create_working_environment()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-07T20:20:56.389599Z","iopub.execute_input":"2025-11-07T20:20:56.389984Z","iopub.status.idle":"2025-11-07T20:20:56.413532Z","shell.execute_reply.started":"2025-11-07T20:20:56.389962Z","shell.execute_reply":"2025-11-07T20:20:56.411744Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport os\nfrom PIL import Image\n\n# Set the correct paths\ndata_path = '/kaggle/input/csiro-biomass'\ntrain_csv_path = f'{data_path}/train.csv'\ntest_csv_path = f'{data_path}/test.csv'\nsample_sub_path = f'{data_path}/sample_submission.csv'\ntrain_images_path = f'{data_path}/train'\ntest_images_path = f'{data_path}/test'\n\nprint(\"üìÅ Competition Data Structure:\")\nprint(f\"Train CSV: {train_csv_path}\")\nprint(f\"Test CSV: {test_csv_path}\")\nprint(f\"Sample submission: {sample_sub_path}\")\nprint(f\"Train images: {train_images_path}\")\nprint(f\"Test images: {test_images_path}\")\n\n# Load the data\ntrain_df = pd.read_csv(train_csv_path)\ntest_df = pd.read_csv(test_csv_path)\nsample_sub = pd.read_csv(sample_sub_path)\n\nprint(f\"\\n‚úÖ Data loaded successfully!\")\nprint(f\"Training samples: {len(train_df)}\")\nprint(f\"Test samples: {len(test_df)}\")\nprint(f\"Sample submission: {len(sample_sub)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-07T20:20:56.414773Z","iopub.execute_input":"2025-11-07T20:20:56.415187Z","iopub.status.idle":"2025-11-07T20:20:56.47244Z","shell.execute_reply.started":"2025-11-07T20:20:56.41512Z","shell.execute_reply":"2025-11-07T20:20:56.470996Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Display data overview\nprint(\"üìä TRAINING DATA:\")\nprint(train_df.head())\nprint(f\"\\nTraining data shape: {train_df.shape}\")\nprint(f\"Columns: {train_df.columns.tolist()}\")\n\nprint(\"\\nüìä TEST DATA:\")\nprint(test_df.head())\nprint(f\"\\nTest data shape: {test_df.shape}\")\n\nprint(\"\\nüìä SAMPLE SUBMISSION:\")\nprint(sample_sub.head())\n\n# Check for missing values\nprint(\"\\nüîç MISSING VALUES:\")\nprint(\"Training data:\")\nprint(train_df.isnull().sum())\nprint(\"\\nTest data:\")\nprint(test_df.isnull().sum())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-07T20:20:56.473822Z","iopub.execute_input":"2025-11-07T20:20:56.474181Z","iopub.status.idle":"2025-11-07T20:20:56.507986Z","shell.execute_reply.started":"2025-11-07T20:20:56.474129Z","shell.execute_reply":"2025-11-07T20:20:56.506646Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Now analyze with the correct column name\nif 'target_column' in locals() and target_column:\n    plt.figure(figsize=(15, 5))\n\n    plt.subplot(1, 3, 1)\n    plt.hist(train_df[target_column], bins=50, alpha=0.7, color='green', edgecolor='black')\n    plt.title(f'Distribution of {target_column}')\n    plt.xlabel(target_column)\n    plt.ylabel('Frequency')\n\n    plt.subplot(1, 3, 2)\n    plt.boxplot(train_df[target_column])\n    plt.title(f'Boxplot of {target_column}')\n    plt.ylabel(target_column)\n\n    plt.subplot(1, 3, 3)\n    # Log transform if needed\n    if train_df[target_column].min() > 0:\n        plt.hist(np.log1p(train_df[target_column]), bins=50, alpha=0.7, color='orange', edgecolor='black')\n        plt.title(f'Log-Transformed {target_column}')\n        plt.xlabel(f'Log({target_column} + 1)')\n        plt.ylabel('Frequency')\n\n    plt.tight_layout()\n    plt.show()\n\n    # Basic statistics\n    print(f\"üìà {target_column.upper()} STATISTICS:\")\n    print(train_df[target_column].describe())\nelse:\n    print(\"‚ùå Could not identify target column\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-07T20:20:56.509346Z","iopub.execute_input":"2025-11-07T20:20:56.509652Z","iopub.status.idle":"2025-11-07T20:20:56.520494Z","shell.execute_reply.started":"2025-11-07T20:20:56.509631Z","shell.execute_reply":"2025-11-07T20:20:56.519086Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\nimport torchvision.transforms as transforms\n\n# Check if GPU is available\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(f\"Using device: {device}\")\n\n# Updated Dataset class with correct target column\nclass BiomassDataset(Dataset):\n    def __init__(self, dataframe, images_dir, target_column=None, transform=None, is_test=False):\n        self.dataframe = dataframe\n        self.images_dir = images_dir\n        self.transform = transform\n        self.is_test = is_test\n        self.target_column = target_column\n        \n        # Try to find the image ID column\n        self.image_id_col = None\n        potential_id_cols = ['id', 'image', 'image_id', 'filename', 'name']\n        \n        for col in potential_id_cols:\n            if col in dataframe.columns:\n                self.image_id_col = col\n                break\n        \n        if self.image_id_col is None:\n            # Use first column as fallback\n            self.image_id_col = dataframe.columns[0]\n        \n        print(f\"Using '{self.image_id_col}' for image IDs\")\n        if not is_test and self.target_column:\n            print(f\"Using '{self.target_column}' as target variable\")\n    \n    def __len__(self):\n        return len(self.dataframe)\n    \n    def __getitem__(self, idx):\n        # Get image ID from dataframe\n        img_id = str(self.dataframe.iloc[idx][self.image_id_col])\n        \n        # Try different image extensions and patterns\n        img_path = None\n        for ext in ['.jpg', '.jpeg', '.png', '.JPG', '.JPEG', '.PNG', '']:\n            for pattern in [img_id + ext, f\"{img_id}{ext}\"]:\n                potential_path = os.path.join(self.images_dir, pattern)\n                if os.path.exists(potential_path):\n                    img_path = potential_path\n                    break\n            if img_path:\n                break\n        \n        if img_path is None:\n            # Try to find any image that contains the ID\n            for img_file in os.listdir(self.images_dir):\n                if img_id in img_file:\n                    img_path = os.path.join(self.images_dir, img_file)\n                    break\n        \n        if img_path is None:\n            # Create a dummy image if file not found (for testing)\n            print(f\"Warning: Could not find image for ID: {img_id}\")\n            img = Image.new('RGB', (256, 256), color='green')\n        else:\n            img = Image.open(img_path).convert('RGB')\n        \n        if self.transform:\n            img = self.transform(img)\n        \n        if self.is_test:\n            return img, img_id\n        else:\n            if self.target_column and self.target_column in self.dataframe.columns:\n                biomass = self.dataframe.iloc[idx][self.target_column]\n                return img, torch.tensor(biomass, dtype=torch.float32)\n            else:\n                # Return dummy value if no target column\n                return img, torch.tensor(0.0, dtype=torch.float32)\n\n# Define transforms\ntrain_transform = transforms.Compose([\n    transforms.Resize((256, 256)),\n    transforms.RandomHorizontalFlip(p=0.3),\n    transforms.RandomRotation(10),\n    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n])\n\nval_transform = transforms.Compose([\n    transforms.Resize((256, 256)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n])\n\n# Create datasets (we'll determine target_column from our analysis)\ntarget_column = 'Dry_biomass'  # This will be updated based on what we find\n\n# Use the actual target column we identified\nif 'target_column' in locals() and target_column:\n    train_dataset = BiomassDataset(train_df, f'{data_path}/train', \n                                 target_column=target_column, transform=train_transform)\nelse:\n    train_dataset = BiomassDataset(train_df, f'{data_path}/train', \n                                 transform=train_transform)\n\ntest_dataset = BiomassDataset(test_df, f'{data_path}/test', \n                            transform=val_transform, is_test=True)\n\n# Create data loaders\ntrain_loader = DataLoader(train_dataset, batch_size=16, shuffle=True, num_workers=2)\ntest_loader = DataLoader(test_dataset, batch_size=16, shuffle=False, num_workers=2)\n\nprint(\"‚úÖ Data loaders created successfully!\")\nprint(f\"Train batches: {len(train_loader)}\")\nprint(f\"Test batches: {len(test_loader)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-07T20:20:56.524241Z","iopub.execute_input":"2025-11-07T20:20:56.524556Z","iopub.status.idle":"2025-11-07T20:21:07.319407Z","shell.execute_reply.started":"2025-11-07T20:20:56.524533Z","shell.execute_reply":"2025-11-07T20:21:07.317978Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Test one batch\ntry:\n    for images, targets in train_loader:\n        print(f\"‚úÖ Pipeline working!\")\n        print(f\"Batch images shape: {images.shape}\")\n        print(f\"Batch targets shape: {targets.shape}\")\n        print(f\"Sample target values: {targets[:5]}\")\n        break\nexcept Exception as e:\n    print(f\"‚ùå Error in pipeline: {e}\")\n    print(\"Let's debug further...\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-07T20:21:07.320455Z","iopub.execute_input":"2025-11-07T20:21:07.321251Z","iopub.status.idle":"2025-11-07T20:21:08.477455Z","shell.execute_reply.started":"2025-11-07T20:21:07.321195Z","shell.execute_reply":"2025-11-07T20:21:08.476312Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport os\nfrom PIL import Image\n\ndata_path = '/kaggle/input/csiro-biomass'\n\n# Load the data\ntrain_df = pd.read_csv(f'{data_path}/train.csv')\ntest_df = pd.read_csv(f'{data_path}/test.csv')\n\nprint(\"üéØ DATA STRUCTURE ANALYSIS:\")\nprint(f\"Training data: {train_df.shape}\")\nprint(f\"Test data: {test_df.shape}\")\n\nprint(\"\\nüìä TRAINING DATA COLUMNS:\")\nprint(train_df.columns.tolist())\n\nprint(\"\\nüìä TRAINING DATA SAMPLE:\")\nprint(train_df.head())\n\nprint(\"\\nüìä TEST DATA SAMPLE:\")\nprint(test_df.head())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-07T20:21:08.479224Z","iopub.execute_input":"2025-11-07T20:21:08.479666Z","iopub.status.idle":"2025-11-07T20:21:08.511442Z","shell.execute_reply.started":"2025-11-07T20:21:08.479622Z","shell.execute_reply":"2025-11-07T20:21:08.510365Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Analyze the target column\nprint(\"üìà TARGET VARIABLE ANALYSIS:\")\nprint(f\"Target column: 'target'\")\nprint(f\"Target statistics:\")\nprint(train_df['target'].describe())\n\nplt.figure(figsize=(15, 5))\n\nplt.subplot(1, 3, 1)\nplt.hist(train_df['target'], bins=50, alpha=0.7, color='green', edgecolor='black')\nplt.title('Distribution of Target Biomass')\nplt.xlabel('Target Biomass')\nplt.ylabel('Frequency')\n\nplt.subplot(1, 3, 2)\nplt.boxplot(train_df['target'])\nplt.title('Boxplot of Target Biomass')\nplt.ylabel('Target Biomass')\n\nplt.subplot(1, 3, 3)\n# Check if we should use log transform\nif train_df['target'].min() > 0:\n    plt.hist(np.log1p(train_df['target']), bins=50, alpha=0.7, color='orange', edgecolor='black')\n    plt.title('Log-Transformed Target Biomass')\n    plt.xlabel('Log(Target + 1)')\n    plt.ylabel('Frequency')\nelse:\n    # Show original distribution again\n    plt.hist(train_df['target'], bins=50, alpha=0.7, color='blue', edgecolor='black')\n    plt.title('Target Distribution (Original)')\n    plt.xlabel('Target Biomass')\n    plt.ylabel('Frequency')\n\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-07T20:21:08.512616Z","iopub.execute_input":"2025-11-07T20:21:08.512972Z","iopub.status.idle":"2025-11-07T20:21:09.599534Z","shell.execute_reply.started":"2025-11-07T20:21:08.512943Z","shell.execute_reply":"2025-11-07T20:21:09.598421Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Check the image paths and files\nprint(\"üñºÔ∏è IMAGE PATHS ANALYSIS:\")\n\n# Check a few image paths from the training data\nprint(\"Sample image paths from training data:\")\nfor i, path in enumerate(train_df['image_path'].head()):\n    print(f\"  {i+1}. {path}\")\n\n# Check if images exist\nprint(\"\\nüîç CHECKING IF IMAGES EXIST:\")\ndata_dir = '/kaggle/input/csiro-biomass'\n\n# Check a few images\nfound_count = 0\nnot_found_count = 0\n\nfor i, img_path in enumerate(train_df['image_path'].head(10)):\n    full_path = os.path.join(data_dir, img_path)\n    if os.path.exists(full_path):\n        print(f\"‚úÖ {img_path} - EXISTS\")\n        found_count += 1\n        # Display first found image\n        if found_count == 1:\n            try:\n                img = Image.open(full_path)\n                print(f\"    Image size: {img.size}, Mode: {img.mode}\")\n            except Exception as e:\n                print(f\"    Error opening image: {e}\")\n    else:\n        print(f\"‚ùå {img_path} - NOT FOUND\")\n        not_found_count += 1\n\nprint(f\"\\nSummary: {found_count} found, {not_found_count} not found in first 10 samples\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-07T20:21:09.600596Z","iopub.execute_input":"2025-11-07T20:21:09.601043Z","iopub.status.idle":"2025-11-07T20:21:09.65701Z","shell.execute_reply.started":"2025-11-07T20:21:09.601012Z","shell.execute_reply":"2025-11-07T20:21:09.655955Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\nimport torchvision.transforms as transforms\n\nclass CorrectBiomassDataset(Dataset):\n    def __init__(self, dataframe, base_dir, target_column='target', transform=None, is_test=False):\n        self.dataframe = dataframe\n        self.base_dir = base_dir\n        self.target_column = target_column\n        self.transform = transform\n        self.is_test = is_test\n        \n    def __len__(self):\n        return len(self.dataframe)\n    \n    def __getitem__(self, idx):\n        # Get image path from dataframe\n        img_relative_path = self.dataframe.iloc[idx]['image_path']\n        img_full_path = os.path.join(self.base_dir, img_relative_path)\n        \n        # Load image\n        try:\n            img = Image.open(img_full_path).convert('RGB')\n        except Exception as e:\n            print(f\"Error loading image {img_full_path}: {e}\")\n            # Create a dummy image as fallback\n            img = Image.new('RGB', (256, 256), color='gray')\n        \n        # Apply transforms\n        if self.transform:\n            img = self.transform(img)\n        \n        if self.is_test:\n            sample_id = self.dataframe.iloc[idx]['sample_id']\n            return img, sample_id\n        else:\n            target_value = float(self.dataframe.iloc[idx][self.target_column])\n            return img, torch.tensor(target_value, dtype=torch.float32)\n\n# Define transforms\ntrain_transform = transforms.Compose([\n    transforms.Resize((256, 256)),\n    transforms.RandomHorizontalFlip(p=0.3),\n    transforms.RandomRotation(10),\n    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n])\n\nval_transform = transforms.Compose([\n    transforms.Resize((256, 256)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n])\n\n# Create datasets\ntrain_dataset = CorrectBiomassDataset(\n    train_df, \n    data_path, \n    target_column='target', \n    transform=train_transform\n)\n\ntest_dataset = CorrectBiomassDataset(\n    test_df, \n    data_path, \n    transform=val_transform, \n    is_test=True\n)\n\n# Create data loaders\ntrain_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=2)\ntest_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=2)\n\nprint(\"‚úÖ Datasets and data loaders created successfully!\")\nprint(f\"Training samples: {len(train_dataset)}\")\nprint(f\"Test samples: {len(test_dataset)}\")\nprint(f\"Train batches: {len(train_loader)}\")\nprint(f\"Test batches: {len(test_loader)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-07T20:21:09.658217Z","iopub.execute_input":"2025-11-07T20:21:09.658538Z","iopub.status.idle":"2025-11-07T20:21:09.675659Z","shell.execute_reply.started":"2025-11-07T20:21:09.658516Z","shell.execute_reply":"2025-11-07T20:21:09.674521Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Test the pipeline\nprint(\"üß™ Testing the data pipeline...\")\n\n# Test training data\nfor images, targets in train_loader:\n    print(f\"‚úÖ Training pipeline working!\")\n    print(f\"Batch images shape: {images.shape}\")\n    print(f\"Batch targets shape: {targets.shape}\")\n    print(f\"Sample target values: {targets[:5]}\")\n    print(f\"Target stats - Min: {targets.min():.2f}, Max: {targets.max():.2f}, Mean: {targets.mean():.2f}\")\n    \n    # Display sample image\n    plt.figure(figsize=(10, 8))\n    \n    # Show first 4 images\n    for i in range(min(4, images.shape[0])):\n        plt.subplot(2, 2, i+1)\n        # Denormalize for display\n        img_display = images[i].permute(1, 2, 0).numpy()\n        img_display = img_display * np.array([0.229, 0.224, 0.225]) + np.array([0.485, 0.456, 0.406])\n        img_display = np.clip(img_display, 0, 1)\n        plt.imshow(img_display)\n        plt.title(f'Target: {targets[i]:.2f}')\n        plt.axis('off')\n    \n    plt.tight_layout()\n    plt.show()\n    break\n\n# Test test data\nprint(\"\\nüß™ Testing test data pipeline...\")\nfor images, sample_ids in test_loader:\n    print(f\"‚úÖ Test pipeline working!\")\n    print(f\"Batch images shape: {images.shape}\")\n    print(f\"Sample IDs: {sample_ids}\")\n    break","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-07T20:21:09.677017Z","iopub.execute_input":"2025-11-07T20:21:09.677321Z","iopub.status.idle":"2025-11-07T20:21:18.800426Z","shell.execute_reply.started":"2025-11-07T20:21:09.6773Z","shell.execute_reply":"2025-11-07T20:21:18.79874Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Display some sample images with their targets\ndef display_sample_images_with_targets(dataset, num_samples=8):\n    fig, axes = plt.subplots(2, 4, figsize=(20, 10))\n    axes = axes.ravel()\n    \n    indices = np.random.choice(len(dataset), num_samples, replace=False)\n    \n    for i, idx in enumerate(indices):\n        image, target = dataset[idx]\n        \n        # Convert tensor back to numpy for display\n        if isinstance(image, torch.Tensor):\n            img_display = image.permute(1, 2, 0).numpy()\n            img_display = img_display * np.array([0.229, 0.224, 0.225]) + np.array([0.485, 0.456, 0.406])\n            img_display = np.clip(img_display, 0, 1)\n        else:\n            img_display = np.array(image)\n        \n        axes[i].imshow(img_display)\n        axes[i].set_title(f'Target: {target:.2f}', fontsize=12, weight='bold')\n        axes[i].axis('off')\n    \n    plt.tight_layout()\n    plt.suptitle('Sample Training Images with Biomass Targets', fontsize=16, y=1.02)\n    plt.show()\n\ndisplay_sample_images_with_targets(train_dataset)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-07T20:21:18.80204Z","iopub.execute_input":"2025-11-07T20:21:18.802951Z","iopub.status.idle":"2025-11-07T20:21:22.16136Z","shell.execute_reply.started":"2025-11-07T20:21:18.802917Z","shell.execute_reply":"2025-11-07T20:21:22.160329Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torchvision.models as models\nimport timm\n\nclass BiomassPredictor(nn.Module):\n    def __init__(self, backbone='resnet50', pretrained=True):\n        super(BiomassPredictor, self).__init__()\n        \n        # Use pre-trained CNN backbone\n        if backbone == 'resnet50':\n            self.backbone = models.resnet50(pretrained=pretrained)\n            # Replace the final fully connected layer\n            in_features = self.backbone.fc.in_features\n            self.backbone.fc = nn.Identity()  # Remove the original classification head\n        elif backbone == 'efficientnet_b0':\n            self.backbone = timm.create_model('efficientnet_b0', pretrained=pretrained, num_classes=0)\n            in_features = self.backbone.num_features\n        else:\n            raise ValueError(f\"Unsupported backbone: {backbone}\")\n        \n        # Regression head for biomass prediction\n        self.regressor = nn.Sequential(\n            nn.Dropout(0.2),\n            nn.Linear(in_features, 512),\n            nn.ReLU(inplace=True),\n            nn.BatchNorm1d(512),\n            nn.Dropout(0.3),\n            nn.Linear(512, 128),\n            nn.ReLU(inplace=True),\n            nn.BatchNorm1d(128),\n            nn.Dropout(0.2),\n            nn.Linear(128, 1)  # Single output for biomass value\n        )\n        \n    def forward(self, x):\n        features = self.backbone(x)\n        biomass = self.regressor(features)\n        return biomass.squeeze()  # Remove extra dimension\n\n# Create model\nmodel = BiomassPredictor(backbone='resnet50', pretrained=True)\n\n# Move to GPU if available\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel = model.to(device)\n\nprint(\"‚úÖ Model created successfully!\")\nprint(f\"Using device: {device}\")\nprint(f\"Model architecture:\\n{model}\")\n\n# Count parameters\ntotal_params = sum(p.numel() for p in model.parameters())\ntrainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\nprint(f\"\\nüìä Total parameters: {total_params:,}\")\nprint(f\"üìä Trainable parameters: {trainable_params:,}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-07T20:21:22.162501Z","iopub.execute_input":"2025-11-07T20:21:22.162775Z","iopub.status.idle":"2025-11-07T20:21:30.055408Z","shell.execute_reply.started":"2025-11-07T20:21:22.162756Z","shell.execute_reply":"2025-11-07T20:21:30.054236Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch.optim as optim\nfrom torch.optim.lr_scheduler import ReduceLROnPlateau\n\n# Loss function - Mean Squared Error for regression\ncriterion = nn.MSELoss()\n\n# Optimizer\noptimizer = optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-4)\n\n# Learning rate scheduler\nscheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=3, verbose=True)\n\nprint(\"‚úÖ Loss function, optimizer, and scheduler defined!\")\nprint(f\"Loss: {criterion}\")\nprint(f\"Optimizer: {optimizer}\")\nprint(f\"Scheduler: ReduceLROnPlateau\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-07T20:21:30.056479Z","iopub.execute_input":"2025-11-07T20:21:30.056836Z","iopub.status.idle":"2025-11-07T20:21:30.068292Z","shell.execute_reply.started":"2025-11-07T20:21:30.056805Z","shell.execute_reply":"2025-11-07T20:21:30.066972Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def train_epoch(model, dataloader, criterion, optimizer, device):\n    model.train()\n    running_loss = 0.0\n    all_predictions = []\n    all_targets = []\n    \n    for batch_idx, (images, targets) in enumerate(dataloader):\n        images, targets = images.to(device), targets.to(device)\n        \n        # Zero gradients\n        optimizer.zero_grad()\n        \n        # Forward pass\n        outputs = model(images)\n        loss = criterion(outputs, targets)\n        \n        # Backward pass\n        loss.backward()\n        optimizer.step()\n        \n        # Statistics\n        running_loss += loss.item()\n        all_predictions.extend(outputs.detach().cpu().numpy())\n        all_targets.extend(targets.cpu().numpy())\n        \n        # Progress update\n        if (batch_idx + 1) % 50 == 0:\n            print(f'    Batch {batch_idx + 1}/{len(dataloader)}, Loss: {loss.item():.4f}')\n    \n    epoch_loss = running_loss / len(dataloader)\n    return epoch_loss, all_predictions, all_targets\n\ndef validate_epoch(model, dataloader, criterion, device):\n    model.eval()\n    running_loss = 0.0\n    all_predictions = []\n    all_targets = []\n    \n    with torch.no_grad():\n        for images, targets in dataloader:\n            images, targets = images.to(device), targets.to(device)\n            \n            outputs = model(images)\n            loss = criterion(outputs, targets)\n            \n            running_loss += loss.item()\n            all_predictions.extend(outputs.cpu().numpy())\n            all_targets.extend(targets.cpu().numpy())\n    \n    epoch_loss = running_loss / len(dataloader)\n    return epoch_loss, all_predictions, all_targets\n\nprint(\"‚úÖ Training and validation functions defined!\")\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-07T20:21:30.069692Z","iopub.execute_input":"2025-11-07T20:21:30.070391Z","iopub.status.idle":"2025-11-07T20:21:30.091229Z","shell.execute_reply.started":"2025-11-07T20:21:30.070356Z","shell.execute_reply":"2025-11-07T20:21:30.089842Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\n# Split training data into train and validation\ntrain_indices, val_indices = train_test_split(\n    range(len(train_df)), \n    test_size=0.2, \n    random_state=42,\n    shuffle=True\n)\n\nprint(f\"Training samples: {len(train_indices)}\")\nprint(f\"Validation samples: {len(val_indices)}\")\n\n# Create subset datasets\nfrom torch.utils.data import Subset\n\ntrain_subset = Subset(train_dataset, train_indices)\nval_subset = Subset(train_dataset, val_indices)\n\n# Create data loaders for train and validation\ntrain_loader = DataLoader(train_subset, batch_size=32, shuffle=True, num_workers=2)\nval_loader = DataLoader(val_subset, batch_size=32, shuffle=False, num_workers=2)\n\nprint(\"‚úÖ Train/validation split created!\")\nprint(f\"Train batches: {len(train_loader)}\")\nprint(f\"Val batches: {len(val_loader)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-07T20:21:30.092352Z","iopub.execute_input":"2025-11-07T20:21:30.092633Z","iopub.status.idle":"2025-11-07T20:21:30.139421Z","shell.execute_reply.started":"2025-11-07T20:21:30.092612Z","shell.execute_reply":"2025-11-07T20:21:30.138133Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.optim.lr_scheduler import ReduceLROnPlateau\nimport numpy as np\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n\n# Set device\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(f\"‚úÖ Device set to: {device}\")\n\n# Define training functions\ndef train_epoch(model, dataloader, criterion, optimizer, device):\n    model.train()\n    running_loss = 0.0\n    all_predictions = []\n    all_targets = []\n    \n    for batch_idx, (images, targets) in enumerate(dataloader):\n        images, targets = images.to(device), targets.to(device)\n        \n        optimizer.zero_grad()\n        outputs = model(images)\n        loss = criterion(outputs, targets)\n        loss.backward()\n        optimizer.step()\n        \n        running_loss += loss.item()\n        all_predictions.extend(outputs.detach().cpu().numpy())\n        all_targets.extend(targets.cpu().numpy())\n        \n    epoch_loss = running_loss / len(dataloader)\n    return epoch_loss, all_predictions, all_targets\n\ndef validate_epoch(model, dataloader, criterion, device):\n    model.eval()\n    running_loss = 0.0\n    all_predictions = []\n    all_targets = []\n    \n    with torch.no_grad():\n        for images, targets in dataloader:\n            images, targets = images.to(device), targets.to(device)\n            outputs = model(images)\n            loss = criterion(outputs, targets)\n            running_loss += loss.item()\n            all_predictions.extend(outputs.cpu().numpy())\n            all_targets.extend(targets.cpu().numpy())\n    \n    epoch_loss = running_loss / len(dataloader)\n    return epoch_loss, all_predictions, all_targets\n\ndef calculate_metrics(predictions, targets):\n    mae = mean_absolute_error(targets, predictions)\n    mse = mean_squared_error(targets, predictions)\n    rmse = np.sqrt(mse)\n    r2 = r2_score(targets, predictions)\n    return mae, mse, rmse, r2\n\nprint(\"‚úÖ All training functions defined!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-07T20:21:30.140692Z","iopub.execute_input":"2025-11-07T20:21:30.141047Z","iopub.status.idle":"2025-11-07T20:21:30.154663Z","shell.execute_reply.started":"2025-11-07T20:21:30.14102Z","shell.execute_reply":"2025-11-07T20:21:30.15353Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torchvision.models as models\nimport timm\n\nclass BiomassPredictor(nn.Module):\n    def __init__(self, backbone='resnet50', pretrained=True):\n        super(BiomassPredictor, self).__init__()\n        \n        if backbone == 'resnet50':\n            self.backbone = models.resnet50(pretrained=pretrained)\n            in_features = self.backbone.fc.in_features\n            self.backbone.fc = nn.Identity()\n        elif backbone == 'efficientnet_b0':\n            self.backbone = timm.create_model('efficientnet_b0', pretrained=pretrained, num_classes=0)\n            in_features = self.backbone.num_features\n        else:\n            raise ValueError(f\"Unsupported backbone: {backbone}\")\n        \n        self.regressor = nn.Sequential(\n            nn.Dropout(0.2),\n            nn.Linear(in_features, 512),\n            nn.ReLU(inplace=True),\n            nn.BatchNorm1d(512),\n            nn.Dropout(0.3),\n            nn.Linear(512, 128),\n            nn.ReLU(inplace=True),\n            nn.BatchNorm1d(128),\n            nn.Dropout(0.2),\n            nn.Linear(128, 1)\n        )\n        \n    def forward(self, x):\n        features = self.backbone(x)\n        biomass = self.regressor(features)\n        return biomass.squeeze()\n\n# Create model\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel = BiomassPredictor(backbone='resnet50', pretrained=True).to(device)\n\nprint(\"‚úÖ Model created successfully!\")\nprint(f\"Model is on: {device}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-07T20:21:30.155721Z","iopub.execute_input":"2025-11-07T20:21:30.15606Z","iopub.status.idle":"2025-11-07T20:21:30.870681Z","shell.execute_reply.started":"2025-11-07T20:21:30.156029Z","shell.execute_reply":"2025-11-07T20:21:30.869339Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nimport os\n\n# Load the data\ndata_path = '/kaggle/input/csiro-biomass'\ntrain_df = pd.read_csv(f'{data_path}/train.csv')\ntest_df = pd.read_csv(f'{data_path}/test.csv')\n\nprint(\"‚úÖ Data loaded!\")\nprint(f\"Training samples: {len(train_df)}\")\nprint(f\"Test samples: {len(test_df)}\")\n\n# Make sure train_dataset exists\nif 'train_dataset' not in locals():\n    # Recreate the dataset if needed\n    from torch.utils.data import Dataset\n    import torchvision.transforms as transforms\n    from PIL import Image\n    \n    class CorrectBiomassDataset(Dataset):\n        def __init__(self, dataframe, base_dir, target_column='target', transform=None, is_test=False):\n            self.dataframe = dataframe\n            self.base_dir = base_dir\n            self.target_column = target_column\n            self.transform = transform\n            self.is_test = is_test\n            \n        def __len__(self):\n            return len(self.dataframe)\n        \n        def __getitem__(self, idx):\n            img_relative_path = self.dataframe.iloc[idx]['image_path']\n            img_full_path = os.path.join(self.base_dir, img_relative_path)\n            \n            try:\n                img = Image.open(img_full_path).convert('RGB')\n            except Exception as e:\n                print(f\"Error loading image {img_full_path}: {e}\")\n                img = Image.new('RGB', (256, 256), color='gray')\n            \n            if self.transform:\n                img = self.transform(img)\n            \n            if self.is_test:\n                sample_id = self.dataframe.iloc[idx]['sample_id']\n                return img, sample_id\n            else:\n                target_value = float(self.dataframe.iloc[idx][self.target_column])\n                return img, torch.tensor(target_value, dtype=torch.float32)\n    \n    # Create transforms\n    train_transform = transforms.Compose([\n        transforms.Resize((256, 256)),\n        transforms.RandomHorizontalFlip(p=0.3),\n        transforms.RandomRotation(10),\n        transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n        transforms.ToTensor(),\n        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n    ])\n    \n    # Create dataset\n    train_dataset = CorrectBiomassDataset(\n        train_df, \n        data_path, \n        target_column='target', \n        transform=train_transform\n    )\n    \n    print(\"‚úÖ train_dataset created!\")\n\nprint(\"‚úÖ All data variables are ready!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-07T20:21:30.871972Z","iopub.execute_input":"2025-11-07T20:21:30.872387Z","iopub.status.idle":"2025-11-07T20:21:30.90214Z","shell.execute_reply.started":"2025-11-07T20:21:30.872356Z","shell.execute_reply":"2025-11-07T20:21:30.900384Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom torch.utils.data import Subset, DataLoader\n\n# Create train/validation split\ntrain_indices, val_indices = train_test_split(\n    range(len(train_df)), \n    test_size=0.2, \n    random_state=42,\n    shuffle=True\n)\n\nprint(f\"Training samples: {len(train_indices)}\")\nprint(f\"Validation samples: {len(val_indices)}\")\n\n# Create subset datasets\ntrain_subset = Subset(train_dataset, train_indices)\nval_subset = Subset(train_dataset, val_indices)\n\n# Create data loaders for train and validation\ntrain_loader = DataLoader(train_subset, batch_size=32, shuffle=True, num_workers=2)\nval_loader = DataLoader(val_subset, batch_size=32, shuffle=False, num_workers=2)\n\nprint(\"‚úÖ Data loaders created!\")\nprint(f\"Train batches: {len(train_loader)}\")\nprint(f\"Val batches: {len(val_loader)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-07T20:21:30.903586Z","iopub.execute_input":"2025-11-07T20:21:30.903954Z","iopub.status.idle":"2025-11-07T20:21:30.91537Z","shell.execute_reply.started":"2025-11-07T20:21:30.90393Z","shell.execute_reply":"2025-11-07T20:21:30.914533Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch.optim as optim\nfrom torch.optim.lr_scheduler import ReduceLROnPlateau\n\n# Loss function and optimizer\ncriterion = nn.MSELoss()\noptimizer = optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-4)\nscheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=3, verbose=True)\n\nprint(\"‚úÖ Loss function and optimizer defined!\")\nprint(f\"Criterion: {criterion}\")\nprint(f\"Optimizer: {optimizer}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-07T20:21:30.916479Z","iopub.execute_input":"2025-11-07T20:21:30.917347Z","iopub.status.idle":"2025-11-07T20:21:30.95545Z","shell.execute_reply.started":"2025-11-07T20:21:30.917315Z","shell.execute_reply":"2025-11-07T20:21:30.954023Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import time\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n\ndef calculate_metrics(predictions, targets):\n    mae = mean_absolute_error(targets, predictions)\n    mse = mean_squared_error(targets, predictions)\n    rmse = np.sqrt(mse)\n    r2 = r2_score(targets, predictions)\n    return mae, mse, rmse, r2\n\n# Training configuration\nnum_epochs = 20\nbest_val_loss = float('inf')\npatience = 5\npatience_counter = 0\n\n# Lists to store metrics\ntrain_losses = []\nval_losses = []\ntrain_metrics = []\nval_metrics = []\n\nprint(\"üöÄ Starting training...\")\nprint(f\"Epochs: {num_epochs}\")\nprint(f\"Device: {device}\")\nprint(\"-\" * 60)\n\nfor epoch in range(num_epochs):\n    start_time = time.time()\n    \n    # Training phase\n    train_loss, train_preds, train_targets = train_epoch(model, train_loader, criterion, optimizer, device)\n    \n    # Validation phase\n    val_loss, val_preds, val_targets = validate_epoch(model, val_loader, criterion, device)\n    \n    # Calculate metrics\n    train_mae, train_mse, train_rmse, train_r2 = calculate_metrics(train_preds, train_targets)\n    val_mae, val_mse, val_rmse, val_r2 = calculate_metrics(val_preds, val_targets)\n    \n    # Update learning rate\n    scheduler.step(val_loss)\n    \n    # Store metrics\n    train_losses.append(train_loss)\n    val_losses.append(val_loss)\n    train_metrics.append((train_mae, train_rmse, train_r2))\n    val_metrics.append((val_mae, val_rmse, val_r2))\n    \n    # Print progress\n    epoch_time = time.time() - start_time\n    print(f'Epoch {epoch+1:02d}/{num_epochs} | Time: {epoch_time:.1f}s')\n    print(f'  Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f}')\n    print(f'  Train MAE: {train_mae:.4f} | Val MAE: {val_mae:.4f}')\n    print(f'  Train RMSE: {train_rmse:.4f} | Val RMSE: {val_rmse:.4f}')\n    print(f'  Train R¬≤: {train_r2:.4f} | Val R¬≤: {val_r2:.4f}')\n    print('-' * 60)\n    \n    # Save best model\n    if val_loss < best_val_loss:\n        best_val_loss = val_loss\n        patience_counter = 0\n        torch.save(model.state_dict(), 'best_model.pth')\n        print(f'üíæ Best model saved! Val Loss: {val_loss:.4f}')\n    else:\n        patience_counter += 1\n        if patience_counter >= patience:\n            print(f'üõë Early stopping after {epoch+1} epochs')\n            break\n\nprint(\"‚úÖ Training completed!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-07T20:21:30.95655Z","iopub.execute_input":"2025-11-07T20:21:30.956895Z"}},"outputs":[],"execution_count":null}]}