{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[],"collapsed_sections":["ccMgG8SF19RQ","hvVvaY-vLTRu","boldIgOoKagL","qACciUk4J5Sm","9oXAtrYpJ_Op","6JZEKc6rKAjS","vlB-K3YwKBFi","jY6Umk2l2Bte","DZyEL9iL2C0r","aD0EtkiFR5nC","b6_iGKa42EP4","83AFzi9m2E3e","tOCzgd3p2Fbo","-kGnSxf12Ghl","_i3XrCH8_hwv","w1eigXCj2HLt","RgYdHsrj2Hxg","6uJSarCh2Is1","IRh_A_sD2JQa","k7dHOAnn2J1p","97I_gcqE2KYt","DUPVplCSUJ0D","c6l9-LD_Z3KL","0pN16re0PfC6","HRSVk_-KGLjJ","x51w-zdpGsAR","1cRaw3k54qVp","YCA-2jY3ZaVK","PAx4dhGpb0Hr","bZpOrNO7chs7","rkGKhREoaPHG","5d_SbhcS6738","N5dJz1HKcwIQ","km7wXTFHPwq8","gKX3N0dLSGGq","tziSnglDSdVG","hCUQFn8yS2yx","_01kluwnS32A","3lxHNs--S4oe","gLA08tLuS5W9","iN-cBhtsS6BT","pr9IeuL8S6rq","5uZR5-V2S7S0","m05_FPzfS75p","8xlibnMxS8n1","SvkveG6cS9rp","4mjyLsgGS-tz","mNAwNvleS_S3","MxjvOuz9TACp","Vh7TduCDTBCo","B95QHdpwTBxQ","hHEQPTkfTCZA","Pbjz0f_dTDtq","PizIG55dTEUd","R-s5eMRBTJCs","v0qzHs692eAY","9aB_frsDXbyL","1NMhzzfgS0o_","pmWfAKeGTFKA","q-l_BBUrTHYu","hojSLVg35jRN","musu962tUeB6","iMDUCWK3UiE4","s9CA7zUdUiyf","-DWh_eASUjbn","uD9lp3DtUkIN","mzrZyJf6Uk3P","J2itJdlyaBpI","3cyTfjQg2txJ","UDtMJugd2uVU","B3oS_H1W2u6P","yBiuAKTi2xZC","3E48sF7o21Is","Lsmdj6h923y2","f7dVrCo8260S","Xq3DqlGo2-SB","xj9YsNZk2-3_","StZRaFp02_cH","SLEeL3h52_9-","PKhpDoB_rHGB","VcQDhmL8xp_i","aEpbzZLGbbz8","czam5ihJbet_","f7gEExD3blQl","Cm3PFch1b0Ab","YM27rUAIb0qr","ynO_1viAxt0f","HSyklOxitwUS","I0kayOYLxmCk","JAe--lNtxor3","u-OTrk1Z9N2K","fmsPYYzL9W4W","D1Re4Ux49W4W","kun1Vd8n9W4W","dYwru-L89W4X","jET2_NQn9W4X","ZHQxmdTQ9W4X","sCa-0Gyltx6f","FfU4G6ILxTf7","TvmsH76acFUs","HsCPmq_tcHtg","g5DFt9OfcJvu","a2L9GZZicYO4","C9_CajMEcY06","MX4sYRPdxbFM","kT_tu3xbezi9","WN_C-os1e1zf","JCqeadVee1zf","gsmj1hiTe1zf","eCiWIhkbe1zf","omAQhevke1zf","OPRXAU_Xxbvi","J51oUtyadNnH","wWMti_I5degd","0w_40--AdkYD","i4xbMsNedqUZ","qf5VJ2dFdq-d","VmzSQ9SXh27q","GcBZyWMGxcYz","HC_PvpXId6Ga","OlAHZOrkeCJ0","xWZXcGRUiLk2","67ljcgkHiLk3","v_omVs8UiLk3","Ncx1GZBQiLk3","0LOHOkE9xdCv","eD6QGpeSxdsX","rk4OikW-xeU2","cnV43dJteHqR","gtGJyyjSeLDh","6ktDRmW9eLDi","bilzJKPqFFv4","KtPX5jqvFFv4","VHOu-d4mFFv5","9XIY-dg3xe94","MIAbHfiSeRW6","-UnIC199eTu0","wD-sCss1eTu0","tSJuwja1FbtJ","XFrjLPRuFbtJ","Rq9AHQneFbtJ","uQbr5-T5xfn7","xplJU_J4edVi","hL8NHdNbegT7","kXzTJvjtegT7","uOGX5YP7F0xy","i7yv_uiCF0xy","QGxfERk1F0xz","13waq-LMxgRH","44E1BnPaei-B","7mC3LlvzelXZ","I2GqIyeJelXZ","5QqnRoBOIEGL","Xj3Yc0R8IEGL","1eCSHAfxIEGL","DDGA3alTt3pU","i_eI2ZoSxJe_","X16mTxXffK_b","wVgHwK4UfYJA","RpaicAscfNC7","jLnKa6V5Iv8Y","M9yQbaEpIv8Y","dTrkY4gJfV5I","d_RrnTWQxL6O","Utj2-Q2NgyFt","GHXMhHpqg0wM","I95us34jJUdg","L05L9bDYJUdh","dFm2xgYnJUdh","mFSSpU-1xMmP","BynSXwpLg9zO","9nHJSsnHhFao","4Cu0DZJZt6cO","Hv38SW_nw8BD","On5i5fUMhOeU","b_A60U_IhQge","yT9_8GWRhQge","XeCG3r7EhSLx","bWc02oayhQge","GSIyE96DhQge","9TZbYLomw-o8","8iA1L-94hZA1","aqPwkt33hbt_","EDYqrvZShbt_","VYm5IgxYhbt_","-R5g8KvlhbuA","_KgSKUe4hbuA","kb6IyBCHw_Up","pGmdnHVkhdXj","sVS0pcy1hft8","VhMxOgM0hft9","ix9ZfnJ9hft9","9cM9nS7mhft9","n_C9pgZFhft9","EAsCwV51w_9d","QsZIBBAvnsf-","g-yusDe5nvDQ","-r-Jc-TcnvDQ","JrejIlBPnvDQ","PrD-Y4krnvDR","0VrDGOrYxApN","esSxrbLiercx","rCPk3TM9et6Z","2WZBErKOet6Z","Akkhd_upet6Z","JLDqdIjCet6a","22augeB-et6a","2ZipkIVgxBZu","HYSMP9dpn-tB","sriLOF0ooBlX","PR4Kc_wToBlX","7pKTod5aoBlX","yooWe62SoBlX","DfSiXUjkxCPq","QeojuGrimoql","kLNKRxUFmsSc","UGVrj4BYmsSd","OIj-GWvXmsSd","d5py4f9MmsSd","ZdJd-XprSfiI","h6uiwF3kmsSd","XDI0GotTxC3M","MFjNlPsZmvIs","jCUAt0q4my0_","SfqhU-Ldmy0_","W8MxypZjmy1A","7WA5kFMemy1A","Rhw9HaNQTwMq","FnmE15ChTuRb","ex0CBtFuxDfA","kmb8NRb1maEU","RIDwCnqhanLw","ZCJJal_yanLx","XJRsy7HzanLx","LVevyy4GanLx","5uRQGrbDanLx","lxS0RnaFanLx","6CVTiYZuxEIW","fLTNqkrHnCpg","LUW_YyronGsm","slEmL5avnGsm","YoHi4xo0nGsm","q799kfoNnGsm","uxA4utiVbrkT","Xm9m1d6znGsm","sc7ux4mJxEx6","xIGRfQK3nLQw","ONn2BCLLnPJo","5RHzOFYRnPJp","xsmLHrBLnPJp","LcFSH-_hnPJp","INuvp-9JnPJp","EqImTVlkxFZW","qwiiTPmjTvS0","kke3l7IjdAUG","k1jKXA6Bt81W","d0nord-gw3S5","pqL94JRun3Tq","Gqq8JsbOn539","5MV3qR6hn539","hWhG29E9n539","a7mPARfLn53-","jKX35I7Jw5N8","RxMqiZH8pyeG","PoOV5tlnp0lH","aVxCTjp5p0lI","sb3WhE3ep0lI","YNMF7iVXp0lI","tq5QRhTet_wh","pXb2O1yHwoMQ","F21R87VFoPeS","3I-9fsBXoar3","Y9FMacKEodAQ","iqFUzeRioi8S","vkxoRogLojnS","MXl-gCm2oz1-","WZtHaodUoknI","voSd246TolSV","a2FuIFVNwtfa","E8q4jM9QqDAw","6t5j3xLpqFlN","UwYLu7aSqFlN","8_670JvDqHvq","DPqSqhgNqFlN","j503YP2PqFlN","JhKOUzQuqMWl","3J8EEp3TqOoZ","y76qXnX0rMgD","Zeke5bnqqRqa","5Yrylp9KqTly","-9MvOlXewuKt","iHIaV4hQpRto","u7_3CIZ3pUDO","dzOzEPcJpUDP","94lPTFuPpUDP","n-g2EPNXpUDP","pLjRBfJZpUDP","COoEwrjWpUDP","u_zo6eNIpUDP","oz1-vtGuW9ie","k6N3J91UiNxx","i9aG5n6owu3E","bPJ0X30GpK_w","w_LwY9IPpNoN","saRhnR2hpNoN","4igNvDO4pNoN","QIY6MptipNoN","mdQkE49XpNoN","JYKe6tERpNoN","BVxpa9yIpNoO","tQoT_wHKX-0B","p8pU-Y4q8IeZ","pCc8-ntu8MEE","MsiH4XSr8MEE","1OACxBKw8MEF","cb1FCDPB8ODt","W2uaq6oQ8MEF","-aY8H0Xh8MEF","-L-EGWQskheg","h5Hvi7M8wvit","AZLqa7pnr2ZU","u1YpP6XAr5gp","L_P8HAPcr5gp","z72yIvwwr5gq","qTTzTwu-r5gq","-_e1FPK4r5gq","CpoWisEwr5gq","qiZ90i87r5gq","fiXKvA5hr5gq","TUwPQNeUYLST","Fmur-sdpmGOw","niqFynEzwwOQ","zojSh9fyq2nt","PI6UNFydq5TX","-yfOva8Pq5TX","ellcQWG5q5TY","I3mplLcGq5TY","v6ZSwl7Iq5TY","mhe4LzHUq5TY","JSlswuJWq5TY","igkJQjigq_Y7","wbSsoKcpq5TY","QD4X6YuEq5TY","rvM7Wpnsww6u","YtLdVCu5ZKKE","qePU7APuwxjq","GhFKtDcXqnQm","mSUz5kFRqprH","mdVdJ74cqprH","Sb7WkWtiqprH","VhqtYDc0qprH","YGyvDXpXqprI","iWjcPtkeqprI","n654fSNUqprI","SVM6qmV4qprI","nYcd18JfqprI","4x3D6Q9PuC07","EfWIJUoCwfrp","UPYWJ-9UsO-F","fTSN5VR9sR-4","bScpM6EmsR-4","_Kf6p13AsR-5","36Dozw1YsR-5","WibECzqnsR-5","R3zpxlFWsR-5","zJDNWJmqsR-5","ITeXRA_PsR-5","JRxE3SqAsaGB","pAJK90-lsaGB","3otyfOFhsaGB","MbcxgN90nD5n","O8MO2jkPuGv8","y-cTJrIVwYzj","V_5KbzdSwc24","nP8fhGQjwdix","IyAnfENpweH8","AUtfDiF85Gtz","F7WD1zB3HGvy","acGkZiojHGvz","--cdKFXlHGvz","RhT0JCQeHGv0","1tYTTSvNHGv0","EfGoHK4ZHGv0","GgQe5ajFHGv0","M-Flkbv0HGv0","q2zirMPd5Lxs","LE0aIlbT5Xu6","f1ZI7nD550re","eB9DPtIw50re","QYbJj2zy50re","wjz6TznP50re","9k6fHrcC50rf","2iMEs1bE50rf","_6bD5Dq96M82","OpLI3wHx6Rzh","lnLCFsNn6ZnI","glfsNjwN6uST","pcFHpqA16uST","qkE4VcH56uST","iKfAtdmD6uSU","Rv00SJFT6uSU","3Mm_6qPZ6uSU","UKDqbr6UiQP3","7178G_QCiWbf","w1gBRCH_iWbg","04isx3Z7iWbh","bNNyo57wiWbh","qj54LlgciWbi","tT1a6juHiWbi","-5mwvgJQiWbi","pRnPV_vFiWbi","6bmwYQNoi_eI","d-hCuPabjQXN","bNEYXEiyj1HN","bej13g5sj1HO","gRP-gaVQj1HP","-mjW_QR4j1HP","EntccZkej1HP","8Vzm6a3dj1HQ","AX85uZ7Jj1HQ","v2WLHkHSj1HQ","qhwDdySwj1HR","wY4GRL5euJZ7","FoO4V6F_GM1x","xtwMnzowGM1y","UN4lEZ7sGM1z","yC1fSRFmGM1z","iRI_andIGM1z","aiiSptxEGM1z","xeMEG4-tG15p","lLjWg0gcG15p","hRe591fVwS8F","LCCdGLIqqdoR","L7TphIsUqisx","71J3zWBaFJyi","DB6lD72KFJyi","H4UOLZGYFJyi","rbamwOlpqisy","oChOSumhqisy","6poDWK8hDyih","Vj2tON4ODyii","nEf5TS4vDyii","ErdhZ7RODyij","_EmNhYSNDyij","Dk50RChYDyij","HuhsrQIWDyij","-9YP2ATWDyij","P1X2HUCSJpE9","5dCX2uKaJpE-","c-x_29PsJpE-","NoYipBYrJpE-","YQFiI8OyJpE-","-Tfg_TtsJpE_","hGcpkBgYJpE_","gaVN40yKJpE_","G6VWHz4xFHXN","cqJ6Q7oAFHXO","x-9fhDaWFHXO","vjahmk2wFHXO","rR13omLzFHXP","HsiII_5qFHXP","fL5hwKQuFHXP","rq8L0r23HsB8","6T_sD2yMHsB8","-WeoFqFXHsB8","scwNKaagHsB9","2kg438BtHsB9","c2RmPzFRHsB9","THxXxCu3HsB9","xEcGt67DIrDU","hm9WvAvqIrDU","Elu2MCdEIrDX","TEK6VtsKIrDX","LQ_-QXsAIrDX","r9pB1osjIrDY","HfnZW4EZJeRh","uClncMfcJeRi","bU_XPZ7hKJkp","48KdZYKyKJkp","9KrJpWFuKJkp","wP8-3j-LKJkq","woLw54dvKJkq","z7l3MG8aKJkq","4styVad0KJkq","Ywr_-M-gKJkq","HXVfmfEBuMFH","6kGKyr2RwOQd","tOJJFV5jpmF9","GFJu28DdppQr","GaVZ67uoFq_4","UmyXHHIGFq_4","HKd6FwJ0Fq_5","_WQ1kTDTwRXx","fngy8yFSuPlT","d_IDaDlWvrWe","nbmE-wEtvtQY","TVQp-tZXvugr","p39i1UEjvvrh","fcY7hiaTvwXw","jQFlqSVTvxB_","XQ0QdL8Uvxq5","tlbOxce9uQ8u","OJ2yhyPQvkAd","hZOyDdhjujfO","FtiNR3oKumaC","k_c3Eno3undD","MJC1sTkEupcn","M0_gRvSBuqE3","uqzVpOoouq7J","M23HastE8Z_N","9OJBs_gM8dbw","aYAWEi_W8lub","Mo7l3tMeurgR","ocWsI4rOusGO","hpHmlrj565dm","hGiBeTIP7AmA","wVAX6i_o7KF6","X6HK77Xp7UiG","8pc6jLduIcjp","zUGS5iol7Ox3","XMOfWJnP7VjC","VEey-etc7MK3","o4Y5GpDc7Wuf","WdxY9lfy7Xdi","10XNH3x57YYu","zgINp2kpusrX","r9TVmEZg7fZo","k1s2DgQS7k1R","iMH15MszJGp-","g50lTrz4JGp-","9iB8HTDfJGp-","HCOcYU7v7k1S","rnusImOMI6Ff","PLZMkPRTI6Fg","8kRQu9r-I6Fg","-OmZRHcpI6Fg","ufHTMGa1I6Fh","_d-JGltKxze9","gScnkk-cx6yy","QKAUdFCKx7bX","wIvEuI5_x8D9","o3ocRfYMx8sA","SpWkDSBWx9Ux","SCGpuoobx99h","R1rwTKVSx-l5","gfsyJkWox_Pt","HthWYZeFgVK8","6jOWb3bGx_3b","FBQ9fBMOyAfq","itbW67nnyBHY","Ti4CsTnSyH20","MmIGbrKJyKD3","XXe_kLshfjC9","hhgnD32Dfm6O","Ni2x9oC6fvWk","69R-4-7Yf0py","fSoTUY4Af1RY","3B-FvVPA9Dwq","29uptjQrf15g","uMCRcAZyyMGD","pebkHEtByUvz","mKmWyKWIyW4H","PegYo9EWniL_","YINgQ8zznl_r","ZX1bGnannl_r","2tsug47Unl_r","Fb0a9Titnl_r","VNnMyNoxnl_r","fd0qCFxGyXcY","03raJE0QymCK","WHtDs86Ayo5z","FFqHHmB41IUC","-SOEQlr31NGP","45usPcE91ZtO","WH4ErGqb1axo","6GMbzp0S1eFl","45m8gTwi1hrE","fO6oU0Ps1lJA","ADl3NayWjt6O","nNasFXn6j5uY","MgX_4Hyj1mJL","50MWcIiX1pMh","eff3igVRf_vf","0ec2c8VPgB-H","--mmqTo9gFMJ","0hwMD5vD1r88","FnNnBc1K1uck","Fi2qfb5Wgciu","x1ZYeMlpgfoG","nsHphvCpOHVD","ThIIv1Q11yJ_","HLWOseNkgopM","PTRrzynxgrXu","eoJiqIe9OdWV","Xwt1NXfh11h5","EbsoVXzB15ZI"],"toc_visible":true},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":3004,"databundleVersionId":861823,"sourceType":"competition"},{"sourceId":3136,"databundleVersionId":26502,"sourceType":"competition"}],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nfrom numpy import array\nfrom keras.datasets import mnist","metadata":{"id":"2YiQnOxA3mKc"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<a id=\"data-science-coding-skills\"></a>\n\n<div style=\"background-color: #e3f2fd; font-size:150%; text-align:left; border: 7px solid #0288d1; text-shadow: 2px 2px 4px rgba(0, 0, 0, 0.3); font-family: Calibri; border-radius: 20px; padding: 10px; width:95%\">\n<h1 align=\"center\"><font color=#0277bd><strong>ESSENTIAL CODING SKILLS FOR DATA SCIENCE, MACHINE LEARNING, & KAGGLE</strong></font></h1>\n<h2 align=\"center\"><font color=#0277bd><strong>Your Guide to Mastering Key Libraries</strong></font></h2>\n<p style=\"font-family: Calibri; color: #0277bd; text-shadow: 2px 2px 4px rgba(0, 0, 0, 0.3); text-align: left; font-size: 110%\">\n    Whether you're just starting out in data science or have some experience, this notebook is designed to help you. For beginners, it serves as an excellent reference, introducing the <strong>key libraries</strong> needed for data analysis, machine learning, and Kaggle competitions. Even if you're not a beginner, the comprehensive overview of libraries such as:\n    <br><br>\n    1. <strong>NumPy</strong> and <strong>Pandas</strong>: For numerical computations and data manipulation.\n    <br>\n    2. <strong>Seaborn (sns)</strong>: For data visualization to enhance analysis.\n    <br>\n    3. <strong>Scikit-learn (sklearn)</strong>: A comprehensive machine learning toolkit covering preprocessing, feature extraction, selection, model training (e.g., SVM, tree-based models), clustering, and model evaluation (metrics).\n    <br>\n    4. <strong>SciPy</strong>: For advanced statistical analysis and sparse matrices, crucial in data analysis workflows.\n    <br>\n    5. <strong>Imbalanced-learn</strong>: For handling imbalanced datasets through under-sampling and over-sampling techniques.\n    <br><br>\n    makes this notebook a useful resource for more experienced practitioners as well. Together, these tools form the foundation for effective data processing, visualization, model building, and evaluation.\n    <br><br>\n    If you found this notebook helpful and appreciate the effort put into it, please consider <strong>upvoting</strong>! Your support motivates me to create more content.\n</p>\n</div>\n","metadata":{}},{"cell_type":"markdown","source":"## numpy","metadata":{"id":"jUuRP2Ii16x7"}},{"cell_type":"markdown","source":"### [array](https://numpy.org/doc/1.23/reference/generated/numpy.array.html)\n\n*Create an array.*","metadata":{"id":"ccMgG8SF19RQ"}},{"cell_type":"markdown","source":"#### Examples","metadata":{"id":"hvVvaY-vLTRu"}},{"cell_type":"code","source":"np.array([1, 2, 3])","metadata":{"id":"2fDe5sHWPrO4","outputId":"5165b5c0-1d92-46d2-b629-d1251723ff3c"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Upcasting","metadata":{"id":"-5y0IhGhP0YM"}},{"cell_type":"code","source":"np.array([1, 2, 3.0])","metadata":{"id":"a2A8ymFrP4EK","outputId":"0a3fa157-96b0-4b08-e4c8-adb8a7b35f88"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"More than one dimension:","metadata":{"id":"9zs2naB9P8Jx"}},{"cell_type":"code","source":"np.array([[1, 2], [3, 4]])","metadata":{"id":"w2vj_aEYP68x","outputId":"5b701182-83bb-4fa4-c5c1-f77c3111076a"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Minimum dimensions 2:","metadata":{"id":"2NPs7PS_QA3E"}},{"cell_type":"code","source":"np.array([1, 2, 3], ndmin=2)","metadata":{"id":"vyJcU8USQC5a","outputId":"dcc9d83b-a17b-42dd-e101-0bde6b74f0f4"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Type provided:","metadata":{"id":"jBlOtI6yQEyQ"}},{"cell_type":"code","source":"np.array([1, 2, 3], dtype='float64')","metadata":{"id":"Tnw9BwMTQGoa","outputId":"b227e0ff-cfab-4db0-9a72-38e27fee80b4"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### Methods","metadata":{"id":"boldIgOoKagL"}},{"cell_type":"markdown","source":"##### [shape()](https://numpy.org/doc/1.23/reference/generated/numpy.ndarray.shape.html)\n\n*Tuple of array dimensions.*","metadata":{"id":"qACciUk4J5Sm"}},{"cell_type":"code","source":"x = np.array([1, 2, 3, 4])\nx.shape","metadata":{"id":"OotBqouHMO43","outputId":"8c29a5de-b6b5-401f-9334-b6ac83afe4cd"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"y = np.zeros((2, 3, 4))\ny.shape","metadata":{"id":"uM1DXXKoMQU-","outputId":"fd8f2d2e-b743-4a25-8aa1-a021d518042e"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"y.shape = (3, 8) # similar to reshape\ny","metadata":{"id":"nKHtw1p4MRbl","outputId":"a047d160-cdf0-4f28-e1ef-43596ace81ca"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"try:\n  y.shape = (3, 6) # cannot reshape since there're 24 elements.\nexcept ValueError:\n  print(\"Exception!\")","metadata":{"id":"_37lfyXvMXjZ","outputId":"d53610d7-7f03-44ee-9183-b48e0cc3a1f6"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"##### [reshape()](https://numpy.org/doc/1.23/reference/generated/numpy.ndarray.reshape.html)\n\n*Returns an array containing the same data with a new shape.*\n","metadata":{"id":"9oXAtrYpJ_Op"}},{"cell_type":"code","source":"y = np.zeros((2, 3, 4))\ny.reshape(3, 8)","metadata":{"id":"lym-NxY3N4Lo","outputId":"a31a7754-d1fc-49ca-fb69-6897056eee41"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"y.reshape((3, 8)) #also works","metadata":{"id":"2z2s4bJwN-Nj","outputId":"c313593b-84c8-4e54-f5d3-542dc40662d8"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"[transpose()](https://numpy.org/doc/1.23/reference/generated/numpy.ndarray.transpose.html)\n\n*Returns a view of the array with axes transposed*","metadata":{"id":"1ijZ5j17J_6Q"}},{"cell_type":"code","source":"a = np.array([[1, 2], [3, 4]])\na","metadata":{"id":"2CZlTha9ORpK","outputId":"0bfd6fa7-5b20-407d-8b3b-91c2e4052dfb"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"a.transpose()","metadata":{"id":"pqo_D8g2OS4s","outputId":"7d544d6c-a0e2-4467-90e5-ebc45f1fde76"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"a.transpose((1, 0)) # interchanges axes 1 and 0.","metadata":{"id":"ISXf7SrkOYlM","outputId":"dcda64bd-5007-4119-ed67-d275875bec6c"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"a.transpose(1, 0) # also works","metadata":{"id":"7JT_OE9ZOZVF","outputId":"a0909038-df7a-4459-9d15-3966e7b49225"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"a = np.arange(12).reshape(2,3,2)\na.transpose(0,2,1)","metadata":{"id":"6tfnXUuxRPdM","outputId":"926fd785-ed2c-46da-a983-5f13a30c19bd"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"The property T is an accessor to this method","metadata":{"id":"GBv3262ZPDfg"}},{"cell_type":"markdown","source":"##### [mean()](https://numpy.org/doc/1.23/reference/generated/numpy.ndarray.mean.html), [var()](https://numpy.org/doc/1.23/reference/generated/numpy.ndarray.var.html), [std()](https://numpy.org/doc/1.23/reference/generated/numpy.ndarray.std.html)\n\n*Returns the average, variance and std. deviation respectively of the array elements along given axis.*","metadata":{"id":"6JZEKc6rKAjS"}},{"cell_type":"markdown","source":"##### [ravel()](https://numpy.org/doc/1.23/reference/generated/numpy.ndarray.ravel.html)\n\n*Return a flattened array.*","metadata":{"id":"vlB-K3YwKBFi"}},{"cell_type":"code","source":"x = np.array([[1, 2, 3], [4, 5, 6]])\nnp.ravel(x)","metadata":{"id":"dka3__DPPm9s","outputId":"e59e4009-b3bb-4b3e-8a8f-621498d24754"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"np.arange(12).reshape(2,3,2).transpose(0,2,1).ravel()","metadata":{"id":"U6RLq39PP4aZ","outputId":"6355c054-1b37-467b-e582-a8d5e0a1eb52"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### [arange](https://numpy.org/doc/1.23/reference/generated/numpy.arange.html)\n\n*Return evenly spaced values within a given interval.*","metadata":{"id":"jY6Umk2l2Bte"}},{"cell_type":"code","source":"np.arange(3)","metadata":{"id":"R1z1p-shRgcU","outputId":"bfaf37fb-7cfc-457a-845e-8c2414cfefae"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"np.arange(3.0)","metadata":{"id":"esQPQVmlReZl","outputId":"d0c014ac-fe46-409c-94dc-65ea3fe3ff0b"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"np.arange(3,7)","metadata":{"id":"ah6rjQ82RfW1","outputId":"bf04a1a2-2568-4ac0-a3bb-512aaf91af86"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"np.arange(3,7,2)","metadata":{"id":"qFzq-LQzRjgd","outputId":"027a0355-657f-4481-81b2-34858ae6c9be"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"np.arange(-3, 3, 0.5)","metadata":{"id":"Y2cy3CM1RVrq","outputId":"4dcdebb5-7ff6-4073-cb9a-eb5d8e1e9a7d"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### [linspace](https://numpy.org/doc/1.23/reference/generated/numpy.linspace.html)\n\n*Returns num evenly spaced samples, calculated over the interval [start, stop].*\n","metadata":{"id":"DZyEL9iL2C0r"}},{"cell_type":"code","source":"np.linspace(2.0, 3.0, num=5)","metadata":{"id":"HipmwxCLSAiX","outputId":"5a599270-ade7-415e-d978-63ec03347e30"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"np.linspace(2.0, 3.0, num=5, endpoint=False)","metadata":{"id":"PZqkaiElSKzl","outputId":"b14c597a-5b73-4a53-b3cf-c95b14f0c26c"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"np.linspace(2.0, 3.0, num=5, retstep=True)","metadata":{"id":"zDJdVy10SLKb","outputId":"19a13d3c-85c7-41f9-acdb-53c143058ed7"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Graphical illustration","metadata":{"id":"BoO0MqR0SYkS"}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nN = 8\ny = np.zeros(N)\nx1 = np.linspace(0, 10, N, endpoint=True)\nx2 = np.linspace(0, 10, N, endpoint=False)\nplt.plot(x1, y, 'o')\n\nplt.plot(x2, y + 0.5, 'o')\n\nplt.ylim([-0.5, 1])\nplt.show()","metadata":{"id":"tNKbFqxiSXox","outputId":"79735064-4b43-4614-b9b1-f3631f1321c1"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### [logspace](https://numpy.org/doc/1.23/reference/generated/numpy.logspace.html)\n\n*Return numbers spaced evenly on a log scale.*","metadata":{"id":"aD0EtkiFR5nC"}},{"cell_type":"code","source":"np.logspace(2.0, 3.0, num=4)","metadata":{"id":"zNZITYeCTaZx","outputId":"45577ded-97c9-40c4-e22e-62a2a826812f"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"np.logspace(2.0, 3.0, num=4, endpoint=False)","metadata":{"id":"g4nSmpWoTcox","outputId":"d411e5ce-9075-47b0-d109-985e716ff23e"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"np.logspace(2.0, 3.0, num=4, base=2.0)","metadata":{"id":"l8P336DXTc-k","outputId":"75f0b5b8-3e03-4e5d-b12b-06c32672def6"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Graphical illustration","metadata":{"id":"ew8S0EhwTg6Q"}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nN = 10\nx1 = np.logspace(0.1, 1, N, endpoint=True)\nx2 = np.logspace(0.1, 1, N, endpoint=False)\ny = np.zeros(N)\n\nplt.plot(x1, y, 'o')\n\nplt.plot(x2, y + 0.5, 'o')\n\nplt.ylim([-0.5, 1])\nplt.show()","metadata":{"id":"nKbzNEEUTf1L","outputId":"cf4b0fa1-72e8-422f-dfc4-e0b5252292a6"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### [unique](https://numpy.org/doc/1.23/reference/generated/numpy.unique.html)\n\n*Returns the sorted unique elements of an array. There are three optional outputs in addition to the unique elements:*\n\n*-the indices of the input array that give the unique values*\n\n*-the indices of the unique array that reconstruct the input array*\n\n*-the number of times each unique value comes up in the input array*","metadata":{"id":"b6_iGKa42EP4"}},{"cell_type":"code","source":"np.unique([1, 1, 2, 2, 3, 3])","metadata":{"id":"fG1FRaCTXksC","outputId":"532cabc5-74f0-4b46-a3ba-7826f35ffb57"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"a = np.array([[1, 1], [2, 3]])\nnp.unique(a)","metadata":{"id":"5u5gH-9FXnJv","outputId":"d97faaad-d109-441a-b55e-b7177ec28460"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Return the unique rows of a 2D array","metadata":{"id":"yF1bL9J7Xset"}},{"cell_type":"code","source":"a = np.array([[1, 0, 0], [1, 0, 0], [2, 3, 4]])\nnp.unique(a, axis=0)","metadata":{"id":"fia0cpcJXr0l","outputId":"0b2a3134-94c0-4b76-d9f9-a0ebd7cf0856"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Return the indices of the original array that give the unique values:","metadata":{"id":"N9l_p3XNXz6v"}},{"cell_type":"code","source":"a = np.array(['a', 'b', 'b', 'c', 'a'])\nu, indices = np.unique(a, return_index=True)\nprint(u)\nprint(indices)","metadata":{"id":"Gg9Y2Fh1X6VY","outputId":"31c4685d-f8a9-422b-82ce-acfc477b7001"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"a[indices]","metadata":{"id":"tq6Ji9GRYGdM","outputId":"3f39dcce-7657-42e2-dab7-72babad3da6b"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Reconstruct the input values from the unique values and counts:","metadata":{"id":"vQwGVMl-YJeo"}},{"cell_type":"code","source":"a = np.array([1, 2, 6, 4, 2, 3, 2])\nvalues, counts = np.unique(a, return_counts=True)\nprint(values)\nprint(counts)","metadata":{"id":"xckwkHq6YLwT","outputId":"97b60532-b865-4fab-b780-09b52f62d050"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"np.repeat(values, counts)  # original order not preserved","metadata":{"id":"nTjsXABWYTuQ","outputId":"3dbe22d0-60f1-461b-b6de-3e7b4167b7a3"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### [zeros](https://numpy.org/doc/1.23/reference/generated/numpy.zeros.html), [ones](https://numpy.org/doc/1.23/reference/generated/numpy.ones.html)\n\n*Return a new array of given shape and type, filled with zeros and ones respectively*\n","metadata":{"id":"83AFzi9m2E3e"}},{"cell_type":"code","source":"np.zeros((5,), dtype=int)","metadata":{"id":"ZTt1CnG4Y4pL","outputId":"eed947b6-35d5-4ed4-d66a-040e53e1f2f5"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"np.ones((5,), dtype=int)","metadata":{"id":"udc5eaAcZSoC","outputId":"71b01908-d434-4459-c849-ce91acce4226"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"np.zeros((2,2))","metadata":{"id":"BTzRabM1Y-Xh","outputId":"38d01271-62e4-4880-a49f-90d90374a7f0"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"np.ones((2,2))","metadata":{"id":"fg76DN31ZV7h","outputId":"6d22d7f2-7729-437a-f305-c17bf78f4766"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"np.zeros((2,), dtype=[('x', 'i4'), ('y', 'i4')]) # custom dtype","metadata":{"id":"xYGxSgGXZDCS","outputId":"cf1d270c-a0d8-4db2-ce27-4098ae0db344"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### [where](https://numpy.org/doc/1.23/reference/generated/numpy.where.html)\n\n*Return elements chosen from x or y depending on condition.*\n\n*When only condition is provided, this function returns indices that match the condition.  In other words, it works is a shorthand for np.asarray(condition).nonzero()*","metadata":{"id":"tOCzgd3p2Fbo"}},{"cell_type":"code","source":"a = np.arange(10)\n\nnp.where(a < 5, a, 10*a)","metadata":{"id":"OpS78hFPZk1o","outputId":"8944ffc7-8dc5-45bd-cd29-c91004e23f32"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"This can be used on multidimensional arrays too:","metadata":{"id":"WtMJPKkZZsoz"}},{"cell_type":"code","source":"np.where([[True, False], [True, True]],\n         [[1, 2], [3, 4]],\n         [[9, 8], [7, 6]])","metadata":{"id":"HJ_mxCuVZxYO","outputId":"da693ac2-3c14-47a8-c477-e06be83b863a"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"The shapes of x, y, and the condition are broadcast together:","metadata":{"id":"NC1iYYhLaFJz"}},{"cell_type":"code","source":"x, y = np.ogrid[:3, :4]","metadata":{"id":"NgpZZFE2aEN_"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"np.where(x < y, x, 10 + y)  # both x and 10+y are broadcast","metadata":{"id":"7lUlE5W9aPGQ","outputId":"c7458ccf-0f60-44e9-d6dd-0c1d506cc1d0"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"A simple *where* clause yields an tuple of lists; from each list, pick up an index to make co-ordinates.  In this case, following coordinates can be created (0, 0) (0, 1), (0, 2)...(2,1)","metadata":{"id":"UBAedeylS4sx"}},{"cell_type":"code","source":"a = np.array([[0, 1, 2],\n              [0, 2, 4],\n              [0, 3, 6]])\n\nnp.where(a < 4)","metadata":{"id":"HbVZkL-5_E69","outputId":"e8f18baa-f4ba-4f4d-b5ae-947dcf1fd0be"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"np.where(a < 4, a, -1)  # -1 is broadcast","metadata":{"id":"tvlPJYm-SGZp","outputId":"51fb87f0-33fd-43ef-ca45-236bcad9649a"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"When only condition is provided","metadata":{"id":"h4chz5rqRrIi"}},{"cell_type":"code","source":"a = np.array([[0, 1, 2],\n              [0, 2, 4],\n              [0, 3, 6]])\nnp.where(a < 4)","metadata":{"id":"IUrOSrdtQuI5","outputId":"57b94ef4-4bc3-4715-8759-4fa91cf52310"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### [argmax](https://numpy.org/doc/1.23/reference/generated/numpy.argmax.html)\n\n*Returns the indices of the maximum values along an axis.*","metadata":{"id":"-kGnSxf12Ghl"}},{"cell_type":"code","source":"a = np.arange(6).reshape(2,3) + 10","metadata":{"id":"TNd-BelW_xMi"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"np.argmax(a)\n","metadata":{"id":"udWJtchm_4QC","outputId":"154e7c67-23aa-4bc7-ed9a-1b0c0f95bcf3"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"np.argmax(a, axis=0)\n","metadata":{"id":"JtDBzFO2_-ir","outputId":"a4a8d2b2-1ff6-46df-e1c7-0ad8383ad776"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"np.argmax(a, axis=1)","metadata":{"id":"T2XrnbOmAAcy","outputId":"d229b571-e0e9-492d-8219-9e99242d28ca"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Indexes of the maximal elements of a N-dimensional array\nind = np.unravel_index(np.argmax(a, axis=None), a.shape)\nind","metadata":{"id":"VZDduZVhAabs","outputId":"a8db5eb6-667a-4b14-8f58-c67044ec5b8f"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"a[ind]","metadata":{"id":"lpwZJEzDDycV","outputId":"45973657-86e3-4e4c-e2dc-e6fdbe5700c7"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"b = np.arange(6)\nb[1] = 5\nnp.argmax(b)  # Only the first occurrence is returned.","metadata":{"id":"lPezvGDPArDh","outputId":"f5014aa1-24b1-40d6-db69-f04e87234a9b"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"x = np.array([[4,2,3], [1,0,3]])\nindex_array = np.argmax(x, axis=-1)\n# Same as np.amax(x, axis=-1, keepdims=True)\nnp.take_along_axis(x, np.expand_dims(index_array, axis=-1), axis=-1)","metadata":{"id":"NDez0DeOC8dg","outputId":"92a29dbc-de66-4119-e16a-5212aab796c4"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"np.take_along_axis(x, np.expand_dims(index_array, axis=-1), axis=-1).squeeze(axis=-1)","metadata":{"id":"Ih0nGLiBDVhw","outputId":"6ef9ad0b-0aba-4e07-fa6a-ca5ab13d2a08"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Setting keepdims to True,\nx = np.arange(24).reshape((2, 3, 4))\nres = np.argmax(x, axis=1)\nres.shape","metadata":{"id":"dnaWE0ACB6Pr","outputId":"5ec7346c-0e8e-408a-9272-6fb3ee237f9e"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### [argmin](https://numpy.org/doc/1.23/reference/generated/numpy.argmin.html)\n\n*Returns the indices of the minimum values along an axis.*","metadata":{"id":"_i3XrCH8_hwv"}},{"cell_type":"code","source":"a = np.arange(6).reshape(2,3) + 10","metadata":{"id":"mjlDdce9D7DJ"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"np.argmin(a)","metadata":{"id":"20-sLo27EAvx","outputId":"d7a3ab1e-ab48-49da-892a-e85bf3171132"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"np.argmin(a, axis=0)","metadata":{"id":"ynu8e2wJEBaO","outputId":"fb10984f-6af5-4b2e-bd83-6a118618467b"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"np.argmin(a, axis=1)","metadata":{"id":"PSbGAbPvECk3","outputId":"6e83e7d6-8e06-4bb2-ba1d-e896804bf110"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"ind = np.unravel_index(np.argmin(a, axis=None), a.shape)\nind","metadata":{"id":"CkqvIzz7EJud","outputId":"70b04dec-f63a-4ad3-9991-3cee584be2fd"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"a[ind]","metadata":{"id":"8qm8-ChhEK1k","outputId":"5c234fe3-1fc5-47bf-dc87-2ca529290287"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"b = np.arange(6) + 10\nb[4] = 10\nnp.argmin(b)  # Only the first occurrence is returned.","metadata":{"id":"bhaaeXqxEVKM","outputId":"5059acb4-c135-49be-df72-78a718de3004"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"x = np.array([[4,2,3], [1,0,3]])\nindex_array = np.argmin(x, axis=-1)\n# Same as np.amin(x, axis=-1, keepdims=True)\nnp.take_along_axis(x, np.expand_dims(index_array, axis=-1), axis=-1)","metadata":{"id":"7oNiTb6jEW1Z","outputId":"705c863f-f2e4-47f7-8f5a-efb44634f9d8"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Same as np.amax(x, axis=-1)\nnp.take_along_axis(x, np.expand_dims(index_array, axis=-1), axis=-1).squeeze(axis=-1)","metadata":{"id":"4UbEVa7XEfcD","outputId":"bfb1d641-93f5-4025-b059-98dae768cc59"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### [argsort](https://numpy.org/doc/1.23/reference/generated/numpy.argsort.html)\n\n*Returns the indices that would sort an array.*\n\n*Perform an indirect sort along the given axis using the algorithm specified by the kind keyword. It returns an array of indices of the same shape as a that index data along the given axis in sorted order.*","metadata":{"id":"w1eigXCj2HLt"}},{"cell_type":"markdown","source":"One dimensional array","metadata":{"id":"3fKUl8J6FDCa"}},{"cell_type":"code","source":"x = np.array([3, 1, 2])\nnp.argsort(x)","metadata":{"id":"wrSVB9ImEvI5","outputId":"0148632c-ffc2-4820-c7ed-384636ac2f2c"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Two dimensional array","metadata":{"id":"FzFaGM1lE-cp"}},{"cell_type":"code","source":"x = np.array([[0, 3], [2, 2]])\nind = np.argsort(x, axis=0)  # sorts along first axis (down)\nind","metadata":{"id":"EXVdQ-NqE0oP","outputId":"9720fa30-2e1e-49f7-f757-c72094aa361e"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"np.take_along_axis(x, ind, axis=0)  # same as np.sort(x, axis=0)","metadata":{"id":"DrR-NdpKE78W","outputId":"92f6fb55-75aa-4b1e-ddf5-7830b235f260"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"ind = np.argsort(x, axis=1)  # sorts along last axis (across)\nind","metadata":{"id":"w1ZuLCZbFIwF","outputId":"5f0b2e95-a01a-4ef6-f1c5-69eaa589c13c"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"np.take_along_axis(x, ind, axis=1)  # same as np.sort(x, axis=1)","metadata":{"id":"Yc4rVstSFLvN","outputId":"bd273fb1-48f7-49e5-c739-d423b233ee9d"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Indices of the sorted elements of a N-dimensional array:","metadata":{"id":"w4x81gRtFQHB"}},{"cell_type":"code","source":"ind = np.unravel_index(np.argsort(x, axis=None), x.shape)\nind","metadata":{"id":"WfsVFFSaFR7W","outputId":"25a9f4c0-1420-49bd-8641-fe8d92ce4412"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"x[ind]  # same as np.sort(x, axis=None)","metadata":{"id":"R35KigdkFTYU","outputId":"403ddec5-7d87-498a-c9f4-0616452b38a8"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Sorting with keys:","metadata":{"id":"IvmH0oRHFXO6"}},{"cell_type":"code","source":"x = np.array([(1, 0), (0, 1)], dtype=[('x', '<i4'), ('y', '<i4')])\nx","metadata":{"id":"xBe-ToGJFX7i","outputId":"0b0a699b-75ba-402e-c735-64ff8c561b4f"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"np.argsort(x, order=('x','y'))","metadata":{"id":"qMznEFL3FbW9","outputId":"23eac54f-4615-42ed-ef62-3435805e99fa"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"np.argsort(x, order=('y','x'))","metadata":{"id":"ab-2J8r5FdA2","outputId":"11b067f2-7108-4fa1-a38c-ac3e1592df09"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### [random.seed](https://numpy.org/doc/1.23/reference/random/generated/numpy.random.seed.html)\n\n*Reseed a legacy MT19937 BitGenerator*","metadata":{"id":"RgYdHsrj2Hxg"}},{"cell_type":"markdown","source":"Legacy function","metadata":{"id":"a4WXK9wvGuK6"}},{"cell_type":"code","source":"from numpy.random import MT19937\nfrom numpy.random import RandomState, SeedSequence\nrs = RandomState(MT19937(SeedSequence(123456789)))","metadata":{"id":"mk2vRcePGNVr"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Later, you want to restart the stream\nrs = RandomState(MT19937(SeedSequence(987654321)))","metadata":{"id":"YPvUItvaGTnn"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"rs.choice(100)","metadata":{"id":"yp696dmvGe8_","outputId":"4adbea28-da8f-4e01-99db-094b07f2d094"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### [random.permutation](https://numpy.org/doc/1.23/reference/random/generated/numpy.random.permutation.html)\n\n*Randomly permute a sequence, or return a permuted range.*\n\n*If x is a multi-dimensional array, it is only shuffled along its first index.*\n","metadata":{"id":"6uJSarCh2Is1"}},{"cell_type":"code","source":"np.random.permutation(10)","metadata":{"id":"HnEBzzeuG3jT","outputId":"2ccbd349-8389-4b09-b53a-5c58c168b82a"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"np.random.permutation([1, 4, 9, 12, 15])","metadata":{"id":"HfUhYdWHHVOa","outputId":"f4e2f4df-6bdc-4b33-9297-df86e82b9549"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"arr = np.arange(9).reshape((3, 3))\nnp.random.permutation(arr)","metadata":{"id":"xsqJ-sxFHbul","outputId":"2bac84ea-f06d-4e0f-b377-309a4aa24c33"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### [count_nonzero](https://numpy.org/doc/1.23/reference/generated/numpy.count_nonzero.html)\n\n*Counts the number of non-zero values in the array a.*","metadata":{"id":"IRh_A_sD2JQa"}},{"cell_type":"code","source":"np.count_nonzero(np.eye(4))\n","metadata":{"id":"NrGN9QD3PN4_","outputId":"358e9a61-85b6-4877-ace9-b4da4324658d"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"a = np.array([[0, 1, 7, 0],\n              [3, 0, 2, 19]])\nnp.count_nonzero(a)","metadata":{"id":"ZDLj2BrvPP75","outputId":"ce0c7cc3-1c07-4d05-f9fc-95311b72c7c8"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"np.count_nonzero(a, axis=0)","metadata":{"id":"vpOeZYcRPQ3d","outputId":"a342de08-82e3-4fe7-d800-0f6363ebcace"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"np.count_nonzero(a, axis=1)","metadata":{"id":"qxlbAY0DPSE1","outputId":"9fce5e72-8175-4f5e-b14d-a79177d31071"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"np.count_nonzero(a, axis=1, keepdims=True)","metadata":{"id":"2quyMlYcPSpL","outputId":"e17d8933-804f-4411-fc94-6ee51a1b1ce1"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### [var](https://numpy.org/doc/1.23/reference/generated/numpy.var.html), [std](https://numpy.org/doc/1.23/reference/generated/numpy.std.html)\n\n*Compute the variance and std. deviation (respectively) on a flattened array (by default) or along the specified axis.*","metadata":{"id":"k7dHOAnn2J1p"}},{"cell_type":"code","source":"a = np.array([[1, 2], [3, 4]])\nnp.var(a)","metadata":{"id":"wGixeh8CP-ST","outputId":"d4f19f5f-198e-4d7f-fc2f-a3bd9ecca4ee"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"np.var(a, axis=0)","metadata":{"id":"eDFwMTqeP_2P","outputId":"910f556f-b447-47d4-a5ae-ac4c68200a7c"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"np.var(a, axis=1)","metadata":{"id":"qzekwSRlQA4f","outputId":"6a3be401-b404-4d74-c944-b9f9ae48b715"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"a = np.zeros((2, 512*512), dtype=np.float32)\na[0, :] = 1.0\na[1, :] = 0.1\nnp.var(a)","metadata":{"id":"V-bYpvROQG9g","outputId":"b25f0ede-32f0-4dc8-843b-45f3b94c7aac"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"np.var(a, dtype=np.float64) # variance is more accurate in float","metadata":{"id":"XU83A9YKQXJ6","outputId":"fc42b5ad-e18e-43a5-ddfb-d9bd632cda63"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Specifying a where argument:","metadata":{"id":"LPihDRxeQczc"}},{"cell_type":"code","source":"a = np.array([[14, 8, 11, 10], [7, 9, 10, 11], [10, 15, 5, 10]])\nnp.var(a)","metadata":{"id":"fGgRtJtOQe4v","outputId":"ab7452f8-a73b-4906-da20-2583a90ae35b"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"np.var(a, where=[[True], [True], [False]]) # only first two rows","metadata":{"id":"WAprYgejQgJ7","outputId":"2f052422-4003-429c-ac7e-ed261fee8720"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"np.var(a, where=[True, True, False, False]) # only first two columns","metadata":{"id":"_J6MM5CGTQ_D","outputId":"41c82886-f727-4c93-bbdf-c79edcc1dd9e"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### [row_stack](https://numpy.org/doc/1.23/reference/generated/numpy.row_stack.html) (vstack)\n\n*Stack arrays in sequence vertically (row wise).*  \n\n*The functions concatenate, stack and block provide more general stacking and concatenation operations.*","metadata":{"id":"97I_gcqE2KYt"}},{"cell_type":"code","source":"a = np.array([1, 2, 3])\nb = np.array([4, 5, 6])\nnp.vstack((a,b))","metadata":{"id":"LuIYbY8iVMhH","outputId":"eedc6095-de91-4883-e079-c497616270f7"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"a = np.array([[1], [2], [3]])\nb = np.array([[4], [5], [6]])\nnp.vstack((a,b))","metadata":{"id":"-MKOmqM9VPGD","outputId":"0263ccb2-54bd-46d7-c2bf-0e2015648e92"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### [column_stack](https://numpy.org/doc/1.23/reference/generated/numpy.column_stack.html) (hstack)\n\n*Stack arrays in sequence horizontally (column wise).*  \n\n*The functions concatenate, stack and block provide more general stacking and concatenation operations.*","metadata":{"id":"DUPVplCSUJ0D"}},{"cell_type":"code","source":"a = np.array([1,2,3])\nb = np.array([2,3,4])\nnp.column_stack((a,b))","metadata":{"id":"kq_pFbM2VV4Q","outputId":"e0bced36-6bc8-40ac-f94e-4e4f30b2ea26"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## pandas","metadata":{"id":"1_s2_Xva2mxx"}},{"cell_type":"markdown","source":"#### Functions","metadata":{"id":"FOmUtPl83cz1"}},{"cell_type":"markdown","source":"##### [cut()](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.cut.html)\n\n*Bin values into discrete intervals.*","metadata":{"id":"hX2Dbjzw3cz1"}},{"cell_type":"code","source":"pd.cut(np.array([1, 7, 5, 4, 6, 3]), 3) # which bin does each data belong to?","metadata":{"outputId":"e53b1a55-8463-44f8-979e-7434d49f482f","id":"d4YpS-hZ3cz1"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pd.cut(np.array([1, 7, 5, 4, 6, 3]), 3, retbins=True) # also returns the bins","metadata":{"outputId":"e82b5876-58a5-423e-8288-e369dcefe049","id":"bcS1NUYc3cz1"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# assigns data specific labels, and ordered.\npd.cut(np.array([1, 7, 5, 4, 6, 3]),\n       3, labels=[\"bad\", \"medium\", \"good\"])","metadata":{"outputId":"30df6d4e-5dc6-4373-8a70-cdee7e5dd2c8","id":"idgt9vWU3cz2"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Passing a Series as an input returns a Series with categorical dtype:\ns = pd.Series(np.array([2, 4, 6, 8, 10]),\n              index=['a', 'b', 'c', 'd', 'e'])\npd.cut(s, 3)","metadata":{"outputId":"0f946058-6ccd-49c4-dc68-7e260d86dbb1","id":"80FIr4m43cz2"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### [DataFrame](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.html)\n\n*Two-dimensional, size-mutable, potentially heterogeneous tabular data.*\n\n*Data structure also contains labeled axes (rows and columns). Arithmetic operations align on both row and column labels. Can be thought of as a dict-like container for Series objects. The primary pandas data structure.*","metadata":{"id":"_AQkurTK2qJh"}},{"cell_type":"markdown","source":"#### Examples","metadata":{"id":"j6hR5B8_ZlL9"}},{"cell_type":"code","source":"d = {'col1': [1, 2], 'col2': [3, 4]}\ndf = pd.DataFrame(data=d)\ndf","metadata":{"id":"waLBXPwkWLka","outputId":"d54ba59e-a9ac-45dd-9eb2-fa8c51b48cee"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Notice that the inferred dtype is int64.\ndf.dtypes","metadata":{"id":"ZQRwGSRHXoKR","outputId":"a90ca159-0347-47e2-d41b-039591ad0ef1"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# To enforce a single dtype:\ndf = pd.DataFrame(data=d, dtype=np.int8)\ndf.dtypes","metadata":{"id":"l_v6eVS8Xssy","outputId":"3e577eaa-2d38-4bf5-b1b6-2137417183f0"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Constructing DataFrame from a dictionary including Series:\nd = {'col1': [0, 1, 2, 3], 'col2': pd.Series([2, 3], index=[2, 3])}\npd.DataFrame(data=d, index=[0, 1, 2, 3])","metadata":{"id":"FwmeiD8BXyDp","outputId":"944d6941-73ce-40d2-e17e-d82da11c97b3"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Constructing DataFrame from numpy ndarray:\ndf2 = pd.DataFrame(np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]]),\n                   columns=['a', 'b', 'c'])\ndf2","metadata":{"id":"j2Jktco1X8d4","outputId":"0fe90a88-0169-4618-ebad-44e1a3602b70"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Constructing DataFrame from a numpy ndarray that has labeled columns:\ndata = np.array([(1, 2, 3), (4, 5, 6), (7, 8, 9)],\n                dtype=[(\"a\", \"i4\"), (\"b\", \"i4\"), (\"c\", \"i4\")])\ndf3 = pd.DataFrame(data, columns=['c', 'a'])\ndf3","metadata":{"id":"16ky-QqwYBbG","outputId":"23b471be-b211-4569-eb6a-733d9bf00d00"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### Methods","metadata":{"id":"c6l9-LD_Z3KL"}},{"cell_type":"markdown","source":"##### [astype()](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.astype.html)\n\n*Cast a pandas object to a specified dtype dtype.*","metadata":{"id":"0pN16re0PfC6"}},{"cell_type":"code","source":"d = {'col1': [1, 2], 'col2': [3, 4]}\ndf = pd.DataFrame(data=d)\ndf.dtypes","metadata":{"outputId":"20f53827-acd6-45fe-dcba-25fead762502","id":"DGLHwQFOPfC7"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Cast all columns to int32\ndf.astype('int32').dtypes","metadata":{"outputId":"164271ab-cd8b-4e21-c623-43b7ed9a929f","id":"Wd3wwwdqPfC7"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Cast col1 to int32 using a dictionary\ndf.astype({'col1': 'int32'}).dtypes","metadata":{"id":"CevfP1JTP5u8","outputId":"273f667d-36af-40a2-992b-3d3e45e195fe"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"ser = pd.Series([1, 2], dtype='int32')\nser.astype('int64')","metadata":{"id":"jXNviorDQG5L","outputId":"94404405-580f-4430-d5ed-800e27552627"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# int32 to category dtype\nser.astype('category')","metadata":{"id":"yFlGCaIwQMuz","outputId":"589dd8ca-2989-46a6-d5c7-c8206ba66c32"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"##### [dtypes()](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.dtypes.html)\n\n*Return the dtypes in the DataFrame, as a Series with the data type of each column.*","metadata":{"id":"HRSVk_-KGLjJ"}},{"cell_type":"code","source":"df = pd.DataFrame({'float': [1.0],\n                   'int': [1],\n                   'datetime': [pd.Timestamp('20180310')],\n                   'string': ['foo']})\n\ndf.dtypes","metadata":{"outputId":"0cc5acbe-31fb-4742-b0f7-1892cefd0066","id":"qlQtKcEHGLjJ"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"##### [select_dtypes()](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.select_dtypes.html)\n\n*Return a subset of the DataFrameâ€™s columns based on the column dtypes.*\n\n*- To select all numeric types, use np.number or 'number'*\n\n*- To select strings you must use the object dtype, but note that this will return all object dtype columns*\n\n*- To select datetimes, use np.datetime64, 'datetime' or 'datetime64'*\n\n*- To select Pandas categorical dtypes, use 'category'*","metadata":{"id":"x51w-zdpGsAR"}},{"cell_type":"code","source":"df = pd.DataFrame({'a': [1, 2] * 3,\n                   'b': [True, False] * 3,\n                   'c': [1.0, 2.0] * 3})\ndf","metadata":{"outputId":"f9f70e9d-20f3-4609-b998-cbe08baab474","id":"IxLxFTXwGsAS"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df.select_dtypes(include='bool')","metadata":{"id":"e4Xbz4GpHVJU","outputId":"86b8a33d-7f95-4e7c-dcf9-518e2bd00089"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df.select_dtypes(include=['float64'])","metadata":{"id":"_xFSB77hHdHR","outputId":"8d00b87e-3b67-4bf8-b309-bffbf37d7ffa"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df.select_dtypes(exclude=['int64'])","metadata":{"id":"pob7qbW7Hf_7","outputId":"7e105028-e74b-46a4-bb30-47e86894592b"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"##### [to_numpy()](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_numpy.html)\n\n*Convert the DataFrame to a NumPy array.*\n\n*By default, the dtype of the returned array will be the common NumPy dtype of all types in the DataFrame.*\n\n*Alternatively, use **values** attribute*","metadata":{"id":"1cRaw3k54qVp"}},{"cell_type":"code","source":"pd.DataFrame({\"A\": [1, 2], \"B\": [3, 4]}).to_numpy()","metadata":{"outputId":"cfc56ed5-1f70-4fa8-b3fb-92d668222a02","id":"HsgfB4x24qVq"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pd.DataFrame({\"A\": [1, 2], \"B\": [3, 4]}).values # .to_numpy() is equivalent to .values","metadata":{"id":"8hMrxV9cWliJ","outputId":"738bac61-5cad-46c9-d1e2-34a7159f6b2e"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df = pd.DataFrame({\"A\": [1, 2], \"B\": [3.0, 4.5]})\ndf.to_numpy()","metadata":{"outputId":"b8fb4a74-e0a5-4c0c-9cf6-12bbcd79ce3d","id":"giCHUqye4qVq"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"##### [head()](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.head.html)\n\n*Return the first n rows.*","metadata":{"id":"YCA-2jY3ZaVK"}},{"cell_type":"code","source":"df = pd.DataFrame({'animal': ['alligator', 'bee', 'falcon', 'lion',\n                   'monkey', 'parrot', 'shark', 'whale', 'zebra']})\ndf.head()","metadata":{"id":"kexP3lEAa1Lo","outputId":"5ae71839-0221-4785-c95f-a55128318085"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df.head(3) # Viewing first 3 lines","metadata":{"id":"HaBWQBL-bWAs","outputId":"b9e495b8-586c-417b-a251-5bf84371d4ba"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df.head(-3) # Viewing all, but last 3.","metadata":{"id":"1FQmDyVhbcFG","outputId":"8c9f8a9e-aecc-4e88-e1d6-950b7af244ba"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"##### [tail()](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.tail.html)\n\n*Return the last n rows.*","metadata":{"id":"PAx4dhGpb0Hr"}},{"cell_type":"code","source":"df = pd.DataFrame({'animal': ['alligator', 'bee', 'falcon', 'lion',\n                   'monkey', 'parrot', 'shark', 'whale', 'zebra']})\n\ndf.tail()","metadata":{"id":"S5tj8hk0cAc_","outputId":"982fd729-6233-44f3-aa7d-250287a43931"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df.tail(3) # Viewing last 3 lines","metadata":{"id":"CziHxkKbcFoT","outputId":"339de968-3e40-4084-ef5b-6ba858538340"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df.tail(-3) # Viewing all but first 3 lines","metadata":{"id":"3FJYUci6cJUz","outputId":"d726482b-3ef2-44bf-c584-760eb31dc0e1"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"##### [columns()](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.columns.html)\n\n*The column labels of the DataFrame.*","metadata":{"id":"bZpOrNO7chs7"}},{"cell_type":"code","source":"df = pd.DataFrame({'float': [1.0],\n                   'int': [1],\n                   'datetime': [pd.Timestamp('20180310')],\n                   'string': ['foo']})\n\ndf.columns","metadata":{"id":"9dFUDPfAZ7Nh","outputId":"f0a423e0-d0da-49f9-afab-462d282c1bd7"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"##### [any()](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.any.html), [all()](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.all.html)\n\n*Return whether any(all) element is True, potentially over an axis.*\n\n*Returns False(True) unless there is at least one element within a series or along a Dataframe axis that is True(False) or equivalent (e.g. non-zero or non-empty)*","metadata":{"id":"rkGKhREoaPHG"}},{"cell_type":"code","source":"pd.Series([False, False]).any()","metadata":{"outputId":"d9c27a63-15d9-4e18-e561-d106d43aea29","id":"lOuU_C_qaPHH"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df = pd.DataFrame({\"A\": [1, 2], \"B\": [0, 2], \"C\": [0, 0]})\ndf.any()","metadata":{"id":"WH_s7jXBaplX","outputId":"87faa917-777f-4c1e-aece-51b5034782d1"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df = pd.DataFrame({\"A\": [True, False], \"B\": [1, 0]})\ndf.any(axis=1) # across rows","metadata":{"id":"U3e9FJWSbLUC","outputId":"1605024d-0f6c-4aaf-e81f-015adcd462e0"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df = pd.DataFrame({'col1': [True, True], 'col2': [True, False]})\ndf.all()","metadata":{"id":"fxlgyZ0Cb7jG","outputId":"f0456968-3361-4be4-d0a5-160f994341a7"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"##### [index()](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.index.html)\n\n*The index (row labels) of the DataFrame.*","metadata":{"id":"5d_SbhcS6738"}},{"cell_type":"code","source":"df = pd.DataFrame([('bird', 389.0),\n                   ('bird', 24.0),\n                   ('mammal', 80.5),\n                   ('mammal', np.nan)],\n                  index=['falcon', 'parrot', 'lion', 'monkey'],\n                  columns=('class', 'max_speed'))\n\ndf.index","metadata":{"id":"AGQIb4LJ8cHO","outputId":"e683f3fd-b73a-4c2f-b764-2e3fd04715ec"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"##### [loc()](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.loc.html)\n\n*Access a group of rows and columns by label(s) or a boolean array.*","metadata":{"id":"N5dJz1HKcwIQ"}},{"cell_type":"code","source":"df = pd.DataFrame([[1, 2], [4, 5], [7, 8]],\n     index=['cobra', 'viper', 'sidewinder'],\n     columns=['max_speed', 'shield'])\n\ndf.loc['viper']","metadata":{"id":"TAv6lJWNc8Fc","outputId":"b4ae9500-2983-4e51-8fd2-da9d0f65dbd1"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# List of labels. Note using [[]] returns a DataFrame.\ndf.loc[['viper', 'sidewinder']]","metadata":{"id":"MyDqWxZjdELZ","outputId":"5647ce26-9113-4a19-dc95-85efef240431"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Single label for row and column\ndf.loc['cobra', 'shield']","metadata":{"id":"mbmlM0GCdROl","outputId":"21c49b70-35be-46b8-c011-2d96bd705a22"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Conditional that returns a boolean Series\ndf.loc[df['shield'] > 6]","metadata":{"id":"M9pvGuiNd3Xb","outputId":"cfa5eb2b-5838-4f1e-efb7-59fdd6b68611"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Conditional that returns a boolean Series with column labels specified\ndf.loc[df['shield'] > 6, ['max_speed']]","metadata":{"id":"hhdtD32LFaoi","outputId":"24d33808-b0a9-4e05-8bb9-8be933872c9c"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Callable that returns a boolean Series\ndf.loc[lambda df: df['shield'] == 8]","metadata":{"id":"S6CR5w8QF-vh","outputId":"3537c82c-a971-4381-b1b6-149149c73719"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Set value for all items matching the list of labels\ndf.loc[['viper', 'sidewinder'], ['shield']] = 50\ndf","metadata":{"id":"fagcmD17HJCb","outputId":"3b01c753-41cf-4993-8028-acd7bcdfa73d"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Set value for an entire row\ndf.loc['cobra'] = 10\ndf","metadata":{"id":"dvy8z057HOe0","outputId":"9f614637-0dca-4806-80c3-516bc7cb0760"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Set value for an entire column\ndf.loc[:, 'max_speed'] = 30\ndf","metadata":{"id":"MLXykFqSHWS_","outputId":"b767d50f-a62c-430f-efdd-acede36485f8"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Set value for rows matching callable condition\ndf.loc[df['shield'] > 35] = 0\ndf","metadata":{"id":"IWDbpGxRHbEp","outputId":"73273ae4-b482-49e5-f754-f8fd062b534f"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df = pd.DataFrame([[1, 2], [4, 5], [7, 8]],\n     index=[7, 8, 9], columns=['max_speed', 'shield'])\ndf.loc[7:9] # loc includes first and last index, since it's integer-based.","metadata":{"id":"gAwfhzxMHxhY","outputId":"f4b1dd1b-7680-4a75-b4d6-fc1917e1c05d"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"##### [iloc()](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.iloc.html)\n\n*Purely integer-location based indexing for selection by position.*","metadata":{"id":"km7wXTFHPwq8"}},{"cell_type":"code","source":"mydict = [{'a': 1, 'b': 2, 'c': 3, 'd': 4},\n          {'a': 100, 'b': 200, 'c': 300, 'd': 400},\n          {'a': 1000, 'b': 2000, 'c': 3000, 'd': 4000 }]\ndf = pd.DataFrame(mydict)\ndf","metadata":{"id":"zMQXTflDP-nX","outputId":"8521d324-5362-46dd-80f6-243af4d28118"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"type(df.iloc[0])","metadata":{"id":"TafEhlgrQKKl","outputId":"6f9b08eb-f031-4c38-b094-a7038af3032e"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Indexing with scalar integer\ndf.iloc[0]","metadata":{"id":"RbEIdPsZQM-Z","outputId":"24df3257-c30c-4473-ce7e-ab76b774b855"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Indexing with a list of integers.\ndf.iloc[[0, 1]]","metadata":{"id":"PJxd-_SeQUyV","outputId":"479f64eb-4eb0-479f-aa92-b87a3d727d6f"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Indexing with a slice object\ndf.iloc[:3]","metadata":{"id":"3tfBKb6NQbYB","outputId":"8d3c3048-2b5a-45c6-c983-ee579738d3ae"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Indexing with a boolean mask\ndf.iloc[[True, False, True]]","metadata":{"id":"MHNpqw7aQkvd","outputId":"f153d251-b553-4e06-d30b-c911683d6242"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Indexing both axes","metadata":{"id":"dDVJLEboRWi6"}},{"cell_type":"code","source":"# With scalar integers\ndf.iloc[0, 1]","metadata":{"id":"0dfRDkO8Rchf","outputId":"76de8470-e5e8-4a35-a08d-0dc0fc9d194d"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# With lists of integers.\ndf.iloc[[0, 2], [1, 3]]","metadata":{"id":"GhDiqeWjRgA3","outputId":"148c8a77-3168-4e37-d3f7-411cf679d178"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# With a boolean array whose length matches the columns.\ndf.iloc[:, [True, False, True, False]]","metadata":{"id":"4KsaFd7VR3k-","outputId":"f8e7ecca-2cd3-459a-a563-1e2da1fd3eb2"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"##### [info()](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.info.html)\n\n*Prints information about a DataFrame including the index dtype and columns, non-null values and memory usage.*","metadata":{"id":"gKX3N0dLSGGq"}},{"cell_type":"code","source":"int_values = [1, 2, 3, 4, 5]\ntext_values = ['alpha', 'beta', 'gamma', 'delta', 'epsilon']\nfloat_values = [0.0, 0.25, 0.5, 0.75, 1.0]\ndf = pd.DataFrame({\"int_col\": int_values, \"text_col\": text_values,\n                  \"float_col\": float_values})\ndf","metadata":{"id":"_MyWUhTDTgfe","outputId":"639d281e-a2d6-4600-f28b-6d1f8e05292f"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df.info()","metadata":{"id":"UnNv9byWTqPC","outputId":"9ec24a37-e634-40e5-92ae-345865963580"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"##### [describe()](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.describe.html)\n\n*Generate descriptive statistics including those that summarize the central tendency, dispersion and shape of a datasetâ€™s distribution, excluding NaN values.*","metadata":{"id":"tziSnglDSdVG"}},{"cell_type":"code","source":"# Describing a numeric Series.\ns = pd.Series([1, 2, 3])\ns.describe()","metadata":{"id":"tvdWmtYpT4N0","outputId":"1992f990-0e8e-40fa-94c4-9cfd211bc951"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Describing a categorical Series.\ns = pd.Series(['a', 'a', 'b', 'c'])\ns.describe()","metadata":{"id":"anBDJjz_T_lL","outputId":"858bf8ca-2a7b-4696-ee4e-cc8485458b75"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Describing a DataFrame. By default only numeric fields are returned.\ndf = pd.DataFrame({'categorical': pd.Categorical(['d','e','f']),\n                   'numeric': [1, 2, 3],\n                   'object': ['a', 'b', 'c']\n                  })\ndf.describe()","metadata":{"id":"iHdugOZsUP9s","outputId":"11b82779-7aab-48fd-d13f-0b65fc5a8955"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Describing all columns of a DataFrame regardless of data type.\ndf.describe(include='all')","metadata":{"id":"SvLrhtowUY_l","outputId":"cf41bbdf-1778-4861-eb93-eadf67fbb697"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Describing a column from a DataFrame\ndf['numeric'].describe()","metadata":{"id":"sTL4v7EWUmyV","outputId":"849cfbe6-e62c-47d6-9cb0-c38a4915e518"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"##### [insert()](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.insert.html)\n\n*Insert column into DataFrame at specified location.*","metadata":{"id":"hCUQFn8yS2yx"}},{"cell_type":"code","source":"df = pd.DataFrame({'col1': [1, 2], 'col2': [3, 4]})\ndf","metadata":{"id":"uZVOi3ILU9Ej","outputId":"884a84aa-ae46-471d-be65-ed4a38611a22"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df.insert(1, \"newcol\", [99, 99])\ndf","metadata":{"id":"9MfpwRbwVCem","outputId":"c18588e6-a1d6-4fce-b73a-dca3ac4b132a"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df.insert(0, \"col1\", [100, 100], allow_duplicates=True)\ndf","metadata":{"id":"jqsTc3GTVMz4","outputId":"6bb2518b-4eeb-41e2-de4a-74a728d0605d"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"##### [pop()](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.pop.html)\n\n*Return item and drop from frame. Raise KeyError if not found.*","metadata":{"id":"_01kluwnS32A"}},{"cell_type":"code","source":"df = pd.DataFrame([('falcon', 'bird', 389.0),\n                   ('parrot', 'bird', 24.0),\n                   ('lion', 'mammal', 80.5),\n                   ('monkey', 'mammal', np.nan)],\n                  columns=('name', 'class', 'max_speed'))\ndf","metadata":{"id":"Fa0tPeRXVYRq","outputId":"fe1c6bfe-6bc6-40d4-f93a-60542e4214d8"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df.pop('class')\ndf","metadata":{"id":"Hex1fhcSVd2w","outputId":"0694ad56-9ebb-42b6-9628-26c1b9ef4af7"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"##### [copy()](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.copy.html)\n\n*Make a copy of this objectâ€™s indices and data.*\n","metadata":{"id":"3lxHNs--S4oe"}},{"cell_type":"code","source":"s = pd.Series([1, 2], index=[\"a\", \"b\"])\ndeep = s.copy()\nshallow = s.copy(deep=False)\ns[0] = 2 # will affect shallow\nshallow","metadata":{"id":"UX5eI3vFWZYI","outputId":"7b56003a-0778-4342-cc08-5c300ccc724b"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"deep # but will not affect deep","metadata":{"id":"Sr0lxR85XcBC","outputId":"f5066be2-3015-4880-d134-f1114c98fd3a"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"##### [plot()](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.plot.html)\n\n*Make plots of Series or DataFrame, using matplotlib (by default)*","metadata":{"id":"gLA08tLuS5W9"}},{"cell_type":"markdown","source":"##### [boxplot()](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.boxplot.html)\n\n*Make a box-and-whisker plot from DataFrame columns, optionally grouped by some other columns.*","metadata":{"id":"iN-cBhtsS6BT"}},{"cell_type":"code","source":"np.random.seed(1234)\ndf = pd.DataFrame(np.random.randn(10, 4),\n                  columns=['Col1', 'Col2', 'Col3', 'Col4'])\nboxplot = df.boxplot(column=['Col1', 'Col2', 'Col3'])","metadata":{"id":"xa6gX9AUwOW3","outputId":"a69fca7e-4b1b-434c-a5ac-3ea6bceb14a7"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"##### [corr()](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.corr.html)\n\n*Compute pairwise correlation of columns, excluding NA/null values.*","metadata":{"id":"pr9IeuL8S6rq"}},{"cell_type":"code","source":"df = pd.DataFrame([(.2, .3), (.0, .6), (.6, .0), (.2, .1)],\n                  columns=['dogs', 'cats'])\ndf.corr()","metadata":{"id":"JF1KHFLPw1AZ","outputId":"6a240723-6dbf-4496-e9a4-3a01b62b0454"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df","metadata":{"id":"Zr9QKcRZxCgm","outputId":"61a0a4ed-003a-4ecd-be9e-8aeab2d8a640"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"##### [drop()](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.drop.html)\n\n*Remove rows or columns by specifying label names and corresponding axis, or by specifying directly index or column names.*","metadata":{"id":"5uZR5-V2S7S0"}},{"cell_type":"code","source":"df = pd.DataFrame(np.arange(12).reshape(3, 4),\n                  columns=['A', 'B', 'C', 'D'])\ndf","metadata":{"id":"G-A03GYTxL1k","outputId":"2e36f09b-3b58-40ab-b51c-d7d0c45cb11d"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df.drop(['B', 'C'], axis=1)","metadata":{"id":"W4Im9_0Nxfsq","outputId":"64d337f1-4aac-467a-a8f5-edd744463af9"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df.drop(columns=['B', 'C'])","metadata":{"id":"xCZ6i8A_xjVi","outputId":"f695325f-b6be-4343-8246-2280f488e1ca"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# drop a row by index\ndf.drop([0, 1])","metadata":{"id":"Uo_Och_nxmYq","outputId":"42427e10-2279-4a09-86c6-6b4a00fa7d81"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"##### [dropna()](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.dropna.html)\n\n*Remove missing values.*","metadata":{"id":"m05_FPzfS75p"}},{"cell_type":"code","source":"df = pd.DataFrame({\"name\": ['Alfred', 'Batman', 'Catwoman'],\n                   \"toy\": [np.nan, 'Batmobile', 'Bullwhip'],\n                   \"born\": [pd.NaT, pd.Timestamp(\"1940-04-25\"),\n                            pd.NaT]}) # pd.NaT is Not a Time, pd.nan is Not a Number.\ndf","metadata":{"id":"8XfpJTeiyBlS","outputId":"f0489ffe-ff4f-49f7-ce7f-dee914d38fdb"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Drop the rows where at least one element is missing.\ndf.dropna()","metadata":{"id":"58CPtK56yW2E","outputId":"7c9b3a37-5835-4531-ef1f-5edb77f5bda9"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Drop the columns where at least one element is missing.\ndf.dropna(axis='columns') # same as df.dropna(axis=1)","metadata":{"id":"JPzQQVMYyh6f","outputId":"de75646e-d14d-42c1-a69f-21a7ec6632ac"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Drop the rows where all elements are missing.\ndf.dropna(how='all')","metadata":{"id":"DV8Tn2o_yufz","outputId":"f818320e-baf7-4bc8-a5cd-a2f5ffca0262"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Keep rows with at least 2 non-NAs.\ndf.dropna(thresh=2)","metadata":{"id":"Az2vQV5qy0Jf","outputId":"dc109c53-bbd0-4bd7-90d3-c000fe184526"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Define in which columns to look for missing values.\ndf.dropna(subset=['name', 'toy'])","metadata":{"id":"k0t7pwDFz3EA","outputId":"afa78297-b6f9-4586-baca-8b0c764f8f77"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Keep the DataFrame with valid entries in the same variable.\ndf.dropna(inplace=True)\ndf","metadata":{"id":"MyH2yK7P0C18","outputId":"91c9e1fc-8dc7-4e74-de5f-da9878f20f5c"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"##### [isna()](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.isna.html), [isnull()](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.isnull.html)\n\n*Return a boolean same-sized object indicating if the values are NA.*\n","metadata":{"id":"8xlibnMxS8n1"}},{"cell_type":"code","source":"df = pd.DataFrame(dict(age=[5, 6, np.NaN],\n                   born=[pd.NaT, pd.Timestamp('1939-05-27'),\n                         pd.Timestamp('1940-04-25')],\n                   name=['Alfred', 'Batman', ''],\n                   toy=[None, 'Batmobile', 'Joker']))\ndf","metadata":{"id":"6bm7zE1v4Np2","outputId":"d82fa167-2cde-477e-8ef2-34b88f0a2dac"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df.isna()","metadata":{"id":"CQF3o7Qs4i9I","outputId":"c7ad6754-16f7-41c3-9660-72d08518f477"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Show which entries in a Series are NA.\ndf['toy'].isna()","metadata":{"id":"WvJSB5U54ojv","outputId":"31a75883-07e9-44a3-8a8f-f119c52e5a6b"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"isnull() is an alias for isna()","metadata":{"id":"Sy2ZydbX48qF"}},{"cell_type":"code","source":"df.isnull() # same as df.isna()","metadata":{"id":"w_TGe6AU5Fx2","outputId":"7f5e9576-56cb-47af-fd08-cb9d1364c44f"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"##### [notna()](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.notna.html), [notnull()](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.notnull.html)\n\n*Return a boolean same-sized object indicating if the values are not NA.*\n","metadata":{"id":"SvkveG6cS9rp"}},{"cell_type":"code","source":"df = pd.DataFrame(dict(age=[5, 6, np.NaN],\n                   born=[pd.NaT, pd.Timestamp('1939-05-27'),\n                         pd.Timestamp('1940-04-25')],\n                   name=['Alfred', 'Batman', ''],\n                   toy=[None, 'Batmobile', 'Joker']))\ndf","metadata":{"id":"hzpx6siZ5Ylu","outputId":"1f3ab3de-1541-464f-aa0d-e510ec99b004"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df.notna()","metadata":{"id":"mLU6fCEf5UIe","outputId":"c0a0d43e-ca05-4c41-cfde-88fc5e0ed012"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Show which entries in a Series are not NA.\ndf['name'].notna() # empty string is not considered as na","metadata":{"id":"Ecu48BS35hqC","outputId":"93dd26e8-72d6-4a5a-e91f-f75d4defa4ba"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"notnull() is an alias for notna()","metadata":{"id":"EaRLH5sV54BQ"}},{"cell_type":"code","source":"df.notnull() # same as df.notna()","metadata":{"id":"_I-dzfl46AAw","outputId":"bd009858-4e8d-4067-a25c-112021620ac3"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"##### [reset_index()](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.reset_index.html)\n\n*Reset the index of the DataFrame, and use the default one instead. *","metadata":{"id":"4mjyLsgGS-tz"}},{"cell_type":"code","source":"df = pd.DataFrame([('bird', 389.0),\n                   ('bird', 24.0),\n                   ('mammal', 80.5),\n                   ('mammal', np.nan)],\n                  index=['falcon', 'parrot', 'lion', 'monkey'],\n                  columns=('class', 'max_speed'))\ndf","metadata":{"id":"ZXTZwUzP6UaS","outputId":"f988af77-421a-40f8-ebf9-a7a3bae23a10"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df.reset_index()","metadata":{"id":"LI7-EKrB6W43","outputId":"f7db315d-0a0c-4588-ea90-86c70721c8d7"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df.reset_index(drop=True)","metadata":{"id":"7Yq0H-uv6Z9L","outputId":"612533d7-9d3d-4d40-c7f9-7f05ad9b6913"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"##### [replace()](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.replace.html)\n\n*Replace values given in to_replace with other values dynamically*","metadata":{"id":"mNAwNvleS_S3"}},{"cell_type":"code","source":"s = pd.Series([1, 2, 3, 4, 5])\ns.replace(1, 5)","metadata":{"id":"BM_IUaoA6qTy","outputId":"9d5a734e-bd05-43e2-90b8-7e23d7558f61"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"First parameter is *to_replace* (None by default), and second parameter is *value* to replace with (None by default)","metadata":{"id":"0-KFwh1X9Nuf"}},{"cell_type":"code","source":"df = pd.DataFrame({'A': [0, 1, 2, 3, 4],\n                   'B': [5, 6, 7, 8, 9],\n                   'C': ['a', 'b', 'c', 'd', 'e']})\ndf.replace(0, 5)","metadata":{"id":"dd10Y_qj6vms","outputId":"b3db4b2f-e5c1-4e2e-8bf6-b9dff434d164"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Replace list of values","metadata":{"id":"ZoSKLxiM7LES"}},{"cell_type":"code","source":"df.replace([0, 1, 2, 3], 4)","metadata":{"id":"ha25_CCO649i","outputId":"3f7eaa5c-449b-44eb-f395-ecae2af21b23"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Replace a list of values from another list\ndf.replace([0, 1, 2, 3], [4, 3, 2, 1])","metadata":{"id":"YGwWpR2d697o","outputId":"73d2d1f2-481e-479d-b0f0-8d24f589c238"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Replace values from a dictionary","metadata":{"id":"eHSjZ_Y-7QFk"}},{"cell_type":"code","source":"df.replace({0: 10, 1: 100})","metadata":{"id":"5fxE2R-r7FhT","outputId":"b2205d56-ea19-42f4-c2d8-1bf096a3d4ff"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df.replace({'A': 0, 'B': 5}, 100) # Columns are keys.","metadata":{"id":"Cp3Xcuh77sEW","outputId":"e1540e9d-143e-46e2-d5eb-829a406f1ee4"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df.replace({'A': {0: 100, 4: 400}})","metadata":{"id":"a5shWos7721k","outputId":"0f035cac-9e62-4ea8-da6d-e13afdd3bdb5"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Replace regular expression","metadata":{"id":"7h8M2iL78xAH"}},{"cell_type":"code","source":"df = pd.DataFrame({'A': ['bat', 'foo', 'bait'],\n                   'B': ['abc', 'bar', 'xyz']})\ndf.replace(to_replace=r'^ba.$', value='new', regex=True)","metadata":{"id":"XbnLG2ll80T8","outputId":"16ff9667-b8d5-4ad0-cac6-59769c03b0d4"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df.replace({'A': r'^ba.$'}, {'A': 'new'}, regex=True)","metadata":{"id":"DLIshKbD9uNY","outputId":"9de72e03-dd5f-4d57-d94e-c013b0601ec6"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"s = pd.Series([10, 'a', 'a', 'b', 'a'])\ns.replace('a', 11)","metadata":{"id":"BEGYmjhL-SwD","outputId":"5929aed4-ffbe-44c0-989e-589b9d577c7a"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"s.replace('a') # forward fill","metadata":{"id":"6oCJuIRw-piK","outputId":"029b304f-1504-42eb-9a30-2a507058cd42"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"##### [transpose()](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.transpose.html)\n\n*Reflect the DataFrame over its main diagonal by writing rows as columns and vice-versa. The property T is an accessor to the method transpose().*","metadata":{"id":"MxjvOuz9TACp"}},{"cell_type":"code","source":"d1 = {'col1': [1, 2], 'col2': [3, 4]}\ndf1 = pd.DataFrame(data=d1)\ndf1","metadata":{"id":"UUUbBTPH_Ktb","outputId":"5fed2dad-ce81-44aa-e0fb-63d59baa7abc"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df1_transposed = df1.transpose() # or df1.T\ndf1_transposed","metadata":{"id":"WJG1JwG-_Nif","outputId":"aefef02e-f0a2-4622-8a88-d9bc8bdaad2a"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"The property T is an accessor to this method","metadata":{"id":"hdEe_ifO_BLt"}},{"cell_type":"markdown","source":"##### [hist()](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.hist.html)\n\n*Make a histogram of the DataFrameâ€™s columns, using matplotlib.pyplot.hist().*\n","metadata":{"id":"Vh7TduCDTBCo"}},{"cell_type":"code","source":"df = pd.DataFrame({\n    'length': [1.5, 0.5, 1.2, 0.9, 3],\n    'width': [0.7, 0.2, 0.15, 0.2, 1.1]\n    }, index=['pig', 'rabbit', 'duck', 'chicken', 'horse'])\nhist = df.hist(bins=3)","metadata":{"id":"pUUIILmbCUH6","outputId":"967e17f9-aa04-427c-a985-7b25ccac66ea"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"##### [sum()](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.sum.html)\n\n*Return the sum of the values over the requested axis.  Equivalent to the method numpy.sum.*","metadata":{"id":"B95QHdpwTBxQ"}},{"cell_type":"code","source":"s = pd.Series([4, 2, 0, 8, np.nan], name='legs')\ns # skipna is True by default","metadata":{"id":"5he5x-5WEcrg","outputId":"c06bf056-90de-4d0a-ec78-452f1970f0f3"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"s.sum(skipna=False)","metadata":{"id":"zMVoa3x9Emcw","outputId":"c339931b-c320-42b3-8a45-15d504e43330"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"##### [mean()](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.mean.html), [median()](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.median.html)\n\n*Return the mean and median respectively of the values over the requested axis.*","metadata":{"id":"hHEQPTkfTCZA"}},{"cell_type":"markdown","source":"##### [var()](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.var.html)\n\n*Return unbiased variance over requested axis.*\n\n*Normalized by N-1 by default. This can be changed using the ddof argument.*","metadata":{"id":"Pbjz0f_dTDtq"}},{"cell_type":"code","source":"df = pd.DataFrame({'person_id': [0, 1, 2, 3],\n                  'age': [21, 25, 62, 43],\n                  'height': [1.61, 1.87, 1.49, 2.01]}\n                 ).set_index('person_id')\ndf","metadata":{"id":"QalNI-tmGc1D","outputId":"a93d0ccd-8f0d-424c-cedf-245718221986"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df.var() # Sample variance","metadata":{"id":"DvHEDDawGfj2","outputId":"b98b1ec3-6858-4c19-e6d3-7912d377ea2e"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df.var(ddof=0) # Population variance","metadata":{"id":"0xMR91Y_Gprn","outputId":"cca7a564-2a7a-4121-f8ea-62e15fa49b32"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"##### [std()](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.std.html)\n\n*Return sample standard deviation over requested axis.*\n\n*Normalized by N-1 by default. This can be changed using the ddof argument.*","metadata":{"id":"PizIG55dTEUd"}},{"cell_type":"code","source":"df = pd.DataFrame({'person_id': [0, 1, 2, 3],\n                  'age': [21, 25, 62, 43],\n                  'height': [1.61, 1.87, 1.49, 2.01]}\n                 ).set_index('person_id')\ndf","metadata":{"id":"vSg5vzbhHDQk","outputId":"7a140b13-6a16-4c32-fd39-a1bb75db0390"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df.std() # Sample std. deviation","metadata":{"id":"hdMjbMDOHHnR","outputId":"1f2b92f6-eac8-407f-de84-9e991e3f5bd2"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df.std(ddof=0) # Population std. deviation","metadata":{"id":"8ukMOrD9HLjC","outputId":"1a3bb73e-66ed-49c0-b78a-1cde5fc5041d"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"##### [groupby()](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.groupby.html)\n\n*Group DataFrame using a mapper or by a Series of columns.*\n\n*A groupby operation involves some combination of splitting the object, applying a function, and combining the results.*","metadata":{"id":"R-s5eMRBTJCs"}},{"cell_type":"code","source":"df = pd.DataFrame({'Animal': ['Falcon', 'Falcon',\n                              'Parrot', 'Parrot'],\n                   'Max Speed': [380., 370., 24., 26.]})\ndf","metadata":{"id":"UrLH78VyHa7o","outputId":"7b66f8c0-0897-4bb1-b30b-76139971ebad"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df.groupby(['Animal']).mean()","metadata":{"id":"54QzsYsTHc6I","outputId":"668ed483-52ab-47af-b005-53ed0eebf962"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"l = [[\"a\", 12, 12], [None, 12.3, 33.], [\"b\", 12.3, 123], [\"a\", 1, 1]]\ndf = pd.DataFrame(l, columns=[\"a\", \"b\", \"c\"])\ndf","metadata":{"id":"O0INgimMIe4d","outputId":"e7342be1-1f59-4fd0-da34-0131e1be3bb8"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df.groupby(by=[\"a\"]).sum()","metadata":{"id":"SUDLcnEhIhzU","outputId":"8cbac83d-c34a-4939-ca13-cf1c5574125d"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df.groupby(by=\"a\", dropna=False).sum()","metadata":{"id":"8cnmlimrIo6k","outputId":"04dcc0e2-3b10-4c8a-a33a-23d65fde7b25"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"##### [where()](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.where.html)\n\n*Replace values where the condition is False.*\n\n*For each element in the calling DataFrame, if cond is True the element is used; otherwise the corresponding element from the DataFrame other is used.*\n\n*Note that in NumPy, where() method behaves differently, and takes 3 arguments*","metadata":{"id":"v0qzHs692eAY"}},{"cell_type":"code","source":"s = pd.Series(range(5))\ns.where(s > 0)","metadata":{"outputId":"ccec0ba1-b6e5-4f86-d3b0-63802608b565","id":"L3DosX0V2eAZ"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"s.where(s > 1, 10)","metadata":{"outputId":"83613b7e-3ec3-4570-f81c-3ea86373e7b5","id":"I8CxTaqa2eAa"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df = pd.DataFrame(np.arange(10).reshape(-1, 2), columns=['A', 'B'])\ndf","metadata":{"outputId":"a8945142-2576-4e40-bcc7-e88109c3d381","id":"qI01SL8J2eAa"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"m = df % 3 == 0\ndf.where(m, -df)","metadata":{"outputId":"dc2d9f89-bb23-44ba-f7ea-39bc670effdb","id":"0iibnKde2eAa"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"##### [sort_values()](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.sort_values.html)\n\n*Sort by the values along either axis.*","metadata":{"id":"9aB_frsDXbyL"}},{"cell_type":"code","source":"df = pd.DataFrame({\n    'col1': ['A', 'A', 'B', np.nan, 'D', 'C'],\n    'col2': [2, 1, 9, 8, 7, 4],\n    'col3': [0, 1, 9, 4, 2, 3],\n    'col4': ['a', 'B', 'c', 'D', 'e', 'F']\n})\ndf","metadata":{"outputId":"f604900a-37aa-43a6-9590-69894bb11a2c","id":"5DBD4C0AXbyM"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Sort by col1\ndf.sort_values(by=['col1'])","metadata":{"outputId":"86fa7247-5c0b-492e-8472-58132b3463ec","id":"zbykvvnVXbyM"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# sort by multiple columns\ndf.sort_values(by=['col1', 'col2'])","metadata":{"outputId":"dddd9237-0b9c-4718-a474-9c090a92f813","id":"I48nZaC_XbyN"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Sort in descending order\ndf.sort_values(by='col1', ascending=False)","metadata":{"outputId":"7ac2c675-eeb2-478f-b533-f8cca63e7f04","id":"Iv8_bVC4XbyN"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Sorting with a key function\ndf.sort_values(by='col4', key=lambda col: col.str.lower())","metadata":{"id":"HDpsm8no5xVU","outputId":"14900cf4-0378-45ac-a406-cac39fca7611"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### [Series](https://pandas.pydata.org/docs/reference/api/pandas.Series.html)\n\n*One-dimensional ndarray with axis labels (including time series).*\n\n*Labels need not be unique but must be a hashable type.*","metadata":{"id":"1NMhzzfgS0o_"}},{"cell_type":"markdown","source":"#### Examples","metadata":{"id":"pmWfAKeGTFKA"}},{"cell_type":"code","source":"d = {'a': 1, 'b': 2, 'c': 3}\nser = pd.Series(data=d, index=['a', 'b', 'c'])\nser","metadata":{"id":"pKGlWrr8TTQ0","outputId":"0b0df29e-a2e2-46a6-88d0-d27e3fa2b832"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"d = {'a': 1, 'b': 2, 'c': 3}\nser = pd.Series(data=d, index=['x', 'y', 'z'])\nser","metadata":{"id":"rHjyDMD7TaLU","outputId":"2b2c2d69-7fc1-4b72-b8a7-3911822915af"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"r = np.array([1, 2]) # a simple list [1, 2] also works\nser = pd.Series(r, copy=False)\nser.iloc[0] = 999\nser","metadata":{"id":"lauW3yI_Ti7Y","outputId":"255ed8f2-f98e-450e-d898-221ff7960c9c"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### Methods","metadata":{"id":"q-l_BBUrTHYu"}},{"cell_type":"markdown","source":"##### [to_frame()](https://pandas.pydata.org/docs/reference/api/pandas.Series.to_frame.html)\n\n*Convert Series to DataFrame.*","metadata":{"id":"hojSLVg35jRN"}},{"cell_type":"code","source":"s = pd.Series([\"a\", \"b\", \"c\"],\n              name=\"vals\")\ns.to_frame()","metadata":{"outputId":"da2584ae-a04b-4287-e9e7-63811db0553d","id":"F9IVVNVv5jRN"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"##### [value_counts()](https://pandas.pydata.org/docs/reference/api/pandas.Series.value_counts.html)\n\n*Return a Series containing counts of unique values.*\n\n*The resulting object will be in descending order so that the first element is the most frequently-occurring element. Excludes NA values by default.*","metadata":{"id":"musu962tUeB6"}},{"cell_type":"code","source":"index = pd.Index([3, 1, 2, 3, 4, np.nan])\nindex.value_counts()","metadata":{"id":"VqryZ65nVvnl","outputId":"9410c0c6-dc68-498a-fb0d-3e5535ad08f4"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# With normalize set to True, returns the relative frequency by dividing all values by the sum of values.\ns = pd.Series([3, 1, 2, 3, 4, np.nan])\ns.value_counts(normalize=True)","metadata":{"id":"WgBEPBTDV3Vr","outputId":"eec1e9e2-2c77-4343-a5b5-5c25151d4508"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Counting in bins\ns.value_counts(bins=3)","metadata":{"id":"qB2mgTOBWAmW","outputId":"67ef6fea-aef1-49b3-eb7f-0600d2527530"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"##### [unique()](https://pandas.pydata.org/docs/reference/api/pandas.Series.unique.html)\n\n*Return unique values of Series object.*\n","metadata":{"id":"iMDUCWK3UiE4"}},{"cell_type":"code","source":"pd.Series([2, 1, 3, 3], name='A').unique()","metadata":{"id":"8NYpk-vQXqUL","outputId":"41bae399-9fd1-4396-9062-d88dd7e2fcc0"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"##### [count()](https://pandas.pydata.org/docs/reference/api/pandas.Series.count.html)\n\n*Return number of non-NA/null observations in the Series.*","metadata":{"id":"s9CA7zUdUiyf"}},{"cell_type":"code","source":"s = pd.Series([0.0, 1.0, np.nan])\ns.count()","metadata":{"id":"mUmyArwVYmkl","outputId":"07a16bc2-b23e-42bf-8224-d62674b94b39"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"##### [replace()](https://pandas.pydata.org/docs/reference/api/pandas.Series.replace.html)\n\n*Replace values given in to_replace with other values dynamically.*","metadata":{"id":"-DWh_eASUjbn"}},{"cell_type":"code","source":"s = pd.Series([1, 2, 3, 4, 5])\ns.replace(1, 5)","metadata":{"id":"tAtTFzIdYv-0","outputId":"6997862d-eb1d-4e1f-f955-e5cbfbdb633b"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"s = pd.Series([10, 'a', 'a', 'b', 'a'])\ns.replace('a')","metadata":{"id":"oMH0mH9dZDNA","outputId":"572111ef-1788-406a-b197-70280301cba0"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"##### [mean()](https://pandas.pydata.org/docs/reference/api/pandas.Series.mean.html), [median()](https://pandas.pydata.org/docs/reference/api/pandas.Series.median.html)\n\n*Return the mean and median repsectively of the values over the requested axis.*","metadata":{"id":"uD9lp3DtUkIN"}},{"cell_type":"markdown","source":"[var()](https://pandas.pydata.org/docs/reference/api/pandas.Series.var.html), [std()](https://pandas.pydata.org/docs/reference/api/pandas.Series.std.html)\n\n*Return unbiased variance and std. deviation repspectively over requested axis.*\n\n*Normalized by N-1 by default. This can be changed using the ddof argument.*","metadata":{"id":"7-cKsEBcZn3y"}},{"cell_type":"markdown","source":"##### [hist()](https://pandas.pydata.org/docs/reference/api/pandas.Series.hist.html)\n\n*Draw histogram of the input series using matplotlib.*","metadata":{"id":"mzrZyJf6Uk3P"}},{"cell_type":"markdown","source":"### [Bunch](https://scikit-learn.org/stable/modules/generated/sklearn.utils.Bunch.html)\n\n*Container object exposing keys as attributes.*","metadata":{"id":"J2itJdlyaBpI"}},{"cell_type":"markdown","source":"Typically returned by fetch_* APIs of sklearn.datasets.  Bunch object has the following keys in it: frame, data, target, target_names, feature_names","metadata":{"id":"lk8DQqhraY_w"}},{"cell_type":"markdown","source":"### [read_csv](https://pandas.pydata.org/docs/reference/api/pandas.read_csv.html)\n\n*Read a comma-separated values (csv) file into DataFrame.*\n\n*Also supports optionally iterating or breaking of the file into chunks.*","metadata":{"id":"3cyTfjQg2txJ"}},{"cell_type":"code","source":"# Downloads test.csv with no header, and two columns Col1 and Col2.\n# pd.read_csv('test.csv', header=None, names=['Col1', 'Col2'])","metadata":{"id":"nOn7sKLzZF1r"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### [concat](https://pandas.pydata.org/docs/reference/api/pandas.concat.html)\n\n*Concatenate pandas objects along a particular axis with optional set logic along the other axes.*","metadata":{"id":"UDtMJugd2uVU"}},{"cell_type":"markdown","source":"Combine two Series.","metadata":{"id":"RYu5rLi4qD_A"}},{"cell_type":"code","source":"s1 = pd.Series(['a', 'b'])\ns2 = pd.Series(['c', 'd'])\npd.concat([s1, s2])","metadata":{"id":"h2q0nsq9a0Kp","outputId":"3bd1bf78-e268-401e-dbcd-9d7ea47b0d48"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Clear the existing index and reset it in the result by setting the ignore_index option to True.","metadata":{"id":"788CSah2qKzs"}},{"cell_type":"code","source":"pd.concat([s1, s2], ignore_index=True)","metadata":{"id":"hu51l6Cga79u","outputId":"e5bc1f3d-6ce0-4efe-afe2-dad4adb4e5ca"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Add a hierarchical index at the outermost level of the data with the keys option.","metadata":{"id":"HEfKMwhNqOBi"}},{"cell_type":"code","source":"pd.concat([s1, s2], keys=['s1', 's2'])","metadata":{"id":"4NF8Mh30bBnB","outputId":"c117f6ac-3935-48bc-b164-ed23b979b2a6"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Label the index keys you create with the names option.","metadata":{"id":"WI51CoCAqRCM"}},{"cell_type":"code","source":"pd.concat([s1, s2], keys=['s1', 's2'],\n          names=['Series name', 'Row ID'])","metadata":{"id":"Mxl-YTq1bKXm","outputId":"6c0735f3-701f-4b62-eb09-00438d604cc1"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Combine two DataFrame objects with identical columns.","metadata":{"id":"qPKatc4mqTu1"}},{"cell_type":"code","source":"df1 = pd.DataFrame([['a', 1], ['b', 2]],\n                   columns=['letter', 'number'])\ndf2 = pd.DataFrame([['c', 3], ['d', 4]],\n                   columns=['letter', 'number'])\npd.concat([df1, df2], ignore_index=True)","metadata":{"id":"lGWKXIHnbPzY","outputId":"870189c0-c2a8-457e-f95b-29c7b12582f5"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Combine DataFrame objects with overlapping columns and return everything. Columns outside the intersection will be filled with NaN values.","metadata":{"id":"dsrjergdqW48"}},{"cell_type":"code","source":"df3 = pd.DataFrame([['c', 3, 'cat'], ['d', 4, 'dog']],\n                   columns=['letter', 'number', 'animal'])\n\npd.concat([df1, df3], sort=False, ignore_index=True)","metadata":{"id":"58_8m2aEbmwy","outputId":"85cb13aa-ec67-4280-d784-9696cba5ef3c"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Combine DataFrame Examples with overlapping columns and return only those that are shared by passing inner to the join keyword argument.","metadata":{"id":"nCr1Fr_OqdQX"}},{"cell_type":"code","source":"pd.concat([df1, df3], join=\"inner\", ignore_index=True)","metadata":{"id":"_BKoTDM9cEBJ","outputId":"18cfe86f-7b6d-48fa-fc28-a2262aed8270"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Combine DataFrame Examples horizontally along the x axis by passing in axis=1.","metadata":{"id":"hl0-oBeEqhcS"}},{"cell_type":"code","source":"df4 = pd.DataFrame([['bird', 'polly'], ['monkey', 'george']],\n                   columns=['animal', 'name'])\npd.concat([df1, df4], axis=1)","metadata":{"id":"ljhXe3zscSTv","outputId":"c06f3e9f-5b10-44c7-a6a1-d09131cd6dd8"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df5 = pd.DataFrame([1], index=['a'])\ndf6 = pd.DataFrame([2], index=['a'])\ntry:\n  pd.concat([df5, df6], verify_integrity=True) # Raises exception.  Opposite of ignore_index=True.\nexcept ValueError:\n  print(\"Exception raised!\")","metadata":{"id":"HiwEMZoxcndV","outputId":"8d0f94d9-1c8a-4c00-fee0-0476928d0646"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### [get_dummies](https://pandas.pydata.org/docs/reference/api/pandas.get_dummies.html)\n\n*Convert categorical variable into dummy/indicator variables.*","metadata":{"id":"B3oS_H1W2u6P"}},{"cell_type":"code","source":"s = pd.Series(list('abca'))\npd.get_dummies(s)","metadata":{"id":"GTMjz87mdZ0H","outputId":"1510b8c8-a93f-4d82-f9ef-c9081eee3cf5"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"s1 = ['a', 'b', np.nan]\npd.get_dummies(s1)","metadata":{"id":"N56F4sWpdjEF","outputId":"cbc4892f-3377-4795-952a-bcac0ff41366"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pd.get_dummies(s1, dummy_na=True)","metadata":{"id":"xydZsj0NdsZT","outputId":"2b14826a-5aca-495b-8085-15b8615a97f6"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df = pd.DataFrame({'A': ['a', 'b', 'a'], 'B': ['b', 'a', 'c'],\n                   'C': [1, 2, 3]})\npd.get_dummies(df, prefix=['col1', 'col2'])","metadata":{"id":"37sspi9JpUZW","outputId":"4074f1a6-33dd-45c5-c168-6f7143d5ce38"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pd.get_dummies(pd.Series(list('abcaa')))","metadata":{"id":"Q3pGTBHGplGo","outputId":"380535a3-fcc4-4284-d857-bb7155d7a26c"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pd.get_dummies(pd.Series(list('abcaa')), drop_first=True)","metadata":{"id":"PxMIYc_lp1kI","outputId":"6bf5744a-3742-4b28-ada9-3bf042ff3965"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pd.get_dummies(pd.Series(list('abc')), dtype=float)","metadata":{"id":"JByoroe9p9Gk","outputId":"a9dd01e2-b0ec-40d5-9a30-f5f095eb8bac"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## pandas.plotting","metadata":{"id":"yBiuAKTi2xZC"}},{"cell_type":"markdown","source":"### [scatter_matrix](https://pandas.pydata.org/docs/reference/api/pandas.plotting.scatter_matrix.html)\n\n*Draw a matrix of scatter plots.*","metadata":{"id":"3E48sF7o21Is"}},{"cell_type":"code","source":"df = pd.DataFrame(np.random.randn(1000, 4), columns=['A','B','C','D'])\npd.plotting.scatter_matrix(df, alpha=0.2)","metadata":{"id":"Dr4Hb4FKsA1-","outputId":"e83c9a04-74bd-4e9b-e808-d7beb3ad40bf"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## sns","metadata":{"id":"Lsmdj6h923y2"}},{"cell_type":"markdown","source":"### [histplot](https://seaborn.pydata.org/generated/seaborn.histplot.html)\n\n*Plot univariate or bivariate histograms to show distributions of datasets.*","metadata":{"id":"f7dVrCo8260S"}},{"cell_type":"code","source":"penguins = sns.load_dataset(\"penguins\")\nsns.histplot(data=penguins, x=\"flipper_length_mm\")","metadata":{"id":"TxCjddnisWLG","outputId":"34a5981f-4564-4e11-af18-6e26105e0f58"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Flip the plot by assigning the data variable to the y axis:","metadata":{"id":"Jw-G8WgHsj0o"}},{"cell_type":"code","source":"sns.histplot(data=penguins, y=\"flipper_length_mm\")","metadata":{"id":"zUy0GbEQsjDZ","outputId":"3a80b6ba-a8d1-4d7a-8456-2b52278653ca"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Check how well the histogram represents the data by specifying a different bin width:","metadata":{"id":"B01yFzxasrUA"}},{"cell_type":"code","source":"sns.histplot(data=penguins, x=\"flipper_length_mm\", binwidth=3)","metadata":{"id":"MLKXne0_ss-1","outputId":"509ce276-0336-423b-f4d1-0150ef5385e3"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"You can also define the total number of bins to use:","metadata":{"id":"A7M13wfIsvj_"}},{"cell_type":"code","source":"sns.histplot(data=penguins, x=\"flipper_length_mm\", bins=30)","metadata":{"id":"RfrURj9ssxs6","outputId":"d05bd02c-c3f7-4cb2-b241-4b48f9166861"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### [scatterplot](https://seaborn.pydata.org/generated/seaborn.scatterplot.html)\n\n*Draw a scatter plot with possibility of several semantic groupings.*\n","metadata":{"id":"Xq3DqlGo2-SB"}},{"cell_type":"code","source":"tips = sns.load_dataset(\"tips\")\nsns.scatterplot(data=tips, x=\"total_bill\", y=\"tip\")","metadata":{"id":"N442wwM7tBeS","outputId":"009661b4-495a-461d-aa5f-e33f01a0ba8a"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Assigning a variable to hue will map its levels to the color of the points:","metadata":{"id":"3BIkjN_EtJ_w"}},{"cell_type":"code","source":"sns.scatterplot(data=tips, x=\"total_bill\", y=\"tip\", hue=\"time\")","metadata":{"id":"VB-8wKM8tLlb","outputId":"fe137197-dafb-4939-aa7f-5a93fea017e2"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Pass the name of a categorical palette or explicit colors (as a Python list of dictionary) to force categorical mapping of the hue variable:","metadata":{"id":"vZfsPYVNtaSO"}},{"cell_type":"code","source":"sns.scatterplot(data=tips, x=\"total_bill\", y=\"tip\", hue=\"size\", palette=\"deep\")","metadata":{"id":"DJ4eYQnktbpT","outputId":"b1b9a659-e12b-434b-9915-9390adb4b7d4"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### [heatmap](https://seaborn.pydata.org/generated/seaborn.heatmap.html)\n\n*Plot rectangular data as a color-encoded matrix.*","metadata":{"id":"xj9YsNZk2-3_"}},{"cell_type":"code","source":"import numpy as np; np.random.seed(0)\nimport seaborn as sns; sns.set_theme()\nuniform_data = np.random.rand(10, 12)\nax = sns.heatmap(uniform_data)","metadata":{"id":"xG0MvMxutkle","outputId":"e47eab70-7726-4f9a-aca4-8f651ad2fad0"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Plot a dataframe with meaningful row and column labels:","metadata":{"id":"IYKXY7kxtwiN"}},{"cell_type":"code","source":"flights = sns.load_dataset(\"flights\")\nflights = flights.pivot(index=\"month\", columns=\"year\", values=\"passengers\")\nax = sns.heatmap(flights)","metadata":{"id":"q0OtgpMstv8N","outputId":"6f432d37-ef6e-448b-e1d7-3e1b1dbb097b"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Annotate each cell with the numeric value using integer formatting:","metadata":{"id":"TyxSPjhGuTHF"}},{"cell_type":"code","source":"ax = sns.heatmap(flights, annot=True, fmt=\"d\")","metadata":{"id":"uYo6UGJGuXE3","outputId":"3786d549-57be-4d14-ce22-7273f4e71b50"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Use a different colormap:","metadata":{"id":"T-RLUWJ8vMCS"}},{"cell_type":"code","source":"ax = sns.heatmap(flights, cmap=\"YlGnBu\")","metadata":{"id":"Bz5nJhHyvLc8","outputId":"6383b7bf-e80f-4cae-e799-8a0a27ce22ae"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### [pairplot](https://seaborn.pydata.org/generated/seaborn.pairplot.html)\n\n*Plot pairwise relationships in a dataset.*","metadata":{"id":"StZRaFp02_cH"}},{"cell_type":"code","source":"penguins = sns.load_dataset(\"penguins\")\nsns.pairplot(penguins)","metadata":{"id":"H49i92MIvjQ5","outputId":"243cef6b-32c0-4766-fe4f-be1277ae8250"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Assigning a hue variable adds a semantic mapping and changes the default marginal plot to a layered kernel density estimate (KDE):","metadata":{"id":"lvJJS73TvonJ"}},{"cell_type":"code","source":"sns.pairplot(penguins, hue=\"species\")","metadata":{"id":"ljRCK7aAvq9M","outputId":"dc7f23eb-e63c-4e7b-93a2-70d7ee503450"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Or histplot() to draw both bivariate and univariate histograms:","metadata":{"id":"K04PC4OUvx99"}},{"cell_type":"code","source":"sns.pairplot(penguins, kind=\"hist\")","metadata":{"id":"wPB9T2htvzhX","outputId":"5dca0601-0991-4185-8af7-78e5f982f5d9"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### [set_style](https://seaborn.pydata.org/generated/seaborn.set_style.html)\n\n*Set the parameters that control the general style of the plots.*\n\n*The style parameters control properties like the color of the background and whether a grid is enabled by default.*","metadata":{"id":"SLEeL3h52_9-"}},{"cell_type":"code","source":"sns.set_style(\"whitegrid\")\nsns.barplot(x=[\"A\", \"B\", \"C\"], y=[1, 3, 2])","metadata":{"id":"Y-_okVBSwAGe","outputId":"4458db70-033f-4500-b315-40a44d526fe4"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"You can also selectively override seabornâ€™s default parameter values:","metadata":{"id":"eBzkw45VwDro"}},{"cell_type":"code","source":"sns.set_style(\"darkgrid\", {\"grid.color\": \".6\", \"grid.linestyle\": \":\"})\nsns.lineplot(x=[\"A\", \"B\", \"C\"], y=[1, 3, 2])","metadata":{"id":"4tpnGMciwFMY","outputId":"74a7a034-81d8-424c-88f4-69c50717e2cf"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## sklearn.feature_extraction","metadata":{"id":"PKhpDoB_rHGB"}},{"cell_type":"markdown","source":"### [DictVectorizer](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.DictVectorizer.html?highlight=dictvectorizer)\n*Convert a collection of text documents to a matrix of token counts.*\n\n*This transformer turns lists of mappings (dict-like Examples) of feature names to feature values into Numpy arrays or scipy.sparse matrices for use with scikit-learn estimators.*","metadata":{"id":"VcQDhmL8xp_i"}},{"cell_type":"markdown","source":"#### Examples","metadata":{"id":"aEpbzZLGbbz8"}},{"cell_type":"code","source":"from sklearn.feature_extraction import DictVectorizer\nv = DictVectorizer(sparse=False)\nD = [{'foo': 1, 'bar': 2}, {'foo': 3, 'baz': 1}]\nX = v.fit_transform(D)\nX","metadata":{"id":"WlLY7hCc3agS","outputId":"2995c9a6-5c71-46c2-ac05-05b1b8028e74"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"v.inverse_transform(X) == [{'bar': 2.0, 'foo': 1.0},\n...                            {'baz': 1.0, 'foo': 3.0}]\nv.transform({'foo': 4, 'unseen_feature': 3})","metadata":{"id":"hQb9BXGh30bg","outputId":"1c7d9a82-82d6-4f3d-8520-91b8cc405259"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.feature_extraction import DictVectorizer\nfrom sklearn.feature_selection import SelectKBest, chi2\nv = DictVectorizer()\nD = [{'foo': 1, 'bar': 2}, {'foo': 3, 'baz': 1}]\nX = v.fit_transform(D)\nsupport = SelectKBest(chi2, k=2).fit(X, [0, 1])\nv.get_feature_names_out()","metadata":{"id":"v-PuFBzp3s5Q","outputId":"3b26db47-8cd0-4513-dfd6-2fc340a9e15e"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"v.restrict(support.get_support())","metadata":{"id":"N5rkzvPs4E5Q","outputId":"175f8c77-2e62-43bd-d808-171f1541a033"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"v.get_feature_names_out()","metadata":{"id":"o03jRMmS4QKw","outputId":"7fb1b8e6-cd9a-45eb-f0b0-791e3c2f8e48"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### Methods","metadata":{"id":"czam5ihJbet_"}},{"cell_type":"markdown","source":"##### fit -- <sub><sup>*Learn a vocabulary dictionary of all tokens in the raw documents*</sup></sub>","metadata":{"id":"f7gEExD3blQl"}},{"cell_type":"markdown","source":"##### transform -- <sub><sup>*Transform documents to document-term matrix.*</sup></sub>","metadata":{"id":"Cm3PFch1b0Ab"}},{"cell_type":"markdown","source":"##### fit_transform -- <sub><sup>*Learn the vocabulary dictionary and return document-term matrix.*</sup></sub>","metadata":{"id":"YM27rUAIb0qr"}},{"cell_type":"markdown","source":"### [FeatureHasher](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.FeatureHasher.html)\n\n*Implements feature hashing, aka the hashing trick.*\n\n*This class turns sequences of symbolic feature names (strings) into scipy.sparse matrices, using a hash function to compute the matrix column corresponding to a name. The hash function employed is the signed 32-bit version of Murmurhash3.*","metadata":{"id":"ynO_1viAxt0f"}},{"cell_type":"code","source":"from sklearn.feature_extraction import FeatureHasher\nh = FeatureHasher(n_features=10)\nD = [{'dog': 1, 'cat':2, 'elephant':4},{'dog': 2, 'run': 5}]\nf = h.transform(D)\nf.toarray()","metadata":{"id":"-x1n71sw4kja","outputId":"59305426-43bb-49cd-a74e-d8538f4c185e"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## sklearn.feature_extraction.text","metadata":{"id":"HSyklOxitwUS"}},{"cell_type":"markdown","source":"### [TfidfVectorizer](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html?highlight=tfidfvectorizer)\n\n*Convert a collection of raw documents to a matrix of TF-IDF features.*\n\n*Equivalent to CountVectorizer followed by TfidfTransformer.*\n","metadata":{"id":"I0kayOYLxmCk"}},{"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer\ncorpus = [\n    'This is the first document.',\n    'This document is the second document.',\n    'And this is the third one.',\n    'Is this the first document?',\n]\nvectorizer = TfidfVectorizer()\nX = vectorizer.fit_transform(corpus)\nvectorizer.get_feature_names_out()","metadata":{"id":"0QaQ72I39tOg","outputId":"e81afe48-fb89-4835-a22a-a37a8f67dd88"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(X.shape)","metadata":{"id":"ONA-oRGC9zg_","outputId":"9592a741-d0cf-4984-ac8f-5295f546b043"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### [CountVectorizer](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html)\n\n*Convert a collection of text documents to a matrix of token counts.*\n\n*This implementation produces a sparse representation of the counts using scipy.sparse.csr_matrix.*\n","metadata":{"id":"JAe--lNtxor3"}},{"cell_type":"markdown","source":"#### Examples","metadata":{"id":"u-OTrk1Z9N2K"}},{"cell_type":"code","source":"from sklearn.feature_extraction.text import CountVectorizer\ncorpus = [\n    'This is the first document.',\n    'This document is the second document.',\n    'And this is the third one.',\n    'Is this the first document?',\n]\nvectorizer = CountVectorizer()\nX = vectorizer.fit_transform(corpus)\nvectorizer.get_feature_names_out()","metadata":{"id":"XOTwixbe-AnV","outputId":"99f38f7f-c26b-4e1e-a9fe-c4d2286116da"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(X.toarray())","metadata":{"id":"Vd-5E68g-H5D","outputId":"492b7c70-a361-4661-d325-4445c4c6c5c5"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### Methods","metadata":{"id":"fmsPYYzL9W4W"}},{"cell_type":"markdown","source":"##### fit -- <sub><sup>*Learn a vocabulary dictionary of all tokens in the raw documents.*</sup></sub>\n","metadata":{"id":"D1Re4Ux49W4W"}},{"cell_type":"markdown","source":"##### transform -- <sub><sup>*Transform documents to document-term matrix.*</sup></sub>\n","metadata":{"id":"kun1Vd8n9W4W"}},{"cell_type":"markdown","source":"##### fit_transform -- <sub><sup>*learn the vocabulary dictionary and return document-term matrix.*</sup></sub>\n","metadata":{"id":"dYwru-L89W4X"}},{"cell_type":"markdown","source":"#### Attributes","metadata":{"id":"jET2_NQn9W4X"}},{"cell_type":"markdown","source":"##### vocabulary_ -- <sub><sup>*A mapping of terms to feature indices.*</sup></sub>\n","metadata":{"id":"ZHQxmdTQ9W4X"}},{"cell_type":"markdown","source":"## sklearn.feature_selection","metadata":{"id":"sCa-0Gyltx6f"}},{"cell_type":"markdown","source":"### [VarianceThreshold](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.VarianceThreshold.html?highlight=variancethreshold)\n\n*Feature selector that removes all low-variance features.*\n\n*This feature selection algorithm looks only at the features (X), not the desired outputs (y), and can thus be used for unsupervised learning.*","metadata":{"id":"FfU4G6ILxTf7"}},{"cell_type":"markdown","source":"#### Examples","metadata":{"id":"TvmsH76acFUs"}},{"cell_type":"code","source":"from sklearn.feature_selection import VarianceThreshold\nX = [[0, 2, 0, 3], [0, 1, 4, 3], [0, 1, 1, 3]]\nselector = VarianceThreshold()\nselector.fit_transform(X)","metadata":{"id":"5OqNpBgC-rij","outputId":"c608b54b-18a6-49cb-8e1e-15f80a6da3d8"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### Methods","metadata":{"id":"HsCPmq_tcHtg"}},{"cell_type":"markdown","source":"##### fit -- <sub><sup>*Learn empirical variances from X.*</sup></sub>\n","metadata":{"id":"g5DFt9OfcJvu"}},{"cell_type":"markdown","source":"##### transform-- <sub><sup>*Reduce X to the selected features.*</sup></sub>\n","metadata":{"id":"a2L9GZZicYO4"}},{"cell_type":"markdown","source":"##### fit_transform -- <sub><sup>*Fit to data, then transform it.*</sup></sub>","metadata":{"id":"C9_CajMEcY06"}},{"cell_type":"markdown","source":"### [SelectKBest](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SelectKBest.html?highlight=selectkbest)\n\n*Select features according to the k highest scores.*\n","metadata":{"id":"MX4sYRPdxbFM"}},{"cell_type":"markdown","source":"#### Examples","metadata":{"id":"kT_tu3xbezi9"}},{"cell_type":"code","source":"from sklearn.datasets import load_digits\nfrom sklearn.feature_selection import SelectKBest, chi2\nX, y = load_digits(return_X_y=True)\nX.shape","metadata":{"id":"GlmF9LH3-7WE","outputId":"b316208c-cfc6-454a-c8c9-00fd9279daef"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X_new = SelectKBest(chi2, k=20).fit_transform(X, y)\nX_new.shape","metadata":{"id":"6mvoM2BX--Xc","outputId":"a8e67088-dae6-47ba-93c2-18406c4e2f7d"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### Methods","metadata":{"id":"WN_C-os1e1zf"}},{"cell_type":"markdown","source":"##### fit -- <sub><sup>*Run score function on (X, y) and get the appropriate features.*</sup></sub>\n","metadata":{"id":"JCqeadVee1zf"}},{"cell_type":"markdown","source":"##### transform -- <sub><sup>*Reduce X to the selected features.*</sup></sub>\n","metadata":{"id":"gsmj1hiTe1zf"}},{"cell_type":"markdown","source":"##### fit_transform -- <sub><sup>*Fit to data, then transform it.*</sup></sub>\n","metadata":{"id":"eCiWIhkbe1zf"}},{"cell_type":"markdown","source":"##### get_feature_names_out -- <sub><sup>*Mask feature names according to selected features.*</sup></sub>","metadata":{"id":"omAQhevke1zf"}},{"cell_type":"markdown","source":"### [SelectPercentile](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SelectPercentile.html?highlight=selectpercentile)\n\n*Select features according to a percentile of the highest scores.*\n","metadata":{"id":"OPRXAU_Xxbvi"}},{"cell_type":"markdown","source":"#### Examples","metadata":{"id":"J51oUtyadNnH"}},{"cell_type":"code","source":"from sklearn.datasets import load_digits\nfrom sklearn.feature_selection import SelectPercentile, chi2\nX, y = load_digits(return_X_y=True)\nX.shape","metadata":{"id":"g6vdnG5C_Hvd","outputId":"a61f880b-791d-45f3-aa74-9f5e47efe18b"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X_new = SelectPercentile(chi2, percentile=10).fit_transform(X, y)\nX_new.shape","metadata":{"id":"2qRVi0F__Kvf","outputId":"a1f3e780-0a07-4d87-eb7d-a3fb4bbca331"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### Methods","metadata":{"id":"wWMti_I5degd"}},{"cell_type":"markdown","source":"##### fit -- <sub><sup>*Run score function on (X, y) and get the appropriate features.*</sup></sub>","metadata":{"id":"0w_40--AdkYD"}},{"cell_type":"markdown","source":"##### transform -- <sub><sup>*Reduce X to the selected features.*</sup></sub>\n","metadata":{"id":"i4xbMsNedqUZ"}},{"cell_type":"markdown","source":"##### fit_transform -- <sub><sup>*Fit to data, then transform it.*</sup></sub>\n","metadata":{"id":"qf5VJ2dFdq-d"}},{"cell_type":"markdown","source":"##### get_feature_names_out -- <sub><sup>*Mask feature names according to selected features.*</sup></sub>","metadata":{"id":"VmzSQ9SXh27q"}},{"cell_type":"markdown","source":"### [GenericUnivariateSelect](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.GenericUnivariateSelect.html?highlight=genericunivariateselect)\n\n*Univariate feature selector with configurable strategy.*\n","metadata":{"id":"GcBZyWMGxcYz"}},{"cell_type":"markdown","source":"#### Examples","metadata":{"id":"HC_PvpXId6Ga"}},{"cell_type":"code","source":"from sklearn.datasets import load_breast_cancer\nfrom sklearn.feature_selection import GenericUnivariateSelect, chi2\nX, y = load_breast_cancer(return_X_y=True)\nX.shape","metadata":{"id":"tDqi2bAD_UTj","outputId":"9c933b4d-2121-4ede-c1e6-35e53c0c7172"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"transformer = GenericUnivariateSelect(chi2, mode='k_best', param=20)\nX_new = transformer.fit_transform(X, y)\nX_new.shape","metadata":{"id":"8hv44WOT_XAy","outputId":"76296855-cf22-403e-aaf5-d7bf8f56507a"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### Methods","metadata":{"id":"OlAHZOrkeCJ0"}},{"cell_type":"markdown","source":"##### fit -- <sub><sup>*Run score function on (X, y) and get the appropriate features.*</sup></sub>","metadata":{"id":"xWZXcGRUiLk2"}},{"cell_type":"markdown","source":"##### transform -- <sub><sup>*Reduce X to the selected features.*</sup></sub>\n","metadata":{"id":"67ljcgkHiLk3"}},{"cell_type":"markdown","source":"##### fit_transform -- <sub><sup>*Fit to data, then transform it.*</sup></sub>\n","metadata":{"id":"v_omVs8UiLk3"}},{"cell_type":"markdown","source":"##### get_feature_names_out -- <sub><sup>*Mask feature names according to selected features.*</sup></sub>","metadata":{"id":"Ncx1GZBQiLk3"}},{"cell_type":"markdown","source":"### [mutual_info_regression](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.mutual_info_regression.html?highlight=mutual_info_regression)\n\n*Estimate mutual information for a continuous target variable.*\n\n*Mutual information (MI) [1] between two random variables is a non-negative value, which measures the dependency between the variables. It is equal to zero if and only if two random variables are independent, and higher values mean higher dependency.*","metadata":{"id":"0LOHOkE9xdCv"}},{"cell_type":"markdown","source":"### [mutual_info_classif](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.mutual_info_classif.html?highlight=mutual_info_classif)\n\n*Estimate mutual information for a discrete target variable.*\n\n*Mutual information (MI) [1] between two random variables is a non-negative value, which measures the dependency between the variables. It is equal to zero if and only if two random variables are independent, and higher values mean higher dependency.*","metadata":{"id":"eD6QGpeSxdsX"}},{"cell_type":"markdown","source":"### [RFE](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.RFE.html)\n\n*Feature ranking with recursive feature elimination.*","metadata":{"id":"rk4OikW-xeU2"}},{"cell_type":"markdown","source":"#### Examples","metadata":{"id":"cnV43dJteHqR"}},{"cell_type":"code","source":"from sklearn.datasets import make_friedman1\nfrom sklearn.feature_selection import RFE\nfrom sklearn.svm import SVR\nX, y = make_friedman1(n_samples=50, n_features=10, random_state=0)\nestimator = SVR(kernel=\"linear\")\nselector = RFE(estimator, n_features_to_select=5, step=1)\nselector = selector.fit(X, y)\nselector.support_","metadata":{"id":"FJWeuWmaApYA","outputId":"69ad60bc-23bf-4135-c1ae-44cd9fda0230"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"selector.ranking_","metadata":{"id":"lB23pW6XAvSo","outputId":"81626177-3963-40d0-963d-7a92088f3470"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### Methods","metadata":{"id":"gtGJyyjSeLDh"}},{"cell_type":"markdown","source":"##### fit -- <sub><sup>*Fit the RFE model and then the underlying estimator on the selected features.*</sup></sub>\n","metadata":{"id":"6ktDRmW9eLDi"}},{"cell_type":"markdown","source":"##### transform -- <sub><sup>*Reduce X to the selected features.*</sup></sub>\n","metadata":{"id":"bilzJKPqFFv4"}},{"cell_type":"markdown","source":"##### fit_transform -- <sub><sup>*Fit to data, then transform it.*</sup></sub>\n","metadata":{"id":"KtPX5jqvFFv4"}},{"cell_type":"markdown","source":"##### get_feature_names_out -- <sub><sup>*Mask feature names according to selected features.*</sup></sub>","metadata":{"id":"VHOu-d4mFFv5"}},{"cell_type":"markdown","source":"### [RFECV](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.RFECV.html)\n\n*Recursive feature elimination with cross-validation to select the number of features.*","metadata":{"id":"9XIY-dg3xe94"}},{"cell_type":"markdown","source":"#### Examples","metadata":{"id":"MIAbHfiSeRW6"}},{"cell_type":"code","source":"from sklearn.datasets import make_friedman1\nfrom sklearn.feature_selection import RFECV\nfrom sklearn.svm import SVR\nX, y = make_friedman1(n_samples=50, n_features=10, random_state=0)\nestimator = SVR(kernel=\"linear\")\nselector = RFECV(estimator, step=1, cv=5)\nselector = selector.fit(X, y)\nselector.support_","metadata":{"id":"yr0P1GUiA9fD","outputId":"1d65851e-78ff-47d2-da59-91aef211a286"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"selector.ranking_","metadata":{"id":"VeTdR3Z0BA2q","outputId":"aca23072-c351-4364-ed94-67328f08ad5c"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### Methods","metadata":{"id":"-UnIC199eTu0"}},{"cell_type":"markdown","source":"##### fit -- <sub><sup>*Fit the RFE model and automatically tune the number of selected features.*</sup></sub>\n","metadata":{"id":"wD-sCss1eTu0"}},{"cell_type":"markdown","source":"##### transform -- <sub><sup>*Reduce X to the selected features.*</sup></sub>\n","metadata":{"id":"tSJuwja1FbtJ"}},{"cell_type":"markdown","source":"##### fit_transform -- <sub><sup>*Fit to data, then transform it.*</sup></sub>\n","metadata":{"id":"XFrjLPRuFbtJ"}},{"cell_type":"markdown","source":"##### get_feature_names_out -- <sub><sup>*Mask feature names according to selected features.*</sup></sub>","metadata":{"id":"Rq9AHQneFbtJ"}},{"cell_type":"markdown","source":"### [SelectFromModel](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SelectFromModel.html)\n\n*Meta-transformer for selecting features based on importance weights.*","metadata":{"id":"uQbr5-T5xfn7"}},{"cell_type":"markdown","source":"#### Examples","metadata":{"id":"xplJU_J4edVi"}},{"cell_type":"code","source":"from sklearn.feature_selection import SelectFromModel\nfrom sklearn.linear_model import LogisticRegression\nX = [[ 0.87, -1.34,  0.31 ],\n     [-2.79, -0.02, -0.85 ],\n     [-1.34, -0.48, -2.55 ],\n     [ 1.92,  1.48,  0.65 ]]\ny = [0, 1, 0, 1]\nselector = SelectFromModel(estimator=LogisticRegression()).fit(X, y)\nselector.estimator_.coef_","metadata":{"id":"QcXz36x7BJ_O","outputId":"cac2a7ce-18ac-4b56-a846-a0e5cd06c0f8"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"selector.threshold_","metadata":{"id":"F6vr3QxzBNsM","outputId":"7980e33b-edd9-42ad-ab4c-b89f09974ecd"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"selector.get_support()","metadata":{"id":"zbD9iKk5BOM3","outputId":"0962e46a-4fff-4909-ff98-c2a40f787023"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"selector.transform(X)","metadata":{"id":"7lKh00jmBOmP","outputId":"a8baf532-78fe-4baf-9af8-ba221d98cbb4"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### Methods","metadata":{"id":"hL8NHdNbegT7"}},{"cell_type":"markdown","source":"##### fit -- <sub><sup>*Fit the SelectFromModel meta-transformer.*</sup></sub>\n","metadata":{"id":"kXzTJvjtegT7"}},{"cell_type":"markdown","source":"##### transform -- <sub><sup>*Reduce X to the selected features.*</sup></sub>\n","metadata":{"id":"uOGX5YP7F0xy"}},{"cell_type":"markdown","source":"##### fit_transform -- <sub><sup>*Fit to data, then transform it.*</sup></sub>\n","metadata":{"id":"i7yv_uiCF0xy"}},{"cell_type":"markdown","source":"##### get_feature_names_out -- <sub><sup>*Mask feature names according to selected features.*</sup></sub>","metadata":{"id":"QGxfERk1F0xz"}},{"cell_type":"markdown","source":"### [SequentialFeatureSelector](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SequentialFeatureSelector.html)\n\n*Transformer that performs Sequential Feature Selection.*\n\n*This Sequential Feature Selector adds (forward selection) or removes (backward selection) features to form a feature subset in a greedy fashion. At each stage, this estimator chooses the best feature to add or remove based on the cross-validation score of an estimator. In the case of unsupervised learning, this Sequential Feature Selector looks only at the features (X), not the desired outputs (y).*","metadata":{"id":"13waq-LMxgRH"}},{"cell_type":"markdown","source":"#### Examples","metadata":{"id":"44E1BnPaei-B"}},{"cell_type":"code","source":"from sklearn.feature_selection import SequentialFeatureSelector\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.datasets import load_iris\nX, y = load_iris(return_X_y=True)\nknn = KNeighborsClassifier(n_neighbors=3)\nsfs = SequentialFeatureSelector(knn, n_features_to_select=3)\nsfs.fit(X, y)","metadata":{"id":"fCFufizaBZpf","outputId":"c1f0de7d-6e11-4936-a95a-78bac31c6dc9"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"sfs.get_support()","metadata":{"id":"ed_L-lkXBdBc","outputId":"6e486501-96a7-4b4b-a0d5-f878a71297be"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"sfs.transform(X).shape","metadata":{"id":"So8UBgMFBdZ3","outputId":"3e2f0fc5-7afc-4bca-a473-04b83705fa77"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### Methods","metadata":{"id":"7mC3LlvzelXZ"}},{"cell_type":"markdown","source":"##### fit -- <sub><sup>*Learn the features to select from X.*</sup></sub>\n","metadata":{"id":"I2GqIyeJelXZ"}},{"cell_type":"markdown","source":"##### transform -- <sub><sup>*Reduce X to the selected features.*</sup></sub>\n","metadata":{"id":"5QqnRoBOIEGL"}},{"cell_type":"markdown","source":"##### fit_transform -- <sub><sup>*Fit to data, then transform it.*</sup></sub>\n","metadata":{"id":"Xj3Yc0R8IEGL"}},{"cell_type":"markdown","source":"##### get_feature_names_out -- <sub><sup>*Mask feature names according to selected features.*</sup></sub>","metadata":{"id":"1eCSHAfxIEGL"}},{"cell_type":"markdown","source":"## sklearn.impute","metadata":{"id":"DDGA3alTt3pU"}},{"cell_type":"markdown","source":"### [SimpleImputer](https://scikit-learn.org/stable/modules/generated/sklearn.impute.SimpleImputer.html)\n\n*Imputation transformer for completing missing values.*\n","metadata":{"id":"i_eI2ZoSxJe_"}},{"cell_type":"markdown","source":"#### Examples","metadata":{"id":"X16mTxXffK_b"}},{"cell_type":"code","source":"import numpy as np\nfrom sklearn.impute import SimpleImputer\nimp_mean = SimpleImputer(missing_values=np.nan, strategy='mean')\nimp_mean.fit([[7, 2, 3], [4, np.nan, 6], [10, 5, 9]])\n\nX = [[np.nan, 2, 3], [4, np.nan, 6], [10, np.nan, 9]]\nprint(imp_mean.transform(X))","metadata":{"id":"tPRBud-SBure","outputId":"0544d375-2172-4842-eb15-1bc099470bed"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### Methods","metadata":{"id":"wVgHwK4UfYJA"}},{"cell_type":"markdown","source":"##### fit -- <sub><sup>*Fit the imputer on X.*</sup></sub>","metadata":{"id":"RpaicAscfNC7"}},{"cell_type":"markdown","source":"##### transform -- <sub><sup>*Impute all missing values in X.*</sup></sub>\n","metadata":{"id":"jLnKa6V5Iv8Y"}},{"cell_type":"markdown","source":"##### fit_transform -- <sub><sup>*Fit to data, then transform it.*</sup></sub>\n","metadata":{"id":"M9yQbaEpIv8Y"}},{"cell_type":"markdown","source":"##### statistics_ -- <sub><sup>*The imputation fill value for each feature.*</sup></sub>\n","metadata":{"id":"dTrkY4gJfV5I"}},{"cell_type":"markdown","source":"### [KNNImputer](https://scikit-learn.org/stable/modules/generated/sklearn.impute.KNNImputer.html)\n\n*Imputation for completing missing values using k-Nearest Neighbors.*\n\n*Each sampleâ€™s missing values are imputed using the mean value from n_neighbors nearest neighbors found in the training set. Two samples are close if the features that neither is missing are close.*\n","metadata":{"id":"d_RrnTWQxL6O"}},{"cell_type":"markdown","source":"#### Examples","metadata":{"id":"Utj2-Q2NgyFt"}},{"cell_type":"code","source":"import numpy as np\nfrom sklearn.impute import KNNImputer\nX = [[1, 2, np.nan], [3, 4, 3], [np.nan, 6, 5], [8, 8, 7]]\nimputer = KNNImputer(n_neighbors=2)\nimputer.fit_transform(X)","metadata":{"id":"cZ5ooawACDJC","outputId":"7c9ec23e-f5ed-4434-8843-624c455003e9"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### Methods","metadata":{"id":"GHXMhHpqg0wM"}},{"cell_type":"markdown","source":"##### fit -- <sub><sup>*Fit the imputer on X.*</sup></sub>","metadata":{"id":"I95us34jJUdg"}},{"cell_type":"markdown","source":"##### transform -- <sub><sup>*Impute all missing values in X.*</sup></sub>\n","metadata":{"id":"L05L9bDYJUdh"}},{"cell_type":"markdown","source":"##### fit_transform -- <sub><sup>*Fit to data, then transform it.*</sup></sub>\n","metadata":{"id":"dFm2xgYnJUdh"}},{"cell_type":"markdown","source":"### [MissingIndicator](https://scikit-learn.org/stable/modules/generated/sklearn.impute.MissingIndicator.html)\n\n*Binary indicators for missing values.*\n\n*Note that this component typically should not be used in a vanilla Pipeline consisting of transformers and a classifier, but rather could be added using a FeatureUnion or ColumnTransformer.*","metadata":{"id":"mFSSpU-1xMmP"}},{"cell_type":"markdown","source":"#### Examples","metadata":{"id":"BynSXwpLg9zO"}},{"cell_type":"code","source":"import numpy as np\nfrom sklearn.impute import MissingIndicator\nX1 = np.array([[np.nan, 1, 3],\n               [4, 0, np.nan],\n               [8, 1, 0]])\nX2 = np.array([[5, 1, np.nan],\n               [np.nan, 2, 3],\n               [2, 4, 0]])\nindicator = MissingIndicator()\nindicator.fit(X1)\n\nX2_tr = indicator.transform(X2)\nX2_tr","metadata":{"id":"GlridqnsCTFz","outputId":"30ea1258-c95f-4c01-86ed-ecce5cf4417e"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### Methods","metadata":{"id":"9nHJSsnHhFao"}},{"cell_type":"markdown","source":"## sklearn.preprocessing","metadata":{"id":"4Cu0DZJZt6cO"}},{"cell_type":"markdown","source":"### [StandardScaler](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html)\n\n*Standardize features by removing the mean and scaling to unit variance.*\n\n*The standard score of a sample x is calculated as: z = (x - u) / s*\n\n*where u is the mean of the training samples or zero if with_mean=False, and s is the standard deviation of the training samples or one if with_std=False.*\n","metadata":{"id":"Hv38SW_nw8BD"}},{"cell_type":"markdown","source":"#### Examples","metadata":{"id":"On5i5fUMhOeU"}},{"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\ndata = [[0, 0], [0, 0], [1, 1], [1, 1]]\nscaler = StandardScaler()\nprint(scaler.fit(data))","metadata":{"id":"Ji-TQZXjCjU_","outputId":"d86967a4-7670-451f-e3b7-f90e902ff0d5"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(scaler.mean_)","metadata":{"id":"_l8VN33OCmvg","outputId":"473a774b-94e7-47cb-faab-dadf3686d1c8"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(scaler.transform(data))","metadata":{"id":"X88-OULDCnK0","outputId":"09a6d15b-a092-44e1-baf0-fe58b0e37a5f"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(scaler.transform([[2, 2]]))","metadata":{"id":"h1TTekQaCnuC","outputId":"6c6a4990-eb01-4d1f-b3af-1503841ee99c"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### Methods","metadata":{"id":"b_A60U_IhQge"}},{"cell_type":"markdown","source":"##### fit -- <sub><sup>*Compute the mean and std to be used for later scaling.*</sup></sub>\n","metadata":{"id":"yT9_8GWRhQge"}},{"cell_type":"markdown","source":"##### partial_fit -- <sub><sup>*Online computation of mean and std on X for later scaling.*</sup></sub>","metadata":{"id":"XeCG3r7EhSLx"}},{"cell_type":"markdown","source":"##### transform -- <sub><sup>*Perform standardization by centering and scaling.*</sup></sub>\n","metadata":{"id":"bWc02oayhQge"}},{"cell_type":"markdown","source":"##### fit_transform -- <sub><sup>*Fit to data, then transform it.*</sup></sub>\n\n","metadata":{"id":"GSIyE96DhQge"}},{"cell_type":"markdown","source":"### [MinMaxScaler](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html)\n\n*Transform features by scaling each feature to a given range.*\n\n*This estimator scales and translates each feature individually such that it is in the given range on the training set, e.g. between zero and one.*\n\n\n\n","metadata":{"id":"9TZbYLomw-o8"}},{"cell_type":"markdown","source":"#### Examples","metadata":{"id":"8iA1L-94hZA1"}},{"cell_type":"code","source":"from sklearn.preprocessing import MinMaxScaler\ndata = [[-1, 2], [-0.5, 6], [0, 10], [1, 18]]\nscaler = MinMaxScaler()\nprint(scaler.fit(data))","metadata":{"id":"JSIoS9A7C3Dz","outputId":"d49fac58-b675-44ab-c381-a7d9c3cd2f31"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(scaler.data_max_)","metadata":{"id":"zF9NypseC9j-","outputId":"4fa64603-549a-4595-d95d-ad82ca0aaf02"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(scaler.transform(data))","metadata":{"id":"IjEg2ZMqC-IQ","outputId":"b127372c-db92-4128-d0af-8de1e0bc0e5f"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(scaler.transform([[2, 2]]))","metadata":{"id":"O3P5d5M7C-sd","outputId":"825cad3c-e1de-42d2-d1a4-e1bdf939b7ac"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### Methods","metadata":{"id":"aqPwkt33hbt_"}},{"cell_type":"markdown","source":"##### fit -- <sub><sup>*Compute the minimum and maximum to be used for later scaling.*</sup></sub>\n","metadata":{"id":"EDYqrvZShbt_"}},{"cell_type":"markdown","source":"##### partial_fit -- <sub><sup>*Online computation of min and max on X for later scaling.*</sup></sub>","metadata":{"id":"VYm5IgxYhbt_"}},{"cell_type":"markdown","source":"##### transform -- <sub><sup>*Scale features of X according to feature_range.*</sup></sub>\n","metadata":{"id":"-R5g8KvlhbuA"}},{"cell_type":"markdown","source":"##### fit_transform -- <sub><sup>*Fit to data, then transform it.*</sup></sub>\n\n","metadata":{"id":"_KgSKUe4hbuA"}},{"cell_type":"markdown","source":"### [MaxAbsScaler](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MaxAbsScaler.html)\n\n*Scale each feature by its maximum absolute value.*\n\n*This estimator scales and translates each feature individually such that the maximal absolute value of each feature in the training set will be 1.0. It does not shift/center the data, and thus does not destroy any sparsity.*","metadata":{"id":"kb6IyBCHw_Up"}},{"cell_type":"markdown","source":"#### Examples","metadata":{"id":"pGmdnHVkhdXj"}},{"cell_type":"code","source":"from sklearn.preprocessing import MaxAbsScaler\nX = [[ 1., -1.,  2.],\n     [ 2.,  0.,  0.],\n     [ 0.,  1., -1.]]\ntransformer = MaxAbsScaler().fit(X)\ntransformer","metadata":{"id":"vcLdmlGVD3f3","outputId":"6d2153ae-2dcc-4a49-c254-541fc1dad90b"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"transformer.transform(X)","metadata":{"id":"Kc-T9ZtsD6sG","outputId":"b9a6bbf7-4ebc-400f-e6f3-7720918bc4e5"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### Methods","metadata":{"id":"sVS0pcy1hft8"}},{"cell_type":"markdown","source":"##### fit -- <sub><sup>*Compute the maximum absolute value to be used for later scaling.*</sup></sub>\n","metadata":{"id":"VhMxOgM0hft9"}},{"cell_type":"markdown","source":"##### partial_fit -- <sub><sup>*Online computation of max absolute value of X for later scaling.*</sup></sub>","metadata":{"id":"ix9ZfnJ9hft9"}},{"cell_type":"markdown","source":"##### transform -- <sub><sup>*Scale the data.*</sup></sub>\n","metadata":{"id":"9cM9nS7mhft9"}},{"cell_type":"markdown","source":"##### fit_transform -- <sub><sup>*Fit to data, then transform it.*</sup></sub>\n\n","metadata":{"id":"n_C9pgZFhft9"}},{"cell_type":"markdown","source":"### [FunctionTransformer](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.FunctionTransformer.html)\n\n*Constructs a transformer from an arbitrary callable.*\n\n*A FunctionTransformer forwards its X (and optionally y) arguments to a user-defined function or function object and returns the result of this function. This is useful for stateless transformations such as taking the log of frequencies, doing custom scaling, etc.*","metadata":{"id":"EAsCwV51w_9d"}},{"cell_type":"markdown","source":"#### Examples","metadata":{"id":"QsZIBBAvnsf-"}},{"cell_type":"code","source":"import numpy as np\nfrom sklearn.preprocessing import FunctionTransformer\ntransformer = FunctionTransformer(np.log1p)\nX = np.array([[0, 1], [2, 3]])\ntransformer.transform(X)","metadata":{"id":"zVayQj-VEDxM","outputId":"e994e6ae-bbb2-4f2c-cfaf-18592ddcf8e9"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### Methods","metadata":{"id":"g-yusDe5nvDQ"}},{"cell_type":"markdown","source":"##### fit -- <sub><sup>*Fit transformer by checking X.*</sup></sub>","metadata":{"id":"-r-Jc-TcnvDQ"}},{"cell_type":"markdown","source":"##### transform -- <sub><sup>*Transform X using the forward function.*</sup></sub>","metadata":{"id":"JrejIlBPnvDQ"}},{"cell_type":"markdown","source":"##### fit_transform -- <sub><sup>*Fit to data, then transform it.*</sup></sub>","metadata":{"id":"PrD-Y4krnvDR"}},{"cell_type":"markdown","source":"### [PolynomialFeatures](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.PolynomialFeatures.html)\n\n*Generate polynomial and interaction features.*\n\n*Generate a new feature matrix consisting of all polynomial combinations of the features with degree less than or equal to the specified degree. For example, if an input sample is two dimensional and of the form [a, b], the degree-2 polynomial features are [1, a, b, a^2, ab, b^2].*","metadata":{"id":"0VrDGOrYxApN"}},{"cell_type":"markdown","source":"#### Examples","metadata":{"id":"esSxrbLiercx"}},{"cell_type":"code","source":"import numpy as np\nfrom sklearn.preprocessing import PolynomialFeatures\nX = np.arange(6).reshape(3, 2)\nX","metadata":{"id":"m0GwE46PENor","outputId":"fcd7d7f7-44ac-4608-bcce-3c5bcdf5ef41"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"poly = PolynomialFeatures(2)\npoly.fit_transform(X)\n","metadata":{"id":"RyqKhYmWEQ-j","outputId":"c8393c84-297f-44e5-fd2f-0f054d8e7276"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"poly = PolynomialFeatures(interaction_only=True)\npoly.fit_transform(X)","metadata":{"id":"92CGMrTkES_N","outputId":"baa0be57-10c6-40c0-d76e-af4b40cbb6f7"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### Methods","metadata":{"id":"rCPk3TM9et6Z"}},{"cell_type":"markdown","source":"##### fit -- <sub><sup>*Compute number of output features.*</sup></sub>\n","metadata":{"id":"2WZBErKOet6Z"}},{"cell_type":"markdown","source":"##### transform -- <sub><sup>*Transform data to polynomial features.*</sup></sub>\n","metadata":{"id":"Akkhd_upet6Z"}},{"cell_type":"markdown","source":"##### fit_transform -- <sub><sup>*Fit to data, then transform it.*</sup></sub>\n","metadata":{"id":"JLDqdIjCet6a"}},{"cell_type":"markdown","source":"##### get_feature_names_out -- <sub><sup>*DEPRECATED.  Do not use.*</sup></sub>","metadata":{"id":"22augeB-et6a"}},{"cell_type":"markdown","source":"### [KBinsDiscretizer](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.KBinsDiscretizer.html)\n\n*Bin continuous data into intervals.*","metadata":{"id":"2ZipkIVgxBZu"}},{"cell_type":"markdown","source":"#### Examples","metadata":{"id":"HYSMP9dpn-tB"}},{"cell_type":"code","source":"from sklearn.preprocessing import KBinsDiscretizer\nX = [[-2, 1, -4,   -1],\n     [-1, 2, -3, -0.5],\n     [ 0, 3, -2,  0.5],\n     [ 1, 4, -1,    2]]\nest = KBinsDiscretizer(n_bins=3, encode='ordinal', strategy='uniform')\nest.fit(X)","metadata":{"id":"42jCWOUDEozj","outputId":"c8461a7b-1640-45ba-f976-2b87ce66074c"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"Xt = est.transform(X)\nXt","metadata":{"id":"Krz92BnDEtWT","outputId":"c560c695-eaf9-47c1-e3f7-60f043177079"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"est.bin_edges_[0]","metadata":{"id":"AY93AWBJExRu","outputId":"4de24796-2e2e-42ef-d112-868f5d487015"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"est.inverse_transform(Xt)","metadata":{"id":"RyeqYcY9Exxt","outputId":"e57513ea-12f2-4bf1-ab2e-767a06d5554c"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### Methods","metadata":{"id":"sriLOF0ooBlX"}},{"cell_type":"markdown","source":"##### fit -- <sub><sup>*Fit the estimator.*</sup></sub>","metadata":{"id":"PR4Kc_wToBlX"}},{"cell_type":"markdown","source":"##### transform -- <sub><sup>*Discretize the data.*</sup></sub>","metadata":{"id":"7pKTod5aoBlX"}},{"cell_type":"markdown","source":"##### fit_transform -- <sub><sup>*Fit to data, then transform it.*</sup></sub>","metadata":{"id":"yooWe62SoBlX"}},{"cell_type":"markdown","source":"### [OneHotEncoder](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html)\n\n*Encode categorical features as a one-hot numeric array.*\n\n*The input to this transformer should be an array-like of integers or strings, denoting the values taken on by categorical (discrete) features. The features are encoded using a one-hot (aka â€˜one-of-Kâ€™ or â€˜dummyâ€™) encoding scheme. This creates a binary column for each category and returns a sparse matrix or dense array (depending on the sparse parameter)*","metadata":{"id":"DfSiXUjkxCPq"}},{"cell_type":"markdown","source":"#### Examples","metadata":{"id":"QeojuGrimoql"}},{"cell_type":"code","source":"from sklearn.preprocessing import OneHotEncoder\nenc = OneHotEncoder(handle_unknown='ignore')\nX = [['Male', 1], ['Female', 3], ['Female', 2]]\nenc.fit(X)","metadata":{"id":"XPLNsfk5E6Dl","outputId":"8a5fdb83-1f72-4337-d172-3c7112f8f20c"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"enc.categories_","metadata":{"id":"MULfBedDE9iP","outputId":"aabe46a2-f039-4417-f690-f586b255fbb0"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"enc.transform([['Female', 1], ['Male', 4]]).toarray()","metadata":{"id":"ZIw6WyM8E99a","outputId":"f09a2fad-63da-4855-f4cf-f90294911cdd"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"enc.inverse_transform([[0, 1, 1, 0, 0], [0, 0, 0, 1, 0]])","metadata":{"id":"drEoj19HE-Yu","outputId":"4807e3d6-93cd-4b5b-fa07-46cd2e63d1b3"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"enc.get_feature_names_out(['gender', 'group'])","metadata":{"id":"n1G5mO1XE-1Z","outputId":"4e61830c-75ba-4c6a-b4e7-96597a073a1d"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"One can always drop the first column for each feature.","metadata":{"id":"G3SPdUEhFZbl"}},{"cell_type":"code","source":"drop_enc = OneHotEncoder(drop='first').fit(X)\ndrop_enc.categories_","metadata":{"id":"6TEMtCufFPzE","outputId":"336b8838-939f-42af-c580-ad732d076838"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"drop_enc.transform([['Female', 1], ['Male', 2]]).toarray()","metadata":{"id":"N0lzixWLFUdo","outputId":"8b56b34a-d2c4-4d8a-d7f4-7bf0510f45ed"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Or drop a column for feature only having 2 categories.","metadata":{"id":"nSH0TkQrHODF"}},{"cell_type":"code","source":"drop_binary_enc = OneHotEncoder(drop='if_binary').fit(X)\ndrop_binary_enc.categories_","metadata":{"id":"bSYYBje3FfeH","outputId":"6662c9f8-2474-48a3-e5af-18085a8b2af0"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"drop_binary_enc.transform([['Female', 1], ['Male', 2]]).toarray()","metadata":{"id":"xd1YuOmgISb1","outputId":"8e4c0125-4adf-40cb-c0b5-225d8d2006b8"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### Methods","metadata":{"id":"kLNKRxUFmsSc"}},{"cell_type":"markdown","source":"##### fit -- <sub><sup>*Fit OneHotEncoder to X.*</sup></sub>","metadata":{"id":"UGVrj4BYmsSd"}},{"cell_type":"markdown","source":"##### transform -- <sub><sup>*Transform X using one-hot encoding.*</sup></sub>","metadata":{"id":"OIj-GWvXmsSd"}},{"cell_type":"markdown","source":"##### fit_transform -- <sub><sup>*Fit OneHotEncoder to X, then transform X.*</sup></sub>","metadata":{"id":"d5py4f9MmsSd"}},{"cell_type":"markdown","source":"#### Attributes","metadata":{"id":"ZdJd-XprSfiI"}},{"cell_type":"markdown","source":"##### categories_ -- <sub><sup>*The categories of each feature determined during fitting (in order of the features in X and corresponding with the output of transform).*</sup></sub>","metadata":{"id":"h6uiwF3kmsSd"}},{"cell_type":"markdown","source":"### [LabelEncoder](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html)\n\n*Encode target labels with value between 0 and n_classes-1.*\n\n*This transformer should be used to encode target values, i.e. y, and not the input X.*","metadata":{"id":"XDI0GotTxC3M"}},{"cell_type":"markdown","source":"#### Examples","metadata":{"id":"MFjNlPsZmvIs"}},{"cell_type":"code","source":"from sklearn import preprocessing\nle = preprocessing.LabelEncoder()\nle.fit([1, 2, 2, 6])","metadata":{"id":"5N1qCaurIkjR","outputId":"d9d59c90-4e0e-4a04-d5bb-77dec35f825e"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"le.classes_","metadata":{"id":"2hGv1ypVIoXT","outputId":"c1f3053b-fa3b-4b4d-bf96-a084b0504a15"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"le.transform([1, 1, 2, 6])","metadata":{"id":"ckn2pSyYIozT","outputId":"81cfee3e-ef56-46d7-811c-d4620222af37"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"le.inverse_transform([0, 0, 1, 2])","metadata":{"id":"uDqnoEZsIpM-","outputId":"d8a99c34-b027-43f0-9a92-4f6eab22237a"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"It can also be used to transform non-numerical labels (as long as they are hashable and comparable) to numerical labels.","metadata":{"id":"4BlU6yhNIzBa"}},{"cell_type":"code","source":"le = preprocessing.LabelEncoder()\nle.fit([\"paris\", \"paris\", \"tokyo\", \"amsterdam\"])","metadata":{"id":"ihV35ya3I37X","outputId":"52aabf8f-a1c0-4015-b199-d7570ce84ebe"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"list(le.classes_)","metadata":{"id":"1-y7nXueI5K0","outputId":"dcf5e8b5-0e91-40bc-cc49-de45bb77d2f6"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"le.transform([\"tokyo\", \"tokyo\", \"paris\"])","metadata":{"id":"QnGuWOVyI9dS","outputId":"08579abd-ccd6-4118-8fd7-e737f3e9f03b"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"list(le.inverse_transform([2, 2, 1]))","metadata":{"id":"lDkD0-KVI954","outputId":"ad56e802-dbc3-4065-82d1-d1c4fcd49281"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### Methods","metadata":{"id":"jCUAt0q4my0_"}},{"cell_type":"markdown","source":"##### fit -- <sub><sup>*Fit label encoder.*</sup></sub>","metadata":{"id":"SfqhU-Ldmy0_"}},{"cell_type":"markdown","source":"##### transform -- <sub><sup>*Transform labels to normalized encoding.*</sup></sub>","metadata":{"id":"W8MxypZjmy1A"}},{"cell_type":"markdown","source":"##### fit_transform -- <sub><sup>*Fit label encoder and return encoded labels.*</sup></sub>","metadata":{"id":"7WA5kFMemy1A"}},{"cell_type":"markdown","source":"#### Attributes","metadata":{"id":"Rhw9HaNQTwMq"}},{"cell_type":"markdown","source":"##### classes_ -- <sub><sup>*Holds the label for each class.*</sup></sub>","metadata":{"id":"FnmE15ChTuRb"}},{"cell_type":"markdown","source":"### [OrdinalEncoder](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OrdinalEncoder.html)\n\n*Encode categorical features as an integer array.*\n\n*The input to this transformer should be an array-like of integers or strings, denoting the values taken on by categorical (discrete) features. The features are converted to ordinal integers. This results in a single column of integers (0 to n_categories - 1) per feature.*\n","metadata":{"id":"ex0CBtFuxDfA"}},{"cell_type":"markdown","source":"#### Examples","metadata":{"id":"kmb8NRb1maEU"}},{"cell_type":"code","source":"from sklearn.preprocessing import OrdinalEncoder\nenc = OrdinalEncoder()\nX = [['Male', 1], ['Female', 3], ['Female', 2]]\nenc.fit(X)","metadata":{"id":"5Zdnr5xoJK5F","outputId":"6006e567-ba4f-4588-c449-67764344ff03"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"enc.categories_","metadata":{"id":"UjF4698VJOQe","outputId":"96810a93-58ba-475d-a48d-ae4d40c67236"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"enc.transform([['Female', 3], ['Male', 1]])","metadata":{"id":"9h986cofJOtM","outputId":"33600957-98af-43b1-a253-9af4fabfcc06"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"enc.inverse_transform([[1, 0], [0, 1]])","metadata":{"id":"CYPiq0XzJQXh","outputId":"3e1f2c4b-1a5d-4d5c-e040-eb279efa0376"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"By default, OrdinalEncoder is lenient towards missing values by propagating them.","metadata":{"id":"8iUXUttHJXPI"}},{"cell_type":"code","source":"import numpy as np\nX = [['Male', 1], ['Female', 3], ['Female', np.nan]]\nenc.fit_transform(X)","metadata":{"id":"hTHl-_mNJYPM","outputId":"2aa5335d-4e3b-49a5-9cd6-1e952097928d"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### Methods","metadata":{"id":"RIDwCnqhanLw"}},{"cell_type":"markdown","source":"##### fit -- <sub><sup>*Fit ordinal encoder.*</sup></sub>","metadata":{"id":"ZCJJal_yanLx"}},{"cell_type":"markdown","source":"##### transform -- <sub><sup>*Transform X to ordinal codes.*</sup></sub>","metadata":{"id":"XJRsy7HzanLx"}},{"cell_type":"markdown","source":"##### fit_transform -- <sub><sup>*Fit to data, then transform it.*</sup></sub>","metadata":{"id":"LVevyy4GanLx"}},{"cell_type":"markdown","source":"#### Attributes","metadata":{"id":"5uRQGrbDanLx"}},{"cell_type":"markdown","source":"##### categories_ -- <sub><sup>*The categories of each feature determined during fit (in order of the features in X and corresponding with the output of transform).*</sup></sub>","metadata":{"id":"lxS0RnaFanLx"}},{"cell_type":"markdown","source":"### [LabelBinarizer](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelBinarizer.html)\n\n*Binarize labels in a one-vs-all fashion.*\n\n*Several regression and binary classification algorithms are available in scikit-learn. A simple way to extend these algorithms to the multi-class classification case is to use the so-called one-vs-all scheme.*","metadata":{"id":"6CVTiYZuxEIW"}},{"cell_type":"markdown","source":"#### Examples","metadata":{"id":"fLTNqkrHnCpg"}},{"cell_type":"code","source":"from sklearn import preprocessing\nlb = preprocessing.LabelBinarizer()\nlb.fit([1, 2, 6, 4, 2])","metadata":{"id":"XrxIafNiJ2qG","outputId":"891aaa06-93fe-4824-8992-ec60443f2d41"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"lb.classes_","metadata":{"id":"lPg3zYWeJ5XB","outputId":"2d4686a0-3a2a-41d8-a084-775f6bd56ecc"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"lb.transform([1, 6])","metadata":{"id":"F4PStCdJJ5v2","outputId":"e1150930-dc4a-4ddc-dc55-48ff0e4f2401"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Binary targets transform to a column vector","metadata":{"id":"hfaCBNmyKGem"}},{"cell_type":"code","source":"lb = preprocessing.LabelBinarizer()\nlb.fit_transform(['yes', 'no', 'no', 'yes'])","metadata":{"id":"YdcJvyH6KI7w","outputId":"0cc2a3ee-3b97-4cc8-9b41-94f01c9583c8"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Passing a 2D matrix for multilabel classification","metadata":{"id":"ZzFBahHnKMq3"}},{"cell_type":"code","source":"import numpy as np\nlb.fit(np.array([[0, 1, 1], [1, 0, 0]]))","metadata":{"id":"PCEwZLraKNTU","outputId":"2d8be4f0-04f0-4dad-daa3-67099825dbe6"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"lb.classes_","metadata":{"id":"oHIyq0soKPjE","outputId":"d0f5c16c-e045-4bb4-af36-b418f7f129e8"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"lb.transform([0, 1, 2, 1])","metadata":{"id":"3zVflJdiKP7T","outputId":"db38c2c2-e0ab-40f5-9bd5-7439ab655f55"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### Methods","metadata":{"id":"LUW_YyronGsm"}},{"cell_type":"markdown","source":"##### fit -- <sub><sup>*Fit label binarizer.*</sup></sub>","metadata":{"id":"slEmL5avnGsm"}},{"cell_type":"markdown","source":"##### transform -- <sub><sup>*Transform multi-class labels to binary labels.*</sup></sub>","metadata":{"id":"YoHi4xo0nGsm"}},{"cell_type":"markdown","source":"##### fit_transform -- <sub><sup>*Fit label binarizer/transform multi-class labels to binary labels.*</sup></sub>","metadata":{"id":"q799kfoNnGsm"}},{"cell_type":"markdown","source":"#### Attributes","metadata":{"id":"uxA4utiVbrkT"}},{"cell_type":"markdown","source":"##### classes_ -- <sub><sup>*Holds the label for each class.*</sup></sub>","metadata":{"id":"Xm9m1d6znGsm"}},{"cell_type":"markdown","source":"### [MultiLabelBinarizer](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MultiLabelBinarizer.html)\n\n*Transform between iterable of iterables and a multilabel format.*\n\n*Although a list of sets or tuples is a very intuitive format for multilabel data, it is unwieldy to process. This transformer converts between this intuitive format and the supported multilabel format: a (samples x classes) binary matrix indicating the presence of a class label.*","metadata":{"id":"sc7ux4mJxEx6"}},{"cell_type":"markdown","source":"#### Examples","metadata":{"id":"xIGRfQK3nLQw"}},{"cell_type":"code","source":"from sklearn.preprocessing import MultiLabelBinarizer\nmlb = MultiLabelBinarizer()\nmlb.fit_transform([(1, 2), (3,)])","metadata":{"id":"sqYwm2HGK6Gc","outputId":"10f05946-f143-45f1-981b-4d9c83b57184"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"mlb.classes_","metadata":{"id":"TZ0QK5wIK9cF","outputId":"42e93789-d892-4ae8-8f7e-8c6e60304614"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"mlb.fit_transform([{'sci-fi', 'thriller'}, {'comedy'}])","metadata":{"id":"donbKsCPLQpX","outputId":"aca4a7e2-2710-476a-f2ed-7e0a8e1557f3"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"list(mlb.classes_)","metadata":{"id":"543nq8jALSg9","outputId":"d6474474-a784-4aed-fd23-bad641f44266"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"A common mistake is to pass in a list, which leads to the following issue:","metadata":{"id":"W95ZWgduLZ8-"}},{"cell_type":"code","source":"mlb = MultiLabelBinarizer()\nmlb.fit(['sci-fi', 'thriller', 'comedy'])  # this is wrong.","metadata":{"id":"ngMlnBzdLb-0","outputId":"95fa58c1-449b-48ac-97ee-5e282f0f00fe"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"mlb.classes_","metadata":{"id":"infzsGdrLdiR","outputId":"413068e6-5a23-4f6e-afa8-5117d7b4bdee"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"To correct this, the list of labels should be passed in as:","metadata":{"id":"eNDqlN_gLnAR"}},{"cell_type":"code","source":"mlb = MultiLabelBinarizer()\nmlb.fit([['sci-fi', 'thriller', 'comedy']])","metadata":{"id":"zcFjG8-PLqaq","outputId":"24ffac34-051b-40b8-fdaf-a9db22a7e85c"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"mlb.classes_","metadata":{"id":"IWWd16yKLr3k","outputId":"44f005a7-fbe9-4707-9ac4-aee888aca0de"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### Methods","metadata":{"id":"ONn2BCLLnPJo"}},{"cell_type":"markdown","source":"##### fit -- <sub><sup>*Fit the label sets binarizer, storing classes_.*</sup></sub>","metadata":{"id":"5RHzOFYRnPJp"}},{"cell_type":"markdown","source":"##### transform -- <sub><sup>*Transform the given label sets.*</sup></sub>","metadata":{"id":"xsmLHrBLnPJp"}},{"cell_type":"markdown","source":"##### fit_transform -- <sub><sup>*Fit the label sets binarizer and transform the given label sets.*</sup></sub>","metadata":{"id":"LcFSH-_hnPJp"}},{"cell_type":"markdown","source":"##### classes_ -- <sub><sup>*A copy of the classes parameter when provided. Otherwise it corresponds to the sorted set of classes found when fitting.*</sup></sub>","metadata":{"id":"INuvp-9JnPJp"}},{"cell_type":"markdown","source":"### [add_dummy_feature](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.add_dummy_feature.html)\n\n*Augment dataset with an additional dummy feature.*\n\n*This is useful for fitting an intercept term with implementations which cannot otherwise fit it directly.*","metadata":{"id":"EqImTVlkxFZW"}},{"cell_type":"code","source":"from sklearn.preprocessing import add_dummy_feature\nadd_dummy_feature([[0, 1], [1, 0]])","metadata":{"id":"aRA7ZX6zL1VT","outputId":"b5fdbf51-c3ec-4c57-881d-5a085a29da90"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### [Normalizer](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.Normalizer.html)\n\n*Normalize samples individually to unit norm.*\n\n*Each sample (i.e. each row of the data matrix) with at least one non zero component is rescaled independently of other samples so that its norm (l1, l2 or inf) equals one.*","metadata":{"id":"qwiiTPmjTvS0"}},{"cell_type":"markdown","source":"#### Examples","metadata":{"id":"kke3l7IjdAUG"}},{"cell_type":"code","source":"from sklearn.preprocessing import Normalizer\nX = [[4, 1, 2, 2],\n     [1, 3, 9, 3],\n     [5, 7, 5, 1]]\ntransformer = Normalizer().fit(X)  # fit does nothing.","metadata":{"id":"GtfFiRTvT3bA"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"transformer.transform(X)  # Normalize samples individually to unit norm.","metadata":{"id":"GTKczWa_T8oY","outputId":"cb279ca6-0231-4d24-aca5-9581d14f3e44"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## sklearn.compose","metadata":{"id":"k1jKXA6Bt81W"}},{"cell_type":"markdown","source":"### [ColumnTransformer](https://scikit-learn.org/stable/modules/generated/sklearn.compose.ColumnTransformer.html)\n\n*Applies transformers to columns of an array or pandas DataFrame.*\n\n*This estimator allows different columns or column subsets of the input to be transformed separately and the features generated by each transformer will be concatenated to form a single feature space. This is useful for heterogeneous or columnar data, to combine several feature extraction mechanisms or transformations into a single transformer.*\n","metadata":{"id":"d0nord-gw3S5"}},{"cell_type":"markdown","source":"#### Examples","metadata":{"id":"pqL94JRun3Tq"}},{"cell_type":"code","source":"import numpy as np\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.preprocessing import Normalizer\nct = ColumnTransformer(\n    [(\"norm1\", Normalizer(norm='l1'), [0, 1]),\n     (\"norm2\", Normalizer(norm='l1'), slice(2, 4))])\nX = np.array([[0., 1., 2., 2.],\n              [1., 1., 0., 1.]])\n# Normalizer scales each row of X to unit norm. A separate scaling\n# is applied for the two first and two last elements of each\n# row independently.\nct.fit_transform(X)","metadata":{"id":"Q1NZzmxfSQmK","outputId":"057eacbc-c8f3-4e1b-b5e8-a141fe9ac06a"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### Methods","metadata":{"id":"Gqq8JsbOn539"}},{"cell_type":"markdown","source":"##### fit -- <sub><sup>*Fit all transformers using X.*</sup></sub>","metadata":{"id":"5MV3qR6hn539"}},{"cell_type":"markdown","source":"##### transform -- <sub><sup>*Transform X separately by each transformer, concatenate results.*</sup></sub>","metadata":{"id":"hWhG29E9n539"}},{"cell_type":"markdown","source":"##### fit_transform -- <sub><sup>*Fit all transformers, transform the data and concatenate results.*</sup></sub>","metadata":{"id":"a7mPARfLn53-"}},{"cell_type":"markdown","source":"### [TransformedTargetRegressor](https://scikit-learn.org/stable/modules/generated/sklearn.compose.TransformedTargetRegressor.html)\n\n*Meta-estimator to regress on a transformed target.*\n\n*Useful for applying a non-linear transformation to the target y in regression problems. This transformation can be given as a Transformer such as the QuantileTransformer or as a function and its inverse such as np.log and np.exp.*","metadata":{"id":"jKX35I7Jw5N8"}},{"cell_type":"markdown","source":"#### Examples","metadata":{"id":"RxMqiZH8pyeG"}},{"cell_type":"code","source":"import numpy as np\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.compose import TransformedTargetRegressor\ntt = TransformedTargetRegressor(regressor=LinearRegression(),\n                                func=np.log, inverse_func=np.exp)\nX = np.arange(4).reshape(-1, 1)\ny = np.exp(2 * X).ravel()\ntt.fit(X, y)","metadata":{"id":"hw9BWRLCUQQk","outputId":"3ef40092-8f97-4df9-a436-f5a52f9dbef3"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"tt.score(X, y)","metadata":{"id":"DMLlTvoyUWx-","outputId":"1d49fa33-4973-4639-d964-f0dfc6d9c111"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"tt.regressor_.coef_","metadata":{"id":"68N8eWdzUXN9","outputId":"6e50ef35-8545-4388-94c6-991baedff775"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### Methods","metadata":{"id":"PoOV5tlnp0lH"}},{"cell_type":"markdown","source":"##### fit -- <sub><sup>*Fit the model according to the given training data.*</sup></sub>\n","metadata":{"id":"aVxCTjp5p0lI"}},{"cell_type":"markdown","source":"##### predict -- <sub><sup>*Predict using the base regressor, applying inverse.*</sup></sub>\n","metadata":{"id":"sb3WhE3ep0lI"}},{"cell_type":"markdown","source":"##### score -- <sub><sup>*Return the coefficient of determination of the prediction.*</sup></sub>\n","metadata":{"id":"YNMF7iVXp0lI"}},{"cell_type":"markdown","source":"## sklearn.linear_model","metadata":{"id":"tq5QRhTet_wh"}},{"cell_type":"markdown","source":"### [LinearRegression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html)\n\n*Ordinary least squares Linear Regression.*\n\n*LinearRegression fits a linear model with coefficients w = (w1, â€¦, wp) to minimize the residual sum of squares between the observed targets in the dataset, and the targets predicted by the linear approximation.*","metadata":{"id":"pXb2O1yHwoMQ"}},{"cell_type":"markdown","source":"#### Examples","metadata":{"id":"F21R87VFoPeS"}},{"cell_type":"code","source":"import numpy as np\nfrom sklearn.linear_model import LinearRegression\nX = np.array([[1, 1], [1, 2], [2, 2], [2, 3]])\n# y = 1 * x_0 + 2 * x_1 + 3\ny = np.dot(X, np.array([1, 2])) + 3\nreg = LinearRegression().fit(X, y)","metadata":{"id":"dkGyQUt1UoDH"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"reg.score(X, y)","metadata":{"id":"4U0SokW_UrVj","outputId":"91a4fd07-d2a0-4e8b-d628-beb6e995f0a9"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"reg.coef_","metadata":{"id":"_G0gHnCzUrxV","outputId":"3916335b-80d9-4227-dd38-0432369356b0"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"reg.intercept_","metadata":{"id":"hLQH3UpLUsJr","outputId":"025f23e3-a5e4-465d-fc3f-c25a76c6e937"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"reg.predict(np.array([[3, 5]]))","metadata":{"id":"UDeaT1l_UsgG","outputId":"83dd19a9-70ad-4282-f5d7-df56d72c5523"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### Methods","metadata":{"id":"3I-9fsBXoar3"}},{"cell_type":"markdown","source":"##### fit -- <sub><sup>*Fit linear model.*</sup></sub>\n","metadata":{"id":"Y9FMacKEodAQ"}},{"cell_type":"markdown","source":"##### predict -- <sub><sup>*Predict using the linear model.*</sup></sub>\n","metadata":{"id":"iqFUzeRioi8S"}},{"cell_type":"markdown","source":"##### score -- <sub><sup>*Return the coefficient of determination of the prediction.*</sup></sub>\n","metadata":{"id":"vkxoRogLojnS"}},{"cell_type":"markdown","source":"#### Attributes","metadata":{"id":"MXl-gCm2oz1-"}},{"cell_type":"markdown","source":"##### coef_ -- <sub><sup>*Estimated coefficients for the linear regression problem.*</sup></sub>\n","metadata":{"id":"WZtHaodUoknI"}},{"cell_type":"markdown","source":"##### intercept_ -- <sub><sup>*Independent term in the linear model. Set to 0.0 if fit_intercept = False.*</sup></sub>","metadata":{"id":"voSd246TolSV"}},{"cell_type":"markdown","source":"### [SGDRegressor](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDRegressor.html)\n\n*Linear model fitted by minimizing a regularized empirical loss with SGD.*\n\n*SGD stands for Stochastic Gradient Descent: the gradient of the loss is estimated each sample at a time and the model is updated along the way with a decreasing strength schedule (aka learning rate).*","metadata":{"id":"a2FuIFVNwtfa"}},{"cell_type":"markdown","source":"#### Examples","metadata":{"id":"E8q4jM9QqDAw"}},{"cell_type":"code","source":"import numpy as np\nfrom sklearn.linear_model import SGDRegressor\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.preprocessing import StandardScaler\nn_samples, n_features = 10, 5\nrng = np.random.RandomState(0)\ny = rng.randn(n_samples)\nX = rng.randn(n_samples, n_features)\n# Always scale the input. The most convenient way is to use a pipeline.\nreg = make_pipeline(StandardScaler(),\n                    SGDRegressor(max_iter=1000, tol=1e-3))\nreg.fit(X, y)","metadata":{"id":"oj-FTDAzVBY0","outputId":"9e3ef9f0-2ad3-486d-8d57-8585472342ef"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"reg.score(X, y)","metadata":{"outputId":"9cfd07ab-c9c0-4f52-9802-f3593e01be38","id":"TgQ1c-8mVwp7"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"reg.predict(np.array([[3, 5, 4, 2, 1]]))","metadata":{"outputId":"b802531a-0bbd-4332-8396-d4bee8285879","id":"snwP-ecdVwp8"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### Methods","metadata":{"id":"6t5j3xLpqFlN"}},{"cell_type":"markdown","source":"##### fit -- <sub><sup>*Fit linear model with Stochastic Gradient Descent.*</sup></sub>\n","metadata":{"id":"UwYLu7aSqFlN"}},{"cell_type":"markdown","source":"##### partial_fit -- <sub><sup>*Perform one epoch of stochastic gradient descent on given samples.*</sup></sub>","metadata":{"id":"8_670JvDqHvq"}},{"cell_type":"markdown","source":"##### predict -- <sub><sup>*Predict using the linear model.*</sup></sub>\n","metadata":{"id":"DPqSqhgNqFlN"}},{"cell_type":"markdown","source":"##### score -- <sub><sup>*Return the coefficient of determination of the prediction.*</sup></sub>\n","metadata":{"id":"j503YP2PqFlN"}},{"cell_type":"markdown","source":"#### Attributes","metadata":{"id":"JhKOUzQuqMWl"}},{"cell_type":"markdown","source":"##### n_iter_ -- <sub><sup>*The actual number of iterations before reaching the stopping criterion.*</sup></sub>","metadata":{"id":"3J8EEp3TqOoZ"}},{"cell_type":"markdown","source":"##### t_ -- <sub><sup>*Number of weight updates performed during training. Same as (n_iter_ * n_samples)*</sup></sub>","metadata":{"id":"y76qXnX0rMgD"}},{"cell_type":"markdown","source":"##### coef_ -- <sub><sup>*Weights assigned to the features.*</sup></sub>","metadata":{"id":"Zeke5bnqqRqa"}},{"cell_type":"markdown","source":"##### intercept_ -- <sub><sup>*The intercept term.*</sup></sub>","metadata":{"id":"5Yrylp9KqTly"}},{"cell_type":"markdown","source":"### [Lasso](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Lasso.html)\n\n*Linear Model trained with L1 prior as regularizer (aka the Lasso).*","metadata":{"id":"-9MvOlXewuKt"}},{"cell_type":"markdown","source":"#### Examples","metadata":{"id":"iHIaV4hQpRto"}},{"cell_type":"code","source":"from sklearn import linear_model\nclf = linear_model.Lasso(alpha=0.1)\nclf.fit([[0,0], [1, 1], [2, 2]], [0, 1, 2])\n\nclf.coef_","metadata":{"id":"XFEbJHPtWWpD","outputId":"65844104-eed0-4b34-e9a2-1a84d6e38dc9"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"clf.intercept_","metadata":{"id":"blRZRBGRWoZJ","outputId":"49f31f8e-23e2-4adc-e323-5efd6acae693"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### Methods","metadata":{"id":"u7_3CIZ3pUDO"}},{"cell_type":"markdown","source":"##### fit -- <sub><sup>*Fit model with coordinate descent.*</sup></sub>\n","metadata":{"id":"dzOzEPcJpUDP"}},{"cell_type":"markdown","source":"##### predict -- <sub><sup>*Predict using the linear model.*</sup></sub>\n","metadata":{"id":"94lPTFuPpUDP"}},{"cell_type":"markdown","source":"##### score -- <sub><sup>*Return the coefficient of determination of the prediction.*</sup></sub>\n","metadata":{"id":"n-g2EPNXpUDP"}},{"cell_type":"markdown","source":"#### Attributes","metadata":{"id":"pLjRBfJZpUDP"}},{"cell_type":"markdown","source":"##### coef_ -- <sub><sup>*Parameter vector (w in the cost function formula).*</sup></sub>\n","metadata":{"id":"COoEwrjWpUDP"}},{"cell_type":"markdown","source":"##### intercept_ -- <sub><sup>*Independent term in decision function.*</sup></sub>","metadata":{"id":"u_zo6eNIpUDP"}},{"cell_type":"markdown","source":"### [LassoCV](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LassoCV.html)\n\n*Lasso linear model with iterative fitting along a regularization path.*\n\n*The best model is selected by cross-validation.*","metadata":{"id":"oz1-vtGuW9ie"}},{"cell_type":"markdown","source":"#### Examples","metadata":{"id":"k6N3J91UiNxx"}},{"cell_type":"code","source":"from sklearn.linear_model import LassoCV\nfrom sklearn.datasets import make_regression\nX, y = make_regression(noise=4, random_state=0)\nreg = LassoCV(cv=5, random_state=0).fit(X, y)\nreg.score(X, y)","metadata":{"id":"f1P-eQXAW1tw","outputId":"49c67022-f07e-42ab-b94e-45e02fb9e39e"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"reg.predict(X[:1,])","metadata":{"id":"rfAmbnTYW27h","outputId":"ff51ce7b-4a40-46bc-aa7c-64dbaf80f066"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### [Ridge](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Ridge.html)\n\n*Linear least squares with l2 regularization.*","metadata":{"id":"i9aG5n6owu3E"}},{"cell_type":"markdown","source":"#### Examples","metadata":{"id":"bPJ0X30GpK_w"}},{"cell_type":"code","source":"from sklearn.linear_model import Ridge\nimport numpy as np\nn_samples, n_features = 10, 5\nrng = np.random.RandomState(0)\ny = rng.randn(n_samples)\nX = rng.randn(n_samples, n_features)\nclf = Ridge(alpha=1.0)\nclf.fit(X, y)","metadata":{"id":"4wflMIJSXY1V","outputId":"49dfce6f-7ffc-4bdc-b5b9-cfab066c9b73"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"clf.score(X, y)","metadata":{"outputId":"db32a881-38f4-473d-97d0-66f9bbf9fa60","id":"JbX6nSaiXuBN"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"clf.coef_","metadata":{"outputId":"6a33e45a-35ea-41a5-9273-cf26c58cf082","id":"9cVypx5IXuBO"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"clf.intercept_","metadata":{"outputId":"45f2074b-a405-4782-bb99-cc2e92ebfb80","id":"YoadUoCXXuBO"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"clf.predict(np.array([[3, 5, 2, 4, 1]]))","metadata":{"outputId":"218d8b2e-7345-427d-849a-232b522a553e","id":"ABIzkT63XuBP"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### Methods","metadata":{"id":"w_LwY9IPpNoN"}},{"cell_type":"markdown","source":"##### fit -- <sub><sup>*Fit Ridge regression model.*</sup></sub>\n","metadata":{"id":"saRhnR2hpNoN"}},{"cell_type":"markdown","source":"##### predict -- <sub><sup>*Predict using the linear model.*</sup></sub>\n","metadata":{"id":"4igNvDO4pNoN"}},{"cell_type":"markdown","source":"##### score -- <sub><sup>*Return the coefficient of determination of the prediction.*</sup></sub>\n","metadata":{"id":"QIY6MptipNoN"}},{"cell_type":"markdown","source":"#### Attributes","metadata":{"id":"mdQkE49XpNoN"}},{"cell_type":"markdown","source":"##### coef_ -- <sub><sup>*Weight vector(s).*</sup></sub>\n","metadata":{"id":"JYKe6tERpNoN"}},{"cell_type":"markdown","source":"##### intercept_ -- <sub><sup>*Independent term in decision function. Set to 0.0 if fit_intercept = False.*</sup></sub>","metadata":{"id":"BVxpa9yIpNoO"}},{"cell_type":"markdown","source":"### [RidgeCV](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.RidgeCV.html)\n\n*Ridge regression with built-in cross-validation.*\n\n*By default, it performs efficient Leave-One-Out Cross-Validation.*","metadata":{"id":"tQoT_wHKX-0B"}},{"cell_type":"markdown","source":"#### Examples","metadata":{"id":"p8pU-Y4q8IeZ"}},{"cell_type":"code","source":"from sklearn.datasets import load_diabetes\nfrom sklearn.linear_model import RidgeCV\nX, y = load_diabetes(return_X_y=True)\nclf = RidgeCV(alphas=[1e-3, 1e-2, 1e-1, 1]).fit(X, y)\nclf.score(X, y)","metadata":{"id":"KZ13528AYE9J","outputId":"fb8b3a0b-82d1-4049-be95-5d2254f7180a"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### Methods","metadata":{"id":"pCc8-ntu8MEE"}},{"cell_type":"markdown","source":"##### fit -- <sub><sup>*Fit Ridge regression model with cv.*</sup></sub>\n","metadata":{"id":"MsiH4XSr8MEE"}},{"cell_type":"markdown","source":"##### predict -- <sub><sup>*Predict using the linear model.*</sup></sub>\n","metadata":{"id":"1OACxBKw8MEF"}},{"cell_type":"markdown","source":"##### score -- <sub><sup>*Return the coefficient of determination of the prediction.*</sup></sub>","metadata":{"id":"cb1FCDPB8ODt"}},{"cell_type":"markdown","source":"#### Attributes","metadata":{"id":"W2uaq6oQ8MEF"}},{"cell_type":"markdown","source":"##### alpha_ -- <sub><sup>*Estimated regularization parameter, or, if alpha_per_target=True, the estimated regularization parameter for each target.*</sup></sub>","metadata":{"id":"-aY8H0Xh8MEF"}},{"cell_type":"markdown","source":"##### best_score_ -- <sub><sup>*Score of base estimator with best alpha, or, if alpha_per_target=True, a score for each target.*</sup></sub>","metadata":{"id":"-L-EGWQskheg"}},{"cell_type":"markdown","source":"### [LogisticRegression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html)\n\n*Logistic Regression (aka logit, MaxEnt) classifier.*\n\n*In the multiclass case, the training algorithm uses the one-vs-rest (OvR) scheme if the â€˜multi_classâ€™ option is set to â€˜ovrâ€™, and uses the cross-entropy loss if the â€˜multi_classâ€™ option is set to â€˜multinomialâ€™. (Currently the â€˜multinomialâ€™ option is supported only by the â€˜lbfgsâ€™, â€˜sagâ€™, â€˜sagaâ€™ and â€˜newton-cgâ€™ solvers.)*","metadata":{"id":"h5Hvi7M8wvit"}},{"cell_type":"markdown","source":"#### Examples","metadata":{"id":"AZLqa7pnr2ZU"}},{"cell_type":"code","source":"from sklearn.datasets import load_iris\nfrom sklearn.linear_model import LogisticRegression\nX, y = load_iris(return_X_y=True)\nclf = LogisticRegression(random_state=0).fit(X, y)\nclf.predict(X[:2, :])","metadata":{"id":"2xWjGSXTYUll","outputId":"9a64ee62-6cf8-44c7-e0d0-57e6c65feb5c"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"clf.predict_proba(X[:2, :])","metadata":{"id":"RJlH5ZpVYZF6","outputId":"a4a4e78c-5a9e-441e-c9ed-61c469d8c062"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"clf.score(X, y)","metadata":{"id":"62rTfqkHYZyC","outputId":"e69bdf51-e46a-42b3-a0ec-e4410d1c979d"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### Methods","metadata":{"id":"u1YpP6XAr5gp"}},{"cell_type":"markdown","source":"##### fit -- <sub><sup>*Fit the model according to the given training data.*</sup></sub>\n","metadata":{"id":"L_P8HAPcr5gp"}},{"cell_type":"markdown","source":"##### predict -- <sub><sup>*Predict class labels for samples in X.*</sup></sub>\n","metadata":{"id":"z72yIvwwr5gq"}},{"cell_type":"markdown","source":"##### score -- <sub><sup>*Return the mean accuracy on the given test data and labels.*</sup></sub>\n","metadata":{"id":"qTTzTwu-r5gq"}},{"cell_type":"markdown","source":"#### Attributes","metadata":{"id":"-_e1FPK4r5gq"}},{"cell_type":"markdown","source":"##### classes_ -- <sub><sup>*A list of class labels known to the classifier.*</sup></sub>","metadata":{"id":"CpoWisEwr5gq"}},{"cell_type":"markdown","source":"##### coef_ -- <sub><sup>*Coefficient of the features in the decision function.*</sup></sub>","metadata":{"id":"qiZ90i87r5gq"}},{"cell_type":"markdown","source":"##### intercept_ -- <sub><sup>*Intercept (a.k.a. bias) added to the decision function.*</sup></sub>","metadata":{"id":"fiXKvA5hr5gq"}},{"cell_type":"markdown","source":"### [LogisticRegressionCV](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegressionCV.html)\n\n*Logistic Regression CV (aka logit, MaxEnt) classifier.*\n\n*This class implements logistic regression using liblinear, newton-cg, sag of lbfgs optimizer. The newton-cg, sag and lbfgs solvers support only L2 regularization with primal formulation. The liblinear solver supports both L1 and L2 regularization, with a dual formulation only for the L2 penalty. Elastic-Net penalty is only supported by the saga solver.*","metadata":{"id":"TUwPQNeUYLST"}},{"cell_type":"markdown","source":"#### Examples","metadata":{"id":"Fmur-sdpmGOw"}},{"cell_type":"code","source":"from sklearn.datasets import load_iris\nfrom sklearn.linear_model import LogisticRegressionCV\nX, y = load_iris(return_X_y=True)\nclf = LogisticRegressionCV(cv=5, random_state=0).fit(X, y)\nclf.predict(X[:2, :])","metadata":{"id":"09zfaioUYopK","outputId":"e432fb96-0b9c-4cba-c27e-71e8a0952b52"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"clf.predict_proba(X[:2, :]).shape","metadata":{"id":"kHeV8WB_YrtX","outputId":"83d46c66-de88-4d8e-8043-38ac6f2a7fea"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"clf.score(X, y)","metadata":{"id":"TTYaZ71GYsPH","outputId":"b6821a09-de40-473c-842c-8a7b52b52d11"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### [SGDClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html)\n\n*Linear classifiers (SVM, logistic regression, etc.) with SGD training.*\n\n*This estimator implements regularized linear models with stochastic gradient descent (SGD) learning: the gradient of the loss is estimated each sample at a time and the model is updated along the way with a decreasing strength schedule (aka learning rate). SGD allows minibatch (online/out-of-core) learning via the partial_fit method. For best results using the default learning rate schedule, the data should have zero mean and unit variance.*","metadata":{"id":"niqFynEzwwOQ"}},{"cell_type":"markdown","source":"#### Examples","metadata":{"id":"zojSh9fyq2nt"}},{"cell_type":"code","source":"import numpy as np\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.pipeline import make_pipeline\nX = np.array([[-1, -1], [-2, -1], [1, 1], [2, 1]])\nY = np.array([1, 1, 2, 2])\n# Always scale the input. The most convenient way is to use a pipeline.\nclf = make_pipeline(StandardScaler(),\n                    SGDClassifier(max_iter=1000, tol=1e-3))\nclf.fit(X, Y)","metadata":{"id":"fLqEorFUY3-4","outputId":"677407cb-0a4e-4986-9b17-35bb4344c6e9"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(clf.predict([[-0.8, -1]]))","metadata":{"id":"3iwaz8iNY7-Q","outputId":"b2539753-58d4-41f1-f41f-1a337c00377a"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### Methods","metadata":{"id":"PI6UNFydq5TX"}},{"cell_type":"markdown","source":"##### fit -- <sub><sup>*Fit linear model with Stochastic Gradient Descent.*</sup></sub>\n","metadata":{"id":"-yfOva8Pq5TX"}},{"cell_type":"markdown","source":"##### partial_fit -- <sub><sup>*Perform one epoch of stochastic gradient descent on given samples.*</sup></sub>","metadata":{"id":"ellcQWG5q5TY"}},{"cell_type":"markdown","source":"##### predict -- <sub><sup>*Predict class labels for samples in X.*</sup></sub>\n","metadata":{"id":"I3mplLcGq5TY"}},{"cell_type":"markdown","source":"##### score -- <sub><sup>*Return the mean accuracy on the given test data and labels.*</sup></sub>\n","metadata":{"id":"v6ZSwl7Iq5TY"}},{"cell_type":"markdown","source":"#### Attributes","metadata":{"id":"mhe4LzHUq5TY"}},{"cell_type":"markdown","source":"##### n_iter_ -- <sub><sup>*The actual number of iterations before reaching the stopping criterion. For multiclass fits, it is the maximum over every binary fit.*</sup></sub>","metadata":{"id":"JSlswuJWq5TY"}},{"cell_type":"markdown","source":"##### t_ -- <sub><sup>*Number of weight updates performed during training. Same as (n_iter_ * n_samples).*</sup></sub>","metadata":{"id":"igkJQjigq_Y7"}},{"cell_type":"markdown","source":"##### coef_ -- <sub><sup>*Weights assigned to the features.*</sup></sub>","metadata":{"id":"wbSsoKcpq5TY"}},{"cell_type":"markdown","source":"##### intercept_ -- <sub><sup>*Constants in decision function.*</sup></sub>","metadata":{"id":"QD4X6YuEq5TY"}},{"cell_type":"markdown","source":"### [RidgeClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.RidgeClassifier.html)\n\n*Classifier using Ridge regression.*\n\n*This classifier first converts the target values into {-1, 1} and then treats the problem as a regression task (multi-output regression in the multiclass case).*\n","metadata":{"id":"rvM7Wpnsww6u"}},{"cell_type":"code","source":"from sklearn.datasets import load_breast_cancer\nfrom sklearn.linear_model import RidgeClassifier\nX, y = load_breast_cancer(return_X_y=True)\nclf = RidgeClassifier().fit(X, y)\nclf.score(X, y)","metadata":{"id":"Lbvb60NxZQq0","outputId":"758e9914-cc91-4361-b364-c22edacc3cdd"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### [RidgeClassifierCV](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.RidgeClassifierCV.html)\n\n*Ridge classifier with built-in cross-validation.*\n\n*By default, it performs Leave-One-Out Cross-Validation. Currently, only the n_features > n_samples case is handled efficiently.*","metadata":{"id":"YtLdVCu5ZKKE"}},{"cell_type":"code","source":"from sklearn.datasets import load_breast_cancer\nfrom sklearn.linear_model import RidgeClassifierCV\nX, y = load_breast_cancer(return_X_y=True)\nclf = RidgeClassifierCV(alphas=[1e-3, 1e-2, 1e-1, 1]).fit(X, y)\nclf.score(X, y)","metadata":{"id":"xRmp3TIiZbD-","outputId":"af7e97d2-f5c4-471f-9cea-330f3a97dc58"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### [Perceptron](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Perceptron.html)\n\n*Linear perceptron classifier.*","metadata":{"id":"qePU7APuwxjq"}},{"cell_type":"markdown","source":"#### Examples","metadata":{"id":"GhFKtDcXqnQm"}},{"cell_type":"code","source":"from sklearn.datasets import load_digits\nfrom sklearn.linear_model import Perceptron\nX, y = load_digits(return_X_y=True)\nclf = Perceptron(tol=1e-3, random_state=0)\nclf.fit(X, y)\n\nclf.score(X, y)","metadata":{"id":"tAht5iyJZmO8","outputId":"f10f6ffb-9f28-432b-b667-77fdbdaf58d6"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### Methods","metadata":{"id":"mSUz5kFRqprH"}},{"cell_type":"markdown","source":"##### fit -- <sub><sup>*Fit linear model with Stochastic Gradient Descent.*</sup></sub>\n","metadata":{"id":"mdVdJ74cqprH"}},{"cell_type":"markdown","source":"##### partial_fit -- <sub><sup>*Perform one epoch of stochastic gradient descent on given samples.*</sup></sub>","metadata":{"id":"Sb7WkWtiqprH"}},{"cell_type":"markdown","source":"##### predict -- <sub><sup>*Predict class labels for samples in X.*</sup></sub>\n","metadata":{"id":"VhqtYDc0qprH"}},{"cell_type":"markdown","source":"##### score -- <sub><sup>*Return the mean accuracy on the given test data and labels*</sup></sub>\n","metadata":{"id":"YGyvDXpXqprI"}},{"cell_type":"markdown","source":"#### Attributes","metadata":{"id":"iWjcPtkeqprI"}},{"cell_type":"markdown","source":"##### classes_ -- <sub><sup>*The unique classes labels.*</sup></sub>","metadata":{"id":"n654fSNUqprI"}},{"cell_type":"markdown","source":"##### coef_ -- <sub><sup>*Weights assigned to the features.*</sup></sub>","metadata":{"id":"SVM6qmV4qprI"}},{"cell_type":"markdown","source":"##### intercept_ -- <sub><sup>*Constants in decision function.*</sup></sub>","metadata":{"id":"nYcd18JfqprI"}},{"cell_type":"markdown","source":"## sklearn.svm","metadata":{"id":"4x3D6Q9PuC07"}},{"cell_type":"markdown","source":"### [SVC](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html)\n\n*C-Support Vector Classification.*\n\n*The implementation is based on libsvm. The fit time scales at least quadratically with the number of samples and may be impractical beyond tens of thousands of samples.*","metadata":{"id":"EfWIJUoCwfrp"}},{"cell_type":"markdown","source":"#### Examples","metadata":{"id":"UPYWJ-9UsO-F"}},{"cell_type":"code","source":"import numpy as np\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.preprocessing import StandardScaler\nX = np.array([[-1, -1], [-2, -1], [1, 1], [2, 1]])\ny = np.array([1, 1, 2, 2])\nfrom sklearn.svm import SVC\nclf = make_pipeline(StandardScaler(), SVC(gamma='auto'))\nclf.fit(X, y)","metadata":{"id":"j8d1nsp6nJd1","outputId":"f0c8a4a0-3845-4506-c27f-03a19df275bf"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(clf.predict([[-0.8, -1]]))","metadata":{"id":"wTCJ1SW2nPH6","outputId":"159256cb-9e6c-40b4-e7f7-40b3b4fb0419"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### Methods","metadata":{"id":"fTSN5VR9sR-4"}},{"cell_type":"markdown","source":"##### fit -- <sub><sup>*Fit the SVM model according to the given training data.*</sup></sub>\n","metadata":{"id":"bScpM6EmsR-4"}},{"cell_type":"markdown","source":"##### predict -- <sub><sup>*Perform classification on samples in X.*</sup></sub>\n","metadata":{"id":"_Kf6p13AsR-5"}},{"cell_type":"markdown","source":"##### score -- <sub><sup>*Return the mean accuracy on the given test data and labels.*</sup></sub>\n","metadata":{"id":"36Dozw1YsR-5"}},{"cell_type":"markdown","source":"#### Attributes","metadata":{"id":"WibECzqnsR-5"}},{"cell_type":"markdown","source":"##### classes_ -- <sub><sup>*Multipliers of parameter C for each class. Computed based on the class_weight parameter.*</sup></sub>","metadata":{"id":"R3zpxlFWsR-5"}},{"cell_type":"markdown","source":"##### coef_ -- <sub><sup>*Weights assigned to the features when kernel=\"linear\".*</sup></sub>","metadata":{"id":"zJDNWJmqsR-5"}},{"cell_type":"markdown","source":"##### intercept_ -- <sub><sup>*Constants in decision function.*</sup></sub>","metadata":{"id":"ITeXRA_PsR-5"}},{"cell_type":"markdown","source":"##### support_ -- <sub><sup>*Indices of support vectors.*</sup></sub>","metadata":{"id":"JRxE3SqAsaGB"}},{"cell_type":"markdown","source":"##### support_vectors_ -- <sub><sup>*Support vectors.*</sup></sub>","metadata":{"id":"pAJK90-lsaGB"}},{"cell_type":"markdown","source":"##### n_support_ -- <sub><sup>*Number of support vectors for each class.*</sup></sub>","metadata":{"id":"3otyfOFhsaGB"}},{"cell_type":"markdown","source":"### [LinearSVC](https://scikit-learn.org/stable/modules/generated/sklearn.svm.LinearSVC.html)\n\n*Linear Support Vector Classification.*\n\n*Similar to SVC with parameter kernel=â€™linearâ€™, but implemented in terms of liblinear rather than libsvm, so it has more flexibility in the choice of penalties and loss functions and should scale better to large numbers of samples.*","metadata":{"id":"MbcxgN90nD5n"}},{"cell_type":"code","source":"from sklearn.svm import LinearSVC\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.datasets import make_classification\nX, y = make_classification(n_features=4, random_state=0)\nclf = make_pipeline(StandardScaler(),\n                    LinearSVC(random_state=0, tol=1e-5))\nclf.fit(X, y)","metadata":{"id":"boTUBszgnQoC","outputId":"b7268d17-b73a-41cf-eca3-a0ba93e2a2ed"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(clf.named_steps['linearsvc'].coef_)","metadata":{"id":"6wv0TRk-nXjf","outputId":"c121aba8-fe11-4d62-e519-493ccf1c4268"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(clf.named_steps['linearsvc'].intercept_)","metadata":{"id":"xeUhNnLKnaBl","outputId":"cf5195f8-1e05-45d4-c1e3-2a4995d74e97"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(clf.predict([[0, 0, 0, 0]]))","metadata":{"id":"ajh6a98Lnb0W","outputId":"dc829f11-559d-4dd7-a8ad-2e40f7acd409"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## sklearn.naive_bayes","metadata":{"id":"O8MO2jkPuGv8"}},{"cell_type":"markdown","source":"### [MultinomialNB](https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html)\n\n*Naive Bayes classifier for multinomial models.*\n\n*The multinomial Naive Bayes classifier is suitable for classification with discrete features (e.g., word counts for text classification). The multinomial distribution normally requires integer feature counts. However, in practice, fractional counts such as tf-idf may also work.*","metadata":{"id":"y-cTJrIVwYzj"}},{"cell_type":"code","source":"import numpy as np\nrng = np.random.RandomState(1)\nX = rng.randint(5, size=(6, 100))\ny = np.array([1, 2, 3, 4, 5, 6])\nfrom sklearn.naive_bayes import MultinomialNB\nclf = MultinomialNB()\nclf.fit(X, y)","metadata":{"id":"5bSKjlggnlV6","outputId":"2b789a62-3d4e-436c-8f54-2c36d105b035"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(clf.predict(X[2:3]))","metadata":{"id":"w3BNnWYunp8u","outputId":"cbddef98-d044-418e-eef7-6bcb32994354"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### [GaussianNB](https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.GaussianNB.html)\n\n*Gaussian Naive Bayes (GaussianNB).*\n\n*Can perform online updates to model parameters via partial_fit. *\n","metadata":{"id":"V_5KbzdSwc24"}},{"cell_type":"code","source":"import numpy as np\nX = np.array([[-1, -1], [-2, -1], [-3, -2], [1, 1], [2, 1], [3, 2]])\nY = np.array([1, 1, 1, 2, 2, 2])\nfrom sklearn.naive_bayes import GaussianNB\nclf = GaussianNB()\nclf.fit(X, Y)","metadata":{"id":"q1bucHtinxHi","outputId":"4b4ce9f9-1a6d-4825-b7bc-2529a35d2b26"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(clf.predict([[-0.8, -1]]))","metadata":{"id":"Xu9wtNJ8n0AK","outputId":"0f4156c2-7042-4179-d93b-d2ff5285580f"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"clf_pf = GaussianNB()\nclf_pf.partial_fit(X, Y, np.unique(Y))","metadata":{"id":"nwq3RWAfn0ei","outputId":"de39d253-71de-4935-f3a0-e33147fde269"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(clf_pf.predict([[-0.8, -1]]))","metadata":{"id":"3JIFz_tGn1HP","outputId":"ceb87532-40da-42fb-dbc8-1b2f4a8f9af0"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### [BernoulliNB](https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.BernoulliNB.html)\n\n*Naive Bayes classifier for multivariate Bernoulli models.*\n\n*Like MultinomialNB, this classifier is suitable for discrete data. The difference is that while MultinomialNB works with occurrence counts, BernoulliNB is designed for binary/boolean features.*\n","metadata":{"id":"nP8fhGQjwdix"}},{"cell_type":"code","source":"import numpy as np\nrng = np.random.RandomState(1)\nX = rng.randint(5, size=(6, 100))\nY = np.array([1, 2, 3, 4, 4, 5])\nfrom sklearn.naive_bayes import BernoulliNB\nclf = BernoulliNB()\nclf.fit(X, Y)\n\nprint(clf.predict(X[2:3]))","metadata":{"id":"fgBX2Jd3oLyW","outputId":"5858bf78-2560-4ee9-a601-abb4ff4f2765"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### [ComplementNB](https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.ComplementNB.html)\n\n*The Complement Naive Bayes classifier described in Rennie et al. (2003).*\n\n*The Complement Naive Bayes classifier was designed to correct the â€œsevere assumptionsâ€ made by the standard Multinomial Naive Bayes classifier. It is particularly suited for imbalanced data sets.*","metadata":{"id":"IyAnfENpweH8"}},{"cell_type":"code","source":"import numpy as np\nrng = np.random.RandomState(1)\nX = rng.randint(5, size=(6, 100))\ny = np.array([1, 2, 3, 4, 5, 6])\nfrom sklearn.naive_bayes import ComplementNB\nclf = ComplementNB()\nclf.fit(X, y)\n\nprint(clf.predict(X[2:3]))","metadata":{"id":"y7deCnvtom_C","outputId":"1b980601-9e4a-4187-81e5-c4eb3c72cef2"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## sklearn.tree","metadata":{"id":"AUtfDiF85Gtz"}},{"cell_type":"markdown","source":"### [DecisionTreeClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html)\n\n*A decision tree classifier.*","metadata":{"id":"F7WD1zB3HGvy"}},{"cell_type":"markdown","source":"#### Examples","metadata":{"id":"acGkZiojHGvz"}},{"cell_type":"code","source":"from sklearn.datasets import load_iris\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.tree import DecisionTreeClassifier\nclf = DecisionTreeClassifier(random_state=0)\niris = load_iris()\ncross_val_score(clf, iris.data, iris.target, cv=10)","metadata":{"outputId":"23981724-7adb-4fca-8934-80f5d54d45e4","id":"vz5EHFaoHGvz"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### Methods","metadata":{"id":"--cdKFXlHGvz"}},{"cell_type":"markdown","source":"##### fit -- <sub><sup>*Build a decision tree classifier from the training set (X, y).*</sup></sub>\n","metadata":{"id":"RhT0JCQeHGv0"}},{"cell_type":"markdown","source":"##### predict -- <sub><sup>*Predict class or regression value for X.*</sup></sub>\n","metadata":{"id":"1tYTTSvNHGv0"}},{"cell_type":"markdown","source":"##### score -- <sub><sup>*Return the mean accuracy on the given test data and labels.*</sup></sub>\n","metadata":{"id":"EfGoHK4ZHGv0"}},{"cell_type":"markdown","source":"#### Attributes","metadata":{"id":"GgQe5ajFHGv0"}},{"cell_type":"markdown","source":"##### feature_importances_ -- <sub><sup>*Return the feature importances.*</sup></sub>\n","metadata":{"id":"M-Flkbv0HGv0"}},{"cell_type":"markdown","source":"### [DecisionTreeRegressor](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeRegressor.html)\n\n*A decision tree regressor.*","metadata":{"id":"q2zirMPd5Lxs"}},{"cell_type":"markdown","source":"#### Examples","metadata":{"id":"LE0aIlbT5Xu6"}},{"cell_type":"code","source":"from sklearn.datasets import load_diabetes\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.tree import DecisionTreeRegressor\nX, y = load_diabetes(return_X_y=True)\nregressor = DecisionTreeRegressor(random_state=0)\ncross_val_score(regressor, X, y, cv=10)","metadata":{"id":"FGuVhi7S5d1M","outputId":"af315428-a9e3-4e41-bde1-d0a399260966"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### Methods","metadata":{"id":"f1ZI7nD550re"}},{"cell_type":"markdown","source":"##### fit -- <sub><sup>*Build a decision tree regressor from the training set (X, y).*</sup></sub>\n","metadata":{"id":"eB9DPtIw50re"}},{"cell_type":"markdown","source":"##### predict -- <sub><sup>*Predict class or regression value for X.*</sup></sub>\n","metadata":{"id":"QYbJj2zy50re"}},{"cell_type":"markdown","source":"##### score -- <sub><sup>*Return the coefficient of determination of the prediction.*</sup></sub>\n","metadata":{"id":"wjz6TznP50re"}},{"cell_type":"markdown","source":"#### Attributes","metadata":{"id":"9k6fHrcC50rf"}},{"cell_type":"markdown","source":"##### feature_importances_ -- <sub><sup>*Return the feature importances.*</sup></sub>\n","metadata":{"id":"2iMEs1bE50rf"}},{"cell_type":"markdown","source":"## sklearn.neighbors","metadata":{"id":"_6bD5Dq96M82"}},{"cell_type":"markdown","source":"### [KNeighborsClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html)\n\n*Classifier implementing the k-nearest neighbors vote.*","metadata":{"id":"OpLI3wHx6Rzh"}},{"cell_type":"markdown","source":"#### Examples","metadata":{"id":"lnLCFsNn6ZnI"}},{"cell_type":"code","source":"X = [[0], [1], [2], [3]]\ny = [0, 0, 1, 1]\nfrom sklearn.neighbors import KNeighborsClassifier\nneigh = KNeighborsClassifier(n_neighbors=3)\nneigh.fit(X, y)\n\nneigh.predict([[1.1]])","metadata":{"id":"2MNOn2n06deN","outputId":"f8f77971-37c1-4319-cd0d-54752fee4a7a"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"neigh.predict_proba([[0.9]])","metadata":{"id":"KEjo8D8N6hxT","outputId":"a1d87d8e-73f9-4662-99d5-4b2060f15d7e"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### Methods","metadata":{"id":"glfsNjwN6uST"}},{"cell_type":"markdown","source":"##### fit -- <sub><sup>*Fit the k-nearest neighbors classifier from the training dataset.*</sup></sub>\n","metadata":{"id":"pcFHpqA16uST"}},{"cell_type":"markdown","source":"##### predict -- <sub><sup>*Predict the class labels for the provided data.*</sup></sub>\n","metadata":{"id":"qkE4VcH56uST"}},{"cell_type":"markdown","source":"##### score -- <sub><sup>*Return the mean accuracy on the given test data and labels.*</sup></sub>\n","metadata":{"id":"iKfAtdmD6uSU"}},{"cell_type":"markdown","source":"#### Attributes","metadata":{"id":"Rv00SJFT6uSU"}},{"cell_type":"markdown","source":"##### classes_ -- <sub><sup>*Class labels known to the classifier*</sup></sub>\n","metadata":{"id":"3Mm_6qPZ6uSU"}},{"cell_type":"markdown","source":"## sklearn.cluster","metadata":{"id":"UKDqbr6UiQP3"}},{"cell_type":"markdown","source":"### [KMeans](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html)\n\n*K-Means clustering.*","metadata":{"id":"7178G_QCiWbf"}},{"cell_type":"markdown","source":"#### Examples","metadata":{"id":"w1gBRCH_iWbg"}},{"cell_type":"code","source":"from sklearn.cluster import KMeans\nimport numpy as np\nX = np.array([[1, 2], [1, 4], [1, 0],\n              [10, 2], [10, 4], [10, 0]])\nkmeans = KMeans(n_clusters=2, random_state=0).fit(X)\nkmeans.labels_\n\nkmeans.predict([[0, 0], [12, 3]])\n\nkmeans.cluster_centers_","metadata":{"outputId":"bde2534b-9949-4b7a-a2bb-3122b71b8db3","id":"4mrFK9TviWbg"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### Methods","metadata":{"id":"04isx3Z7iWbh"}},{"cell_type":"markdown","source":"##### fit -- <sub><sup>*Compute k-means clustering.*</sup></sub>\n","metadata":{"id":"bNNyo57wiWbh"}},{"cell_type":"markdown","source":"##### predict -- <sub><sup>*Predict the closest cluster each sample in X belongs to.*</sup></sub>\n","metadata":{"id":"qj54LlgciWbi"}},{"cell_type":"markdown","source":"##### score -- <sub><sup>*Transform X to a cluster-distance space.*</sup></sub>\n","metadata":{"id":"tT1a6juHiWbi"}},{"cell_type":"markdown","source":"#### Attributes","metadata":{"id":"-5mwvgJQiWbi"}},{"cell_type":"markdown","source":"##### inertia_ -- <sub><sup>*Sum of squared distances of samples to their closest cluster center, weighted by the sample weights if provided.*</sup></sub>\n","metadata":{"id":"pRnPV_vFiWbi"}},{"cell_type":"markdown","source":"##### labels_ -- <sub><sup>*Labels of each point*</sup></sub>\n","metadata":{"id":"6bmwYQNoi_eI"}},{"cell_type":"markdown","source":"##### cluster_centers_ -- <sub><sup>*Coordinates of cluster centers.*</sup></sub>\n","metadata":{"id":"d-hCuPabjQXN"}},{"cell_type":"markdown","source":"### [AgglomerativeClustering](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.AgglomerativeClustering.html)\n\n*Recursively merges pair of clusters of sample data; uses linkage distance.*","metadata":{"id":"bNEYXEiyj1HN"}},{"cell_type":"markdown","source":"#### Examples","metadata":{"id":"bej13g5sj1HO"}},{"cell_type":"code","source":"from sklearn.cluster import AgglomerativeClustering\nimport numpy as np\nX = np.array([[1, 2], [1, 4], [1, 0],\n              [4, 2], [4, 4], [4, 0]])\nclustering = AgglomerativeClustering().fit(X)\nclustering\n\nclustering.labels_","metadata":{"outputId":"70f0f3bf-d777-4b25-e1c3-822e64d8374e","id":"KPo6kS40j1HO"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### Methods","metadata":{"id":"gRP-gaVQj1HP"}},{"cell_type":"markdown","source":"##### fit -- <sub><sup>*Fit the hierarchical clustering from features, or distance matrix.*</sup></sub>\n","metadata":{"id":"-mjW_QR4j1HP"}},{"cell_type":"markdown","source":"##### predict -- <sub><sup>*Fit and return the result of each sample's clustering assignment.*</sup></sub>\n","metadata":{"id":"EntccZkej1HP"}},{"cell_type":"markdown","source":"#### Attributes","metadata":{"id":"8Vzm6a3dj1HQ"}},{"cell_type":"markdown","source":"##### n_clusters_ -- <sub><sup>*The number of clusters found by the algorithm.*</sup></sub>\n","metadata":{"id":"AX85uZ7Jj1HQ"}},{"cell_type":"markdown","source":"##### labels_ -- <sub><sup>*Cluster labels for each point.*</sup></sub>\n","metadata":{"id":"v2WLHkHSj1HQ"}},{"cell_type":"markdown","source":"##### n_leaves_ -- <sub><sup>*Number of leaves in the hierarchical tree.*</sup></sub>\n","metadata":{"id":"qhwDdySwj1HR"}},{"cell_type":"markdown","source":"## sklearn.ensemble","metadata":{"id":"wY4GRL5euJZ7"}},{"cell_type":"markdown","source":"### [RandomForestClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html)\n\n*A random forest is a meta estimator that fits a number of decision tree classifiers on various sub-samples of the dataset and uses averaging to improve the predictive accuracy and control over-fitting. The sub-sample size is controlled with the max_samples parameter if bootstrap=True (default), otherwise the whole dataset is used to build each tree.*","metadata":{"id":"FoO4V6F_GM1x"}},{"cell_type":"markdown","source":"#### Examples","metadata":{"id":"xtwMnzowGM1y"}},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.datasets import make_classification\nX, y = make_classification(n_samples=1000, n_features=4,\n                           n_informative=2, n_redundant=0,\n                           random_state=0, shuffle=False)\nclf = RandomForestClassifier(max_depth=2, random_state=0)\nclf.fit(X, y)\n\nprint(clf.predict([[0, 0, 0, 0]]))","metadata":{"outputId":"867bc6c9-4e29-4e3e-8029-ca810fb73135","id":"FZQd6FmBGM1z"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### Methods","metadata":{"id":"UN4lEZ7sGM1z"}},{"cell_type":"markdown","source":"##### fit -- <sub><sup>*Build a forest of trees from the training set (X, y).*</sup></sub>\n","metadata":{"id":"yC1fSRFmGM1z"}},{"cell_type":"markdown","source":"##### predict -- <sub><sup>*Predict class for X.*</sup></sub>\n","metadata":{"id":"iRI_andIGM1z"}},{"cell_type":"markdown","source":"##### score -- <sub><sup>*Return the mean accuracy on the given test data and labels.*</sup></sub>\n","metadata":{"id":"aiiSptxEGM1z"}},{"cell_type":"markdown","source":"#### Attributes","metadata":{"id":"xeMEG4-tG15p"}},{"cell_type":"markdown","source":"##### feature_importances_ -- <sub><sup>*The impurity-based feature importances.*</sup></sub>","metadata":{"id":"lLjWg0gcG15p"}},{"cell_type":"markdown","source":"### [RandomForestRegressor](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html)\n\n*A random forest is a meta estimator that fits a number of classifying decision trees on various sub-samples of the dataset and uses averaging to improve the predictive accuracy and control over-fitting. The sub-sample size is controlled with the max_samples parameter if bootstrap=True (default), otherwise the whole dataset is used to build each tree.*","metadata":{"id":"hRe591fVwS8F"}},{"cell_type":"markdown","source":"#### Examples","metadata":{"id":"LCCdGLIqqdoR"}},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor\nfrom sklearn.datasets import make_regression\nX, y = make_regression(n_features=4, n_informative=2,\n                       random_state=0, shuffle=False)\nregr = RandomForestRegressor(max_depth=2, random_state=0)\nregr.fit(X, y)\n\nprint(regr.predict([[0, 0, 0, 0]]))","metadata":{"id":"QQbHIaSco2Na","outputId":"1d524dfd-f8a3-485b-e5cb-1dc559de168f"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### Methods","metadata":{"id":"L7TphIsUqisx"}},{"cell_type":"markdown","source":"##### fit -- <sub><sup>*Build a forest of trees from the training set (X, y).*</sup></sub>\n","metadata":{"id":"71J3zWBaFJyi"}},{"cell_type":"markdown","source":"##### predict -- <sub><sup>*Predict regression target for X.*</sup></sub>\n","metadata":{"id":"DB6lD72KFJyi"}},{"cell_type":"markdown","source":"##### score -- <sub><sup>*Return the coefficient of determination of the prediction.*</sup></sub>\n","metadata":{"id":"H4UOLZGYFJyi"}},{"cell_type":"markdown","source":"#### Attributes","metadata":{"id":"rbamwOlpqisy"}},{"cell_type":"markdown","source":"##### feature_importances_ -- <sub><sup>*The impurity-based feature importances.*</sup></sub>","metadata":{"id":"oChOSumhqisy"}},{"cell_type":"markdown","source":"### [AdaBoostClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostClassifier.html)\n\n*An AdaBoost classifier is a meta-estimator that begins by fitting a classifier on the original dataset and then fits additional copies of the classifier on the same dataset but where the weights of incorrectly classified instances are adjusted such that subsequent classifiers focus more on difficult cases.*","metadata":{"id":"6poDWK8hDyih"}},{"cell_type":"markdown","source":"#### Examples","metadata":{"id":"Vj2tON4ODyii"}},{"cell_type":"code","source":"from sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.datasets import make_classification\nX, y = make_classification(n_samples=1000, n_features=4,\n                           n_informative=2, n_redundant=0,\n                           random_state=0, shuffle=False)\nclf = AdaBoostClassifier(n_estimators=100, random_state=0)\nclf.fit(X, y)\n\nclf.predict([[0, 0, 0, 0]])\n\nclf.score(X, y)","metadata":{"outputId":"893b1ec8-1ac1-463b-838d-99de64cbcb2d","id":"upak9QUADyii"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### Methods","metadata":{"id":"nEf5TS4vDyii"}},{"cell_type":"markdown","source":"##### fit -- <sub><sup>*Build a boosted classifier from the training set (X, y).*</sup></sub>\n","metadata":{"id":"ErdhZ7RODyij"}},{"cell_type":"markdown","source":"##### predict -- <sub><sup>*Predict classes for X.*</sup></sub>\n","metadata":{"id":"_EmNhYSNDyij"}},{"cell_type":"markdown","source":"##### score -- <sub><sup>*Return the mean accuracy on the given test data and labels.*</sup></sub>\n","metadata":{"id":"Dk50RChYDyij"}},{"cell_type":"markdown","source":"#### Attributes","metadata":{"id":"HuhsrQIWDyij"}},{"cell_type":"markdown","source":"##### feature_importances_ -- <sub><sup>*The impurity-based feature importances.*</sup></sub>","metadata":{"id":"-9YP2ATWDyij"}},{"cell_type":"markdown","source":"### [AdaBoostRegressor](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostRegressor.html)\n\n*An AdaBoost regressor is a meta-estimator that begins by fitting a regressor on the original dataset and then fits additional copies of the regressor on the same dataset but where the weights of instances are adjusted according to the error of the current prediction. As such, subsequent regressors focus more on difficult cases.*","metadata":{"id":"P1X2HUCSJpE9"}},{"cell_type":"markdown","source":"#### Examples","metadata":{"id":"5dCX2uKaJpE-"}},{"cell_type":"code","source":"from sklearn.ensemble import AdaBoostRegressor\nfrom sklearn.datasets import make_regression\nX, y = make_regression(n_features=4, n_informative=2,\n                       random_state=0, shuffle=False)\nregr = AdaBoostRegressor(random_state=0, n_estimators=100)\nregr.fit(X, y)\n\nregr.predict([[0, 0, 0, 0]])\n\nregr.score(X, y)","metadata":{"outputId":"ce79e849-9506-4d27-d0b1-1268e2d42c81","id":"tjy0WIgiJpE-"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### Methods","metadata":{"id":"c-x_29PsJpE-"}},{"cell_type":"markdown","source":"##### fit -- <sub><sup>*Build a boosted regressor from the training set (X, y).*</sup></sub>\n","metadata":{"id":"NoYipBYrJpE-"}},{"cell_type":"markdown","source":"##### predict -- <sub><sup>*Predict regression value for X.*</sup></sub>\n","metadata":{"id":"YQFiI8OyJpE-"}},{"cell_type":"markdown","source":"##### score -- <sub><sup>*Return the coefficient of determination of the prediction.*</sup></sub>\n","metadata":{"id":"-Tfg_TtsJpE_"}},{"cell_type":"markdown","source":"#### Attributes","metadata":{"id":"hGcpkBgYJpE_"}},{"cell_type":"markdown","source":"##### feature_importances_ -- <sub><sup>*The impurity-based feature importances.*</sup></sub>","metadata":{"id":"gaVN40yKJpE_"}},{"cell_type":"markdown","source":"### [BaggingClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.BaggingClassifier.html)\n\n*A Bagging classifier is an ensemble meta-estimator that fits base classifiers each on random subsets of the original dataset and then aggregate their individual predictions (either by voting or by averaging) to form a final prediction. Such a meta-estimator can typically be used as a way to reduce the variance of a black-box estimator (e.g., a decision tree), by introducing randomization into its construction procedure and then making an ensemble out of it.*","metadata":{"id":"G6VWHz4xFHXN"}},{"cell_type":"markdown","source":"#### Examples","metadata":{"id":"cqJ6Q7oAFHXO"}},{"cell_type":"code","source":"from sklearn.svm import SVC\nfrom sklearn.ensemble import BaggingClassifier\nfrom sklearn.datasets import make_classification\nX, y = make_classification(n_samples=100, n_features=4,\n                           n_informative=2, n_redundant=0,\n                           random_state=0, shuffle=False)\nclf = BaggingClassifier(base_estimator=SVC(),\n                        n_estimators=10, random_state=0).fit(X, y)\nclf.predict([[0, 0, 0, 0]])","metadata":{"outputId":"6d6cb198-5096-4b2f-e616-b8232331e188","id":"f9zjGh2LFHXO"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### Methods","metadata":{"id":"x-9fhDaWFHXO"}},{"cell_type":"markdown","source":"##### fit -- <sub><sup>*Build a Bagging ensemble of estimators from the training set (X, y).*</sup></sub>\n","metadata":{"id":"vjahmk2wFHXO"}},{"cell_type":"markdown","source":"##### predict -- <sub><sup>*Predict class for X.*</sup></sub>\n","metadata":{"id":"rR13omLzFHXP"}},{"cell_type":"markdown","source":"##### score -- <sub><sup>*Return the mean accuracy on the given test data and labels.*</sup></sub>\n","metadata":{"id":"HsiII_5qFHXP"}},{"cell_type":"markdown","source":"#### Attributes","metadata":{"id":"fL5hwKQuFHXP"}},{"cell_type":"markdown","source":"### [BaggingRegressor](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.BaggingRegressor.html)\n\n*Bagging regressor is an ensemble meta-estimator that fits base regressors each on random subsets of the original dataset and then aggregate their individual predictions (either by voting or by averaging) to form a final prediction. Such a meta-estimator can typically be used as a way to reduce the variance of a black-box estimator (e.g., a decision tree), by introducing randomization into its construction procedure and then making an ensemble out of it.*","metadata":{"id":"rq8L0r23HsB8"}},{"cell_type":"markdown","source":"#### Examples","metadata":{"id":"6T_sD2yMHsB8"}},{"cell_type":"code","source":"from sklearn.svm import SVR\nfrom sklearn.ensemble import BaggingRegressor\nfrom sklearn.datasets import make_regression\nX, y = make_regression(n_samples=100, n_features=4,\n                       n_informative=2, n_targets=1,\n                       random_state=0, shuffle=False)\nregr = BaggingRegressor(base_estimator=SVR(),\n                        n_estimators=10, random_state=0).fit(X, y)\nregr.predict([[0, 0, 0, 0]])","metadata":{"outputId":"84630335-a741-4e2c-fdc9-78bf5880bb4b","id":"RnTfRhHbHsB8"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### Methods","metadata":{"id":"-WeoFqFXHsB8"}},{"cell_type":"markdown","source":"##### fit -- <sub><sup>*Build a Bagging ensemble of estimators from the training set (X, y).*</sup></sub>\n","metadata":{"id":"scwNKaagHsB9"}},{"cell_type":"markdown","source":"##### predict -- <sub><sup>*Predict regression target for X.*</sup></sub>\n","metadata":{"id":"2kg438BtHsB9"}},{"cell_type":"markdown","source":"##### score -- <sub><sup>*Return the coefficient of determination of the prediction.*</sup></sub>\n","metadata":{"id":"c2RmPzFRHsB9"}},{"cell_type":"markdown","source":"#### Attributes","metadata":{"id":"THxXxCu3HsB9"}},{"cell_type":"markdown","source":"### [GradientBoostingClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html)\n\n*GB builds an additive model in a forward stage-wise fashion; it allows for the optimization of arbitrary differentiable loss functions. In each stage n_classes_ regression trees are fit on the negative gradient of the loss function, e.g. binary or multiclass log loss. Binary classification is a special case where only a single regression tree is induced.*","metadata":{"id":"xEcGt67DIrDU"}},{"cell_type":"markdown","source":"#### Examples","metadata":{"id":"hm9WvAvqIrDU"}},{"cell_type":"code","source":"from sklearn.datasets import make_hastie_10_2\nfrom sklearn.ensemble import GradientBoostingClassifier\n\nX, y = make_hastie_10_2(random_state=0)\nX_train, X_test = X[:2000], X[2000:]\ny_train, y_test = y[:2000], y[2000:]\nclf = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0,\n    max_depth=1, random_state=0).fit(X_train, y_train)\nclf.score(X_test, y_test)","metadata":{"outputId":"831c8a26-253b-4854-b67a-550f69f20d77","id":"CQAFvx8OIrDX"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### Methods","metadata":{"id":"Elu2MCdEIrDX"}},{"cell_type":"markdown","source":"##### fit -- <sub><sup>*Fit the gradient boosting model.*</sup></sub>\n","metadata":{"id":"TEK6VtsKIrDX"}},{"cell_type":"markdown","source":"##### predict -- <sub><sup>*Predict class for X.*</sup></sub>\n","metadata":{"id":"LQ_-QXsAIrDX"}},{"cell_type":"markdown","source":"##### score -- <sub><sup>*Return the mean accuracy on the given test data and labels.*</sup></sub>\n","metadata":{"id":"r9pB1osjIrDY"}},{"cell_type":"markdown","source":"#### Attributes","metadata":{"id":"HfnZW4EZJeRh"}},{"cell_type":"markdown","source":"##### feature_importances_ -- <sub><sup>*The impurity-based feature importances.*</sup></sub>","metadata":{"id":"uClncMfcJeRi"}},{"cell_type":"markdown","source":"### [GradientBoostingRegressor](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingRegressor.html)\n\n*GB builds an additive model in a forward stage-wise fashion; it allows for the optimization of arbitrary differentiable loss functions. In each stage a regression tree is fit on the negative gradient of the given loss function.*","metadata":{"id":"bU_XPZ7hKJkp"}},{"cell_type":"markdown","source":"#### Examples","metadata":{"id":"48KdZYKyKJkp"}},{"cell_type":"code","source":"from sklearn.datasets import make_regression\nfrom sklearn.ensemble import GradientBoostingRegressor\nfrom sklearn.model_selection import train_test_split\nX, y = make_regression(random_state=0)\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, random_state=0)\nreg = GradientBoostingRegressor(random_state=0)\nreg.fit(X_train, y_train)\n\nreg.predict(X_test[1:2])\n\nreg.score(X_test, y_test)","metadata":{"outputId":"ff0742b8-aaa4-489b-c524-83df64a2fd2c","id":"_NSaUkbQKJkp"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### Methods","metadata":{"id":"9KrJpWFuKJkp"}},{"cell_type":"markdown","source":"##### fit -- <sub><sup>*Fit the gradient boosting model.*</sup></sub>\n","metadata":{"id":"wP8-3j-LKJkq"}},{"cell_type":"markdown","source":"##### predict -- <sub><sup>*Predict regression target for X.*</sup></sub>\n","metadata":{"id":"woLw54dvKJkq"}},{"cell_type":"markdown","source":"##### score -- <sub><sup>*Return the coefficient of determination of the prediction.*</sup></sub>\n","metadata":{"id":"z7l3MG8aKJkq"}},{"cell_type":"markdown","source":"#### Attributes","metadata":{"id":"4styVad0KJkq"}},{"cell_type":"markdown","source":"##### feature_importances_ -- <sub><sup>*The impurity-based feature importances.*</sup></sub>","metadata":{"id":"Ywr_-M-gKJkq"}},{"cell_type":"markdown","source":"## sklearn.dummy","metadata":{"id":"HXVfmfEBuMFH"}},{"cell_type":"markdown","source":"### [DummyRegressor](https://scikit-learn.org/stable/modules/generated/sklearn.dummy.DummyRegressor.html)\n\n*Regressor that makes predictions using simple rules.*\n\n*This regressor is useful as a simple baseline to compare with other (real) regressors. Do not use it for real problems.*","metadata":{"id":"6kGKyr2RwOQd"}},{"cell_type":"markdown","source":"#### Examples","metadata":{"id":"tOJJFV5jpmF9"}},{"cell_type":"code","source":"import numpy as np\nfrom sklearn.dummy import DummyRegressor\nX = np.array([1.0, 2.0, 3.0, 4.0])\ny = np.array([2.0, 3.0, 5.0, 10.0])\ndummy_regr = DummyRegressor(strategy=\"mean\")\ndummy_regr.fit(X, y)","metadata":{"id":"tJtrzW7ipCfR","outputId":"5cfa82dd-895a-4573-88d2-2f71fb0cd78e"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"dummy_regr.predict(X)","metadata":{"id":"aBEXqO0zpF6q","outputId":"628ac61a-e6ee-4d3c-bbad-2844193d8206"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"dummy_regr.score(X, y)","metadata":{"id":"9b5OaCE3pGUK","outputId":"bb8b6420-80fe-4a47-9a35-6c73b2b2427f"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### Methods","metadata":{"id":"GFJu28DdppQr"}},{"cell_type":"markdown","source":"##### fit -- <sub><sup>*Fit the random regressor.*</sup></sub>\n","metadata":{"id":"GaVZ67uoFq_4"}},{"cell_type":"markdown","source":"##### predict -- <sub><sup>*Perform classification on test vectors X.*</sup></sub>\n","metadata":{"id":"UmyXHHIGFq_4"}},{"cell_type":"markdown","source":"##### score -- <sub><sup>*Return the coefficient of determination of the prediction.*</sup></sub>\n","metadata":{"id":"HKd6FwJ0Fq_5"}},{"cell_type":"markdown","source":"### [DummyClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.dummy.DummyClassifier.html)\n\n*DummyClassifier makes predictions that ignore the input features.*\n\n*This classifier serves as a simple baseline to compare against other more complex classifiers. The specific behavior of the baseline is selected with the strategy parameter.*","metadata":{"id":"_WQ1kTDTwRXx"}},{"cell_type":"code","source":"import numpy as np\nfrom sklearn.dummy import DummyClassifier\nX = np.array([-1, 1, 1, 1])\ny = np.array([0, 1, 1, 1])\ndummy_clf = DummyClassifier(strategy=\"most_frequent\")\ndummy_clf.fit(X, y)","metadata":{"id":"LemtVV_Gp_Dy","outputId":"b3a4dca9-8846-4ed6-f3e3-69e10b424768"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"dummy_clf.predict(X)","metadata":{"id":"j3P4Ny68qBts","outputId":"8c3f978d-b495-4e10-c128-2e7971408f11"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"dummy_clf.score(X, y)","metadata":{"id":"R6Dc44qoqCEq","outputId":"412ccf2b-afa5-4d20-d5dc-61c378556e0d"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## sklearn.datasets","metadata":{"id":"fngy8yFSuPlT"}},{"cell_type":"markdown","source":"### [load_iris](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_iris.html)\n\n*Load and return the iris dataset (classification).*\n\n*The iris dataset is a classic and very easy multi-class classification dataset.*","metadata":{"id":"d_IDaDlWvrWe"}},{"cell_type":"code","source":"from sklearn.datasets import load_iris\ndata = load_iris()\ndata.target[[10, 25, 50]]","metadata":{"id":"ASeSG_a2qY3u","outputId":"4235013a-855b-4264-86ff-977a8874dffb"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"list(data.target_names)","metadata":{"id":"RZ5PQZIFqdXu","outputId":"6f381103-a306-482e-d2ef-2b22fa0cc399"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### [fetch_california_housing](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_california_housing.html)\n","metadata":{"id":"nbmE-wEtvtQY"}},{"cell_type":"markdown","source":"### [fetch_openml](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_openml.html)\n","metadata":{"id":"TVQp-tZXvugr"}},{"cell_type":"markdown","source":"### [make_regression](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_regression.html)\n","metadata":{"id":"p39i1UEjvvrh"}},{"cell_type":"markdown","source":"### [make_blobs](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_blobs.html)\n","metadata":{"id":"fcY7hiaTvwXw"}},{"cell_type":"code","source":"from sklearn.datasets import make_blobs\nX, y = make_blobs(n_samples=10, centers=3, n_features=2,\n                  random_state=0)\nprint(X.shape)\n\ny","metadata":{"id":"UYXjuDL-rNNN","outputId":"758e50df-9611-4537-ca52-0efeeb657ad3"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X, y = make_blobs(n_samples=[3, 3, 4], centers=None, n_features=2,\n                  random_state=0)\nprint(X.shape)\n\ny","metadata":{"id":"vujEgwKErSBM","outputId":"4e4e9a35-46ff-4e9c-ab00-905ef19167ce"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### [make_classification](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_classification.html)\n","metadata":{"id":"jQFlqSVTvxB_"}},{"cell_type":"markdown","source":"### [make_multilabel_classification](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_multilabel_classification.html)","metadata":{"id":"XQ0QdL8Uvxq5"}},{"cell_type":"markdown","source":"## keras.datasets","metadata":{"id":"tlbOxce9uQ8u"}},{"cell_type":"markdown","source":"### [mnist](https://keras.io/api/datasets/mnist/)\n\n*Loads the MNIST dataset.*\n\n*This is a dataset of 60,000 28x28 grayscale images of the 10 digits, along with a test set of 10,000 images.*","metadata":{"id":"OJ2yhyPQvkAd"}},{"cell_type":"code","source":"(X_train, y_train), (X_test, y_test) = mnist.load_data()\nassert X_train.shape == (60000, 28, 28)\nassert X_test.shape == (10000, 28, 28)\nassert y_train.shape == (60000,)\nassert y_test.shape == (10000,)","metadata":{"id":"tlGQhr6p5WRd","outputId":"a0e7af82-ebb6-484c-af0c-20c16c59df33"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## sklearn.model_selection","metadata":{"id":"AUJTNJnbudUA"}},{"cell_type":"markdown","source":"### [train_test_split](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html)\n\n*Split arrays or matrices into random train and test subsets.*","metadata":{"id":"hZOyDdhjujfO"}},{"cell_type":"code","source":"import numpy as np\nfrom sklearn.model_selection import train_test_split\nX, y = np.arange(10).reshape((5, 2)), range(5)\nX","metadata":{"id":"GmXZeXGn5jGL","outputId":"1aa5d946-a572-4d36-d8e6-0bad4a7c8785"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"list(y)","metadata":{"id":"8QV0BJEw5m_X","outputId":"6619117c-a556-48d8-eb17-01062ff7c0fe"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.33, random_state=42)\n\nX_train","metadata":{"id":"0vaLfaXH5q0F","outputId":"181c7d39-666d-4aff-f179-b1685321a116"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"y_train","metadata":{"id":"5MZiExoY5rtA","outputId":"1a3e9b69-68d0-471a-9aa1-4c31b8c11e69"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X_test","metadata":{"id":"Im_CG02Q5sIa","outputId":"19543953-d0bf-43e6-b7e9-ca9ca604e1a4"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"y_test","metadata":{"id":"VYH0LCdd5shC","outputId":"7115f7ac-9cf5-4d23-f9bb-2010fa0d87ea"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_test_split(y, shuffle=False)","metadata":{"id":"MWiu-8n_5x45","outputId":"a82c8669-d401-4259-b4bd-f78228d0c01b"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### [cross_validate](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_validate.html)\n\n*Evaluate metric(s) by cross-validation and also record fit/score times.*","metadata":{"id":"FtiNR3oKumaC"}},{"cell_type":"code","source":"from sklearn import datasets, linear_model\nfrom sklearn.model_selection import cross_validate\nfrom sklearn.metrics import make_scorer\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.svm import LinearSVC\ndiabetes = datasets.load_diabetes()\nX = diabetes.data[:150]\ny = diabetes.target[:150]\nlasso = linear_model.Lasso()","metadata":{"id":"qHEswvq96Acg"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Single metric evaluation using cross_validate\ncv_results = cross_validate(lasso, X, y, cv=3)\nsorted(cv_results.keys())\n\ncv_results['test_score']","metadata":{"id":"WIhutRsq6GmZ","outputId":"cbd0775c-9240-47d5-91b1-3ae48ac5a479"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Multiple metric evaluation using cross_validate\nscores = cross_validate(lasso, X, y, cv=3,\n                        scoring=('r2', 'neg_mean_squared_error'),\n                        return_train_score=True)\nprint(scores['test_neg_mean_squared_error'])\n\nprint(scores['train_r2'])","metadata":{"id":"gy1tlNZ36LWP","outputId":"fbf1d3ff-3dda-4854-f54a-52fc25963d96"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### [cross_val_score](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html)\n\n*Evaluate a score by cross-validation.*","metadata":{"id":"k_c3Eno3undD"}},{"cell_type":"code","source":"from sklearn import datasets, linear_model\nfrom sklearn.model_selection import cross_val_score\ndiabetes = datasets.load_diabetes()\nX = diabetes.data[:150]\ny = diabetes.target[:150]\nlasso = linear_model.Lasso()\nprint(cross_val_score(lasso, X, y, cv=3))","metadata":{"id":"uy3pBTFq6Ydj","outputId":"d9dc94d8-59aa-4367-899d-1d5c7e165259"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### [cross_val_predict](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_predict.html)\n\n*Generate cross-validated estimates for each input data point.*\n\n*The data is split according to the cv parameter. Each sample belongs to exactly one test set, and its prediction is computed with an estimator fitted on the corresponding training set.*\n","metadata":{"id":"B4P5ZSdvuoIw"}},{"cell_type":"code","source":"from sklearn import datasets, linear_model\nfrom sklearn.model_selection import cross_val_predict\ndiabetes = datasets.load_diabetes()\nX = diabetes.data[:150]\ny = diabetes.target[:150]\nlasso = linear_model.Lasso()\ny_pred = cross_val_predict(lasso, X, y, cv=3)","metadata":{"id":"8FOgT2Cj6hz2"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### [learning_curve](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.learning_curve.html)\n\n*Determines cross-validated training and test scores for different training set sizes.*\n\n*A cross-validation generator splits the whole dataset k times in training and test data. Subsets of the training set with varying sizes will be used to train the estimator and a score for each training subset size and the test set will be computed. Afterwards, the scores will be averaged over all k runs for each training subset size.*\n","metadata":{"id":"BUUwMAvDuozT"}},{"cell_type":"markdown","source":"### [validation_curve](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.validation_curve.html)\n\n*Determine training and test scores for varying parameter values.*\n\n*Compute scores for an estimator with different values of a specified parameter. This is similar to grid search with one parameter. However, this will also compute training scores and is merely a utility for plotting the results.*\n","metadata":{"id":"MJC1sTkEupcn"}},{"cell_type":"markdown","source":"### [ShuffleSplit](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.ShuffleSplit.html)\n\n*Random permutation cross-validator*\n\n*Yields indices to split data into training and test sets.*\n","metadata":{"id":"M0_gRvSBuqE3"}},{"cell_type":"code","source":"import numpy as np\nfrom sklearn.model_selection import ShuffleSplit\nX = np.array([[1, 2], [3, 4], [5, 6], [7, 8], [3, 4], [5, 6]])\ny = np.array([1, 2, 1, 2, 1, 2])\n","metadata":{"id":"3X-isIdh6-CF"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"rs = ShuffleSplit(n_splits=5, test_size=.25, random_state=0)\nrs.get_n_splits(X)\n\nprint(rs)\n\nfor train_index, test_index in rs.split(X):\n    print(\"TRAIN:\", train_index, \"TEST:\", test_index)","metadata":{"id":"zpff5BCA7IX1","outputId":"7e55022f-e709-402e-8689-a78f4149ffc0"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"rs = ShuffleSplit(n_splits=5, train_size=0.5, test_size=.25,\n                  random_state=0)\nfor train_index, test_index in rs.split(X):\n    print(\"TRAIN:\", train_index, \"TEST:\", test_index)","metadata":{"id":"Z90lN-Jp7GIc","outputId":"1d98e2be-be13-463d-f8b6-9d27aaa0e313"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### [StratifiedShuffleSplit](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedShuffleSplit.html)\n\n*Provides train/test indices to split data in train/test sets.*\n\n*This cross-validation object is a merge of StratifiedKFold and ShuffleSplit, which returns stratified randomized folds. The folds are made by preserving the percentage of samples for each class.*\n","metadata":{"id":"uqzVpOoouq7J"}},{"cell_type":"markdown","source":"#### Examples","metadata":{"id":"M23HastE8Z_N"}},{"cell_type":"code","source":"import numpy as np\nfrom sklearn.model_selection import StratifiedShuffleSplit\nX = np.array([[1, 2], [3, 4], [1, 2], [3, 4], [1, 2], [3, 4]])\ny = np.array([0, 0, 0, 1, 1, 1])\nsss = StratifiedShuffleSplit(n_splits=5, test_size=0.5, random_state=0)\nsss.get_n_splits(X, y)\n\nprint(sss)\n\nfor train_index, test_index in sss.split(X, y):\n    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n    X_train, X_test = X[train_index], X[test_index]\n    y_train, y_test = y[train_index], y[test_index]","metadata":{"id":"8ZwJe7LF7bQS","outputId":"afde6133-3a8b-4c70-dfd9-01590ae8c9c1"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### Methods","metadata":{"id":"9OJBs_gM8dbw"}},{"cell_type":"markdown","source":"##### split -- <sub><sup>*Generate indices to split data into training and test set.*</sup></sub>","metadata":{"id":"aYAWEi_W8lub"}},{"cell_type":"markdown","source":"### [permutation_test_score](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.permutation_test_score.html)\n\n*Evaluate the significance of a cross-validated score with permutations*\n\n*Permutes targets to generate â€˜randomized dataâ€™ and compute the empirical p-value against the null hypothesis that features and targets are independent.*","metadata":{"id":"Mo7l3tMeurgR"}},{"cell_type":"markdown","source":"### [GridSearchCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html)\n\n*Exhaustive search over specified parameter values for an estimator.*\n\n*The parameters of the estimator used to apply these methods are optimized by cross-validated grid-search over a parameter grid.*","metadata":{"id":"ocWsI4rOusGO"}},{"cell_type":"markdown","source":"#### Examples","metadata":{"id":"hpHmlrj565dm"}},{"cell_type":"code","source":"from sklearn import svm, datasets\nfrom sklearn.model_selection import GridSearchCV\niris = datasets.load_iris()\nparameters = {'kernel':('linear', 'rbf'), 'C':[1, 10]}\nsvc = svm.SVC()\nclf = GridSearchCV(svc, parameters)\nclf.fit(iris.data, iris.target)\n\nsorted(clf.cv_results_.keys())","metadata":{"id":"IdBescvo7wcx","outputId":"26b2a738-9125-4043-c408-f42af25bda27"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### Methods","metadata":{"id":"hGiBeTIP7AmA"}},{"cell_type":"markdown","source":"##### fit -- <sub><sup>*Run fit with all sets of parameters.*</sup></sub>\n","metadata":{"id":"wVAX6i_o7KF6"}},{"cell_type":"markdown","source":"##### predict -- <sub><sup>*Call predict on the estimator with the best found parameters.*</sup></sub>\n","metadata":{"id":"X6HK77Xp7UiG"}},{"cell_type":"markdown","source":"##### transform -- <sub><sup>*Call transform on the estimator with the best found parameters.*</sup></sub>\n","metadata":{"id":"8pc6jLduIcjp"}},{"cell_type":"markdown","source":"#### Attributes","metadata":{"id":"zUGS5iol7Ox3"}},{"cell_type":"markdown","source":"##### cv_results_ (only after fit) -- <sub><sup>*A dict with keys as column headers and values as columns, that can be imported into a pandas DataFrame.*</sup></sub>","metadata":{"id":"XMOfWJnP7VjC"}},{"cell_type":"markdown","source":"##### best_index_ -- <sub><sup>*The index (of the cv_results_ arrays) which corresponds to the best candidate parameter setting.*</sup></sub>\n","metadata":{"id":"VEey-etc7MK3"}},{"cell_type":"markdown","source":"##### best_estimator_ -- <sub><sup>Estimator that was chosen by the search, i.e. estimator which gave highest score (or smallest loss if specified) on the left out data.*</sup></sub>\n","metadata":{"id":"o4Y5GpDc7Wuf"}},{"cell_type":"markdown","source":"##### best_params_ -- <sub><sup>*Parameter setting that gave the best results on the hold out data.*</sup></sub>\n","metadata":{"id":"WdxY9lfy7Xdi"}},{"cell_type":"markdown","source":"##### best_score_ -- <sub><sup>*Mean cross-validated score of the best_estimator*</sup></sub>","metadata":{"id":"10XNH3x57YYu"}},{"cell_type":"markdown","source":"### [RandomizedSearchCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html)\n\n*The parameters of the estimator used to apply these methods are optimized by cross-validated search over parameter settings.*\n\n*In contrast to GridSearchCV, not all parameter values are tried out, but rather a fixed number of parameter settings is sampled from the specified distributions. The number of parameter settings that are tried is given by n_iter.*","metadata":{"id":"zgINp2kpusrX"}},{"cell_type":"markdown","source":"#### Examples","metadata":{"id":"r9TVmEZg7fZo"}},{"cell_type":"code","source":"from sklearn.datasets import load_iris\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import RandomizedSearchCV\nfrom scipy.stats import uniform\niris = load_iris()\nlogistic = LogisticRegression(solver='saga', tol=1e-2, max_iter=200,\n                              random_state=0)\ndistributions = dict(C=uniform(loc=0, scale=4),\n                     penalty=['l2', 'l1'])\nclf = RandomizedSearchCV(logistic, distributions, random_state=0)\nsearch = clf.fit(iris.data, iris.target)\nsearch.best_params_","metadata":{"id":"ofrvSnPF_uGg","outputId":"ad9f2491-a122-484d-ed1a-0e0308566ce7"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### Methods","metadata":{"id":"k1s2DgQS7k1R"}},{"cell_type":"markdown","source":"##### fit -- <sub><sup>*Run fit with all sets of parameters.*</sup></sub>\n","metadata":{"id":"iMH15MszJGp-"}},{"cell_type":"markdown","source":"##### predict -- <sub><sup>*Call predict on the estimator with the best found parameters.*</sup></sub>\n","metadata":{"id":"g50lTrz4JGp-"}},{"cell_type":"markdown","source":"##### transform -- <sub><sup>*Call transform on the estimator with the best found parameters.*</sup></sub>\n","metadata":{"id":"9iB8HTDfJGp-"}},{"cell_type":"markdown","source":"#### Attributes","metadata":{"id":"HCOcYU7v7k1S"}},{"cell_type":"markdown","source":"##### cv_results_ (only after fit) -- <sub><sup>*A dict with keys as column headers and values as columns, that can be imported into a pandas DataFrame.*</sup></sub>","metadata":{"id":"rnusImOMI6Ff"}},{"cell_type":"markdown","source":"##### best_index_ -- <sub><sup>*The index (of the cv_results_ arrays) which corresponds to the best candidate parameter setting.*</sup></sub>\n","metadata":{"id":"PLZMkPRTI6Fg"}},{"cell_type":"markdown","source":"##### best_estimator_ -- <sub><sup>Estimator that was chosen by the search, i.e. estimator which gave highest score (or smallest loss if specified) on the left out data.*</sup></sub>\n","metadata":{"id":"8kRQu9r-I6Fg"}},{"cell_type":"markdown","source":"##### best_params_ -- <sub><sup>*Parameter setting that gave the best results on the hold out data.*</sup></sub>\n","metadata":{"id":"-OmZRHcpI6Fg"}},{"cell_type":"markdown","source":"##### best_score_ -- <sub><sup>*Mean cross-validated score of the best_estimator*</sup></sub>","metadata":{"id":"ufHTMGa1I6Fh"}},{"cell_type":"markdown","source":"## sklearn.metrics","metadata":{"id":"nGncB17exx_a"}},{"cell_type":"markdown","source":"### [mean_squared_error](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_squared_error.html)\n\n*Mean squared error regression loss.*","metadata":{"id":"_d-JGltKxze9"}},{"cell_type":"code","source":"from sklearn.metrics import mean_squared_error\ny_true = [3, -0.5, 2, 7]\ny_pred = [2.5, 0.0, 2, 8]\nmean_squared_error(y_true, y_pred)","metadata":{"id":"2sKuz6XLAAzo","outputId":"be6d450c-1eba-4b70-cfa8-4bb3a32489fc"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"y_true = [3, -0.5, 2, 7]\ny_pred = [2.5, 0.0, 2, 8]\nmean_squared_error(y_true, y_pred, squared=False)","metadata":{"id":"Vzl13GTDANch","outputId":"276277f2-fa73-4470-cbbf-735c7f5656de"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"y_true = [[0.5, 1],[-1, 1],[7, -6]]\ny_pred = [[0, 2],[-1, 2],[8, -5]]\nmean_squared_error(y_true, y_pred)","metadata":{"id":"SztvgZYUARI2","outputId":"5dfd8473-c078-46c4-c39f-0fdbe90c4f2b"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"mean_squared_error(y_true, y_pred, squared=False)","metadata":{"id":"keYnIct5AUXw","outputId":"a0dbfa5f-839a-4001-8b1f-75012c2d9ed1"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"mean_squared_error(y_true, y_pred, multioutput='raw_values')","metadata":{"id":"M7C6rszhAFQD","outputId":"22e8eaa7-a1f6-405a-8d60-8fc7bb4357b4"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"mean_squared_error(y_true, y_pred, multioutput=[0.3, 0.7])","metadata":{"id":"A3Jgj_yEAFuq","outputId":"ab730f2f-40d5-4b01-db72-5577a0fe0ff6"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### [mean_absolute_error](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_absolute_error.html)\n\n*Mean absolute error regression loss.*","metadata":{"id":"gScnkk-cx6yy"}},{"cell_type":"code","source":"from sklearn.metrics import mean_absolute_error\ny_true = [3, -0.5, 2, 7]\ny_pred = [2.5, 0.0, 2, 8]\nmean_absolute_error(y_true, y_pred)","metadata":{"id":"GxRZAU0qAzue","outputId":"3e0e91c4-c74a-480f-a307-54bb5a5f615b"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"y_true = [[0.5, 1], [-1, 1], [7, -6]]\ny_pred = [[0, 2], [-1, 2], [8, -5]]\nmean_absolute_error(y_true, y_pred)","metadata":{"id":"1uAZ6mUuA3SI","outputId":"11986e4d-5cf4-4a0d-af71-3d00ad0793b5"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"mean_absolute_error(y_true, y_pred, multioutput='raw_values')","metadata":{"id":"QEs0xM4xA3_i","outputId":"d16701bd-0aaa-4b6e-9cfb-4d99e078b6a8"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"mean_absolute_error(y_true, y_pred, multioutput=[0.3, 0.7])","metadata":{"id":"AgcYTVp7A4Z1","outputId":"14f0067c-1f1c-4d7d-aa13-2d72bdafbedc"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### [mean_absolute_percentage_error](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_absolute_percentage_error.html)\n\n*Note here that the output is not a percentage in the range [0, 100] and a value of 100 does not mean 100% but 1e2. Furthermore, the output can be arbitrarily high when y_true is small (which is specific to the metric) or when abs(y_true - y_pred) is large (which is common for most regression metrics).*\n","metadata":{"id":"QKAUdFCKx7bX"}},{"cell_type":"code","source":"from sklearn.metrics import mean_absolute_percentage_error\ny_true = [3, -0.5, 2, 7]\ny_pred = [2.5, 0.0, 2, 8]\nmean_absolute_percentage_error(y_true, y_pred)","metadata":{"id":"Y4nI9RaSBCw7","outputId":"e3ca559a-9665-4207-ba80-e154039f964a"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"y_true = [[0.5, 1], [-1, 1], [7, -6]]\ny_pred = [[0, 2], [-1, 2], [8, -5]]\nmean_absolute_percentage_error(y_true, y_pred)","metadata":{"id":"19EcOL3fBGHK","outputId":"b389a427-0f56-4504-d1af-118568018e27"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"mean_absolute_percentage_error(y_true, y_pred, multioutput=[0.3, 0.7])","metadata":{"id":"aoBe-_AeBG08","outputId":"906d4438-171e-41b2-df7f-16ad59681643"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# the value when some element of the y_true is zero is arbitrarily high because\n# of the division by epsilon\ny_true = [1., 0., 2.4, 7.]\ny_pred = [1.2, 0.1, 2.4, 8.]\nmean_absolute_percentage_error(y_true, y_pred)","metadata":{"id":"_YDOzGUxBHzB","outputId":"8d2e422a-44f5-4863-ae1a-dbd2f1ed6b32"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### [log_loss](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.log_loss.html)\n\n*This is the loss function used in (multinomial) logistic regression and extensions of it such as neural networks, defined as the negative log-likelihood of a logistic model that returns y_pred probabilities for its training data y_true. The log loss is only defined for two or more labels.*\n","metadata":{"id":"wIvEuI5_x8D9"}},{"cell_type":"code","source":"from sklearn.metrics import log_loss\nlog_loss([\"spam\", \"ham\", \"ham\", \"spam\"],\n         [[.1, .9], [.9, .1], [.8, .2], [.35, .65]])","metadata":{"id":"P8ktuD5aBWYA","outputId":"a4634f63-8317-49d5-a5d4-96b8bcc44a60"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### [hinge_loss](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.hinge_loss.html)\n\n*Average hinge loss (non-regularized).*\n\n*The cumulated hinge loss is therefore an upper bound of the number of mistakes made by the classifier.*","metadata":{"id":"o3ocRfYMx8sA"}},{"cell_type":"code","source":"from sklearn import svm\nfrom sklearn.metrics import hinge_loss\nX = [[0], [1]]\ny = [-1, 1]\nest = svm.LinearSVC(random_state=0)\nest.fit(X, y)","metadata":{"id":"EwBqNlfwBf1Z","outputId":"912e4800-7e0d-42d6-a943-a037b6878771"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pred_decision = est.decision_function([[-2], [3], [0.5]])\npred_decision","metadata":{"id":"NyOmEIvBBktd","outputId":"43e2c7db-0e1a-4929-b863-4afbe4910790"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"hinge_loss([-1, 1, 1], pred_decision)","metadata":{"id":"rFGGTZoCBli7","outputId":"dcfb9cc4-a648-4589-eb9b-a101661dd0ef"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"In the multiclass case:","metadata":{"id":"zYdJ_hGlBq9x"}},{"cell_type":"code","source":"import numpy as np\nX = np.array([[0], [1], [2], [3]])\nY = np.array([0, 1, 2, 3])\nlabels = np.array([0, 1, 2, 3])\nest = svm.LinearSVC()\nest.fit(X, Y)","metadata":{"id":"JSfSjOW-Boxb","outputId":"598bf754-3b6f-4fc5-ab28-c13f66887a8e"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pred_decision = est.decision_function([[-1], [2], [3]])\npred_decision","metadata":{"id":"1tdbL_wlBtaF","outputId":"93de33e5-7c64-495d-fa6f-c35333e1438d"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"y_true = [0, 2, 3]\nhinge_loss(y_true, pred_decision, labels=labels)","metadata":{"id":"blukKFpvBuaH","outputId":"2912e4c4-db53-4cf7-eed3-7168d5f090e5"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### [confusion_matrix](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html)","metadata":{"id":"SpWkDSBWx9Ux"}},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\ny_true = [2, 0, 2, 2, 0, 1]\ny_pred = [0, 0, 2, 2, 0, 2]\nconfusion_matrix(y_true, y_pred)","metadata":{"id":"ptzmQEwAB6TB","outputId":"7e264464-9b58-4549-9b56-2028b15a4090"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"y_true = [\"cat\", \"ant\", \"cat\", \"cat\", \"ant\", \"bird\"]\ny_pred = [\"ant\", \"ant\", \"cat\", \"cat\", \"ant\", \"cat\"]\nconfusion_matrix(y_true, y_pred, labels=[\"ant\", \"bird\", \"cat\"])","metadata":{"id":"a5PVcbXKB_6t","outputId":"5065879c-4eac-4951-d17d-c082de60af11"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"In the binary case, we can extract true positives, etc as follows:","metadata":{"id":"kq033yJ6CI0P"}},{"cell_type":"code","source":"tn, fp, fn, tp = confusion_matrix([0, 1, 0, 1], [1, 1, 1, 0]).ravel()\n(tn, fp, fn, tp)","metadata":{"id":"tOIpZLH_CJpV","outputId":"c6708117-9e8d-4252-9ee7-93fa1f4aa46d"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### [ConfusionMatrixDisplay](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.ConfusionMatrixDisplay.html)\n\n*Compute confusion matrix to evaluate the accuracy of a classification.*","metadata":{"id":"SCGpuoobx99h"}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nfrom sklearn.datasets import make_classification\nfrom sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.svm import SVC\nX, y = make_classification(random_state=0)\nX_train, X_test, y_train, y_test = train_test_split(X, y,\n                                                    random_state=0)\nclf = SVC(random_state=0)\nclf.fit(X_train, y_train)\n\npredictions = clf.predict(X_test)\ncm = confusion_matrix(y_test, predictions, labels=clf.classes_)\ndisp = ConfusionMatrixDisplay(confusion_matrix=cm,\n                              display_labels=clf.classes_)\ndisp.plot()\n\nplt.show()","metadata":{"id":"L2aBinRGChOC","outputId":"8be233f9-698d-426b-d801-3f26b5947658"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nfrom sklearn.datasets import make_classification\nfrom sklearn.metrics import ConfusionMatrixDisplay\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.svm import SVC\nX, y = make_classification(random_state=0)\nX_train, X_test, y_train, y_test = train_test_split(\n        X, y, random_state=0)\nclf = SVC(random_state=0)\nclf.fit(X_train, y_train)\n\nConfusionMatrixDisplay.from_estimator(\n    clf, X_test, y_test)\n\nplt.show()","metadata":{"id":"GtMizvl7CmWz","outputId":"f3a76b77-9d13-4013-f2fc-16353b29ca7a"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nfrom sklearn.datasets import make_classification\nfrom sklearn.metrics import ConfusionMatrixDisplay\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.svm import SVC\nX, y = make_classification(random_state=0)\nX_train, X_test, y_train, y_test = train_test_split(\n        X, y, random_state=0)\nclf = SVC(random_state=0)\nclf.fit(X_train, y_train)\n\ny_pred = clf.predict(X_test)\nConfusionMatrixDisplay.from_predictions(\n   y_test, y_pred)\n\nplt.show()","metadata":{"id":"NajwcRGiCp-a","outputId":"49f23490-d562-446f-ada6-5d33a90ba050"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### [precision_score](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_score.html)\n\n*The precision is the ratio tp / (tp + fp) where tp is the number of true positives and fp the number of false positives. The precision is intuitively the ability of the classifier not to label as positive a sample that is negative.*\n\n*The best value is 1 and the worst value is 0.*","metadata":{"id":"R1rwTKVSx-l5"}},{"cell_type":"code","source":"from sklearn.metrics import precision_score\ny_true = [0, 1, 2, 0, 1, 2]\ny_pred = [0, 2, 1, 0, 0, 1]\nprecision_score(y_true, y_pred, average='macro')","metadata":{"id":"PtzFNmaKC0dj","outputId":"68cdbde4-8785-498a-874b-c8e8f7fbefda"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"precision_score(y_true, y_pred, average='micro')","metadata":{"id":"Uh9-Hb8tDBL8","outputId":"84ce804f-c19f-4632-b387-242a572f1989"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"precision_score(y_true, y_pred, average='weighted')","metadata":{"id":"QjcRuXndDB5J","outputId":"72aa3675-5454-475e-ab0a-22306a594f9f"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"precision_score(y_true, y_pred, average=None)","metadata":{"id":"M3jLV_IWDCUC","outputId":"4c85de41-2e0b-4b3d-8ca3-211341a5e97a"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"y_pred = [0, 0, 0, 0, 0, 0]\nprecision_score(y_true, y_pred, average=None)","metadata":{"id":"MBI7FEPYDC1b","outputId":"e2910a45-7513-4e27-ab18-e741098477db"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"precision_score(y_true, y_pred, average=None, zero_division=1)","metadata":{"id":"9j8wOuKbDDc8","outputId":"c427c355-e9bd-4326-fbf4-15cc80cb26f0"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# multilabel classification\ny_true = [[0, 0, 0], [1, 1, 1], [0, 1, 1]]\ny_pred = [[0, 0, 0], [1, 1, 1], [1, 1, 0]]\nprecision_score(y_true, y_pred, average=None)","metadata":{"id":"3TIYYe3-DD7r","outputId":"0d1a442b-4be6-42c3-bfaa-87b0f5a42efc"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### [recall_score](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.recall_score.html)\n\n*The recall is the ratio tp / (tp + fn) where tp is the number of true positives and fn the number of false negatives. The recall is intuitively the ability of the classifier to find all the positive samples.*\n\n*The best value is 1 and the worst value is 0.*","metadata":{"id":"gfsyJkWox_Pt"}},{"cell_type":"code","source":"from sklearn.metrics import recall_score\ny_true = [0, 1, 2, 0, 1, 2]\ny_pred = [0, 2, 1, 0, 0, 1]\nrecall_score(y_true, y_pred, average='macro')","metadata":{"id":"f9G03CunDSQO","outputId":"b8c62ae1-7860-4ca8-dd6d-8984bbe11488"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"recall_score(y_true, y_pred, average='micro')","metadata":{"id":"HcD06yirDWCo","outputId":"81987875-ec5b-4f2b-b164-0799bafce323"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"recall_score(y_true, y_pred, average='weighted')","metadata":{"id":"V938BaEzDWlO","outputId":"3c6c8229-7bb4-4c96-9367-8ea6cba86af8"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"recall_score(y_true, y_pred, average=None)","metadata":{"id":"lPSp7WfbDXCt","outputId":"0ca9511f-0faf-49d5-b7fc-4f79d6dbd70b"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"y_true = [0, 0, 0, 0, 0, 0]\nrecall_score(y_true, y_pred, average=None)","metadata":{"id":"avABix6yDXc3","outputId":"c9b04319-c79f-4f6c-903f-fed35fe0ee08"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"recall_score(y_true, y_pred, average=None, zero_division=1)","metadata":{"id":"N3R6CSXyDX5A","outputId":"2f19ce62-43e3-4834-9df7-0e6a3df3587b"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# multilabel classification\ny_true = [[0, 0, 0], [1, 1, 1], [0, 1, 1]]\ny_pred = [[0, 0, 0], [1, 1, 1], [1, 1, 0]]\nrecall_score(y_true, y_pred, average=None)","metadata":{"id":"5IgeUl7YDYSk","outputId":"5f78f96c-7dc5-4e62-f416-0d11ffacf431"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### [silhouette_score](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.silhouette_score.html)\n\n*Compute the mean Silhouette Coefficient of all samples.*\n\n*The Silhouette Coefficient is calculated using the mean intra-cluster distance (a) and the mean nearest-cluster distance (b) for each sample. The Silhouette Coefficient for a sample is (b - a) / max(a, b). To clarify, b is the distance between a sample and the nearest cluster that the sample is not a part of.*\n\n*The best value is 1 and the worst value is -1.*","metadata":{"id":"HthWYZeFgVK8"}},{"cell_type":"code","source":"#sklearn.metrics.silhouette_score(X, labels)","metadata":{"id":"84XoojWWgVK_"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### [make_scorer](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.make_scorer.html)\n\n*This factory function wraps scoring functions for use in GridSearchCV and cross_val_score. It takes a score function, such as accuracy_score, mean_squared_error, adjusted_rand_score or average_precision_score and returns a callable that scores an estimatorâ€™s output. The signature of the call is (estimator, X, y) where estimator is the model to be evaluated, X is the data and y is the ground truth labeling (or None in the case of unsupervised models).*","metadata":{"id":"6jOWb3bGx_3b"}},{"cell_type":"code","source":"from sklearn.metrics import fbeta_score, make_scorer\nftwo_scorer = make_scorer(fbeta_score, beta=2)\nftwo_scorer","metadata":{"id":"OeC1UDDCDpey","outputId":"b1b647ad-46dd-452b-8e19-baee64f005d8"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV\nfrom sklearn.svm import LinearSVC\ngrid = GridSearchCV(LinearSVC(), param_grid={'C': [1, 10]},\n                    scoring=ftwo_scorer)","metadata":{"id":"NS8mR_cFDttT"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### [classification_report](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html)\n\n*Build a text report showing the main classification metrics.*","metadata":{"id":"FBQ9fBMOyAfq"}},{"cell_type":"code","source":"from sklearn.metrics import classification_report\ny_true = [0, 1, 2, 2, 2]\ny_pred = [0, 0, 2, 2, 1]\ntarget_names = ['class 0', 'class 1', 'class 2']\nprint(classification_report(y_true, y_pred, target_names=target_names))","metadata":{"id":"Vngy3CY_D7ka","outputId":"a4122f1b-cf73-491f-d7c2-1bc4aafc0842"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"y_pred = [1, 1, 0]\ny_true = [1, 1, 1]\nprint(classification_report(y_true, y_pred, labels=[1, 2, 3], digits=4)) # precision of 4 decimals.","metadata":{"id":"gzVzid40D9NQ","outputId":"8c7a3463-7eb8-49c2-e765-eb8032ac9496"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### [precision_recall_curve](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_recall_curve.html)\n\n*Compute precision-recall pairs for different probability thresholds.*\n\n*Note: this implementation is restricted to the binary classification task.*","metadata":{"id":"itbW67nnyBHY"}},{"cell_type":"code","source":"import numpy as np\nfrom sklearn.metrics import precision_recall_curve\ny_true = np.array([0, 0, 1, 1])\ny_scores = np.array([0.1, 0.4, 0.35, 0.8])\nprecision, recall, thresholds = precision_recall_curve(\n    y_true, y_scores)\nprecision","metadata":{"id":"rjo9LdPfEMPI","outputId":"8995d36b-2307-43ff-e3c8-0ecadae79234"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"recall","metadata":{"id":"RN3XIRePEPIL","outputId":"6a7c58ee-b56d-4600-b191-426b47499c9e"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"thresholds","metadata":{"id":"F7NjYS0_EPtU","outputId":"13b25aa3-f699-468b-9592-b2b952aa0896"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### [roc_curve](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_curve.html)\n\n*Compute Receiver operating characteristic (ROC).*","metadata":{"id":"RqNDroe0yBuW"}},{"cell_type":"code","source":"import numpy as np\nfrom sklearn import metrics\ny = np.array([1, 1, 2, 2])\nscores = np.array([0.1, 0.4, 0.35, 0.8])\nfpr, tpr, thresholds = metrics.roc_curve(y, scores, pos_label=2)\nfpr","metadata":{"id":"BZp8Lhk1E7Bq","outputId":"2e010efc-0829-4068-981c-f7f1cbd6c660"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"tpr","metadata":{"id":"lsDvCEIRE72h","outputId":"dbbb62f8-2f05-40ca-8edd-9775ecb4bf05"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"thresholds","metadata":{"id":"GSn6wWrME8XY","outputId":"165a7f94-26d5-4222-c35b-6dd71f49de4c"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## sklearn.decomposition","metadata":{"id":"Ti4CsTnSyH20"}},{"cell_type":"markdown","source":"### [PCA](https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html)\n\n*Principal component analysis (PCA).*\n\n*Linear dimensionality reduction using Singular Value Decomposition of the data to project it to a lower dimensional space. The input data is centered but not scaled for each feature before applying the SVD.*","metadata":{"id":"MmIGbrKJyKD3"}},{"cell_type":"markdown","source":"#### Examples","metadata":{"id":"XXe_kLshfjC9"}},{"cell_type":"code","source":"import numpy as np\nfrom sklearn.decomposition import PCA\nX = np.array([[-1, -1], [-2, -1], [-3, -2], [1, 1], [2, 1], [3, 2]])\npca = PCA(n_components=2)\npca.fit(X)\n\nprint(pca.explained_variance_ratio_)\n\nprint(pca.singular_values_)","metadata":{"id":"a5lYFFzPFdoc","outputId":"662f60b7-f9bf-437c-cf63-b58af79c56f4"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pca = PCA(n_components=2, svd_solver='full')\npca.fit(X)\n\nprint(pca.explained_variance_ratio_)\n\nprint(pca.singular_values_)","metadata":{"id":"mo4p9do-FkGB","outputId":"739a8c2e-5366-48c0-f05d-ceb1d29315ad"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pca = PCA(n_components=1, svd_solver='arpack')\npca.fit(X)\n\nprint(pca.explained_variance_ratio_)\n\nprint(pca.singular_values_)","metadata":{"id":"-H4YuhVXFn4o","outputId":"46f7f506-b833-484a-afdb-8a4778453c0c"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### Methods","metadata":{"id":"hhgnD32Dfm6O"}},{"cell_type":"markdown","source":"##### fit -- <sub><sup>*Fit the model with X.*</sup></sub>\n","metadata":{"id":"Ni2x9oC6fvWk"}},{"cell_type":"markdown","source":"##### transform -- <sub><sup>*Apply dimensionality reduction to X.*</sup></sub>\n","metadata":{"id":"69R-4-7Yf0py"}},{"cell_type":"markdown","source":"##### fit_transform -- <sub><sup>*Fit the model with X and apply the dimensionality reduction on X.*</sup></sub>\n","metadata":{"id":"fSoTUY4Af1RY"}},{"cell_type":"markdown","source":"#### Attributes","metadata":{"id":"3B-FvVPA9Dwq"}},{"cell_type":"markdown","source":"##### explained_variance_ -- <sub><sup>*The amount of variance explained by each of the selected components. The variance estimation uses n_samples - 1 degrees of freedom.  Equal to n_components largest eigenvalues of the covariance matrix of X.*</sup></sub>","metadata":{"id":"29uptjQrf15g"}},{"cell_type":"markdown","source":"## sklearn.pipeline","metadata":{"id":"uMCRcAZyyMGD"}},{"cell_type":"markdown","source":"### [make_pipeline](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.make_pipeline.html)\n\n*This is a shorthand for the Pipeline constructor; it does not require, and does not permit, naming the estimators. Instead, their names will be set to the lowercase of their types automatically.*","metadata":{"id":"pebkHEtByUvz"}},{"cell_type":"code","source":"from sklearn.naive_bayes import GaussianNB\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.pipeline import make_pipeline\nmake_pipeline(StandardScaler(), GaussianNB(priors=None))","metadata":{"id":"m5ZUpJ_RFxeu","outputId":"831e93ef-e570-44be-fdd5-dc6948fcf1d6"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### [Pipeline](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html)\n\n*Sequentially apply a list of transforms and a final estimator. Intermediate steps of the pipeline must be â€˜transformsâ€™, that is, they must implement fit and transform methods. The final estimator only needs to implement fit. The transformers in the pipeline can be cached using memory argument.*","metadata":{"id":"mKmWyKWIyW4H"}},{"cell_type":"markdown","source":"#### Examples","metadata":{"id":"PegYo9EWniL_"}},{"cell_type":"code","source":"from sklearn.svm import SVC\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.datasets import make_classification\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.pipeline import Pipeline\nX, y = make_classification(random_state=0)\nX_train, X_test, y_train, y_test = train_test_split(X, y,\n                                                    random_state=0)\npipe = Pipeline([('scaler', StandardScaler()), ('svc', SVC())])\n# The pipeline can be used as any other estimator\n# and avoids leaking the test set into the train set\npipe.fit(X_train, y_train)\n\npipe.score(X_test, y_test)","metadata":{"id":"4WNUKflmF9ii","outputId":"db30b0b8-2092-401e-cbf4-4303ef1e1fff"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### Methods","metadata":{"id":"YINgQ8zznl_r"}},{"cell_type":"markdown","source":"##### fit -- <sub><sup>*Fit the model.*</sup></sub>","metadata":{"id":"ZX1bGnannl_r"}},{"cell_type":"markdown","source":"##### transform -- <sub><sup>*Transform the data, and apply transform with the final estimator.*</sup></sub>","metadata":{"id":"2tsug47Unl_r"}},{"cell_type":"markdown","source":"##### fit_transform -- <sub><sup>*Fit the model and transform with the final estimator.*</sup></sub>","metadata":{"id":"Fb0a9Titnl_r"}},{"cell_type":"markdown","source":"##### score -- <sub><sup>*Transform the data, and apply score with the final estimator.*</sup></sub>","metadata":{"id":"VNnMyNoxnl_r"}},{"cell_type":"markdown","source":"### [FeatureUnion](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.FeatureUnion.html)\n\n*This estimator applies a list of transformer Examples in parallel to the input data, then concatenates the results. This is useful to combine several feature extraction mechanisms into a single transformer.*","metadata":{"id":"fd0qCFxGyXcY"}},{"cell_type":"code","source":"from sklearn.pipeline import FeatureUnion\nfrom sklearn.decomposition import PCA, TruncatedSVD\nunion = FeatureUnion([(\"pca\", PCA(n_components=1)),\n                      (\"svd\", TruncatedSVD(n_components=2))])\nX = [[0., 1., 3], [2., 2., 5]]\nunion.fit_transform(X)","metadata":{"id":"Pu_EhDWFGKo5","outputId":"bb8c772e-25fb-4321-b655-b0616d8738c2"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## sklearn.set_config","metadata":{"id":"03raJE0QymCK"}},{"cell_type":"markdown","source":"### [set_config](https://scikit-learn.org/stable/modules/generated/sklearn.set_config.html)\n\n*Set global scikit-learn configuration*","metadata":{"id":"WHtDs86Ayo5z"}},{"cell_type":"markdown","source":"## sklearn.utils","metadata":{"id":"FFqHHmB41IUC"}},{"cell_type":"markdown","source":"### [all_estimators](https://scikit-learn.org/stable/modules/generated/sklearn.utils.all_estimators.html)\n\n*Get a list of all estimators from sklearn.*","metadata":{"id":"-SOEQlr31NGP"}},{"cell_type":"markdown","source":"## sklearn.utils.multiclass","metadata":{"id":"45usPcE91ZtO"}},{"cell_type":"markdown","source":"### [type_of_target](https://scikit-learn.org/stable/modules/generated/sklearn.utils.multiclass.type_of_target.html)\n\n*Determine the type of data indicated by the target.*","metadata":{"id":"WH4ErGqb1axo"}},{"cell_type":"code","source":"from sklearn.utils.multiclass import type_of_target\nimport numpy as np\ntype_of_target([0.1, 0.6])","metadata":{"id":"ykhX8ekvGxjd","outputId":"bee3f92e-b65b-4ef3-aba7-3364fff2abca"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"type_of_target([1, -1, -1, 1])","metadata":{"id":"ur_HkjBXG04b","outputId":"66cadd32-4119-4958-972f-62631f5a7fb6"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"type_of_target(['a', 'b', 'a'])","metadata":{"id":"5u2fJmO4G2JM","outputId":"c6391f98-e2b5-4115-eb43-bd539a3a8361"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"type_of_target([1.0, 2.0])","metadata":{"id":"OwqZbDY0G2mF","outputId":"66eb5380-3fff-423b-cb3b-2da099db4b59"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"type_of_target([1, 0, 2])","metadata":{"id":"SlmrghkgG28U","outputId":"a18acfeb-362f-477f-fb6b-909d723967e6"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"type_of_target([1.0, 0.0, 3.0])","metadata":{"id":"K4v7Wr2AG3Ry","outputId":"602c1211-03ba-41b8-af5f-0da429929b19"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"type_of_target(['a', 'b', 'c'])","metadata":{"id":"urd1ocf2G3lV","outputId":"cbf988f1-420b-48dc-fcc9-59cf400a6edc"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"type_of_target(np.array([[1, 2], [3, 1]]))","metadata":{"id":"aONjCju6G355","outputId":"01eea731-0f49-42fa-c9a4-ca26d313376f"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"type_of_target([[1, 2]])","metadata":{"id":"e-SnPgF_G4Pw","outputId":"a5552e21-2126-45cf-921e-12bba0707bff"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"type_of_target(np.array([[1.5, 2.0], [3.0, 1.6]]))","metadata":{"id":"PkdkoJfAG4lV","outputId":"ff1658c3-6b3f-4905-c271-df5f564faf47"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"type_of_target(np.array([[0, 1], [1, 1]]))","metadata":{"id":"xDpC2jZUG4-e","outputId":"1dff58e9-2df4-437e-a2e5-2bae6feeb5e3"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## scipy.stats","metadata":{"id":"6GMbzp0S1eFl"}},{"cell_type":"markdown","source":"### [uniform](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.uniform.html)\n\n*A uniform continuous random variable.*\n\n*In the standard form, the distribution is uniform on [0, 1]. Using the parameters loc and scale, one obtains the uniform distribution on [loc, loc + scale].*","metadata":{"id":"45m8gTwi1hrE"}},{"cell_type":"code","source":"from scipy.stats import uniform\nimport matplotlib.pyplot as plt\n\nfig, ax = plt.subplots(1, 1)\n\n# Calculate the first four moments:\nmean, var, skew, kurt = uniform.stats(moments='mvsk')\n\n# Display the probability density function (pdf):\nx = np.linspace(uniform.ppf(0.01),\n                uniform.ppf(0.99), 100)\nax.plot(x, uniform.pdf(x),\n       'r-', lw=5, alpha=0.6, label='uniform pdf')\n\n# Alternatively, the distribution object can be called (as a function) to fix the shape, location and scale parameters.\n# This returns a â€œfrozenâ€ RV object holding the given parameters fixed.\n#Freeze the distribution and display the frozen pdf.\n\nrv = uniform()\nax.plot(x, rv.pdf(x), 'k-', lw=2, label='frozen pdf')\n\n# Check accuracy of cdf and ppf:\nvals = uniform.ppf([0.001, 0.5, 0.999])\nnp.allclose([0.001, 0.5, 0.999], uniform.cdf(vals))\n\n# Generate random numbers:\nr = uniform.rvs(size=1000)\n\n# And compare the histogram:\nax.hist(r, density=True, histtype='stepfilled', alpha=0.2)\nax.legend(loc='best', frameon=False)\nplt.show()","metadata":{"id":"RsinNKXhHnNQ","outputId":"7d10705c-e5b1-40bb-8542-76587c779c43"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### [loguniform](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.loguniform.html)\n\n*A loguniform or reciprocal continuous random variable.*","metadata":{"id":"fO6oU0Ps1lJA"}},{"cell_type":"code","source":"from scipy.stats import loguniform\nimport matplotlib.pyplot as plt\nfig, ax = plt.subplots(1, 1)\n\n# Calculate the first four moments:\na, b = 0.01, 1.25\nmean, var, skew, kurt = loguniform.stats(a, b, moments='mvsk')\n\n# Display the probability density function (pdf):\nx = np.linspace(loguniform.ppf(0.01, a, b),\n                loguniform.ppf(0.99, a, b), 100)\nax.plot(x, loguniform.pdf(x, a, b),\n       'r-', lw=5, alpha=0.6, label='loguniform pdf')\n\n# Freeze the distribution and display the frozen pdf:\nrv = loguniform(a, b)\nax.plot(x, rv.pdf(x), 'k-', lw=2, label='frozen pdf')\n\n# Check accuracy of cdf and ppf\nvals = loguniform.ppf([0.001, 0.5, 0.999], a, b)\nnp.allclose([0.001, 0.5, 0.999], loguniform.cdf(vals, a, b))\n\n# Generate random numbers:\nr = loguniform.rvs(a, b, size=1000)\n\n# And compare the histogram:\nax.hist(r, density=True, histtype='stepfilled', alpha=0.2)\nax.legend(loc='best', frameon=False)\nplt.show()","metadata":{"id":"_U972TfgKdIm","outputId":"1f8027a5-df48-4738-cdb0-e2935d412877"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## scipy.sparse","metadata":{"id":"ADl3NayWjt6O"}},{"cell_type":"markdown","source":"### [csr_matrix](https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.csr_matrix.html)\n\n*Compressed Sparse Row matrix*","metadata":{"id":"nNasFXn6j5uY"}},{"cell_type":"code","source":"from scipy.sparse import csr_matrix\ncsr_matrix((3, 4), dtype=np.int8).toarray()","metadata":{"id":"9l25HbD9kENb","outputId":"4caf178a-b294-4704-d861-b530e95c834e"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"row = np.array([0, 0, 1, 2, 2, 2])\ncol = np.array([0, 2, 2, 0, 1, 2])\ndata = np.array([1, 2, 3, 4, 5, 6])\ncsr = csr_matrix((data, (row, col)), shape=(3, 3)) # a[row[k], col[k]] = data[k]\ncsr.toarray()","metadata":{"id":"nZ8_FaNGkKW3","outputId":"c0555cb6-2a0c-436f-9a06-ea5b4ad885ca"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"csr.todense() # converts to matrix object","metadata":{"id":"tLPfXeJrlJ4K","outputId":"21a48c98-3f86-4e9f-c48c-43c67e311d9d"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## imblearn.under_sampling","metadata":{"id":"MgX_4Hyj1mJL"}},{"cell_type":"markdown","source":"### [RandomUnderSampler](https://imbalanced-learn.org/stable/references/generated/imblearn.under_sampling.RandomUnderSampler.html)\n\n*Under-sample the majority class(es) by randomly picking samples with or without replacement.*","metadata":{"id":"50MWcIiX1pMh"}},{"cell_type":"markdown","source":"#### Examples","metadata":{"id":"eff3igVRf_vf"}},{"cell_type":"code","source":"from collections import Counter\nfrom sklearn.datasets import make_classification\nfrom imblearn.under_sampling import RandomUnderSampler\nX, y = make_classification(n_classes=2, class_sep=2,\n weights=[0.1, 0.9], n_informative=3, n_redundant=1, flip_y=0,\nn_features=20, n_clusters_per_class=1, n_samples=1000, random_state=10)\nprint('Original dataset shape %s' % Counter(y))","metadata":{"id":"6jz-lNm-NNz4","outputId":"b9a73dc1-2a9f-42bd-e2bb-d8f981548aca"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"rus = RandomUnderSampler(random_state=42)\nX_res, y_res = rus.fit_resample(X, y)\nprint('Resampled dataset shape %s' % Counter(y_res))","metadata":{"id":"BesIJL-kNPTG","outputId":"9484f58f-61aa-49ce-f489-946e931851fa"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## imblearn.over_sampling","metadata":{"id":"0hwMD5vD1r88"}},{"cell_type":"markdown","source":"### [RandomOverSampler](https://imbalanced-learn.org/stable/references/generated/imblearn.over_sampling.RandomOverSampler.html)\n\n*Object to over-sample the minority class(es) by picking samples at random with replacement. The bootstrap can be generated in a smoothed manner.*","metadata":{"id":"FnNnBc1K1uck"}},{"cell_type":"markdown","source":"#### Examples","metadata":{"id":"Fi2qfb5Wgciu"}},{"cell_type":"code","source":"from collections import Counter\nfrom sklearn.datasets import make_classification\nfrom imblearn.over_sampling import RandomOverSampler\nX, y = make_classification(n_classes=2, class_sep=2,\nweights=[0.1, 0.9], n_informative=3, n_redundant=1, flip_y=0,\nn_features=20, n_clusters_per_class=1, n_samples=1000, random_state=10)\nprint('Original dataset shape %s' % Counter(y))","metadata":{"id":"bJE2iBPNNpdw","outputId":"b21707a6-031d-4746-a39f-d5b845a1a5ba"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"ros = RandomOverSampler(random_state=42)\nX_res, y_res = ros.fit_resample(X, y)\nprint('Resampled dataset shape %s' % Counter(y_res))","metadata":{"id":"_J9PmoLZNsan","outputId":"dd7b78db-60bc-4ab5-81eb-7a717dc72328"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### [SMOTE](https://imbalanced-learn.org/stable/references/generated/imblearn.over_sampling.SMOTE.html)\n\n*Class to perform over-sampling using SMOTE (Synthetic Minority Over-sampling Technique).*","metadata":{"id":"ThIIv1Q11yJ_"}},{"cell_type":"markdown","source":"#### Examples","metadata":{"id":"HLWOseNkgopM"}},{"cell_type":"code","source":"from collections import Counter\nfrom sklearn.datasets import make_classification\nfrom imblearn.over_sampling import SMOTE\nX, y = make_classification(n_classes=2, class_sep=2,\nweights=[0.1, 0.9], n_informative=3, n_redundant=1, flip_y=0,\nn_features=20, n_clusters_per_class=1, n_samples=1000, random_state=10)\nprint('Original dataset shape %s' % Counter(y))","metadata":{"id":"xXm4FUivN0oq","outputId":"6fec1233-699a-48e2-afca-d0ea24016fdd"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"sm = SMOTE(random_state=42)\nX_res, y_res = sm.fit_resample(X, y)\nprint('Resampled dataset shape %s' % Counter(y_res))","metadata":{"id":"IMo4qdidN3rV","outputId":"28923c88-0ba8-43fd-cf74-4d576f85d7fd"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## warnings","metadata":{"id":"Xwt1NXfh11h5"}},{"cell_type":"markdown","source":"### [filterwarnings](https://stackoverflow.com/questions/29086398/sklearn-turning-off-warnings)\n\n*Turn off warnings in sklearn*","metadata":{"id":"EbsoVXzB15ZI"}},{"cell_type":"code","source":"import warnings\nfrom sklearn.exceptions import DataConversionWarning\nwarnings.filterwarnings(action='ignore', category=DataConversionWarning)","metadata":{"id":"1DQ9couWPLKC"},"outputs":[],"execution_count":null}]}