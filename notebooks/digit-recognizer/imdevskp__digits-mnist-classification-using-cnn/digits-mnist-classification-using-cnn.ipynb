{"cells":[{"metadata":{},"cell_type":"markdown","source":"## About the Dataset\n> * MNIST (\"Modified National Institute of Standards and Technology\") is the de facto “hello world” dataset of computer vision.   \n> * Since its release in 1999, this classic dataset of handwritten images has served as the basis for benchmarking classification algorithms. \n> * As new machine learning techniques emerge, MNIST remains a reliable resource for researchers and learners alike.\n\n## Task\n> * To correctly identify digits from a dataset of tens of thousands of handwritten images in the test dataset","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Libraries","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# for numerical analysis\nimport numpy as np \n# to store and process in a dataframe\nimport pandas as pd \n\n# for ploting graphs\nimport matplotlib.pyplot as plt\n# advancec ploting\nimport seaborn as sns\n\n# image processing\nimport matplotlib.image as mpimg\n\n# train test split\nfrom sklearn.model_selection import train_test_split\n# model performance metrics\nfrom sklearn.metrics import confusion_matrix, classification_report\n\n# utility functions\nfrom tensorflow.keras.utils import to_categorical\n# sequential model\nfrom tensorflow.keras.models import Sequential\n# layers\nfrom tensorflow.keras.layers import Conv2D, MaxPool2D, Dense, Flatten, Dropout\n\n\n# from keras.optimizers import RMSprop\n# from keras.preprocessing.image import ImageDataGenerator\n# from keras.callbacks import ReduceLROnPlateau","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# list of files\n! ls ../input/digit-recognizer","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# import train and test dataset\ntrain = pd.read_csv(\"../input/digit-recognizer/train.csv\")\ntest = pd.read_csv(\"../input/digit-recognizer/test.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# training dataset\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# test dataset\ntest.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# looking for missing values\nprint(train.isna().sum().sum())\nprint(test.isna().sum().sum())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# EDA","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Label count","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(8, 5))\nsns.countplot(train['label'], palette='Dark2')\nplt.title('Train labels count')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['label'].value_counts().sort_index()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# first few train images with labels\nfig, ax = plt.subplots(figsize=(18, 8))\nfor ind, row in train.iloc[:8, :].iterrows():\n    plt.subplot(2, 4, ind+1)\n    plt.title(row[0])\n    img = row.to_numpy()[1:].reshape(28, 28)\n    fig.suptitle('Train images', fontsize=24)\n    plt.axis('off')\n    plt.imshow(img, cmap='magma')","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true},"cell_type":"markdown","source":"> Test images doesn't have labels  \n> We need to create a model to predict them","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# first few test images\nfig, ax = plt.subplots(figsize=(18, 8))\nfor ind, row in test.iloc[:8, :].iterrows():\n    plt.subplot(2, 4, ind+1)\n    img = row.to_numpy()[:].reshape(28, 28)\n    fig.suptitle('Test images', fontsize=24)\n    plt.axis('off')\n    plt.imshow(img, cmap='magma')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Preprocessing","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# split into image and labels and convert to numpy array\nX = train.iloc[:, 1:].to_numpy()\ny = train['label'].to_numpy()\n\n# test dataset\ntest = test.loc[:, :].to_numpy()\n\nfor i in [X, y, test]:\n    print(i.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# normalize the data\n# ==================\n\nX = X / 255.0\ntest = test / 255.0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# reshape dataset\n# ===============\n\n# shape of training and test dataset\nprint(X.shape)\nprint(test.shape)\n\n# reshape the dataframe to 3x3 matrix with 1 channel grey scale values\nX = X.reshape(-1,28,28,1)\ntest = test.reshape(-1,28,28,1)\n\n# shape of training and test dataset\nprint(X.shape)\nprint(test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# one hot encode target\n# =====================\n\n# shape and values of target\nprint(y.shape)\nprint(y[0])\n\n# convert Y_train to categorical by one-hot-encoding\ny_enc = to_categorical(y, num_classes = 10)\n\n# shape and values of target\nprint(y_enc.shape)\nprint(y_enc[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# train test split\n# ================\n\n# random seed\nrandom_seed = 2\n\n# train validation split\nX_train, X_val, y_train_enc, y_val_enc = train_test_split(X, y_enc, test_size=0.3)\n\n# shape\nfor i in [X_train, y_train_enc, X_val, y_val_enc]:\n    print(i.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Plot images","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"g = plt.imshow(X_train[0][:,:,0])\nprint(y_train_enc[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"g = plt.imshow(X_train[9][:,:,0])\nprint(y_train_enc[9])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# CNN","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Model parameters","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"INPUT_SHAPE = (28,28,1)\nOUTPUT_SHAPE = 10\nBATCH_SIZE = 128\nEPOCHS = 10\nVERBOSE = 2","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Define CNN Model","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"model = Sequential()\n\nmodel.add(Conv2D(32, kernel_size=(3,3), activation='relu', input_shape=INPUT_SHAPE))\nmodel.add(MaxPool2D((2,2)))\n\nmodel.add(Conv2D(64, kernel_size=(3,3), activation='relu'))\nmodel.add(MaxPool2D((2,2)))\n\nmodel.add(Flatten())\n\nmodel.add(Dense(128, activation='relu'))\nmodel.add(Dropout(0.2))\n\nmodel.add(Dense(64, activation='relu'))\nmodel.add(Dropout(0.2))\n\nmodel.add(Dense(10, activation='softmax'))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Compile model","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(optimizer='adam', \n              loss='categorical_crossentropy', \n              metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Model summary","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"model.summary()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Model fitting","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"history = model.fit(X_train, y_train_enc,\n                    epochs=EPOCHS,\n                    batch_size=BATCH_SIZE,\n                    verbose=VERBOSE,\n                    validation_split=0.3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Accurayc and loss","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(14, 5))\n\nplt.subplot(1, 2, 1)\nplt.plot(history.history['accuracy'], label='Training Accuracy')\nplt.plot(history.history['val_accuracy'], label='Validation Accuracy')\nplt.legend(loc='lower right')\nplt.title('Training and Validation Accuracy')\n\nplt.subplot(1, 2, 2)\nplt.plot(history.history['loss'], label='Training Loss')\nplt.plot(history.history['val_loss'], label='Validation Loss')\nplt.legend(loc='upper right')\nplt.title('Training and Validation Loss')\n\nplt.savefig('./foo.png')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Evaluating on validationa dataset","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# model loss and accuracy on validation set\nmodel.evaluate(X_val, y_val_enc, verbose=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# predicted values\ny_pred_enc = model.predict(X_val)\n\n# actual\ny_act = [np.argmax(i) for i in y_val_enc]\n\n# decoding predicted values\ny_pred = [np.argmax(i) for i in y_pred_enc]\n\nprint(y_pred_enc[0])\nprint(y_pred[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(classification_report(y_act, y_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(7, 7))\nsns.heatmap(confusion_matrix(y_act, y_pred), annot=True, \n            cbar=False, fmt='1d', cmap='Blues', ax=ax)\nax.set_title('Confusion Matrix', loc='left', fontsize=16)\nax.set_xlabel('Predicted')\nax.set_ylabel('Actual')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Predicting on test","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# predicted values\ny_pred_enc = model.predict(test)\n\n# decoding predicted values\ny_pred = [np.argmax(i) for i in y_pred_enc]\n\nprint(y_pred_enc[0])\nprint(y_pred[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# predicted targets of each images\n# (labels above the images are predicted labels)\nfig, ax = plt.subplots(figsize=(18, 12))\nfor ind, row in enumerate(test[:15]):\n    plt.subplot(3, 5, ind+1)\n    plt.title(y_pred[ind])\n    img = row.reshape(28, 28)\n    fig.suptitle('Predicted values', fontsize=24)\n    plt.axis('off')\n    plt.imshow(img, cmap='cividis')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# X_train, X_val, y_train_enc, y_val_enc","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}