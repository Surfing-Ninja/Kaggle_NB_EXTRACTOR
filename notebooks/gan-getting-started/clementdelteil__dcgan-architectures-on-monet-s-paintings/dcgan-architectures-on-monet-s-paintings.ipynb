{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Dependencies","metadata":{}},{"cell_type":"code","source":"pip install imageio","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n\nimport tensorflow as tf\nimport zipfile\nimport pandas as pd\nimport tensorflow.keras as keras\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport PIL\nimport re\nimport imageio\nfrom PIL import Image\nimport shutil\nimport glob\nimport time\nimport matplotlib.animation as animation\nfrom IPython.display import HTML\nimport glob\nfrom kaggle_datasets import KaggleDatasets\nfrom IPython import display\n\nfrom tensorflow.keras import layers\nfrom tensorflow.keras import optimizers\nfrom tensorflow.keras.utils import plot_model\nfrom tensorflow.keras.initializers import RandomNormal\nfrom tensorflow.keras.models import Sequential, Model, load_model\nfrom tensorflow.keras.layers import Conv2D, Conv2DTranspose, Dense, Flatten, Reshape\nfrom tensorflow.keras.layers import BatchNormalization, Dropout\nfrom tensorflow.keras.layers import ReLU, LeakyReLU, Activation\nfrom tensorflow.keras.optimizers import Adam\n\ntry:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n    print('Device:', tpu.master())\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.TPUStrategy(tpu)\nexcept Exception as e:\n    print(\"can't initialize tpu, using default, exception: \" + str(e))\n    strategy = tf.distribute.get_strategy()\nprint('Number of replicas:', strategy.num_replicas_in_sync)\n\nAUTOTUNE = tf.data.experimental.AUTOTUNE","metadata":{"execution":{"iopub.status.busy":"2023-05-20T18:39:10.351338Z","iopub.execute_input":"2023-05-20T18:39:10.351721Z","iopub.status.idle":"2023-05-20T18:39:18.525283Z","shell.execute_reply.started":"2023-05-20T18:39:10.351683Z","shell.execute_reply":"2023-05-20T18:39:18.52404Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"---\n# Create subdirectories for all the GANs","metadata":{}},{"cell_type":"code","source":"for i in range(5):\n    os.makedirs(os.path.join('/kaggle/working/', 'grid_' + str(i+1)))\n    os.makedirs(os.path.join('/kaggle/working/', 'single_' + str(i+1)))","metadata":{"execution":{"iopub.status.busy":"2023-05-20T18:39:18.527591Z","iopub.execute_input":"2023-05-20T18:39:18.528582Z","iopub.status.idle":"2023-05-20T18:39:18.536099Z","shell.execute_reply.started":"2023-05-20T18:39:18.528536Z","shell.execute_reply":"2023-05-20T18:39:18.535011Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"---\n# Data","metadata":{}},{"cell_type":"code","source":"GCS_PATH = KaggleDatasets().get_gcs_path('monet-tfrecords-256x256')\nMONET_FILENAMES = tf.io.gfile.glob(str(GCS_PATH + '/monet*.tfrec'))\n\ndef count_data_items(filenames):\n    n = [int(re.compile(r\"-([0-9]*)\\.\").search(filename).group(1)) for filename in filenames]\n    return np.sum(n)\n\ncount_data_items(MONET_FILENAMES)","metadata":{"execution":{"iopub.status.busy":"2023-05-20T18:39:18.538871Z","iopub.execute_input":"2023-05-20T18:39:18.540985Z","iopub.status.idle":"2023-05-20T18:39:19.094684Z","shell.execute_reply.started":"2023-05-20T18:39:18.540935Z","shell.execute_reply":"2023-05-20T18:39:19.09294Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# return the image from the TFRecord\nimage_size = [256, 256]\n\ndef decode_image(image):\n    image = tf.image.decode_jpeg(image, channels=3)\n    image = (tf.cast(image, tf.float32) / 127.5) - 1\n    image = tf.reshape(image, [*image_size, 3])\n    return image\n\ndef read_tfrecord(example):\n    tfrecord_format = {\n        'image':      tf.io.FixedLenFeature([], tf.string)\n    }\n    example = tf.io.parse_single_example(example, tfrecord_format)\n    image = decode_image(example['image'])\n    return image","metadata":{"execution":{"iopub.status.busy":"2023-05-20T18:39:19.097567Z","iopub.execute_input":"2023-05-20T18:39:19.097981Z","iopub.status.idle":"2023-05-20T18:39:19.105258Z","shell.execute_reply.started":"2023-05-20T18:39:19.097924Z","shell.execute_reply":"2023-05-20T18:39:19.10423Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# define the function to extract the image from the files\ndef load_data(filenames, labeled=True, ordered=False):\n    data = tf.data.TFRecordDataset(filenames)\n    data = data.map(read_tfrecord, num_parallel_calls=AUTOTUNE)\n    return data","metadata":{"execution":{"iopub.status.busy":"2023-05-20T18:39:19.10691Z","iopub.execute_input":"2023-05-20T18:39:19.10765Z","iopub.status.idle":"2023-05-20T18:39:19.129932Z","shell.execute_reply.started":"2023-05-20T18:39:19.107606Z","shell.execute_reply":"2023-05-20T18:39:19.128881Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"monet = load_data(MONET_FILENAMES).batch(32)\nsample_monet = next(iter(monet))","metadata":{"execution":{"iopub.status.busy":"2023-05-20T18:39:19.132172Z","iopub.execute_input":"2023-05-20T18:39:19.133213Z","iopub.status.idle":"2023-05-20T18:39:22.777952Z","shell.execute_reply.started":"2023-05-20T18:39:19.133173Z","shell.execute_reply":"2023-05-20T18:39:22.776612Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_monet.shape","metadata":{"execution":{"iopub.status.busy":"2023-05-20T18:39:22.779659Z","iopub.execute_input":"2023-05-20T18:39:22.780062Z","iopub.status.idle":"2023-05-20T18:39:22.78818Z","shell.execute_reply.started":"2023-05-20T18:39:22.780019Z","shell.execute_reply":"2023-05-20T18:39:22.787026Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# define visualization function to view image\ndef visualize_images(example):\n    plt.figure(figsize = (10, 10))\n    for i in range(25):\n        ax = plt.subplot(5, 5, i + 1)\n        plt.imshow(example[i] * 0.5 + 0.5)\n        plt.axis(\"off\")","metadata":{"execution":{"iopub.status.busy":"2023-05-20T18:39:22.789897Z","iopub.execute_input":"2023-05-20T18:39:22.790712Z","iopub.status.idle":"2023-05-20T18:39:22.798897Z","shell.execute_reply.started":"2023-05-20T18:39:22.790658Z","shell.execute_reply":"2023-05-20T18:39:22.797911Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"visualize_images(sample_monet)","metadata":{"execution":{"iopub.status.busy":"2023-05-20T18:39:22.800869Z","iopub.execute_input":"2023-05-20T18:39:22.801344Z","iopub.status.idle":"2023-05-20T18:39:24.390837Z","shell.execute_reply.started":"2023-05-20T18:39:22.801306Z","shell.execute_reply":"2023-05-20T18:39:24.389888Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"---\n# Utils","metadata":{}},{"cell_type":"code","source":"def zip_images(directory, zip_file_name):\n    \"\"\"\n    Given a directory containing image files and a name for a zip file,\n    creates a zip file containing all the images in the directory.\n    \n    Args:\n        directory (str): Path to directory containing image files\n        zip_file_name (str): Name for the zip file to be created\n        \n    Returns:\n        None\n    \"\"\"\n    \n    # Create a list of all the image files in the directory\n    image_files = [os.path.join(directory, f) for f in os.listdir(directory) if f.endswith('.jpg') or f.endswith('.jpeg') or f.endswith('.png')]\n    \n    # Create a new zip file\n    with zipfile.ZipFile(zip_file_name, 'w') as zip_file:\n        # Add each image file to the zip file\n        for image_file in image_files:\n            zip_file.write(image_file, os.path.basename(image_file))","metadata":{"execution":{"iopub.status.busy":"2023-05-20T18:39:24.395816Z","iopub.execute_input":"2023-05-20T18:39:24.396636Z","iopub.status.idle":"2023-05-20T18:39:24.40635Z","shell.execute_reply.started":"2023-05-20T18:39:24.396579Z","shell.execute_reply":"2023-05-20T18:39:24.405427Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Display a single image using the epoch number\ndef display_image(directory, epoch_no):\n    return PIL.Image.open(os.path.join(directory, 'image_at_epoch_{:04d}.png'.format(epoch_no)))","metadata":{"execution":{"iopub.status.busy":"2023-05-20T18:39:24.407825Z","iopub.execute_input":"2023-05-20T18:39:24.408472Z","iopub.status.idle":"2023-05-20T18:39:24.418446Z","shell.execute_reply.started":"2023-05-20T18:39:24.408436Z","shell.execute_reply":"2023-05-20T18:39:24.417449Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def save_batch(directory, batch_predictions):\n    for i, image in enumerate(batch_predictions):\n    # Create a new figure and axis for each image\n        fig, ax = plt.subplots()\n        # Display the image on the axis\n        ax.imshow(batch_predictions[i, :, :, :])\n        plt.axis('off')\n        plt.savefig(os.path.join(directory, f'image_{i}.png'), bbox_inches='tight', pad_inches=0)\n        # Close the figure to free up memory\n        plt.close(fig)","metadata":{"execution":{"iopub.status.busy":"2023-05-20T18:39:24.419915Z","iopub.execute_input":"2023-05-20T18:39:24.420759Z","iopub.status.idle":"2023-05-20T18:39:24.431681Z","shell.execute_reply.started":"2023-05-20T18:39:24.420724Z","shell.execute_reply":"2023-05-20T18:39:24.430551Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def save_single_image(directory, first_image, epoch):\n    image = 0.5 * first_image + 0.5\n    plt.imsave(os.path.join(directory, f\"image_at{epoch}.png\"), image)","metadata":{"execution":{"iopub.status.busy":"2023-05-20T18:39:24.433455Z","iopub.execute_input":"2023-05-20T18:39:24.434224Z","iopub.status.idle":"2023-05-20T18:39:24.443175Z","shell.execute_reply.started":"2023-05-20T18:39:24.434186Z","shell.execute_reply":"2023-05-20T18:39:24.442088Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def tf_gif(directory, anim_file):\n    with imageio.get_writer(anim_file, mode='I') as writer:\n        filenames = glob.glob(os.path.join('/kaggle/working/', directory, 'image*.png'))\n        filenames = sorted(filenames)\n\n        for i in range(len(filenames)):\n            filename = filenames[i]\n            image = imageio.imread(filename)\n            \n            # Filter to reduce size of gif\n            if i < 200:\n                if i % 3 == 0:\n                    writer.append_data(image)\n            else:\n                if i % 2 == 0:\n                    writer.append_data(image)","metadata":{"execution":{"iopub.status.busy":"2023-05-20T20:41:54.257202Z","iopub.execute_input":"2023-05-20T20:41:54.257912Z","iopub.status.idle":"2023-05-20T20:41:54.266415Z","shell.execute_reply.started":"2023-05-20T20:41:54.257873Z","shell.execute_reply":"2023-05-20T20:41:54.264888Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def embed_gif(directory):\n    fig = plt.figure(figsize=(8, 8))\n    fig.subplots_adjust(left=0, bottom=0, right=1, top=1, wspace=None, hspace=None)\n    plt.axis(\"off\")\n\n    imgs_gif = []\n    for file_name in sorted(glob.glob(os.path.join('/kaggle/working/', directory, 'image*.png'))):\n        #epoch_imgs = plt.imshow(plt.imread(file_name), animated=True)\n        imgs_gif.append([plt.imshow(plt.imread(file_name), animated=True)])\n\n    return animation.ArtistAnimation(fig, imgs_gif, interval=250, repeat_delay=250, blit=True)","metadata":{"execution":{"iopub.status.busy":"2023-05-20T18:39:24.456315Z","iopub.execute_input":"2023-05-20T18:39:24.457097Z","iopub.status.idle":"2023-05-20T18:39:24.466148Z","shell.execute_reply.started":"2023-05-20T18:39:24.457058Z","shell.execute_reply":"2023-05-20T18:39:24.465128Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_loss_training(epochs, mean_loss, title):\n    plt.plot(epochs, mean_loss, label='Average loss per epoch', linestyle='--', color='red')\n    plt.xlabel('Epochs', fontsize=12)\n    plt.ylabel('Loss', fontsize=12)\n    plt.title('Average Loss per Epoch', fontsize=14)\n    plt.grid()\n    plt.xlim(0, max(epochs)+1)\n    plt.ylim(0, max(mean_loss)+0.5)\n    plt.legend()\n    plt.savefig(title)\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2023-05-20T18:39:24.469234Z","iopub.execute_input":"2023-05-20T18:39:24.469586Z","iopub.status.idle":"2023-05-20T18:39:24.477783Z","shell.execute_reply.started":"2023-05-20T18:39:24.469553Z","shell.execute_reply":"2023-05-20T18:39:24.477019Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"---\n# Generator","metadata":{}},{"cell_type":"code","source":"def create_generator():\n    model = Sequential(name=\"Generator\")\n    \n    # Hidden Layer 1: Start with 16 x 16 image\n    n_nodes = 16 * 16 * 512 # number of nodes in the first hidden layer\n    model.add(Dense(n_nodes, input_shape=(100,), name='Generator-Hidden-Layer-1'))\n    model.add(Reshape((16, 16, 512), name='Generator-Hidden-Layer-Reshape-1'))\n   \n    # Hidden Layer 2: Upsample to 32 x 32\n    model.add(Conv2DTranspose(filters=256, kernel_size=(3, 3), strides=(2, 2), padding='same', name='Generator-Hidden-Layer-2'))\n    model.add(LeakyReLU(alpha=0.2))\n        \n    # Hidden Layer 3: Upsample to 64 x 64\n    model.add(Conv2DTranspose(filters=128, kernel_size=(3, 3), strides=(2, 2), padding='same', name='Generator-Hidden-Layer-3'))\n    model.add(LeakyReLU(alpha=0.2))\n        \n    # Hidden Layer 4: Upsample to 128 x 128\n    model.add(Conv2DTranspose(filters=64, kernel_size=(3, 3), strides=(2, 2), padding='same', name='Generator-Hidden-Layer-4'))\n    model.add(LeakyReLU(alpha=0.2))\n        \n    # Hidden Layer 5: Upsample to 256 x 256\n    model.add(Conv2DTranspose(filters=32, kernel_size=(3, 3), strides=(2, 2), padding='same', name='Generator-Hidden-Layer-5'))\n    model.add(LeakyReLU(alpha=0.2))\n        \n    # Output Layer: we use 3 filters because we have 3 channels for a color image.\n    model.add(Conv2DTranspose(3, kernel_size=(3, 3), activation='tanh', strides=(1, 1), padding='same', name='Generator-Output-Layer'))\n  \n    return model","metadata":{"execution":{"iopub.status.busy":"2023-05-20T18:39:24.479525Z","iopub.execute_input":"2023-05-20T18:39:24.480327Z","iopub.status.idle":"2023-05-20T18:39:24.493357Z","shell.execute_reply.started":"2023-05-20T18:39:24.480279Z","shell.execute_reply":"2023-05-20T18:39:24.49237Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Use the noise vector to create an image. The generator is still untrained here!\nwith strategy.scope():\n    generator = create_generator()\n\n# Show model summary\ngenerator.summary()","metadata":{"execution":{"iopub.status.busy":"2023-05-20T18:39:24.495607Z","iopub.execute_input":"2023-05-20T18:39:24.495903Z","iopub.status.idle":"2023-05-20T18:39:24.699449Z","shell.execute_reply.started":"2023-05-20T18:39:24.495875Z","shell.execute_reply":"2023-05-20T18:39:24.698629Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# create vector of random noise to pass through the generator to see what the output is without the network having been trained\nnoise = tf.random.normal([1, 100])\nwith strategy.scope():\n    generated_image = generator(noise, training=False)\n\nplt.imshow(generated_image[0,:,:,0])","metadata":{"execution":{"iopub.status.busy":"2023-05-20T18:39:24.700574Z","iopub.execute_input":"2023-05-20T18:39:24.700945Z","iopub.status.idle":"2023-05-20T18:39:30.138783Z","shell.execute_reply.started":"2023-05-20T18:39:24.700903Z","shell.execute_reply":"2023-05-20T18:39:30.137698Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"---\n# Discriminator","metadata":{}},{"cell_type":"code","source":"# create a function to build the discriminator model\ndef create_discriminator():\n    model = Sequential(name=\"Discriminator\") # Model\n    \n    # Hidden Layer 1\n    model.add(Conv2D(filters=32, kernel_size=(3,3), strides=(2, 2), padding='same', input_shape=[256, 256, 3], name='Discriminator-Hidden-Layer-1'))\n    model.add(LeakyReLU(alpha=0.2, name='Discriminator-Hidden-Layer-Activation-1'))\n    \n    # Hidden Layer 2\n    model.add(Conv2D(filters=64, kernel_size=(3,3), strides=(2, 2), padding='same', name='Discriminator-Hidden-Layer-2'))\n    model.add(BatchNormalization())\n    model.add(LeakyReLU(alpha=0.2, name='Discriminator-Hidden-Layer-Activation-2'))\n       \n    # Hidden Layer 3\n    model.add(Conv2D(filters=128, kernel_size=(3,3), strides=(2, 2), padding='same', name='Discriminator-Hidden-Layer-3'))\n    model.add(BatchNormalization())\n    model.add(LeakyReLU(alpha=0.2, name='Discriminator-Hidden-Layer-Activation-3'))\n      \n    # Hidden Layer 4\n    model.add(Conv2D(filters=256, kernel_size=(3,3), strides=(2, 2), padding='same', name='Discriminator-Hidden-Layer-4'))\n    model.add(BatchNormalization())\n    model.add(LeakyReLU(alpha=0.2, name='Discriminator-Hidden-Layer-Activation-4'))\n  \n    # Hidden Layer 5\n    model.add(Conv2D(filters=512, kernel_size=(3,3), strides=(2, 2), padding='same', name='Discriminator-Hidden-Layer-5'))\n    model.add(BatchNormalization())\n    model.add(LeakyReLU(alpha=0.2, name='Discriminator-Hidden-Layer-Activation-5'))\n    \n    # Flatten and Output Layers\n    model.add(Flatten(name='Discriminator-Flatten-Layer')) # Flatten the shape\n    model.add(Dropout(0.3, name='Discriminator-Flatten-Layer-Dropout')) # Randomly drop some connections for better generalization\n    model.add(Dense(1, activation='sigmoid', name='Discriminator-Output-Layer')) # Output Layer\n    \n    return model","metadata":{"execution":{"iopub.status.busy":"2023-05-20T18:39:30.140227Z","iopub.execute_input":"2023-05-20T18:39:30.141425Z","iopub.status.idle":"2023-05-20T18:39:30.157915Z","shell.execute_reply.started":"2023-05-20T18:39:30.141386Z","shell.execute_reply":"2023-05-20T18:39:30.156716Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Use the noise vector to create an image. The generator is still untrained here!\nwith strategy.scope():\n    discriminator = create_discriminator()\n\n# Show model summary \ndiscriminator.summary()","metadata":{"execution":{"iopub.status.busy":"2023-05-20T18:39:30.15993Z","iopub.execute_input":"2023-05-20T18:39:30.160336Z","iopub.status.idle":"2023-05-20T18:39:30.365395Z","shell.execute_reply.started":"2023-05-20T18:39:30.160297Z","shell.execute_reply":"2023-05-20T18:39:30.364573Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"---\n# Random test","metadata":{}},{"cell_type":"code","source":"# Use the discriminator to classify the image above (1 for real and 0 for fake)\nwith strategy.scope():\n    decision = discriminator(generated_image)\nprint(decision)","metadata":{"execution":{"iopub.status.busy":"2023-05-20T18:39:30.366515Z","iopub.execute_input":"2023-05-20T18:39:30.366935Z","iopub.status.idle":"2023-05-20T18:39:30.446207Z","shell.execute_reply.started":"2023-05-20T18:39:30.366904Z","shell.execute_reply":"2023-05-20T18:39:30.445016Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"---\n# Loss Functions & Optimizers","metadata":{}},{"cell_type":"code","source":"# create loss function for the generator\nwith strategy.scope():\n    def generator_loss(fake_output):\n        cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True, reduction=tf.keras.losses.Reduction.NONE)\n        return cross_entropy(tf.ones_like(fake_output), fake_output)\n\n    # create loss function for the discriminator\n    def discriminator_loss(real_output, fake_output):\n        cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True, reduction=tf.keras.losses.Reduction.NONE)\n        real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n        fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n        total_loss = real_loss + fake_loss\n        return total_loss","metadata":{"execution":{"iopub.status.busy":"2023-05-20T18:39:30.447797Z","iopub.execute_input":"2023-05-20T18:39:30.44864Z","iopub.status.idle":"2023-05-20T18:39:30.457301Z","shell.execute_reply.started":"2023-05-20T18:39:30.448596Z","shell.execute_reply":"2023-05-20T18:39:30.456352Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create two separate optimizers for the generator and discriminator\nwith strategy.scope():\n    generator_optimizer = tf.keras.optimizers.Adam(learning_rate=0.0002, beta_1=0.5)\n    discriminator_optimizer = tf.keras.optimizers.Adam(learning_rate=0.0002, beta_1=0.5)","metadata":{"execution":{"iopub.status.busy":"2023-05-20T18:39:30.459008Z","iopub.execute_input":"2023-05-20T18:39:30.459545Z","iopub.status.idle":"2023-05-20T18:39:30.474539Z","shell.execute_reply.started":"2023-05-20T18:39:30.459492Z","shell.execute_reply":"2023-05-20T18:39:30.473223Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"---\n# Training Loop","metadata":{}},{"cell_type":"code","source":"# Set the hyperparameters to be used for training\nEPOCHS = 500\nBATCH_SIZE = 32\nnoise_dim = 100\nshape_dim = [256,256,3]\nexamples_to_generate = 25\nseed = tf.random.normal([examples_to_generate, noise_dim])","metadata":{"execution":{"iopub.status.busy":"2023-05-20T18:39:30.476379Z","iopub.execute_input":"2023-05-20T18:39:30.476848Z","iopub.status.idle":"2023-05-20T18:39:30.485515Z","shell.execute_reply.started":"2023-05-20T18:39:30.47681Z","shell.execute_reply":"2023-05-20T18:39:30.48443Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class DCGAN_model:\n    def __init__(self, noise_dim, seed, EPOCHS, BATCH_SIZE, generator, discriminator, dataset, num_model):  \n        self.noise_dim = noise_dim\n        self.EPOCHS = EPOCHS\n        self.BATCH_SIZE = BATCH_SIZE\n        \n        self.generator = generator\n        #self.discriminator = discriminator2\n        self.dataset = dataset\n        self.num = num_model\n        self.seed = seed\n    \n    @tf.function\n    def train(self, images):\n    \n    # Create random noise vector\n        noise = tf.random.normal([images.shape[0], noise_dim])\n\n        with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n        \n        # generate images use random noise vector\n            generated_images = self.generator(noise, training=True)\n\n            # use discriminator to evaluate the real and fake images\n            real_output = discriminator(images, training=True)\n            fake_output = discriminator(generated_images, training=True)\n\n            # compute generator loss and discriminator loss\n            gen_loss = generator_loss(fake_output)\n            disc_loss = discriminator_loss(real_output, fake_output)\n\n            # Compute gradients\n            gradients_of_generator = gen_tape.gradient(gen_loss, self.generator.trainable_variables)\n            gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n\n            # Update optimizers\n            generator_optimizer.apply_gradients(zip(gradients_of_generator, self.generator.trainable_variables))\n            discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n        \n        return (gen_loss + disc_loss) * 0.5\n    \n    @tf.function\n    def distributed_train(self, images):\n        per_replica_losses = strategy.run(self.train, args=(images,))\n        return strategy.reduce(tf.distribute.ReduceOp.MEAN, per_replica_losses, axis=None)\n    \n    def generate_images(self):\n        predictions = self.generator.predict(self.seed)\n        return predictions\n        \n    def save_images(self, directory, epoch, images):\n        gen_imgs = 0.5 * images + 0.5\n\n        fig = plt.figure(figsize=(5, 5))\n\n        for i in range(25):\n            plt.subplot(5, 5, i+1)\n            plt.imshow(gen_imgs[i, :, :, :])\n            plt.axis('off')\n\n        plt.savefig(os.path.join(directory, 'image_at_epoch_{:04d}.png'.format(epoch)))\n        plt.close()\n            \n    def plot_images(self, images):      \n        gen_imgs = 0.5 * images + 0.5\n        \n        fig = plt.figure(figsize=(10, 10))\n        for i in range(25):\n            plt.subplot(5, 5, i+1)\n            plt.imshow(gen_imgs[i, :, :, :])\n            plt.axis('off')\n        plt.show()\n\n    def train_loop(self):\n        e_ls = []\n        mean_ls = []\n        \n        for epoch in range(self.EPOCHS):\n            start = time.time()\n\n            total_loss = 0.0\n            num_batches = 0\n\n            for image_batch in self.dataset:\n                loss = self.distributed_train(image_batch)\n                total_loss += tf.reduce_mean(loss)  # Compute the mean loss accross the tensors\n                num_batches += 1\n            \n            mean_loss = total_loss / num_batches\n            \n            mean_ls.append(mean_loss)\n            e_ls.append(epoch+1)\n            \n            images = self.generate_images()\n            self.save_images('grid_' + self.num, epoch+1, images)\n            save_single_image('single_' + self.num, images[0], epoch+1)\n\n            if (epoch+1) % 20 == 0:                                  \n                print ('Time for epoch {} is {} sec, mean loss is {}'.format(epoch + 1, time.time()-start, mean_loss))\n                self.plot_images(images)\n       \n        table = pd.DataFrame({\"Epoch\": e_ls, \"Mean Loss\": np.array(mean_ls)})\n        \n        return table, e_ls, mean_ls","metadata":{"execution":{"iopub.status.busy":"2023-05-20T18:39:30.487464Z","iopub.execute_input":"2023-05-20T18:39:30.488113Z","iopub.status.idle":"2023-05-20T18:39:30.515936Z","shell.execute_reply.started":"2023-05-20T18:39:30.48806Z","shell.execute_reply":"2023-05-20T18:39:30.514879Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# train, visualize and print out the result for DCGAN model\ngan1 = DCGAN_model(noise_dim, seed, EPOCHS, BATCH_SIZE, generator, discriminator, monet, '1')","metadata":{"execution":{"iopub.status.busy":"2023-05-20T18:39:30.519799Z","iopub.execute_input":"2023-05-20T18:39:30.520529Z","iopub.status.idle":"2023-05-20T18:39:30.531161Z","shell.execute_reply.started":"2023-05-20T18:39:30.520488Z","shell.execute_reply":"2023-05-20T18:39:30.530142Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"table, ep_ls, mean_ls = gan1.train_loop()","metadata":{"execution":{"iopub.status.busy":"2023-05-20T18:39:30.538409Z","iopub.execute_input":"2023-05-20T18:39:30.538761Z","iopub.status.idle":"2023-05-20T19:51:09.055883Z","shell.execute_reply.started":"2023-05-20T18:39:30.538727Z","shell.execute_reply":"2023-05-20T19:51:09.054814Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plot the losses\nplot_loss_training(ep_ls, mean_ls, 'avg_loss_per_epoch')","metadata":{"execution":{"iopub.status.busy":"2023-05-20T19:51:09.059323Z","iopub.execute_input":"2023-05-20T19:51:09.059641Z","iopub.status.idle":"2023-05-20T19:51:09.467312Z","shell.execute_reply.started":"2023-05-20T19:51:09.05961Z","shell.execute_reply":"2023-05-20T19:51:09.466282Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"---\n# Training Gif","metadata":{}},{"cell_type":"code","source":"tf_gif('single_1', 'single_1.gif')\ntf_gif('grid_1', \"dcgan_1.gif\")","metadata":{"execution":{"iopub.status.busy":"2023-05-20T19:51:09.468578Z","iopub.execute_input":"2023-05-20T19:51:09.469264Z","iopub.status.idle":"2023-05-20T19:53:21.993391Z","shell.execute_reply.started":"2023-05-20T19:51:09.469231Z","shell.execute_reply":"2023-05-20T19:53:21.992042Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for folder in ['single', 'grid']:\n    zip_images('/kaggle/working/' + folder + '_1', 'dcgan_' + folder + '_1.zip')","metadata":{"execution":{"iopub.status.busy":"2023-05-20T19:54:33.651719Z","iopub.execute_input":"2023-05-20T19:54:33.652823Z","iopub.status.idle":"2023-05-20T19:54:34.640053Z","shell.execute_reply.started":"2023-05-20T19:54:33.652748Z","shell.execute_reply":"2023-05-20T19:54:34.638998Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"---\n# DCGAN 2 Adam LR=0.0004\nSame architecture as DCGAN 1 but with different hyperparameters in Adam optimizer\n\nlearning_rate=0.0002 --> learning_rate=0.0004","metadata":{}},{"cell_type":"code","source":"with strategy.scope():\n    generator = create_generator()\n    discriminator = create_discriminator()\n    \n    def generator_loss(fake_output):\n        cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True, reduction=tf.keras.losses.Reduction.NONE)\n        return cross_entropy(tf.ones_like(fake_output), fake_output)\n\n    # create loss function for the discriminator\n    def discriminator_loss(real_output, fake_output):\n        cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True, reduction=tf.keras.losses.Reduction.NONE)\n        real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n        fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n        total_loss = real_loss + fake_loss\n        return total_loss\n    \n    generator_optimizer = tf.keras.optimizers.Adam(learning_rate=0.0004, beta_1=0.5)\n    discriminator_optimizer = tf.keras.optimizers.Adam(learning_rate=0.0004, beta_1=0.5)","metadata":{"execution":{"iopub.status.busy":"2023-04-19T20:51:02.039273Z","iopub.execute_input":"2023-04-19T20:51:02.039669Z","iopub.status.idle":"2023-04-19T20:51:02.272955Z","shell.execute_reply.started":"2023-04-19T20:51:02.039635Z","shell.execute_reply":"2023-04-19T20:51:02.271905Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gan2 = DCGAN_model(noise_dim, seed, EPOCHS, BATCH_SIZE, generator, discriminator, monet, '2')","metadata":{"execution":{"iopub.status.busy":"2023-04-19T20:51:02.317317Z","iopub.execute_input":"2023-04-19T20:51:02.318371Z","iopub.status.idle":"2023-04-19T20:51:02.323983Z","shell.execute_reply.started":"2023-04-19T20:51:02.318326Z","shell.execute_reply":"2023-04-19T20:51:02.322732Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"table_2, ep_ls_2, mean_ls_2 = gan2.train_loop()","metadata":{"execution":{"iopub.status.busy":"2023-04-19T20:51:03.134928Z","iopub.execute_input":"2023-04-19T20:51:03.135865Z","iopub.status.idle":"2023-04-19T21:42:00.319438Z","shell.execute_reply.started":"2023-04-19T20:51:03.135812Z","shell.execute_reply":"2023-04-19T21:42:00.318535Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_loss_training(ep_ls_2, mean_ls_2, 'avg_loss_per_epoch_2')","metadata":{"execution":{"iopub.status.busy":"2023-04-19T21:42:00.321631Z","iopub.execute_input":"2023-04-19T21:42:00.322599Z","iopub.status.idle":"2023-04-19T21:42:00.658385Z","shell.execute_reply.started":"2023-04-19T21:42:00.322544Z","shell.execute_reply":"2023-04-19T21:42:00.657433Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tf_gif('single_2', 'single_2.gif')\ntf_gif('grid_2', \"dcgan_2.gif\")","metadata":{"execution":{"iopub.status.busy":"2023-04-19T20:47:33.362612Z","iopub.status.idle":"2023-04-19T20:47:33.363113Z","shell.execute_reply.started":"2023-04-19T20:47:33.362847Z","shell.execute_reply":"2023-04-19T20:47:33.362871Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for folder in ['single', 'grid']:\n    zip_images('/kaggle/working/' + folder + '_2', 'dcgan_' + folder + '_2.zip')","metadata":{"execution":{"iopub.status.busy":"2023-04-19T20:47:33.364977Z","iopub.status.idle":"2023-04-19T20:47:33.365458Z","shell.execute_reply.started":"2023-04-19T20:47:33.36521Z","shell.execute_reply":"2023-04-19T20:47:33.365234Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"---\n# DCGAN 3 : SGD with diff LR\n* Same architecture but with different Optimizer and Learning Rates. I've set the discriminator learning rate as 0.0001 and generator learning rate as 0.0003. This is to make sure that the discriminator doesnâ€™t overpower the generator.\n","metadata":{}},{"cell_type":"code","source":"with strategy.scope():\n    generator = create_generator()\n    discriminator = create_discriminator()\n    \n    def generator_loss(fake_output):\n        cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True, reduction=tf.keras.losses.Reduction.NONE)\n        return cross_entropy(tf.ones_like(fake_output), fake_output)\n\n    # create loss function for the discriminator\n    def discriminator_loss(real_output, fake_output):\n        cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True, reduction=tf.keras.losses.Reduction.NONE)\n        real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n        fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n        total_loss = real_loss + fake_loss\n        return total_loss\n    \n    generator_optimizer = tf.keras.optimizers.SGD(learning_rate=0.0003)\n    discriminator_optimizer = tf.keras.optimizers.SGD(learning_rate=0.0001)","metadata":{"execution":{"iopub.status.busy":"2023-04-19T21:42:00.659992Z","iopub.execute_input":"2023-04-19T21:42:00.660346Z","iopub.status.idle":"2023-04-19T21:42:00.884152Z","shell.execute_reply.started":"2023-04-19T21:42:00.66031Z","shell.execute_reply":"2023-04-19T21:42:00.883174Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gan3 = DCGAN_model(noise_dim, seed, EPOCHS, BATCH_SIZE, generator, discriminator, monet, '3')","metadata":{"execution":{"iopub.status.busy":"2023-04-19T21:42:00.887132Z","iopub.execute_input":"2023-04-19T21:42:00.887497Z","iopub.status.idle":"2023-04-19T21:42:00.894276Z","shell.execute_reply.started":"2023-04-19T21:42:00.887459Z","shell.execute_reply":"2023-04-19T21:42:00.893269Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"table_3, ep_ls_3, mean_ls_3 = gan3.train_loop()","metadata":{"execution":{"iopub.status.busy":"2023-04-19T21:42:00.895839Z","iopub.execute_input":"2023-04-19T21:42:00.896436Z","iopub.status.idle":"2023-04-19T22:32:23.725996Z","shell.execute_reply.started":"2023-04-19T21:42:00.8964Z","shell.execute_reply":"2023-04-19T22:32:23.724887Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_loss_training(ep_ls_3, mean_ls_3, 'avg_loss_per_epoch_3')","metadata":{"execution":{"iopub.status.busy":"2023-04-19T22:32:23.727614Z","iopub.execute_input":"2023-04-19T22:32:23.728575Z","iopub.status.idle":"2023-04-19T22:32:24.088138Z","shell.execute_reply.started":"2023-04-19T22:32:23.728542Z","shell.execute_reply":"2023-04-19T22:32:24.087208Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tf_gif('single_3', 'single_3.gif')\ntf_gif('grid_3', \"dcgan_3.gif\")","metadata":{"execution":{"iopub.status.busy":"2023-04-19T20:47:33.378187Z","iopub.status.idle":"2023-04-19T20:47:33.37905Z","shell.execute_reply.started":"2023-04-19T20:47:33.378793Z","shell.execute_reply":"2023-04-19T20:47:33.378819Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for folder in ['single', 'grid']:\n    zip_images('/kaggle/working/' + folder + '_3', 'dcgan_' + folder + '_3.zip')","metadata":{"execution":{"iopub.status.busy":"2023-04-19T20:47:33.380465Z","iopub.status.idle":"2023-04-19T20:47:33.381326Z","shell.execute_reply.started":"2023-04-19T20:47:33.381069Z","shell.execute_reply":"2023-04-19T20:47:33.381095Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"---\n# DCGAN 4 5x5 2x2","metadata":{}},{"cell_type":"code","source":"def create_generator():\n    model = Sequential(name=\"Generator\")\n    \n    # Hidden Layer 1: Start with 16 x 16 image\n    n_nodes = 16 * 16 * 512 # number of nodes in the first hidden layer\n    model.add(Dense(n_nodes, input_shape=(100,), name='Generator-Hidden-Layer-1'))\n    model.add(Reshape((16, 16, 512), name='Generator-Hidden-Layer-Reshape-1'))\n   \n    # Hidden Layer 2: Upsample to 32 x 32\n    model.add(Conv2DTranspose(filters=256, kernel_size=(5, 5), strides=(2, 2), padding='same', name='Generator-Hidden-Layer-2'))\n    model.add(LeakyReLU(alpha=0.2))\n        \n    # Hidden Layer 3: Upsample to 64 x 64\n    model.add(Conv2DTranspose(filters=128, kernel_size=(5, 5), strides=(2, 2), padding='same', name='Generator-Hidden-Layer-3'))\n    model.add(LeakyReLU(alpha=0.2))\n        \n    # Hidden Layer 4: Upsample to 128 x 128\n    model.add(Conv2DTranspose(filters=64, kernel_size=(5, 5), strides=(2, 2), padding='same', name='Generator-Hidden-Layer-4'))\n    model.add(LeakyReLU(alpha=0.2))\n        \n    # Hidden Layer 5: Upsample to 256 x 256\n    model.add(Conv2DTranspose(filters=32, kernel_size=(5, 5), strides=(2, 2), padding='same', name='Generator-Hidden-Layer-5'))\n    model.add(LeakyReLU(alpha=0.2))\n        \n    # Output Layer: we use 3 filters because we have 3 channels for a color image.\n    model.add(Conv2DTranspose(3, kernel_size=(5, 5), activation='tanh', strides=(1, 1), padding='same', name='Generator-Output-Layer'))\n  \n    return model","metadata":{"execution":{"iopub.status.busy":"2023-04-19T22:32:24.090329Z","iopub.execute_input":"2023-04-19T22:32:24.091396Z","iopub.status.idle":"2023-04-19T22:32:24.101399Z","shell.execute_reply.started":"2023-04-19T22:32:24.091355Z","shell.execute_reply":"2023-04-19T22:32:24.100457Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# create a function to build the discriminator model\ndef create_discriminator():\n    model = Sequential(name=\"Discriminator\") # Model\n    \n    # Hidden Layer 1\n    model.add(Conv2D(filters=32, kernel_size=(5,5), strides=(2, 2), padding='same', input_shape=[256, 256, 3], name='Discriminator-Hidden-Layer-1'))\n    model.add(LeakyReLU(alpha=0.2, name='Discriminator-Hidden-Layer-Activation-1'))\n    \n    # Hidden Layer 2\n    model.add(Conv2D(filters=64, kernel_size=(5,5), strides=(2, 2), padding='same', name='Discriminator-Hidden-Layer-2'))\n    model.add(BatchNormalization())\n    model.add(LeakyReLU(alpha=0.2, name='Discriminator-Hidden-Layer-Activation-2'))\n       \n    # Hidden Layer 3\n    model.add(Conv2D(filters=128, kernel_size=(5,5), strides=(2, 2), padding='same', name='Discriminator-Hidden-Layer-3'))\n    model.add(BatchNormalization())\n    model.add(LeakyReLU(alpha=0.2, name='Discriminator-Hidden-Layer-Activation-3'))\n      \n    # Hidden Layer 4\n    model.add(Conv2D(filters=256, kernel_size=(5,5), strides=(2, 2), padding='same', name='Discriminator-Hidden-Layer-4'))\n    model.add(BatchNormalization())\n    model.add(LeakyReLU(alpha=0.2, name='Discriminator-Hidden-Layer-Activation-4'))\n  \n    # Hidden Layer 5\n    model.add(Conv2D(filters=512, kernel_size=(5,5), strides=(2, 2), padding='same', name='Discriminator-Hidden-Layer-5'))\n    model.add(BatchNormalization())\n    model.add(LeakyReLU(alpha=0.2, name='Discriminator-Hidden-Layer-Activation-5'))\n    \n    # Flatten and Output Layers\n    model.add(Flatten(name='Discriminator-Flatten-Layer')) # Flatten the shape\n    model.add(Dropout(0.3, name='Discriminator-Flatten-Layer-Dropout')) # Randomly drop some connections for better generalization\n    model.add(Dense(1, activation='sigmoid', name='Discriminator-Output-Layer')) # Output Layer\n    \n    return model","metadata":{"execution":{"iopub.status.busy":"2023-04-19T22:32:24.102661Z","iopub.execute_input":"2023-04-19T22:32:24.102942Z","iopub.status.idle":"2023-04-19T22:32:24.118891Z","shell.execute_reply.started":"2023-04-19T22:32:24.102911Z","shell.execute_reply":"2023-04-19T22:32:24.117878Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with strategy.scope():\n    generator = create_generator()\n    discriminator = create_discriminator()\n    \n    def generator_loss(fake_output):\n        cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True, reduction=tf.keras.losses.Reduction.NONE)\n        return cross_entropy(tf.ones_like(fake_output), fake_output)\n\n    # create loss function for the discriminator\n    def discriminator_loss(real_output, fake_output):\n        cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True, reduction=tf.keras.losses.Reduction.NONE)\n        real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n        fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n        total_loss = real_loss + fake_loss\n        return total_loss\n    \n    generator_optimizer = tf.keras.optimizers.Adam(learning_rate=0.0002, beta_1=0.5)\n    discriminator_optimizer = tf.keras.optimizers.Adam(learning_rate=0.0002, beta_1=0.5)","metadata":{"execution":{"iopub.status.busy":"2023-04-19T22:32:24.120226Z","iopub.execute_input":"2023-04-19T22:32:24.120672Z","iopub.status.idle":"2023-04-19T22:32:24.390784Z","shell.execute_reply.started":"2023-04-19T22:32:24.120627Z","shell.execute_reply":"2023-04-19T22:32:24.389791Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gan4 = DCGAN_model(noise_dim, seed, EPOCHS, BATCH_SIZE, generator, discriminator, monet, '4')","metadata":{"execution":{"iopub.status.busy":"2023-04-19T22:32:24.395128Z","iopub.execute_input":"2023-04-19T22:32:24.395425Z","iopub.status.idle":"2023-04-19T22:32:24.402227Z","shell.execute_reply.started":"2023-04-19T22:32:24.395392Z","shell.execute_reply":"2023-04-19T22:32:24.401144Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"table_4, ep_ls_4, mean_ls_4 = gan4.train_loop()","metadata":{"execution":{"iopub.status.busy":"2023-04-19T22:32:24.404009Z","iopub.execute_input":"2023-04-19T22:32:24.404392Z","iopub.status.idle":"2023-04-19T23:31:32.309281Z","shell.execute_reply.started":"2023-04-19T22:32:24.404323Z","shell.execute_reply":"2023-04-19T23:31:32.308374Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_loss_training(ep_ls_4, mean_ls_4, 'avg_loss_per_epoch_4')","metadata":{"execution":{"iopub.status.busy":"2023-04-19T23:31:32.310844Z","iopub.execute_input":"2023-04-19T23:31:32.311584Z","iopub.status.idle":"2023-04-19T23:31:32.627683Z","shell.execute_reply.started":"2023-04-19T23:31:32.311545Z","shell.execute_reply":"2023-04-19T23:31:32.62665Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tf_gif('single_4', 'single_4.gif')\ntf_gif('grid_4', \"dcgan_4.gif\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for folder in ['single', 'grid']:\n    zip_images('/kaggle/working/' + folder + '_4', 'dcgan_' + folder + '_4.zip')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"---\n# DCGAN 5 4x4 2x2","metadata":{}},{"cell_type":"code","source":"def create_generator():\n    model = Sequential(name=\"Generator\")\n    \n    # Hidden Layer 1: Start with 16 x 16 image\n    n_nodes = 16 * 16 * 512 # number of nodes in the first hidden layer\n    model.add(Dense(n_nodes, input_shape=(100,), name='Generator-Hidden-Layer-1'))\n    model.add(Reshape((16, 16, 512), name='Generator-Hidden-Layer-Reshape-1'))\n   \n    # Hidden Layer 2: Upsample to 32 x 32\n    model.add(Conv2DTranspose(filters=256, kernel_size=(4, 4), strides=(2, 2), padding='same', name='Generator-Hidden-Layer-2'))\n    model.add(LeakyReLU(alpha=0.2))\n        \n    # Hidden Layer 3: Upsample to 64 x 64\n    model.add(Conv2DTranspose(filters=128, kernel_size=(4, 4), strides=(2, 2), padding='same', name='Generator-Hidden-Layer-3'))\n    model.add(LeakyReLU(alpha=0.2))\n        \n    # Hidden Layer 4: Upsample to 128 x 128\n    model.add(Conv2DTranspose(filters=64, kernel_size=(4, 4), strides=(2, 2), padding='same', name='Generator-Hidden-Layer-4'))\n    model.add(LeakyReLU(alpha=0.2))\n        \n    # Hidden Layer 5: Upsample to 256 x 256\n    model.add(Conv2DTranspose(filters=32, kernel_size=(4, 4), strides=(2, 2), padding='same', name='Generator-Hidden-Layer-5'))\n    model.add(LeakyReLU(alpha=0.2))\n        \n    # Output Layer: we use 3 filters because we have 3 channels for a color image.\n    model.add(Conv2DTranspose(3, kernel_size=(5, 5), activation='tanh', strides=(1, 1), padding='same', name='Generator-Output-Layer'))\n  \n    return model","metadata":{"execution":{"iopub.status.busy":"2023-04-19T23:31:32.629256Z","iopub.execute_input":"2023-04-19T23:31:32.629904Z","iopub.status.idle":"2023-04-19T23:31:32.639793Z","shell.execute_reply.started":"2023-04-19T23:31:32.629864Z","shell.execute_reply":"2023-04-19T23:31:32.638746Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# create a function to build the discriminator model\ndef create_discriminator():\n    model = Sequential(name=\"Discriminator\") # Model\n    \n    # Hidden Layer 1\n    model.add(Conv2D(filters=32, kernel_size=(4,4), strides=(2, 2), padding='same', input_shape=[256, 256, 3], name='Discriminator-Hidden-Layer-1'))\n    model.add(LeakyReLU(alpha=0.2, name='Discriminator-Hidden-Layer-Activation-1'))\n    \n    # Hidden Layer 2\n    model.add(Conv2D(filters=64, kernel_size=(4,4), strides=(2, 2), padding='same', name='Discriminator-Hidden-Layer-2'))\n    model.add(BatchNormalization())\n    model.add(LeakyReLU(alpha=0.2, name='Discriminator-Hidden-Layer-Activation-2'))\n       \n    # Hidden Layer 3\n    model.add(Conv2D(filters=128, kernel_size=(4,4), strides=(2, 2), padding='same', name='Discriminator-Hidden-Layer-3'))\n    model.add(BatchNormalization())\n    model.add(LeakyReLU(alpha=0.2, name='Discriminator-Hidden-Layer-Activation-3'))\n      \n    # Hidden Layer 4\n    model.add(Conv2D(filters=256, kernel_size=(4,4), strides=(2, 2), padding='same', name='Discriminator-Hidden-Layer-4'))\n    model.add(BatchNormalization())\n    model.add(LeakyReLU(alpha=0.2, name='Discriminator-Hidden-Layer-Activation-4'))\n  \n    # Hidden Layer 5\n    model.add(Conv2D(filters=512, kernel_size=(4,4), strides=(2, 2), padding='same', name='Discriminator-Hidden-Layer-5'))\n    model.add(BatchNormalization())\n    model.add(LeakyReLU(alpha=0.2, name='Discriminator-Hidden-Layer-Activation-5'))\n    \n    # Flatten and Output Layers\n    model.add(Flatten(name='Discriminator-Flatten-Layer')) # Flatten the shape\n    model.add(Dropout(0.3, name='Discriminator-Flatten-Layer-Dropout')) # Randomly drop some connections for better generalization\n    model.add(Dense(1, activation='sigmoid', name='Discriminator-Output-Layer')) # Output Layer\n    \n    return model","metadata":{"execution":{"iopub.status.busy":"2023-04-19T23:31:32.64138Z","iopub.execute_input":"2023-04-19T23:31:32.641801Z","iopub.status.idle":"2023-04-19T23:31:32.654962Z","shell.execute_reply.started":"2023-04-19T23:31:32.64172Z","shell.execute_reply":"2023-04-19T23:31:32.653938Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with strategy.scope():\n    generator = create_generator()\n    discriminator = create_discriminator()\n    \n    def generator_loss(fake_output):\n        cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True, reduction=tf.keras.losses.Reduction.NONE)\n        return cross_entropy(tf.ones_like(fake_output), fake_output)\n\n    # create loss function for the discriminator\n    def discriminator_loss(real_output, fake_output):\n        cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True, reduction=tf.keras.losses.Reduction.NONE)\n        real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n        fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n        total_loss = real_loss + fake_loss\n        return total_loss\n    \n    generator_optimizer = tf.keras.optimizers.Adam(learning_rate=0.0002, beta_1=0.5)\n    discriminator_optimizer = tf.keras.optimizers.Adam(learning_rate=0.0002, beta_1=0.5)","metadata":{"execution":{"iopub.status.busy":"2023-04-19T23:31:32.656266Z","iopub.execute_input":"2023-04-19T23:31:32.656694Z","iopub.status.idle":"2023-04-19T23:31:32.897311Z","shell.execute_reply.started":"2023-04-19T23:31:32.656658Z","shell.execute_reply":"2023-04-19T23:31:32.89638Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gan5 = DCGAN_model(noise_dim, seed, EPOCHS, BATCH_SIZE, generator, discriminator, monet, '5')","metadata":{"execution":{"iopub.status.busy":"2023-04-19T23:31:32.89882Z","iopub.execute_input":"2023-04-19T23:31:32.899162Z","iopub.status.idle":"2023-04-19T23:31:32.90526Z","shell.execute_reply.started":"2023-04-19T23:31:32.899129Z","shell.execute_reply":"2023-04-19T23:31:32.904187Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"table_5, ep_ls_5, mean_ls_5 = gan5.train_loop()","metadata":{"execution":{"iopub.status.busy":"2023-04-19T23:31:32.906662Z","iopub.execute_input":"2023-04-19T23:31:32.9077Z","iopub.status.idle":"2023-04-20T00:23:46.381118Z","shell.execute_reply.started":"2023-04-19T23:31:32.90766Z","shell.execute_reply":"2023-04-20T00:23:46.379867Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_loss_training(ep_ls_5, mean_ls_5, 'avg_loss_per_epoch_5')","metadata":{"execution":{"iopub.status.busy":"2023-04-20T00:23:46.383312Z","iopub.execute_input":"2023-04-20T00:23:46.383864Z","iopub.status.idle":"2023-04-20T00:23:46.73957Z","shell.execute_reply.started":"2023-04-20T00:23:46.383806Z","shell.execute_reply":"2023-04-20T00:23:46.738472Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(ep_ls_5, mean_ls_5, label='5x5 - 2x2',color='red')\nplt.plot(ep_ls_4, mean_ls_4, label='4x4 - 2x2',color='blue')\nplt.xlabel('Epochs', fontsize=12)\nplt.ylabel('Loss', fontsize=12)\nplt.title('Average Loss per Epoch', fontsize=14)\nplt.grid()\nplt.xlim(0, max(ep_ls_5)+1)\nplt.ylim(0, max(mean_ls_4)+0.5)\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-04-20T00:23:46.741148Z","iopub.execute_input":"2023-04-20T00:23:46.741758Z","iopub.status.idle":"2023-04-20T00:23:47.016661Z","shell.execute_reply.started":"2023-04-20T00:23:46.741715Z","shell.execute_reply":"2023-04-20T00:23:47.015664Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tf_gif('single_5', 'single_5.gif')\ntf_gif('grid_5', \"dcgan_5.gif\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for folder in ['single', 'grid']:\n    zip_images('/kaggle/working/' + folder + '_5', 'dcgan_' + folder + '_5.zip')","metadata":{},"execution_count":null,"outputs":[]}]}