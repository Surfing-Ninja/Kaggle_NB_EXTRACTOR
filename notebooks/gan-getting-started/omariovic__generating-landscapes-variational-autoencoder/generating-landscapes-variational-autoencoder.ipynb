{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":21755,"databundleVersionId":1475600,"sourceType":"competition"},{"sourceId":2009923,"sourceType":"datasetVersion","datasetId":1202753},{"sourceId":2154267,"sourceType":"datasetVersion","datasetId":923624}],"dockerImageVersionId":30674,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nfrom tqdm import tqdm\nimport os\nimport cv2\nfrom tensorflow.keras import layers, Sequential, datasets, Model\nimport warnings\nwarnings.filterwarnings('ignore')\n# مازال يشكوا الصد حتي كرهت نفسه صاد الحروف و دالها","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-03-23T13:44:27.907792Z","iopub.execute_input":"2024-03-23T13:44:27.908105Z","iopub.status.idle":"2024-03-23T13:44:40.828604Z","shell.execute_reply.started":"2024-03-23T13:44:27.908077Z","shell.execute_reply":"2024-03-23T13:44:40.827784Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dir_path = r\"/kaggle/input/gan-getting-started/photo_jpg\"\ndef load_images(folder_path, img_size = (128, 128)):\n    X = []\n    limit = 10000\n    for img_name in tqdm(os.listdir(folder_path)[:limit]):\n        img_path = os.path.join(folder_path, img_name)\n        img_array = cv2.imread(img_path)\n        img_array = cv2.resize(img_array, img_size)\n        img_array = img_array[:,:,::-1]\n        X.append(img_array / 255.0)\n        if len(X) >= limit:\n            break\n    return np.array(X)\n\nimg_size = 64\nX_train = load_images(dir_path, (img_size, img_size))\nX_train.shape","metadata":{"execution":{"iopub.status.busy":"2024-03-23T13:44:40.830163Z","iopub.execute_input":"2024-03-23T13:44:40.830718Z","iopub.status.idle":"2024-03-23T13:45:33.175618Z","shell.execute_reply.started":"2024-03-23T13:44:40.830691Z","shell.execute_reply":"2024-03-23T13:45:33.174662Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"learning_rate = 0.0003\nKL_coef = 0.0075\nlatent_dim = 64\nbatch_size = 100","metadata":{"execution":{"iopub.status.busy":"2024-03-23T14:01:12.094689Z","iopub.execute_input":"2024-03-23T14:01:12.095409Z","iopub.status.idle":"2024-03-23T14:01:12.099472Z","shell.execute_reply.started":"2024-03-23T14:01:12.095368Z","shell.execute_reply":"2024-03-23T14:01:12.098533Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def show_images(images, title = None):\n    plt.figure(figsize = (6, 6))\n    for i in range(12):\n        plt.subplot(3, 4, i + 1)\n        plt.imshow(images[i])\n        plt.title(title)\n        plt.xticks([])\n        plt.yticks([])\n    plt.tight_layout()\n    plt.show()\nshow_images(X_train)","metadata":{"execution":{"iopub.status.busy":"2024-03-23T14:01:12.10091Z","iopub.execute_input":"2024-03-23T14:01:12.101155Z","iopub.status.idle":"2024-03-23T14:01:12.858014Z","shell.execute_reply.started":"2024-03-23T14:01:12.101132Z","shell.execute_reply":"2024-03-23T14:01:12.857148Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class VariationalAutoencoder(Model):\n    def __init__(self, latent_dim = latent_dim):\n        super().__init__()\n        self.encoder = Sequential([\n            layers.Conv2D(64, kernel_size = (3, 3), strides = 2, padding = 'same'),\n            layers.BatchNormalization(),\n            layers.LeakyReLU(0.2),\n            \n            layers.Conv2D(128, kernel_size = (3, 3), strides = 2, padding = 'same'),\n            layers.BatchNormalization(),\n            layers.LeakyReLU(0.2),\n            \n            layers.Conv2D(256, kernel_size = (3, 3), strides = 2, padding = 'same'),\n            layers.BatchNormalization(),\n            layers.LeakyReLU(0.2),\n            \n            layers.Flatten(),\n            layers.Dense(2048),\n            layers.BatchNormalization(),\n            layers.LeakyReLU(0.2),\n        ])\n        \n        self.get_mean = layers.Dense(latent_dim)\n        self.get_logvar = layers.Dense(latent_dim)\n        \n        self.decoder = Sequential([\n            layers.Dense(2048),\n            layers.BatchNormalization(),\n            layers.LeakyReLU(0.2),\n            \n            layers.Dense(256 * 8 * 8),\n            layers.BatchNormalization(),\n            layers.LeakyReLU(0.2),\n            layers.Reshape((8, 8, 256)),\n            \n            layers.Conv2DTranspose(128, kernel_size = (3, 3), strides = 2, padding = 'same'),\n            layers.BatchNormalization(),\n            layers.LeakyReLU(0.2),\n            \n            layers.Conv2DTranspose(64, kernel_size = (3, 3), strides = 2, padding = 'same'),\n            layers.BatchNormalization(),\n            layers.LeakyReLU(0.2),\n            \n            layers.Conv2DTranspose(32, kernel_size = (3, 3), strides = 2, padding = 'same'),\n            layers.BatchNormalization(),\n            layers.LeakyReLU(0.2),\n\n            layers.Conv2DTranspose(3, kernel_size = (3, 3), strides = 1, padding = 'same', activation = 'sigmoid'),\n        ])\n        \n    def vae_loss(self, reconstructions, inputs, z_mean, z_log_var):\n        reconstruction_loss = tf.reduce_mean(tf.square(reconstructions - inputs))\n        kl_loss = -KL_coef * tf.reduce_mean(1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var))\n        total_loss = reconstruction_loss + kl_loss\n        return kl_loss, reconstruction_loss, total_loss\n        \n    def encode(self, x):\n        return self.encoder(x)\n        \n    def decode(self, x):\n        return self.decoder(x)\n        \n    def sample(self, mean, logvar):\n        eps = tf.random.normal(tf.shape(mean))\n        return mean + tf.exp(logvar) * eps\n    \n    def call(self, x):\n        encoded = self.encode(x)\n        mean, logvar = self.get_mean(encoded), self.get_logvar(encoded)\n        latent_space = self.sample(mean, logvar)\n        decoded = self.decode(latent_space)\n        return mean, logvar, decoded\n    \n    def train_step(self, batch):\n        with tf.GradientTape() as tape:\n            mean, logvar, y_pred = self.call(batch)\n            kl_loss, reconstruction_loss, loss = self.vae_loss(y_pred, batch, mean, logvar)\n        gradients = tape.gradient(loss, self.trainable_variables)\n        self.optimizer.apply_gradients(zip(gradients, self.trainable_variables))\n        \n        return {'kl_loss' : kl_loss, 'reconstruction_loss': reconstruction_loss, 'total_loss' : loss}","metadata":{"execution":{"iopub.status.busy":"2024-03-23T14:01:12.859953Z","iopub.execute_input":"2024-03-23T14:01:12.860297Z","iopub.status.idle":"2024-03-23T14:01:12.881378Z","shell.execute_reply.started":"2024-03-23T14:01:12.860269Z","shell.execute_reply":"2024-03-23T14:01:12.880531Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = VariationalAutoencoder()\nmodel.compile(optimizer = tf.keras.optimizers.Adam(learning_rate = learning_rate))","metadata":{"execution":{"iopub.status.busy":"2024-03-23T14:01:52.884009Z","iopub.execute_input":"2024-03-23T14:01:52.884739Z","iopub.status.idle":"2024-03-23T14:01:52.922027Z","shell.execute_reply.started":"2024-03-23T14:01:52.884708Z","shell.execute_reply":"2024-03-23T14:01:52.921224Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fixed_noise = tf.random.normal((60, latent_dim))","metadata":{"execution":{"iopub.status.busy":"2024-03-23T14:01:53.480156Z","iopub.execute_input":"2024-03-23T14:01:53.480776Z","iopub.status.idle":"2024-03-23T14:01:53.485796Z","shell.execute_reply.started":"2024-03-23T14:01:53.480746Z","shell.execute_reply":"2024-03-23T14:01:53.484736Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.fit(X_train, epochs = 1000)","metadata":{"execution":{"iopub.status.busy":"2024-03-23T14:03:06.900896Z","iopub.execute_input":"2024-03-23T14:03:06.901259Z","iopub.status.idle":"2024-03-23T14:03:49.166782Z","shell.execute_reply.started":"2024-03-23T14:03:06.901228Z","shell.execute_reply":"2024-03-23T14:03:49.165802Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred = model.decode(fixed_noise)\nshow_images(y_pred)","metadata":{"execution":{"iopub.status.busy":"2024-03-23T14:03:49.16867Z","iopub.execute_input":"2024-03-23T14:03:49.169034Z","iopub.status.idle":"2024-03-23T14:03:49.857175Z","shell.execute_reply.started":"2024-03-23T14:03:49.168999Z","shell.execute_reply":"2024-03-23T14:03:49.856191Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}