{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<div style=\"color:white;\n           display:fill;\n           border-radius:5px;\n           background-color:#C85C8E;\n           font-size:110%;\n           font-family:Verdana;\n           letter-spacing:0.5px\">\n\n<h1 style=\"padding: 10px;\n              color:white; \">\nImage Colorization with U-Net and GAN  <br>\n    (Using UNet and implementation in Pytorch)\n</h1>\n</div>","metadata":{}},{"cell_type":"markdown","source":"# Story","metadata":{}},{"cell_type":"markdown","source":"I have tried to implement the \n*[Image-to-Image Translation with Conditional Adversarial Networks](https://arxiv.org/pdf/1611.07004.pdf)*\nwith additional pre-training to the Generator in terms of replacing it's backbone with a resnet pretrained on ImageNet followed by additional pretraining for colorization in a supervised manner using L1 loss.<br>\nSo, I have tried to make this notebook as a resource for studying and understanding GANs and this is my way of approaching this problem.\n","metadata":{}},{"cell_type":"markdown","source":"<h3> Loss Function </h3>\n<div>\n<img src=\"https://miro.medium.com/max/1400/1*_e3VcDdd7x7-RGG4BoNZ0A.webp\" width=\"600px\"align=\"center\">\n    </div><br>\nconditional GAN loss function","metadata":{}},{"cell_type":"markdown","source":"\n<div>\n<img src=\"https://miro.medium.com/max/1400/1*S9vJ_R-Jn3sL0C09DjtL4w.webp\" width=\"500px\"align=\"center\">\n    </div><br>\n    L1 loss","metadata":{}},{"cell_type":"markdown","source":"<div>\n<img src=\"https://miro.medium.com/max/1400/1*e0nyJD1hTm5OoKDrU_F6bw.webp\" width=\"600px\"align=\"center\">\n    </div><br>\n    combined loss function we‚Äôll optimize","metadata":{}},{"cell_type":"markdown","source":"* x -> grayscale image *(the condition introduced)*\n* y -> 2 channel output of generator\n* z -> input noise of generator\n* G -> Generator Model\n* D -> Discriminator Model","metadata":{}},{"cell_type":"markdown","source":"# Generative Adversarial Networks (GANs)","metadata":{}},{"cell_type":"markdown","source":"<div>\n<img src=\"https://miro.medium.com/max/1400/1*cC2SDljLTY9OISBgiC_sFw.webp\" width=\"900px\"align=\"center\">\n    </div><br>","metadata":{}},{"cell_type":"markdown","source":"Idea here is we don‚Äôt explicitly model density or the underlying distribution, Instead we try to generate new instances which are similar to data over the iterations. This optimizes to sample from very complex distributions which cannot be learned and modeled directly. Instead we‚Äôre going to have to built same approximation of the input data.\n<br>\nTo achieve this functionality GANs are way to make a generative model by having two neural networks named as Generator(G) and Discriminator(D) which competes with each other.\n<br>\n**Generator(G)** - Generator turns noise into an imitation of the data and try to trick the discriminator.\n<br>\n**Discriminator(D)**- Discriminator tries to identify real data from the fakes created by the generator.","metadata":{}},{"cell_type":"markdown","source":"## Intuition behind GANS\nG starts from noise to try to create an imitation of the real data. Discriminator tries to predict the what‚Äôs real and what fake, by checking the probabilities real vs not real.\n<br>\nNow G is going to take the instances of where the real data lies as lies as input to train & it tries to improve over the iteration process between discriminator and generator.\n<br>\nThings get hard for discriminator to effectively distinguish between what‚Äôs real and what‚Äôs fake.\n<br>\n<div>\n<img src=\"https://miro.medium.com/max/1000/1*Hkg5LYRqcBmHX9KE2mmvbg.webp\" width=\"300px\"align=\"center\">\n    </div><br>","metadata":{}},{"cell_type":"markdown","source":"## How we train GANs ?\nGenerator tries to synthesize fake instances that fool discriminator, discriminator tries to identify the fake one‚Äôs. To actually train we should define the Loss function. Loss function that defines competing and adversarial objectives for each iteration of generator and discriminator and also the global optimum i.e the best possible, would mean that generator could perfectly reproduce the true data distribution. When we train generator of a GAN synthesizes new instances its effectively learning a transformation form a distribution of noise to a target data distribution.\n<br>\nLoss term is based on cross-entropy between generator and discriminator. In GANs we have two neural networks every one has their own loss functions.\n\n<div>\n<img src=\"https://miro.medium.com/max/1400/1*1ntF3BxdtRyHq4E91xLcow.webp\" width=\"800px\"align=\"center\">\n    </div>\n    <br>\n    <div>\n<img src=\"https://miro.medium.com/max/916/1*TjDZ1Qu_F-e4OGSdahZeiQ.webp\" width=\"400px\"align=\"center\">\n    </div>","metadata":{}},{"cell_type":"markdown","source":"In case of Discriminative loss,\n\n> *Maximize the probability that the fake data is identified.*\n\nIn case of Generator loss,\n\n> *Generator will minimize the probability of Fake, because it can‚Äôt effect D(x) (discriminator probability)*","metadata":{}},{"cell_type":"markdown","source":"# GAN Extension\nExtension of the GAN architecture is the idea of the conditioning which improves a bit of additional further structure on types of output that can be synthesized.\n\n<div>\n<img src=\"https://miro.medium.com/max/1400/1*qI7jUL8gqsqrbaL8oP1Ftw.webp\" width=\"800px\"align=\"center\">\n    </div>\nTo train a Conditional GAN, train both networks simultaneously to maximize the performance of both:\n\n1. Train the generator to generate data that ‚Äúfools‚Äù the discriminator.\n2. Train the discriminator to distinguish between real and generated data.","metadata":{}},{"cell_type":"markdown","source":"## Difference between GAN and Conditional GAN\nIn GAN, there is no control over modes of the data to be generated. The conditional GAN changes that by adding the label y as an additional parameter to the generator and hopes that the corresponding images are generated. We also add the labels to the discriminator input to distinguish real images better.\n<br>\nInstead of pair translation is that of unpaired image to image translation this can be achieved by **CycleGAN**.\n<br>\n<div>\n<img src=\"https://miro.medium.com/max/1248/1*uaOVmoDEQ23Ceoz1swyBhw.webp\" width=\"300px\"align=\"center\">\n    </div>\n    <br>\nThis can be achieved by introducing the cyclic relationship in a loss function where we oscillate between domains X & Y in the system. This idea is to go from a particular data manifold to another data manifold.","metadata":{}},{"cell_type":"markdown","source":"But enough said, the journey is not just about reading paper and implementing...\n<div>\n<img src=\"https://miro.medium.com/max/1400/1*xBY_eY5fFqMx7M5Yv_lIJQ.webp\" width=\"800px\"align=\"center\">\n    </div>\n   <br>\n    Let's see this further in the code!","metadata":{}},{"cell_type":"markdown","source":"# 1 ‚Äî Implementing the paper ‚Äî My Approach Baseline","metadata":{}},{"cell_type":"markdown","source":"# 1.1- Loading Image Paths\n","metadata":{}},{"cell_type":"code","source":"class Config:\n    external_data_size = 10000\n    train_size = 8000\n    image_size_1 = 256\n    image_size_2 = 256\n    batch_size = 32\n    LeakyReLU_slope = 0.2\n    dropout = 0.5\n    kernel_size = 4\n    stride = 2\n    padding = 1\n    gen_lr = 2e-4\n    disc_lr = 2e-4\n    beta1 = 0.5\n    beta2 = 0.999\n    lambda_l1 = 100\n    gan_mode = 'vanilla'\n    layers_to_cut = -2\n    epochs = 5\n    pretrain_lr = 1e-4","metadata":{"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-12-31T08:42:23.623634Z","iopub.execute_input":"2022-12-31T08:42:23.624187Z","iopub.status.idle":"2022-12-31T08:42:23.63225Z","shell.execute_reply.started":"2022-12-31T08:42:23.624144Z","shell.execute_reply":"2022-12-31T08:42:23.631186Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# !pip install --upgrade torch torchvision","metadata":{"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-12-31T08:15:43.815793Z","iopub.execute_input":"2022-12-31T08:15:43.816158Z","iopub.status.idle":"2022-12-31T08:15:43.820887Z","shell.execute_reply.started":"2022-12-31T08:15:43.816126Z","shell.execute_reply":"2022-12-31T08:15:43.819664Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport glob\nimport time\nimport numpy as np\nfrom PIL import Image\nfrom pathlib import Path\nfrom tqdm.notebook import tqdm\nimport matplotlib.pyplot as plt\nfrom skimage.color import rgb2lab, lab2rgb\nPath.ls = lambda x: list(x.iterdir())\n\nimport PIL\nfrom PIL import Image\n\nimport torch\nfrom torch import nn, optim\nfrom torch import nn, optim\nfrom torchvision import transforms\nfrom torchvision.models.resnet import resnet18\nfrom torchvision.models.vgg import vgg19\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision.utils import make_grid\nfrom torch.hub import load_state_dict_from_url\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","metadata":{"execution":{"iopub.status.busy":"2022-12-31T08:15:44.09551Z","iopub.execute_input":"2022-12-31T08:15:44.09658Z","iopub.status.idle":"2022-12-31T08:15:46.249048Z","shell.execute_reply.started":"2022-12-31T08:15:44.096537Z","shell.execute_reply":"2022-12-31T08:15:46.24799Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install fastai==2.4","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2022-12-31T08:15:46.251227Z","iopub.execute_input":"2022-12-31T08:15:46.252159Z","iopub.status.idle":"2022-12-31T08:17:03.955215Z","shell.execute_reply.started":"2022-12-31T08:15:46.252118Z","shell.execute_reply":"2022-12-31T08:17:03.954033Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"try:\n    from torch.hub import load_state_dict_from_url\nexcept ImportError:\n    from torch.utils.model_zoo import load_url as load_state_dict_from_url","metadata":{"execution":{"iopub.status.busy":"2022-12-31T08:17:03.957738Z","iopub.execute_input":"2022-12-31T08:17:03.958167Z","iopub.status.idle":"2022-12-31T08:17:03.96471Z","shell.execute_reply.started":"2022-12-31T08:17:03.958125Z","shell.execute_reply":"2022-12-31T08:17:03.963031Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install torch torchvision==0.7.0","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2022-12-31T08:17:11.286659Z","iopub.execute_input":"2022-12-31T08:17:11.28705Z","iopub.status.idle":"2022-12-31T08:18:07.433682Z","shell.execute_reply.started":"2022-12-31T08:17:11.287015Z","shell.execute_reply":"2022-12-31T08:18:07.432442Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip3 install Cython","metadata":{"execution":{"iopub.status.busy":"2022-12-31T08:19:46.527709Z","iopub.execute_input":"2022-12-31T08:19:46.528164Z","iopub.status.idle":"2022-12-31T08:19:56.091142Z","shell.execute_reply.started":"2022-12-31T08:19:46.528123Z","shell.execute_reply":"2022-12-31T08:19:56.089674Z"},"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from fastai.vision.learner import create_body\nfrom fastai.vision.models.unet import DynamicUnet","metadata":{"execution":{"iopub.status.busy":"2022-12-31T08:20:02.738684Z","iopub.execute_input":"2022-12-31T08:20:02.73911Z","iopub.status.idle":"2022-12-31T08:20:03.642265Z","shell.execute_reply.started":"2022-12-31T08:20:02.739071Z","shell.execute_reply":"2022-12-31T08:20:03.641249Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from fastai.data.external import untar_data, URLs\ncoco_path = untar_data(URLs.COCO_SAMPLE)\ncoco_path = str(coco_path) + \"/train_sample\"\nuse_colab = True","metadata":{"execution":{"iopub.status.busy":"2022-12-31T08:20:06.366063Z","iopub.execute_input":"2022-12-31T08:20:06.366719Z","iopub.status.idle":"2022-12-31T08:21:53.021021Z","shell.execute_reply.started":"2022-12-31T08:20:06.366672Z","shell.execute_reply":"2022-12-31T08:21:53.020026Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if use_colab == True:\n    path = coco_path\nelse:\n    path = \"Your path to the dataset\"\n    \npaths = glob.glob(path + \"/*.jpg\") # Grabbing all the image file names\nnp.random.seed(123)\npaths_subset = np.random.choice(paths, 10_000, replace=False) # choosing 1000 images randomly\nrand_idxs = np.random.permutation(10_000)\ntrain_idxs = rand_idxs[:8000] # choosing the first 8000 as training set\nval_idxs = rand_idxs[8000:] # choosing last 2000 as validation set\ntrain_paths = paths_subset[train_idxs]\nval_paths = paths_subset[val_idxs]\nprint(len(train_paths), len(val_paths))","metadata":{"execution":{"iopub.status.busy":"2022-12-31T08:21:53.022999Z","iopub.execute_input":"2022-12-31T08:21:53.023359Z","iopub.status.idle":"2022-12-31T08:21:53.115349Z","shell.execute_reply.started":"2022-12-31T08:21:53.023325Z","shell.execute_reply":"2022-12-31T08:21:53.114153Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"_, axes = plt.subplots(4, 4, figsize=(10, 10))\nfor ax, img_path in zip(axes.flatten(), train_paths):\n    ax.imshow(Image.open(img_path))\n    ax.axis(\"off\")","metadata":{"execution":{"iopub.status.busy":"2022-12-31T08:21:54.702467Z","iopub.execute_input":"2022-12-31T08:21:54.703075Z","iopub.status.idle":"2022-12-31T08:21:56.224464Z","shell.execute_reply.started":"2022-12-31T08:21:54.703039Z","shell.execute_reply":"2022-12-31T08:21:56.222985Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 1.2- Making Datasets and DataLoaders","metadata":{}},{"cell_type":"code","source":"SIZE = 256\nclass ColorizationDataset(Dataset):\n    def __init__(self, paths, split='train'):\n        if split == 'train':\n            self.transforms = transforms.Compose([\n                transforms.Resize((SIZE, SIZE),  Image.Resampling.BICUBIC),\n                transforms.RandomHorizontalFlip(), # A little data augmentation!\n            ])\n        elif split == 'val':\n            self.transforms = transforms.Resize((SIZE, SIZE),  Image.Resampling.BICUBIC)\n        \n        self.split = split\n        self.size = SIZE\n        self.paths = paths\n    \n    def __getitem__(self, idx):\n        img = Image.open(self.paths[idx]).convert(\"RGB\")\n        img = self.transforms(img)\n        img = np.array(img)\n        img_lab = rgb2lab(img).astype(\"float32\") # Converting RGB to L*a*b\n        img_lab = transforms.ToTensor()(img_lab)\n        L = img_lab[[0], ...] / 50. - 1. # Between -1 and 1\n        ab = img_lab[[1, 2], ...] / 110. # Between -1 and 1\n        \n        return {'L': L, 'ab': ab}\n\n    def __len__(self):\n        return len(self.paths)","metadata":{"execution":{"iopub.status.busy":"2022-12-31T08:42:31.951379Z","iopub.execute_input":"2022-12-31T08:42:31.951842Z","iopub.status.idle":"2022-12-31T08:42:31.968149Z","shell.execute_reply.started":"2022-12-31T08:42:31.951802Z","shell.execute_reply":"2022-12-31T08:42:31.967Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def make_dataloaders(batch_size=16,\n                     n_workers=2,\n                     pin_memory=True,\n                     **kwargs): # A handy function to make our dataloaders\n    dataset = ColorizationDataset(**kwargs)\n    dataloader = DataLoader(dataset,\n                            batch_size=batch_size,\n                            num_workers=n_workers,\n                            pin_memory=pin_memory)\n    return dataloader","metadata":{"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-12-31T08:42:32.232368Z","iopub.execute_input":"2022-12-31T08:42:32.235505Z","iopub.status.idle":"2022-12-31T08:42:32.25341Z","shell.execute_reply.started":"2022-12-31T08:42:32.235449Z","shell.execute_reply":"2022-12-31T08:42:32.250088Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dl = make_dataloaders(paths=train_paths, split='train')\nval_dl = make_dataloaders(paths=val_paths, split='val')\n\ndata = next(iter(train_dl))\nLs, abs_ = data['L'], data['ab']\nprint(Ls.shape, abs_.shape)\nprint(len(train_dl), len(val_dl))","metadata":{"execution":{"iopub.status.busy":"2022-12-31T08:42:32.509593Z","iopub.execute_input":"2022-12-31T08:42:32.510062Z","iopub.status.idle":"2022-12-31T08:42:35.212008Z","shell.execute_reply.started":"2022-12-31T08:42:32.51002Z","shell.execute_reply":"2022-12-31T08:42:35.210431Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 1.3- Generator proposed by the paper","metadata":{}},{"cell_type":"code","source":"class UnetBlock(nn.Module):\n    def __init__(self, nf, ni, submodule=None, input_c=None, dropout=False,\n                 innermost=False, outermost=False):\n        super().__init__()\n        self.outermost = outermost\n        if input_c is None: input_c = nf\n        downconv = nn.Conv2d(input_c, ni, kernel_size=4,\n                             stride=2, padding=1, bias=False)\n        downrelu = nn.LeakyReLU(0.2, True)\n        downnorm = nn.BatchNorm2d(ni)\n        uprelu = nn.ReLU(True)\n        upnorm = nn.BatchNorm2d(nf)\n        \n        if outermost:\n            upconv = nn.ConvTranspose2d(ni * 2, nf, kernel_size=4,\n                                        stride=2, padding=1)\n            down = [downconv]\n            up = [uprelu, upconv, nn.Tanh()]\n            model = down + [submodule] + up\n        elif innermost:\n            upconv = nn.ConvTranspose2d(ni, nf, kernel_size=4,\n                                        stride=2, padding=1, bias=False)\n            down = [downrelu, downconv]\n            up = [uprelu, upconv, upnorm]\n            model = down + up\n        else:\n            upconv = nn.ConvTranspose2d(ni * 2, nf, kernel_size=4,\n                                        stride=2, padding=1, bias=False)\n            down = [downrelu, downconv, downnorm]\n            up = [uprelu, upconv, upnorm]\n            if dropout: up += [nn.Dropout(0.5)]\n            model = down + [submodule] + up\n        self.model = nn.Sequential(*model)\n    \n    def forward(self, x):\n        if self.outermost:\n            return self.model(x)\n        else:\n            return torch.cat([x, self.model(x)], 1)\n\nclass Unet(nn.Module):\n    def __init__(self, input_c=1, output_c=2, n_down=8, num_filters=64):\n        super().__init__()\n        unet_block = UnetBlock(num_filters * 8, num_filters * 8, innermost=True)\n        for _ in range(n_down - 5):\n            unet_block = UnetBlock(num_filters * 8, num_filters * 8, submodule=unet_block, dropout=True)\n        out_filters = num_filters * 8\n        for _ in range(3):\n            unet_block = UnetBlock(out_filters // 2, out_filters, submodule=unet_block)\n            out_filters //= 2\n        self.model = UnetBlock(output_c, out_filters, input_c=input_c, submodule=unet_block, outermost=True)\n    \n    def forward(self, x):\n        return self.model(x)","metadata":{"execution":{"iopub.status.busy":"2022-12-31T08:42:35.214612Z","iopub.execute_input":"2022-12-31T08:42:35.215043Z","iopub.status.idle":"2022-12-31T08:42:35.242144Z","shell.execute_reply.started":"2022-12-31T08:42:35.214998Z","shell.execute_reply":"2022-12-31T08:42:35.240752Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 1.4- Discriminator","metadata":{}},{"cell_type":"code","source":"class PatchDiscriminator(nn.Module):\n    def __init__(self, input_c, num_filters=64, n_down=3):\n        super().__init__()\n        model = [self.get_layers(input_c, num_filters, norm=False)]\n        model += [self.get_layers(num_filters * 2 ** i, num_filters * 2 ** (i + 1), s=1 if i == (n_down-1) else 2) \n                          for i in range(n_down)] # the 'if' statement is taking care of not using\n                                                  # stride of 2 for the last block in this loop\n        model += [self.get_layers(num_filters * 2 ** n_down, 1, s=1, norm=False, act=False)] # Make sure to not use normalization or\n                                                                                             # activation for the last layer of the model\n        self.model = nn.Sequential(*model)                                                   \n        \n    def get_layers(self, ni, nf, k=4, s=2, p=1, norm=True, act=True): # when needing to make some repeatitive blocks of layers,\n        layers = [nn.Conv2d(ni, nf, k, s, p, bias=not norm)]          # it's always helpful to make a separate method for that purpose\n        if norm: layers += [nn.BatchNorm2d(nf)]\n        if act: layers += [nn.LeakyReLU(0.2, True)]\n        return nn.Sequential(*layers)\n    \n    def forward(self, x):\n        return self.model(x)","metadata":{"execution":{"iopub.status.busy":"2022-12-31T08:42:35.24453Z","iopub.execute_input":"2022-12-31T08:42:35.2461Z","iopub.status.idle":"2022-12-31T08:42:35.260566Z","shell.execute_reply.started":"2022-12-31T08:42:35.246056Z","shell.execute_reply":"2022-12-31T08:42:35.259417Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"PatchDiscriminator(3)","metadata":{"execution":{"iopub.status.busy":"2022-12-31T08:42:35.266944Z","iopub.execute_input":"2022-12-31T08:42:35.267957Z","iopub.status.idle":"2022-12-31T08:42:35.320495Z","shell.execute_reply.started":"2022-12-31T08:42:35.267908Z","shell.execute_reply":"2022-12-31T08:42:35.319373Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"discriminator = PatchDiscriminator(3)\ndummy_input = torch.randn(16, 3, 256, 256) # batch_size, channels, size, size\nout = discriminator(dummy_input)\nout.shape","metadata":{"execution":{"iopub.status.busy":"2022-12-31T08:42:35.324837Z","iopub.execute_input":"2022-12-31T08:42:35.32813Z","iopub.status.idle":"2022-12-31T08:42:37.500369Z","shell.execute_reply.started":"2022-12-31T08:42:35.328087Z","shell.execute_reply":"2022-12-31T08:42:37.499364Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 1.5- GAN Loss","metadata":{}},{"cell_type":"code","source":"class GANLoss(nn.Module):\n    def __init__(self, gan_mode='vanilla', real_label=1.0, fake_label=0.0):\n        super().__init__()\n        self.register_buffer('real_label', torch.tensor(real_label))\n        self.register_buffer('fake_label', torch.tensor(fake_label))\n        if gan_mode == 'vanilla':\n            self.loss = nn.BCEWithLogitsLoss()\n        elif gan_mode == 'lsgan':\n            self.loss = nn.MSELoss()\n    \n    def get_labels(self, preds, target_is_real):\n        if target_is_real:\n            labels = self.real_label\n        else:\n            labels = self.fake_label\n        return labels.expand_as(preds)\n    \n    def __call__(self, preds, target_is_real):\n        labels = self.get_labels(preds, target_is_real)\n        loss = self.loss(preds, labels)\n        return loss","metadata":{"execution":{"iopub.status.busy":"2022-12-31T08:42:37.504661Z","iopub.execute_input":"2022-12-31T08:42:37.507657Z","iopub.status.idle":"2022-12-31T08:42:37.518927Z","shell.execute_reply.started":"2022-12-31T08:42:37.507612Z","shell.execute_reply":"2022-12-31T08:42:37.517404Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 1.x Model Initialization","metadata":{}},{"cell_type":"code","source":"def init_weights(net, init='norm', gain=0.02):\n    \n    def init_func(m):\n        classname = m.__class__.__name__\n        if hasattr(m, 'weight') and 'Conv' in classname:\n            if init == 'norm':\n                nn.init.normal_(m.weight.data, mean=0.0, std=gain)\n            elif init == 'xavier':\n                nn.init.xavier_normal_(m.weight.data, gain=gain)\n            elif init == 'kaiming':\n                nn.init.kaiming_normal_(m.weight.data, a=0, mode='fan_in')\n            \n            if hasattr(m, 'bias') and m.bias is not None:\n                nn.init.constant_(m.bias.data, 0.0)\n        elif 'BatchNorm2d' in classname:\n            nn.init.normal_(m.weight.data, 1., gain)\n            nn.init.constant_(m.bias.data, 0.)\n            \n    net.apply(init_func)\n    print(f\"model initialized with {init} initialization\")\n    return net\n\ndef init_model(model, device):\n    model = model.to(device)\n    model = init_weights(model)\n    return model","metadata":{"execution":{"iopub.status.busy":"2022-12-31T08:42:37.522069Z","iopub.execute_input":"2022-12-31T08:42:37.523Z","iopub.status.idle":"2022-12-31T08:42:37.535134Z","shell.execute_reply.started":"2022-12-31T08:42:37.522937Z","shell.execute_reply":"2022-12-31T08:42:37.534115Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 1.6- Putting everything together","metadata":{}},{"cell_type":"code","source":"class MainModel(nn.Module):\n    def __init__(self, net_G=None, lr_G=2e-4, lr_D=2e-4, \n                 beta1=0.5, beta2=0.999, lambda_L1=100.):\n        super().__init__()\n        \n        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n        self.lambda_L1 = lambda_L1\n        \n        if net_G is None:\n            self.net_G = init_model(Unet(input_c=1, output_c=2, n_down=8, num_filters=64), self.device)\n        else:\n            self.net_G = net_G.to(self.device)\n        self.net_D = init_model(PatchDiscriminator(input_c=3, n_down=3, num_filters=64), self.device)\n        self.GANcriterion = GANLoss(gan_mode='vanilla').to(self.device)\n        self.L1criterion = nn.L1Loss()\n        self.opt_G = optim.Adam(self.net_G.parameters(), lr=lr_G, betas=(beta1, beta2))\n        self.opt_D = optim.Adam(self.net_D.parameters(), lr=lr_D, betas=(beta1, beta2))\n    \n    def set_requires_grad(self, model, requires_grad=True):\n        for p in model.parameters():\n            p.requires_grad = requires_grad\n        \n    def setup_input(self, data):\n        self.L = data['L'].to(self.device)\n        self.ab = data['ab'].to(self.device)\n        \n    def forward(self):\n        self.fake_color = self.net_G(self.L)\n    \n    def backward_D(self):\n        fake_image = torch.cat([self.L, self.fake_color], dim=1)\n        fake_preds = self.net_D(fake_image.detach())\n        self.loss_D_fake = self.GANcriterion(fake_preds, False)\n        real_image = torch.cat([self.L, self.ab], dim=1)\n        real_preds = self.net_D(real_image)\n        self.loss_D_real = self.GANcriterion(real_preds, True)\n        self.loss_D = (self.loss_D_fake + self.loss_D_real) * 0.5\n        self.loss_D.backward()\n    \n    def backward_G(self):\n        fake_image = torch.cat([self.L, self.fake_color], dim=1)\n        fake_preds = self.net_D(fake_image)\n        self.loss_G_GAN = self.GANcriterion(fake_preds, True)\n        self.loss_G_L1 = self.L1criterion(self.fake_color, self.ab) * self.lambda_L1\n        self.loss_G = self.loss_G_GAN + self.loss_G_L1\n        self.loss_G.backward()\n    \n    def optimize(self):\n        self.forward()\n        self.net_D.train()\n        self.set_requires_grad(self.net_D, True)\n        self.opt_D.zero_grad()\n        self.backward_D()\n        self.opt_D.step()\n        \n        self.net_G.train()\n        self.set_requires_grad(self.net_D, False)\n        self.opt_G.zero_grad()\n        self.backward_G()\n        self.opt_G.step()","metadata":{"execution":{"iopub.status.busy":"2022-12-31T08:42:37.536961Z","iopub.execute_input":"2022-12-31T08:42:37.537701Z","iopub.status.idle":"2022-12-31T08:42:37.558789Z","shell.execute_reply.started":"2022-12-31T08:42:37.537665Z","shell.execute_reply":"2022-12-31T08:42:37.55777Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 1.xx Utility functions","metadata":{}},{"cell_type":"code","source":"class AverageMeter:\n    def __init__(self):\n        self.reset()\n\n    def reset(self):\n        self.count, self.avg, self.sum = [0.] * 3\n\n    def update(self, val, count=1):\n        self.count += count\n        self.sum += count * val\n        self.avg = self.sum / self.count\n\ndef create_loss_meters():\n    loss_D_fake = AverageMeter()\n    loss_D_real = AverageMeter()\n    loss_D = AverageMeter()\n    loss_G_GAN = AverageMeter()\n    loss_G_L1 = AverageMeter()\n    loss_G = AverageMeter()\n\n    return {'loss_D_fake': loss_D_fake,\n            'loss_D_real': loss_D_real,\n            'loss_D': loss_D,\n            'loss_G_GAN': loss_G_GAN,\n            'loss_G_L1': loss_G_L1,\n            'loss_G': loss_G}\n\ndef update_losses(model, loss_meter_dict, count):\n    for loss_name, loss_meter in loss_meter_dict.items():\n        loss = getattr(model, loss_name)\n        loss_meter.update(loss.item(), count=count)\n\ndef lab_to_rgb(L, ab):\n    \"\"\"\n    Takes a batch of images\n    \"\"\"\n    L = (L + 1.) * 50.\n    ab = ab * 110.\n    Lab = torch.cat([L, ab], dim=1).permute(0, 2, 3, 1).cpu().numpy()\n    rgb_imgs = []\n    for img in Lab:\n        img_rgb = lab2rgb(img)\n        rgb_imgs.append(img_rgb)\n    return np.stack(rgb_imgs, axis=0)\n\ndef visualize(model, data, save=True):\n    model.net_G.eval()\n    with torch.no_grad():\n        model.setup_input(data)\n        model.forward()\n    model.net_G.train()\n    fake_color = model.fake_color.detach()\n    real_color = model.ab\n    L = model.L\n    fake_imgs = lab_to_rgb(L, fake_color)\n    real_imgs = lab_to_rgb(L, real_color)\n    fig = plt.figure(figsize=(15, 8))\n    for i in range(5):\n        ax = plt.subplot(3, 5, i + 1)\n        ax.imshow(L[i][0].cpu(), cmap='gray')\n        ax.axis(\"off\")\n        ax = plt.subplot(3, 5, i + 1 + 5)\n        ax.imshow(fake_imgs[i])\n        ax.axis(\"off\")\n        ax = plt.subplot(3, 5, i + 1 + 10)\n        ax.imshow(real_imgs[i])\n        ax.axis(\"off\")\n    plt.show()\n    if save:\n        fig.savefig(f\"colorization_{time.time()}.png\")\n\ndef log_results(loss_meter_dict):\n    for loss_name, loss_meter in loss_meter_dict.items():\n        print(f\"{loss_name}: {loss_meter.avg:.5f}\")","metadata":{"execution":{"iopub.status.busy":"2022-12-31T08:42:37.665365Z","iopub.execute_input":"2022-12-31T08:42:37.665905Z","iopub.status.idle":"2022-12-31T08:42:37.68655Z","shell.execute_reply.started":"2022-12-31T08:42:37.665852Z","shell.execute_reply":"2022-12-31T08:42:37.685387Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def build_backbone_unet(input_channels=1, output_channels=2, size=Config.image_size_1):\n    \"\"\"Function that helps build the generator backbone using another pretrained model trained on imagenet for image classification\"\"\"\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    body = create_body(resnet18, pretrained=True, n_in=input_channels, cut=Config.layers_to_cut)\n    generator = DynamicUnet(body, output_channels, (size, size)).to(device)\n    return generator\n\ndef pretrain_generator(generator, train_dl, opt, criterion, epochs):\n    \"\"\"\n\n    Function to pretrain the generator in a supervised manner on the colorization task using L1 Loss.\n\n    \"\"\"\n\n    for e in range(epochs):\n        loss_meter = AverageMeter()\n        for data in tqdm(train_dl):\n            L, ab = data['L'].to(device), data['ab'].to(device)\n            preds = generator(L)\n            loss = criterion(preds, ab)\n            opt.zero_grad()\n            loss.backward()\n            opt.step()\n\n            loss_meter.update(loss.item(), L.size(0))\n\n        print(f\"Epoch {e + 1}/{epochs}\")\n        print(f\"L1 Loss: {loss_meter.avg:.5f}\")","metadata":{"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-12-31T08:42:38.305358Z","iopub.execute_input":"2022-12-31T08:42:38.305832Z","iopub.status.idle":"2022-12-31T08:42:38.317796Z","shell.execute_reply.started":"2022-12-31T08:42:38.305792Z","shell.execute_reply":"2022-12-31T08:42:38.316505Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 1.7- Training function","metadata":{}},{"cell_type":"code","source":"def train_model(model, train_dl, epochs, display_every=200):\n    data = next(iter(val_dl)) # getting a batch for visualizing the model output after fixed intrvals\n    for e in range(epochs):\n        loss_meter_dict = create_loss_meters() # function returing a dictionary of objects to \n        i = 0                                  # log the losses of the complete network\n        for data in tqdm(train_dl):\n            model.setup_input(data) \n            model.optimize()\n            update_losses(model, loss_meter_dict, count=data['L'].size(0)) # function updating the log objects\n            i += 1\n            if i % display_every == 0:\n                print(f\"\\nEpoch {e+1}/{epochs}\")\n                print(f\"Iteration {i}/{len(train_dl)}\")\n                log_results(loss_meter_dict) # function to print out the losses\n                visualize(model, data, save=False) # function displaying the model's outputs","metadata":{"execution":{"iopub.status.busy":"2022-12-31T08:42:39.825888Z","iopub.execute_input":"2022-12-31T08:42:39.826513Z","iopub.status.idle":"2022-12-31T08:42:39.841522Z","shell.execute_reply.started":"2022-12-31T08:42:39.826468Z","shell.execute_reply":"2022-12-31T08:42:39.840348Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"generator = build_backbone_unet(input_channels=1, output_channels=2, size=Config.image_size_1)\nopt = optim.Adam(generator.parameters(), lr=Config.pretrain_lr)\nloss = nn.L1Loss()\npretrain_generator(generator, train_dl, opt, loss, Config.epochs)\ntorch.save(generator.state_dict(), \"res18-unet.pt\")\ngenerator.load_state_dict(torch.load(\"res18-unet.pt\", map_location=device))\nmodel = MainModel(net_G=generator)\ntrain_model(model, train_dl, Config.epochs)\ntorch.save(model.state_dict(), \"main-model.pt\")","metadata":{"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-12-31T08:42:43.623162Z","iopub.execute_input":"2022-12-31T08:42:43.623753Z","iopub.status.idle":"2022-12-31T09:24:07.218282Z","shell.execute_reply.started":"2022-12-31T08:42:43.62371Z","shell.execute_reply":"2022-12-31T09:24:07.217189Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 1.8 Model Inference","metadata":{}},{"cell_type":"code","source":"path = \"/kaggle/input/pip2pix-data2/test_image.jpeg\"\nimg = PIL.Image.open(path)\nimg = img.resize((256, 256))\nimg = transforms.ToTensor()(img)[:1] * 2. - 1.\nmodel.eval()\nwith torch.no_grad():\n    preds = model.net_G(img.unsqueeze(0).to(device))\n    gen_output = lab_to_rgb(img.unsqueeze(0), preds.cpu())[0]\n# plt.imshow(img)\nplt.imshow(gen_output)","metadata":{"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-12-31T09:24:07.222339Z","iopub.execute_input":"2022-12-31T09:24:07.223396Z","iopub.status.idle":"2022-12-31T09:24:07.524869Z","shell.execute_reply.started":"2022-12-31T09:24:07.223355Z","shell.execute_reply":"2022-12-31T09:24:07.523912Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"So, it's working. Run it for more epochs and the result will be better. Try experimenting with it as well.","metadata":{}},{"cell_type":"markdown","source":"## Courtesy and Sources:\nThank you for reading this notebook. I hope you found something useful. This notebook could not be possible without these resources. Make sure to check it out.\n* https://medium.com/@harikrishnareddy19995/gans-with-memes-4233952ba151\n* https://phillipi.github.io/pix2pix/\n* https://arxiv.org/pdf/1611.07004.pdf\n* https://towardsdatascience.com/colorizing-black-white-images-with-u-net-and-conditional-gan-a-tutorial-81b2df111cd8\n\nIf you do find this notebook useful, please upvote. This will motivate me to create more notebooks further ahead.","metadata":{}},{"cell_type":"markdown","source":"<div style=\"color:white;\n           display:fill;\n           border-radius:5px;\n           background-color:#5642C5;\n           font-size:140%;\n           font-family:Verdana;\n           letter-spacing:0.5px;\">\n\n<p style=\"padding: 10px;\n              color:white;\n          text-align: center;\">  Please do upvote üôè\n</p>\n</div>","metadata":{}}]}