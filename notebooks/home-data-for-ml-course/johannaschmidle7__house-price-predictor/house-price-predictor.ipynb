{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":10211,"databundleVersionId":111096,"sourceType":"competition"}],"dockerImageVersionId":30746,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# House Price Predictor Project\nThis is my code for my competition submission for the [Housing Prices Competition for Kaggle Learn Users](https://www.kaggle.com/competitions/home-data-for-ml-course)\n\n**Goal:** build a machine learning model to predict the sales price for each house. For each Id in the test set, I must predict the value of the **SalePrice** variable. \n\nSubmissions are evaluated on **Root-Mean-Squared-Error** (RMSE) between the logarithm of the predicted value and the logarithm of the observed sales price. (Taking logs means that errors in predicting expensive houses and cheap houses will affect the result equally.)\n\nI am going to create 3 models (the final model is the one I am going to submit):\n- **Model 1:** Random Forest Regressor\n- **Model 2:** Random Forest Regressor + Cross-Validation (Parameter Turing)\n- **Model 3**: XGBoost + Cross-Validation (Parameter Turing)\n\n# Setting Up","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np \nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport warnings\nwarnings.simplefilter(action='ignore', category=FutureWarning)\nfrom IPython.display import display, HTML\n\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.model_selection import train_test_split\n\nfrom sklearn.preprocessing import OrdinalEncoder\nfrom sklearn.preprocessing import OneHotEncoder\nimport category_encoders as ce\nfrom sklearn.tree import DecisionTreeRegressor\n\nfrom scipy import stats\n\nfrom sklearn.metrics import mean_squared_error, r2_score\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import GridSearchCV\nimport xgboost as xgb\n\n# I will use this colourmap later\ncmap = plt.get_cmap('coolwarm')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-07-26T15:37:40.748269Z","iopub.execute_input":"2024-07-26T15:37:40.748663Z","iopub.status.idle":"2024-07-26T15:37:40.756599Z","shell.execute_reply.started":"2024-07-26T15:37:40.748636Z","shell.execute_reply":"2024-07-26T15:37:40.755381Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data = pd.read_csv(\"/kaggle/input/home-data-for-ml-course/train.csv\")","metadata":{"execution":{"iopub.status.busy":"2024-07-26T16:05:36.047628Z","iopub.execute_input":"2024-07-26T16:05:36.048044Z","iopub.status.idle":"2024-07-26T16:05:36.074098Z","shell.execute_reply.started":"2024-07-26T16:05:36.048014Z","shell.execute_reply":"2024-07-26T16:05:36.07293Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data.head()","metadata":{"execution":{"iopub.status.busy":"2024-07-26T15:37:45.965717Z","iopub.execute_input":"2024-07-26T15:37:45.966093Z","iopub.status.idle":"2024-07-26T15:37:46.005845Z","shell.execute_reply.started":"2024-07-26T15:37:45.966062Z","shell.execute_reply":"2024-07-26T15:37:46.004767Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data.describe()","metadata":{"execution":{"iopub.status.busy":"2024-07-26T16:23:33.52388Z","iopub.execute_input":"2024-07-26T16:23:33.524261Z","iopub.status.idle":"2024-07-26T16:23:33.621503Z","shell.execute_reply.started":"2024-07-26T16:23:33.524229Z","shell.execute_reply":"2024-07-26T16:23:33.620242Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Picking Features","metadata":{}},{"cell_type":"code","source":"train_data.columns","metadata":{"execution":{"iopub.status.busy":"2024-07-26T15:37:52.761392Z","iopub.execute_input":"2024-07-26T15:37:52.761766Z","iopub.status.idle":"2024-07-26T15:37:52.769468Z","shell.execute_reply.started":"2024-07-26T15:37:52.761738Z","shell.execute_reply":"2024-07-26T15:37:52.768406Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"There are a lot of features to choose from. I am going to focus on the ones that I think will have the most significant impact on housing price:\n- **Quality and Condition:** Overall quality and condition ratings, kitchen quality, and heating quality provide a direct measure of the house's condition and materials, which are critical in determining price.\n- **Size and Space:** Features such as living area square footage, basement area, first and second floor areas, total rooms, and garage size are direct indicators of the house's space and capacity, which significantly influence price.\n- **Year Built and Remodel Date:** The age of the house and any renovations provide insight into the property's age and modernization level.\n- **Location:** The neighborhood is crucial as location often dictates real estate prices.\n- **Amenities:** Features like fireplaces, air conditioning, and garage are amenities that can add value to a property.\n\n","metadata":{}},{"cell_type":"code","source":"features = ['OverallQual', 'OverallCond', 'YearBuilt', 'YearRemodAdd', 'GrLivArea', \n            'TotalBsmtSF','1stFlrSF', '2ndFlrSF', 'GarageCars', 'GarageArea', 'FullBath', \n            'HalfBath', 'KitchenQual', 'TotRmsAbvGrd', 'Fireplaces', 'FireplaceQu', \n            'GarageYrBlt', 'LotArea', 'Neighborhood', 'BsmtFinSF1', 'BsmtFinSF2', \n            'BsmtUnfSF', 'HeatingQC', 'CentralAir', 'BedroomAbvGr']","metadata":{"execution":{"iopub.status.busy":"2024-07-26T16:07:51.092312Z","iopub.execute_input":"2024-07-26T16:07:51.092724Z","iopub.status.idle":"2024-07-26T16:07:51.098282Z","shell.execute_reply.started":"2024-07-26T16:07:51.092684Z","shell.execute_reply":"2024-07-26T16:07:51.097099Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Understanding the Data","metadata":{}},{"cell_type":"code","source":"# Get Numerical Features \nnumerical_cols = train_data[features].select_dtypes(include=['int64', 'float64']).columns.tolist()\nprint(f\"Numerical columns: {numerical_cols}\")","metadata":{"execution":{"iopub.status.busy":"2024-07-26T15:38:17.970991Z","iopub.execute_input":"2024-07-26T15:38:17.971519Z","iopub.status.idle":"2024-07-26T15:38:17.97963Z","shell.execute_reply.started":"2024-07-26T15:38:17.971485Z","shell.execute_reply":"2024-07-26T15:38:17.978501Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Numerical features\nnum_features= ['SalePrice', 'OverallQual', 'OverallCond', 'YearBuilt', 'YearRemodAdd',\n               'TotalBsmtSF', '1stFlrSF', '2ndFlrSF', 'GarageCars', 'GarageArea', \n               'FullBath', 'HalfBath', 'TotRmsAbvGrd', 'Fireplaces', 'GarageYrBlt', \n               'LotArea', 'BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF', 'BedroomAbvGr', \n               'GrLivArea']","metadata":{"execution":{"iopub.status.busy":"2024-07-26T16:06:14.638251Z","iopub.execute_input":"2024-07-26T16:06:14.638638Z","iopub.status.idle":"2024-07-26T16:06:14.644392Z","shell.execute_reply.started":"2024-07-26T16:06:14.638606Z","shell.execute_reply":"2024-07-26T16:06:14.643192Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(15,8))\nsns.heatmap(train_data[num_features].corr(), annot=True, cmap=\"coolwarm\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-07-26T16:06:16.277421Z","iopub.execute_input":"2024-07-26T16:06:16.277818Z","iopub.status.idle":"2024-07-26T16:06:17.736861Z","shell.execute_reply.started":"2024-07-26T16:06:16.277785Z","shell.execute_reply":"2024-07-26T16:06:17.73542Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Strong Correlation to SalePrice**\n- OverallQual: 0.79\n- GrLivArea: 0.71\n\nI just want to check if any of the numerical features I have not included are strongly correlated to the sale price. ","metadata":{}},{"cell_type":"code","source":"num_columns_not_used = ['Id','MSSubClass','LotFrontage','MasVnrArea','WoodDeckSF','OpenPorchSF',\n                     'EnclosedPorch','3SsnPorch','ScreenPorch','PoolArea','MiscVal','MoSold',\n                     'YrSold', 'SalePrice']\n\nplt.figure(figsize=(15,8))\nsns.heatmap(train_data[num_columns_not_used].corr(), annot=True, cmap=\"coolwarm\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-07-26T15:40:28.61145Z","iopub.execute_input":"2024-07-26T15:40:28.612601Z","iopub.status.idle":"2024-07-26T15:40:29.51436Z","shell.execute_reply.started":"2024-07-26T15:40:28.612561Z","shell.execute_reply":"2024-07-26T15:40:29.513239Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Doesn't seem like any of them are needed","metadata":{}},{"cell_type":"code","source":"train_data[num_features].hist(figsize=(15,15))\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-07-26T16:06:58.408322Z","iopub.execute_input":"2024-07-26T16:06:58.40876Z","iopub.status.idle":"2024-07-26T16:07:02.162281Z","shell.execute_reply.started":"2024-07-26T16:06:58.408725Z","shell.execute_reply":"2024-07-26T16:07:02.161045Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Preprocessing\n### 1. Skewness\nNotice in the histograms for some of the features (LotArea, BsmtFinSF2, BsmtFinSF1) the graphs are skewed. I am going to check how skewed all of the numerical features are","metadata":{}},{"cell_type":"code","source":"skewness = train_data[num_features].skew().sort_values(ascending=False)\nprint(skewness)","metadata":{"execution":{"iopub.status.busy":"2024-07-26T16:07:13.836355Z","iopub.execute_input":"2024-07-26T16:07:13.836764Z","iopub.status.idle":"2024-07-26T16:07:13.849411Z","shell.execute_reply.started":"2024-07-26T16:07:13.836725Z","shell.execute_reply":"2024-07-26T16:07:13.848228Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Highly Skewed**\n- LotArea: 12.207688\n- BsmtFinSF2: 4.255261\n- BsmtFinSF1: 1.685503\n- TotalBsmtSF: 1.524255\n- 1stFlrSF: 1.376757\n- GrLivArea: 1.366560\n\nSome features are only moderatley skewed so I will take note of these and see if they significantly affect the model performance. If they are I will consider transforming them. \n\n**Moderatley skewed:**\n- BsmtUnfSF: 0.920268\n- 2ndFlrSF: 0.813030","metadata":{}},{"cell_type":"code","source":"skewed = ['LotArea','BsmtFinSF2','BsmtFinSF1','TotalBsmtSF','1stFlrSF', 'GrLivArea']\n\nfor feature in skewed:\n    train_data[feature] = np.log(train_data[feature] + 1)","metadata":{"execution":{"iopub.status.busy":"2024-07-26T16:07:17.517553Z","iopub.execute_input":"2024-07-26T16:07:17.517945Z","iopub.status.idle":"2024-07-26T16:07:17.528197Z","shell.execute_reply.started":"2024-07-26T16:07:17.517915Z","shell.execute_reply":"2024-07-26T16:07:17.526944Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data[skewed].hist(figsize=(7,7))\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-07-26T16:07:19.419562Z","iopub.execute_input":"2024-07-26T16:07:19.419962Z","iopub.status.idle":"2024-07-26T16:07:20.358406Z","shell.execute_reply.started":"2024-07-26T16:07:19.419931Z","shell.execute_reply":"2024-07-26T16:07:20.357059Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 2. Null Values\nI want to investigate the null values in my table and see what I can do about them.","metadata":{}},{"cell_type":"code","source":"# Investigate which columns have null values\nnull_feat = train_data[features].isnull().sum()\nnull_feat[null_feat > 0]","metadata":{"execution":{"iopub.status.busy":"2024-07-26T16:08:03.841129Z","iopub.execute_input":"2024-07-26T16:08:03.841542Z","iopub.status.idle":"2024-07-26T16:08:03.854891Z","shell.execute_reply.started":"2024-07-26T16:08:03.841512Z","shell.execute_reply":"2024-07-26T16:08:03.853825Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**FireplaceQu** <br />\nI think this is a result of the house not having a garage. I am going to check this. If I am right, there should be 690 0 values in the GarageFinish column. If I am right, I will fix this by imputing a specific value: *No*. I will do one hot encoding on this column later (because it is a categorical column with 5 unique values), I will just encode this with 0 <br />\n**GarageYrBlt** <br />\nI think this is a result of the house not having a garage. I am going to check this. If I am right, there should be 81 null values in the GarageFinish column. If I am right, I will fix this by imputing a specific value: 0 <br />","metadata":{}},{"cell_type":"code","source":"#FireplaceQu\nmissing_fireplacequ = train_data[train_data['FireplaceQu'].isnull()]\nno_fireplace_check = missing_fireplacequ[missing_fireplacequ['Fireplaces'] == 0].shape[0]\nif no_fireplace_check == 690:\n    print(\"Yay I was right about FireplaceQu :)\")\nelse:\n    print(f\"Back to the dawing board :( you got {no_fireplace_check}\")\n    \n#GarageYrBlt\nmissing_garage_yrb = train_data[train_data['GarageYrBlt'].isnull()]\nno_garage_check = missing_garage_yrb['GarageFinish'].isnull().sum()\nif no_garage_check == 81:\n    print(\"Yay I was right about GarageYrBlt :)\")\nelse:\n    print(f\"Back to the dawing board :( you got {no_garage_check}\")","metadata":{"execution":{"iopub.status.busy":"2024-07-26T16:08:18.520343Z","iopub.execute_input":"2024-07-26T16:08:18.52075Z","iopub.status.idle":"2024-07-26T16:08:18.537253Z","shell.execute_reply.started":"2024-07-26T16:08:18.520717Z","shell.execute_reply":"2024-07-26T16:08:18.535883Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data['FireplaceQu'].fillna('No', inplace=True)\nprint(f\"Number of nulls for FireplaceQu: {train_data['FireplaceQu'].isnull().sum()}\")\n\ntrain_data['GarageYrBlt'].fillna(0, inplace=True)\nprint(f\"Number of nulls for GarageYrBlt: {train_data['GarageYrBlt'].isnull().sum()}\")","metadata":{"execution":{"iopub.status.busy":"2024-07-26T16:08:22.860068Z","iopub.execute_input":"2024-07-26T16:08:22.860463Z","iopub.status.idle":"2024-07-26T16:08:22.869569Z","shell.execute_reply.started":"2024-07-26T16:08:22.860433Z","shell.execute_reply":"2024-07-26T16:08:22.868355Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 3. Split the Data\nI will split the data into training and validation sets. This ensures that your preprocessing steps are based solely on the training set and that the validation set remains a true representation of unseen data. (Avoid data leakage)","metadata":{}},{"cell_type":"code","source":"X = train_data[features]\ny = train_data.SalePrice\n\ntrain_X, val_X, train_y, val_y = train_test_split(X, y, test_size = 0.2, random_state=1)","metadata":{"execution":{"iopub.status.busy":"2024-07-26T16:08:25.598991Z","iopub.execute_input":"2024-07-26T16:08:25.599382Z","iopub.status.idle":"2024-07-26T16:08:25.611772Z","shell.execute_reply.started":"2024-07-26T16:08:25.599354Z","shell.execute_reply":"2024-07-26T16:08:25.610558Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Make a copy before encoding\nencoded_train_X, encoded_val_X = train_X.copy(), val_X.copy()","metadata":{"execution":{"iopub.status.busy":"2024-07-26T16:08:26.662619Z","iopub.execute_input":"2024-07-26T16:08:26.663019Z","iopub.status.idle":"2024-07-26T16:08:26.670447Z","shell.execute_reply.started":"2024-07-26T16:08:26.662986Z","shell.execute_reply":"2024-07-26T16:08:26.669237Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 4. Dealing with Categorical Features\n\nThere are some categorical features. I still want to include them in my data because they are probabaly a contributing factory to the house value.","metadata":{}},{"cell_type":"code","source":"# Get categorical columns\ns = X.dtypes=='object'\nprint(list(s[s].index))","metadata":{"execution":{"iopub.status.busy":"2024-07-26T16:08:32.984269Z","iopub.execute_input":"2024-07-26T16:08:32.984674Z","iopub.status.idle":"2024-07-26T16:08:32.991326Z","shell.execute_reply.started":"2024-07-26T16:08:32.984641Z","shell.execute_reply":"2024-07-26T16:08:32.990158Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cat_features = ['KitchenQual', 'FireplaceQu', 'HeatingQC','CentralAir', 'Neighborhood']\n\nfor feature in cat_features:\n    print(f\"{feature}: {train_data[feature].unique()}\")","metadata":{"execution":{"iopub.status.busy":"2024-07-26T16:08:34.600255Z","iopub.execute_input":"2024-07-26T16:08:34.600622Z","iopub.status.idle":"2024-07-26T16:08:34.60937Z","shell.execute_reply.started":"2024-07-26T16:08:34.600596Z","shell.execute_reply":"2024-07-26T16:08:34.608353Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### KitchenQual\nOur unique values are ['Gd' 'TA' 'Ex' 'Fa']. I will use **ordinal encoding** for this becausse there is a clear assumed ordering for the values. The assigned values are: \n**Ex**: Excellent (4) > **Gd**: Good (3)> **TA**: Average (2) >  **Fa**: Fair (1)","metadata":{}},{"cell_type":"code","source":"categories = [['Fa', 'TA', 'Gd', 'Ex']] #In ascending order\n\nencoder_kitchenQu = OrdinalEncoder(categories=categories)\n\nencoded_train_X[['KitchenQual']] = encoder_kitchenQu.fit_transform(train_X[['KitchenQual']])\nencoded_val_X[['KitchenQual']] = encoder_kitchenQu.transform(val_X[['KitchenQual']])","metadata":{"execution":{"iopub.status.busy":"2024-07-26T16:08:36.245575Z","iopub.execute_input":"2024-07-26T16:08:36.245986Z","iopub.status.idle":"2024-07-26T16:08:36.25725Z","shell.execute_reply.started":"2024-07-26T16:08:36.245954Z","shell.execute_reply":"2024-07-26T16:08:36.256224Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### FireplaceQu\nOur unique values are ['No' 'TA' 'Gd' 'Fa' 'Ex' 'Po']. This is similar to above and I will use **ordinal encoding**. The assigned values are: \n**Ex**: Excellent (5) > **Gd**: Good (4)> **TA**: Average (3) >  **Fa**: Fair (2) > **Po**: Poor (1) > **No**: No Fireplace (0) ","metadata":{}},{"cell_type":"code","source":"categories = [['No','Po','Fa', 'TA', 'Gd', 'Ex']] #In ascending order\n\nencoder_fireplaceQu = OrdinalEncoder(categories=categories)\n\nencoded_train_X[['FireplaceQu']] = encoder_fireplaceQu.fit_transform(train_X[['FireplaceQu']])\nencoded_val_X[['FireplaceQu']] = encoder_fireplaceQu.transform(val_X[['FireplaceQu']])","metadata":{"execution":{"iopub.status.busy":"2024-07-26T16:08:47.428555Z","iopub.execute_input":"2024-07-26T16:08:47.428949Z","iopub.status.idle":"2024-07-26T16:08:47.440083Z","shell.execute_reply.started":"2024-07-26T16:08:47.428917Z","shell.execute_reply":"2024-07-26T16:08:47.43869Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### HeatingQC\nOur unique values are ['TA' 'Gd' 'Fa' 'Ex' 'Po']. Again, this is similar to above and I will use **ordinal encoding**. The assigned values are: \n**Ex**: Excellent (5) > **Gd**: Good (4)> **TA**: Average (3) >  **Fa**: Fair (2) > **Po**: Poor (1) ","metadata":{}},{"cell_type":"code","source":"categories = [['Po','Fa', 'TA', 'Gd', 'Ex']] #In ascending order\n\nencoder_heatingQu = OrdinalEncoder(categories=categories)\n\nencoded_train_X[['HeatingQC']] = encoder_heatingQu.fit_transform(train_X[['HeatingQC']])\nencoded_val_X[['HeatingQC']] = encoder_heatingQu.transform(val_X[['HeatingQC']])","metadata":{"execution":{"iopub.status.busy":"2024-07-26T16:08:49.137239Z","iopub.execute_input":"2024-07-26T16:08:49.137743Z","iopub.status.idle":"2024-07-26T16:08:49.148441Z","shell.execute_reply.started":"2024-07-26T16:08:49.137709Z","shell.execute_reply":"2024-07-26T16:08:49.147114Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### CentralAir\nOur unique values are ['Y' 'N']. These do not have an inherit ordering. So I will use **OneHot encoding**","metadata":{}},{"cell_type":"code","source":"OH_encoder = OneHotEncoder(handle_unknown='ignore', sparse=False)\n\nOH_cols_train = pd.DataFrame(OH_encoder.fit_transform(train_X[['CentralAir']]), columns=OH_encoder.get_feature_names_out(['CentralAir']))\nOH_cols_valid = pd.DataFrame(OH_encoder.transform(val_X[['CentralAir']]), columns=OH_encoder.get_feature_names_out(['CentralAir']))\n\n# Put index back and remove CentralAir column\nOH_cols_train.index = train_X.index\nOH_cols_valid.index = val_X.index\nnum_X_train = encoded_train_X.drop(['CentralAir'], axis=1)\nnum_X_valid = encoded_val_X.drop(['CentralAir'], axis=1)\n\nencoded_train_X = pd.concat([num_X_train, OH_cols_train], axis=1)\nencoded_val_X = pd.concat([num_X_valid, OH_cols_valid], axis=1)","metadata":{"execution":{"iopub.status.busy":"2024-07-26T16:08:51.169374Z","iopub.execute_input":"2024-07-26T16:08:51.170333Z","iopub.status.idle":"2024-07-26T16:08:51.186395Z","shell.execute_reply.started":"2024-07-26T16:08:51.170281Z","shell.execute_reply":"2024-07-26T16:08:51.185239Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"encoded_train_X[['CentralAir_N','CentralAir_Y']].head()","metadata":{"execution":{"iopub.status.busy":"2024-07-26T16:08:53.371693Z","iopub.execute_input":"2024-07-26T16:08:53.372087Z","iopub.status.idle":"2024-07-26T16:08:53.384497Z","shell.execute_reply.started":"2024-07-26T16:08:53.372055Z","shell.execute_reply":"2024-07-26T16:08:53.38334Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Neighborhood\nThere are a lot of unique values for this so OneHot encoding might be impractical. But there is no obvious assumed ordering either. I will just explore this feature a little bit more and try to understand it","metadata":{}},{"cell_type":"code","source":"neighborhood_price = train_data.groupby('Neighborhood')['SalePrice'].mean().sort_values(ascending=False)\nneighborhood_order = neighborhood_price.index\n\nplt.figure(figsize=(15, 8))\nsns.boxplot(x='Neighborhood', y='SalePrice', data=train_data, palette='coolwarm', order=neighborhood_order)\nplt.xticks(rotation=90)\nplt.xlabel('')\nplt.title('Distribution of Sale Price by Neighborhood')\n\nplt.figure(figsize=(15, 8))\nsns.barplot(x=neighborhood_price.index, y=neighborhood_price.values, palette='coolwarm')\nplt.xticks(rotation=90)\nplt.ylabel('Average Sale Price')\nplt.title('Average Sale Price by Neighborhood')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-07-26T16:08:55.285359Z","iopub.execute_input":"2024-07-26T16:08:55.285765Z","iopub.status.idle":"2024-07-26T16:08:56.399395Z","shell.execute_reply.started":"2024-07-26T16:08:55.285731Z","shell.execute_reply":"2024-07-26T16:08:56.398306Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"I want to see if it is worth keeping this column. I will run an **ANOVA** (Analysis of Variance) test to see the statistical significance of the neighborhood on the sale price. \n- **F-statistic**:\n    - The F-statistic measures how much the means of different groups (in your case, different neighborhoods) differ relative to the variance within each group.\n    - A high F-statistic suggests that there is more variability between the groups than within the groups, indicating that the group means are different.\n- **p-value**: \n    - The p-value indicates the probability of observing the data, or something more extreme, assuming the null hypothesis (no effect) is true.\n    - A very low p-value (typically less than 0.05) indicates strong evidence against the null hypothesis.","metadata":{}},{"cell_type":"code","source":"F_stat, p_value = stats.f_oneway(*[train_data[train_data['Neighborhood'] == neighborhood]['SalePrice'] for neighborhood in train_data['Neighborhood'].unique()])\nprint(f\"F-statistic: {F_stat}\")\nprint(f\"p-value: {p_value}\")","metadata":{"execution":{"iopub.status.busy":"2024-07-26T16:08:59.767961Z","iopub.execute_input":"2024-07-26T16:08:59.769074Z","iopub.status.idle":"2024-07-26T16:08:59.801124Z","shell.execute_reply.started":"2024-07-26T16:08:59.769033Z","shell.execute_reply":"2024-07-26T16:08:59.800025Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The results of the ANOVA test indicate that there are statistically significant differences in SalePrice between the different neighborhoods. This suggests that the Neighborhood feature has a significant impact on SalePrice, and it is worth keeping this feature in the model. Considering this, I will use target encoding (also known as mean encoding) for this variable. \n\n**Target Encoding**\n-  This method replaces each category with the mean of the target variable (SalePrice in our case) for that category. It’s particularly useful for categorical features with many unique values. ","metadata":{}},{"cell_type":"code","source":"target_encoder = ce.TargetEncoder(cols=['Neighborhood'])\n\nencoded_train_X['Neighborhood'] = target_encoder.fit_transform(train_X['Neighborhood'], train_y)\nencoded_val_X['Neighborhood'] = target_encoder.transform(val_X['Neighborhood'])","metadata":{"execution":{"iopub.status.busy":"2024-07-26T16:09:04.95731Z","iopub.execute_input":"2024-07-26T16:09:04.957693Z","iopub.status.idle":"2024-07-26T16:09:04.984005Z","shell.execute_reply.started":"2024-07-26T16:09:04.957661Z","shell.execute_reply":"2024-07-26T16:09:04.982885Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### View The Encoded Table","metadata":{}},{"cell_type":"code","source":"# Compare encoded_train_X and train_X\ncat_features2 = ['KitchenQual', 'FireplaceQu', 'HeatingQC', 'Neighborhood', 'CentralAir_N','CentralAir_Y']\ndisplay(HTML(f\"\"\"<table><tr><td>{encoded_train_X[cat_features2].head(10).to_html()}</td><td>{train_X[cat_features].head(10).to_html()}</td></tr></table>\"\"\"))","metadata":{"execution":{"iopub.status.busy":"2024-07-26T16:09:07.454005Z","iopub.execute_input":"2024-07-26T16:09:07.455089Z","iopub.status.idle":"2024-07-26T16:09:07.472704Z","shell.execute_reply.started":"2024-07-26T16:09:07.455053Z","shell.execute_reply":"2024-07-26T16:09:07.471304Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# List unique values for previously categorical features\nfor feature in cat_features2:\n    print(f\"{feature}: {encoded_train_X[feature].unique()}\")","metadata":{"execution":{"iopub.status.busy":"2024-07-26T16:09:10.652207Z","iopub.execute_input":"2024-07-26T16:09:10.652643Z","iopub.status.idle":"2024-07-26T16:09:10.660853Z","shell.execute_reply.started":"2024-07-26T16:09:10.652613Z","shell.execute_reply":"2024-07-26T16:09:10.659638Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Define Model\nI will be using a random forest regressor as my model.","metadata":{}},{"cell_type":"code","source":"rf_model = RandomForestRegressor(n_estimators=100, random_state=1)\n\nrf_model.fit(encoded_train_X, train_y)\nrf_val_predictions = rf_model.predict(encoded_val_X)","metadata":{"execution":{"iopub.status.busy":"2024-07-26T16:09:51.476771Z","iopub.execute_input":"2024-07-26T16:09:51.477148Z","iopub.status.idle":"2024-07-26T16:09:52.626278Z","shell.execute_reply.started":"2024-07-26T16:09:51.477117Z","shell.execute_reply":"2024-07-26T16:09:52.625181Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Evaluate model ","metadata":{}},{"cell_type":"code","source":"min_price = train_data['SalePrice'].min()\nmax_price = train_data['SalePrice'].max()\nprint(f\"Minimum SalePrice: {min_price}\")\nprint(f\"Maximum SalePrice: {max_price}\")","metadata":{"execution":{"iopub.status.busy":"2024-07-26T15:54:02.721294Z","iopub.execute_input":"2024-07-26T15:54:02.721673Z","iopub.status.idle":"2024-07-26T15:54:02.728072Z","shell.execute_reply.started":"2024-07-26T15:54:02.721642Z","shell.execute_reply":"2024-07-26T15:54:02.726868Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The SalePrice of a house is between \\\\$34,900 and $755,000\n\nHow I will measure accuracy:\n- **Mean Absolute Error** (MAE): Is the average of the absolute differences between the predicted values and the actual values. It indicates the average magnitude of errors in your predictions. Lower is better.\n- **Root Mean Squared Error** (RMSE): Is the square root of MSE and provides a measure of the average magnitude of the errors. It can be easier to understand and communicate  than MSE because it gives a sense of the average magnitude of the errors.\n- **R² Score** (R-Squared): (coefficient of determination) Shows the proportion of variance explained by the model. A value close to 1 indicates a good fit.\n\nNote that this competition is judged on MSE","metadata":{}},{"cell_type":"code","source":"rf_val_mae = mean_absolute_error(rf_val_predictions, val_y)\nfr_val_mse = mean_squared_error(val_y, rf_val_predictions)\nrf_val_rmse = np.sqrt(fr_val_mse)\nrf_val_r2 = r2_score(val_y, rf_val_predictions)\n\nprint(\"Mean Absolute Error: {:,.0f}\".format(rf_val_mae))\nprint(f'Root Mean Squared Error (RMSE): {rf_val_rmse}')\nprint(f\"R^2 Score: {rf_val_r2}\")","metadata":{"execution":{"iopub.status.busy":"2024-07-26T16:10:34.136181Z","iopub.execute_input":"2024-07-26T16:10:34.136884Z","iopub.status.idle":"2024-07-26T16:10:34.145111Z","shell.execute_reply.started":"2024-07-26T16:10:34.136847Z","shell.execute_reply":"2024-07-26T16:10:34.144067Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Mean Absolute Error** \n- On average, the model’s predictions are off by \\\\$15,166 from the actual values \n- Considering the sale prices range from \\\\$34,900 to \\$755,000, the MAE represents roughly 2.5% to 43% of the sale price. This suggests that while the model's average error is significant, it is reasonably small relative to the total price range.\n\n**Root Mean Squared Error** \n- On average, the model’s predictions are off by approximately $22,479.03 \n- \\\\$22,479.03 is approximately 3% to 64% of the sale price, depending on the house's actual sale price. This means the average error is substantial, but considering the wide range of sale prices, it reflects the model's performance with respect to varying house values.\n\n**R² Score**\n- Approximately 92.9% of the variance in the target variable can be explained by the model. This is a high R² value, suggesting that the model fits the data very well and explains a significant portion of the variance in the target variable.\n\nThese values are pretty good!! I want to visualize the accuracy of the model \n\n### Visualize model\nIn an ideal scenario, the points would be close to a 45-degree line (line of equality) where Actual Sale Price equals Predicted Sale Price.","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(10, 6))\nplt.scatter(val_y, rf_val_predictions, alpha=0.5, color = cmap(0.9))\nplt.xlabel('Actual Sale Price')\nplt.ylabel('Predicted Sale Price')\nplt.title('Actual vs. Predicted Sale Price: Model 1 (Random Forest Regressor)')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-07-26T16:10:39.176811Z","iopub.execute_input":"2024-07-26T16:10:39.177222Z","iopub.status.idle":"2024-07-26T16:10:39.422638Z","shell.execute_reply.started":"2024-07-26T16:10:39.177185Z","shell.execute_reply":"2024-07-26T16:10:39.421484Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"This model is pretty good. It appears to somewhat resemble a 45 degree line. I am now going to make some improvements.\n\n# Cross Validation\nCross-validation splits the data into multiple training and validation sets to evaluate the model’s performance and robustness. It averages the results to provide a more reliable measure of how well the model generalizes to unseen data.\n\nSteps:\n1. **GridSearchCV Initialization:**\n    - Set up GridSearchCV to optimize for MSE ('neg_mean_squared_error').\n2. **Model Fitting:**\n    - Train the model with the grid search on the training data.\n3. **Best Parameters and Score:**\n    - Print the best parameters and MSE score.\n4. **Model Evaluation:**\n    - Use the best best model from the grid search to make predictions on the validation set, and calculate MSE.","metadata":{}},{"cell_type":"code","source":"#1\nmodel = RandomForestRegressor(random_state=1)\n\nparam_grid = {\n    'n_estimators': [100, 200, 300],\n    'max_depth': [None, 10, 20, 30],\n    'min_samples_split': [2, 5, 10]\n}\n\ngrid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=5, scoring='neg_mean_squared_error')\n#2\ngrid_search.fit(encoded_train_X, train_y)\n\n#3\nprint(f\"Best parameters: {grid_search.best_params_}\")\nprint(f\"Best score (MSE): {-grid_search.best_score_}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-07-26T16:12:12.375745Z","iopub.execute_input":"2024-07-26T16:12:12.376144Z","iopub.status.idle":"2024-07-26T16:16:57.683552Z","shell.execute_reply.started":"2024-07-26T16:12:12.376115Z","shell.execute_reply":"2024-07-26T16:16:57.682444Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#4\nbest_model = grid_search.best_estimator_\ncross_val_predictions = best_model.predict(encoded_val_X)\n\ncross_mae = mean_absolute_error(cross_val_predictions, val_y)\ncross_mse = mean_squared_error(val_y, cross_val_predictions)\ncross_rmse = np.sqrt(cross_mse)\ncross_r2 = r2_score(val_y, cross_val_predictions)\n\nprint(\"Mean Absolute Error: {:,.0f}\".format(cross_mae))\nprint(f'Root Mean Squared Error (RMSE): {cross_rmse}')\nprint(f\"R^2 Score: {cross_r2}\")","metadata":{"execution":{"iopub.status.busy":"2024-07-26T16:19:50.44073Z","iopub.execute_input":"2024-07-26T16:19:50.44114Z","iopub.status.idle":"2024-07-26T16:19:50.46196Z","shell.execute_reply.started":"2024-07-26T16:19:50.441109Z","shell.execute_reply":"2024-07-26T16:19:50.460927Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Mean Absolute Error** \n- On average, the model’s predictions are off by \\\\$15,376 from the actual values \n\n**Root Mean Squared Error** \n- On average, the model’s predictions are off by approximately $22,976.88\n\n**R² Score**\n- Approximately 92.6% of the variance in the target variable can be explained by the model.\n\nAlthough some of these values are slightly worse than what we had before, this is ok because these parameters are set to predict the overall data better. Not just this validation set. \n\n### Visual Representation of Model","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(10, 6))\nplt.scatter(val_y, cross_val_predictions, alpha=0.5, color = cmap(0.7))\nplt.xlabel('Actual Sale Price')\nplt.ylabel('Predicted Sale Price')\nplt.title('Actual vs. Predicted Sale Price: Model 2 (Cross-Validation)')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-07-26T16:19:53.315523Z","iopub.execute_input":"2024-07-26T16:19:53.316459Z","iopub.status.idle":"2024-07-26T16:19:53.553018Z","shell.execute_reply.started":"2024-07-26T16:19:53.316425Z","shell.execute_reply":"2024-07-26T16:19:53.551989Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"This is good too! But I want to make a furhter improvement.\n\n# XGBoost (with Cross-Validation)\nXGBoost builds a series of decision trees sequentially, where each tree corrects the errors of the previous ones. It uses gradient boosting techniques and regularization to improve accuracy and prevent overfitting.","metadata":{}},{"cell_type":"code","source":"xgb_model = xgb.XGBRegressor(random_state=1)","metadata":{"execution":{"iopub.status.busy":"2024-07-26T16:20:02.120037Z","iopub.execute_input":"2024-07-26T16:20:02.121025Z","iopub.status.idle":"2024-07-26T16:20:02.126046Z","shell.execute_reply.started":"2024-07-26T16:20:02.120986Z","shell.execute_reply":"2024-07-26T16:20:02.124709Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"param_grid = {\n    'n_estimators': [100, 200, 300],\n    'max_depth': [3, 6, 10],\n    'learning_rate': [0.01, 0.1, 0.2],\n    'subsample': [0.8, 1.0]\n}\n\ngrid_search_xgb = GridSearchCV(estimator=xgb_model, param_grid=param_grid, cv=5, scoring='neg_mean_squared_error')\n\ngrid_search_xgb.fit(encoded_train_X, train_y)\n\nprint(f\"Best parameters for MSE: {grid_search_xgb.best_params_}\")\nprint(f\"Best score (MSE): {-grid_search_xgb.best_score_}\")","metadata":{"execution":{"iopub.status.busy":"2024-07-26T16:20:52.958012Z","iopub.execute_input":"2024-07-26T16:20:52.958992Z","iopub.status.idle":"2024-07-26T16:23:33.522179Z","shell.execute_reply.started":"2024-07-26T16:20:52.958951Z","shell.execute_reply":"2024-07-26T16:23:33.52096Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"best_xgb_model = grid_search_xgb.best_estimator_\nxgb_val_predictions = best_xgb_model.predict(encoded_val_X)\n\nxgb_mae = mean_absolute_error(xgb_val_predictions, val_y)\nxgb_mse = mean_squared_error(val_y, xgb_val_predictions)\nxgb_rmse = np.sqrt(xgb_mse)\nxgb_r2 = r2_score(val_y, xgb_val_predictions)\n\nprint(\"Mean Absolute Error: {:,.0f}\".format(xgb_mae))\nprint(f'Root Mean Squared Error (RMSE): {xgb_rmse}')\nprint(f\"R^2 Score: {xgb_r2}\")","metadata":{"execution":{"iopub.status.busy":"2024-07-26T16:26:18.975663Z","iopub.execute_input":"2024-07-26T16:26:18.976037Z","iopub.status.idle":"2024-07-26T16:26:18.994521Z","shell.execute_reply.started":"2024-07-26T16:26:18.976008Z","shell.execute_reply":"2024-07-26T16:26:18.993229Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Mean Absolute Error** \n- On average, the model’s predictions are off by \\\\$14,872 from the actual values \n\n**Root Mean Squared Error** \n- On average, the model’s predictions are off by approximately $22,964.39\n\n**R² Score**\n- Approximately 92.6% of the variance in the target variable can be explained by the model.\n\n### Visual Representation of Model","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(10, 6))\nplt.scatter(val_y, xgb_val_predictions, alpha=0.5, color = cmap(0.1))\nplt.xlabel('Actual Sale Price')\nplt.ylabel('Predicted Sale Price')\nplt.title('Actual vs. Predicted Sale Price: Model 3 (XGB + Cross-Validation)')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-07-26T14:58:25.851872Z","iopub.execute_input":"2024-07-26T14:58:25.856561Z","iopub.status.idle":"2024-07-26T14:58:26.201073Z","shell.execute_reply.started":"2024-07-26T14:58:25.856507Z","shell.execute_reply":"2024-07-26T14:58:26.199814Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model for Competition Submission\n### Preprocessing\nI will create a dataset called **test_data** that is a copy of train_data. Note that train_data has already been preprocessed in terms of dealing with NA values, and dealing with skewed data.\n\nI am going to repeat the encoding steps from above. Recall that:\n- *encoder_kitchenQu, encoder_fireplaceQu, encoder_heatingQu* are the ordinal encoders from above\n- *OH_encoder* is the onehot encoder from above\n- *target_encoder* is the target encoder from above","metadata":{}},{"cell_type":"code","source":"# 1. Set up the test data\ntest_data = train_data.copy()\nencoded_test_data = test_data.copy()\n\n# 2. Ordinal Encoding KitchenQual, FireplaceQu, HeatingQc\nencoded_test_data[['KitchenQual']] = encoder_kitchenQu.transform(test_data[['KitchenQual']])\nencoded_test_data[['FireplaceQu']] = encoder_fireplaceQu.transform(test_data[['FireplaceQu']])\nencoded_test_data[['HeatingQC']] = encoder_heatingQu.transform(test_data[['HeatingQC']])\n\n# 3. One-hot Encoding for CentralAir\nOH_cols_test = pd.DataFrame(OH_encoder.transform(test_data[['CentralAir']]), columns=OH_encoder.get_feature_names_out(['CentralAir']))\nOH_cols_test.index = test_data.index\nnum_X_test = encoded_test_data.drop(['CentralAir'], axis=1)\nencoded_test_data = pd.concat([num_X_test, OH_cols_test], axis=1)\n\n# v. Target encoding for Neighborhood\nencoded_test_data['Neighborhood'] = target_encoder.transform(test_data['Neighborhood'])","metadata":{"execution":{"iopub.status.busy":"2024-07-26T16:26:38.626878Z","iopub.execute_input":"2024-07-26T16:26:38.627428Z","iopub.status.idle":"2024-07-26T16:26:38.654026Z","shell.execute_reply.started":"2024-07-26T16:26:38.627387Z","shell.execute_reply":"2024-07-26T16:26:38.652786Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"encoded_test_data[cat_features2]","metadata":{"execution":{"iopub.status.busy":"2024-07-26T16:34:26.930948Z","iopub.execute_input":"2024-07-26T16:34:26.931648Z","iopub.status.idle":"2024-07-26T16:34:26.960568Z","shell.execute_reply.started":"2024-07-26T16:34:26.931604Z","shell.execute_reply":"2024-07-26T16:34:26.959359Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Get Predictions","metadata":{}},{"cell_type":"code","source":"final_features = ['OverallQual', 'OverallCond', 'YearBuilt', 'YearRemodAdd', 'GrLivArea',\n                  'TotalBsmtSF', '1stFlrSF', '2ndFlrSF', 'GarageCars', 'GarageArea',\n                  'FullBath', 'HalfBath', 'KitchenQual', 'TotRmsAbvGrd', 'Fireplaces',\n                  'FireplaceQu', 'GarageYrBlt', 'LotArea', 'Neighborhood', 'BsmtFinSF1',\n                  'BsmtFinSF2', 'BsmtUnfSF', 'HeatingQC', 'BedroomAbvGr', 'CentralAir_N',\n                  'CentralAir_Y']\n\ntest_X = encoded_test_data[final_features]\ntest_y = encoded_test_data.SalePrice\n\n# Use Model 3: XGB model to create predictions\npredictions = best_xgb_model.predict(test_X)","metadata":{"execution":{"iopub.status.busy":"2024-07-26T16:35:22.504694Z","iopub.execute_input":"2024-07-26T16:35:22.505128Z","iopub.status.idle":"2024-07-26T16:35:22.52043Z","shell.execute_reply.started":"2024-07-26T16:35:22.505092Z","shell.execute_reply":"2024-07-26T16:35:22.5194Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Evaluate Predictions","metadata":{}},{"cell_type":"code","source":"xgb_mae = mean_absolute_error(test_y, predictions)\nxgb_mse = mean_squared_error(test_y, predictions)\nxgb_rmse = np.sqrt(xgb_mse)\nxgb_r2 = r2_score(test_y, predictions)\n\nprint(\"Mean Absolute Error: {:,.0f}\".format(xgb_mae))\nprint(f'Root Mean Squared Error (RMSE): {xgb_rmse}')\nprint(f\"R^2 Score: {xgb_r2}\")","metadata":{"execution":{"iopub.status.busy":"2024-07-26T16:37:16.173404Z","iopub.execute_input":"2024-07-26T16:37:16.173811Z","iopub.status.idle":"2024-07-26T16:37:16.183378Z","shell.execute_reply.started":"2024-07-26T16:37:16.173779Z","shell.execute_reply":"2024-07-26T16:37:16.182229Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Visualize Model","metadata":{}},{"cell_type":"code","source":"# Visualization: Actual vs. Predicted Sale Price\nplt.figure(figsize=(10, 6))\nplt.scatter(test_y, predictions, alpha=0.5, color = cmap(0.3))  # Adjust color as needed\nplt.xlabel('Actual Sale Price')\nplt.ylabel('Predicted Sale Price')\nplt.title('Actual vs. Predicted Sale Price: Competition Model')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-07-26T16:37:53.095416Z","iopub.execute_input":"2024-07-26T16:37:53.095816Z","iopub.status.idle":"2024-07-26T16:37:53.386582Z","shell.execute_reply.started":"2024-07-26T16:37:53.095784Z","shell.execute_reply":"2024-07-26T16:37:53.385508Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Create Submission File","metadata":{}},{"cell_type":"code","source":"submission = pd.DataFrame({'Id': test_data['Id'],\n                           'SalePrice': predictions})\n\nsubmission.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2024-07-26T16:38:16.933988Z","iopub.execute_input":"2024-07-26T16:38:16.934983Z","iopub.status.idle":"2024-07-26T16:38:16.946101Z","shell.execute_reply.started":"2024-07-26T16:38:16.934943Z","shell.execute_reply":"2024-07-26T16:38:16.944926Z"},"trusted":true},"execution_count":null,"outputs":[]}]}