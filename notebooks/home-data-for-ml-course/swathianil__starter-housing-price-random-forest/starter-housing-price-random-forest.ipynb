{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"![alt text for screen readers](https://thumbs.dreamstime.com/b/outline-ames-iowa-skyline-white-buildings-vector-illustration-business-travel-tourism-concept-historic-architecture-203382169.jpg \"Credits: dreamstime.com\")\n\n<span style=\"color:PaleVioletRed;font-weight:600;font-size:50px;font-family:monotype;\">\n    Housing Prices Competition: Ames Housing dataset \n</span>\n    \n\n\n        \n\n    This is a tutorial for beginners to work through the Housing Prices Competition for Kaggle Learn Users [Competition](https://www.kaggle.com/competitions/home-data-for-ml-course/)\n    \n    Here is a short problem description:\n    \"With 79 explanatory variables describing (almost) every aspect of residential homes in Ames, Iowa, this competition challenges you to predict the final price of each home.\"\n    The task is to predict the selling price of a home based on a dataset describing exisiting homes, and their features and the final price.\n    \n    In this kernel, we will work through the kaggle dataset Ames Housing to understand basic concepts of a Random forest Regressor.\n    \n    Hope you enjoy the kernel! ","metadata":{"execution":{"iopub.status.busy":"2022-10-16T11:18:33.736507Z","iopub.execute_input":"2022-10-16T11:18:33.736927Z","iopub.status.idle":"2022-10-16T11:18:33.75413Z","shell.execute_reply.started":"2022-10-16T11:18:33.736889Z","shell.execute_reply":"2022-10-16T11:18:33.752749Z"}}},{"cell_type":"markdown","source":"<span style=\"color:grey;font-weight:500;font-size:20px;font-style:serif\">\n<span style=\"color:pink;font-weight:600;font-size:30px;font-style:serif\">\n    Objective\n</span>\n\nPredict the selling price of a home based on a dataset describing exisiting homes, and their features and the final price\n\n<span style=\"color:pink;font-weight:600;font-size:30px;font-style:serif\">\n    File description\n</span>\n    \n- **Starter: Housing Price prediction | Random Forest.ipynb:** Tutorial and steps to load, wrangle the data, apply logistic regression classifier and test model performance.\n- **home-data-for-ml-course:** data file consisiting of the Ames Housing dataset\n- **data_description.txt:** full description of each column, originally prepared by Dean De Cock but lightly edited to match the column names used here\n\n<span style=\"color:pink;font-weight:600;font-size:30px;font-style:serif\">\n   Data description\n</span> \n \n Tabular data consisting of 1460 entries, each with 81 attributes, including 'SalePrice', which would be the target for prediction \n \n<span style=\"color:pink;font-weight:600;font-size:20px;font-style:serif\">\n    Attribute information\n</span>\n    \n        SalePrice: The property's sale price in dollars. This is the target variable that you're trying to predict    \n        MSSubClass: The building class    \n        MSZoning: The general zoning classification    \n        LotFrontage: Linear feet of street connected to property    \n        LotArea: Lot size in square feet    \n        Street: Type of road access    \n        Alley: Type of alley access    \n        LotShape: General shape of property    \n        LandContour: Flatness of the property    \n        Utilities: Type of utilities available    \n        LotConfig: Lot configuration    \n        LandSlope: Slope of property    \n        Neighborhood: Physical locations within Ames city limits    \n        Condition1: Proximity to main road or railroad    \n        Condition2: Proximity to main road or railroad (if a second is present)    \n        BldgType: Type of dwelling    \n        HouseStyle: Style of dwelling    \n        OverallQual: Overall material and finish quality    \n        OverallCond: Overall condition rating    \n        YearBuilt: Original construction date    \n        YearRemodAdd: Remodel date    \n        RoofStyle: Type of roof    \n        RoofMatl: Roof material    \n        Exterior1st: Exterior covering on house    \n        Exterior2nd: Exterior covering on house (if more than one material)    \n        MasVnrType: Masonry veneer type    \n        MasVnrArea: Masonry veneer area in square feet    \n        ExterQual: Exterior material quality    \n        ExterCond: Present condition of the material on the exterior   \n        Foundation: Type of foundation    \n        BsmtQual: Height of the basement    \n        BsmtCond: General condition of the basement    \n        BsmtExposure: Walkout or garden level basement walls    \n        BsmtFinType1: Quality of basement finished area    \n        BsmtFinSF1: Type 1 finished square feet    \n        BsmtFinType2: Quality of second finished area (if present)    \n        BsmtFinSF2: Type 2 finished square feet    \n        BsmtUnfSF: Unfinished square feet of basement area    \n        TotalBsmtSF: Total square feet of basement area    \n        Heating: Type of heating    \n        HeatingQC: Heating quality and condition    \n        CentralAir: Central air conditioning    \n        Electrical: Electrical system    \n        1stFlrSF: First Floor square feet    \n        2ndFlrSF: Second floor square feet\n        LowQualFinSF: Low quality finished square feet (all floors)\n        GrLivArea: Above grade (ground) living area square feet\n        BsmtFullBath: Basement full bathrooms\n        BsmtHalfBath: Basement half bathrooms\n        FullBath: Full bathrooms above grade\n        HalfBath: Half baths above grade\n        Bedroom: Number of bedrooms above basement level\n        Kitchen: Number of kitchens\n        KitchenQual: Kitchen quality\n        TotRmsAbvGrd: Total rooms above grade (does not include bathrooms)\n        Functional: Home functionality rating\n        Fireplaces: Number of fireplaces\n        FireplaceQu: Fireplace quality\n        GarageType: Garage location\n        GarageYrBlt: Year garage was built\n        GarageFinish: Interior finish of the garage\n        GarageCars: Size of garage in car capacity\n        GarageArea: Size of garage in square feet\n        GarageQual: Garage quality\n        GarageCond: Garage condition\n        PavedDrive: Paved driveway\n        WoodDeckSF: Wood deck area in square feet\n        OpenPorchSF: Open porch area in square feet\n        EnclosedPorch: Enclosed porch area in square feet\n        3SsnPorch: Three season porch area in square feet\n        ScreenPorch: Screen porch area in square feet\n        PoolArea: Pool area in square feet\n        PoolQC: Pool quality\n        Fence: Fence quality\n        MiscFeature: Miscellaneous feature not covered in other categories\n        MiscVal: Value of miscellaneous feature\n        MoSold: Month Sold\n        YrSold: Year Sold\n        SaleType: Type of sale\n        SaleCondition: Condition of sale\n\n    \n    \n**Source:** The Ames Housing dataset was compiled by Dean De Cock for use in data science education. \n</span>\n","metadata":{"execution":{"iopub.status.busy":"2022-10-16T11:30:01.238697Z","iopub.execute_input":"2022-10-16T11:30:01.239089Z","iopub.status.idle":"2022-10-16T11:30:01.255842Z","shell.execute_reply.started":"2022-10-16T11:30:01.239055Z","shell.execute_reply":"2022-10-16T11:30:01.254499Z"}}},{"cell_type":"markdown","source":"<a id='21'>\n</a>\n<span style=\"color:pink;font-weight:600;font-size:30px;font-style:serif\">\n   Data Analysis Content\n</span>\n<span style=\"font-weight:600;font-size:20px;font-style:serif\">\n    \n1. [Import Dependencies](#1)\n1. [Load Data](#2)\n1. [Data preprocessing](#2b)\n    1. [Remove null values](#3)\n    1. [Remove highly correlated features](#4) \n    1. [Feature engineering](#5)\n    1. [Split dataset](#6)\n    1. [One hot encode](#7)\n    1. [Feature scaling](#8)\n1. [ Random Forest Regressor](#9)\n    1. [Performance Evaluation](#10)\n    1. [Train model on all data](#11)\n1. [Load raw data for prediction](#12)\n1. [Test-data preprocessing](#13)\n    1. [Feature match with training data](#14) \n    1. [Feature engineering](#15)\n    1. [Replace null values](#16)\n    1. [One hot encode](#17)\n    1. [Feature scaling](#18)\n1. [Data prediction on test data](#19)\n1. [Generate submission](#20)\n","metadata":{}},{"cell_type":"markdown","source":"<a id='1'></a>\n<span style=\"color:pink;font-weight:600;font-size:25px;font-style:serif\">\n    Import Dependencies\n</span>\n\n<span style=\"color:grey;font-weight:500;font-size:20px;font-style:serif\">\n    First we will import our helper modules that we will use throughout this kernel\n</span>\n","metadata":{"execution":{"iopub.status.busy":"2022-10-16T11:48:52.239308Z","iopub.execute_input":"2022-10-16T11:48:52.239744Z","iopub.status.idle":"2022-10-16T11:48:52.24863Z","shell.execute_reply.started":"2022-10-16T11:48:52.239705Z","shell.execute_reply":"2022-10-16T11:48:52.246608Z"}}},{"cell_type":"code","source":"# Import helpful libraries\nimport pandas as pd\nimport numpy as np\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler \nfrom sklearn.decomposition import PCA\nfrom sklearn.cluster import k_means","metadata":{"execution":{"iopub.status.busy":"2022-10-17T08:57:27.565774Z","iopub.execute_input":"2022-10-17T08:57:27.566253Z","iopub.status.idle":"2022-10-17T08:57:28.482062Z","shell.execute_reply.started":"2022-10-17T08:57:27.56616Z","shell.execute_reply":"2022-10-17T08:57:28.480855Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id='2'></a>\n<span style=\"color:pink;font-weight:600;font-size:25px;font-style:serif\">\n    Load Data\n</span>\n","metadata":{}},{"cell_type":"code","source":"# Load the data, and separate the target\niowa_file_path = '../input/train.csv'\ndf = pd.read_csv(iowa_file_path)\n\n\npd.options.display.max_rows = 20","metadata":{"execution":{"iopub.status.busy":"2022-10-17T08:57:28.484636Z","iopub.execute_input":"2022-10-17T08:57:28.485151Z","iopub.status.idle":"2022-10-17T08:57:28.532392Z","shell.execute_reply.started":"2022-10-17T08:57:28.485106Z","shell.execute_reply":"2022-10-17T08:57:28.531047Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.columns","metadata":{"execution":{"iopub.status.busy":"2022-10-17T08:57:28.534531Z","iopub.execute_input":"2022-10-17T08:57:28.535044Z","iopub.status.idle":"2022-10-17T08:57:28.545381Z","shell.execute_reply.started":"2022-10-17T08:57:28.534998Z","shell.execute_reply":"2022-10-17T08:57:28.544542Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id='2b'></a>\n<span style=\"color:pink;font-weight:600;font-size:25px;font-style:serif\">\n    Data preprocessing\n</span>\n","metadata":{}},{"cell_type":"code","source":"# Split dataset into independent & dependent datasets\nX = df.drop('SalePrice', axis=1)\ny = df.SalePrice","metadata":{"execution":{"iopub.status.busy":"2022-10-17T08:57:28.547531Z","iopub.execute_input":"2022-10-17T08:57:28.548661Z","iopub.status.idle":"2022-10-17T08:57:28.57123Z","shell.execute_reply.started":"2022-10-17T08:57:28.548612Z","shell.execute_reply":"2022-10-17T08:57:28.56918Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id='3'></a>\n<span style=\"color:pink;font-weight:600;font-size:20px;font-style:serif\">\n    Remove null values\n</span>\n","metadata":{"execution":{"iopub.status.busy":"2022-10-16T11:55:17.92671Z","iopub.execute_input":"2022-10-16T11:55:17.928077Z","iopub.status.idle":"2022-10-16T11:55:17.935844Z","shell.execute_reply.started":"2022-10-16T11:55:17.928026Z","shell.execute_reply":"2022-10-16T11:55:17.934174Z"}}},{"cell_type":"code","source":"# Detect null values\nX.isna().sum()","metadata":{"execution":{"iopub.status.busy":"2022-10-17T08:57:28.572809Z","iopub.execute_input":"2022-10-17T08:57:28.573236Z","iopub.status.idle":"2022-10-17T08:57:28.592675Z","shell.execute_reply.started":"2022-10-17T08:57:28.573181Z","shell.execute_reply":"2022-10-17T08:57:28.591645Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Drop null values\ndef nulldrop(df):\n    df.dropna(axis=1, inplace=True)\n    return df\n       \nX = nulldrop(X)\nX.isna().sum()","metadata":{"execution":{"iopub.status.busy":"2022-10-17T08:57:28.593869Z","iopub.execute_input":"2022-10-17T08:57:28.594914Z","iopub.status.idle":"2022-10-17T08:57:28.617646Z","shell.execute_reply.started":"2022-10-17T08:57:28.594879Z","shell.execute_reply":"2022-10-17T08:57:28.616573Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X.shape","metadata":{"execution":{"iopub.status.busy":"2022-10-17T08:57:28.619589Z","iopub.execute_input":"2022-10-17T08:57:28.619948Z","iopub.status.idle":"2022-10-17T08:57:28.627409Z","shell.execute_reply.started":"2022-10-17T08:57:28.619919Z","shell.execute_reply":"2022-10-17T08:57:28.625993Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id='4'></a>\n<span style=\"color:pink;font-weight:600;font-size:20px;font-style:serif\">\n    Remove highly correlated features\n</span>\n\n<span style=\"color:grey;font-weight:500;font-size:20px;font-style:serif\">\nHighly correlated features can lead to multicollinearity among independent variables. This can affect model performance. Hence, it is important to remove such features. \n</span>","metadata":{"execution":{"iopub.status.busy":"2022-10-16T16:43:53.838807Z","iopub.execute_input":"2022-10-16T16:43:53.839342Z","iopub.status.idle":"2022-10-16T16:43:53.84756Z","shell.execute_reply.started":"2022-10-16T16:43:53.839298Z","shell.execute_reply":"2022-10-16T16:43:53.846043Z"}}},{"cell_type":"code","source":"# removing highly correlated features to avoid multicolinearity\ndef corrdrop(df, maxcorr):\n    corr_matrix = df.corr().abs() \n    mask = np.triu(np.ones_like(corr_matrix, dtype = bool))\n    tri_df = corr_matrix.mask(mask)\n    to_drop = [x for x in tri_df.columns if any(tri_df[x] > maxcorr)]\n    df = df.drop(to_drop, axis = 1)\n    return df\n\nX = corrdrop(X, 0.95)\nprint(f\"The reduced dataframe has {X.shape[1]} columns.\")","metadata":{"execution":{"iopub.status.busy":"2022-10-17T08:57:28.628862Z","iopub.execute_input":"2022-10-17T08:57:28.629217Z","iopub.status.idle":"2022-10-17T08:57:28.660372Z","shell.execute_reply.started":"2022-10-17T08:57:28.629188Z","shell.execute_reply":"2022-10-17T08:57:28.659156Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Note down column names for later\ncorr_cols = X.columns","metadata":{"execution":{"iopub.status.busy":"2022-10-17T08:57:28.66232Z","iopub.execute_input":"2022-10-17T08:57:28.66268Z","iopub.status.idle":"2022-10-17T08:57:28.667871Z","shell.execute_reply.started":"2022-10-17T08:57:28.662636Z","shell.execute_reply":"2022-10-17T08:57:28.666555Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id='5'></a>\n<span style=\"color:pink;font-weight:600;font-size:20px;font-style:serif\">\n    Feature engineering\n</span>\n\n<span style=\"color:grey;font-weight:500;font-size:20px;font-style:serif\">\nHere, we will create new features from exisiting ones that would act as good indicators of the price of a house, for example, the total number of bathrooms a house has.\n</span>","metadata":{}},{"cell_type":"code","source":"def create_extra_features(df):    \n    df['TotBath'] = df['FullBath'] + (0.5* df['HalfBath']) + df['BsmtFullBath'] + (0.5*df['BsmtHalfBath'])    \n    df['Total_Home_Quality'] = df['OverallQual'] + df['OverallCond']\n    df[\"HighQualSF\"] = df[\"1stFlrSF\"] + df[\"2ndFlrSF\"]\n    return df\n\nX = create_extra_features(X)\nX.shape","metadata":{"execution":{"iopub.status.busy":"2022-10-17T08:57:28.671262Z","iopub.execute_input":"2022-10-17T08:57:28.671585Z","iopub.status.idle":"2022-10-17T08:57:28.689688Z","shell.execute_reply.started":"2022-10-17T08:57:28.671557Z","shell.execute_reply":"2022-10-17T08:57:28.68832Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X.head()","metadata":{"execution":{"iopub.status.busy":"2022-10-17T08:57:28.691281Z","iopub.execute_input":"2022-10-17T08:57:28.691653Z","iopub.status.idle":"2022-10-17T08:57:28.725149Z","shell.execute_reply.started":"2022-10-17T08:57:28.691621Z","shell.execute_reply":"2022-10-17T08:57:28.723979Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id='6'></a>\n<span style=\"color:pink;font-weight:600;font-size:20px;font-style:serif\">\n    Split dataset\n</span>\n\n<span style=\"color:grey;font-weight:500;font-size:20px;font-style:serif\">\n    We need data to build the model and then data to validate the model. For this purpose we split out dataset into a training set and a test set, respectively. So that we get the same split every time this notebook is run, we will set random_state as a fixed number. This is considered good practice.\n</span>","metadata":{}},{"cell_type":"code","source":"# Split into validation and training data\nX_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)","metadata":{"execution":{"iopub.status.busy":"2022-10-17T08:57:28.727516Z","iopub.execute_input":"2022-10-17T08:57:28.727857Z","iopub.status.idle":"2022-10-17T08:57:28.737292Z","shell.execute_reply.started":"2022-10-17T08:57:28.727826Z","shell.execute_reply":"2022-10-17T08:57:28.736013Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train.shape\nX_test.shape","metadata":{"execution":{"iopub.status.busy":"2022-10-17T08:57:28.739358Z","iopub.execute_input":"2022-10-17T08:57:28.739853Z","iopub.status.idle":"2022-10-17T08:57:28.753084Z","shell.execute_reply.started":"2022-10-17T08:57:28.739811Z","shell.execute_reply":"2022-10-17T08:57:28.751831Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id='7'></a>\n<span style=\"color:pink;font-weight:600;font-size:20px;font-style:serif\">\n    One hot encode\n</span>\n\n<span style=\"color:grey;font-weight:500;font-size:20px;font-style:serif\">\n    In order for a machine learning algorithm to work with your data, it is important that all values are entrerd in a numerical (machine-readable) form. We need to first explore the datatypes present in our dataset. get_dummies from pandas library is a great tool for one hot encoding the features of a tabular dataset, like ours.\n</span>\n","metadata":{}},{"cell_type":"code","source":"def onehotencode(df):\n    encoded = pd.get_dummies(df)\n    return encoded","metadata":{"execution":{"iopub.status.busy":"2022-10-17T08:57:28.756727Z","iopub.execute_input":"2022-10-17T08:57:28.757554Z","iopub.status.idle":"2022-10-17T08:57:28.765663Z","shell.execute_reply.started":"2022-10-17T08:57:28.757503Z","shell.execute_reply":"2022-10-17T08:57:28.764299Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train_encoded = onehotencode(X_train)\nX_train_encoded.shape","metadata":{"execution":{"iopub.status.busy":"2022-10-17T08:57:28.768087Z","iopub.execute_input":"2022-10-17T08:57:28.768559Z","iopub.status.idle":"2022-10-17T08:57:28.813746Z","shell.execute_reply.started":"2022-10-17T08:57:28.768517Z","shell.execute_reply":"2022-10-17T08:57:28.812553Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_test_encoded = onehotencode(X_test)\nX_test_encoded.shape","metadata":{"execution":{"iopub.status.busy":"2022-10-17T08:57:28.815529Z","iopub.execute_input":"2022-10-17T08:57:28.815877Z","iopub.status.idle":"2022-10-17T08:57:28.85191Z","shell.execute_reply.started":"2022-10-17T08:57:28.815849Z","shell.execute_reply":"2022-10-17T08:57:28.851066Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_train.shape\ny_test.shape","metadata":{"execution":{"iopub.status.busy":"2022-10-17T08:57:31.623447Z","iopub.execute_input":"2022-10-17T08:57:31.624404Z","iopub.status.idle":"2022-10-17T08:57:31.632446Z","shell.execute_reply.started":"2022-10-17T08:57:31.624346Z","shell.execute_reply":"2022-10-17T08:57:31.631185Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train_encoded_final , X_test_encoded_final = X_train_encoded.align(X_test_encoded, join='inner', axis=1) ","metadata":{"execution":{"iopub.status.busy":"2022-10-17T08:57:31.806904Z","iopub.execute_input":"2022-10-17T08:57:31.808268Z","iopub.status.idle":"2022-10-17T08:57:31.821715Z","shell.execute_reply.started":"2022-10-17T08:57:31.808217Z","shell.execute_reply":"2022-10-17T08:57:31.820509Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id='8'></a>\n<span style=\"color:pink;font-weight:600;font-size:20px;font-style:serif\">\n    Feature scaling\n</span>\n\n<span style=\"color:grey;font-weight:500;font-size:20px;font-style:serif\">\n    We need to bring our feature values within a comparable range, while still maintaining their independence. For this we will use the fit_transform method on the training dataset. This method learns about our data (mean and variance) and then uses this information to transform the data into a zero mean, unit variance range. We use the same information to tranform the test data, instead of learning the  test data as well, so that the model still is 'surprised' by the test data (so no-peeking!)\n</span>","metadata":{}},{"cell_type":"code","source":"scaler = StandardScaler()\nX_train_encoded_scaled = scaler.fit_transform(X_train_encoded_final)\nX_test_encoded_scaled = scaler.transform(X_test_encoded_final)","metadata":{"execution":{"iopub.status.busy":"2022-10-17T08:57:34.973255Z","iopub.execute_input":"2022-10-17T08:57:34.974365Z","iopub.status.idle":"2022-10-17T08:57:34.997902Z","shell.execute_reply.started":"2022-10-17T08:57:34.974322Z","shell.execute_reply":"2022-10-17T08:57:34.996659Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train_encoded_scaled.shape\nX_test_encoded_scaled.shape","metadata":{"execution":{"iopub.status.busy":"2022-10-17T08:57:35.018957Z","iopub.execute_input":"2022-10-17T08:57:35.019357Z","iopub.status.idle":"2022-10-17T08:57:35.027119Z","shell.execute_reply.started":"2022-10-17T08:57:35.019325Z","shell.execute_reply":"2022-10-17T08:57:35.025855Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<span style=\"color:pink;font-weight:600;font-size:16px;font-style:serif\">\n    Choosing a Machine Learning Model\n</span>\n\n\n    We choose the machine learning model according to the problem we are trying to solve. Two different kinds of problems in supervised learning are classification and regression. Since our aim is to predict the value of a variable and not to classify them, we are dealing with a regression problem.\n    Here, we will use a Random Forest Regression model.\n\n![alt text for screen readers](https://www.frontiersin.org/files/Articles/284242/fnagi-09-00329-HTML/image_m/fnagi-09-00329-g001.jpg)\n\n\n**Source:** Sarica, Cerasa & Quattrone, 2017\n\n<span style=\"color:pink;font-weight:600;font-size:16px;font-style:serif\">\n    What is a Random Forest Regressor?\n</span>\n\n    - Random Forest Regression is a supervised learning algorithm, used for regression tasks. It uses the ensemble learning method, which is a technique that combines predictions from several machine learning algorithms to make a predition, enabling it t make more accurate predtions than a single model.\n\n    - For this, a Random Forest constructs several decision trees during model training, and uses the result from all these trees to generate a strong prediction. This is a very powerful method, however with a caveat. Overfitting can easily occur in a Random Forest model. It is advantageos to test outputs from several values of tree depth to determine the optimal tree depth. Mean absolute error is a useful metric to do this. \n\n![alt text for screen readers](https://www.kdnuggets.com/wp-content/uploads/rand-forest-2.jpg \"Credits: kdnuggets.com\")\n","metadata":{}},{"cell_type":"markdown","source":"<a id='9'></a>\n<span style=\"color:pink;font-weight:600;font-size:25px;font-style:serif\">\n    Random Forest Regressor\n</span>\n\n[Top](#21)\n","metadata":{}},{"cell_type":"code","source":"# Define a random forest model\nrf_model = RandomForestRegressor(random_state=0)\nrf_model.fit(X_train_encoded_scaled, y_train)","metadata":{"execution":{"iopub.status.busy":"2022-10-17T08:57:35.127121Z","iopub.execute_input":"2022-10-17T08:57:35.127995Z","iopub.status.idle":"2022-10-17T08:57:37.291455Z","shell.execute_reply.started":"2022-10-17T08:57:35.12795Z","shell.execute_reply":"2022-10-17T08:57:37.290482Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id='10'></a>\n<span style=\"color:pink;font-weight:600;font-size:20px;font-style:serif\">\n    Performance evaluation\n</span>\n\n<span style=\"color:grey;font-weight:500;font-size:20px;font-style:serif\">\n    Now that we have our model, it is important to do a basic evaluation, to see how our model is performing. The mean_absolute_error is a simple way to observe this. It calculates the mean absolute error regression loss, using the true values and predicted values of the prediction target, in our case, the final price of the house. Note: The order in which the arguments are provided does not matter.\n</span>","metadata":{}},{"cell_type":"code","source":"rf_val_predictions = rf_model.predict(X_test_encoded_scaled)\nrf_val_mae = mean_absolute_error(rf_val_predictions, y_test)\n\nprint(\"Validation MAE for Random Forest Model: {:,.0f}\".format(rf_val_mae))","metadata":{"execution":{"iopub.status.busy":"2022-10-17T08:57:37.293194Z","iopub.execute_input":"2022-10-17T08:57:37.294293Z","iopub.status.idle":"2022-10-17T08:57:37.32237Z","shell.execute_reply.started":"2022-10-17T08:57:37.294245Z","shell.execute_reply":"2022-10-17T08:57:37.321196Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rf_val_predictions.shape\ny_test.shape","metadata":{"execution":{"iopub.status.busy":"2022-10-17T08:57:37.323896Z","iopub.execute_input":"2022-10-17T08:57:37.324257Z","iopub.status.idle":"2022-10-17T08:57:37.331508Z","shell.execute_reply.started":"2022-10-17T08:57:37.324225Z","shell.execute_reply":"2022-10-17T08:57:37.330345Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id='11'></a>\n<span style=\"color:pink;font-weight:600;font-size:20px;font-style:serif\">\n    Train model on all data\n</span>\n","metadata":{}},{"cell_type":"code","source":"# To improve accuracy, create a new Random Forest model which you will train on all training data\nrf_model_on_full_data = RandomForestRegressor(random_state=0)\n\n# fit rf_model_on_full_data on all data from the training data\nX_encoded = onehotencode(X)\nscaler_2 = StandardScaler()\nX_encoded_scaled = scaler.fit_transform(X_encoded)\n\nrf_model_on_full_data.fit(X_encoded_scaled,y)","metadata":{"execution":{"iopub.status.busy":"2022-10-16T18:08:10.086357Z","iopub.execute_input":"2022-10-16T18:08:10.08682Z","iopub.status.idle":"2022-10-16T18:08:12.468335Z","shell.execute_reply.started":"2022-10-16T18:08:10.086785Z","shell.execute_reply":"2022-10-16T18:08:12.467262Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id='12'></a>\n<span style=\"color:pink;font-weight:600;font-size:25px;font-style:serif\">\n    Load raw data for prediction\n</span>\n\n<span style=\"color:grey;font-weight:500;font-size:20px;font-style:serif\">\nThis data will be refered to as test data from now on, not to be consfused with validation data used to assess model performance after model training\n</span>","metadata":{}},{"cell_type":"code","source":"# path to file you will use for predictions\ntest_data_path = '../input/test.csv'\n\n# read test data file using pandas\ntest_data = pd.read_csv(test_data_path)\ntest_data.shape","metadata":{"execution":{"iopub.status.busy":"2022-10-16T10:47:34.027048Z","iopub.execute_input":"2022-10-16T10:47:34.027605Z","iopub.status.idle":"2022-10-16T10:47:34.062709Z","shell.execute_reply.started":"2022-10-16T10:47:34.027571Z","shell.execute_reply":"2022-10-16T10:47:34.061445Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id='13'></a>\n<span style=\"color:pink;font-weight:600;font-size:25px;font-style:serif\">\n    Test-data preprocessing\n</span>\n\n<span style=\"color:grey;font-weight:500;font-size:20px;font-style:serif\">\nTest data must match the structure that the random forest model is expecting\n</span>","metadata":{}},{"cell_type":"code","source":"test_data.head()","metadata":{"execution":{"iopub.status.busy":"2022-10-16T10:47:34.071846Z","iopub.execute_input":"2022-10-16T10:47:34.072345Z","iopub.status.idle":"2022-10-16T10:47:34.10181Z","shell.execute_reply.started":"2022-10-16T10:47:34.072297Z","shell.execute_reply":"2022-10-16T10:47:34.10055Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id='14'></a>\n<span style=\"color:pink;font-weight:600;font-size:20px;font-style:serif\">\n    Feature match with training data\n</span>\n\n<span style=\"color:grey;font-weight:500;font-size:20px;font-style:serif\">\nTraining data and test data must have the same features (columns)\n    </span>\n    \n    \n\n\n","metadata":{}},{"cell_type":"code","source":"test_data = test_data[corr_cols]\ntest_data.shape","metadata":{"execution":{"iopub.status.busy":"2022-10-16T10:47:34.103259Z","iopub.execute_input":"2022-10-16T10:47:34.104052Z","iopub.status.idle":"2022-10-16T10:47:34.115891Z","shell.execute_reply.started":"2022-10-16T10:47:34.104016Z","shell.execute_reply":"2022-10-16T10:47:34.114737Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_data.head()","metadata":{"execution":{"iopub.status.busy":"2022-10-16T10:47:34.117308Z","iopub.execute_input":"2022-10-16T10:47:34.11775Z","iopub.status.idle":"2022-10-16T10:47:34.145946Z","shell.execute_reply.started":"2022-10-16T10:47:34.117706Z","shell.execute_reply":"2022-10-16T10:47:34.144766Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id='15'></a>\n<span style=\"color:pink;font-weight:600;font-size:20px;font-style:serif\">\n    Featre engineering\n</span>\n","metadata":{}},{"cell_type":"code","source":"test_data = create_extra_features(test_data)\ntest_data.shape","metadata":{"execution":{"iopub.status.busy":"2022-10-16T10:47:34.147328Z","iopub.execute_input":"2022-10-16T10:47:34.147752Z","iopub.status.idle":"2022-10-16T10:47:34.158562Z","shell.execute_reply.started":"2022-10-16T10:47:34.147717Z","shell.execute_reply":"2022-10-16T10:47:34.157428Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id='16'></a>\n<span style=\"color:pink;font-weight:600;font-size:20px;font-style:serif\">\n    Replace null values\n</span>\n","metadata":{}},{"cell_type":"code","source":"test_data.isna().sum()","metadata":{"execution":{"iopub.status.busy":"2022-10-16T10:47:35.834491Z","iopub.execute_input":"2022-10-16T10:47:35.83543Z","iopub.status.idle":"2022-10-16T10:47:35.848175Z","shell.execute_reply.started":"2022-10-16T10:47:35.835391Z","shell.execute_reply":"2022-10-16T10:47:35.846759Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_data = test_data.fillna(0)           \ntest_data.isna().sum()","metadata":{"execution":{"iopub.status.busy":"2022-10-16T10:47:36.069194Z","iopub.execute_input":"2022-10-16T10:47:36.070386Z","iopub.status.idle":"2022-10-16T10:47:36.090436Z","shell.execute_reply.started":"2022-10-16T10:47:36.070343Z","shell.execute_reply":"2022-10-16T10:47:36.089373Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id='17'></a>\n<span style=\"color:pink;font-weight:600;font-size:20px;font-style:serif\">\n    One hot encode\n</span>\n","metadata":{}},{"cell_type":"code","source":"test_data = pd.get_dummies(test_data)","metadata":{"execution":{"iopub.status.busy":"2022-10-16T10:47:36.217305Z","iopub.execute_input":"2022-10-16T10:47:36.21818Z","iopub.status.idle":"2022-10-16T10:47:36.253093Z","shell.execute_reply.started":"2022-10-16T10:47:36.218138Z","shell.execute_reply":"2022-10-16T10:47:36.251978Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_data.shape","metadata":{"execution":{"iopub.status.busy":"2022-10-16T10:47:37.143587Z","iopub.execute_input":"2022-10-16T10:47:37.144039Z","iopub.status.idle":"2022-10-16T10:47:37.151001Z","shell.execute_reply.started":"2022-10-16T10:47:37.144002Z","shell.execute_reply":"2022-10-16T10:47:37.14972Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_encoded.shape","metadata":{"execution":{"iopub.status.busy":"2022-10-16T10:47:37.305716Z","iopub.execute_input":"2022-10-16T10:47:37.306098Z","iopub.status.idle":"2022-10-16T10:47:37.312823Z","shell.execute_reply.started":"2022-10-16T10:47:37.306067Z","shell.execute_reply":"2022-10-16T10:47:37.311734Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final_train, final_test = X_encoded.align(test_data, join='left', axis=1, fill_value=0)  # inner join","metadata":{"execution":{"iopub.status.busy":"2022-10-16T10:47:37.502466Z","iopub.execute_input":"2022-10-16T10:47:37.5032Z","iopub.status.idle":"2022-10-16T10:47:37.510447Z","shell.execute_reply.started":"2022-10-16T10:47:37.503153Z","shell.execute_reply":"2022-10-16T10:47:37.509559Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final_test.shape","metadata":{"execution":{"iopub.status.busy":"2022-10-16T10:47:38.421295Z","iopub.execute_input":"2022-10-16T10:47:38.421704Z","iopub.status.idle":"2022-10-16T10:47:38.428551Z","shell.execute_reply.started":"2022-10-16T10:47:38.421655Z","shell.execute_reply":"2022-10-16T10:47:38.427259Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final_train.shape","metadata":{"execution":{"iopub.status.busy":"2022-10-16T10:47:39.303197Z","iopub.execute_input":"2022-10-16T10:47:39.304241Z","iopub.status.idle":"2022-10-16T10:47:39.310601Z","shell.execute_reply.started":"2022-10-16T10:47:39.304171Z","shell.execute_reply":"2022-10-16T10:47:39.309807Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id='18'></a>\n<span style=\"color:pink;font-weight:600;font-size:20px;font-style:serif\">\n    Feature scaling\n</span>\n","metadata":{}},{"cell_type":"code","source":"final_test_scaled = scaler.transform(final_test)\nfinal_test_scaled.shape","metadata":{"execution":{"iopub.status.busy":"2022-10-16T10:47:39.711168Z","iopub.execute_input":"2022-10-16T10:47:39.711961Z","iopub.status.idle":"2022-10-16T10:47:39.730825Z","shell.execute_reply.started":"2022-10-16T10:47:39.71192Z","shell.execute_reply":"2022-10-16T10:47:39.729767Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final_test_scaled.shape","metadata":{"execution":{"iopub.status.busy":"2022-10-16T10:47:40.565113Z","iopub.execute_input":"2022-10-16T10:47:40.565528Z","iopub.status.idle":"2022-10-16T10:47:40.572806Z","shell.execute_reply.started":"2022-10-16T10:47:40.56549Z","shell.execute_reply":"2022-10-16T10:47:40.571694Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id='19'></a>\n<span style=\"color:pink;font-weight:600;font-size:25px;font-style:serif\">\n    Data prediction on test data\n</span>\n","metadata":{}},{"cell_type":"code","source":"# make predictions which we will submit. \ntest_preds = rf_model_on_full_data.predict(final_test_scaled)","metadata":{"execution":{"iopub.status.busy":"2022-10-16T10:47:40.749558Z","iopub.execute_input":"2022-10-16T10:47:40.749959Z","iopub.status.idle":"2022-10-16T10:47:40.793224Z","shell.execute_reply.started":"2022-10-16T10:47:40.749928Z","shell.execute_reply":"2022-10-16T10:47:40.792323Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final_test.shape","metadata":{"execution":{"iopub.status.busy":"2022-10-16T10:47:40.93321Z","iopub.execute_input":"2022-10-16T10:47:40.933598Z","iopub.status.idle":"2022-10-16T10:47:40.940734Z","shell.execute_reply.started":"2022-10-16T10:47:40.933564Z","shell.execute_reply":"2022-10-16T10:47:40.939347Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<span style=\"font-weight:600;font-size:25px;font-style:serif;\">\n    \n    I hope you enjoyed this kernel!\n    If you have any questions or tips, feel free to reach out :)\n</span>\n\n","metadata":{}},{"cell_type":"markdown","source":"[Top](#21)","metadata":{}},{"cell_type":"markdown","source":"<div class=\"alert\" style=\"background-color:thistle; text-align:center; color:white; weight:200; font-size:30px;\">\n    ðŸ•Š Feedback & upvotes much appreciated! ðŸ•Š\n</div>","metadata":{}}]}