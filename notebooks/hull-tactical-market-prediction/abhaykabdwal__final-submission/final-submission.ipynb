{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":111543,"databundleVersionId":13750964,"sourceType":"competition"}],"dockerImageVersionId":31154,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Imports","metadata":{}},{"cell_type":"code","source":"import os\nfrom pathlib import Path\nimport datetime\n\nfrom tqdm import tqdm\nfrom dataclasses import dataclass, asdict\n\nimport pandas as pd\nimport polars as pl \nimport numpy as np\nfrom sklearn.linear_model import ElasticNet, ElasticNetCV, LinearRegression\nfrom sklearn.preprocessing import StandardScaler\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport kaggle_evaluation.default_inference_server\n\nimport warnings\nwarnings.filterwarnings(\"ignore\", message=\"use_inf_as_na option is deprecated\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-28T13:30:45.367991Z","iopub.execute_input":"2025-10-28T13:30:45.36851Z","iopub.status.idle":"2025-10-28T13:30:45.373161Z","shell.execute_reply.started":"2025-10-28T13:30:45.368489Z","shell.execute_reply":"2025-10-28T13:30:45.372565Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-28T13:20:54.0007Z","iopub.execute_input":"2025-10-28T13:20:54.001099Z","iopub.status.idle":"2025-10-28T13:20:54.009503Z","shell.execute_reply.started":"2025-10-28T13:20:54.00108Z","shell.execute_reply":"2025-10-28T13:20:54.008576Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Data Loading","metadata":{}},{"cell_type":"code","source":"# ============ PATHS ============\nDATA_PATH: Path = Path('/kaggle/input/hull-tactical-market-prediction/')\n\n# ============ RETURNS TO SIGNAL CONFIGS ============\nMIN_SIGNAL: float = 0.0                         # Minimum value for the daily signal \nMAX_SIGNAL: float = 2.0                         # Maximum value for the daily signal \nSIGNAL_MULTIPLIER: float = 400.0                # Multiplier of the OLS market forward excess returns predictions to signal \n\n# ============ MODEL CONFIGS ============\nCV: int = 10                                    # Number of cross validation folds in the model fitting\nL1_RATIO: float = 0.5                           # ElasticNet mixing parameter\nALPHAS: np.ndarray = np.logspace(-4, 2, 100)    # Constant that multiplies the penalty terms\nMAX_ITER: int = 1000000                         # The maximum number of iterations","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-28T13:20:54.010291Z","iopub.execute_input":"2025-10-28T13:20:54.010676Z","iopub.status.idle":"2025-10-28T13:20:54.026617Z","shell.execute_reply.started":"2025-10-28T13:20:54.010657Z","shell.execute_reply":"2025-10-28T13:20:54.025765Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"MIN_INVESTMENT = 0.0\nMAX_INVESTMENT = 2.0","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-28T13:41:27.897383Z","iopub.execute_input":"2025-10-28T13:41:27.897649Z","iopub.status.idle":"2025-10-28T13:41:27.901444Z","shell.execute_reply.started":"2025-10-28T13:41:27.897629Z","shell.execute_reply":"2025-10-28T13:41:27.900779Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"@dataclass\nclass DatasetOutput:\n    X_train : pl.DataFrame \n    X_test: pl.DataFrame\n    y_train: pl.Series\n    y_test: pl.Series\n    scaler: StandardScaler\n\n@dataclass \nclass ElasticNetParameters:\n    l1_ratio : float \n    cv: int\n    alphas: np.ndarray \n    max_iter: int \n    \n    def __post_init__(self): \n        if self.l1_ratio < 0 or self.l1_ratio > 1: \n            raise ValueError(\"Wrong initializing value for ElasticNet l1_ratio\")\n        \n@dataclass(frozen=True)\nclass RetToSignalParameters:\n    signal_multiplier: float \n    min_signal : float = MIN_SIGNAL\n    max_signal : float = MAX_SIGNAL\n\nret_signal_params = RetToSignalParameters(\n    signal_multiplier= SIGNAL_MULTIPLIER\n)\n\nenet_params = ElasticNetParameters(\n    l1_ratio = L1_RATIO, \n    cv = CV, \n    alphas = ALPHAS, \n    max_iter = MAX_ITER\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-28T13:23:15.422372Z","iopub.execute_input":"2025-10-28T13:23:15.422654Z","iopub.status.idle":"2025-10-28T13:23:15.429824Z","shell.execute_reply.started":"2025-10-28T13:23:15.422632Z","shell.execute_reply":"2025-10-28T13:23:15.429071Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Utility Functions","metadata":{}},{"cell_type":"code","source":"def load_trainset() -> pl.DataFrame:\n    \"\"\"\n    Loads and preprocesses the training dataset.\n\n    Returns:\n        pl.DataFrame: The preprocessed training DataFrame.\n    \"\"\"\n    return (\n        pl.read_csv(DATA_PATH / \"train.csv\")\n        .rename({'market_forward_excess_returns':'target'})\n        .with_columns(\n            pl.exclude('date_id').cast(pl.Float64, strict=False)\n        )\n        .head(-10)\n    )\n\ndef load_testset() -> pl.DataFrame:\n    \"\"\"\n    Loads and preprocesses the testing dataset.\n\n    Returns:\n        pl.DataFrame: The preprocessed testing DataFrame.\n    \"\"\"\n    return (\n        pl.read_csv(DATA_PATH / \"test.csv\")\n        .rename({'lagged_forward_returns':'target'})\n        .with_columns(\n            pl.exclude('date_id').cast(pl.Float64, strict=False)\n        )\n    )\n\ndef create_example_dataset(df: pl.DataFrame) -> pl.DataFrame:\n    \"\"\"\n    Creates new features and cleans a DataFrame.\n\n    Args:\n        df (pl.DataFrame): The input Polars DataFrame.\n\n    Returns:\n        pl.DataFrame: The DataFrame with new features, selected columns, and no null values.\n    \"\"\"\n    vars_to_keep: List[str] = [\n        \"M1\", \"M2\", \"V1\",\"V2\", \"S2\", \"E2\", \"E3\", \"P9\", \"S1\", \"S5\", \"I2\", \"P8\",\n        \"P10\", \"P12\", \"P13\", \"U1\", \"U2\"\n    ]\n\n    return (\n        df.with_columns(\n            (pl.col(\"I2\") - pl.col(\"I1\")).alias(\"U1\"),\n            (pl.col(\"M11\") / ((pl.col(\"I2\") + pl.col(\"I9\") + pl.col(\"I7\")) / 3)).alias(\"U2\")\n        )\n        .select([\"date_id\", \"target\"] + vars_to_keep)\n        .with_columns([\n            pl.col(col).fill_null(pl.col(col).ewm_mean(com=0.5))\n            for col in vars_to_keep\n        ])\n        .drop_nulls()\n    )\n    \ndef join_train_test_dataframes(train: pl.DataFrame, test: pl.DataFrame) -> pl.DataFrame:\n    \"\"\"\n    Joins two dataframes by common columns and concatenates them vertically.\n\n    Args:\n        train (pl.DataFrame): The training DataFrame.\n        test (pl.DataFrame): The testing DataFrame.\n\n    Returns:\n        pl.DataFrame: A single DataFrame with vertically stacked data from common columns.\n    \"\"\"\n    common_columns: list[str] = [col for col in train.columns if col in test.columns]\n    \n    return pl.concat([train.select(common_columns), test.select(common_columns)], how=\"vertical\")\n\ndef split_dataset(train: pl.DataFrame, test: pl.DataFrame, features: list[str]) -> DatasetOutput: \n    \"\"\"\n    Splits the data into features (X) and target (y), and scales the features.\n\n    Args:\n        train (pl.DataFrame): The processed training DataFrame.\n        test (pl.DataFrame): The processed testing DataFrame.\n        features (list[str]): List of features to used in model. \n\n    Returns:\n        DatasetOutput: A dataclass containing the scaled feature sets, target series, and the fitted scaler.\n    \"\"\"\n    X_train = train.drop(['date_id','target']) \n    y_train = train.get_column('target')\n    X_test = test.drop(['date_id','target']) \n    y_test = test.get_column('target')\n    \n    scaler = StandardScaler() \n    \n    X_train_scaled_np = scaler.fit_transform(X_train)\n    X_train = pl.from_numpy(X_train_scaled_np, schema=features)\n    \n    X_test_scaled_np = scaler.transform(X_test)\n    X_test = pl.from_numpy(X_test_scaled_np, schema=features)\n    \n    \n    return DatasetOutput(\n        X_train = X_train,\n        y_train = y_train, \n        X_test = X_test, \n        y_test = y_test,\n        scaler = scaler\n    )\ndef convert_ret_to_signal(\n    ret_arr: np.ndarray,\n    params: RetToSignalParameters\n) -> np.ndarray:\n    \"\"\"\n    Converts raw model predictions (expected returns) into a trading signal.\n\n    Args:\n        ret_arr (np.ndarray): The array of predicted returns.\n        params (RetToSignalParameters): Parameters for scaling and clipping the signal.\n\n    Returns:\n        np.ndarray: The resulting trading signal, clipped between min and max values.\n    \"\"\"\n    return np.clip(\n        ret_arr * params.signal_multiplier + 1, params.min_signal, params.max_signal\n    )\n\ndef score(solution: pd.DataFrame, submission: pd.DataFrame, row_id_column_name: str) -> float:\n    \"\"\"\n    Calculates a custom evaluation metric (volatility-adjusted Sharpe ratio).\n    \"\"\"\n\n    if not pd.api.types.is_numeric_dtype(submission['prediction']):\n        raise ParticipantVisibleError('Predictions must be numeric')\n\n    # This function modifies the solution df, so pass a copy\n    solution = solution.copy()\n    solution['position'] = submission['prediction']\n\n    if solution['position'].max() > MAX_INVESTMENT:\n        raise ParticipantVisibleError(f'Position of {solution[\"position\"].max()} exceeds maximum of {MAX_INVESTMENT}')\n    if solution['position'].min() < MIN_INVESTMENT:\n        raise ParticipantVisibleError(f'Position of {solution[\"position\"].min()} below minimum of {MIN_INVESTMENT}')\n\n    solution['strategy_returns'] = solution['risk_free_rate'] * (1 - solution['position']) + solution['position'] * solution['forward_returns']\n\n    # Calculate strategy's Sharpe ratio\n    strategy_excess_returns = solution['strategy_returns'] - solution['risk_free_rate']\n    strategy_excess_cumulative = (1 + strategy_excess_returns).prod()\n    strategy_mean_excess_return = (strategy_excess_cumulative) ** (1 / len(solution)) - 1\n    strategy_std = solution['strategy_returns'].std()\n\n    trading_days_per_yr = 252\n    if strategy_std == 0:\n        # Return 0 instead of crashing if std is zero\n        return 0.0 \n        \n    sharpe = strategy_mean_excess_return / strategy_std * np.sqrt(trading_days_per_yr)\n    strategy_volatility = float(strategy_std * np.sqrt(trading_days_per_yr) * 100)\n\n    # Calculate market return and volatility\n    market_excess_returns = solution['forward_returns'] - solution['risk_free_rate']\n    market_excess_cumulative = (1 + market_excess_returns).prod()\n    market_mean_excess_return = (market_excess_cumulative) ** (1 / len(solution)) - 1\n    market_std = solution['forward_returns'].std()\n\n    market_volatility = float(market_std * np.sqrt(trading_days_per_yr) * 100)\n\n    if market_volatility == 0:\n        raise ParticipantVisibleError('Division by zero, market std is zero')\n\n    # Calculate the volatility penalty\n    excess_vol = max(0, strategy_volatility / market_volatility - 1.2) if market_volatility > 0 else 0\n    vol_penalty = 1 + excess_vol\n\n    # Calculate the return penalty\n    return_gap = max(\n        0,\n        (market_mean_excess_return - strategy_mean_excess_return) * 100 * trading_days_per_yr,\n    )\n    return_penalty = 1 + (return_gap**2) / 100\n\n    # Adjust the Sharpe ratio by the volatility and return penalty\n    adjusted_sharpe = sharpe / (vol_penalty * return_penalty)\n    return min(float(adjusted_sharpe), 1_000_000)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-28T13:38:35.237782Z","iopub.execute_input":"2025-10-28T13:38:35.238054Z","iopub.status.idle":"2025-10-28T13:38:35.253061Z","shell.execute_reply.started":"2025-10-28T13:38:35.238033Z","shell.execute_reply":"2025-10-28T13:38:35.252489Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train: pl.DataFrame = load_trainset()\ntest: pl.DataFrame = load_testset() \nprint(train.tail(3)) \nprint(test.head(3))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-28T13:24:01.243974Z","iopub.execute_input":"2025-10-28T13:24:01.2446Z","iopub.status.idle":"2025-10-28T13:24:01.583941Z","shell.execute_reply.started":"2025-10-28T13:24:01.244574Z","shell.execute_reply":"2025-10-28T13:24:01.583264Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df: pl.DataFrame = join_train_test_dataframes(train, test)\ndf = create_example_dataset(df=df) \ntrain: pl.DataFrame = df.filter(pl.col('date_id').is_in(train.get_column('date_id')))\ntest: pl.DataFrame = df.filter(pl.col('date_id').is_in(test.get_column('date_id')))\n\nFEATURES: list[str] = [col for col in test.columns if col not in ['date_id', 'target']]\n\ndataset: DatasetOutput = split_dataset(train=train, test=test, features=FEATURES) \n\nX_train: pl.DataFrame = dataset.X_train\nX_test: pl.DataFrame = dataset.X_test\ny_train: pl.DataFrame = dataset.y_train\ny_test: pl.DataFrame = dataset.y_test\nscaler: StandardScaler = dataset.scaler ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-28T13:24:16.716161Z","iopub.execute_input":"2025-10-28T13:24:16.716717Z","iopub.status.idle":"2025-10-28T13:24:16.808242Z","shell.execute_reply.started":"2025-10-28T13:24:16.716691Z","shell.execute_reply":"2025-10-28T13:24:16.807707Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Preprocessing and EDA","metadata":{}},{"cell_type":"code","source":"train_pd = train.to_pandas()\ntest_pd = test.to_pandas()\ntrain_pd = train_pd.replace([np.inf, -np.inf], np.nan)\ntest_pd = test_pd.replace([np.inf, -np.inf], np.nan)\n\n\nprint(\"✅ TRAIN SET OVERVIEW\")\nprint(train_pd.info())\nprint(train_pd.describe().T)\n\nprint(\"\\n✅ TEST SET OVERVIEW\")\nprint(test_pd.info())\nprint(test_pd.describe().T)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-28T13:30:19.929441Z","iopub.execute_input":"2025-10-28T13:30:19.929916Z","iopub.status.idle":"2025-10-28T13:30:19.996213Z","shell.execute_reply.started":"2025-10-28T13:30:19.929894Z","shell.execute_reply":"2025-10-28T13:30:19.995464Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plt.figure(figsize=(8,4))\nsns.histplot(train_pd['target'], bins=50, kde=True)\nplt.title(\"Distribution of Target (market_forward_excess_returns)\")\nplt.xlabel(\"Target Value\")\nplt.show()\n\n# Basic stats\nprint(train_pd['target'].describe())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-28T13:30:51.592641Z","iopub.execute_input":"2025-10-28T13:30:51.593107Z","iopub.status.idle":"2025-10-28T13:30:51.856737Z","shell.execute_reply.started":"2025-10-28T13:30:51.593083Z","shell.execute_reply":"2025-10-28T13:30:51.856168Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plt.figure(figsize=(12,4))\nsns.lineplot(data=train_pd, x='date_id', y='target', linewidth=0.8)\nplt.title(\"Target Over Time\")\nplt.xlabel(\"Date ID\")\nplt.ylabel(\"Target\")\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-28T13:30:53.840604Z","iopub.execute_input":"2025-10-28T13:30:53.840874Z","iopub.status.idle":"2025-10-28T13:30:54.04862Z","shell.execute_reply.started":"2025-10-28T13:30:53.840854Z","shell.execute_reply":"2025-10-28T13:30:54.047897Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_pd['target_rolling'] = train_pd['target'].rolling(30).mean()\nplt.figure(figsize=(12,4))\nsns.lineplot(data=train_pd, x='date_id', y='target_rolling', color='orange')\nplt.title(\"30-Day Rolling Mean of Target\")\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-28T13:30:55.527606Z","iopub.execute_input":"2025-10-28T13:30:55.528288Z","iopub.status.idle":"2025-10-28T13:30:55.719323Z","shell.execute_reply.started":"2025-10-28T13:30:55.528262Z","shell.execute_reply":"2025-10-28T13:30:55.718621Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"FEATURES_TO_PLOT = [\"M1\", \"M2\", \"V1\", \"V2\", \"S2\", \"E2\", \"E3\", \"P9\", \"S1\", \"S5\", \"I2\", \"P8\"]\n\ntrain_pd[FEATURES_TO_PLOT].hist(figsize=(14,10), bins=30)\nplt.suptitle(\"Feature Distributions\", fontsize=16)\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-28T13:31:34.037943Z","iopub.execute_input":"2025-10-28T13:31:34.038264Z","iopub.status.idle":"2025-10-28T13:31:35.566608Z","shell.execute_reply.started":"2025-10-28T13:31:34.03824Z","shell.execute_reply":"2025-10-28T13:31:35.565808Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"corr = train_pd.corr(numeric_only=True)\n\n# Correlation with target\ntarget_corr = corr['target'].sort_values(ascending=False)\nprint(\"Top Positive Correlations:\\n\", target_corr.head(10))\nprint(\"\\nTop Negative Correlations:\\n\", target_corr.tail(10))\n\n# Heatmap\nplt.figure(figsize=(10,8))\nsns.heatmap(corr.loc[FEATURES_TO_PLOT + ['target'], FEATURES_TO_PLOT + ['target']], \n            cmap='coolwarm', center=0, annot=False)\nplt.title(\"Feature Correlation Heatmap\")\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-28T13:31:45.400413Z","iopub.execute_input":"2025-10-28T13:31:45.400668Z","iopub.status.idle":"2025-10-28T13:31:45.78069Z","shell.execute_reply.started":"2025-10-28T13:31:45.400652Z","shell.execute_reply":"2025-10-28T13:31:45.779917Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"variance = train_pd.var().sort_values(ascending=True)\nprint(\"Low Variance Features:\\n\", variance.head(10))\n\n# Boxplot of top features for outliers\nplt.figure(figsize=(12,6))\nsns.boxplot(data=train_pd[FEATURES_TO_PLOT])\nplt.xticks(rotation=45)\nplt.title(\"Feature Boxplots (Outlier Detection)\")\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-28T13:32:06.057406Z","iopub.execute_input":"2025-10-28T13:32:06.057678Z","iopub.status.idle":"2025-10-28T13:32:06.285298Z","shell.execute_reply.started":"2025-10-28T13:32:06.057659Z","shell.execute_reply":"2025-10-28T13:32:06.28464Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Top Performing Models","metadata":{}},{"cell_type":"markdown","source":"## Lightgbm","metadata":{}},{"cell_type":"code","source":"import lightgbm as lgb\n\nmodel = lgb.LGBMRegressor(\n    device='gpu',\n    gpu_platform_id=0,\n    gpu_device_id=0,\n    n_estimators=100\n)\nmodel.fit(X_train, y_train)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-28T13:34:29.160304Z","iopub.execute_input":"2025-10-28T13:34:29.161091Z","iopub.status.idle":"2025-10-28T13:34:39.12982Z","shell.execute_reply.started":"2025-10-28T13:34:29.161061Z","shell.execute_reply":"2025-10-28T13:34:39.129182Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def predict(test: pl.DataFrame) -> float:\n    test = test.rename({'lagged_forward_returns':'target'})\n    df: pl.DataFrame = create_example_dataset(test)\n    X_test: pl.DataFrame = df.select(FEATURES)\n    X_test_scaled_np: np.ndarray = scaler.transform(X_test)\n    X_test: pl.DataFrame = pl.from_numpy(X_test_scaled_np, schema=FEATURES)\n    raw_pred: float = model.predict(X_test)[0]\n    return convert_ret_to_signal(raw_pred, ret_signal_params)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-28T13:39:37.711008Z","iopub.execute_input":"2025-10-28T13:39:37.711304Z","iopub.status.idle":"2025-10-28T13:39:37.715923Z","shell.execute_reply.started":"2025-10-28T13:39:37.711287Z","shell.execute_reply":"2025-10-28T13:39:37.715016Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"\\n--- Calculating Local Score for LightGBM Model ---\")\n\n# 1. Load the ground truth solution (train data)\ntry:\n    solution_df = pd.read_csv(DATA_PATH / \"train.csv\")\n    solution_df = solution_df[['date_id', 'forward_returns', 'risk_free_rate']]\nexcept Exception as e:\n    print(f\"Error loading solution data: {e}\")\n    raise\n\n# 2. Generate predictions for the train set\nX_train_np = X_train.to_numpy()\ntrain_date_ids = train.get_column('date_id').to_numpy()\n\n# LightGBM raw predictions (expected returns)\nraw_preds_train = model.predict(X_train_np)\n\n# Convert raw returns to final 0–2 signals\nfinal_signals_train = convert_ret_to_signal(raw_preds_train, ret_signal_params)\n\n# Create the submission DataFrame\nsubmission_df = pd.DataFrame({\n    'date_id': train_date_ids,\n    'prediction': final_signals_train\n})\n\n# 3. Align both DataFrames on date_id\ncommon_ids = set(solution_df['date_id']).intersection(set(submission_df['date_id']))\n\nsolution_df = (\n    solution_df[solution_df['date_id'].isin(common_ids)]\n    .sort_values('date_id')\n    .reset_index(drop=True)\n)\n\nsubmission_df = (\n    submission_df[submission_df['date_id'].isin(common_ids)]\n    .sort_values('date_id')\n    .reset_index(drop=True)\n)\n\n# 4. Evaluate with the provided score function\nrow_id_col = 'date_id'\n\nif not solution_df.empty and not submission_df.empty:\n    try:\n        local_score = score(solution_df, submission_df, row_id_col)\n        print(f\"\\nLightGBM Local Adjusted Sharpe Ratio: {local_score:.5f}\")\n    except ParticipantVisibleError as e:\n        print(f\"Metric Error: {e}\")\n    except Exception as e:\n        print(f\"Unexpected Error: {e}\")\nelse:\n    print(\"Could not calculate score: DataFrames are empty after alignment.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-28T13:41:37.763384Z","iopub.execute_input":"2025-10-28T13:41:37.764121Z","iopub.status.idle":"2025-10-28T13:41:37.96359Z","shell.execute_reply.started":"2025-10-28T13:41:37.764084Z","shell.execute_reply":"2025-10-28T13:41:37.962923Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#this change is done by shad jamil\nprint(\"Add additional models\")\nprint(\"Light GBM\")","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}