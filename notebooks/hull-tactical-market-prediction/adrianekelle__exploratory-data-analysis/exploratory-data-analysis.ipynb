{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":111543,"databundleVersionId":13750964,"sourceType":"competition"}],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-09-30T17:45:06.608048Z","iopub.execute_input":"2025-09-30T17:45:06.608325Z","iopub.status.idle":"2025-09-30T17:45:08.973286Z","shell.execute_reply.started":"2025-09-30T17:45:06.608294Z","shell.execute_reply":"2025-09-30T17:45:08.972111Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from pathlib import Path\n\nDIR : Path = Path('/kaggle/input/hull-tactical-market-prediction/')\ndf_train = pd.read_csv(DIR/\"train.csv\")\ndf_train.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-30T17:46:17.972507Z","iopub.execute_input":"2025-09-30T17:46:17.972785Z","iopub.status.idle":"2025-09-30T17:46:18.353374Z","shell.execute_reply.started":"2025-09-30T17:46:17.972766Z","shell.execute_reply":"2025-09-30T17:46:18.352449Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Exploratory data analysis","metadata":{}},{"cell_type":"markdown","source":"\n## Atributtes Description\n\n- date_id - An identifier for a single trading day.\n- M* - Market Dynamics/Technical features.\n- E* - Macro Economic features.\n- I* - Interest Rate features.\n- P* - Price/Valuation features.\n- V* - Volatility features.\n- S* - Sentiment features.\n- MOM* - Momentum features.\n- D* - Dummy/Binary features.\n- forward_returns - The returns from buying the S&P 500 and selling it a day later. Train set only.\n- risk_free_rate - The federal funds rate. Train set only.\n- market_forward_excess_returns - Forward returns relative to expectations. Computed by subtracting the rolling five-year mean forward returns and winsorizing the result using a median absolute deviation (MAD) with a criterion of 4. Train set only.\n","metadata":{}},{"cell_type":"code","source":"print(\"\\nData Info:\")\ndf_train.info()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-30T17:46:24.264594Z","iopub.execute_input":"2025-09-30T17:46:24.264916Z","iopub.status.idle":"2025-09-30T17:46:24.294896Z","shell.execute_reply.started":"2025-09-30T17:46:24.26486Z","shell.execute_reply":"2025-09-30T17:46:24.294023Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_train.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-30T17:46:28.283319Z","iopub.execute_input":"2025-09-30T17:46:28.283597Z","iopub.status.idle":"2025-09-30T17:46:28.289293Z","shell.execute_reply.started":"2025-09-30T17:46:28.283574Z","shell.execute_reply":"2025-09-30T17:46:28.288411Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Handling Missing Data","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\n\nsns.set(style=\"whitegrid\")\n\n#Calculate the percentage of missing values for each column\nmissing_percentage = (df_train.isnull().sum() / len(df_train)) * 100\nmissing_df = pd.DataFrame({'column_name': df_train.columns,\n                           'missing_percentage': missing_percentage})\n\n#Filter for columns with missing data and sort them\nmissing_df = missing_df[missing_df['missing_percentage'] > 0].sort_values('missing_percentage', ascending=False)\n\nprint(\"Columns with Missing Data (%):\")\nprint(missing_df)\n\nplt.figure()\nsns.barplot(x='missing_percentage', y='column_name', data=missing_df.head(20), palette='plasma')\nplt.title('20 Features by Percentage of Missing Values')\nplt.xlabel('Percentage Missing (%)')\nplt.ylabel('Feature Name')\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-30T17:46:30.971213Z","iopub.execute_input":"2025-09-30T17:46:30.971489Z","iopub.status.idle":"2025-09-30T17:46:32.458842Z","shell.execute_reply.started":"2025-09-30T17:46:30.971469Z","shell.execute_reply":"2025-09-30T17:46:32.458094Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Target Variable Analysis (market_forward_excess_returns)","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(12, 7))\nsns.histplot(df_train['market_forward_excess_returns'], bins=100, kde=True)\nplt.title('Distribution of \"market_forward_excess_returns\"', fontsize=16)\nplt.xlabel('Excess Return', fontsize=12)\nplt.ylabel('Frequency', fontsize=12)\nplt.axvline(df_train['market_forward_excess_returns'].mean(), color='red', linestyle='--', label=f\"Mean: {df_train['market_forward_excess_returns'].mean():.4f}\")\nplt.axvline(df_train['market_forward_excess_returns'].median(), color='green', linestyle='-', label=f\"Median: {df_train['market_forward_excess_returns'].median():.4f}\")\nplt.legend()\nplt.show()\n\nprint(\"\\nDescriptive statistics of the target variable:\")\nprint(df_train['market_forward_excess_returns'].describe())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-30T17:46:35.727355Z","iopub.execute_input":"2025-09-30T17:46:35.728124Z","iopub.status.idle":"2025-09-30T17:46:36.340904Z","shell.execute_reply.started":"2025-09-30T17:46:35.728095Z","shell.execute_reply":"2025-09-30T17:46:36.340076Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Time series analysis of the target variable","metadata":{}},{"cell_type":"code","source":"print(\"\\nAnalyzing the Target Variable Over Time\")\nplt.figure(figsize=(18, 7))\nplt.plot(df_train['date_id'], df_train['market_forward_excess_returns'], lw=0.8, alpha=0.9)\nplt.title('Market Excess Return vs. Date ID (Time Series)', fontsize=16)\nplt.xlabel('Date ID', fontsize=12)\nplt.ylabel('Excess Return', fontsize=12)\nplt.grid(True)\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-30T17:46:40.691772Z","iopub.execute_input":"2025-09-30T17:46:40.692139Z","iopub.status.idle":"2025-09-30T17:46:41.13486Z","shell.execute_reply.started":"2025-09-30T17:46:40.692112Z","shell.execute_reply":"2025-09-30T17:46:41.134056Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Feature Analysis","metadata":{}},{"cell_type":"markdown","source":"### Grouping Features","metadata":{}},{"cell_type":"code","source":"#Create lists of feature names by category\nfeature_groups = {\n    'D': [col for col in df_train.columns if col.startswith('D')],\n    'E': [col for col in df_train.columns if col.startswith('E')],\n    'I': [col for col in df_train.columns if col.startswith('I')],\n    'M': [col for col in df_train.columns if col.startswith('M')],\n    'P': [col for col in df_train.columns if col.startswith('P')],\n    'S': [col for col in df_train.columns if col.startswith('S')],\n    'V': [col for col in df_train.columns if col.startswith('V')],\n}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-30T17:46:50.600238Z","iopub.execute_input":"2025-09-30T17:46:50.600535Z","iopub.status.idle":"2025-09-30T17:46:50.606292Z","shell.execute_reply.started":"2025-09-30T17:46:50.600512Z","shell.execute_reply":"2025-09-30T17:46:50.605261Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Correlation analysis with the target variable","metadata":{}},{"cell_type":"code","source":"#apply a simple imputation (forward fill) for the sake of correlation analysis\ndf_imputed = df_train.fillna(method='ffill').fillna(method='bfill') # ffill then bfill to handle NaNs\n\ntarget = 'market_forward_excess_returns'\n#Calculate correlations with the target variable\ncorrelations = df_imputed.corr()[target].sort_values(ascending=False)\n\n#Remove self-correlation and other target-related columns\ncorrelations = correlations.drop([target, 'forward_returns', 'risk_free_rate'])\n\nplt.figure(figsize=(10, 8))\ntop_corr = pd.concat([correlations.head(20), correlations.tail(20)])\nsns.barplot(x=top_corr.values, y=top_corr.index, palette='coolwarm')\nplt.title('20 Positive & Negative Feature Correlations with Target')\nplt.xlabel('Correlation Coefficient')\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-30T17:48:11.548342Z","iopub.execute_input":"2025-09-30T17:48:11.54865Z","iopub.status.idle":"2025-09-30T17:48:12.272196Z","shell.execute_reply.started":"2025-09-30T17:48:11.548626Z","shell.execute_reply":"2025-09-30T17:48:12.271324Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_imputed = df_train.fillna(method='ffill').fillna(method='bfill')\n\nfeatures_to_plot = ['V13', 'S5', 'V7', 'M4', 'S2', 'E11']\n\nfig, axes = plt.subplots(2, 3, figsize=(20, 12))\nfig.suptitle('Revised Scatter Plots of Top Correlated Continuous Features vs. Target', fontsize=20, y=1.03)\n\naxes = axes.flatten()\n\nsample_df = df_imputed.sample(n=min(2000, len(df_imputed)), random_state=42)\n\nfor i, feature in enumerate(features_to_plot):\n    corr_value = df_imputed[[feature, target]].corr().iloc[0, 1]\n    sns.scatterplot(x=feature, y=target, data=sample_df, ax=axes[i], alpha=0.6)\n    axes[i].set_title(f'{feature} (Correlation: {corr_value:.3f})', fontsize=14)\n    axes[i].set_xlabel(f'Value of Feature {feature}')\n    axes[i].set_ylabel('Excess Return (Target)')\n\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-30T17:48:37.283088Z","iopub.execute_input":"2025-09-30T17:48:37.283383Z","iopub.status.idle":"2025-09-30T17:48:39.242679Z","shell.execute_reply.started":"2025-09-30T17:48:37.283361Z","shell.execute_reply":"2025-09-30T17:48:39.241949Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#box plot\nplt.figure()\nsns.boxplot(x='D2', y=target, data=df_imputed)\nplt.title('Distribution of Target Returns by D2', fontsize=16)\nplt.xlabel('Category of D2', fontsize=12)\nplt.ylabel('Excess Return (Target)', fontsize=12)\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-30T17:48:44.782672Z","iopub.execute_input":"2025-09-30T17:48:44.783059Z","iopub.status.idle":"2025-09-30T17:48:44.970484Z","shell.execute_reply.started":"2025-09-30T17:48:44.783034Z","shell.execute_reply":"2025-09-30T17:48:44.969693Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Multicollinearity Check","metadata":{}},{"cell_type":"code","source":"df_imputed = df_train.fillna(method='ffill').fillna(method='bfill')\n\n#Define the feature groups\nfeature_categories = ['D', 'E', 'I', 'M', 'P', 'S', 'V']\nfeature_groups = {cat: [col for col in df_imputed.columns if col.startswith(cat)] for cat in feature_categories}\n\n#Loop to generate a heatmap for each category\nfor category, features in feature_groups.items():\n    # Check if there are enough features to create a correlation matrix\n    if len(features) < 2:\n        print(f\"\\nGroup '{category}' has fewer than 2 features, skipping the heatmap.\")\n        continue\n\n    print(f\"\\nGenerating heatmap for group '{category}'...\")\n\n    #Calculate the correlation matrix for the current group\n    corr_matrix = df_imputed[features].corr()\n\n    #Decide whether to show annotations based on the number of features\n    show_annotations = len(features) < 15\n\n    #heatmap\n    plt.figure(figsize=(12, 9))\n    sns.heatmap(\n        corr_matrix,\n        annot=show_annotations, # Show numbers only if the matrix isn't too large\n        cmap='coolwarm',        # Color palette (red-blue)\n        fmt='.2f',              # Format numbers to 2 decimal places\n        linewidths=.5\n    )\n    plt.title(f'Correlation Heatmap for {category} Group Features', fontsize=16)\n    plt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-30T17:48:48.051262Z","iopub.execute_input":"2025-09-30T17:48:48.052226Z","iopub.status.idle":"2025-09-30T17:48:52.055576Z","shell.execute_reply.started":"2025-09-30T17:48:48.052187Z","shell.execute_reply":"2025-09-30T17:48:52.054611Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Time Series Deep Dive","metadata":{}},{"cell_type":"markdown","source":"### Seasonality Analysis (Day-of-the-Week Effect)","metadata":{}},{"cell_type":"code","source":"from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\nfrom sklearn.ensemble import RandomForestRegressor\n\nprint(\"\\nSeasonality Analysis (Day of the Week)\")\n\n#assume trading days are sequential.\ndf_train['day_of_week'] = df_train['date_id'] % 5\nday_names = {0: 'Mon', 1: 'Tue', 2: 'Wed', 3: 'Thu', 4: 'Fri'}\ndf_train['day_name'] = df_train['day_of_week'].map(day_names)\n\nplt.figure(figsize=(12, 7))\nsns.boxplot(data=df_train, x='day_name', y='market_forward_excess_returns', order=['Mon', 'Tue', 'Wed', 'Thu', 'Fri'])\nplt.title('Distribution of Returns by Day of the Week', fontsize=16)\nplt.xlabel('Day of the Week', fontsize=12)\nplt.ylabel('Excess Return', fontsize=12)\nplt.axhline(0, color='red', linestyle='--', alpha=0.7)\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-30T17:49:01.209325Z","iopub.execute_input":"2025-09-30T17:49:01.20962Z","iopub.status.idle":"2025-09-30T17:49:02.281668Z","shell.execute_reply.started":"2025-09-30T17:49:01.209595Z","shell.execute_reply":"2025-09-30T17:49:02.280781Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Autocorrelation of Returns (ACF)","metadata":{}},{"cell_type":"code","source":"print(\"\\nAutocorrelation Analysis (ACF)\")\n\nfig, ax = plt.subplots(figsize=(14, 6))\nplot_acf(df_train['market_forward_excess_returns'], lags=40, ax=ax)\nax.set_title('Autocorrelation Function (ACF) for Excess Returns', fontsize=16)\nax.set_xlabel('Lag (in days)', fontsize=12)\nax.set_ylabel('Autocorrelation', fontsize=12)\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-30T17:49:06.088187Z","iopub.execute_input":"2025-09-30T17:49:06.088645Z","iopub.status.idle":"2025-09-30T17:49:06.4051Z","shell.execute_reply.started":"2025-09-30T17:49:06.088618Z","shell.execute_reply":"2025-09-30T17:49:06.404258Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Rolling Statistics Analysis","metadata":{}},{"cell_type":"code","source":"print(\"\\nRolling Statistics Analysis\")\n\nwindow_size = 50 # Window of approximately 2 trading months\ndf_train['rolling_mean'] = df_train['market_forward_excess_returns'].rolling(window=window_size).mean()\ndf_train['rolling_std'] = df_train['market_forward_excess_returns'].rolling(window=window_size).std()\n\nfig, axes = plt.subplots(2, 1, figsize=(18, 12), sharex=True)\n\naxes[0].plot(df_train['date_id'], df_train['market_forward_excess_returns'], label='Original Return', alpha=0.5, lw=0.8)\naxes[0].plot(df_train['date_id'], df_train['rolling_mean'], label=f'Rolling Mean ({window_size} days)', color='red')\naxes[0].set_title('Excess Returns and Rolling Mean', fontsize=16)\naxes[0].set_ylabel('Value', fontsize=12)\naxes[0].legend()\naxes[0].grid(True)\n\n#rolling standard deviation (volatility)\naxes[1].plot(df_train['date_id'], df_train['rolling_std'], label=f'Rolling Standard Deviation ({window_size} days)', color='green')\naxes[1].set_title('Rolling Volatility (Risk)', fontsize=16)\naxes[1].set_xlabel('Date ID', fontsize=12)\naxes[1].set_ylabel('Standard Deviation', fontsize=12)\naxes[1].legend()\naxes[1].grid(True)\n\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-30T17:49:14.137975Z","iopub.execute_input":"2025-09-30T17:49:14.138811Z","iopub.status.idle":"2025-09-30T17:49:14.96462Z","shell.execute_reply.started":"2025-09-30T17:49:14.138782Z","shell.execute_reply":"2025-09-30T17:49:14.9638Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Detailed Feature Analysis","metadata":{}},{"cell_type":"markdown","source":"### Distribution of Important Features","metadata":{}},{"cell_type":"code","source":"print(\"\\nDistribution of Selected Features ---\")\n\nfeatures_to_plot = ['M4', 'S5', 'V13']\n\nfig, axes = plt.subplots(1, len(features_to_plot), figsize=(18, 5))\n\nfor i, feature in enumerate(features_to_plot):\n    sns.histplot(data=df_train, x=feature, kde=True, ax=axes[i])\n    axes[i].set_title(f'Distribution of {feature}', fontsize=14)\n\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-30T17:49:19.830053Z","iopub.execute_input":"2025-09-30T17:49:19.830336Z","iopub.status.idle":"2025-09-30T17:49:22.491092Z","shell.execute_reply.started":"2025-09-30T17:49:19.830316Z","shell.execute_reply":"2025-09-30T17:49:22.4902Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"##  Interaction Analysis","metadata":{}},{"cell_type":"markdown","source":"### Correlation Heatmap (Between Features)","metadata":{}},{"cell_type":"code","source":"print(\"\\nCorrelation Heatmap\")\n\nfeatures_subset = ['market_forward_excess_returns', 'M4', 'S2', 'E11', 'E12', 'P8', 'V13', 'S5', 'D2', 'D1']\ncorrelation_matrix = df_train[features_subset].corr()\n\nplt.figure(figsize=(10, 8))\nsns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt='.2f', linewidths=.5)\nplt.title('Correlation Heatmap of Selected Features', fontsize=16)\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-30T17:49:25.992064Z","iopub.execute_input":"2025-09-30T17:49:25.992371Z","iopub.status.idle":"2025-09-30T17:49:26.513618Z","shell.execute_reply.started":"2025-09-30T17:49:25.992348Z","shell.execute_reply":"2025-09-30T17:49:26.512715Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Advanced Analysis","metadata":{}},{"cell_type":"markdown","source":"### Feature Importance from a Baseline Model","metadata":{}},{"cell_type":"code","source":"print(\"\\nPerforming Feature Engineering...\")\ndf_train['day_of_week'] = df_train['date_id'] % 5\nday_names = {0: 'Mon', 1: 'Tue', 2: 'Wed', 3: 'Thu', 4: 'Fri'}\ndf_train['day_name'] = df_train['day_of_week'].map(day_names)\nprint(\"Columns after adding 'day_name':\", df_train.columns.tolist())\n\n#Handle Missing Values\ndf_processed = df_train.dropna()\nprint(f\"\\nHandled missing values. Shape is now: {df_processed.shape}\")\n\n#Encode Categorical Features (like 'day_name')\nprint(\"\\nApplying One-Hot Encoding...\")\ndf_encoded = pd.get_dummies(df_processed, columns=['day_name'], prefix='day')\nprint(\"Columns after encoding:\", df_encoded.columns.tolist())\n\ntarget_variable = 'market_forward_excess_returns'\ny = df_encoded[target_variable]\n\ncols_to_drop = [\n    'market_forward_excess_returns',\n    'forward_returns',\n    'date_id',\n    'day_of_week'\n]\n\nX = df_encoded.drop(columns=cols_to_drop)\n\nfrom sklearn.ensemble import RandomForestRegressor\nmodel = RandomForestRegressor(random_state=42)\nmodel.fit(X, y)\n\nfeature_importance = pd.DataFrame({\n    'feature': X.columns,\n    'importance': model.feature_importances_\n}).sort_values('importance', ascending=False)\n\nplt.figure(figsize=(18, 16))\nsns.barplot(data=feature_importance, x='importance', y='feature')\nplt.title('Corrected Feature Importance from a Random Forest Model', fontsize=12)\nplt.xlabel('Importance', fontsize=8)\nplt.ylabel('Feature', fontsize=8)\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-30T17:49:30.540997Z","iopub.execute_input":"2025-09-30T17:49:30.54132Z","iopub.status.idle":"2025-09-30T17:49:54.988374Z","shell.execute_reply.started":"2025-09-30T17:49:30.541295Z","shell.execute_reply":"2025-09-30T17:49:54.987534Z"}},"outputs":[],"execution_count":null}]}