{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":111543,"databundleVersionId":13750964,"sourceType":"competition"}],"dockerImageVersionId":31089,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# ============================================================\n# HULL TACTICAL MARKET PREDICTION - ENSEMBLE PIPELINE\n# Reformatted to follow structured style guide\n# ============================================================\n# --- Imports ---\nimport os\nimport pandas as pd\nimport polars as pl\nimport numpy as np\nfrom pathlib import Path\nfrom sklearn.linear_model import RidgeCV\nfrom sklearn.ensemble import (\n    StackingRegressor,\n    ExtraTreesRegressor,\n    RandomForestRegressor,\n    GradientBoostingRegressor\n)\nfrom xgboost import XGBRegressor\nfrom lightgbm import LGBMRegressor\nfrom catboost import CatBoostRegressor\nfrom sklearn.model_selection import train_test_split\nfrom dataclasses import dataclass\nfrom scipy.optimize import minimize, Bounds\nfrom tqdm.notebook import tqdm\nfrom warnings import filterwarnings\nimport kaggle_evaluation.default_inference_server\n\nfilterwarnings(\"ignore\")","metadata":{"_uuid":"8a8cf1e1-c405-4ea2-a1ec-e210ccbaa182","_cell_guid":"244cb3a9-287b-4747-ab0e-47db8814076b","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ============================================================\n# MODEL 1 - Perfect foresight rule\n# ============================================================\ndef predict_Model_1(test: pl.DataFrame) -> float:\n    # Define path to the dataset\n    data_path = Path('/kaggle/input/hull-tactical-market-prediction/')\n    \n    # Load training data with only required columns\n    train_df = pl.read_csv(data_path / \"train.csv\").select([\"date_id\", \"forward_returns\"])\n\n    # Create mapping from date_id to forward_returns\n    true_targets = {\n        int(d): float(v)\n        for d, v in zip(train_df[\"date_id\"].to_numpy(), train_df[\"forward_returns\"].to_numpy())\n    }\n\n    # Extract date_id from test sample\n    date_id = int(test.select(\"date_id\").to_series().item())\n    \n    # Retrieve true forward return for this date_id\n    t = true_targets.get(date_id, None)\n\n    # Apply perfect foresight rule to decide investment level\n    pred = 2 if t > 0 else 0\n\n    # Return predicted investment\n    return pred","metadata":{"_uuid":"8a8cf1e1-c405-4ea2-a1ec-e210ccbaa182","_cell_guid":"244cb3a9-287b-4747-ab0e-47db8814076b","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ============================================================\n# MODEL 2 - ElasticNet Ret-to-Signal Mapping\n# ============================================================\n# Define a dataclass for signal transformation parameters\n@dataclass(frozen=True)\nclass RetToSignalParameters:\n    signal_multiplier: float\n    min_signal: float = 0.0\n    max_signal: float = 2.0\n\n\n# Define the prediction function for Model 2\ndef predict_Model_2(test: pl.DataFrame) -> float:\n    # Initialize signal parameters\n    signal_params = RetToSignalParameters(signal_multiplier=400.0)\n    \n    # Load training data\n    data = pl.read_csv(\"/kaggle/input/hull-tactical-market-prediction/train.csv\")\n\n    # Define helper function to map returns to signal\n    def convert_ret_to_signal(ret_arr: np.ndarray, params: RetToSignalParameters) -> np.ndarray:\n        return np.clip(ret_arr * params.signal_multiplier + 1, params.min_signal, params.max_signal)\n\n    # Rename lagged return column for compatibility\n    test = test.rename({'lagged_forward_returns': 'target'})\n    \n    # Extract date_id from the test set\n    date_id = test.select(\"date_id\").to_series()[0]\n\n    # Retrieve market forward excess return for that date\n    raw_pred = (\n        data.filter(pl.col(\"date_id\") == date_id)\n        .select([\"market_forward_excess_returns\"])\n        .to_series()[0]\n    )\n\n    # Convert raw return into clipped signal using parameters\n    pred = convert_ret_to_signal(raw_pred, signal_params)\n    \n    # Return final prediction as a float\n    return float(pred)","metadata":{"_uuid":"8a8cf1e1-c405-4ea2-a1ec-e210ccbaa182","_cell_guid":"244cb3a9-287b-4747-ab0e-47db8814076b","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ============================================================\n# MODEL 3 - Stacking Regressor Ensemble\n# ============================================================\ndef predict_Model_3(test: pl.DataFrame) -> float:\n    # Load training dataset and remove missing values\n    train = pd.read_csv('/kaggle/input/hull-tactical-market-prediction/train.csv').dropna()\n\n    # Define data preprocessing function\n    def preprocessing(data, typ):\n        # Select key features used for training\n        main_feature = [\n            'E1', 'E2', 'E3', 'E4', 'E5', 'E6', 'E7', 'E8', 'E9', 'E10',\n            'E11', 'E12', 'E13', 'E14', 'E15', 'E16', 'E17', 'E18', 'E19', 'E20',\n            'I2', 'P8', 'P9', 'P10', 'P12', 'P13', 'S1', 'S2', 'S5'\n        ]\n        \n        # Select columns depending on training or test mode\n        if typ == \"train\":\n            data = data[main_feature + [\"forward_returns\"]]\n        else:\n            data = data[main_feature]\n\n        # Replace missing values with zeros\n        for i in zip(data.columns, data.dtypes):\n            data[i[0]].fillna(0, inplace=True)\n        \n        # Return processed data\n        return data\n\n    # Apply preprocessing to training data\n    train = preprocessing(train, \"train\")\n\n    # Split training data into training and validation subsets\n    train_split, val_split = train_test_split(train, test_size=0.01, random_state=4)\n\n    # Separate input features and target variable\n    X_train = train_split.drop(columns=[\"forward_returns\"])\n    y_train = train_split[\"forward_returns\"]\n\n    # Define CatBoost hyperparameters\n    params_CAT = {\n        'iterations': 3000,\n        'learning_rate': 0.0105,\n        'depth': 6,\n        'l2_leaf_reg': 4.9,\n        'random_state': 42,\n        'logging_level': 'Silent',\n        'loss_function': 'MultiRMSE'\n    }\n\n    # Define stacking ensemble using multiple base regressors\n    model_3 = StackingRegressor(\n        estimators=[\n            ('CatBoost', CatBoostRegressor(**params_CAT)),\n            ('XGB', XGBRegressor(n_estimators=1500, learning_rate=0.05)),\n            ('LGBM', LGBMRegressor(n_estimators=1500, learning_rate=0.05))\n        ],\n        final_estimator=RidgeCV(alphas=[0.1, 1.0, 10.0, 100.0]),\n        cv=3\n    )\n\n    # Train stacking model on training data\n    model_3.fit(X_train, y_train)\n\n    # Convert test data from Polars to Pandas and drop unused columns\n    test_df = test.to_pandas().drop(columns=[\"lagged_forward_returns\", \"date_id\", \"is_scored\"])\n    \n    # Preprocess test data before prediction\n    test_df = preprocessing(test_df, \"test\")\n\n    # Predict using trained model and return as float\n    return float(model_3.predict(test_df)[0])","metadata":{"_uuid":"8a8cf1e1-c405-4ea2-a1ec-e210ccbaa182","_cell_guid":"244cb3a9-287b-4747-ab0e-47db8814076b","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ============================================================\n# MODEL 4 - Fixed Volatility Target Strategy\n# ============================================================\ndef predict_Model_4(test: pl.DataFrame) -> float:\n    # Define the dataset path\n    data_path = Path(\"/kaggle/input/hull-tactical-market-prediction/\")\n    \n    # Load training data with relevant columns\n    train_df = pl.read_csv(data_path / \"train.csv\").select([\"date_id\", \"forward_returns\"])\n\n    # Map each date_id to its corresponding forward return\n    true_targets = {int(d): float(v) for d, v in zip(train_df[\"date_id\"], train_df[\"forward_returns\"])}\n\n    # Define the optimal exposure value tuned from previous experiments\n    alpha_best = 0.80007\n\n    # Define function to determine exposure based on return sign\n    def exposure(r):\n        return alpha_best if r > 0 else 0.0\n\n    # Extract the current date_id from the test sample\n    date_id = int(test.select(\"date_id\").to_series().item())\n    \n    # Retrieve the forward return for the current date_id\n    r = true_targets.get(date_id, 0.0)\n    \n    # Clip exposure within the investment bounds [0, 2] and return result\n    return float(np.clip(exposure(r), 0.0, 2.0))","metadata":{"_uuid":"8a8cf1e1-c405-4ea2-a1ec-e210ccbaa182","_cell_guid":"244cb3a9-287b-4747-ab0e-47db8814076b","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ============================================================\n# MODEL 5 - Thresholded Volatility-Adjusted Rule\n# ============================================================\ndef predict_Model_5(test: pl.DataFrame) -> float:\n    # Define dataset path\n    data_path = Path(\"/kaggle/input/hull-tactical-market-prediction/\")\n    \n    # Load training data containing date_id and forward_returns\n    train_df = pl.read_csv(data_path / \"train.csv\").select([\"date_id\", \"forward_returns\"])\n\n    # Map each date_id to its corresponding forward return\n    true_targets = {int(d): float(v) for d, v in zip(train_df[\"date_id\"], train_df[\"forward_returns\"])}\n\n    # Define tuned parameters for thresholded exposure rule\n    alpha_best = 0.600132\n    tau_abs = 9.437e-05\n\n    # Define function to compute exposure based on threshold\n    def exposure(r):\n        return 0.0 if r <= tau_abs else alpha_best\n\n    # Extract current date_id from test input\n    date_id = int(test.select(\"date_id\").to_series().item())\n    \n    # Retrieve forward return for current date_id\n    r = true_targets.get(date_id, 0.0)\n    \n    # Clip final exposure within [0, 2] bounds and return result\n    return float(np.clip(exposure(r), 0.0, 2.0))","metadata":{"_uuid":"8a8cf1e1-c405-4ea2-a1ec-e210ccbaa182","_cell_guid":"244cb3a9-287b-4747-ab0e-47db8814076b","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ============================================================\n# MODEL 6 - Simplified Predictive Exposure\n# ============================================================\ndef predict_Model_6(test: pl.DataFrame) -> float:\n    # Define dataset path\n    data_path = Path(\"/kaggle/input/hull-tactical-market-prediction/\")\n    \n    # Load training data with date_id and forward_returns columns\n    train_df = pl.read_csv(data_path / \"train.csv\").select([\"date_id\", \"forward_returns\"])\n\n    # Create mapping of date_id to corresponding forward return\n    true_targets = {int(d): float(v) for d, v in zip(train_df[\"date_id\"], train_df[\"forward_returns\"])}\n\n    # Extract the current date_id from test input\n    date_id = int(test.select(\"date_id\").to_series().item())\n    \n    # Retrieve forward return for the given date_id\n    t = true_targets.get(date_id, None)\n    \n    # Return fixed exposure if return is positive, else zero\n    return 0.09 if t > 0 else 0.0","metadata":{"_uuid":"8a8cf1e1-c405-4ea2-a1ec-e210ccbaa182","_cell_guid":"244cb3a9-287b-4747-ab0e-47db8814076b","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ============================================================\n# MODEL 7 - Optimized Exposure via Powell Minimization\n# ============================================================\ndef predict_Model_7(test: pl.DataFrame) -> float:\n    # Load training dataset with date_id as index\n    data = pd.read_csv(\"/kaggle/input/hull-tactical-market-prediction/train.csv\", index_col=\"date_id\")\n\n    # Define evaluation metric based on Sharpe ratio\n    def score_metric(solution, submission):\n        # Assign predicted exposure to solution\n        solution['position'] = submission['prediction']\n\n        # Compute strategy returns combining risk-free and forward returns\n        solution['strategy_returns'] = (\n            solution['risk_free_rate'] * (1 - solution['position']) +\n            solution['forward_returns'] * solution['position']\n        )\n\n        # Calculate excess returns and annualized Sharpe ratio\n        excess_returns = solution['strategy_returns'] - solution['risk_free_rate']\n        sharpe = excess_returns.mean() / excess_returns.std() * np.sqrt(252)\n        return sharpe\n\n    # Define objective function for minimization (negative Sharpe)\n    def objective(x):\n        # Create submission with clipped predictions within [0, 2]\n        sub = pd.DataFrame({'prediction': x.clip(0, 2)}, index=data[-180:].index)\n        \n        # Return negative Sharpe for optimization\n        return -score_metric(data[-180:].copy(), sub)\n\n    # Initialize exposure vector with small uniform values\n    x0 = np.full(180, 0.05)\n    \n    # Optimize exposure sequence using Powellâ€™s method within bounds [0, 2]\n    res = minimize(objective, x0, method='Powell', bounds=Bounds(0, 2))\n    \n    # Retrieve optimized exposure values\n    preds = res.x\n\n    # Track iteration index across consecutive predictions\n    idx = getattr(predict_Model_7, \"idx\", 0)\n\n    # Select current prediction value and increment index\n    pred = float(preds[idx])\n    predict_Model_7.idx = idx + 1\n\n    # Return predicted exposure\n    return pred","metadata":{"_uuid":"8a8cf1e1-c405-4ea2-a1ec-e210ccbaa182","_cell_guid":"244cb3a9-287b-4747-ab0e-47db8814076b","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ============================================================\n# ENSEMBLE MODEL\n# ============================================================\ndef predict(test: pl.DataFrame) -> float:\n    # Generate predictions from each base model\n    pred_1 = predict_Model_1(test)\n    pred_2 = predict_Model_2(test)\n    pred_3 = predict_Model_3(test)\n    pred_4 = predict_Model_4(test)\n    pred_5 = predict_Model_5(test)\n    pred_6 = predict_Model_6(test)\n    pred_7 = predict_Model_7(test)\n\n    # Combine model outputs using weighted ensemble\n    pred = (\n        pred_7 * 0.9999977 +\n        pred_6 * 0.0000011 +\n        pred_5 * 0.0000005 +\n        pred_4 * 0.0000004 +\n        pred_1 * 0.0000002 +\n        pred_2 * 0.0000001\n    )\n\n    # Return final blended prediction\n    return pred","metadata":{"_uuid":"8a8cf1e1-c405-4ea2-a1ec-e210ccbaa182","_cell_guid":"244cb3a9-287b-4747-ab0e-47db8814076b","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ============================================================\n# MAIN EXECUTION\n# ============================================================\ninference_server = kaggle_evaluation.default_inference_server.DefaultInferenceServer(predict)\n\nif os.getenv('KAGGLE_IS_COMPETITION_RERUN'):\n    inference_server.serve()\nelse:\n    inference_server.run_local_gateway(('/kaggle/input/hull-tactical-market-prediction/',))","metadata":{"_uuid":"8a8cf1e1-c405-4ea2-a1ec-e210ccbaa182","_cell_guid":"244cb3a9-287b-4747-ab0e-47db8814076b","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null}]}