{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":111543,"databundleVersionId":13750964,"sourceType":"competition"},{"sourceId":13592309,"sourceType":"datasetVersion","datasetId":8635903},{"sourceId":596525,"sourceType":"modelInstanceVersion","modelInstanceId":446699,"modelId":463164}],"dockerImageVersionId":31089,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os, numpy as np, pandas as pd, lightgbm as lgb, pyarrow as pa, pyarrow.parquet as pq\nfrom sklearn.model_selection import TimeSeriesSplit\nfrom sklearn.decomposition import PCA\nfrom sklearn.preprocessing import StandardScaler\nimport optuna\nimport kaggle_evaluation.default_inference_server\nimport warnings\nimport os\nwarnings.filterwarnings('ignore')\n\nprint(\"Available input folders:\", os.listdir(\"/kaggle/input\"))\nprint(\"Contents of my dataset folder:\")\nfor root, dirs, files in os.walk(\"/kaggle/input\"):\n    for f in files:\n        if \"lgb\" in f or \"metadata\" in f:\n            print(os.path.join(root, f))\n\n# CONFIG \nTARGET_COL = \"market_forward_excess_returns\"\n\n# Paths for SAVING (Training Notebook - /kaggle/working/)\nMODEL_SAVE_PATH_MOM = \"/kaggle/working/lgb_model_mom.txt\"\nMODEL_SAVE_PATH_REV = \"/kaggle/working/lgb_model_rev.txt\"\nMODEL_SAVE_PATH_VOL = \"/kaggle/working/lgb_model_vol.txt\"\nMETADATA_SAVE_PATH = \"/kaggle/working/model_metadata.npy\"\n\n# Paths for LOADING (Submission Notebook - /kaggle/input/<dataset-name>/)\nMODEL_LOAD_DIR =  \"/kaggle/input/hull-lgb-trained-models\"\nMODEL_LOAD_PATH_MOM = f\"{MODEL_LOAD_DIR}/lgb_model_mom.txt\"\nMODEL_LOAD_PATH_REV = f\"{MODEL_LOAD_DIR}/lgb_model_rev.txt\"\nMODEL_LOAD_PATH_VOL = f\"{MODEL_LOAD_DIR}/lgb_model_vol.txt\"\nMETADATA_LOAD_PATH = f\"{MODEL_LOAD_DIR}/model_metadata.npy\"\n\nTARGET_VOL, _model_mom, _model_rev, _model_vol, _initialized, _metadata = None, None, None, None, False, None\nMIN_INVESTMENT, MAX_INVESTMENT = 0, 2\nUSE_OPTUNA = False  # Set to True for hyperparameter tuning (slower but better)\nN_CV_FOLDS = 10  # Increased from 5\nOPTUNA_TRIALS = 30  # Number of hyperparameter trials (reduced for speed)\n\n\n# CUSTOM EVALUATION METRIC \nclass ParticipantVisibleError(Exception): pass\n\ndef score(solution: pd.DataFrame, submission: pd.DataFrame, row_id_column_name: str) -> float:\n    if not pd.api.types.is_numeric_dtype(submission['prediction']):\n        raise ParticipantVisibleError('Predictions must be numeric')\n    solution = solution.copy()\n    solution['position'] = submission['prediction']\n    if solution['position'].max() > MAX_INVESTMENT:\n        raise ParticipantVisibleError(f'Position {solution[\"position\"].max()} exceeds max {MAX_INVESTMENT}')\n    if solution['position'].min() < MIN_INVESTMENT:\n        raise ParticipantVisibleError(f'Position {solution[\"position\"].min()} below min {MIN_INVESTMENT}')\n    solution['strategy_returns'] = solution['risk_free_rate'] * (1 - solution['position']) + \\\n                                   solution['position'] * solution['forward_returns']\n    strat_excess = solution['strategy_returns'] - solution['risk_free_rate']\n    strat_cum = (1 + strat_excess).prod()\n    strat_mean = strat_cum ** (1 / len(solution)) - 1\n    strat_std = solution['strategy_returns'].std()\n    if strat_std == 0: raise ParticipantVisibleError('Division by zero, strategy std is zero')\n    trading_days = 252\n    sharpe = strat_mean / strat_std * np.sqrt(trading_days)\n    strat_vol = float(strat_std * np.sqrt(trading_days) * 100)\n    mkt_excess = solution['forward_returns'] - solution['risk_free_rate']\n    mkt_cum = (1 + mkt_excess).prod()\n    mkt_mean = mkt_cum ** (1 / len(solution)) - 1\n    mkt_std = solution['forward_returns'].std()\n    if mkt_std == 0: raise ParticipantVisibleError('Division by zero, market std is zero')\n    mkt_vol = float(mkt_std * np.sqrt(trading_days) * 100)\n    excess_vol = max(0, strat_vol / mkt_vol - 1.2) if mkt_vol > 0 else 0\n    vol_penalty = 1 + excess_vol\n    return_gap = max(0, (mkt_mean - strat_mean) * 100 * trading_days)\n    return_penalty = 1 + (return_gap ** 2) / 100\n    adj_sharpe = sharpe / (vol_penalty * return_penalty)\n    return min(float(adj_sharpe), 1_000_000)\n\n\n# ENHANCED FEATURE ENGINEERING \ndef calculate_rsi(series, period=14):\n    \"\"\"Calculate Relative Strength Index\"\"\"\n    delta = series.diff()\n    gain = (delta.where(delta > 0, 0)).rolling(window=period).mean()\n    loss = (-delta.where(delta < 0, 0)).rolling(window=period).mean()\n    rs = gain / loss\n    rsi = 100 - (100 / (1 + rs))\n    return rsi\n\ndef calculate_macd(series, fast=12, slow=26, signal=9):\n    \"\"\"Calculate MACD indicators\"\"\"\n    ema_fast = series.ewm(span=fast).mean()\n    ema_slow = series.ewm(span=slow).mean()\n    macd = ema_fast - ema_slow\n    macd_signal = macd.ewm(span=signal).mean()\n    macd_hist = macd - macd_signal\n    return macd, macd_signal, macd_hist\n\ndef feature_engineer(df, is_inference=False, feature_importance=None, top_n_features=None):\n    df = df.sort_values(\"date_id\").reset_index(drop=True).copy()\n    \n    # Identify base features\n    base_feats = [c for c in df.columns \n                  if c not in [\"date_id\", \"risk_free_rate\", \"forward_returns\", TARGET_COL, \"target\"]]\n    \n    feature_dict = {}\n    \n    # For each base feature, create technical indicators\n    for c in base_feats:\n        # Basic lags (reduced from [1,2,5,10] to [1,5,10])\n        for lag in [1, 5, 10]:\n            feature_dict[f\"{c}_lag_{lag}\"] = df[c].shift(lag).values\n        \n        # Rolling statistics (more selective)\n        for w in [5, 10, 20]:\n            feature_dict[f\"{c}_ma_{w}\"] = df[c].shift(1).rolling(w).mean().values\n            feature_dict[f\"{c}_std_{w}\"] = df[c].shift(1).rolling(w).std().values\n        \n        # Technical indicators\n        feature_dict[f\"{c}_rsi_14\"] = calculate_rsi(df[c], 14).values\n        \n        macd, macd_sig, macd_hist = calculate_macd(df[c])\n        feature_dict[f\"{c}_macd\"] = macd.values\n        feature_dict[f\"{c}_macd_signal\"] = macd_sig.values\n        feature_dict[f\"{c}_macd_hist\"] = macd_hist.values\n        \n        # Momentum indicators\n        for period in [5, 10, 20]:\n            feature_dict[f\"{c}_mom_{period}\"] = (df[c] / df[c].shift(period) - 1).values\n        \n        # Volatility\n        for w in [5, 10, 20]:\n            feature_dict[f\"{c}_vol_{w}\"] = df[c].shift(1).rolling(w).std().values\n        \n        # Rate of change\n        feature_dict[f\"{c}_roc_5\"] = (df[c] - df[c].shift(5)) / df[c].shift(5).values\n    \n    # Combine all features\n    feat_df = pd.DataFrame(feature_dict, index=df.index)\n    df = pd.concat([df, feat_df], axis=1)\n    \n    # Handle inf and nan\n    df = df.replace([np.inf, -np.inf], np.nan)\n    df = df.ffill().bfill()\n    \n    # Feature selection based on importance (if available)\n    if feature_importance is not None and top_n_features is not None and not is_inference:\n        feature_cols = [c for c in df.columns if c not in base_feats + \n                               [\"date_id\", \"risk_free_rate\", \"forward_returns\", TARGET_COL, \"target\"]]\n        \n        # Keep only top features\n        top_features = feature_importance.nlargest(top_n_features).index.tolist()\n        keep_cols = base_feats + [\"date_id\", \"risk_free_rate\", \"forward_returns\", TARGET_COL, \"target\"] + top_features\n        df = df[[c for c in keep_cols if c in df.columns]]\n    \n    return df\n\ndef remove_correlated_features(X, threshold=0.95):\n    \"\"\"Remove highly correlated features\"\"\"\n    corr_matrix = X.corr().abs()\n    upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n    to_drop = [column for column in upper.columns if any(upper[column] > threshold)]\n    print(f\"  Removing {len(to_drop)} highly correlated features (threshold={threshold})\")\n    return X.drop(columns=to_drop), to_drop\n\n# HYPERPARAMETER OPTIMIZATION \ndef objective(trial, X, y, features, tscv):\n    \"\"\"Optuna objective function for hyperparameter tuning\"\"\"\n    params = {\n        'n_estimators': trial.suggest_int('n_estimators', 200, 600),\n        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.08, log=True),\n        'num_leaves': trial.suggest_int('num_leaves', 31, 127),\n        'min_child_samples': trial.suggest_int('min_child_samples', 20, 100),\n        'subsample': trial.suggest_float('subsample', 0.6, 1.0),\n        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 1.0),\n        'reg_alpha': trial.suggest_float('reg_alpha', 0.0, 0.5),\n        'reg_lambda': trial.suggest_float('reg_lambda', 0.0, 0.5),\n        'max_depth': trial.suggest_int('max_depth', 4, 8),\n        'verbose': -1,\n        'random_state': 42\n    }\n    \n    cv_scores = []\n    for tr_i, va_i in tscv.split(X):\n        Xtr, Xva = X.iloc[tr_i], X.iloc[va_i]\n        ytr, yva = y.iloc[tr_i], y.iloc[va_i]\n        \n        model = lgb.LGBMRegressor(**params)\n        model.fit(Xtr[features], ytr, \n                  eval_set=[(Xva[features], yva)],\n                  callbacks=[lgb.early_stopping(30, verbose=False)])\n        \n        pred = model.predict(Xva[features])\n        # Use correlation as optimization target (better than MSE for this task)\n        corr = np.corrcoef(pred, yva)[0, 1]\n        cv_scores.append(corr)\n    \n    return np.mean(cv_scores)\n\n# OPTIMIZE ENSEMBLE WEIGHTS \ndef optimize_ensemble_weights(predictions_dict, y_true, forward_returns, risk_free_rate):\n    \"\"\"Find optimal ensemble weights via grid search\"\"\"\n    best_sharpe = -np.inf\n    best_weights = (0.5, 0.3, 0.2)  # Default fallback\n    best_scale = 5  # Default fallback\n    \n    # Convert to numpy arrays\n    pred_mom = np.array(predictions_dict['mom'])\n    pred_rev = np.array(predictions_dict['rev'])\n    pred_vol = np.array(predictions_dict['vol'])\n    forward_returns = np.array(forward_returns)\n    risk_free_rate = np.array(risk_free_rate)\n    \n    print(\"  Testing weight combinations...\")\n    tested = 0\n    successful = 0\n    \n    # Grid search over weights and scaling factor\n    for w1 in np.linspace(0.3, 0.7, 9):\n        for w2 in np.linspace(0.1, 0.5, 9):\n            w3 = 1 - w1 - w2\n            if w3 < 0.1 or w3 > 0.6:\n                continue\n            \n            for scale in [3, 4, 5, 6, 7, 8, 9, 10]:\n                tested += 1\n                try:\n                    p = w1 * pred_mom + w2 * pred_rev + w3 * pred_vol\n                    pred = np.clip(1 + np.tanh(p * scale), 0, 2)\n                    \n                    sol = pd.DataFrame({\n                        'forward_returns': forward_returns,\n                        'risk_free_rate': risk_free_rate,\n                        'prediction': pred\n                    })\n                    \n                    s = score(sol, sol, row_id_column_name=\"date_id\")\n                    successful += 1\n                    \n                    if s > best_sharpe:\n                        best_sharpe = s\n                        best_weights = (w1, w2, w3)\n                        best_scale = scale\n                except Exception as e:\n                    continue\n    \n    print(f\"  Tested {tested} combinations, {successful} successful\")\n    return best_weights, best_scale, best_sharpe\n\n# TRAIN MODEL\ndef train_model():\n    global TARGET_VOL\n    print(\"\\n\" + \"=\"*70)\n    print(\"ENHANCED TRAINING PIPELINE - OPTIMIZATION MODE\")\n    print(\"=\"*70)\n    \n    print(\"\\n\" + \"=\"*70)\n    print(\"LOADING DATA\")\n    print(\"=\"*70)\n    tr = pd.read_csv(\"/kaggle/input/hull-tactical-market-prediction/train.csv\").dropna()\n    te = pd.read_csv(\"/kaggle/input/hull-tactical-market-prediction/test.csv\").dropna()\n    print(f\"Training samples: {len(tr)}\")\n    print(f\"Test samples: {len(te)}\")\n    \n    TARGET_VOL = tr[\"forward_returns\"].std()\n    print(f\"Target volatility: {TARGET_VOL:.6f}\")\n    \n    tr[\"target\"] = tr[TARGET_COL].shift(-1)\n    tr = tr.dropna(subset=[\"target\"])\n    \n    print(\"\\n\" + \"=\"*70)\n    print(\"ENHANCED FEATURE ENGINEERING\")\n    print(\"=\"*70)\n    tr = feature_engineer(tr)\n    print(f\"Total features created: {len(tr.columns)}\")\n    \n    X = tr.drop(columns=[\"target\", TARGET_COL, \"date_id\", \"forward_returns\", \"risk_free_rate\"], errors='ignore')\n    y = tr[\"target\"]\n    \n    # Remove highly correlated features\n    X, dropped_corr = remove_correlated_features(X, threshold=0.95)\n    print(f\"Features after correlation removal: {len(X.columns)}\")\n    \n    # Separate feature types\n    mom_features = [c for c in X.columns if any(x in c for x in ['_lag_', '_ma_', '_mom_', '_roc_'])]\n    vol_features = [c for c in X.columns if any(x in c for x in ['_std_', '_vol_', '_rsi_'])]\n    rev_features = [c for c in X.columns if any(x in c for x in ['_macd'])]\n    \n    # Add remaining to reversal\n    used = set(mom_features + vol_features + rev_features)\n    rev_features += [c for c in X.columns if c not in used]\n    \n    print(f\"Momentum features: {len(mom_features)}\")\n    print(f\"Volatility features: {len(vol_features)}\")\n    print(f\"Reversal features: {len(rev_features)}\")\n    \n    # Cross-validation setup\n    print(\"\\n\" + \"=\"*70)\n    print(f\"TIME SERIES CROSS-VALIDATION ({N_CV_FOLDS} Folds)\")\n    print(\"=\"*70)\n    \n    tscv = TimeSeriesSplit(n_splits=N_CV_FOLDS)\n    \n    # Hyperparameter tuning with Optuna\n    best_params_mom, best_params_rev, best_params_vol = None, None, None\n    \n    if USE_OPTUNA:\n        print(\"\\nOptimizing hyperparameters with Optuna...\")\n        print(\"(This may take several minutes...)\")\n        \n        # Tune momentum model\n        print(\"  Tuning Momentum model...\")\n        study_mom = optuna.create_study(direction='maximize', sampler=optuna.samplers.TPESampler(seed=42))\n        study_mom.optimize(lambda trial: objective(trial, X, y, mom_features, TimeSeriesSplit(n_splits=3)), \n                           n_trials=OPTUNA_TRIALS, show_progress_bar=False)\n        best_params_mom = study_mom.best_params\n        print(f\"    Best correlation: {study_mom.best_value:.6f}\")\n        \n        # Tune reversal model\n        print(\"  Tuning Reversal model...\")\n        study_rev = optuna.create_study(direction='maximize', sampler=optuna.samplers.TPESampler(seed=43))\n        study_rev.optimize(lambda trial: objective(trial, X, y, rev_features, TimeSeriesSplit(n_splits=3)), \n                           n_trials=OPTUNA_TRIALS, show_progress_bar=False)\n        best_params_rev = study_rev.best_params\n        print(f\"    Best correlation: {study_rev.best_value:.6f}\")\n        \n        # Tune volatility model\n        print(\"  Tuning Volatility model...\")\n        study_vol = optuna.create_study(direction='maximize', sampler=optuna.samplers.TPESampler(seed=44))\n        study_vol.optimize(lambda trial: objective(trial, X, y, vol_features, TimeSeriesSplit(n_splits=3)), \n                           n_trials=OPTUNA_TRIALS, show_progress_bar=False)\n        best_params_vol = study_vol.best_params\n        print(f\"    Best correlation: {study_vol.best_value:.6f}\")\n    else:\n        # Default improved parameters with better regularization\n        best_params_mom = {\n            'n_estimators': 400, 'learning_rate': 0.03, 'num_leaves': 64, \n            'min_child_samples': 30, 'subsample': 0.8, 'colsample_bytree': 0.8,\n            'reg_alpha': 0.1, 'reg_lambda': 0.1, 'max_depth': 6, \n            'verbose': -1, 'random_state': 42\n        }\n        best_params_rev = {\n            'n_estimators': 400, 'learning_rate': 0.03, 'num_leaves': 64,\n            'min_child_samples': 30, 'subsample': 0.8, 'colsample_bytree': 0.8,\n            'reg_alpha': 0.1, 'reg_lambda': 0.1, 'max_depth': 6,\n            'verbose': -1, 'random_state': 43\n        }\n        best_params_vol = {\n            'n_estimators': 400, 'learning_rate': 0.03, 'num_leaves': 64,\n            'min_child_samples': 30, 'subsample': 0.8, 'colsample_bytree': 0.8,\n            'reg_alpha': 0.1, 'reg_lambda': 0.1, 'max_depth': 6,\n            'verbose': -1, 'random_state': 44\n        }\n    \n    # Cross-validation with optimized models\n    print(\"\\nRunning full cross-validation...\")\n    scores = []\n    fold_predictions_all = []\n    fold_actuals_all = []\n    all_preds_dict = {'mom': [], 'rev': [], 'vol': []}\n    all_forward_returns = []\n    all_risk_free_rate = []\n    \n    for fold, (tr_i, va_i) in enumerate(tscv.split(X), 1):\n        Xtr, Xva = X.iloc[tr_i], X.iloc[va_i]\n        ytr, yva = y.iloc[tr_i], y.iloc[va_i]\n        \n        m1 = lgb.LGBMRegressor(**best_params_mom)\n        m2 = lgb.LGBMRegressor(**best_params_rev)\n        m3 = lgb.LGBMRegressor(**best_params_vol)\n        \n        m1.fit(Xtr[mom_features], ytr, eval_set=[(Xva[mom_features], yva)],\n              callbacks=[lgb.early_stopping(30, verbose=False)])\n        m2.fit(Xtr[rev_features], ytr, eval_set=[(Xva[rev_features], yva)],\n              callbacks=[lgb.early_stopping(30, verbose=False)])\n        m3.fit(Xtr[vol_features], ytr, eval_set=[(Xva[vol_features], yva)],\n              callbacks=[lgb.early_stopping(30, verbose=False)])\n        \n        p1 = m1.predict(Xva[mom_features])\n        p2 = m2.predict(Xva[rev_features])\n        p3 = m3.predict(Xva[vol_features])\n        \n        all_preds_dict['mom'].extend(p1)\n        all_preds_dict['rev'].extend(p2)\n        all_preds_dict['vol'].extend(p3)\n        all_forward_returns.extend(tr.iloc[va_i]['forward_returns'].values)\n        all_risk_free_rate.extend(tr.iloc[va_i]['risk_free_rate'].values)\n        \n        # Use default weights for fold scoring\n        p = 0.5 * p1 + 0.3 * p2 + 0.2 * p3\n        pred = np.clip(1 + np.tanh(p * 5), 0, 2)\n        \n        fold_predictions_all.extend(pred)\n        fold_actuals_all.extend(yva.values)\n        \n        sol = tr.iloc[va_i][[\"forward_returns\", \"risk_free_rate\"]].copy()\n        sol[\"prediction\"] = pred\n        \n        try:\n            s = score(sol, sol, row_id_column_name=\"date_id\")\n            scores.append(s)\n            print(f\"  Fold {fold:2d} - Adjusted Sharpe: {s:.6f}\")\n        except Exception as e:\n            scores.append(0)\n            print(f\"  Fold {fold:2d} - Error: {e}\")\n    \n    # Optimize ensemble weights\n    print(\"\\n\" + \"=\"*70)\n    print(\"OPTIMIZING ENSEMBLE WEIGHTS\")\n    print(\"=\"*70)\n    best_weights, best_scale, opt_sharpe = optimize_ensemble_weights(\n        all_preds_dict, fold_actuals_all, all_forward_returns, all_risk_free_rate\n    )\n    print(f\"Optimal weights: Mom={best_weights[0]:.3f}, Rev={best_weights[1]:.3f}, Vol={best_weights[2]:.3f}\")\n    print(f\"Optimal scaling factor: {best_scale}\")\n    print(f\"Optimized Sharpe: {opt_sharpe:.6f}\")\n    \n    # Calculate metrics with optimized weights\n    fold_predictions_all = np.array(fold_predictions_all)\n    fold_actuals_all = np.array(fold_actuals_all)\n    \n    mae = np.mean(np.abs(fold_predictions_all - fold_actuals_all))\n    rmse = np.sqrt(np.mean((fold_predictions_all - fold_actuals_all) ** 2))\n    correlation = np.corrcoef(fold_predictions_all, fold_actuals_all)[0, 1]\n    r2 = 1 - (np.sum((fold_actuals_all - fold_predictions_all) ** 2) / \n              np.sum((fold_actuals_all - fold_actuals_all.mean()) ** 2))\n    \n    # print(\"\\n\" + \"=\"*70)\n    # print(\"CROSS-VALIDATION SUMMARY\")\n    # print(\"=\"*70)\n    # print(f\"Mean Adjusted Sharpe:        {np.mean(scores):.6f} ± {np.std(scores):.6f}\")\n    # print(f\"Best Fold Sharpe:            {np.max(scores):.6f}\")\n    # print(f\"Worst Fold Sharpe:           {np.min(scores):.6f}\")\n    # print(f\"\\nPrediction Quality Metrics:\")\n    # print(f\"  MAE (Position Error):      {mae:.6f}\")\n    # print(f\"  RMSE (Position Error):     {rmse:.6f}\")\n    # print(f\"  R² Score:                  {r2:.6f}\")\n    # print(f\"  Correlation (Pred/Actual): {correlation:.6f}\")\n    # print(f\"\\nPosition Statistics:\")\n    # print(f\"  Mean Position:             {fold_predictions_all.mean():.4f}\")\n    # print(f\"  Position Std Dev:          {fold_predictions_all.std():.4f}\")\n    # print(f\"  Min Position:              {fold_predictions_all.min():.4f}\")\n    # print(f\"  Max Position:              {fold_predictions_all.max():.4f}\")\n    \n    # Train final models\n    print(\"\\n\" + \"=\"*70)\n    print(\"TRAINING FINAL MODELS ON FULL DATA\")\n    print(\"=\"*70)\n    \n    m1 = lgb.LGBMRegressor(**best_params_mom)\n    m2 = lgb.LGBMRegressor(**best_params_rev)\n    m3 = lgb.LGBMRegressor(**best_params_vol)\n    \n    m1.fit(X[mom_features], y)\n    m2.fit(X[rev_features], y)\n    m3.fit(X[vol_features], y)\n    \n    # Save to /kaggle/working/\n    m1.booster_.save_model(MODEL_SAVE_PATH_MOM)\n    m2.booster_.save_model(MODEL_SAVE_PATH_REV)\n    m3.booster_.save_model(MODEL_SAVE_PATH_VOL)\n    print(\"✓ All models saved successfully to /kaggle/working/!\")\n    \n    # Save metadata for inference\n    metadata = {\n        'best_weights': best_weights,\n        'best_scale': best_scale,\n        'dropped_corr': dropped_corr,\n        'mom_features': mom_features,\n        'rev_features': rev_features,\n        'vol_features': vol_features\n    }\n    np.save(METADATA_SAVE_PATH, metadata)\n    print(\"✓ Metadata saved successfully to /kaggle/working/model_metadata.npy\")\n\n    # The rest of the logic for local testing is kept, but it's optional for the Training Notebook\n    if not os.getenv(\"KAGGLE_IS_COMPETITION_RERUN\"):\n        # Test predictions\n        te = feature_engineer(te, is_inference=True)\n        X_test = te.drop(columns=[\"date_id\", \"forward_returns\", \"risk_free_rate\"], errors='ignore')\n        X_test = X_test[[c for c in X_test.columns if c not in dropped_corr]]\n        \n        pt = np.clip(1 + np.tanh((best_weights[0] * m1.predict(X_test[mom_features]) + \n                                  best_weights[1] * m2.predict(X_test[rev_features]) + \n                                  best_weights[2] * m3.predict(X_test[vol_features])) * best_scale), 0, 2)\n        \n        # print(\"\\n\" + \"=\"*70)\n        # print(\"TEST SET PREDICTIONS\")\n        # print(\"=\"*70)\n        # print(f\"Predictions generated:         {len(pt)}\")\n        # print(f\"Mean test position:          {pt.mean():.4f}\")\n        # print(f\"Test position std:           {pt.std():.4f}\")\n        # print(f\"Min test position:           {pt.min():.4f}\")\n        # print(f\"Max test position:           {pt.max():.4f}\")\n        \n        sub = pd.DataFrame({\"date_id\": te[\"date_id\"].astype(\"int64\"), TARGET_COL: pt})\n        pq.write_table(\n            pa.Table.from_pandas(sub, schema=pa.schema([(\"date_id\", pa.int64()), (TARGET_COL, pa.float64())])),\n            \"/kaggle/working/submission.parquet\"\n        )\n        \n        print(\"\\n✓ Submission file created: /kaggle/working/submission.parquet\")\n    \n    print(\"=\"*70 + \"\\n\")\n    \n    return m1, m2, m3\n\n\n# PREDICT FUNCTION \ndef _safe_load_model():\n    \"\"\"Loads models and metadata from the specified Kaggle Input path.\"\"\"\n    global _initialized, _model_mom, _model_rev, _model_vol, _metadata\n    if _initialized:\n        return _model_mom, _model_rev, _model_vol, _metadata\n\n    print(f\"Loading models from: {MODEL_LOAD_DIR}\")\n    _model_mom = lgb.Booster(model_file=MODEL_LOAD_PATH_MOM)\n    _model_rev = lgb.Booster(model_file=MODEL_LOAD_PATH_REV)\n    _model_vol = lgb.Booster(model_file=MODEL_LOAD_PATH_VOL)\n    \n    _metadata = np.load(METADATA_LOAD_PATH, allow_pickle=True).item()\n    \n    _initialized = True\n    print(\"Models and metadata loaded successfully.\")\n    return _model_mom, _model_rev, _model_vol, _metadata\n\ndef predict(test):\n    \"\"\"The function used by the inference server to generate a single prediction.\"\"\"\n    df = test.to_pandas()\n    # Load models and metadata from the input path\n    m1, m2, m3, metadata = _safe_load_model()\n    \n    # Apply feature engineering\n    df = feature_engineer(df, is_inference=True)\n    \n    # Drop correlated features as recorded in metadata\n    df = df[[c for c in df.columns if c not in metadata['dropped_corr']]]\n    \n    # Select features for each model\n    X_m = df[metadata['mom_features']]\n    X_r = df[metadata['rev_features']]\n    X_v = df[metadata['vol_features']]\n    \n    # Ensemble prediction\n    p = (metadata['best_weights'][0] * m1.predict(X_m) + \n         metadata['best_weights'][1] * m2.predict(X_r) + \n         metadata['best_weights'][2] * m3.predict(X_v))\n    \n    # Apply scaling and clipping to get the final allocation\n    alloc = float(np.clip(1 + np.tanh(p[-1] * metadata['best_scale']), 0, 2))\n    return alloc\n\n# ENTRY POINT \nif __name__ == \"__main__\":\n    if not os.getenv(\"KAGGLE_IS_COMPETITION_RERUN\"):\n        # Training Notebook (Offline Run)\n        print(\"Running in TRAINING Mode...\")\n        train_model()\n        print(\"Local run complete. Save this notebook's output as a dataset.\")\n    else:\n        # Submission Notebook (Inference Only Run)\n        # This will load the models and metadata from the mounted dataset path (MODEL_LOAD_DIR)\n        print(\"Running in INFERENCE Mode...\")\n        kaggle_evaluation.default_inference_server.DefaultInferenceServer(predict).serve()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-03T04:04:12.739289Z","iopub.execute_input":"2025-11-03T04:04:12.744254Z","iopub.status.idle":"2025-11-03T04:05:02.512615Z","shell.execute_reply.started":"2025-11-03T04:04:12.744188Z","shell.execute_reply":"2025-11-03T04:05:02.511205Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}