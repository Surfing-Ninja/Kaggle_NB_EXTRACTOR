{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":111543,"databundleVersionId":13750964,"sourceType":"competition"}],"dockerImageVersionId":31089,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"%%time\nimport os\nimport numpy as np\nimport pandas as pd\nimport polars as pl\n\nfrom sklearn.linear_model import Ridge , LinearRegression\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler , FunctionTransformer\nfrom sklearn.ensemble import RandomForestRegressor, StackingRegressor , BaggingRegressor\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.linear_model import LinearRegression, Ridge\nfrom sklearn.svm import SVR\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom xgboost import XGBRegressor\nfrom lightgbm import LGBMRegressor\n\nimport kaggle_evaluation.default_inference_server","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-15T13:11:01.336209Z","iopub.execute_input":"2025-10-15T13:11:01.336528Z","iopub.status.idle":"2025-10-15T13:11:14.992483Z","shell.execute_reply.started":"2025-10-15T13:11:01.336501Z","shell.execute_reply":"2025-10-15T13:11:14.991333Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train = pd.read_csv(\"/kaggle/input/hull-tactical-market-prediction/train.csv\")\ntest = pd.read_csv(\"/kaggle/input/hull-tactical-market-prediction/test.csv\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-15T13:11:14.99451Z","iopub.execute_input":"2025-10-15T13:11:14.995299Z","iopub.status.idle":"2025-10-15T13:11:15.380457Z","shell.execute_reply.started":"2025-10-15T13:11:14.995263Z","shell.execute_reply":"2025-10-15T13:11:15.379103Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Pre processing","metadata":{}},{"cell_type":"code","source":"print(\"columns ONLY in train before adjusting lags risk free and exc frw ret\\n\")\n\nfor c in train.columns:\n    if c not in test.columns:\n        print(c)\n\nprint(\"\\ncolumns ONLY in test before adjusting lags risk free and exc frw ret\\n\")\n\nfor c in test.columns:\n    if c not in train.columns:\n        print(c)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-15T13:11:15.381947Z","iopub.execute_input":"2025-10-15T13:11:15.38233Z","iopub.status.idle":"2025-10-15T13:11:15.394637Z","shell.execute_reply.started":"2025-10-15T13:11:15.382287Z","shell.execute_reply":"2025-10-15T13:11:15.393427Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Create lagged columns\ntrain[\"lagged_forward_returns\"] = train[\"forward_returns\"].shift(1)\ntrain[\"lagged_risk_free_rate\"] = train[\"risk_free_rate\"].shift(1)\ntrain[\"lagged_market_forward_excess_returns\"] = train[\"market_forward_excess_returns\"].shift(1)\n\ntarget = \"market_forward_excess_returns\"\nexclude_cols = [\"date_id\", target]\nfeatures = [c for c in train.columns if c not in exclude_cols]\n\nX = train[features]\ny = train[target]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-15T13:11:15.396311Z","iopub.execute_input":"2025-10-15T13:11:15.396629Z","iopub.status.idle":"2025-10-15T13:11:15.435445Z","shell.execute_reply.started":"2025-10-15T13:11:15.396605Z","shell.execute_reply":"2025-10-15T13:11:15.43426Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"columns ONLY in train after adjusting lags risk free and exc frw ret\\n\")\n\nfor c in train.columns:\n    if c not in test.columns:\n        print(c)\n\nprint(\"\\ncolumns ONLY in test after adjusting lags risk free and exc frw ret\\n\")\n\nfor c in test.columns:\n    if c not in train.columns:\n        print(c)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-15T13:11:15.438158Z","iopub.execute_input":"2025-10-15T13:11:15.438452Z","iopub.status.idle":"2025-10-15T13:11:15.446004Z","shell.execute_reply.started":"2025-10-15T13:11:15.438431Z","shell.execute_reply":"2025-10-15T13:11:15.445107Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"target = \"forward_returns\" \n\nx = train.drop(columns = [target])\ny = train[target]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-15T13:11:15.44721Z","iopub.execute_input":"2025-10-15T13:11:15.447588Z","iopub.status.idle":"2025-10-15T13:11:15.474219Z","shell.execute_reply.started":"2025-10-15T13:11:15.447552Z","shell.execute_reply":"2025-10-15T13:11:15.473019Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"columns ONLY in X after adjusting lags risk free and exc frw ret\\n\")\n\nfor c in x.columns:\n    if c not in test.columns:\n        print(c)\n\nprint(\"\\ncolumns ONLY in test after adjusting lags risk free and exc frw ret\\n\")\n\nfor c in test.columns:\n    if c not in x.columns:\n        print(c)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-15T13:11:15.475278Z","iopub.execute_input":"2025-10-15T13:11:15.475555Z","iopub.status.idle":"2025-10-15T13:11:15.484076Z","shell.execute_reply.started":"2025-10-15T13:11:15.475534Z","shell.execute_reply":"2025-10-15T13:11:15.482789Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"x = x.drop(columns = [ \"risk_free_rate\" , \"market_forward_excess_returns\" ])\ntest = test.drop(columns = [\"is_scored\"])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-15T13:11:15.485443Z","iopub.execute_input":"2025-10-15T13:11:15.485817Z","iopub.status.idle":"2025-10-15T13:11:15.515764Z","shell.execute_reply.started":"2025-10-15T13:11:15.485789Z","shell.execute_reply":"2025-10-15T13:11:15.514605Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"columns ONLY in X after adjusting lags risk free and exc frw ret\\n\")\n\nfor c in x.columns:\n    if c not in test.columns:\n        print(c)\n\nprint(\"\\ncolumns ONLY in test after adjusting lags risk free and exc frw ret\\n\")\n\nfor c in test.columns:\n    if c not in x.columns:\n        print(c)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-15T13:11:15.51686Z","iopub.execute_input":"2025-10-15T13:11:15.517228Z","iopub.status.idle":"2025-10-15T13:11:15.5267Z","shell.execute_reply.started":"2025-10-15T13:11:15.517194Z","shell.execute_reply":"2025-10-15T13:11:15.525565Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# feature engineering","metadata":{}},{"cell_type":"code","source":"def create_lags(data, lags):\n    \"\"\"\n    Create lag features for a pandas Series or list.\n\n    Parameters:\n    -----------\n    data : pd.Series or list-like\n        The original time-series data.\n    lags : int or list of ints\n        Lag values (e.g., 1 or [1, 2, 7]).\n\n    Returns:\n    --------\n    pd.DataFrame\n        Columns named 'lag_{n}' with shifted values.\n    \"\"\"\n    s = pd.Series(data).reset_index(drop=True)\n    lags = [lags] if isinstance(lags, int) else lags\n    lag_df = pd.DataFrame({f'lag_{n}': s.shift(n) for n in lags})\n    return lag_df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-15T13:11:15.528422Z","iopub.execute_input":"2025-10-15T13:11:15.528813Z","iopub.status.idle":"2025-10-15T13:11:15.555724Z","shell.execute_reply.started":"2025-10-15T13:11:15.528774Z","shell.execute_reply":"2025-10-15T13:11:15.554651Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def create_rolling_features(data, windows, functions=['mean']):\n    \"\"\"\n    Create rolling window features for a pd.Series or list.\n\n    Parameters:\n    -----------\n    data : pd.Series or list-like\n    windows : int or list of ints\n        Window sizes (e.g., 3 or [3, 7]).\n    functions : str or list of str\n        Aggregations to compute: 'mean', 'max', 'min', 'std', etc.\n\n    Returns:\n    --------\n    pd.DataFrame\n        Columns like 'roll_{func}_{w}'.\n    \"\"\"\n    s = pd.Series(data).reset_index(drop=True)\n    windows = [windows] if isinstance(windows, int) else windows\n    functions = [functions] if isinstance(functions, str) else functions\n\n    df = pd.DataFrame()\n    for w in windows:\n        rolled = s.rolling(window=w)\n        for func in functions:\n            if hasattr(rolled, func):\n                df[f'roll_{func}_{w}'] = getattr(rolled, func)()\n            else:\n                raise ValueError(f\"Unsupported function: {func}\")\n    return df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-15T13:11:15.556791Z","iopub.execute_input":"2025-10-15T13:11:15.557144Z","iopub.status.idle":"2025-10-15T13:11:15.581107Z","shell.execute_reply.started":"2025-10-15T13:11:15.557114Z","shell.execute_reply":"2025-10-15T13:11:15.579914Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def create_diff_features(data, lags):\n    \"\"\"\n    Create difference-from-past features.\n\n    Parameters:\n    - data: pd.Series, list, or DataFrame column\n    - lags: int or list of ints\n\n    Returns:\n    - pd.DataFrame with difference features\n    \"\"\"\n    if isinstance(data, list):\n        data = pd.Series(data)\n    if isinstance(lags, int):\n        lags = [lags]\n\n    diff_df = pd.DataFrame()\n    for lag in lags:\n        diff_df[f'diff_{lag}'] = data.diff(lag)\n\n    return diff_df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-15T13:11:15.58214Z","iopub.execute_input":"2025-10-15T13:11:15.582478Z","iopub.status.idle":"2025-10-15T13:11:15.612511Z","shell.execute_reply.started":"2025-10-15T13:11:15.582445Z","shell.execute_reply":"2025-10-15T13:11:15.611261Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def prepare_features_for_col(\n    col, \n    col_name, \n    lag_values=None,\n    win_values=None,\n    win_methods=None,\n    diff_values=None,\n    is_a_target = False\n):\n    \"\"\"\n    Generate lag, rolling window, and difference features for a single column.\n    \n    Parameters:\n    ----------\n    col : list, pandas.Series, or numpy.ndarray\n        The input column data.\n    col_name : str\n        Name of the column for naming generated features.\n    lag_values : list[int]\n        List of lag steps.\n    win_values : list[int]\n        List of window sizes for rolling features.\n    win_methods : list[str]\n        Methods for rolling aggregation: 'mean', 'max', 'min', 'sum', etc.\n    diff_values : list[int]\n        List of periods for calculating differences.\n        \n    Returns:\n    -------\n    pandas.DataFrame\n        DataFrame with all generated features.\n    \"\"\"\n    \n    # Ensure input is a pandas Series\n    if not isinstance(col, pd.Series):\n        col = pd.Series(col)\n    \n    # Initialize result DataFrame\n    features = pd.DataFrame(index=col.index)\n\n    # add col as well\n    if not is_a_target:\n        features[f\"{col_name}\"] = col\n    \n    # --- Lag Features ---\n    if lag_values:\n        for lag in lag_values:\n            features[f\"lag_{lag}_{col_name}\"] = col.shift(lag)\n    \n    # --- Rolling Window Features ---\n    if win_values and win_methods:\n        for win in win_values:\n            for method in win_methods:\n                if hasattr(pd.Series.rolling(col, win), method):\n                    features[f\"win_{method}_{win}_{col_name}\"] = getattr(col.rolling(win), method)()\n                else:\n                    raise ValueError(f\"Method '{method}' is not supported for rolling windows.\")\n     # --- Difference Features ---\n    if diff_values:\n        for diff in diff_values:\n            features[f\"diff_{diff}_{col_name}\"] = col.diff(diff)\n    \n    return features","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-15T13:11:15.613972Z","iopub.execute_input":"2025-10-15T13:11:15.614362Z","iopub.status.idle":"2025-10-15T13:11:15.640285Z","shell.execute_reply.started":"2025-10-15T13:11:15.614333Z","shell.execute_reply":"2025-10-15T13:11:15.638417Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def prepare_features_for_df(\n    df,\n    lag_values=[1, 2,5,7,10,15,20,-1,-2,-5,-7,-10,-20 ],\n    win_values=[2, 3 , 5 , 7 , 10 , 15 , 30 ],\n    win_methods=[\"mean\", \"max\"],\n    diff_values=[1, 2, 5 , 7 , 10 , 15 , 20 ,-1,-2, -5,-7,-10,-15,-20 ]\n):\n    to_return = pd.DataFrame()\n    for col in list(df.columns):\n        featdf = prepare_features_for_col(\n            col=df[col],\n            col_name=col,\n            lag_values=lag_values,\n            win_values=win_values,\n            win_methods=win_methods,\n            diff_values=diff_values\n        )\n        to_return = pd.concat([to_return,featdf],axis = 1)\n    to_return = to_return.fillna(method='ffill').fillna(method='bfill')\n    return to_return.fillna(method='ffill').fillna(method='bfill')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-15T13:11:15.643534Z","iopub.execute_input":"2025-10-15T13:11:15.643844Z","iopub.status.idle":"2025-10-15T13:11:15.671476Z","shell.execute_reply.started":"2025-10-15T13:11:15.643821Z","shell.execute_reply":"2025-10-15T13:11:15.670176Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"smpdf= pd.DataFrame(\n    {\n        'A':[3,4,5],\n        'B':[4,5,6]\n    }\n)\n\nsmpfeatdf = prepare_features_for_df(\n    smpdf\n).fillna(0)\nsmpfeatdf","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-15T13:11:15.672464Z","iopub.execute_input":"2025-10-15T13:11:15.672791Z","iopub.status.idle":"2025-10-15T13:11:15.802963Z","shell.execute_reply.started":"2025-10-15T13:11:15.672768Z","shell.execute_reply":"2025-10-15T13:11:15.801394Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# model engnieering","metadata":{}},{"cell_type":"code","source":"log_transformer = FunctionTransformer(lambda x: np.log1p(np.abs(x)) * np.sign(x))\nfeature_maker = FunctionTransformer(prepare_features_for_df, validate=False)\n\nn_est_cmn = 50\n\nbase_models = [\n    (\"xgb\", XGBRegressor(\n        n_estimators=n_est_cmn, \n        learning_rate=0.05, \n        max_depth=5, \n        subsample=0.8, \n        colsample_bytree=0.8,\n        random_state=42\n    )),\n    (\"lgbm\", LGBMRegressor(\n        n_estimators=n_est_cmn, \n        learning_rate=0.05, \n        max_depth=-1, \n        subsample=0.8, \n        colsample_bytree=0.8,\n        random_state=42,\n        verbosity=-1\n    )),\n    (\"rf\", RandomForestRegressor(\n        n_estimators=n_est_cmn, \n        max_depth=None, \n        n_jobs=-1, \n        random_state=42\n    )),\n    # # Bagging over Decision Trees\n    # (\"bagging_dt\", BaggingRegressor(\n    #     base_estimator=DecisionTreeRegressor(max_depth=5, random_state=42),\n    #     n_estimators=50,\n    #     max_samples=0.8,\n    #     max_features=0.8,\n    #     bootstrap=True,\n    #     n_jobs=-1,\n    #     random_state=42\n    # )),\n\n    # # Bagging over Linear Regression\n    # (\"bagging_lr\", BaggingRegressor(\n    #     base_estimator=LinearRegression(),\n    #     n_estimators=50,\n    #     max_samples=0.8,\n    #     max_features=0.8,\n    #     bootstrap=True,\n    #     n_jobs=-1,\n    #     random_state=42\n    # )),\n\n    # # Bagging over Ridge\n    # (\"bagging_ridge\", BaggingRegressor(\n    #     base_estimator=Ridge(alpha=1.0, random_state=42),\n    #     n_estimators=50,\n    #     max_samples=0.8,\n    #     max_features=0.8,\n    #     bootstrap=True,\n    #     n_jobs=-1,\n    #     random_state=42\n    # )),\n\n    # # Bagging over SVR (a bit slower, but adds diversity)\n    # (\"bagging_svr\", BaggingRegressor(\n    #     base_estimator=SVR(kernel=\"rbf\", C=1.0, epsilon=0.1),\n    #     n_estimators=20,   # lower because SVR is heavier\n    #     max_samples=0.8,\n    #     max_features=0.8,\n    #     bootstrap=True,\n    #     n_jobs=-1,\n    #     random_state=42\n    # )),\n\n    # # Bagging over KNN\n    # (\"bagging_knn\", BaggingRegressor(\n    #     base_estimator=KNeighborsRegressor(n_neighbors=5),\n    #     n_estimators=50,\n    #     max_samples=0.8,\n    #     max_features=0.8,\n    #     bootstrap=True,\n    #     n_jobs=-1,\n    #     random_state=42\n    # )),\n]\n\n# Stacked model with Ridge as meta-learner\nstacked_model = StackingRegressor(\n    estimators=base_models,\n    final_estimator=Ridge(alpha=1.0),\n    n_jobs=-1,\n    passthrough=True  # if True, meta-model also sees raw features\n)\n\n# Full pipeline\nmodel = Pipeline([\n    (\"Feature maker\",feature_maker ),\n    (\"imputer\", SimpleImputer(strategy=\"median\")),\n    (\"scaler\", StandardScaler()),\n    (\"log_norm\", log_transformer),\n    (\"stacked\", stacked_model)\n])\n\n# Fit\nmodel.fit(x, y)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-15T13:11:15.804798Z","iopub.execute_input":"2025-10-15T13:11:15.805155Z","iopub.status.idle":"2025-10-15T13:17:26.48843Z","shell.execute_reply.started":"2025-10-15T13:11:15.805127Z","shell.execute_reply":"2025-10-15T13:17:26.487325Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"previous_allocation = 1.0  # start neutral\n\ndef predict(test: pl.DataFrame) -> float:\n    global previous_allocation\n    # Convert Polars -> Pandas\n    row = test.to_pandas()\n    # Make sure only training features are used\n    row = row.reindex(columns=x.columns, fill_value=0)\n    # Predict\n    pred = model.predict(row)[0]\n    # Convert prediction into allocation\n    allocation = 1.0 + 50 * pred  # scaling factor\n    # Clip to [0, 2]\n    allocation = np.clip(allocation, 0.0, 2.0)\n    # Smooth with previous allocation\n    allocation = 0.8 * allocation + 0.2 * previous_allocation\n    previous_allocation = allocation\n    return float(allocation)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-15T13:17:26.489855Z","iopub.execute_input":"2025-10-15T13:17:26.490236Z","iopub.status.idle":"2025-10-15T13:17:26.497203Z","shell.execute_reply.started":"2025-10-15T13:17:26.490204Z","shell.execute_reply":"2025-10-15T13:17:26.496262Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"inference_server = kaggle_evaluation.default_inference_server.DefaultInferenceServer(predict)\n\nif os.getenv(\"KAGGLE_IS_COMPETITION_RERUN\"):\n    inference_server.serve()\nelse:\n    inference_server.run_local_gateway((\"/kaggle/input/hull-tactical-market-prediction/\",))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-15T13:17:26.498003Z","iopub.execute_input":"2025-10-15T13:17:26.4984Z","iopub.status.idle":"2025-10-15T13:17:41.489167Z","shell.execute_reply.started":"2025-10-15T13:17:26.498378Z","shell.execute_reply":"2025-10-15T13:17:41.488091Z"}},"outputs":[],"execution_count":null}]}