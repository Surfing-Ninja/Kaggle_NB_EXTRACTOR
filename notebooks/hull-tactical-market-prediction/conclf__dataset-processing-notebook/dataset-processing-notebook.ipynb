{"cells":[{"cell_type":"markdown","source":"## Instructions:\nComplete the code for all functions that have a \"TODO\" in their docstring.\n\nThis notebook should take you ~20 minutes to complete. AI usage is allowed, but try not to overuse it.","metadata":{"id":"S_ZPy_4vUByF"},"id":"S_ZPy_4vUByF"},{"cell_type":"markdown","id":"cfc49fd1","metadata":{"id":"cfc49fd1"},"source":"## Imports"},{"cell_type":"code","execution_count":null,"id":"e033959d","metadata":{"id":"e033959d"},"outputs":[],"source":"\nimport os\nfrom pathlib import Path\nimport datetime\n\nfrom tqdm import tqdm\nfrom dataclasses import dataclass, asdict\n\nimport polars as pl\nimport numpy as np\nfrom sklearn.linear_model import ElasticNet, ElasticNetCV, LinearRegression\nfrom sklearn.preprocessing import StandardScaler\n\nimport kaggle_evaluation.default_inference_server\n"},{"cell_type":"markdown","id":"e43e26b3","metadata":{"id":"e43e26b3"},"source":"## Project Directory Structure"},{"cell_type":"code","execution_count":null,"id":"54ea7efd","metadata":{"id":"54ea7efd"},"outputs":[],"source":"\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n"},{"cell_type":"markdown","id":"8105b2dd","metadata":{"id":"8105b2dd"},"source":"## Configurations"},{"cell_type":"code","execution_count":null,"id":"277f4b4d","metadata":{"id":"277f4b4d"},"outputs":[],"source":"\n# ============ PATHS ============\nDATA_PATH: Path = Path('/kaggle/input/hull-tactical-market-prediction/')\n\n# ============ RETURNS TO SIGNAL CONFIGS ============\nMIN_SIGNAL: float = 0.0\nMAX_SIGNAL: float = 2.0\nSIGNAL_MULTIPLIER: float = 400.0\n\n# ============ MODEL CONFIGS ============\nCV: int = 10\nL1_RATIO: float = 0.5\nALPHAS: np.ndarray = np.logspace(-4, 2, 100)\nMAX_ITER: int = 1000000\n"},{"cell_type":"markdown","id":"412b3219","metadata":{"id":"412b3219"},"source":"## Dataclasses Helpers"},{"cell_type":"code","execution_count":null,"id":"404abaa9","metadata":{"id":"404abaa9"},"outputs":[],"source":"\n@dataclass\nclass DatasetOutput:\n    X_train : pl.DataFrame\n    X_test: pl.DataFrame\n    y_train: pl.Series\n    y_test: pl.Series\n    scaler: StandardScaler\n\n@dataclass(frozen=True)\nclass RetToSignalParameters:\n    signal_multiplier: float\n    min_signal : float = MIN_SIGNAL\n    max_signal : float = MAX_SIGNAL\n"},{"cell_type":"markdown","id":"3b5ae8e2","metadata":{"id":"3b5ae8e2"},"source":"## Set the Parameters"},{"cell_type":"markdown","id":"2f8dad2f","metadata":{"id":"2f8dad2f"},"source":"## Dataset Loading/Creating Helper Functions"},{"cell_type":"code","execution_count":null,"id":"c59a4c45","metadata":{"id":"c59a4c45"},"outputs":[],"source":"\ndef load_trainset() -> pl.DataFrame:\n    \"\"\"\n    TODO: Load and preprocess the training dataset.\n    - Read the CSV file from DATA_PATH ('train.csv').\n    - Rename the column 'market_forward_excess_returns' to 'target'.\n    - Convert numeric columns to Float64 (excluding 'date_id').\n    - Return the processed DataFrame.\n    \"\"\"\n    raise NotImplementedError(\"Implement load_trainset()\")\n"},{"cell_type":"code","execution_count":null,"id":"2c14fc97","metadata":{"id":"2c14fc97"},"outputs":[],"source":"\ndef load_testset() -> pl.DataFrame:\n    \"\"\"\n    TODO: Load and preprocess the testing dataset.\n    - Read the CSV file from DATA_PATH ('test.csv').\n    - Rename the column 'lagged_forward_returns' to 'target'.\n    - Convert numeric columns to Float64 (excluding 'date_id').\n    - Return the processed DataFrame.\n    \"\"\"\n    raise NotImplementedError(\"Implement load_testset()\")\n"},{"cell_type":"code","execution_count":null,"id":"954d32cf","metadata":{"id":"954d32cf"},"outputs":[],"source":"\ndef create_example_dataset(df: pl.DataFrame) -> pl.DataFrame:\n    \"\"\"\n    TODO: Create new engineered features and clean the data.\n    - Compute new columns 'U1' = I2 - I1 and 'U2' = M11 / ((I2 + I9 + I7) / 3).\n    - Fill null values using exponential weighted mean or a similar method.\n    - Drop any remaining nulls.\n    \"\"\"\n    raise NotImplementedError(\"Implement create_example_dataset()\")\n"},{"cell_type":"code","execution_count":null,"id":"c394aa66","metadata":{"id":"c394aa66"},"outputs":[],"source":"\ndef join_train_test_dataframes(train: pl.DataFrame, test: pl.DataFrame) -> pl.DataFrame:\n    \"\"\"\n    TODO: Combine training and testing DataFrames.\n    - Identify common columns.\n    - Concatenate them vertically into a single DataFrame.\n    - Return the combined DataFrame.\n    \"\"\"\n    raise NotImplementedError(\"Implement join_train_test_dataframes()\")\n"},{"cell_type":"code","execution_count":null,"id":"2e7c53cc","metadata":{"id":"2e7c53cc"},"outputs":[],"source":"\ndef split_dataset(train: pl.DataFrame, test: pl.DataFrame, features: list[str]) -> DatasetOutput:\n    \"\"\"\n    TODO: Split the data into training/testing sets and scale the features.\n    Steps:\n    1. Separate X (features) and y (target) for both train and test sets.\n    2. Use StandardScaler to fit on train and transform both train/test.\n    3. Convert scaled numpy arrays back to Polars DataFrames.\n    4. Return a DatasetOutput dataclass instance.\n    \"\"\"\n    raise NotImplementedError(\"Implement split_dataset()\")\n"},{"cell_type":"markdown","id":"1939848f","metadata":{"id":"1939848f"},"source":"## Converting Return Prediction to Signal"},{"cell_type":"code","execution_count":null,"id":"02142836","metadata":{"id":"02142836"},"outputs":[],"source":"\ndef convert_ret_to_signal(ret_arr: np.ndarray, params: RetToSignalParameters) -> np.ndarray:\n    \"\"\"\n    TODO: Convert model return predictions into a daily signal.\n    - Multiply predicted returns by params.signal_multiplier and add 1.\n    - Clip resulting signal between params.min_signal and params.max_signal.\n    - Return the clipped numpy array.\n    \"\"\"\n    raise NotImplementedError(\"Implement convert_ret_to_signal()\")\n"},{"cell_type":"markdown","id":"f24e8fff","metadata":{"id":"f24e8fff"},"source":"## Looking at the Data"},{"cell_type":"code","execution_count":null,"id":"705a8140","metadata":{"id":"705a8140"},"outputs":[],"source":"\n# Once implemented, these lines will load and display samples of your data.\ntrain: pl.DataFrame = load_trainset()\ntest: pl.DataFrame = load_testset()\nprint(train.tail(3))\nprint(test.head(3))\n"},{"cell_type":"markdown","source":"Here is what the output should look like:\n\n```\nshape: (3, 98)\n┌─────────┬─────┬─────┬─────┬───┬───────────┬─────────────────┬────────────────┬──────────┐\n│ date_id ┆ D1  ┆ D2  ┆ D3  ┆ … ┆ V9        ┆ forward_returns ┆ risk_free_rate ┆ target   │\n│ ---     ┆ --- ┆ --- ┆ --- ┆   ┆ ---       ┆ ---             ┆ ---            ┆ ---      │\n│ i64     ┆ f64 ┆ f64 ┆ f64 ┆   ┆ f64       ┆ f64             ┆ f64            ┆ f64      │\n╞═════════╪═════╪═════╪═════╪═══╪═══════════╪═════════════════╪════════════════╪══════════╡\n│ 8977    ┆ 0.0 ┆ 0.0 ┆ 0.0 ┆ … ┆ -0.708599 ┆ 0.004187        ┆ 0.000162       ┆ 0.003713 │\n│ 8978    ┆ 0.0 ┆ 0.0 ┆ 0.0 ┆ … ┆ -0.725858 ┆ 0.002279        ┆ 0.000162       ┆ 0.001805 │\n│ 8979    ┆ 0.0 ┆ 0.0 ┆ 0.0 ┆ … ┆ -0.720092 ┆ 0.003541        ┆ 0.000161       ┆ 0.003068 │\n└─────────┴─────┴─────┴─────┴───┴───────────┴─────────────────┴────────────────┴──────────┘\nshape: (3, 99)\n┌─────────┬─────┬─────┬─────┬───┬───────────┬───────────┬─────────────────────┬────────────────────┐\n│ date_id ┆ D1  ┆ D2  ┆ D3  ┆ … ┆ is_scored ┆ target    ┆ lagged_risk_free_ra ┆ lagged_market_forw │\n│ ---     ┆ --- ┆ --- ┆ --- ┆   ┆ ---       ┆ ---       ┆ te                  ┆ ard_excess_r…      │\n│ i64     ┆ f64 ┆ f64 ┆ f64 ┆   ┆ f64       ┆ f64       ┆ ---                 ┆ ---                │\n│         ┆     ┆     ┆     ┆   ┆           ┆           ┆ f64                 ┆ f64                │\n╞═════════╪═════╪═════╪═════╪═══╪═══════════╪═══════════╪═════════════════════╪════════════════════╡\n│ 8980    ┆ 0.0 ┆ 0.0 ┆ 0.0 ┆ … ┆ 1.0       ┆ 0.003541  ┆ 0.000161            ┆ 0.003068           │\n│ 8981    ┆ 0.0 ┆ 0.0 ┆ 0.0 ┆ … ┆ 1.0       ┆ -0.005964 ┆ 0.000162            ┆ -0.006437          │\n│ 8982    ┆ 0.0 ┆ 0.0 ┆ 0.0 ┆ … ┆ 1.0       ┆ -0.00741  ┆ 0.00016             ┆ -0.007882          │\n└─────────┴─────┴─────┴─────┴───┴───────────┴───────────┴─────────────────────┴────────────────────┘\n```","metadata":{"id":"Lk1ndoKXa6Tz"},"id":"Lk1ndoKXa6Tz"},{"cell_type":"markdown","id":"2b66c2ea","metadata":{"id":"2b66c2ea"},"source":"## Generating the Train and Test"},{"cell_type":"code","execution_count":null,"id":"eeef012b","metadata":{"id":"eeef012b"},"outputs":[],"source":"\ndf: pl.DataFrame = join_train_test_dataframes(train, test)\ndf = create_example_dataset(df=df)\ntrain: pl.DataFrame = df.filter(pl.col('date_id').is_in(train.get_column('date_id')))\ntest: pl.DataFrame = df.filter(pl.col('date_id').is_in(test.get_column('date_id')))\n\nFEATURES: list[str] = [col for col in test.columns if col not in ['date_id', 'target']]\ndataset: DatasetOutput = split_dataset(train=train, test=test, features=FEATURES)\n\nX_train: pl.DataFrame = dataset.X_train\nX_test: pl.DataFrame = dataset.X_test\ny_train: pl.Series = dataset.y_train\ny_test: pl.Series = dataset.y_test\nscaler: StandardScaler = dataset.scaler\n\nprint(df.head(3))\nprint(FEATURES)\n"},{"cell_type":"markdown","source":"Here's what the output should look like:\n```\nshape: (3, 15)\n┌─────────┬───────────┬───────────┬──────────┬───┬───────────┬──────────┬───────────┬───────────┐\n│ date_id ┆ target    ┆ S2        ┆ E2       ┆ … ┆ P12       ┆ P13      ┆ U1        ┆ U2        │\n│ ---     ┆ ---       ┆ ---       ┆ ---      ┆   ┆ ---       ┆ ---      ┆ ---       ┆ ---       │\n│ i64     ┆ f64       ┆ f64       ┆ f64      ┆   ┆ f64       ┆ f64      ┆ f64       ┆ f64       │\n╞═════════╪═══════════╪═══════════╪══════════╪═══╪═══════════╪══════════╪═══════════╪═══════════╡\n│ 1511    ┆ 0.003079  ┆ -0.28579  ┆ 2.029588 ┆ … ┆ -0.162462 ┆ 0.592262 ┆ -2.318559 ┆ -0.731815 │\n│ 1512    ┆ 0.004344  ┆ -0.399753 ┆ 2.045731 ┆ … ┆ -0.578615 ┆ 0.591931 ┆ -2.305802 ┆ -0.220781 │\n│ 1513    ┆ -0.001013 ┆ 0.059127  ┆ 2.075762 ┆ … ┆ -0.781019 ┆ 0.591601 ┆ -2.370795 ┆ -0.300937 │\n└─────────┴───────────┴───────────┴──────────┴───┴───────────┴──────────┴───────────┴───────────┘\n['S2', 'E2', 'E3', 'P9', 'S1', 'S5', 'I2', 'P8', 'P10', 'P12', 'P13', 'U1', 'U2']\n```","metadata":{"id":"00bm91MibJJs"},"id":"00bm91MibJJs"}],"metadata":{"language_info":{"name":"python"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}