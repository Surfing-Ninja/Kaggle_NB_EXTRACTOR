{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":111543,"databundleVersionId":14348714,"sourceType":"competition"}],"dockerImageVersionId":31153,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from dataclasses import dataclass\n\nimport os\n\nimport math\n\nimport polars as pl\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport kaggle_evaluation.default_inference_server\n\nimport torch\nimport torch.nn as nn # defining our neural network\nimport torch.optim as optim # training our neural network\nimport torch.nn.functional as F\nfrom torch.utils.data import DataLoader, Dataset # loading data in batches","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.status.busy":"2025-11-07T19:10:16.983932Z","iopub.execute_input":"2025-11-07T19:10:16.984362Z","iopub.status.idle":"2025-11-07T19:10:28.492943Z","shell.execute_reply.started":"2025-11-07T19:10:16.984336Z","shell.execute_reply":"2025-11-07T19:10:28.49201Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Config","metadata":{}},{"cell_type":"code","source":"@dataclass\nclass Config:\n\n    # FFN learning rate\n    learning_rate = 5e-4\n    momentum = 0.95\n    epochs = 10\n\n    train_path = \"/kaggle/input/hull-tactical-market-prediction/train.csv\"\n    test_path = \"/kaggle/input/hull-tactical-market-prediction/test.csv\"\n\n    target_column = \"market_forward_excess_returns\"\n    # target_column = \"forward_returns\"\n\n    base_signal = 1.0\n    signal_multiplier: float = 8.0\n    min_signal : float = 0.0 \n    max_signal : float = 2.0\n    ","metadata":{"execution":{"iopub.status.busy":"2025-11-07T19:10:28.495142Z","iopub.execute_input":"2025-11-07T19:10:28.495641Z","iopub.status.idle":"2025-11-07T19:10:28.502537Z","shell.execute_reply.started":"2025-11-07T19:10:28.495615Z","shell.execute_reply":"2025-11-07T19:10:28.501138Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Loading and Processing Data","metadata":{}},{"cell_type":"code","source":"\n# Load data\ntrain = pd.read_csv(\"/kaggle/input/hull-tactical-market-prediction/train.csv\")\ntest = pd.read_csv(\"/kaggle/input/hull-tactical-market-prediction/test.csv\")\n\nexclude = [\"date_id\", 'forward_returns', 'risk_free_rate', 'market_forward_excess_returns']\ntest_cols = []\nfor col in train.columns:\n    nans = train[col].isna().sum()\n    if nans <= 1006 and col not in exclude:\n        test_cols.append(col)\n\n# Columns to keep\nprint(f\"test_cols: {test_cols}\")\ntrain_cols = [\"forward_returns\", \"risk_free_rate\", \"market_forward_excess_returns\"]\nbase_col = [\"date_id\"]\n\n# Apply filtering\ntrain_filtered = train[base_col + test_cols + train_cols]\ntest_filtered = test[base_col + test_cols]\n\nwindow = 50 # number of days in each normalization window\n\n# rolling_min = train_filtered[\"market_forward_excess_returns\"].rolling(window).min()\n# rolling_max = train_filtered[\"market_forward_excess_returns\"].rolling(window).max()\n\n# train_filtered[\"target_market_norm\"] = (\n#     (train_filtered[\"forward_returns\"] - rolling_min) / (rolling_max - rolling_min)\n# )\n# train_filtered[\"target_market_norm\"].bfill(inplace=True)\n\n# remove duplicate colums\ntrain_filtered = train_filtered.loc[:, ~train_filtered.columns.duplicated()]\ntest_filtered = test_filtered.loc[:, ~test_filtered.columns.duplicated()]\n\nprint(f\"Number of rows in train: {len(train_filtered)}\")\nprint(f\"Number of rows in test: {len(test_filtered)}\")\n","metadata":{"execution":{"iopub.status.busy":"2025-11-07T19:10:28.506998Z","iopub.execute_input":"2025-11-07T19:10:28.507347Z","iopub.status.idle":"2025-11-07T19:10:28.910475Z","shell.execute_reply.started":"2025-11-07T19:10:28.507317Z","shell.execute_reply":"2025-11-07T19:10:28.909255Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"target = train_filtered[Config.target_column]\nplt.hist(target, bins=50)\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-07T19:10:28.911262Z","iopub.execute_input":"2025-11-07T19:10:28.911508Z","iopub.status.idle":"2025-11-07T19:10:29.206114Z","shell.execute_reply.started":"2025-11-07T19:10:28.911488Z","shell.execute_reply":"2025-11-07T19:10:29.205172Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"target.mean(), target.std()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-07T19:10:29.207679Z","iopub.execute_input":"2025-11-07T19:10:29.20802Z","iopub.status.idle":"2025-11-07T19:10:29.215149Z","shell.execute_reply.started":"2025-11-07T19:10:29.207984Z","shell.execute_reply":"2025-11-07T19:10:29.214201Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"n = len(target)\nmu = target.mean()\nsigma = target.std()\none_sigma_prop = ((target - mu >= -sigma) & (target - mu < sigma)).sum() / n\ntwo_sigma_prop = ((target - mu >= -2 * sigma) & (target - mu < 2 * sigma)).sum() / n\nthree_sigma_prop = ((target - mu >= -3 * sigma) & (target - mu < 3 * sigma)).sum() / n\none_sigma_prop, two_sigma_prop, three_sigma_prop","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-07T19:10:29.218616Z","iopub.execute_input":"2025-11-07T19:10:29.218891Z","iopub.status.idle":"2025-11-07T19:10:29.245704Z","shell.execute_reply.started":"2025-11-07T19:10:29.21887Z","shell.execute_reply":"2025-11-07T19:10:29.244543Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"The values suggest the target is not normally distributed, a potential distribution is the t-distribution, which has larger tails and can be denser within 1 sigma.","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.stats import gennorm, norm\n\n# Standardize data\ntarget = train_filtered[Config.target_column].dropna()\nz = (target - target.mean()) / target.std()\n\n# Fit generalized normal\nparams = gennorm.fit(z)  # returns (beta, loc, scale)\nbeta, loc, scale = params\nprint(f\"Fitted generalized normal: beta={beta:.3f}, loc={loc:.3f}, scale={scale:.3f}\")\n\n# x-range and PDFs\nx = np.linspace(-6, 6, 1000)\npdf_fit = gennorm.pdf(x, *params)\npdf_norm = norm.pdf(x)\n\n# Plot\nplt.figure(figsize=(8,5))\nplt.hist(z, bins=50, density=True, alpha=0.4, color='gray', label='Standardized empirical')\nplt.plot(x, pdf_fit, label=f'GenNorm Î²={beta:.2f}', linewidth=2)\nplt.plot(x, pdf_norm, 'k--', label='Normal (0,1)')\nplt.xlabel(\"Standardized Value (z-score)\")\nplt.ylabel(\"Density\")\nplt.title(\"Empirical Data vs Fitted Generalized Normal Distribution\")\nplt.legend()\nplt.grid(alpha=0.3)\nplt.tight_layout()\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-07T19:10:29.246951Z","iopub.execute_input":"2025-11-07T19:10:29.247546Z","iopub.status.idle":"2025-11-07T19:10:29.687274Z","shell.execute_reply.started":"2025-11-07T19:10:29.247506Z","shell.execute_reply":"2025-11-07T19:10:29.686131Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from scipy.stats import laplace, norm\n\n# Standardize your data\ntarget = train_filtered[Config.target_column].dropna()\nz = (target - target.mean()) / target.std()\n\n# Fit Laplace parameters (loc and scale)\nloc, scale = laplace.fit(z)\nprint(f\"Laplace fit: loc={loc:.3f}, scale={scale:.3f}\")\n\n# Define x-range and PDFs\nx = np.linspace(-6, 6, 1000)\npdf_laplace = laplace.pdf(x, loc=loc, scale=scale)\npdf_norm = norm.pdf(x)\n\n# Plot\nplt.figure(figsize=(8,5))\nplt.hist(z, bins=50, density=True, alpha=0.4, color='gray', label='Standardized empirical data')\nplt.plot(x, pdf_laplace, label=f'Laplace fit (loc={loc:.2f}, scale={scale:.2f})', linewidth=2)\nplt.plot(x, pdf_norm, 'k--', label='Normal (0,1)', linewidth=1.5)\n\n# Labels and legend\nplt.title(\"Empirical Data vs Fitted Laplace and Normal Distributions\", fontsize=14)\nplt.xlabel(\"Standardized Value (z-score)\", fontsize=12)\nplt.ylabel(\"Density\", fontsize=12)\nplt.legend()\nplt.grid(alpha=0.3)\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-07T19:10:29.68826Z","iopub.execute_input":"2025-11-07T19:10:29.688551Z","iopub.status.idle":"2025-11-07T19:10:30.04464Z","shell.execute_reply.started":"2025-11-07T19:10:29.688527Z","shell.execute_reply":"2025-11-07T19:10:30.043652Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Count number of rows with at least one NaN\nnum_nan_train = train_filtered.isna().any(axis=1).sum()\nnum_nan_test = test_filtered.isna().any(axis=1).sum()\n\nprint(f\"Number of rows with NaN in train: {num_nan_train}\")\nprint(f\"Number of rows with NaN in test: {num_nan_test}\")\n\nX = train_filtered[test_cols]  # features\ny = train_filtered[Config.target_column]  # target\n\nmask = X.isna().sum(axis=1) == 0\nX = X[mask]\ny = y[mask]","metadata":{"execution":{"iopub.status.busy":"2025-11-07T19:10:30.045682Z","iopub.execute_input":"2025-11-07T19:10:30.045919Z","iopub.status.idle":"2025-11-07T19:10:30.082815Z","shell.execute_reply.started":"2025-11-07T19:10:30.045902Z","shell.execute_reply":"2025-11-07T19:10:30.08131Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X.shape, y.shape","metadata":{"execution":{"iopub.status.busy":"2025-11-07T19:10:30.083949Z","iopub.execute_input":"2025-11-07T19:10:30.084367Z","iopub.status.idle":"2025-11-07T19:10:30.092469Z","shell.execute_reply.started":"2025-11-07T19:10:30.0843Z","shell.execute_reply":"2025-11-07T19:10:30.091Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X.head()","metadata":{"execution":{"iopub.status.busy":"2025-11-07T19:10:30.093656Z","iopub.execute_input":"2025-11-07T19:10:30.093947Z","iopub.status.idle":"2025-11-07T19:10:30.142763Z","shell.execute_reply.started":"2025-11-07T19:10:30.093925Z","shell.execute_reply":"2025-11-07T19:10:30.14166Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"y.head()","metadata":{"execution":{"iopub.status.busy":"2025-11-07T19:10:30.144105Z","iopub.execute_input":"2025-11-07T19:10:30.145009Z","iopub.status.idle":"2025-11-07T19:10:30.152871Z","shell.execute_reply.started":"2025-11-07T19:10:30.14498Z","shell.execute_reply":"2025-11-07T19:10:30.151761Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## FFN Model Definition","metadata":{}},{"cell_type":"code","source":"\n# our neural network class is a subclass of nn.Module\n# this handles a lot of the boilerplate code for us\n# including parameter initialization, etc.\nclass FFN(nn.Module):\n\n    def __init__(self, input_size, hidden_size, output_size):\n\n        '''\n        Args:\n            input_size: size of the input\n            hidden_size: size of the hidden layer\n            output_size: size of the output layer\n        '''\n\n        super().__init__() # call the parent class's constructor\n\n        # define layers\n        # nn.Linear takes in the size of the input and output\n        self.fc1 = nn.Linear(input_size, hidden_size) # first fully connected layer\n        self.fc2 = nn.Linear(hidden_size, hidden_size) # second fully connected layer\n        self.fc3 = nn.Linear(hidden_size, output_size)\n\n        self.relu = nn.ReLU() # activation function\n    \n    def forward(self, x):\n        # define the forward pass\n        out = self.fc1(x) # pass through first layer\n        out = self.relu(out) # apply activation function\n        out = self.fc2(out) # pass through second layer\n        out = self.relu(out)\n        out = self.fc3(out)\n        return out\n\n","metadata":{"execution":{"iopub.status.busy":"2025-11-07T19:10:30.154044Z","iopub.execute_input":"2025-11-07T19:10:30.154567Z","iopub.status.idle":"2025-11-07T19:10:30.183981Z","shell.execute_reply.started":"2025-11-07T19:10:30.154542Z","shell.execute_reply":"2025-11-07T19:10:30.182601Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Dataset Definition","metadata":{}},{"cell_type":"code","source":"\nclass SP500Dataset(Dataset):\n    def __init__(self, data, target_column):\n        # data is a dataframe\n        self.dataframe = data\n        self.target = target_column\n\n    def __len__(self):\n        return len(self.dataframe)\n\n    def __getitem__(self, idx):\n        # return a tuple of (features, target)\n        return torch.tensor(self.dataframe.iloc[idx].values, dtype=torch.float32), \\\n            torch.tensor(self.target.iloc[idx], dtype=torch.float32)\n\n","metadata":{"execution":{"iopub.status.busy":"2025-11-07T19:10:30.184771Z","iopub.execute_input":"2025-11-07T19:10:30.185113Z","iopub.status.idle":"2025-11-07T19:10:30.211849Z","shell.execute_reply.started":"2025-11-07T19:10:30.185082Z","shell.execute_reply":"2025-11-07T19:10:30.210754Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Training Loop","metadata":{}},{"cell_type":"code","source":"\nx = np.linspace(-1, 1, 201)\nprint(x)\nlpdf = laplace.pdf(x, loc=loc, scale=scale)\nlcdf = laplace.cdf(x, loc=loc, scale=scale)\nplt.plot(x, lcdf)\nplt.plot(x, lpdf)\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-07T19:10:30.212968Z","iopub.execute_input":"2025-11-07T19:10:30.213352Z","iopub.status.idle":"2025-11-07T19:10:30.406638Z","shell.execute_reply.started":"2025-11-07T19:10:30.213321Z","shell.execute_reply":"2025-11-07T19:10:30.405603Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\ndf, labels = X, y\ndataset = SP500Dataset(X, y)\n\n# This is an iterable that will yield batches of data\ndataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n# Our model, optimizer, and loss function\nmodel = FFN(input_size=len(X.columns), hidden_size=10, output_size=1)\n\n# Variant of Stochastic Gradient Descent\noptimizer = optim.SGD(\n    model.parameters(),\n    lr=Config.learning_rate,\n    momentum=Config.momentum\n)\n\n# Mean Squared Error Loss for regression tasks\ncriterion = nn.L1Loss()\ncriterion2 = nn.BCELoss()\n\nloss_graph = []\nfor epoch in range(Config.epochs): # loop over the dataset multiple times\n    for inputs, targets in dataloader:\n        optimizer.zero_grad() # zero the parameter gradients\n        outputs = model(inputs)\n        targets_transformed = torch.tensor(\n            laplace.cdf(targets.numpy(), loc=loc, scale=scale),\n            dtype=torch.float32\n        )\n        outputs_transformed = F.sigmoid(outputs) # forward pass\n        \n        loss = criterion(outputs.squeeze(), targets) # compute loss\n        # loss += criterion2(outputs_transformed.squeeze(), targets_transformed) * .01\n        loss.backward() # backward pass\n        optimizer.step() # update parameters\n        loss_graph.append(loss.item())\n\n    print(f'Epoch {epoch+1}, Loss: {loss.item()}')\n\n","metadata":{"execution":{"iopub.status.busy":"2025-11-07T19:10:30.407949Z","iopub.execute_input":"2025-11-07T19:10:30.408408Z","iopub.status.idle":"2025-11-07T19:10:50.287863Z","shell.execute_reply.started":"2025-11-07T19:10:30.408378Z","shell.execute_reply":"2025-11-07T19:10:50.286651Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plt.plot(loss_graph)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2025-11-07T19:10:50.28875Z","iopub.execute_input":"2025-11-07T19:10:50.289173Z","iopub.status.idle":"2025-11-07T19:10:50.45919Z","shell.execute_reply.started":"2025-11-07T19:10:50.28915Z","shell.execute_reply":"2025-11-07T19:10:50.458076Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_data = torch.tensor(X.to_numpy(), dtype=torch.float32)\n\noutput = model.forward(train_data).view(-1).detach().numpy()\n\nplt.hist((output - mu) / sigma, bins=50, density=True)\nplt.hist((y - mu)/sigma, bins=50, density=True)\nprint(output.shape, y.shape)\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-07T19:10:50.46061Z","iopub.execute_input":"2025-11-07T19:10:50.460959Z","iopub.status.idle":"2025-11-07T19:10:50.732877Z","shell.execute_reply.started":"2025-11-07T19:10:50.460924Z","shell.execute_reply":"2025-11-07T19:10:50.731779Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Prediction","metadata":{}},{"cell_type":"code","source":"def convert_ret_to_signal(\n    ret_arr: np.ndarray,\n) -> np.ndarray:\n    \"\"\"\n    Converts raw model predictions (expected returns) into a trading signal.\n\n    Args:\n        ret_arr (np.ndarray): The array of predicted returns.\n        params (RetToSignalParameters): Parameters for scaling and clipping the signal.\n\n    Returns:\n        np.ndarray: The resulting trading signal, clipped between min and max values.\n    \"\"\"\n    return np.clip(\n        ret_arr * Config.signal_multiplier + Config.base_signal, Config.min_signal, Config.max_signal\n    )","metadata":{"execution":{"iopub.status.busy":"2025-11-07T19:10:50.733872Z","iopub.execute_input":"2025-11-07T19:10:50.734217Z","iopub.status.idle":"2025-11-07T19:10:50.739578Z","shell.execute_reply.started":"2025-11-07T19:10:50.734194Z","shell.execute_reply":"2025-11-07T19:10:50.738477Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def predict(test: pl.DataFrame) -> float:\n    data = test.to_pandas()\n    data = torch.tensor(data[test_cols].copy().to_numpy(),dtype=torch.float32)\n    y_pred = model.forward(data)\n    pred = float(y_pred.item())\n    print(pred)\n    signal = convert_ret_to_signal(pred)\n    print(signal)\n    return signal\n    \n","metadata":{"execution":{"iopub.status.busy":"2025-11-07T19:10:50.740866Z","iopub.execute_input":"2025-11-07T19:10:50.741258Z","iopub.status.idle":"2025-11-07T19:10:50.766857Z","shell.execute_reply.started":"2025-11-07T19:10:50.741229Z","shell.execute_reply":"2025-11-07T19:10:50.765633Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# When your notebook is run on the hidden test set, inference_server.serve must be called within 15 minutes of the notebook starting\n# or the gateway will throw an error. If you need more than 15 minutes to load your model you can do so during the very\n# first `predict` call, which does not have the usual 1 minute response deadline.\ninference_server = kaggle_evaluation.default_inference_server.DefaultInferenceServer(predict)\n\nif os.getenv('KAGGLE_IS_COMPETITION_RERUN'):\n    inference_server.serve()\nelse:\n    inference_server.run_local_gateway(('/kaggle/input/hull-tactical-market-prediction/',))","metadata":{"execution":{"iopub.status.busy":"2025-11-07T19:10:50.771219Z","iopub.execute_input":"2025-11-07T19:10:50.771726Z","iopub.status.idle":"2025-11-07T19:10:51.371677Z","shell.execute_reply.started":"2025-11-07T19:10:50.7717Z","shell.execute_reply":"2025-11-07T19:10:51.370634Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"thing = pd.read_parquet(\"/kaggle/working/submission.parquet\")\nthing","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-07T19:10:51.372721Z","iopub.execute_input":"2025-11-07T19:10:51.37298Z","iopub.status.idle":"2025-11-07T19:10:51.56545Z","shell.execute_reply.started":"2025-11-07T19:10:51.37296Z","shell.execute_reply":"2025-11-07T19:10:51.564117Z"}},"outputs":[],"execution_count":null}]}