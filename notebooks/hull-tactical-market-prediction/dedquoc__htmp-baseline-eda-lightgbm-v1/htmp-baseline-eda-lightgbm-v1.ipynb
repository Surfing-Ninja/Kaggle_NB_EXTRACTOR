{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":111543,"databundleVersionId":13750964,"sourceType":"competition"}],"dockerImageVersionId":31089,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Load Data","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport warnings\nwarnings.filterwarnings('ignore')\n\ntrain = pd.read_csv(\"/kaggle/input/hull-tactical-market-prediction/train.csv\")\ntest = pd.read_csv(\"/kaggle/input/hull-tactical-market-prediction/test.csv\")\n\nprint(\"Train shape:\", train.shape)\nprint(\"Test shape:\", test.shape)\nprint(\"Train columns:\", train.columns.tolist())\nprint(\"Test columns:\", test.columns.tolist())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-20T11:27:28.602341Z","iopub.execute_input":"2025-09-20T11:27:28.60256Z","iopub.status.idle":"2025-09-20T11:27:29.186424Z","shell.execute_reply.started":"2025-09-20T11:27:28.60254Z","shell.execute_reply":"2025-09-20T11:27:29.185507Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# EDA + Train Model","metadata":{}},{"cell_type":"markdown","source":"## EDA Notebook Template (clean + analytic)","metadata":{}},{"cell_type":"code","source":"%%time\n# ==============================\n# 1. Setup\n# ==============================\nimport pandas as pd, numpy as np\nimport matplotlib.pyplot as plt, seaborn as sns\nfrom sklearn.decomposition import PCA\nfrom sklearn.ensemble import RandomForestRegressor\n\ntrain = pd.read_csv(\"/kaggle/input/hull-tactical-market-prediction/train.csv\")\ntest  = pd.read_csv(\"/kaggle/input/hull-tactical-market-prediction/test.csv\")\n\nprint(train.shape, test.shape)\ntrain.head()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-20T11:27:29.187307Z","iopub.execute_input":"2025-09-20T11:27:29.187543Z","iopub.status.idle":"2025-09-20T11:27:30.222363Z","shell.execute_reply.started":"2025-09-20T11:27:29.187522Z","shell.execute_reply":"2025-09-20T11:27:30.221348Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%%time\n# ==============================\n# 2. Targets\n# ==============================\ntarget_cols = [\"forward_returns\", \"risk_free_rate\", \"market_forward_excess_returns\"]\n\nfig, axes = plt.subplots(1, 3, figsize=(15,4))\nfor i, col in enumerate(target_cols):\n    sns.histplot(train[col], bins=30, kde=True, ax=axes[i])\n    axes[i].set_title(col)\nplt.tight_layout()\nplt.show()\n\nprint(train[target_cols].corr())\nsns.heatmap(train[target_cols].corr(), annot=True, cmap=\"coolwarm\")\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-20T11:27:30.223385Z","iopub.execute_input":"2025-09-20T11:27:30.223681Z","iopub.status.idle":"2025-09-20T11:27:31.404905Z","shell.execute_reply.started":"2025-09-20T11:27:30.22366Z","shell.execute_reply":"2025-09-20T11:27:31.404061Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%%time\n# ==============================\n# 2. Targets\n# ==============================\ntarget_cols = [\"forward_returns\", \"risk_free_rate\", \"market_forward_excess_returns\"]\n\nfig, axes = plt.subplots(1, 3, figsize=(15,4))\nfor i, col in enumerate(target_cols):\n    sns.histplot(train[col], bins=30, kde=True, ax=axes[i])\n    axes[i].set_title(col)\nplt.tight_layout()\nplt.show()\n\nprint(train[target_cols].corr())\nsns.heatmap(train[target_cols].corr(), annot=True, cmap=\"coolwarm\")\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-20T11:27:31.405889Z","iopub.execute_input":"2025-09-20T11:27:31.406211Z","iopub.status.idle":"2025-09-20T11:27:32.514831Z","shell.execute_reply.started":"2025-09-20T11:27:31.406184Z","shell.execute_reply":"2025-09-20T11:27:32.514064Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%%time\n# ==============================\n# 3. Feature Groups\n# ==============================\ngroups = {\n    \"D\": [f\"D{i}\" for i in range(1,10)],\n    \"E\": [f\"E{i}\" for i in list(range(1,10))+list(range(10,21))],\n    \"I\": [f\"I{i}\" for i in range(1,10)],\n    \"M\": [f\"M{i}\" for i in range(1,19)],\n    \"P\": [f\"P{i}\" for i in range(1,14)],\n    \"S\": [f\"S{i}\" for i in range(1,13)],\n    \"V\": [f\"V{i}\" for i in range(1,14)],\n}\n\nfor g, cols in groups.items():\n    plt.figure(figsize=(10,6))\n    sns.heatmap(train[cols].corr(), cmap=\"coolwarm\", center=0)\n    plt.title(f\"Correlation Heatmap: Group {g}\")\n    plt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-20T11:27:32.515656Z","iopub.execute_input":"2025-09-20T11:27:32.515925Z","iopub.status.idle":"2025-09-20T11:27:34.630364Z","shell.execute_reply.started":"2025-09-20T11:27:32.515898Z","shell.execute_reply":"2025-09-20T11:27:34.629475Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%%time\n# ==============================\n# 4. Train vs Test Comparison\n# ==============================\nshared_cols = [c for c in train.columns if c in test.columns and c not in [\"date_id\"]]\n\nfor col in shared_cols[:5]:  # preview first 5\n    plt.figure(figsize=(7,4))\n    sns.kdeplot(train[col], label=\"Train\", fill=True)\n    sns.kdeplot(test[col], label=\"Test\", fill=True)\n    plt.title(f\"Train vs Test: {col}\")\n    plt.legend()\n    plt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-20T11:27:34.632861Z","iopub.execute_input":"2025-09-20T11:27:34.633287Z","iopub.status.idle":"2025-09-20T11:27:35.970739Z","shell.execute_reply.started":"2025-09-20T11:27:34.633266Z","shell.execute_reply":"2025-09-20T11:27:35.969969Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%%time\n# ==============================\n# 4. Train vs Test Comparison\n# ==============================\nshared_cols = [c for c in train.columns if c in test.columns and c not in [\"date_id\"]]\n\nfor col in shared_cols[:5]:  # preview first 5\n    plt.figure(figsize=(7,4))\n    sns.kdeplot(train[col], label=\"Train\", fill=True)\n    sns.kdeplot(test[col], label=\"Test\", fill=True)\n    plt.title(f\"Train vs Test: {col}\")\n    plt.legend()\n    plt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-20T11:27:35.971921Z","iopub.execute_input":"2025-09-20T11:27:35.972563Z","iopub.status.idle":"2025-09-20T11:27:37.468181Z","shell.execute_reply.started":"2025-09-20T11:27:35.97254Z","shell.execute_reply":"2025-09-20T11:27:37.467126Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%%time\n# ==============================\n# 6. Feature Importance\n# ==============================\nX = train[shared_cols].fillna(0)\ny = train[\"forward_returns\"]\n\nrf = RandomForestRegressor(n_estimators=200, random_state=42)\nrf.fit(X, y)\n\nimp = pd.DataFrame({\"feature\": shared_cols, \"importance\": rf.feature_importances_})\nimp = imp.sort_values(\"importance\", ascending=False)\n\nplt.figure(figsize=(8,6))\nsns.barplot(data=imp.head(20), x=\"importance\", y=\"feature\")\nplt.title(\"Top 20 Feature Importances (RF baseline)\")\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-20T11:27:37.469073Z","iopub.execute_input":"2025-09-20T11:27:37.469397Z","iopub.status.idle":"2025-09-20T11:33:14.973256Z","shell.execute_reply.started":"2025-09-20T11:27:37.469368Z","shell.execute_reply":"2025-09-20T11:33:14.972227Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%%time\n# =========================================\n# Hull Tactical - Market Prediction\n# Baseline with EDA + LightGBM\n# =========================================\n\nimport os\nimport pandas as pd\nimport polars as pl\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error\nimport lightgbm as lgb\n\n\n# -------------------------\n# 1. Load Data\n# -------------------------\nDATA_PATH = \"/kaggle/input/hull-tactical-market-prediction/\"\n\ntrain = pd.read_csv(os.path.join(DATA_PATH, \"train.csv\"))\ntest = pd.read_csv(os.path.join(DATA_PATH, \"test.csv\"))\n\nprint(\"Train shape:\", train.shape)\nprint(\"Test shape:\", test.shape)\nprint(train.head())\n\n# -------------------------\n# 2. EDA\n# -------------------------\nplt.figure(figsize=(8,4))\nsns.histplot(train[\"forward_returns\"], bins=50, kde=True)\nplt.title(\"Distribution of Forward Returns\")\nplt.show()\n\nplt.figure(figsize=(10,6))\ncorr = train.corr(numeric_only=True)\nsns.heatmap(corr, cmap=\"coolwarm\", center=0)\nplt.title(\"Correlation Heatmap\")\nplt.show()\n\n# -------------------------\n# 3. Feature Preparation\n# -------------------------\ntarget = \"forward_returns\"\nfeatures = [c for c in train.columns if c not in [target, \"risk_free_rate\"]]\n\nX = train[features]\ny = train[target]\n\n# time-based split: last 20% as validation\nsplit_idx = int(len(train) * 0.8)\nX_train, X_val = X.iloc[:split_idx], X.iloc[split_idx:]\ny_train, y_val = y.iloc[:split_idx], y.iloc[split_idx:]\n\n# -------------------------\n# 4. Baseline Model\n# -------------------------\nmodel = lgb.LGBMRegressor(\n    n_estimators=200,\n    learning_rate=0.05,\n    max_depth=6,\n    random_state=42\n)\n\nmodel.fit(X_train, y_train,\n          eval_set=[(X_val, y_val)],\n          eval_metric=\"rmse\",\n          #early_stopping_rounds=50,\n          #verbose=False\n          #force_col_wise=true\n         )\n\nval_preds = model.predict(X_val)\nrmse = mean_squared_error(y_val, val_preds, squared=False)\nprint(f\"Validation RMSE: {rmse:.5f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-20T11:33:14.974461Z","iopub.execute_input":"2025-09-20T11:33:14.974811Z","iopub.status.idle":"2025-09-20T11:33:22.279993Z","shell.execute_reply.started":"2025-09-20T11:33:14.974757Z","shell.execute_reply":"2025-09-20T11:33:22.279124Z"},"_kg_hide-input":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Prediction","metadata":{}},{"cell_type":"code","source":"%%time\nimport os\nimport numpy as np\nimport pandas as pd\nimport polars as pl\n\nfrom sklearn.linear_model import Ridge\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler\n\nimport kaggle_evaluation.default_inference_server\n\n\n# =======================\n# Load Training Data\n# =======================\ntrain = pd.read_csv(\"/kaggle/input/hull-tactical-market-prediction/train.csv\")\n\ntarget = \"market_forward_excess_returns\"\nexclude_cols = [\"date_id\", target]\nfeatures = [c for c in train.columns if c not in exclude_cols]\n\nX = train[features]\ny = train[target]\n\n# =======================\n# Train Model\n# =======================\nmodel = Pipeline([\n    (\"imputer\", SimpleImputer(strategy=\"median\")),\n    (\"scaler\", StandardScaler()),\n    (\"ridge\", Ridge(alpha=1.0))\n])\nmodel.fit(X, y)\n\n# =======================\n# Predict Function\n# =======================\nprevious_allocation = 1.0  # start neutral\n\ndef predict(test: pl.DataFrame) -> float:\n    global previous_allocation\n\n    # Convert Polars -> Pandas\n    row = test.to_pandas()\n\n    # Make sure only training features are used\n    row = row.reindex(columns=features, fill_value=0)\n\n    # Predict\n    pred = model.predict(row)[0]\n\n    # Convert prediction into allocation\n    allocation = 1.0 + 50 * pred  # scaling factor\n\n    # Clip to [0, 2]\n    allocation = np.clip(allocation, 0.0, 2.0)\n\n    # Smooth with previous allocation\n    allocation = 0.8 * allocation + 0.2 * previous_allocation\n\n    previous_allocation = allocation\n    return float(allocation)\n\n\n# =======================\n# Start Inference Server\n# =======================\ninference_server = kaggle_evaluation.default_inference_server.DefaultInferenceServer(predict)\n\nif os.getenv(\"KAGGLE_IS_COMPETITION_RERUN\"):\n    inference_server.serve()\nelse:\n    inference_server.run_local_gateway((\"/kaggle/input/hull-tactical-market-prediction/\",))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-20T11:33:22.280903Z","iopub.execute_input":"2025-09-20T11:33:22.281129Z","iopub.status.idle":"2025-09-20T11:33:22.999267Z","shell.execute_reply.started":"2025-09-20T11:33:22.281112Z","shell.execute_reply":"2025-09-20T11:33:22.998329Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Submit","metadata":{}},{"cell_type":"code","source":"%%time\nimport pandas as pd\n\ndef save_and_validate_submission(predictions, row_ids, filename=\"submission.parquet\"):\n    \"\"\"\n    Save predictions in Parquet format and validate structure before submission.\n    \"\"\"\n    # Build dataframe\n    submission = pd.DataFrame({\n        \"row_id\": row_ids,\n        \"prediction\": predictions\n    })\n\n    # Save to parquet\n    submission.to_parquet(filename, index=False)\n\n    # Reload to validate\n    sub_check = pd.read_parquet(filename)\n\n    # Validation checks\n    print(\"âœ… Submission saved as Parquet\")\n    print(\"Columns:\", sub_check.columns.tolist())\n    print(\"Number of rows:\", len(sub_check))\n    print(\"Missing values:\", sub_check.isnull().sum().sum())\n    print(sub_check.head())\n\n    return filename\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-20T11:33:23.00015Z","iopub.execute_input":"2025-09-20T11:33:23.000406Z","iopub.status.idle":"2025-09-20T11:33:23.007194Z","shell.execute_reply.started":"2025-09-20T11:33:23.000385Z","shell.execute_reply":"2025-09-20T11:33:23.006318Z"}},"outputs":[],"execution_count":null}]}