{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":111543,"databundleVersionId":13750964,"isSourceIdPinned":false,"sourceType":"competition"}],"dockerImageVersionId":31090,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-10-06T11:58:06.481809Z","iopub.execute_input":"2025-10-06T11:58:06.482065Z","iopub.status.idle":"2025-10-06T11:58:06.803636Z","shell.execute_reply.started":"2025-10-06T11:58:06.482044Z","shell.execute_reply":"2025-10-06T11:58:06.802835Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport polars as pl\nimport pandas as pd\nimport numpy as np\nfrom sklearn.preprocessing import StandardScaler\nimport pickle\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import TensorDataset, DataLoader","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-06T11:58:06.804806Z","iopub.execute_input":"2025-10-06T11:58:06.805333Z","iopub.status.idle":"2025-10-06T11:58:14.938165Z","shell.execute_reply.started":"2025-10-06T11:58:06.805315Z","shell.execute_reply":"2025-10-06T11:58:14.937552Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"FINAL_MODEL = None\nSCALER = None\nFEATURE_COLUMNS = []\nHISTORY_BUFFER = None\nDEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nSEQUENCE_LENGTH = 20","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-06T11:58:14.938885Z","iopub.execute_input":"2025-10-06T11:58:14.939224Z","iopub.status.idle":"2025-10-06T11:58:15.026359Z","shell.execute_reply.started":"2025-10-06T11:58:14.939205Z","shell.execute_reply":"2025-10-06T11:58:15.025774Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":" class LSTMPredictor(nn.Module):\n   \"\"\"LSTM-based model for market return prediction\"\"\"\n   def __init__(self, input_dim, hidden_dim=128, num_layers=2, dropout=0.2):\n        super(LSTMPredictor, self).__init__()\n        \n        self.hidden_dim = hidden_dim\n        self.num_layers = num_layers\n        \n        self.lstm = nn.LSTM(\n            input_size=input_dim,\n            hidden_size=hidden_dim,\n            num_layers=num_layers,\n            batch_first=True,\n            dropout=dropout if num_layers > 1 else 0\n        )\n        \n        self.attention = nn.Sequential(\n            nn.Linear(hidden_dim, hidden_dim // 2),\n            nn.Tanh(),\n            nn.Linear(hidden_dim // 2, 1)\n        )\n        \n        self.fc = nn.Sequential(\n            nn.Linear(hidden_dim, 64),\n            nn.ReLU(),\n            nn.Dropout(dropout),\n            nn.Linear(64, 32),\n            nn.ReLU(),\n            nn.Dropout(dropout),\n            nn.Linear(32, 1)\n        )\n   def forward(self, x):\n        lstm_out, (hidden, cell) = self.lstm(x)\n        attention_weights = torch.softmax(self.attention(lstm_out), dim=1)\n        context = torch.sum(attention_weights * lstm_out, dim=1)        \n        output = self.fc(context)\n        return output","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-06T11:58:15.028033Z","iopub.execute_input":"2025-10-06T11:58:15.0283Z","iopub.status.idle":"2025-10-06T11:58:15.043696Z","shell.execute_reply.started":"2025-10-06T11:58:15.028271Z","shell.execute_reply":"2025-10-06T11:58:15.043002Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def convert_to_signal(predictions: np.ndarray, multiplier: float = 400.0) -> np.ndarray:\n    signals = predictions * multiplier + 1\n    return np.clip(signals, 0.0, 2.0)\n\ndef simple_impute(df):\n    df_imp = df.copy()\n    \n    numeric_cols = df_imp.select_dtypes(include=[np.number]).columns\n    for col in numeric_cols:\n        df_imp[col] = df_imp[col].fillna(method='ffill').fillna(method='bfill').fillna(0)\n    \n    return df_imp","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-06T11:58:15.0446Z","iopub.execute_input":"2025-10-06T11:58:15.044852Z","iopub.status.idle":"2025-10-06T11:58:15.064131Z","shell.execute_reply.started":"2025-10-06T11:58:15.044827Z","shell.execute_reply":"2025-10-06T11:58:15.063598Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def create_sequences(X, y, sequence_length):\n    \"\"\"Create sequences for LSTM training\"\"\"\n    X_seq = []\n    y_seq = []\n    \n    for i in range(len(X) - sequence_length):\n        X_seq.append(X[i:i + sequence_length])\n        y_seq.append(y[i + sequence_length])\n    \n    return np.array(X_seq), np.array(y_seq)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-06T11:58:15.064822Z","iopub.execute_input":"2025-10-06T11:58:15.065494Z","iopub.status.idle":"2025-10-06T11:58:15.079654Z","shell.execute_reply.started":"2025-10-06T11:58:15.065472Z","shell.execute_reply":"2025-10-06T11:58:15.078979Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def train_model():\n    global FINAL_MODEL, SCALER, FEATURE_COLUMNS, HISTORY_BUFFER, SEQUENCE_LENGTH\n    \n    print(\"Training LSTM model...\")\n    print(f\"Using device: {DEVICE}\")\n    start_time = pd.Timestamp.now()\n    \n    path = \"/kaggle/input/hull-tactical-market-prediction\"\n    print(f\"Loading data from {path}\")\n    \n    training_df = pd.read_csv(f\"{path}/train.csv\")\n    print(f\"Loaded {len(training_df)} rows\")\n    \n    print(\"Imputing missing values...\")\n    training_df = simple_impute(training_df)\n    print(f\"Imputation done. Remaining NaN: {training_df.isnull().sum().sum()}\")\n    \n    if isinstance(training_df, pd.DataFrame):\n        training_df = pl.from_pandas(training_df)\n    \n    training_df = training_df.rename({'market_forward_excess_returns': 'target'})\n    \n    feature_cols = [col for col in training_df.columns if col != 'date_id']\n    training_df = training_df.with_columns(pl.col(feature_cols).cast(pl.Float64, strict=False))\n    \n    training_df = training_df.drop_nulls()\n    print(f\"After dropping nulls: {len(training_df)} rows\")\n    \n    FEATURE_COLUMNS = [col for col in training_df.columns \n                       if col not in ['date_id', 'target', 'forward_returns', 'risk_free_rate']]\n    \n    print(f\"Training with {len(FEATURE_COLUMNS)} features\")\n    \n    X_train = training_df.select(FEATURE_COLUMNS).to_numpy()\n    y_train = training_df.select('target').to_numpy().ravel()\n    \n    SCALER = StandardScaler()\n    X_train_scaled = SCALER.fit_transform(X_train)\n    \n    print(f\"Creating sequences with length {SEQUENCE_LENGTH}...\")\n    X_seq, y_seq = create_sequences(X_train_scaled, y_train, SEQUENCE_LENGTH)\n    print(f\"Created {len(X_seq)} sequences\")\n    \n    X_tensor = torch.FloatTensor(X_seq).to(DEVICE)\n    y_tensor = torch.FloatTensor(y_seq).reshape(-1, 1).to(DEVICE)\n    \n    dataset = TensorDataset(X_tensor, y_tensor)\n    train_loader = DataLoader(dataset, batch_size=128, shuffle=True)\n    \n    input_dim = len(FEATURE_COLUMNS)\n    FINAL_MODEL = LSTMPredictor(\n        input_dim=input_dim,\n        hidden_dim=128,\n        num_layers=2,\n        dropout=0.3\n    ).to(DEVICE)\n    \n    criterion = nn.MSELoss()\n    optimizer = optim.Adam(FINAL_MODEL.parameters(), lr=0.001, weight_decay=1e-5)\n    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5, verbose=True)\n    \n    num_epochs = 100\n    best_loss = float('inf')\n    patience = 15\n    patience_counter = 0\n    \n    print(\"Starting training...\")\n    FINAL_MODEL.train()\n    \n    for epoch in range(num_epochs):\n        total_loss = 0\n        \n        for batch_X, batch_y in train_loader:\n            optimizer.zero_grad()\n            \n            predictions = FINAL_MODEL(batch_X)\n            \n            loss = criterion(predictions, batch_y)\n            \n            loss.backward()\n            \n            torch.nn.utils.clip_grad_norm_(FINAL_MODEL.parameters(), max_norm=1.0)\n            \n            optimizer.step()\n            \n            total_loss += loss.item()\n        \n        avg_loss = total_loss / len(train_loader)\n        scheduler.step(avg_loss)\n        \n        if (epoch + 1) % 10 == 0:\n            print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.6f}\")\n        \n        if avg_loss < best_loss:\n            best_loss = avg_loss\n            patience_counter = 0\n        else:\n            patience_counter += 1\n        \n        if patience_counter >= patience:\n            print(f\"Early stopping at epoch {epoch+1}\")\n            break\n    \n    FINAL_MODEL.eval()\n    print(f\"Model training complete! Best Loss: {best_loss:.6f}\")\n    \n    buffer_size = SEQUENCE_LENGTH + 50\n    HISTORY_BUFFER = training_df.select(\n        ['date_id'] + FEATURE_COLUMNS + ['target', 'forward_returns', 'risk_free_rate']\n    ).tail(buffer_size)\n    \n    elapsed = (pd.Timestamp.now() - start_time).total_seconds()\n    print(f\"Model training complete in {elapsed:.1f} seconds. Ready for predictions.\")\n\ndef predict(test: pl.DataFrame) -> float:\n    \"\"\"\n    Make a prediction for a single test row.\n    \n    Args:\n        test: A polars DataFrame with one row containing the test features\n        \n    Returns:\n        A float signal value between 0 and 2\n    \"\"\"\n    global HISTORY_BUFFER, FINAL_MODEL, SCALER, FEATURE_COLUMNS, SEQUENCE_LENGTH\n    \n    try:\n        feature_cols = [col for col in test.columns if col != 'date_id']\n        test = test.with_columns(pl.col(feature_cols).cast(pl.Float64, strict=False))\n        \n        rename_mapping = {}\n        if 'lagged_forward_returns' in test.columns:\n            rename_mapping['lagged_forward_returns'] = 'forward_returns'\n        if 'lagged_risk_free_rate' in test.columns:\n            rename_mapping['lagged_risk_free_rate'] = 'risk_free_rate'\n        if 'lagged_market_forward_excess_returns' in test.columns:\n            rename_mapping['lagged_market_forward_excess_returns'] = 'target'\n        \n        if rename_mapping:\n            test = test.rename(rename_mapping)\n        \n        if 'is_scored' in test.columns:\n            test = test.drop('is_scored')\n        \n        for col in HISTORY_BUFFER.columns:\n            if col not in test.columns:\n                test = test.with_columns(pl.lit(0.0).cast(pl.Float64).alias(col))\n        \n        test = test.select(HISTORY_BUFFER.columns)\n        \n        HISTORY_BUFFER = pl.concat([HISTORY_BUFFER, test], how=\"vertical\")\n        \n        max_buffer = SEQUENCE_LENGTH + 100\n        if len(HISTORY_BUFFER) > max_buffer:\n            HISTORY_BUFFER = HISTORY_BUFFER.tail(max_buffer)\n        \n        if len(HISTORY_BUFFER) < SEQUENCE_LENGTH:\n            needed = SEQUENCE_LENGTH - len(HISTORY_BUFFER)\n            first_row = HISTORY_BUFFER.head(1)\n            padding = pl.concat([first_row] * needed, how=\"vertical\")\n            sequence_data = pl.concat([padding, HISTORY_BUFFER], how=\"vertical\")\n        else:\n            sequence_data = HISTORY_BUFFER.tail(SEQUENCE_LENGTH)\n        \n        X_sequence = sequence_data.select(FEATURE_COLUMNS).to_numpy()\n        \n        X_sequence = np.nan_to_num(X_sequence, nan=0.0)\n        \n        X_sequence_scaled = SCALER.transform(X_sequence)\n        \n        X_sequence_scaled = X_sequence_scaled.reshape(1, SEQUENCE_LENGTH, -1)\n        \n        X_tensor = torch.FloatTensor(X_sequence_scaled).to(DEVICE)\n        \n        with torch.no_grad():\n            raw_prediction = FINAL_MODEL(X_tensor).cpu().numpy()[0, 0]\n        \n        signal = convert_to_signal(np.array([raw_prediction]))[0]\n        \n        return float(signal)\n        \n    except Exception as e:\n        print(f\"Error in prediction: {e}\")\n        import traceback\n        traceback.print_exc()\n        return 1.0\n\nprint(\"=\"*50)\nprint(\"Starting LSTM model training...\")\nprint(\"=\"*50)\ntrain_model()\nprint(\"=\"*50)\nprint(\"Model ready. Starting inference server...\")\nprint(\"=\"*50)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-06T11:58:15.080463Z","iopub.execute_input":"2025-10-06T11:58:15.08069Z","iopub.status.idle":"2025-10-06T11:58:30.195404Z","shell.execute_reply.started":"2025-10-06T11:58:15.080672Z","shell.execute_reply":"2025-10-06T11:58:30.194632Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import kaggle_evaluation.default_inference_server\n\ninference_server = kaggle_evaluation.default_inference_server.DefaultInferenceServer(predict)\n\nif os.getenv('KAGGLE_IS_COMPETITION_RERUN'):\n    print(\"Running in competition mode\")\n    inference_server.serve()\nelse:\n    print(\"Running in local gateway mode\")\n    inference_server.run_local_gateway(\n        ('/kaggle/input/hull-tactical-market-prediction/',)\n    )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-06T11:58:30.19616Z","iopub.execute_input":"2025-10-06T11:58:30.1966Z","iopub.status.idle":"2025-10-06T11:58:30.687832Z","shell.execute_reply.started":"2025-10-06T11:58:30.196565Z","shell.execute_reply":"2025-10-06T11:58:30.686833Z"}},"outputs":[],"execution_count":null}]}