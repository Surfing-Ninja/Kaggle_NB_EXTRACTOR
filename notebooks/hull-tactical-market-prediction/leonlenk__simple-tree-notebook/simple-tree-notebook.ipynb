{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":111543,"databundleVersionId":13750964,"sourceType":"competition"}],"dockerImageVersionId":31153,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport xgboost as xgb\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport polars as pl\nimport os\nimport kaggle_evaluation.default_inference_server","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-22T02:28:50.846047Z","iopub.execute_input":"2025-10-22T02:28:50.846671Z","iopub.status.idle":"2025-10-22T02:28:56.634813Z","shell.execute_reply.started":"2025-10-22T02:28:50.84664Z","shell.execute_reply":"2025-10-22T02:28:56.633666Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Load data\ntrain = pd.read_csv(\"/kaggle/input/hull-tactical-market-prediction/train.csv\")\ntest = pd.read_csv(\"/kaggle/input/hull-tactical-market-prediction/test.csv\")\n\n# Columns to keep\ntest_cols = [\"M1\", \"E1\", \"I1\", \"P1\", \"V1\", \"S1\", \"D1\"]\ntrain_cols = [\"forward_returns\", \"risk_free_rate\", \"market_forward_excess_returns\"]\nbase_col = [\"date_id\"]\n\n# Apply filtering\ntrain_filtered = train[base_col + test_cols + train_cols]\ntest_filtered = test[base_col + test_cols]\n\nwindow = 50 # number of days in each normalization window\n\nrolling_min = train_filtered[\"market_forward_excess_returns\"].rolling(window).min()\nrolling_max = train_filtered[\"market_forward_excess_returns\"].rolling(window).max()\n\ntrain_filtered[\"target_market_norm\"] = (\n    (train_filtered[\"forward_returns\"] - rolling_min) / (rolling_max - rolling_min)\n)\ntrain_filtered[\"target_market_norm\"].bfill(inplace=True)\n\n# remove duplicate colums\ntrain_filtered = train_filtered.loc[:, ~train_filtered.columns.duplicated()]\ntest_filtered = test_filtered.loc[:, ~test_filtered.columns.duplicated()]\n\nprint(f\"Number of rows in train: {len(train_filtered)}\")\nprint(f\"Number of rows in test: {len(test_filtered)}\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-10-22T02:30:20.924749Z","iopub.execute_input":"2025-10-22T02:30:20.926641Z","iopub.status.idle":"2025-10-22T02:30:21.163949Z","shell.execute_reply.started":"2025-10-22T02:30:20.926604Z","shell.execute_reply":"2025-10-22T02:30:21.162881Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Count number of rows with at least one NaN\nnum_nan_train = train_filtered.isna().any(axis=1).sum()\nnum_nan_test = test_filtered.isna().any(axis=1).sum()\n\nprint(f\"Number of rows with NaN in train: {num_nan_train}\")\nprint(f\"Number of rows with NaN in test: {num_nan_test}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-22T02:30:34.417123Z","iopub.execute_input":"2025-10-22T02:30:34.417456Z","iopub.status.idle":"2025-10-22T02:30:34.425622Z","shell.execute_reply.started":"2025-10-22T02:30:34.417435Z","shell.execute_reply":"2025-10-22T02:30:34.424373Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X = train_filtered[test_cols]  # features\ny = train_filtered[\"target_market_norm\"]  # target\n\n# Optional: remove rows where target is NaN\nmask = y.notna()\nX = X[mask]\ny = y[mask]\n# X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, shuffle=False)  # preserve time order\n# xg_reg = xgb.XGBRegressor(\n#     n_estimators=100,\n#     max_depth=5,\n#     learning_rate=0.1,\n#     subsample=0.8,\n#     colsample_bytree=0.8,\n#     missing=np.nan,\n#     random_state=42\n# )\n\n# xg_reg.fit(X_train, y_train)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-22T02:36:09.644288Z","iopub.execute_input":"2025-10-22T02:36:09.64546Z","iopub.status.idle":"2025-10-22T02:36:09.654516Z","shell.execute_reply.started":"2025-10-22T02:36:09.645418Z","shell.execute_reply":"2025-10-22T02:36:09.653005Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def competition_metric(y_true, y_pred, market_forward_excess_returns):\n    \"\"\"\n    Custom Hull Tactical evaluation metric:\n    Measures risk-adjusted performance relative to the market.\n    \"\"\"\n    # Strategy excess return relative to market\n    strategy_excess = y_pred - market_forward_excess_returns\n\n    # Penalized Sharpe-like ratio\n    numerator = np.mean(strategy_excess)\n    denominator = np.std(strategy_excess)\n\n    # To avoid division by zero\n    if denominator == 0:\n        return 0.0\n\n    return numerator / denominator","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-22T02:36:11.173641Z","iopub.execute_input":"2025-10-22T02:36:11.173975Z","iopub.status.idle":"2025-10-22T02:36:11.17975Z","shell.execute_reply.started":"2025-10-22T02:36:11.173953Z","shell.execute_reply":"2025-10-22T02:36:11.178642Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# y_pred = xg_reg.predict(X_val)\n# market_excess = train_filtered.loc[y_val.index, \"market_forward_excess_returns\"]\n# score = competition_metric(y_val.values, y_pred, market_excess.values)\n# print(f\"Sharpe ratio: {score:.6f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-22T02:36:12.560659Z","iopub.execute_input":"2025-10-22T02:36:12.560998Z","iopub.status.idle":"2025-10-22T02:36:12.566889Z","shell.execute_reply.started":"2025-10-22T02:36:12.560975Z","shell.execute_reply":"2025-10-22T02:36:12.565409Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.model_selection import TimeSeriesSplit\n\n# --- 1. Prepare Data ---\n# We need X, y, and the market returns aligned *before* splitting\nX = train_filtered[test_cols]\ny = train_filtered[\"target_market_norm\"]\nmarket_returns = train_filtered[\"market_forward_excess_returns\"]\n\n# Remove rows where the target (y) is NaN, and apply the same mask to X and market_returns\nmask = y.notna()\nX = X[mask]\ny = y[mask]\nmarket_returns = market_returns[mask]\n\n# --- 2. Define Cross-Validation Strategy ---\nN_SPLITS = 5\ntscv = TimeSeriesSplit(n_splits=N_SPLITS)\n\n# Store scores from each fold\nscores = []\n\nprint(\"Starting 5-fold time-series cross-validation...\")\n\n# --- 3. Run the CV Loop ---\n# We run the loop manually because our custom metric needs an extra argument (market_returns)\nfor fold, (train_index, val_index) in enumerate(tscv.split(X)):\n    print(f\"--- Fold {fold+1}/{N_SPLITS} ---\")\n    \n    # Get the data for this fold\n    X_train, X_val = X.iloc[train_index], X.iloc[val_index]\n    y_train, y_val = y.iloc[train_index], y.iloc[val_index]\n    market_val = market_returns.iloc[val_index] # Get market returns for the validation set\n    \n    print(f\"Train size: {len(X_train)}, Validation size: {len(X_val)}\")\n\n    # Define the model *inside* the loop to ensure it's retrained from scratch\n    xg_reg = xgb.XGBRegressor(\n        n_estimators=100,\n        max_depth=5,\n        learning_rate=0.1,\n        subsample=0.8,\n        colsample_bytree=0.8,\n        missing=np.nan,\n        random_state=42\n    )\n    \n    # Train the model\n    xg_reg.fit(X_train, y_train)\n    \n    # Make predictions\n    y_pred = xg_reg.predict(X_val)\n    \n    # Evaluate using the competition metric\n    score = competition_metric(y_val.values, y_pred, market_val.values)\n    scores.append(score)\n    print(f\"Fold {fold+1} Sharpe ratio: {score:.6f}\")\n\n# --- 4. Report Final Results ---\nprint(\"\\n--- CV Results ---\")\nprint(f\"Scores per fold: {[round(s, 6) for s in scores]}\")\nprint(f\"Mean Sharpe ratio: {np.mean(scores):.6f}\")\nprint(f\"Std Dev of Sharpe ratio: {np.std(scores):.6f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-22T02:37:22.431591Z","iopub.execute_input":"2025-10-22T02:37:22.432754Z","iopub.status.idle":"2025-10-22T02:37:24.22682Z","shell.execute_reply.started":"2025-10-22T02:37:22.432715Z","shell.execute_reply":"2025-10-22T02:37:24.225674Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"\\nTraining final model on all data...\")\n\n# Use the full X and y (with NaNs removed)\nfinal_model = xgb.XGBRegressor(\n    n_estimators=100,\n    max_depth=5,\n    learning_rate=0.1,\n    subsample=0.8,\n    colsample_bytree=0.8,\n    missing=np.nan,\n    random_state=42\n)\n\nfinal_model.fit(X, y)\n\nprint(\"Final model trained.\")\n\n# --- Make predictions on the test set ---\n# The test_filtered DataFrame was loaded in your second cell\nX_test = test_filtered[test_cols]\ntest_predictions = final_model.predict(X_test)\n\nprint(f\"Generated {len(test_predictions)} predictions for the test set.\")\n\n# (You would then format 'test_predictions' for submission)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-22T02:37:30.206884Z","iopub.execute_input":"2025-10-22T02:37:30.207248Z","iopub.status.idle":"2025-10-22T02:37:30.639962Z","shell.execute_reply.started":"2025-10-22T02:37:30.207224Z","shell.execute_reply":"2025-10-22T02:37:30.638369Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# xgb.plot_importance(xg_reg, max_num_features=10)\n# plt.show()\nxgb.plot_importance(final_model, max_num_features=10) \nplt.savefig(\"feature_importance.png\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-22T02:37:31.950291Z","iopub.execute_input":"2025-10-22T02:37:31.950632Z","iopub.status.idle":"2025-10-22T02:37:32.253037Z","shell.execute_reply.started":"2025-10-22T02:37:31.950611Z","shell.execute_reply":"2025-10-22T02:37:32.251931Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def predict(test: pl.DataFrame) -> float:\n    data = test.to_pandas()\n    data = data[test_cols].copy()\n    y_pred = xg_reg.predict(data)\n    pred = np.clip(y_pred, 0.0, 2.0)[0]\n    print(f\"pred: {pred}\")\n    return float(pred)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-22T02:37:35.522062Z","iopub.execute_input":"2025-10-22T02:37:35.52247Z","iopub.status.idle":"2025-10-22T02:37:35.530115Z","shell.execute_reply.started":"2025-10-22T02:37:35.522445Z","shell.execute_reply":"2025-10-22T02:37:35.52842Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# When your notebook is run on the hidden test set, inference_server.serve must be called within 15 minutes of the notebook starting\n# or the gateway will throw an error. If you need more than 15 minutes to load your model you can do so during the very\n# first `predict` call, which does not have the usual 1 minute response deadline.\ninference_server = kaggle_evaluation.default_inference_server.DefaultInferenceServer(predict)\n\nif os.getenv('KAGGLE_IS_COMPETITION_RERUN'):\n    inference_server.serve()\nelse:\n    inference_server.run_local_gateway(('/kaggle/input/hull-tactical-market-prediction/',))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-22T02:37:35.75104Z","iopub.execute_input":"2025-10-22T02:37:35.751428Z","iopub.status.idle":"2025-10-22T02:37:35.929478Z","shell.execute_reply.started":"2025-10-22T02:37:35.751402Z","shell.execute_reply":"2025-10-22T02:37:35.928065Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}