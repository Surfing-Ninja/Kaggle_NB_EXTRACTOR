{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":111543,"databundleVersionId":13750964,"sourceType":"competition"}],"dockerImageVersionId":31090,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-10-05T05:30:25.379136Z","iopub.execute_input":"2025-10-05T05:30:25.379483Z","iopub.status.idle":"2025-10-05T05:30:25.393706Z","shell.execute_reply.started":"2025-10-05T05:30:25.37946Z","shell.execute_reply":"2025-10-05T05:30:25.393106Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"The metric is a **Modified Sharpe Ratio**. Its goal is to find a strategy that is not just profitable on a risk-adjusted basis (the standard Sharpe Ratio), but one that also definitively beats the market without taking reckless risks.\n\n---\n\n## The Core Components (with Formulas)\n\nLet's define our variables for a given day $t$:\n* $p_t$ = Your position signal (from 0 to 2)\n* $R_{m,t}$ = The market's forward return\n* $R_{f,t}$ = The risk-free rate\n\n#### 1. Strategy Daily Return ($R_{s,t}$)\nThis is the return your portfolio earns each day. It's a weighted average based on your signal: the portion in the market ($p_t$) earns the market return, and the portion in cash ($1-p_t$) earns the risk-free rate.\n\n$$R_{s,t} = p_t \\cdot R_{m,t} + (1 - p_t) \\cdot R_{f,t}$$\n\n---\n#### 2. Annualized Sharpe Ratio ($S$)\nThis is the standard measure of risk-adjusted return. It uses the **geometric mean** of your strategy's *excess returns* ($R_{s,t} - R_{f,t}$) and divides it by the volatility (standard deviation) of your strategy's returns. It's then annualized by multiplying by $\\sqrt{252}$ (the approximate number of trading days in a year).\n\n* Strategy Excess Return: $R_{se,t} = R_{s,t} - R_{f,t}$\n* Geometric Mean Excess Return: $\\bar{R}_{se,g} = \\left( \\prod_{t=1}^{N} (1 + R_{se,t}) \\right)^{1/N} - 1$\n* Strategy Volatility: $\\sigma_s = \\text{StDev}(R_{s,1}, \\dots, R_{s,N})$\n\n$$S = \\frac{\\bar{R}_{se,g}}{\\sigma_s} \\cdot \\sqrt{252}$$\n\n---\n#### 3. Volatility Penalty ($P_v$)\nThis penalizes you if your strategy's annualized volatility ($V_s$) is more than 20% higher than the market's annualized volatility ($V_m$).\n\n* Strategy Annualized Volatility: $V_s = \\sigma_s \\cdot \\sqrt{252}$\n* Market Annualized Volatility: $V_m = \\text{StDev}(R_{m,1}, \\dots, R_{m,N}) \\cdot \\sqrt{252}$\n\n$$P_v = 1 + \\max\\left(0, \\frac{V_s}{V_m} - 1.2\\right)$$\n\n---\n#### 4. Return Penalty ($P_r$)\nThis heavily penalizes you if your strategy's annualized geometric mean return is lower than the market's. The penalty is **quadratic**, meaning it grows very quickly as the performance gap widens.\n\n* Annualized Return Gap ($G_r$): $G_r = \\max(0, (\\bar{R}_{me,g} - \\bar{R}_{se,g}) \\cdot 252)$\n\n$$P_r = 1 + \\frac{G_r^2}{100}$$\n\n---\n#### 5. Final Adjusted Sharpe Ratio ($S_{\\text{adj}}$)\nYour final score is the standard Sharpe Ratio, diminished by any penalties you incurred.\n\n$$S_{\\text{adj}} = \\frac{S}{P_v \\cdot P_r}$$\n\n---\n ## A Step-by-Step Calculation Example\n\nLet's use a simple 3-day period.\n\n| Day (t) | Market Return ($R_{m,t}$) | Risk-Free Rate ($R_{f,t}$) | Your Signal ($p_t$) |\n| :--- | :--- | :--- | :--- |\n| 1 | +1.0% | 0.01% | 1.5 |\n| 2 | -2.0% | 0.01% | 0.2 |\n| 3 | +1.5% | 0.01% | 2.0 |\n\n#### Step 1: Calculate Daily Returns\n* **Strategy Return ($R_{s,t}$)**:\n    * Day 1: $1.5 \\cdot 0.01 + (1 - 1.5) \\cdot 0.0001 = 0.01495 = +1.495\\%$\n    * Day 2: $0.2 \\cdot -0.02 + (1 - 0.2) \\cdot 0.0001 = -0.00392 = -0.392\\%$\n    * Day 3: $2.0 \\cdot 0.015 + (1 - 2.0) \\cdot 0.0001 = 0.0299 = +2.99\\%$\n* **Strategy Excess Return ($R_{se,t}$)**:\n    * Day 1: $1.495\\% - 0.01\\% = +1.485\\%$\n    * Day 2: $-0.392\\% - 0.01\\% = -0.402\\%$\n    * Day 3: $2.99\\% - 0.01\\% = +2.98\\%$\n* **Market Excess Return ($R_{me,t}$)**:\n    * Day 1: $1.0\\% - 0.01\\% = +0.99\\%$\n    * Day 2: $-2.0\\% - 0.01\\% = -2.01\\%$\n    * Day 3: $1.5\\% - 0.01\\% = +1.49\\%$\n\n#### Step 2: Calculate Key Statistics (Mean & Std Dev)\n* **Strategy Geometric Mean**: $\\bar{R}_{se,g} = ((1.01485) \\cdot (0.99598) \\cdot (1.0298))^{1/3} - 1 = 0.01345 = 1.345\\%$\n* **Market Geometric Mean**: $\\bar{R}_{me,g} = ((1.0099) \\cdot (0.9799) \\cdot (1.0149))^{1/3} - 1 = 0.00143 = 0.143\\%$\n* **Strategy StDev**: $\\sigma_s = \\text{StDev}([0.01495, -0.00392, 0.0299]) = 0.0171$\n* **Market StDev**: $\\sigma_m = \\text{StDev}([0.01, -0.02, 0.015]) = 0.0153$\n\n#### Step 3: Calculate the Unadjusted Sharpe Ratio\n$$S = \\frac{0.01345}{0.0171} \\cdot \\sqrt{252} \\approx 12.5$$\n\n#### Step 4: Calculate the Penalties\n* **Volatility Penalty ($P_v$)**:\n    * $V_s = 0.0171 \\cdot \\sqrt{252} \\approx 0.271$ (27.1%)\n    * $V_m = 0.0153 \\cdot \\sqrt{252} \\approx 0.243$ (24.3%)\n    * Ratio: $27.1 / 24.3 \\approx 1.115$. This is **less than 1.2**, so there is no penalty.\n    * $P_v = 1 + \\max(0, 1.115 - 1.2) = 1.0$\n* **Return Penalty ($P_r$)**:\n    * Your strategy's mean (1.345%) is **greater than** the market's mean (0.143%), so there is no penalty.\n    * $P_r = 1.0$\n\n#### Step 5: Calculate the Final Adjusted Score\n$$S_{\\text{adj}} = \\frac{12.5}{1.0 \\cdot 1.0} = 12.5$$\nIn this example, because the strategy comfortably beat the market's return and stayed within its volatility budget, the final score is the same as the unadjusted Sharpe Ratio.","metadata":{}},{"cell_type":"markdown","source":"# Feature Engineering","metadata":{}},{"cell_type":"code","source":"import polars as pl\nimport numpy as np\nimport xgboost as xgb\nimport itertools\nimport os\n\n\n# --- 1. Metric Implementation (No changes here) ---\ndef calculate_competition_score(y_true_df: pl.DataFrame, y_pred_signals: np.ndarray) -> float:\n    solution = y_true_df.to_pandas()\n    solution['position'] = y_pred_signals\n    solution['strategy_returns'] = (\n        solution['risk_free_rate'] * (1 - solution['position']) +\n        solution['position'] * solution['forward_returns']\n    )\n    strategy_excess_returns = solution['strategy_returns'] - solution['risk_free_rate']\n    strategy_geo_mean = (1 + strategy_excess_returns).prod() ** (1 / len(solution)) - 1\n    strategy_std = solution['strategy_returns'].std()\n    if strategy_std == 0: return 0.0\n    trading_days_per_yr = 252\n    sharpe = strategy_geo_mean / strategy_std * np.sqrt(trading_days_per_yr)\n    market_std = solution['forward_returns'].std()\n    market_volatility = market_std * np.sqrt(trading_days_per_yr) * 100\n    strategy_volatility = strategy_std * np.sqrt(trading_days_per_yr) * 100\n    excess_vol = max(0, strategy_volatility / market_volatility - 1.2) if market_volatility > 0 else 0\n    vol_penalty = 1 + excess_vol\n    market_excess_returns = solution['forward_returns'] - solution['risk_free_rate']\n    market_geo_mean = (1 + market_excess_returns).prod() ** (1 / len(solution)) - 1\n    return_gap = max(0, (market_geo_mean - strategy_geo_mean) * 100 * trading_days_per_yr)\n    return_penalty = 1 + (return_gap**2) / 100\n    adjusted_sharpe = sharpe / (vol_penalty * return_penalty)\n    return adjusted_sharpe\n\n\n# --- 2. Feature Engineering (MODIFIED) ---\ndef create_and_save_interaction_features(df: pl.DataFrame, batch_size: int = 20, output_dir=\"features\") -> list[str]:\n    \"\"\"\n    Generates pairwise interaction features in batches to conserve memory and saves them to disk.\n    \"\"\"\n    if not os.path.exists(output_dir):\n        os.makedirs(output_dir)\n\n    base_features = [col for col in df.columns if col not in [\"date_id\", \"forward_returns\", \"risk_free_rate\", \"target\"]]\n    print(f\"Starting batched feature generation for {len(base_features)} base features...\")\n    \n    file_paths = []\n    \n    # Iterate through the features in chunks\n    for i in range(0, len(base_features), batch_size):\n        batch_features = base_features[i:i + batch_size]\n        \n        # Create a temporary DataFrame for this batch's new features\n        batch_interaction_df = pl.DataFrame()\n        \n        # --- Interactions WITHIN the current batch ---\n        for f1, f2 in itertools.combinations(batch_features, 2):\n            batch_interaction_df = batch_interaction_df.with_columns(\n                (df[f1] + df[f2]).alias(f'{f1}_add_{f2}'),\n                (df[f1] - df[f2]).alias(f'{f1}_sub_{f2}'),\n                (df[f1] * df[f2]).alias(f'{f1}_mult_{f2}'),\n            )\n            \n        # --- Interactions BETWEEN the current batch and ALL PREVIOUS features ---\n        previous_features = base_features[:i]\n        for f1 in batch_features:\n            for f2 in previous_features:\n                 batch_interaction_df = batch_interaction_df.with_columns(\n                    (df[f1] + df[f2]).alias(f'{f1}_add_{f2}'),\n                    (df[f1] - df[f2]).alias(f'{f1}_sub_{f2}'),\n                    (df[f1] * df[f2]).alias(f'{f1}_mult_{f2}'),\n                )\n        \n        if batch_interaction_df.width > 0:\n            file_path = f\"{output_dir}/interactions_batch_{i//batch_size}.parquet\"\n            batch_interaction_df.write_parquet(file_path)\n            file_paths.append(file_path)\n            print(f\"  ... Saved batch {i//batch_size} with {batch_interaction_df.width} features to {file_path}\")\n            \n    return file_paths\n\n# --- Main Script ---\n# 1. Load and do initial prep\nfull_train_df = pl.read_csv(\"/kaggle/input/hull-tactical-market-prediction/train.csv\")\nfull_train_df = full_train_df.rename({'market_forward_excess_returns': 'target'})\n\n# Explicitly cast all columns except date_id to Float64 to ensure they are all numeric\nfeature_cols = [col for col in full_train_df.columns if col != 'date_id']\nfull_train_df = full_train_df.with_columns(\n    pl.col(feature_cols).cast(pl.Float64, strict=False)\n)\n\n# Handle nulls in the base data first\nbase_df = full_train_df.with_columns(pl.all().forward_fill()).drop_nulls()\n\n# 2. Generate and save interaction features in batches\ninteraction_files = create_and_save_interaction_features(base_df, batch_size=20)\n\n# 3. Load all features for the selection process\nprint(\"\\nLoading all original and generated features for selection...\")\ninteraction_dfs = [pl.read_parquet(f) for f in interaction_files]\n# Combine original data with all generated feature batches horizontally\nprocessed_df = pl.concat([base_df] + interaction_dfs, how=\"horizontal\")\n\n# 4. Chronological split (same as before)\nVALIDATION_SIZE = 180\ntrain_df = processed_df.head(-VALIDATION_SIZE)\n# We don't need the validation set for feature selection, only training data\nALL_FEATURES = [col for col in train_df.columns if col not in [\"date_id\", \"forward_returns\", \"risk_free_rate\", \"target\"]]\nTARGET_COL = \"target\"\nX_train_all = train_df.select(ALL_FEATURES)\ny_train = train_df.select(TARGET_COL)\n\nprint(f\"\\nGenerated a total of {len(ALL_FEATURES)} features for selection.\")\n\n# 5. Feature Selection using XGBoost Importance\nprint(\"\\nStarting feature selection...\")\nN_FEATURES_TO_SELECT = 150\nselector_model = xgb.XGBRegressor(objective='reg:squarederror', n_estimators=200, random_state=42, n_jobs=-1, tree_method='hist', device='cuda')\nselector_model.fit(X_train_all, y_train, verbose=False)\n\nimportances = selector_model.feature_importances_\nfeature_importance_df = pl.DataFrame({'feature': ALL_FEATURES, 'importance': importances}).sort('importance', descending=True)\nselected_features = feature_importance_df.head(N_FEATURES_TO_SELECT).get_column('feature').to_list()\n\nprint(f\"Selected the top {len(selected_features)} most important features.\")\nfinal_training_data = processed_df.select(\n    selected_features + [\"target\", \"forward_returns\", \"risk_free_rate\"]\n)\n# 6. Save the list of selected features for later use\noutput_filename = \"final_training_data_150_features.parquet\"\nfinal_training_data.write_parquet(output_filename)\n\nprint(f\"Successfully saved final training data with {final_training_data.width} columns to '{output_filename}'\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-05T06:15:07.637639Z","iopub.execute_input":"2025-10-05T06:15:07.637914Z","iopub.status.idle":"2025-10-05T06:15:35.812074Z","shell.execute_reply.started":"2025-10-05T06:15:07.637894Z","shell.execute_reply":"2025-10-05T06:15:35.811236Z"},"scrolled":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Cross validaiton","metadata":{}},{"cell_type":"code","source":"# === Run this in a SEPARATE \"Experimentation\" Notebook ===\n\nimport polars as pl\nimport numpy as np\nimport xgboost as xgb\nfrom sklearn.model_selection import TimeSeriesSplit\n\n# --- Copy the metric and signal functions from your other notebook ---\n\ndef calculate_competition_score(y_true_df: pl.DataFrame, y_pred_signals: np.ndarray) -> float:\n    # (The full function code goes here)\n    solution = y_true_df.to_pandas()\n    solution['position'] = y_pred_signals\n    solution['strategy_returns'] = (\n        solution['risk_free_rate'] * (1 - solution['position']) +\n        solution['position'] * solution['forward_returns']\n    )\n    strategy_excess_returns = solution['strategy_returns'] - solution['risk_free_rate']\n    strategy_geo_mean = (1 + strategy_excess_returns).prod() ** (1 / len(solution)) - 1\n    strategy_std = solution['strategy_returns'].std()\n    if strategy_std == 0: return 0.0\n    trading_days_per_yr = 252\n    sharpe = strategy_geo_mean / strategy_std * np.sqrt(trading_days_per_yr)\n    market_std = solution['forward_returns'].std()\n    market_volatility = market_std * np.sqrt(trading_days_per_yr) * 100\n    strategy_volatility = strategy_std * np.sqrt(trading_days_per_yr) * 100\n    excess_vol = max(0, strategy_volatility / market_volatility - 1.2) if market_volatility > 0 else 0\n    vol_penalty = 1 + excess_vol\n    market_excess_returns = solution['forward_returns'] - solution['risk_free_rate']\n    market_geo_mean = (1 + market_excess_returns).prod() ** (1 / len(solution)) - 1\n    return_gap = max(0, (market_geo_mean - strategy_geo_mean) * 100 * trading_days_per_yr)\n    return_penalty = 1 + (return_gap**2) / 100\n    adjusted_sharpe = sharpe / (vol_penalty * return_penalty)\n    return adjusted_sharpe\n\ndef convert_to_signal(predictions: np.ndarray, multiplier: float = 400.0) -> np.ndarray:\n    # (The full function code goes here)\n    signals = predictions * multiplier + 1\n    return np.clip(signals, 0.0, 2.0)\n\n# --- Main Cross-Validation Script ---\n\nprint(\"Loading pre-processed training data for cross-validation...\")\ntraining_df = pl.read_parquet(\"/kaggle/working/final_training_data_150_features.parquet\")\n\nFEATURES = [col for col in training_df.columns if col not in [\"target\", \"forward_returns\", \"risk_free_rate\"]]\nTARGET_COL = \"target\"\n\nX = training_df.select(FEATURES)\ny = training_df.select(TARGET_COL)\nscorer_info_df = training_df.select([\"forward_returns\", \"risk_free_rate\"])\n\nprint(\"\\n\" + \"=\"*50)\nprint(\"Starting 5-Fold Time Series Cross-Validation...\")\ntscv = TimeSeriesSplit(n_splits=5)\ncv_scores = []\n\nfor i, (train_index, test_index) in enumerate(tscv.split(X)):\n    X_train, X_test = X[train_index], X[test_index]\n    y_train = y[train_index]\n    y_test_info = scorer_info_df[test_index]\n    \n    # Use your final model parameters for an accurate score estimate\n    model = xgb.XGBRegressor(\n        objective='reg:squarederror', n_estimators=500, device='cuda',\n        learning_rate=0.05, max_depth=5, subsample=0.8, colsample_bytree=0.8,\n        n_jobs=-1, random_state=42\n    )\n    model.fit(X_train, y_train, verbose=False)\n    \n    predictions = model.predict(X_test)\n    signals = convert_to_signal(predictions)\n    score = calculate_competition_score(y_test_info, signals)\n    cv_scores.append(score)\n    print(f\"  Fold {i+1}/5 Score: {score:.4f}\")\n\nprint(f\"\\nMean CV Score: {np.mean(cv_scores):.4f} (+/- {np.std(cv_scores):.4f})\")\nprint(\"=\"*50)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-05T06:22:28.703104Z","iopub.execute_input":"2025-10-05T06:22:28.703417Z","iopub.status.idle":"2025-10-05T06:22:34.247782Z","shell.execute_reply.started":"2025-10-05T06:22:28.703388Z","shell.execute_reply":"2025-10-05T06:22:34.247164Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport polars as pl\nimport numpy as np\nimport xgboost as xgb\nimport kaggle_evaluation.default_inference_server\n\n# --- Global Variables ---\nFINAL_MODEL = None\nMODEL_IS_TRAINED = False\nFINAL_FEATURE_LIST = [] \nHISTORY_BUFFER = None\n\n# --- Helper Functions ---\ndef convert_to_signal(predictions: np.ndarray, multiplier: float = 400.0) -> np.ndarray:\n    signals = predictions * multiplier + 1\n    return np.clip(signals, 0.0, 2.0)\n\n# The fast, \"production\" function for creating features during the prediction loop\ndef generate_final_features_optimized(df: pl.DataFrame, feature_list: list[str]) -> pl.DataFrame:\n    final_feature_exprs = []\n    \n    for feature_name in feature_list:\n        if '_' not in feature_name:\n            if feature_name in df.columns: final_feature_exprs.append(pl.col(feature_name))\n        else:\n            parts = feature_name.split('_')\n            f1, op, f2 = parts[0], parts[1], \"_\".join(parts[2:])\n            if f1 in df.columns and f2 in df.columns:\n                if op == 'add': expr = (pl.col(f1) + pl.col(f2)).alias(feature_name)\n                elif op == 'sub': expr = (pl.col(f1) - pl.col(f2)).alias(feature_name)\n                elif op == 'mult': expr = (pl.col(f1) * pl.col(f2)).alias(feature_name)\n                final_feature_exprs.append(expr)\n\n    if not final_feature_exprs: return pl.DataFrame()\n    return df.select(final_feature_exprs)\n\ndef train_model_if_needed():\n    \"\"\"Handles the one-time model training by loading the pre-processed Parquet file.\"\"\"\n    global FINAL_MODEL, MODEL_IS_TRAINED, FINAL_FEATURE_LIST, HISTORY_BUFFER\n\n    if MODEL_IS_TRAINED:\n        return\n\n    print(\"First prediction call received. Starting one-time model training...\")\n    \n    # Load the pre-processed training data\n    training_df = pl.read_parquet(\"/kaggle/working/final_training_data_150_features.parquet\")\n    \n    FINAL_FEATURE_LIST = [col for col in training_df.columns if col not in [\"target\", \"forward_returns\", \"risk_free_rate\"]]\n    print(f\"Training final model with {len(FINAL_FEATURE_LIST)} pre-processed features.\")\n\n    X_train_full = training_df.select(FINAL_FEATURE_LIST)\n    y_train_full = training_df.select(\"target\")\n\n    # Train the final XGBoost model\n    FINAL_MODEL = xgb.XGBRegressor(\n        objective='reg:squarederror', n_estimators=500, device='cuda',\n        learning_rate=0.05, max_depth=5, subsample=0.8, colsample_bytree=0.8,\n        n_jobs=-1, random_state=42\n    )\n    FINAL_MODEL.fit(X_train_full, y_train_full, verbose=False)\n    \n    # --- FIX STARTS HERE ---\n    # Initialize the history buffer with the raw data, ensuring the target column is renamed\n    raw_train_df = pl.read_csv(\"/kaggle/input/hull-tactical-market-prediction/train.csv\")\n    raw_train_df = raw_train_df.rename({'market_forward_excess_returns': 'target'}) # Rename to 'target'\n    \n    feature_cols = [col for col in raw_train_df.columns if col != 'date_id']\n    raw_train_df = raw_train_df.with_columns(pl.col(feature_cols).cast(pl.Float64, strict=False))\n    base_df = raw_train_df.with_columns(pl.all().forward_fill()).drop_nulls()\n    HISTORY_BUFFER = base_df.tail(35)\n    # --- FIX ENDS HERE ---\n    \n    MODEL_IS_TRAINED = True\n    print(\"Model training complete. Ready for predictions.\")\n\n# --- Main Prediction Function ---\ndef predict(test: pl.DataFrame) -> float:\n    global HISTORY_BUFFER, FINAL_MODEL, FINAL_FEATURE_LIST\n    \n    train_model_if_needed()\n    \n    # Standardize incoming data\n    feature_cols = [col for col in test.columns if col != 'date_id']\n    test = test.with_columns(pl.col(feature_cols).cast(pl.Float64, strict=False))\n    rename_mapping = {'lagged_forward_returns': 'forward_returns', 'lagged_risk_free_rate': 'risk_free_rate', 'lagged_market_forward_excess_returns': 'target'}\n    test = test.rename(rename_mapping)\n    if 'is_scored' in test.columns: test = test.drop('is_scored')\n        \n    HISTORY_BUFFER = pl.concat([HISTORY_BUFFER, test], how=\"vertical\")\n    \n    # Use the OPTIMIZED function to generate features for the live data\n    features_df = generate_final_features_optimized(HISTORY_BUFFER, FINAL_FEATURE_LIST)\n    \n    latest_features = features_df.tail(1)\n    \n    raw_prediction = FINAL_MODEL.predict(latest_features)[0]\n    signal = convert_to_signal(np.array([raw_prediction]))[0]\n    \n    return float(signal)\n\n# --- Launch Server ---\ninference_server = kaggle_evaluation.default_inference_server.DefaultInferenceServer(predict)\nif os.getenv('KAGGLE_IS_COMPETITION_RERUN'):\n    inference_server.serve()\nelse:\n    inference_server.run_local_gateway(('/kaggle/input/hull-tactical-market-prediction/',))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-05T06:17:46.830448Z","iopub.execute_input":"2025-10-05T06:17:46.830719Z","iopub.status.idle":"2025-10-05T06:17:48.491654Z","shell.execute_reply.started":"2025-10-05T06:17:46.830699Z","shell.execute_reply":"2025-10-05T06:17:48.491066Z"},"scrolled":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}