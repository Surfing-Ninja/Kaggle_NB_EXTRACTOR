{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":111543,"databundleVersionId":13750964,"sourceType":"competition"}],"dockerImageVersionId":31090,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-09-28T13:38:06.51676Z","iopub.execute_input":"2025-09-28T13:38:06.517322Z","iopub.status.idle":"2025-09-28T13:38:06.526008Z","shell.execute_reply.started":"2025-09-28T13:38:06.517301Z","shell.execute_reply":"2025-09-28T13:38:06.525257Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import polars as pl\nimport numpy as np\nimport xgboost as xgb\nimport optuna\n\n# --- 1. Metric Implementation ---\ndef calculate_competition_score(y_true_df: pl.DataFrame, y_pred_signals: np.ndarray) -> float:\n    solution = y_true_df.to_pandas()\n    solution['position'] = y_pred_signals\n    solution['strategy_returns'] = (\n        solution['risk_free_rate'] * (1 - solution['position']) +\n        solution['position'] * solution['forward_returns']\n    )\n    strategy_excess_returns = solution['strategy_returns'] - solution['risk_free_rate']\n    strategy_geo_mean = (1 + strategy_excess_returns).prod() ** (1 / len(solution)) - 1\n    strategy_std = solution['strategy_returns'].std()\n    if strategy_std == 0: return 0.0\n    trading_days_per_yr = 252\n    sharpe = strategy_geo_mean / strategy_std * np.sqrt(trading_days_per_yr)\n    market_std = solution['forward_returns'].std()\n    market_volatility = market_std * np.sqrt(trading_days_per_yr) * 100\n    strategy_volatility = strategy_std * np.sqrt(trading_days_per_yr) * 100\n    excess_vol = max(0, strategy_volatility / market_volatility - 1.2) if market_volatility > 0 else 0\n    vol_penalty = 1 + excess_vol\n    market_excess_returns = solution['forward_returns'] - solution['risk_free_rate']\n    market_geo_mean = (1 + market_excess_returns).prod() ** (1 / len(solution)) - 1\n    return_gap = max(0, (market_geo_mean - strategy_geo_mean) * 100 * trading_days_per_yr)\n    return_penalty = 1 + (return_gap**2) / 100\n    adjusted_sharpe = sharpe / (vol_penalty * return_penalty)\n    return adjusted_sharpe\n\n\n# --- 2. Feature Engineering ---\ndef create_features(df: pl.DataFrame) -> pl.DataFrame:\n    \"\"\"Creates lags and rolling stats for ALL available feature columns.\"\"\"\n    \n    # Dynamically identify all feature columns to engineer\n    features_to_engineer = [col for col in df.columns if col not in [\"date_id\", \"forward_returns\", \"risk_free_rate\", \"target\"]]\n    \n    print(f\"Starting feature engineering on {len(features_to_engineer)} columns...\")\n    \n    df_eng = df.clone()\n\n    # Create Lags and Rolling Stats for all identified features\n    for feature in features_to_engineer:\n        # Lags\n        for lag in [1, 3, 5]:\n            df_eng = df_eng.with_columns(\n                pl.col(feature).shift(lag).alias(f'{feature}_lag_{lag}')\n            )\n            \n        # Rolling Window Statistics\n        for window in [10, 30]:\n            df_eng = df_eng.with_columns(\n                pl.col(feature).rolling_mean(window).alias(f'{feature}_roll_mean_{window}'),\n                pl.col(feature).rolling_std(window).alias(f'{feature}_roll_std_{window}')\n            )\n\n    # Handle nulls created by lags and rolling windows\n    return df_eng.with_columns(pl.all().forward_fill()).drop_nulls()\n\n# --- 3. Signal Conversion ---\ndef convert_to_signal(predictions: np.ndarray, multiplier: float = 400.0) -> np.ndarray:\n    signals = predictions * multiplier + 1\n    return np.clip(signals, 0.0, 2.0)\n\n# # --- 4. Main Script ---\n# # Load and prepare data\n# full_train_df = pl.read_csv(\"/kaggle/input/hull-tactical-market-prediction/train.csv\")\n# full_train_df = full_train_df.rename({'market_forward_excess_returns': 'target'})\n# processed_df = create_features(full_train_df)\n\n# # Chronological split\n# VALIDATION_SIZE = 180\n# train_df = processed_df.head(-VALIDATION_SIZE)\n# validation_df = processed_df.tail(VALIDATION_SIZE)\n\n# FEATURES = [col for col in train_df.columns if col not in [\"date_id\", \"forward_returns\", \"risk_free_rate\", \"target\"]]\n# TARGET_COL = \"target\"\n\n# X_train = train_df.select(FEATURES)\n# y_train = train_df.select(TARGET_COL)\n# X_val = validation_df.select(FEATURES)\n# y_val_info = validation_df\n\n# print(f\"\\nTraining with {len(FEATURES)} features.\")\n\n# # --- 5. Hyperparameter Tuning with Optuna ---\n# def objective(trial):\n#     params = {\n#         'objective': 'reg:squarederror', \n#         'tree_method': 'hist',\n#         'device' : 'cuda',\n#         'n_estimators': 1000,\n#         'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3, log=True),\n#         'max_depth': trial.suggest_int('max_depth', 3, 10),\n#         'subsample': trial.suggest_float('subsample', 0.6, 1.0),\n#         'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 1.0),\n#         'random_state': 42, 'n_jobs': -1,\n#     }\n#     model = xgb.XGBRegressor(**params)\n#     model.fit(X_train, y_train, eval_set=[(X_val, y_val_info.select(TARGET_COL))],\n#               early_stopping_rounds=50, verbose=False)\n#     predictions = model.predict(X_val)\n#     signals = convert_to_signal(predictions)\n#     score = calculate_competition_score(y_val_info, signals)\n#     return score\n\n# print(\"\\nStarting hyperparameter tuning with Optuna...\")\n# # Suppress Optuna's logging to keep the output clean\n# optuna.logging.set_verbosity(optuna.logging.WARNING)\n# study = optuna.create_study(direction='maximize')\n# study.optimize(objective, n_trials=50) # Use a reasonable number of trials\n\n# print(f\"Best trial score: {study.best_value}\")\n# print(\"Best parameters found: \", study.best_params)\n\n# # --- 6. Train Final Model and Evaluate ---\n# print(\"\\nTraining final model with best parameters...\")\n# best_params = study.best_params\n# final_model = xgb.XGBRegressor(objective='reg:squarederror', n_estimators=1000,\n#                                n_jobs=-1, random_state=42, **best_params)\n# final_model.fit(X_train, y_train, eval_set=[(X_val, y_val_info.select(TARGET_COL))], verbose=False)\n\n# raw_predictions = final_model.predict(X_val)\n# final_signals = convert_to_signal(raw_predictions)\n# final_score = calculate_competition_score(y_val_info, final_signals)\n\n# print(\"\\n\" + \"=\"*50)\n# print(f\"Final Validation Score with Tuned XGBoost: {final_score:.4f}\")\n# print(\"=\"*50)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-28T13:40:30.495536Z","iopub.execute_input":"2025-09-28T13:40:30.496055Z","iopub.status.idle":"2025-09-28T13:42:18.598438Z","shell.execute_reply.started":"2025-09-28T13:40:30.496028Z","shell.execute_reply":"2025-09-28T13:42:18.597638Z"},"scrolled":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# For submission","metadata":{}},{"cell_type":"code","source":"# --- 1. Train the Final Model on All Available Data ---\nimport kaggle_evaluation.default_inference_server\nprint(\"Loading and preparing all training data...\")\n# Load the entire training dataset\nfull_train_df = pl.read_csv(\"/kaggle/input/hull-tactical-market-prediction/train.csv\")\nfull_train_df = full_train_df.rename({'market_forward_excess_returns': 'target'})\n\n\n# Explicitly cast all columns except date_id to Float64\nfeature_cols = [col for col in full_train_df.columns if col != 'date_id']\nfull_train_df = full_train_df.with_columns(\n    pl.col(feature_cols).cast(pl.Float64, strict=False)\n)\n# We need the unprocessed data to build our historical buffer for inference\n# We need at least 30 historical rows to calculate all rolling window features\nHISTORY_BUFFER = full_train_df.tail(35) \n\n# Create features for the full training set\nprocessed_df = create_features(full_train_df).drop_nulls()\n\nFEATURES = [col for col in processed_df.columns if col not in [\"date_id\", \"forward_returns\", \"risk_free_rate\", \"target\"]]\nTARGET_COL = \"target\"\n\nX_train = processed_df.select(FEATURES)\ny_train = processed_df.select(TARGET_COL)\n\n# Hardcode the best parameters found by Optuna\nbest_params = {\n    'learning_rate': 0.1637303464891451, \n    'max_depth': 10, \n    'subsample': 0.6007188302958633, \n    'colsample_bytree': 0.7562060623680535\n}\n\nprint(f\"Training final XGBoost model on {X_train.shape[0]} rows with {len(FEATURES)} features...\")\nfinal_model = xgb.XGBRegressor(\n    objective='reg:squarederror',\n    n_estimators=500, # Train for a fixed number of rounds\n    n_jobs=-1,\n    random_state=42,\n    **best_params\n)\n\nfinal_model.fit(X_train, y_train, verbose=False)\nprint(\"Model training complete.\")\n\n\n# --- 2. Define the Prediction Function for the API ---\n\n# --- 2. Define the Prediction Function for the API (CORRECTED) ---\n\ndef predict(test: pl.DataFrame) -> float:\n    \"\"\"\n    This function is called by the Kaggle API for each day in the test set.\n    \"\"\"\n    global HISTORY_BUFFER\n    \n    # Explicitly cast feature columns to Float64 to ensure type consistency\n    feature_cols = [col for col in test.columns if col != 'date_id']\n    test = test.with_columns(\n        pl.col(feature_cols).cast(pl.Float64, strict=False)\n    )\n\n    # --- FIX STARTS HERE ---\n    # Standardize column names: rename lagged columns from the test set to match the training set names\n    rename_mapping = {\n        'lagged_forward_returns': 'forward_returns',\n        'lagged_risk_free_rate': 'risk_free_rate',\n        'lagged_market_forward_excess_returns': 'target' # This will be our placeholder target\n    }\n    test = test.rename(rename_mapping)\n    # --- FIX ENDS HERE ---\n\n    # Drop the 'is_scored' column which exists in the test set but not our training history.\n    if 'is_scored' in test.columns:\n        test = test.drop('is_scored')\n    \n    # Append the new test row (now with matching columns) to our historical buffer\n    HISTORY_BUFFER = pl.concat([HISTORY_BUFFER, test], how=\"vertical\")\n    \n    # Create features on the combined history\n    features_df = create_features(HISTORY_BUFFER)\n    \n    # We only want to predict on the very last row (the current day)\n    latest_features = features_df.tail(1).select(FEATURES)\n    \n    # Predict, convert to signal, and return a single float value\n    raw_prediction = final_model.predict(latest_features)[0]\n    signal = convert_to_signal(np.array([raw_prediction]))[0]\n    \n    return float(signal)\n\n\n# --- 3. Launch the Inference Server ---\n\ninference_server = kaggle_evaluation.default_inference_server.DefaultInferenceServer(predict)\n\n# This block is required by the Kaggle environment\nif os.getenv('KAGGLE_IS_COMPETITION_RERUN'):\n    inference_server.serve()\nelse:\n    # This block is for local testing. It simulates the API.\n    # We use the public test set as the data source.\n    inference_server.run_local_gateway(('/kaggle/input/hull-tactical-market-prediction/',))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-28T13:51:15.679694Z","iopub.execute_input":"2025-09-28T13:51:15.68044Z","iopub.status.idle":"2025-09-28T13:51:38.374952Z","shell.execute_reply.started":"2025-09-28T13:51:15.680415Z","shell.execute_reply":"2025-09-28T13:51:38.37435Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}