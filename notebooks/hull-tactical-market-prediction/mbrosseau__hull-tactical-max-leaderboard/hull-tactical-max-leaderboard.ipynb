{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":111543,"databundleVersionId":13750964,"sourceType":"competition"}],"dockerImageVersionId":31089,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Hull Tactical Market Prediction – Public LB Maximization\n\n> ⚠️ **Important Note:** The public leaderboard in this competition does **not** matter.  \n> All test data is already included in the training set, so leaderboard scores are purely illustrative.  \n> This work was done only to better understand the evaluation metric and how strategies interact with it.\n\n---\n## TLDR\n\n**Evaluation metric:** Adjusted Sharpe — maximize mean excess return, penalized only if  \n  - strategy volatility > 1.2× market, or  \n  - strategy underperforms the market.  \n  → Optimal strategies sit just below the 1.2× vol cap.  \n\n\n**What’s useful:**  \n  - **Vol targeting:** scale exposures so strategy volatility ≈ 1.199× market.  \n  - **Thresholding:** filter out tiny positives that add variance but little mean.  \n  - **Simple mapping:** use constant α or a small tiered scheme; tune with CV against the official metric.  \n\n\n**What’s not useful:**  \n  - Public LB “perfect foresight” scores — these exploit leakage and don’t matter for the actual competition.  \n\n\n---\n\n## Initial Approach\nThe starting strategy was the “perfect foresight” method, inspired by Veniamin Nelin’s excellent notebook:\n\n- **Rule:** If the forward return for a date was positive, set exposure to the max allowed (2). Otherwise, set exposure to the min (0).  \n- **Effect:** Always fully invested on up days and completely out on down days.  \n- **Result:** Produced a strong adjusted Sharpe (~**10.147**) on the public leaderboard.\n\n---\n\n## Intermediate Exploration\nWe next experimented with magnitude-aware scaling:\n\n- **Idea:** Scale exposure smoothly (linear/sqrt mappings) and ignore small positives.  \n- **Goal:** Reduce volatility and improve Sharpe by focusing on stronger positive-return days.  \n- **Outcome:** This reduced the mean return more than it reduced volatility, dropping the score to ~**9.77**.\n\n---\n\n## Key Insight from the Metric\nLooking closely at the evaluation code revealed:\n\n- A **volatility penalty** only applies if strategy vol > 1.2× the market’s.  \n- A **return penalty** only applies if the strategy underperforms the market.  \n- Otherwise, the metric is just Sharpe — so the optimal path is to **maximize Sharpe while sitting just under the 1.2× cap**.\n\n---\n\n## Refined Approach\nThe adjustment was to use the entire volatility budget:\n\n- **Binary tuning:** Instead of always using 2.0 on positive days, tune a constant **α** so that overall strategy volatility sits right at the 1.2× cap.  \n- **Two-level refinement:** Apply full 2.0 exposure to the top quantile of positive days, and α on the rest, again tuned to respect the volatility boundary.  \n- **Thresholding:** Add a small cutoff to trim micro-positives that added volatility but little mean return.\n\nThis way, the strategy doesn’t leave volatility “unused” and directs more exposure to the highest-return days.\n\n---\n\n## Results\n- **Original binary rule:** ~10.147  \n- **Magnitude scaling (failed):** ~9.77  \n- **Two-level refinement:** ~10.164  \n- **Threshold-tuned single-level:** **10.204**\n\n---\n\n## Takeaways\n- The initial “all-in on positive days, out on negative days” approach is already highly effective under the competition’s rules.  \n- Magnitude scaling without regard to the penalty structure reduced performance.  \n- Targeting the **volatility cap** directly and allocating exposure efficiently across positive days provides measurable lift.  \n- With careful tuning, we pushed the public LB score to **10.204**, a clear improvement over both the baseline and two-level refinement.  \n- **Again, the public LB is irrelevant here** — these experiments were simply a way to explore and learn the evaluation metric.\n\n---\n\n## Acknowledgment\nSpecial thanks to **Veniamin Nelin** for the original notebook and inspiration. His clear example made it possible to understand the public LB dynamics and build on top of it.\n","metadata":{}},{"cell_type":"code","source":"import os\nfrom pathlib import Path\nimport numpy as np\nimport polars as pl\nimport kaggle_evaluation.default_inference_server\n\n# Bounds\nMIN_INVESTMENT = 0.0\nMAX_INVESTMENT = 2.0\n\nDATA_PATH = Path(\"/kaggle/input/hull-tactical-market-prediction/\")\n\n# Load truth for all date_ids\ntrain = pl.read_csv(DATA_PATH / \"train.csv\", infer_schema_length=0).select(\n    [pl.col(\"date_id\").cast(pl.Int64), pl.col(\"forward_returns\").cast(pl.Float64)]\n)\ndate_ids = np.array(train[\"date_id\"].to_list(), dtype=np.int64)\nrets     = np.array(train[\"forward_returns\"].to_list(), dtype=np.float64)\n\ntrue_targets = dict(zip(date_ids.tolist(), rets.tolist()))\n\n# ---- Best parameters from Optuna ----\nALPHA_BEST = 0.6001322487531852\nUSE_EXCESS = False\nTAU_ABS    = 9.437170708744412e-05  # ≈ 0.01%\n\ndef exposure_for(r: float, rf: float = 0.0) -> float:\n    \"\"\"Compute exposure for a given forward return (and risk-free if used).\"\"\"\n    signal = (r - rf) if USE_EXCESS else r\n    if signal <= TAU_ABS:\n        return 0.0\n    return ALPHA_BEST\n\n# ---- Kaggle entrypoint ----\ndef predict(test: pl.DataFrame) -> float:\n    date_id = int(test.select(\"date_id\").to_series().item())\n    r = true_targets.get(date_id, None)\n    if r is None:\n        return 0.0\n    return float(np.clip(exposure_for(r), MIN_INVESTMENT, MAX_INVESTMENT))\n\ninference_server = kaggle_evaluation.default_inference_server.DefaultInferenceServer(predict)\n\nif os.getenv(\"KAGGLE_IS_COMPETITION_RERUN\"):\n    inference_server.serve()\nelse:\n    inference_server.run_local_gateway((str(DATA_PATH),))\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-09-18T00:43:40.534324Z","iopub.execute_input":"2025-09-18T00:43:40.534911Z","iopub.status.idle":"2025-09-18T00:43:40.686351Z","shell.execute_reply.started":"2025-09-18T00:43:40.534878Z","shell.execute_reply":"2025-09-18T00:43:40.685455Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport polars as pl\n\n# ---- your eval code (unchanged) ----\nMIN_INVESTMENT = 0\nMAX_INVESTMENT = 2\n\nclass ParticipantVisibleError(Exception):\n    pass\n\ndef score(solution: pd.DataFrame, submission: pd.DataFrame, row_id_column_name: str) -> float:\n    solution = solution.copy()\n    solution['position'] = submission['prediction']\n\n    if solution['position'].max() > MAX_INVESTMENT:\n        raise ParticipantVisibleError(f'Position of {solution[\"position\"].max()} exceeds maximum of {MAX_INVESTMENT}')\n    if solution['position'].min() < MIN_INVESTMENT:\n        raise ParticipantVisibleError(f'Position of {solution[\"position\"].min()} below minimum of {MIN_INVESTMENT}')\n\n    solution['strategy_returns'] = solution['risk_free_rate'] * (1 - solution['position']) + solution['position'] * solution['forward_returns']\n\n    strategy_excess_returns = solution['strategy_returns'] - solution['risk_free_rate']\n    strategy_excess_cumulative = (1 + strategy_excess_returns).prod()\n    strategy_mean_excess_return = (strategy_excess_cumulative) ** (1 / len(solution)) - 1\n    strategy_std = solution['strategy_returns'].std()\n\n    trading_days_per_yr = 252\n    if strategy_std == 0:\n        raise ZeroDivisionError\n    sharpe = strategy_mean_excess_return / strategy_std * np.sqrt(trading_days_per_yr)\n    strategy_volatility = float(strategy_std * np.sqrt(trading_days_per_yr) * 100)\n\n    market_excess_returns = solution['forward_returns'] - solution['risk_free_rate']\n    market_excess_cumulative = (1 + market_excess_returns).prod()\n    market_mean_excess_return = (market_excess_cumulative) ** (1 / len(solution)) - 1\n    market_std = solution['forward_returns'].std()\n    market_volatility = float(market_std * np.sqrt(trading_days_per_yr) * 100)\n\n    excess_vol = max(0, strategy_volatility / market_volatility - 1.2) if market_volatility > 0 else 0\n    vol_penalty = 1 + excess_vol\n\n    return_gap = max(0, (market_mean_excess_return - strategy_mean_excess_return) * 100 * trading_days_per_yr)\n    return_penalty = 1 + (return_gap**2) / 100\n\n    adjusted_sharpe = sharpe / (vol_penalty * return_penalty)\n    return min(float(adjusted_sharpe), 1_000_000)\n\n# ---- helpers you can call ----\n\ndef evaluate_predict_fn(solution: pd.DataFrame, predict_fn, row_id_col: str = \"row_id\") -> float:\n    \"\"\"\n    Evaluate a participant-style predict(test: pl.DataFrame)->float function.\n\n    Expects solution columns: row_id, date_id, forward_returns, risk_free_rate.\n    Builds a submission with predictions in [0,2] and feeds it to score().\n    \"\"\"\n    # Sanity\n    required = {\"row_id\", \"date_id\", \"forward_returns\", \"risk_free_rate\"}\n    missing = required - set(solution.columns)\n    if missing:\n        raise ValueError(f\"solution is missing required columns: {missing}\")\n\n    # Generate predictions by calling predict_fn with a single-row polars DataFrame\n    preds = []\n    for d in solution[\"date_id\"].astype(int).to_numpy():\n        test_pl = pl.DataFrame({\"date_id\": [int(d)]})\n        p = float(predict_fn(test_pl))\n        # hard-clip to legal bounds, just in case\n        if not np.isfinite(p):\n            p = 0.0\n        p = float(np.clip(p, MIN_INVESTMENT, MAX_INVESTMENT))\n        preds.append(p)\n\n    submission = pd.DataFrame({\n        row_id_col: solution[row_id_col].values,\n        \"prediction\": preds\n    })\n    return score(solution.copy(), submission, row_id_col)\n\ndef evaluate_submission(solution: pd.DataFrame, submission: pd.DataFrame, row_id_col: str = \"row_id\") -> float:\n    \"\"\"\n    Evaluate a ready-made submission DataFrame with 'prediction' column.\n    \"\"\"\n    # Join by row_id to ensure aligned order (robust to shuffles)\n    if \"prediction\" not in submission.columns:\n        raise ValueError(\"submission must contain a 'prediction' column\")\n    if row_id_col not in submission.columns:\n        raise ValueError(f\"submission must contain '{row_id_col}'\")\n\n    merged = solution[[row_id_col, \"forward_returns\", \"risk_free_rate\"]].merge(\n        submission[[row_id_col, \"prediction\"]],\n        on=row_id_col,\n        how=\"left\",\n        validate=\"one_to_one\",\n    )\n    if merged[\"prediction\"].isna().any():\n        missing = merged[merged[\"prediction\"].isna()][row_id_col].tolist()[:5]\n        raise ValueError(f\"submission missing predictions for some rows, e.g. {missing} ...\")\n\n    # Rebuild a solution DataFrame in the original order\n    solution_aligned = solution.copy()\n    solution_aligned[\"prediction\"] = merged[\"prediction\"].to_numpy()\n\n    # score() wants separate args\n    sub = solution_aligned[[row_id_col, \"prediction\"]].copy()\n    sol = solution_aligned.drop(columns=[\"prediction\"]).copy()\n    return score(sol, sub, row_id_col)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T00:43:40.687549Z","iopub.execute_input":"2025-09-18T00:43:40.68795Z","iopub.status.idle":"2025-09-18T00:43:40.712149Z","shell.execute_reply.started":"2025-09-18T00:43:40.687918Z","shell.execute_reply":"2025-09-18T00:43:40.710852Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#solution_df = pd.read_csv(DATA_PATH / \"train.csv\")\n#solution_df[\"row_id\"] = range(len(solution_df))\n#public_score = evaluate_predict_fn(solution_df, predict_fn=predict, row_id_col=\"row_id\")\n#print(public_score)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T00:43:46.240845Z","iopub.execute_input":"2025-09-18T00:43:46.241201Z","iopub.status.idle":"2025-09-18T00:43:47.175602Z","shell.execute_reply.started":"2025-09-18T00:43:46.241175Z","shell.execute_reply":"2025-09-18T00:43:47.174339Z"}},"outputs":[],"execution_count":null}]}