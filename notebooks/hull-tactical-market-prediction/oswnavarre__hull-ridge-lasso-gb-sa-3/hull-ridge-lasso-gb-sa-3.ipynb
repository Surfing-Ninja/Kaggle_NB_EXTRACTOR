{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":111543,"databundleVersionId":14348714,"sourceType":"competition"}],"dockerImageVersionId":31192,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"id":"6fc360b5-9a14-48f1-b2c6-5428f8a00f92","cell_type":"markdown","source":"# Hull Tactical Market Prediction — Ensemble robusto con inference\n","metadata":{}},{"id":"761a6340-41cf-485c-af4e-846a8f4af66f","cell_type":"code","source":"import os, gc, numpy as np, pandas as pd\n\nfrom sklearn.model_selection import TimeSeriesSplit\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import Ridge, Lasso\nfrom sklearn.ensemble import GradientBoostingRegressor\nfrom sklearn.metrics import r2_score, mean_squared_error\n\npd.set_option(\"display.max_columns\", 200)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-09T03:23:47.605675Z","iopub.execute_input":"2025-11-09T03:23:47.606324Z","iopub.status.idle":"2025-11-09T03:23:49.059451Z","shell.execute_reply.started":"2025-11-09T03:23:47.606295Z","shell.execute_reply":"2025-11-09T03:23:49.058664Z"}},"outputs":[],"execution_count":null},{"id":"e1a98123-4eeb-46a9-9352-d013e52e0add","cell_type":"code","source":"KAGGLE_INPUT = \"/kaggle/input/hull-tactical-market-prediction\"\nLOCAL_INPUT = \"/kaggle/input\" if os.path.exists(\"/kaggle/input\") else \"/mnt/data\"\n\ndata_dir = KAGGLE_INPUT if os.path.exists(KAGGLE_INPUT) else LOCAL_INPUT\ntrain_path = os.path.join(data_dir, \"train.csv\")\ntest_path  = os.path.join(data_dir, \"test.csv\")\n\ntrain = pd.read_csv(train_path)\ntest  = pd.read_csv(test_path) if os.path.exists(test_path) else None\n\nTARGET = \"forward_returns\"\nDATE   = \"date_id\"\nLEAK   = {\"forward_returns\",\"risk_free_rate\",\"market_forward_excess_returns\"}\n\nprint(\"Loaded:\", {\"train\": train.shape, \"test\": None if test is None else test.shape})","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-09T03:23:49.061307Z","iopub.execute_input":"2025-11-09T03:23:49.061747Z","iopub.status.idle":"2025-11-09T03:23:49.396161Z","shell.execute_reply.started":"2025-11-09T03:23:49.061724Z","shell.execute_reply":"2025-11-09T03:23:49.395287Z"}},"outputs":[],"execution_count":null},{"id":"b5691435-2786-46ae-b27b-d91e90fe0cd4","cell_type":"code","source":"# Selección de features numéricas seguras\nif test is not None:\n    commons = set(train.columns) & set(test.columns)\n    feat = [c for c in train.columns if c in commons and c not in LEAK and c != DATE]\nelse:\n    feat = [c for c in train.columns if c not in LEAK and c != DATE]\n\nnum_cols = train[feat].select_dtypes(include=[np.number]).columns.tolist()\nassert len(num_cols) > 0, \"No numeric features found.\"\n\ntrain_sorted = train.sort_values(DATE).reset_index(drop=True)\nX = train_sorted[num_cols].copy()\ny = train_sorted[TARGET].astype(float).copy()\n\npre = ColumnTransformer([\n    (\"num\", Pipeline([\n        (\"imputer\", SimpleImputer(strategy=\"median\")),\n        (\"scaler\", StandardScaler(with_mean=False))\n    ]), num_cols)\n], remainder=\"drop\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-09T03:23:49.397209Z","iopub.execute_input":"2025-11-09T03:23:49.397471Z","iopub.status.idle":"2025-11-09T03:23:49.434396Z","shell.execute_reply.started":"2025-11-09T03:23:49.397449Z","shell.execute_reply":"2025-11-09T03:23:49.433604Z"}},"outputs":[],"execution_count":null},{"id":"0aa11387-172d-4495-8d9c-b5696daab8d4","cell_type":"code","source":"models = {\n    \"ridge\": Ridge(alpha=0.5, random_state=42),\n    \"lasso\": Lasso(alpha=1e-4, random_state=42, max_iter=20000),\n    \"gbr\":   GradientBoostingRegressor(\n        n_estimators=400, learning_rate=0.05, max_depth=3, subsample=0.8, random_state=42\n    )\n}\n\ntscv = TimeSeriesSplit(n_splits=5)\n\ncv_summary, oof_dict = [], {}\nfor name, mdl in models.items():\n    pipe = Pipeline([(\"prep\", pre), (\"model\", mdl)])\n    oof_pred  = np.zeros(len(train_sorted))\n    fold_mets = []\n    for tr_idx, va_idx in tscv.split(X):\n        X_tr, X_va = X.iloc[tr_idx], X.iloc[va_idx]\n        y_tr, y_va = y.iloc[tr_idx], y.iloc[va_idx]\n        pipe.fit(X_tr, y_tr)\n        p = pipe.predict(X_va)\n        r2  = r2_score(y_va, p)\n        rmse = mean_squared_error(y_va, p, squared=False)\n        oof_pred[va_idx] = p\n        fold_mets.append((r2, rmse))\n    r2m   = float(np.mean([m[0] for m in fold_mets]))\n    rmsem = float(np.mean([m[1] for m in fold_mets]))\n    cv_summary.append({\"model\": name, \"cv_r2\": r2m, \"cv_rmse\": rmsem})\n    oof_dict[name] = oof_pred\n\ncv_df = pd.DataFrame(cv_summary).sort_values(\"cv_r2\", ascending=False).reset_index(drop=True)\ncv_df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-09T03:23:49.435278Z","iopub.execute_input":"2025-11-09T03:23:49.435517Z","iopub.status.idle":"2025-11-09T03:26:03.975869Z","shell.execute_reply.started":"2025-11-09T03:23:49.435496Z","shell.execute_reply":"2025-11-09T03:26:03.974911Z"}},"outputs":[],"execution_count":null},{"id":"4c39cf83-603b-49ee-9563-b76ec6a07746","cell_type":"code","source":"# Ensemble por 1/RMSE\nw = {}\nden = 0.0\nfor row in cv_summary:\n    w[row[\"model\"]] = 1.0 / (row[\"cv_rmse\"] + 1e-12)\n    den += w[row[\"model\"]]\nfor k in w: w[k] /= den\n\nyhat_oof = np.zeros(len(train_sorted))\nfor name, preds in oof_dict.items():\n    yhat_oof += w[name] * preds\n\ndef sharpe_like(y_true, y_pred, k):\n    pos = np.clip(k * y_pred, 0.0, 2.0)\n    ret = y_true * pos\n    mu  = float(np.mean(ret))\n    sd  = float(np.std(ret, ddof=1) + 1e-12)\n    return mu / sd\n\nhold = 180\nidx_val = np.arange(len(y))[-hold:] if len(y) > hold else np.arange(len(y))\n\nbest_k, best_s = None, -1e9\nfor k_try in np.linspace(5.0, 15.0, 21):\n    s = sharpe_like(y.iloc[idx_val].values, yhat_oof[idx_val], k_try)\n    if s > best_s:\n        best_s, best_k = s, float(k_try)\n\nk_opt = float(best_k if best_k is not None else 10.0)\nprint({\"k_opt\": k_opt, \"val_sharpe_like\": best_s})","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-09T03:26:03.978254Z","iopub.execute_input":"2025-11-09T03:26:03.978513Z","iopub.status.idle":"2025-11-09T03:26:03.993522Z","shell.execute_reply.started":"2025-11-09T03:26:03.978492Z","shell.execute_reply":"2025-11-09T03:26:03.992403Z"}},"outputs":[],"execution_count":null},{"id":"1f93793f-5a80-47e9-8b68-c33a77321356","cell_type":"code","source":"# Entrenar full y predecir test\nX_full  = X\nfitted = {}\nfor name, mdl in models.items():\n    pipe = Pipeline([(\"prep\", pre), (\"model\", mdl)])\n    pipe.fit(X_full, y)\n    fitted[name] = pipe\n\nif test is not None:\n    X_test  = test[num_cols].copy()\n    yhat_test = np.zeros(len(X_test))\n    for name, pipe in fitted.items():\n        yhat_test += w[name] * pipe.predict(X_test)\n    position = np.clip(k_opt * yhat_test, 0.0, 2.0).astype(\"float64\")\n    sub = pd.DataFrame({\"date_id\": test[\"date_id\"].astype(\"int64\").values, \"position\": position})\n    out = \"/kaggle/working/submission.parquet\" if os.path.exists(\"/kaggle/working\") else \"submission.parquet\"\n    sub.to_parquet(out, index=False)\n    print(\"WROTE:\", out, sub.shape)\n\ndiag = pd.DataFrame({\n    \"date_id\": train_sorted[DATE].astype(\"int64\").values,\n    \"y_true\": y.values.astype(\"float64\"),\n    \"y_pred_oof\": yhat_oof.astype(\"float64\")\n})\nout = \"/kaggle/working/preds_analysis.parquet\" if os.path.exists(\"/kaggle/working\") else \"preds_analysis.parquet\"\ndiag.to_parquet(out, index=False)\nprint(\"WROTE:\", out, diag.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-09T03:26:03.994603Z","iopub.execute_input":"2025-11-09T03:26:03.995109Z","iopub.status.idle":"2025-11-09T03:27:11.629975Z","shell.execute_reply.started":"2025-11-09T03:26:03.995086Z","shell.execute_reply":"2025-11-09T03:27:11.629016Z"}},"outputs":[],"execution_count":null},{"id":"bf5cddb6-e670-4337-804e-42488716a150","cell_type":"code","source":"# ===== INFERENCE SERVER (self-contained y robusto) =====\nimport os, gc, numpy as np, pandas as pd\nfrom collections.abc import Mapping\n\n# Reconstruye si algo no existe (evaluación fuera de orden)\ntry:\n    num_cols; fitted; k_opt\nexcept Exception:\n    KAGGLE_INPUT = \"/kaggle/input/hull-tactical-market-prediction\"\n    data_dir = KAGGLE_INPUT if os.path.exists(KAGGLE_INPUT) else \"/kaggle/input\"\n    train_path = os.path.join(data_dir, \"train.csv\")\n    test_path  = os.path.join(data_dir, \"test.csv\")\n    train = pd.read_csv(train_path)\n    TARGET = \"forward_returns\"; DATE = \"date_id\"\n    LEAK = {\"forward_returns\",\"risk_free_rate\",\"market_forward_excess_returns\"}\n    test_cols = set(pd.read_csv(test_path, nrows=1).columns) if os.path.exists(test_path) else set(train.columns)\n    feat_all = [c for c in train.columns if c not in LEAK and c != DATE]\n    feat = [c for c in feat_all if c in test_cols]\n    num_cols = train[feat].select_dtypes(include=[np.number]).columns.tolist()\n\n    # >>> FIX aquí: ColumnTransformer correcto (sin paréntesis extra) <<<\n    from sklearn.compose import ColumnTransformer\n    from sklearn.pipeline import Pipeline\n    from sklearn.impute import SimpleImputer\n    from sklearn.preprocessing import StandardScaler\n    from sklearn.linear_model import Ridge, Lasso\n    from sklearn.ensemble import GradientBoostingRegressor\n\n    pre = ColumnTransformer([\n        (\"num\", Pipeline([\n            (\"imputer\", SimpleImputer(strategy=\"median\")),\n            (\"scaler\", StandardScaler(with_mean=False))\n        ]), num_cols)\n    ], remainder=\"drop\")\n\n    models = {\n        \"ridge\": Ridge(alpha=0.5, random_state=42),\n        \"lasso\": Lasso(alpha=1e-4, random_state=42, max_iter=20000),\n        \"gbr\":   GradientBoostingRegressor(n_estimators=400, learning_rate=0.05,\n                                           max_depth=3, subsample=0.8, random_state=42)\n    }\n    train_sorted = train.sort_values(DATE).reset_index(drop=True)\n    X_full = train_sorted[num_cols].copy()\n    y_full = train_sorted[TARGET].astype(float).copy()\n    fitted = {}\n    for name, mdl in models.items():\n        pipe = Pipeline([(\"prep\", pre), (\"model\", mdl)])\n        pipe.fit(X_full, y_full)\n        fitted[name] = pipe\n    k_opt = 10.0\n    w = {n: 1.0/len(fitted) for n in fitted}\n\nif 'w' not in globals():\n    w = {name: 1.0/len(fitted) for name in fitted.keys()}\n\ndef _row_to_frame(row, cols):\n    if isinstance(row, Mapping):\n        return pd.DataFrame([{c: row.get(c, 0.0) for c in cols}])[cols]\n    if isinstance(row, pd.Series):\n        return row.to_frame().T.reindex(columns=cols, fill_value=0.0)\n    if isinstance(row, pd.DataFrame):\n        return row.iloc[:1].reindex(columns=cols, fill_value=0.0)\n    return pd.DataFrame([row], columns=cols)[cols]\n\ndef _ensemble_predict(X_df):\n    pred = np.zeros(len(X_df))\n    for name, pipe in fitted.items():\n        pred += w.get(name, 1.0/len(fitted)) * pipe.predict(X_df)\n    return pred\n\ndef predict(row):\n    X_row = _row_to_frame(row, num_cols)\n    y_pred = float(_ensemble_predict(X_row)[0])\n    pos = float(np.clip(float(k_opt) * y_pred, 0.0, 2.0))\n    if not np.isfinite(pos):\n        pos = 0.0\n    return pos\n\ntry:\n    from kaggle_evaluation.default_inference_server import DefaultInferenceServer\n    if \"KAGGLE_IS_COMPETITION_RERUN\" in os.environ:\n        DefaultInferenceServer(predict).serve()\n    elif os.getenv(\"RUN_LOCAL_GATEWAY\") == \"1\":\n        DefaultInferenceServer(predict).run_local_gateway((\"/kaggle/input/hull-tactical-market-prediction\",))\n    else:\n        print(\"Inference server: SKIPPED (exporta RUN_LOCAL_GATEWAY=1 para probar local).\")\nexcept Exception as e:\n    print(\"WARNING: inference server not started:\", repr(e))\nfinally:\n    gc.collect()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-09T03:40:35.180763Z","iopub.execute_input":"2025-11-09T03:40:35.181154Z","iopub.status.idle":"2025-11-09T03:41:46.832057Z","shell.execute_reply.started":"2025-11-09T03:40:35.181126Z","shell.execute_reply":"2025-11-09T03:41:46.830895Z"}},"outputs":[],"execution_count":null}]}