{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":111543,"databundleVersionId":13750964,"sourceType":"competition"}],"dockerImageVersionId":31153,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-10-29T06:46:02.649426Z","iopub.execute_input":"2025-10-29T06:46:02.649665Z","iopub.status.idle":"2025-10-29T06:46:03.747601Z","shell.execute_reply.started":"2025-10-29T06:46:02.64964Z","shell.execute_reply":"2025-10-29T06:46:03.746832Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_train = pd.read_csv(\"/kaggle/input/hull-tactical-market-prediction/train.csv\")\ndf_train.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-29T06:46:03.748956Z","iopub.execute_input":"2025-10-29T06:46:03.749366Z","iopub.status.idle":"2025-10-29T06:46:04.159367Z","shell.execute_reply.started":"2025-10-29T06:46:03.749348Z","shell.execute_reply":"2025-10-29T06:46:04.158508Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(df_train.columns)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-29T06:46:04.160061Z","iopub.execute_input":"2025-10-29T06:46:04.160331Z","iopub.status.idle":"2025-10-29T06:46:04.165817Z","shell.execute_reply.started":"2025-10-29T06:46:04.160314Z","shell.execute_reply":"2025-10-29T06:46:04.165078Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"cat_cols = [f\"D{i}\" for i in range(1, 10)]\ndf_train[cat_cols] = df_train[cat_cols].astype(\"category\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-29T06:46:04.166566Z","iopub.execute_input":"2025-10-29T06:46:04.16682Z","iopub.status.idle":"2025-10-29T06:46:04.188387Z","shell.execute_reply.started":"2025-10-29T06:46:04.166805Z","shell.execute_reply":"2025-10-29T06:46:04.187556Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_train.info()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-29T06:46:04.189999Z","iopub.execute_input":"2025-10-29T06:46:04.190304Z","iopub.status.idle":"2025-10-29T06:46:04.214995Z","shell.execute_reply.started":"2025-10-29T06:46:04.190286Z","shell.execute_reply":"2025-10-29T06:46:04.214332Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_test = pd.read_csv(\"/kaggle/input/hull-tactical-market-prediction/test.csv\")\ndf_test.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-29T06:46:04.215922Z","iopub.execute_input":"2025-10-29T06:46:04.216291Z","iopub.status.idle":"2025-10-29T06:46:04.237686Z","shell.execute_reply.started":"2025-10-29T06:46:04.216263Z","shell.execute_reply":"2025-10-29T06:46:04.237074Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_test.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-29T06:46:04.238332Z","iopub.execute_input":"2025-10-29T06:46:04.238621Z","iopub.status.idle":"2025-10-29T06:46:04.243453Z","shell.execute_reply.started":"2025-10-29T06:46:04.238603Z","shell.execute_reply":"2025-10-29T06:46:04.242643Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_train.describe()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-29T06:46:04.244241Z","iopub.execute_input":"2025-10-29T06:46:04.244921Z","iopub.status.idle":"2025-10-29T06:46:04.440677Z","shell.execute_reply.started":"2025-10-29T06:46:04.244892Z","shell.execute_reply":"2025-10-29T06:46:04.439816Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ##Changing dtypes to getCategorical features ##\n# categorical_x_vars = df_train[['D1', 'D2', 'D3', 'D4', 'D5', 'D6', 'D7', 'D8', 'D9']].columns\n# cols_x  = df_train.columns.difference(['forward_returns' , 'market_forward_excess_returns' , 'risk_free_rate'])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-29T06:46:04.441538Z","iopub.execute_input":"2025-10-29T06:46:04.441835Z","iopub.status.idle":"2025-10-29T06:46:04.445256Z","shell.execute_reply.started":"2025-10-29T06:46:04.441817Z","shell.execute_reply":"2025-10-29T06:46:04.444478Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def preprocess(df, drop_cols=None):\n    df = df.copy()\n\n    # Identify training mode (has forward_returns)\n    is_train = \"forward_returns\" in df.columns\n\n    # Drop high-null columns only during training\n    if is_train:\n        print(\"Training data Preprocess\")\n        high_null_cols = [c for c in df.columns if df[c].isnull().mean() > 0.5]\n        drop_cols = high_null_cols  # Save for test data\n    elif drop_cols is not None:\n        # For test data, drop same columns as training\n        df = df.drop(columns=drop_cols, errors='ignore')\n\n    # Fill missing values\n    for col in df.columns:\n        if df[col].dtype in ['float64', 'int64']:\n            df[col] = df[col].fillna(df[col].median())\n        else:\n            if len(df[col].mode()) > 0:\n                df[col] = df[col].fillna(df[col].mode()[0])\n\n    return df, drop_cols\n\n\n# First, preprocess training data and capture dropped columns\ndf_train, drop_cols = preprocess(df_train)\n\n# Then, apply same logic to test data\ndf_test, _ = preprocess(df_test, drop_cols=drop_cols)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-29T06:46:04.44622Z","iopub.execute_input":"2025-10-29T06:46:04.446477Z","iopub.status.idle":"2025-10-29T06:46:04.528455Z","shell.execute_reply.started":"2025-10-29T06:46:04.446452Z","shell.execute_reply":"2025-10-29T06:46:04.527701Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(df_train.shape)\nprint(df_test.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-29T06:46:04.529199Z","iopub.execute_input":"2025-10-29T06:46:04.529547Z","iopub.status.idle":"2025-10-29T06:46:04.534103Z","shell.execute_reply.started":"2025-10-29T06:46:04.529522Z","shell.execute_reply":"2025-10-29T06:46:04.533458Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"##Creating lagged Features ##\ndef lagged_variables_creation(df: pd.DataFrame, mode: str = 'train') -> pd.DataFrame:\n    df = df.copy()  \n    \n    if mode == \"train\":\n        for i in [1, 2, 3, 5, 10]:\n            df[f'lagged_forward_returns_{i}'] = df['forward_returns'].shift(i)\n            df[f'lagged_risk_free_rate_{i}'] = df['risk_free_rate'].shift(i)\n            df[f'lagged_market_forward_excess_returns_{i}'] = df['market_forward_excess_returns'].shift(i)\n    \n    else:  # mode == 'test'\n        for i in [2, 3, 5, 10]:\n            df[f'lagged_forward_returns_{i}'] = df['lagged_forward_returns'].shift(i)\n            df[f'lagged_risk_free_rate_{i}'] = df['lagged_risk_free_rate'].shift(i)\n            df[f'lagged_market_forward_excess_returns_{i}'] = df['lagged_market_forward_excess_returns'].shift(i)\n    \n    return df\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-29T06:46:04.534742Z","iopub.execute_input":"2025-10-29T06:46:04.534905Z","iopub.status.idle":"2025-10-29T06:46:04.546422Z","shell.execute_reply.started":"2025-10-29T06:46:04.534891Z","shell.execute_reply":"2025-10-29T06:46:04.545501Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_train = lagged_variables_creation(df_train , mode = \"train\")\ndf_test = lagged_variables_creation(df_test , mode = 'test')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-29T06:46:04.547439Z","iopub.execute_input":"2025-10-29T06:46:04.547665Z","iopub.status.idle":"2025-10-29T06:46:04.581241Z","shell.execute_reply.started":"2025-10-29T06:46:04.547642Z","shell.execute_reply":"2025-10-29T06:46:04.580452Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"## Renaming columns as per training data ##\ndf_test.rename(columns = {\"lagged_forward_returns\" : \"lagged_forward_returns_1\" , \"lagged_risk_free_rate\" : \n                          \"lagged_risk_free_rate_1\" , \n                          \"lagged_market_forward_excess_returns\" : \"lagged_market_forward_excess_returns_1\"} , inplace = True)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-29T06:46:04.583604Z","iopub.execute_input":"2025-10-29T06:46:04.58381Z","iopub.status.idle":"2025-10-29T06:46:04.58816Z","shell.execute_reply.started":"2025-10-29T06:46:04.583794Z","shell.execute_reply":"2025-10-29T06:46:04.587419Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"## Removing useless cols ##\nprint(df_train.columns.difference(df_test.columns))\ndf_train.drop(columns = ['E7', 'M1', 'M13', 'M14', 'M6', 'S3', 'V10', 'V9' ,'market_forward_excess_returns', 'risk_free_rate'] , inplace = True)\nprint(df_test.columns.difference(df_train.columns))\ndf_test.drop(columns = ['is_scored'] , inplace = True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-29T06:46:04.589025Z","iopub.execute_input":"2025-10-29T06:46:04.589249Z","iopub.status.idle":"2025-10-29T06:46:04.604275Z","shell.execute_reply.started":"2025-10-29T06:46:04.589234Z","shell.execute_reply":"2025-10-29T06:46:04.603563Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"## Backward filing values for lag variables ##\ncols_lag = [c for c in df_train.columns if 'lagged_' in c]\ndf_train[cols_lag] = df_train[cols_lag].bfill()\ndf_test[cols_lag] = df_test[cols_lag].bfill()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-29T06:46:04.605185Z","iopub.execute_input":"2025-10-29T06:46:04.605488Z","iopub.status.idle":"2025-10-29T06:46:04.622484Z","shell.execute_reply.started":"2025-10-29T06:46:04.605466Z","shell.execute_reply":"2025-10-29T06:46:04.621741Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(f'Training data {df_train.shape}')\nprint(f'Testing data {df_test.shape}')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-29T06:46:04.623331Z","iopub.execute_input":"2025-10-29T06:46:04.623597Z","iopub.status.idle":"2025-10-29T06:46:04.628035Z","shell.execute_reply.started":"2025-10-29T06:46:04.623575Z","shell.execute_reply":"2025-10-29T06:46:04.627294Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"## Data Splitting for train test ##\nfrom sklearn.model_selection import train_test_split \n\ncols_x =  df_train.columns.difference(['forward_returns'])\ntrainx , testx , trainy , testy  =  train_test_split(df_train[cols_x] , df_train['forward_returns'] , test_size = 0.2 , random_state = 0 )\nprint('Train size' , trainx.shape)\nprint('Val size' , testx.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-29T06:46:04.628755Z","iopub.execute_input":"2025-10-29T06:46:04.62897Z","iopub.status.idle":"2025-10-29T06:46:05.20156Z","shell.execute_reply.started":"2025-10-29T06:46:04.628951Z","shell.execute_reply":"2025-10-29T06:46:05.200611Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ##Optuna for Hyper Parametre optimization ##\n# import lightgbm as lgb\n# import optuna\n# from sklearn.metrics import mean_squared_error\n# from sklearn.model_selection import TimeSeriesSplit\n# import numpy as np\n\n\n\n\n# X = trainx\n# Y = trainy\n\n# tscv = TimeSeriesSplit(n_splits=5)\n\n# def objective(trial):\n#     params = {\n#         'n_estimators': trial.suggest_int('n_estimators', 1000, 2000),\n#         'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.1),\n#         'num_leaves': trial.suggest_int('num_leaves', 16, 256),\n#         'feature_fraction': trial.suggest_float('feature_fraction', 0.6, 1.0),\n#         'bagging_fraction': trial.suggest_float('bagging_fraction', 0.6, 1.0),\n#         'bagging_freq': trial.suggest_int('bagging_freq', 1, 10),\n#         'lambda_l1': trial.suggest_float('lambda_l1', 1e-3, 10.0, log=True),\n#         'lambda_l2': trial.suggest_float('lambda_l2', 1e-3, 10.0, log=True),\n#         'min_data_in_leaf': trial.suggest_int('min_data_in_leaf', 10, 200),\n#         'max_depth': trial.suggest_int('max_depth', 3, 25),\n#         'objective': 'regression',\n#         'metric': 'rmse',\n#         'verbosity': -1,\n#         'n_jobs': -1 , \n#         'device' : 'gpu'\n#     }\n\n#     rmse_scores = []\n\n#     for train_idx, test_idx in tscv.split(X):\n#         X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n#         y_train, y_test = Y.iloc[train_idx], Y.iloc[test_idx]\n\n#         model = lgb.LGBMRegressor(**params)\n\n    \n#         model.fit(\n#             X_train, y_train,\n#             eval_set=[(X_test, y_test)],\n#             eval_metric='rmse',\n#         )\n\n#         preds = model.predict(X_test)\n#         rmse = mean_squared_error(y_test, preds, squared=False)\n#         rmse_scores.append(rmse)\n\n#     return np.mean(rmse_scores)\n\n# study = optuna.create_study(direction='minimize')\n# study.optimize(objective, n_trials=100)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-29T06:46:05.202712Z","iopub.execute_input":"2025-10-29T06:46:05.203164Z","iopub.status.idle":"2025-10-29T07:54:31.141751Z","shell.execute_reply.started":"2025-10-29T06:46:05.203137Z","shell.execute_reply":"2025-10-29T07:54:31.141099Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# print(\"Best params:\", study.best_params)\n# print(\"Best score:\", study.best_value)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-29T07:54:31.14313Z","iopub.execute_input":"2025-10-29T07:54:31.146655Z","iopub.status.idle":"2025-10-29T07:54:31.151625Z","shell.execute_reply.started":"2025-10-29T07:54:31.14663Z","shell.execute_reply":"2025-10-29T07:54:31.151148Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"## Model training ##\nimport lightgbm as lgb\nfrom sklearn.metrics import mean_squared_error\n\n##params got from optuna ##\nparams  = {'n_estimators': 1945, 'learning_rate': 0.04053314077367818, 'num_leaves': 173, 'feature_fraction': 0.8710874581442012, 'bagging_fraction': 0.6037115183441955, 'bagging_freq': 3, \n 'lambda_l1': 0.9517420004019254, 'lambda_l2': 0.7270178245553806, 'min_data_in_leaf': 108, 'max_depth': 25}\n\n\nmodel = lgb.LGBMRegressor(**params  )\nmodel.fit(trainx , trainy)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-29T08:05:39.032858Z","iopub.execute_input":"2025-10-29T08:05:39.033596Z","iopub.status.idle":"2025-10-29T08:05:40.07181Z","shell.execute_reply.started":"2025-10-29T08:05:39.033569Z","shell.execute_reply":"2025-10-29T08:05:40.071024Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.metrics import mean_squared_error\n\npreds = model.predict(testx)\n\nval_pred = pd.DataFrame({'actual' : testy , 'predicted' : preds})\n\nval_pred.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-29T08:05:44.372144Z","iopub.execute_input":"2025-10-29T08:05:44.372852Z","iopub.status.idle":"2025-10-29T08:05:44.405599Z","shell.execute_reply.started":"2025-10-29T08:05:44.372819Z","shell.execute_reply":"2025-10-29T08:05:44.404838Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print('Mean Squared Error',mean_squared_error(val_pred.actual , val_pred.predicted))\nprint('Root Mean Squared Error' , mean_squared_error(val_pred.actual , val_pred.predicted , squared = False))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-29T08:06:08.473061Z","iopub.execute_input":"2025-10-29T08:06:08.473638Z","iopub.status.idle":"2025-10-29T08:06:08.479664Z","shell.execute_reply.started":"2025-10-29T08:06:08.473618Z","shell.execute_reply":"2025-10-29T08:06:08.479069Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\nimport polars as pl\nimport lightgbm as lgb\nimport kaggle_evaluation.default_inference_server\n\nfrom gc import collect\nfrom warnings import filterwarnings\nfilterwarnings(\"ignore\")\n\n# ===============================\n# Constants\n# ===============================\nMIN_SIGNAL = 0.0\nMAX_SIGNAL = 2.0\nSIGNAL_MULTIPLIER = 1.0\n\n\n# ===============================\n# Utility functions\n# ===============================\n\n\n\n# def predictions_to_signal(predictions):\n#     \"\"\"Convert raw model predictions to valid signals in [0, 2].\"\"\"\n#     signals = np.clip(predictions * SIGNAL_MULTIPLIER, MIN_SIGNAL, MAX_SIGNAL)\n#     return signals\n\n\nALPHA_FOR_SCORER = 0.600132\nTAU_ABS_FOR_SCORER = 9.43717e-05\nMIN_INVESTMENT, MAX_INVESTMENT = 0.0, 2.0\nTRADING_DAYS = 252\n\ndef post_process_signal(y_pred,\n                        *,\n                        tau: float = TAU_ABS_FOR_SCORER,\n                        alpha: float = ALPHA_FOR_SCORER,\n                        min_investment: float = MIN_INVESTMENT,\n                        max_investment: float = MAX_INVESTMENT):\n    sig = np.asarray(y_pred, dtype=float).ravel()\n    pos = np.where(sig > tau, alpha, 0.0)\n    return np.clip(pos, min_investment, max_investment)\n\n\n\n\n# Example feature columns (must match training)\ncols_x = model.feature_name_\ncat_cols = [c for c in cols_x if c.startswith(\"D\")]\n\nprint(f\"Model loaded with {len(cols_x)} features.\")\n\n\n\n\n\ndef predict(test: pl.DataFrame) -> float:\n    \"\"\"\n    Predict single-day market position for inference server.\n    Must return a single float.\n    \"\"\"\n    global model, cols_x, cat_cols\n\n    # Convert Polars → Pandas\n    test = test.to_pandas()\n\n    # Convert categorical\n    if cat_cols:\n        for c in cat_cols:\n            if c in test.columns:\n                test[c] = test[c].astype(\"category\")\n\n    # Preprocess (handles NaN + alignment)\n    test, _ = preprocess(test)   # ✅ FIX: unpack tuple safely\n\n    # Lagged feature creation\n    test = lagged_variables_creation(test, mode=\"test\")\n\n    # Rename lagged vars for consistency\n    test.rename(columns={\n        \"lagged_forward_returns\": \"lagged_forward_returns_1\",\n        \"lagged_risk_free_rate\": \"lagged_risk_free_rate_1\",\n        \"lagged_market_forward_excess_returns\": \"lagged_market_forward_excess_returns_1\"\n    }, inplace=True)\n\n    # Apply backward fill for lagged columns\n    cols_lag = [c for c in test.columns if 'lagged_' in c]\n    test[cols_lag] = test[cols_lag].bfill()\n\n    # Align columns with model input\n    test = test.reindex(columns=cols_x, fill_value=0)\n\n    # Predict\n    preds = model.predict(test)\n    # preds = np.asarray(preds).ravel()\n    pos = post_process_signal(preds)\n    return float(np.asarray(pos).ravel()[0])\n\n    # Convert to valid signal\n    # signal = predictions_to_signal(preds[0])\n   \n    # return float(signal)\n\n\n\n# Inference Server\n# ===============================\nprint(\"Starting inference server...\")\n\ninference_server = kaggle_evaluation.default_inference_server.DefaultInferenceServer(predict)\n\nif os.getenv(\"KAGGLE_IS_COMPETITION_RERUN\"):\n    inference_server.serve()\nelse:\n    inference_server.run_local_gateway((\"/kaggle/input/hull-tactical-market-prediction/\",))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-29T08:06:35.835615Z","iopub.execute_input":"2025-10-29T08:06:35.836364Z","iopub.status.idle":"2025-10-29T08:06:36.491135Z","shell.execute_reply.started":"2025-10-29T08:06:35.836338Z","shell.execute_reply":"2025-10-29T08:06:36.49039Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}