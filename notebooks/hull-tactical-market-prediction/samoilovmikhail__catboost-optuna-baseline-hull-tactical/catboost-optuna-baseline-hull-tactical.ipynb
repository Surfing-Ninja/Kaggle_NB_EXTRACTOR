{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":111543,"databundleVersionId":13750964,"sourceType":"competition"}],"dockerImageVersionId":31089,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# 1. Introduction","metadata":{}},{"cell_type":"markdown","source":"## Imports","metadata":{}},{"cell_type":"code","source":"import os\nimport gc\nimport warnings\nimport joblib\nimport numpy as np\nimport pandas as pd\nimport polars as pl\nimport catboost\nimport optuna\nimport kaggle_evaluation.default_inference_server\nfrom catboost import CatBoostRegressor\nfrom sklearn.model_selection import TimeSeriesSplit\nfrom scipy.stats import spearmanr\n\nwarnings.filterwarnings('ignore')\noptuna.logging.set_verbosity(optuna.logging.WARNING)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-10-02T16:42:40.541349Z","iopub.execute_input":"2025-10-02T16:42:40.54171Z","iopub.status.idle":"2025-10-02T16:42:40.549731Z","shell.execute_reply.started":"2025-10-02T16:42:40.541685Z","shell.execute_reply":"2025-10-02T16:42:40.547925Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Config","metadata":{}},{"cell_type":"code","source":"TRAIN_PATH = '/kaggle/input/hull-tactical-market-prediction/train.csv'\nLOCAL_GATEWAY_PATH = '/kaggle/input/hull-tactical-market-prediction/'\nMODEL_PATH = 'catboost_model.cbm'\nFEATURES_PATH = 'features.joblib'\n\nTOP_FEATURES_FOR_FE = ['M4', 'V13', 'S5', 'S2', 'D2']\nLAG_PERIODS = [1, 5, 20]\nROLLING_WINDOWS = [5, 20, 60]\n\nTARGET = 'market_forward_excess_returns'\nCOLS_TO_DROP = ['forward_returns', 'risk_free_rate', 'excess_return', 'E7', 'V10', 'S3', 'M1', 'M14']\nBEST_C = 0.5","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-02T16:43:01.962702Z","iopub.execute_input":"2025-10-02T16:43:01.963015Z","iopub.status.idle":"2025-10-02T16:43:01.969591Z","shell.execute_reply.started":"2025-10-02T16:43:01.962994Z","shell.execute_reply":"2025-10-02T16:43:01.968437Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 2. Auxiliary function for creating features","metadata":{}},{"cell_type":"code","source":"def create_features(df: pd.DataFrame) -> pd.DataFrame:\n    df_out = df.copy()\n    \n    for col in TOP_FEATURES_FOR_FE:\n        if col in df_out.columns:\n            for lag in LAG_PERIODS:\n                df_out[f'{col}_lag_{lag}'] = df_out[col].shift(lag)\n            for window in ROLLING_WINDOWS:\n                df_out[f'{col}_roll_mean_{window}'] = df_out[col].rolling(window=window, min_periods=1).mean()\n                df_out[f'{col}_roll_std_{window}'] = df_out[col].rolling(window=window, min_periods=1).std()\n\n    df_out.ffill(inplace=True)\n    for col in df_out.columns:\n        if df_out[col].isnull().any():\n            median_val = df_out[col].median()\n            df_out[col].fillna(median_val if not np.isnan(median_val) else 0, inplace=True)\n            \n    return df_out","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-02T16:43:59.588412Z","iopub.execute_input":"2025-10-02T16:43:59.588729Z","iopub.status.idle":"2025-10-02T16:43:59.595539Z","shell.execute_reply.started":"2025-10-02T16:43:59.588709Z","shell.execute_reply":"2025-10-02T16:43:59.594517Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 3. Catboost train","metadata":{}},{"cell_type":"code","source":"if not os.path.exists(MODEL_PATH):\n    print(\"Model not found. Starting training process...\")\n    \n    train_df = pd.read_csv(TRAIN_PATH)\n    if 'date_id' not in train_df.columns:\n        train_df['date_id'] = train_df.index\n    train_df.drop(columns=[col for col in COLS_TO_DROP if col in train_df.columns], inplace=True)\n\n    train_featured = create_features(train_df)\n    train_featured.dropna(subset=[TARGET], inplace=True)\n    \n    FEATURES = [col for col in train_featured.columns if col not in [TARGET, 'date_id']]\n    X = train_featured[FEATURES]\n    y = train_featured[TARGET]\n\n    def objective(trial):\n        params = {\n            'objective': 'RMSE',\n            'iterations': trial.suggest_int('iterations', 480, 2100),\n            'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.05, log=True),\n            'depth': trial.suggest_int('depth', 5, 8),\n            'l2_leaf_reg': trial.suggest_float('l2_leaf_reg', 2.0, 10.0, log=True),\n            'random_strength': trial.suggest_float('random_strength', 1e-8, 1.0, log=True),\n            'colsample_bylevel': trial.suggest_float('colsample_bylevel', 0.6, 1.0),\n            'verbose': 0,\n            'early_stopping_rounds': 50\n        }\n        \n        tscv = TimeSeriesSplit(n_splits=4)\n        scores = []\n        for train_index, val_index in tscv.split(X):\n            model_opt = CatBoostRegressor(**params)\n            model_opt.fit(X.iloc[train_index], y.iloc[train_index], eval_set=(X.iloc[val_index], y.iloc[val_index]))\n            preds = model_opt.predict(X.iloc[val_index])\n            score, _ = spearmanr(y.iloc[val_index], preds)\n            scores.append(score)\n        return np.mean(scores)\n\n    study = optuna.create_study(direction='maximize')\n    study.optimize(objective, n_trials=200, timeout=5400)\n\n    print(f\"Best params found: {study.best_params}\")\n    final_model = CatBoostRegressor(**study.best_params, verbose=500, random_seed=42)\n    final_model.fit(X, y)\n    final_model.save_model(MODEL_PATH)\n    joblib.dump(FEATURES, FEATURES_PATH)\n    print(\"Training complete. Model and features saved.\")\n    \nelse:\n    print(\"Model training skipped: Model file already exists.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-02T16:44:51.863542Z","iopub.execute_input":"2025-10-02T16:44:51.863872Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 4. Loading artifacts and initializing the status for the inference","metadata":{}},{"cell_type":"code","source":"print(\"Loading artifacts for inference...\")\ntry:\n    model = CatBoostRegressor()\n    model.load_model(MODEL_PATH)\n    MODEL_FEATURES = joblib.load(FEATURES_PATH)\nexcept Exception as e:\n    raise RuntimeError(f\"Could not load model/features. Ensure training was successful. Error: {e}\")\n\nprint(\"Initializing prediction history...\")\nhistory_df = pd.read_csv(TRAIN_PATH)\n\ncols_to_drop_hist = [\n    col for col in COLS_TO_DROP \n    if col in history_df.columns and col != TARGET\n]\nhistory_df.drop(columns=cols_to_drop_hist, inplace=True)\nif 'date_id' not in history_df.columns:\n    history_df['date_id'] = history_df.index\n    \nprint(\"Setup complete. Ready for prediction.\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 5. Submission with `predict`","metadata":{}},{"cell_type":"code","source":"def predict(test_df_pl: pl.DataFrame) -> float:\n    global history_df\n    \n    test_df_pd = test_df_pl.to_pandas()\n    if 'date_id' not in test_df_pd.columns:\n        last_date_id = history_df['date_id'].max() if not history_df.empty else -1\n        test_df_pd['date_id'] = last_date_id + 1\n    \n    history_df = pd.concat([history_df, test_df_pd], ignore_index=True)\n\n    slice_size = max(ROLLING_WINDOWS) + max(LAG_PERIODS) + 5\n    historical_slice = history_df.tail(slice_size)\n    processed_slice = create_features(historical_slice)\n    \n    current_features = processed_slice.tail(1)[MODEL_FEATURES]\n    prediction = model.predict(current_features)[0]\n    \n    allocation = np.clip(1 + BEST_C * prediction, 0, 2)\n    \n    gc.collect()\n    \n    return float(allocation)\n\ninference_server = kaggle_evaluation.default_inference_server.DefaultInferenceServer(predict)\n\nif os.getenv('KAGGLE_IS_COMPETITION_RERUN'):\n    print(\"Serving predictions for the competition...\")\n    inference_server.serve()\nelse:\n    print(\"Running local gateway for testing...\")\n    inference_server.run_local_gateway((LOCAL_GATEWAY_PATH,))\n\nprint(\"Submission script finished.\")","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}