{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":86518,"databundleVersionId":9809560,"sourceType":"competition"},{"sourceId":6063,"sourceType":"modelInstanceVersion","modelInstanceId":4684,"modelId":2820},{"sourceId":205017,"sourceType":"modelInstanceVersion","modelInstanceId":4684,"modelId":2820}],"dockerImageVersionId":31089,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<div style=\"background-color: #333; padding: 40px; border: 2px solid #ffd700; border-radius: 10px; color: #ffd700; text-align: center; box-shadow: 0 4px 8px rgba(0, 0, 0, 0.2);\">\n\n<h1 style=\"font-size: 48px; font-weight: bold; color: #ffd700;\">LLM Classification finetuning DeBERTA</h1>\n\n<img src=\"https://cdn.arstechnica.net/wp-content/uploads/2023/12/GettyImages-152404829-scaled.jpg\" alt=\"Chatbot arena\" style=\"width: 500px; margin: 20px auto; border-radius: 10px; box-shadow: 0 4px 8px rgba(0, 0, 0, 0.2);\">\n    \n</div>","metadata":{"_uuid":"9edf1f7b-6ae4-4f68-85de-74bc6279bbc9","_cell_guid":"4b0b030f-9e60-443a-a897-24acfced08d9","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"markdown","source":"## <div style=\"border-radius: 10px; border: 2px solid #ffd700; padding: 15px; background-color: #333; font-size: 120%; text-align: center; color: #ffd700; font-weight: bold;\">Table of content</div>","metadata":{}},{"cell_type":"markdown","source":"<ul class=\"list-group\" id=\"list-tab\" role=\"tablist\">\n    <li><a href=\"#0.-Introduction\">0. Introduction</a></li><br>\n    <li><a href=\"#1.-Import-Libraries\">1. Import Libraries</a></li><br>\n    <li><a href=\"#2.-Data-Loading-&-Inspection\">2. Data Loading & Inspection</a></li><br>\n    <li><a href=\"#3.-Text-Preprocessing\">3. Text Preprocessing</a></li><br>\n    <li><a href=\"#4.-Dataset-Preparation\">4. Dataset Preparation</a></li><br>\n    <li><a href=\"#5.-Model-Building\">5. Model Building</a></li><br>\n    <li><a href=\"#6.-Training-&-Evaluation\">6. Training & Evaluation</a></li><br>\n    <li><a href=\"#7.-Prediction-&-Submission\">7. Prediction & Submission</a></li><br>\n</ul>","metadata":{}},{"cell_type":"markdown","source":"## <div style=\"border-radius: 10px; border: 2px solid #ffd700; padding: 15px; background-color: #333; font-size: 120%; text-align: center; color: #ffd700; font-weight: bold;\">0. Introduction</div>","metadata":{}},{"cell_type":"markdown","source":"### Intro : \n\nIn the rapidly evolving world of large language models (LLMs), one of the most critical challenges is ensuring that AI-generated responses align with human preferences. While modern chatbots can produce fluent and coherent text, not all responses are equally engaging, helpful, or satisfying to users. This Kaggle competition tackles this challenge head-on by leveraging real-world data from Chatbot Arena, where users compare responses from different LLMs and choose their preferred one.\n\n### Competition Overview :\n\nThe goal is to predict which LLM response a human judge will prefer in a head-to-head battle. Each conversation consists of:\n\nA user prompt (the input given to the chatbots).\n\nTwo LLM-generated responses (anonymous models competing against each other).\n\nA human preference label (indicating which response was preferred).\n\nThis task mirrors Reinforcement Learning from Human Feedback (RLHF), a key technique for aligning AI with human values. Successfully predicting preferences helps improve reward models, which are essential for training better chatbots.\n\n### Key challenges :\n\n1. Biases in Human Judgments\n\n    * Position bias: Users may favor the first or second response due to ordering.\n\n    * Verbosity bias: Longer responses might be preferred even if less accurate.\n\n    * Self-enhancement bias: Models may subtly promote themselves.\n\n2. Model Generalization\n\n    * The test set (~25K samples) requires robust predictions beyond the training data (55K samples).\n\n3. Interpretable Preference Modeling\n\n    * Understanding why users prefer certain responses can guide better LLM fine-tuning.\n  \n### Why this matters :\n\nImproving preference prediction models directly enhances:\n\n* Chatbot training.\n\n* User satisfaction (by aligning AI with human expectations).\n\n* Fairness & robustness (reducing biases in AI judgments).\n\nBy competing in this challenge, we contribute to the future of human-aligned AI assistantsâ€”making them not just smarter, but also more attuned to what users truly want.","metadata":{}},{"cell_type":"markdown","source":"## <div style=\"border-radius: 10px; border: 2px solid #ffd700; padding: 15px; background-color: #333; font-size: 120%; text-align: center; color: #ffd700; font-weight: bold;\">1. Import Libraries</div>","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nprint(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\nprint(tf.test.gpu_device_name())\n\n# Configure GPU memory growth (prevents OOM errors)\ngpus = tf.config.experimental.list_physical_devices('GPU')\nif gpus:\n    try:\n        for gpu in gpus:\n            tf.config.experimental.set_memory_growth(gpu, True)\n    except RuntimeError as e:\n        print(e)","metadata":{"_uuid":"7199a26c-e7fc-4b97-a67c-4a5651f4e968","_cell_guid":"6c7b61b9-fe93-4fc1-8efe-d26c8395c114","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-07-30T11:42:51.22046Z","iopub.execute_input":"2025-07-30T11:42:51.221038Z","iopub.status.idle":"2025-07-30T11:43:05.474422Z","shell.execute_reply.started":"2025-07-30T11:42:51.221013Z","shell.execute_reply":"2025-07-30T11:43:05.47366Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport re\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nimport keras_nlp\nfrom sklearn.model_selection import train_test_split\nfrom keras import backend as K\n\n# Configuration\nMODEL_NAME = \"deberta_v3_extra_small_en\"\nSEQUENCE_LENGTH = 128\nBATCH_SIZE = 32\nEPOCHS = 5\nLEARNING_RATE = 5e-6","metadata":{"_uuid":"1938c30a-099a-4e49-b648-48dfad50fd33","_cell_guid":"844f9497-0a09-4b60-98f8-1a35ecee3060","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-07-30T11:43:05.47571Z","iopub.execute_input":"2025-07-30T11:43:05.47614Z","iopub.status.idle":"2025-07-30T11:43:06.752821Z","shell.execute_reply.started":"2025-07-30T11:43:05.47612Z","shell.execute_reply":"2025-07-30T11:43:06.752262Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## <div style=\"border-radius: 10px; border: 2px solid #ffd700; padding: 15px; background-color: #333; font-size: 120%; text-align: center; color: #ffd700; font-weight: bold;\">2. Data Loading & Inspection</div>","metadata":{"_uuid":"69d59df5-2187-4cbb-b1ec-54a65db6d634","_cell_guid":"9a05b397-6264-4051-b3c2-9c45c8a5c39d","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"# Load datasets\ntrain_df = pd.read_csv(\"/kaggle/input/llm-classification-finetuning/train.csv\")\ntest_df = pd.read_csv(\"/kaggle/input/llm-classification-finetuning/test.csv\")\n\n# Quick inspection\nprint(\"Train shape:\", train_df.shape)\nprint(\"Test shape:\", test_df.shape)\ntrain_df.head()","metadata":{"_uuid":"325e37b2-91e5-45f5-97de-7b0bac32b5b3","_cell_guid":"02ed24a1-0d59-4e38-a0b5-d4f102a2303e","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-07-30T11:43:06.753628Z","iopub.execute_input":"2025-07-30T11:43:06.753899Z","iopub.status.idle":"2025-07-30T11:43:10.073688Z","shell.execute_reply.started":"2025-07-30T11:43:06.753875Z","shell.execute_reply":"2025-07-30T11:43:10.072957Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Basic validation checks\ndef check_data(df, name):\n    print(f\"\\n{name} Data Summary:\")\n    print(\"- Missing values:\", df.isna().sum().sum())\n    print(\"- Duplicates:\", df.duplicated().sum())\n    print(\"- Target distribution:\")\n    print(df[['winner_model_a', 'winner_model_b', 'winner_tie']].mean())\n\n\ncheck_data(train_df, \"Train\")","metadata":{"_uuid":"441b6550-2266-4ee3-b933-78ef09395c52","_cell_guid":"5491495a-3047-435b-b7d6-e6897c06b812","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-07-30T11:43:10.075094Z","iopub.execute_input":"2025-07-30T11:43:10.075326Z","iopub.status.idle":"2025-07-30T11:43:10.495621Z","shell.execute_reply.started":"2025-07-30T11:43:10.075307Z","shell.execute_reply":"2025-07-30T11:43:10.495018Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## <div style=\"border-radius: 10px; border: 2px solid #ffd700; padding: 15px; background-color: #333; font-size: 120%; text-align: center; color: #ffd700; font-weight: bold;\">3. Text Preprocessing</div>","metadata":{"_uuid":"83eb2d5c-d0e9-4e2e-bc5c-6201060145b2","_cell_guid":"d9d49b91-e474-4f17-9a2a-508c46a58572","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"class TextPreprocessor:\n    def __init__(self):\n        self.tokenizer = keras_nlp.models.DebertaV3Tokenizer.from_preset(MODEL_NAME)\n        \n    def clean_text(self, text):\n        \"\"\"Normalize text for DeBERTa\"\"\"\n        text = str(text)\n        text = re.sub(r\"\\s+\", \" \", text)  # Collapse whitespace\n        text = re.sub(r\"[^\\x00-\\x7F]+\", \" \", text)  # Remove non-ASCII\n        return text.strip()\n    \n    def create_input_pairs(self, row):\n        \"\"\"Format prompt-response pairs\"\"\"\n        clean_prompt = self.clean_text(row['prompt'])\n        return [\n            f\"Prompt: {clean_prompt} {self.tokenizer.sep_token} Response: {self.clean_text(row['response_a'])}\",\n            f\"Prompt: {clean_prompt} {self.tokenizer.sep_token} Response: {self.clean_text(row['response_b'])}\"\n        ]\n\n# Initialize processor\nprocessor = TextPreprocessor()","metadata":{"_uuid":"4bbe4d59-0d72-47ca-ad81-a69d97d506c0","_cell_guid":"6f1f4d47-f597-4913-aabb-c8daf692991a","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-07-30T11:43:10.496353Z","iopub.execute_input":"2025-07-30T11:43:10.496625Z","iopub.status.idle":"2025-07-30T11:43:12.730092Z","shell.execute_reply.started":"2025-07-30T11:43:10.496596Z","shell.execute_reply":"2025-07-30T11:43:12.729502Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Apply preprocessing\ntrain_df['inputs'] = train_df.apply(processor.create_input_pairs, axis=1)\ntest_df['inputs'] = test_df.apply(processor.create_input_pairs, axis=1)\n\n# Create labels (0: model_a wins, 1: model_b wins, 2: tie)\ntrain_df['label'] = train_df[['winner_model_a', 'winner_model_b', 'winner_tie']].idxmax(axis=1)\ntrain_df['label'] = train_df['label'].map({'winner_model_a':0, 'winner_model_b':1, 'winner_tie':2})\n\n# Preview processed data\ntrain_df[['inputs', 'label']].head()","metadata":{"_uuid":"315fad2f-0713-448d-8755-5c54b729c480","_cell_guid":"12035fbd-930d-414d-9477-0f77565f0c1f","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-07-30T11:43:12.730925Z","iopub.execute_input":"2025-07-30T11:43:12.73145Z","iopub.status.idle":"2025-07-30T11:43:24.206472Z","shell.execute_reply.started":"2025-07-30T11:43:12.731423Z","shell.execute_reply":"2025-07-30T11:43:24.205764Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## <div style=\"border-radius: 10px; border: 2px solid #ffd700; padding: 15px; background-color: #333; font-size: 120%; text-align: center; color: #ffd700; font-weight: bold;\">4. Dataset Preparation</div>","metadata":{"_uuid":"a471f145-fb75-4876-bc4e-2e8826aaa716","_cell_guid":"f8223c6e-df93-4510-9d49-1606a4608308","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"# Train/validation split\ntrain_df, valid_df = train_test_split(\n    train_df, \n    test_size=0.1, \n    stratify=train_df['label'],\n    random_state=42\n)\n\n# Create TensorFlow datasets with proper input pair handling\ndef create_dataset(text_pairs, labels=None, preprocessor=None):\n    \"\"\"Convert to optimized TF Dataset with proper input pair handling\"\"\"\n    AUTO = tf.data.AUTOTUNE\n    \n    # Convert to TensorFlow Dataset\n    if labels is not None:\n        ds = tf.data.Dataset.from_tensor_slices((text_pairs, labels))\n        ds = ds.shuffle(1000)\n    else:\n        ds = tf.data.Dataset.from_tensor_slices(text_pairs)\n    \n    # Preprocessing function\n    def preprocess_pair(text_pair, label=None):\n        \"\"\"Convert raw text pairs to model-ready format\"\"\"\n        # Tokenize each response separately\n        processed_a = preprocessor(text_pair[0])  # {'token_ids': ..., 'padding_mask': ...}\n        processed_b = preprocessor(text_pair[1])\n        \n        # Stack to create (2, seq_len) tensors\n        model_inputs = {\n            \"token_ids\": tf.stack([processed_a[\"token_ids\"], processed_b[\"token_ids\"]], axis=0),\n            \"padding_mask\": tf.stack([processed_a[\"padding_mask\"], processed_b[\"padding_mask\"]], axis=0)\n        }\n        return (model_inputs, label) if label is not None else model_inputs\n    \n    # Apply preprocessing and batching\n    ds = ds.map(preprocess_pair, num_parallel_calls=AUTO)\n    ds = ds.batch(BATCH_SIZE).prefetch(AUTO)\n    return ds\n\n# Initialize preprocessor\npreprocessor = keras_nlp.models.DebertaV3Preprocessor.from_preset(\n    MODEL_NAME,\n    sequence_length=SEQUENCE_LENGTH\n)\n\n# Prepare all datasets\ntrain_ds = create_dataset(\n    train_df['inputs'].tolist(), \n    tf.keras.utils.to_categorical(train_df['label']),\n    preprocessor=preprocessor\n)\nvalid_ds = create_dataset(\n    valid_df['inputs'].tolist(), \n    tf.keras.utils.to_categorical(valid_df['label']),\n    preprocessor=preprocessor\n)\ntest_ds = create_dataset(\n    test_df['inputs'].tolist(),\n    preprocessor=preprocessor\n)","metadata":{"_uuid":"d1185666-1b9b-40c9-9fcb-22937d6ad549","_cell_guid":"1fbdaebb-6734-4ab4-ba1b-8b93c9f4b92e","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-07-30T11:43:24.20727Z","iopub.execute_input":"2025-07-30T11:43:24.207559Z","iopub.status.idle":"2025-07-30T11:43:33.312322Z","shell.execute_reply.started":"2025-07-30T11:43:24.20753Z","shell.execute_reply":"2025-07-30T11:43:33.311724Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Check a batch from your dataset\nfor batch in train_ds.take(1):\n    inputs, labels = batch\n    print(\"Token IDs shape:\", inputs[\"token_ids\"].shape)  # Should be (batch_size, 2, 128)\n    print(\"Mask shape:\", inputs[\"padding_mask\"].shape)\n    print(\"Example token_ids[0,0,:5]:\", inputs[\"token_ids\"][0,0,:5])  # First 5 tokens of response_a","metadata":{"_uuid":"a873b616-57bb-4bc1-93af-b7d5374f3954","_cell_guid":"fb69a98c-39b6-44a2-be72-49a864afe239","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-07-30T11:43:33.313035Z","iopub.execute_input":"2025-07-30T11:43:33.313274Z","iopub.status.idle":"2025-07-30T11:43:33.694405Z","shell.execute_reply.started":"2025-07-30T11:43:33.313255Z","shell.execute_reply":"2025-07-30T11:43:33.693684Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## <div style=\"border-radius: 10px; border: 2px solid #ffd700; padding: 15px; background-color: #333; font-size: 120%; text-align: center; color: #ffd700; font-weight: bold;\">5. Model Building</div>","metadata":{"_uuid":"1e3cee59-c1b1-474f-99d3-807700365a16","_cell_guid":"05ae1193-c526-41a6-9367-b89a65a9f17f","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"def build_deberta_classifier():\n    with tf.device('/GPU:0'):\n        # Define input layers\n        token_ids = tf.keras.layers.Input(\n            shape=(2, SEQUENCE_LENGTH), \n            dtype=tf.int32,\n            name=\"token_ids\"\n        )\n        padding_mask = tf.keras.layers.Input(\n            shape=(2, SEQUENCE_LENGTH),\n            dtype=tf.int32,\n            name=\"padding_mask\"\n        )\n        \n        inputs = {\"token_ids\": token_ids, \"padding_mask\": padding_mask}\n        \n        # Initialize backbone\n        backbone = keras_nlp.models.DebertaV3Backbone.from_preset(MODEL_NAME)\n        \n        # Process both responses\n        def process_response(inputs, index):\n            return {\n                \"token_ids\": inputs[\"token_ids\"][:, index, :],\n                \"padding_mask\": inputs[\"padding_mask\"][:, index, :]\n            }\n        \n        emb_a = backbone(process_response(inputs, 0))\n        emb_b = backbone(process_response(inputs, 1))\n        \n        # Classification head\n        combined = tf.keras.layers.Concatenate()([emb_a, emb_b])\n        x = tf.keras.layers.GlobalAveragePooling1D()(combined)\n        x = tf.keras.layers.Dropout(0.5)(x)\n        outputs = tf.keras.layers.Dense(3, activation='softmax')(x)\n    \n    return tf.keras.Model(inputs=inputs, outputs=outputs)\n\n# 2. Build and compile the model\nmodel = build_deberta_classifier()\n\nmodel.compile(\n    optimizer=tf.keras.optimizers.AdamW(LEARNING_RATE, weight_decay=0.01),\n    loss=tf.keras.losses.CategoricalCrossentropy(label_smoothing=0.1),\n    metrics=[\"accuracy\", \"categorical_crossentropy\"]\n)","metadata":{"_uuid":"ea870872-43fd-4e0e-bbe9-0482093b4801","_cell_guid":"d4a5fff8-031a-4ea4-b30a-44df29ee5b1a","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-07-30T11:43:33.695137Z","iopub.execute_input":"2025-07-30T11:43:33.69541Z","iopub.status.idle":"2025-07-30T11:43:40.273655Z","shell.execute_reply.started":"2025-07-30T11:43:33.695381Z","shell.execute_reply":"2025-07-30T11:43:40.273077Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## <div style=\"border-radius: 10px; border: 2px solid #ffd700; padding: 15px; background-color: #333; font-size: 120%; text-align: center; color: #ffd700; font-weight: bold;\">6. Training & Evaluation</div>","metadata":{"_uuid":"8b4871db-3c9d-4cd6-9799-c6a54af482ed","_cell_guid":"999b0f1b-79a6-41e6-a56b-4c4bca750cab","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"# Callbacks\ncallbacks = [\n    tf.keras.callbacks.EarlyStopping(patience=2, restore_best_weights=True),\n    tf.keras.callbacks.ModelCheckpoint(\"best_model.weights.h5\", save_best_only=True),\n    tf.keras.callbacks.ReduceLROnPlateau(factor=0.5, patience=1)\n]\n\n# Train model\nhistory = model.fit(\n    train_ds,\n    validation_data=valid_ds,\n    epochs=EPOCHS,\n    callbacks=callbacks\n)\n\n# Plot training history\npd.DataFrame(history.history)[['loss', 'val_loss']].plot()\nplt.title(\"Training History\")\nplt.show()","metadata":{"_uuid":"0e2a61a8-0cee-40eb-abd5-b1d18c50a4d9","_cell_guid":"d7de469d-9e1d-4168-bc18-77944ce18dbd","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-07-30T11:43:40.275498Z","iopub.execute_input":"2025-07-30T11:43:40.27575Z","iopub.status.idle":"2025-07-30T12:05:22.170623Z","shell.execute_reply.started":"2025-07-30T11:43:40.275723Z","shell.execute_reply":"2025-07-30T12:05:22.169917Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## <div style=\"border-radius: 10px; border: 2px solid #ffd700; padding: 15px; background-color: #333; font-size: 120%; text-align: center; color: #ffd700; font-weight: bold;\">7. Prediction & Submission</div>","metadata":{"_uuid":"ea2513d6-336a-4f6f-b8e8-68c35a4ccb4b","_cell_guid":"c6f5579f-16e1-4024-993f-6c7745c6b63b","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"# Generate predictions\ntest_preds = model.predict(test_ds)\ntest_df['prediction'] = np.argmax(test_preds, axis=1)\n\n# Create submission\nsubmission = pd.DataFrame({\n            \"id\": test_df.id,\n            \"winner_model_a\": test_preds[:, 0],\n            \"winner_model_b\": test_preds[:, 1],\n            \"winner_tie\": test_preds[:, 2]\n        })\nsubmission.to_csv(\"submission.csv\", index=False)\nprint(\"Submission saved!\")\nsubmission","metadata":{"_uuid":"5fa5ba9e-e121-437d-83f2-f2990e924dc9","_cell_guid":"633d44ea-5dd5-4552-a251-5d0b0008772d","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-07-30T12:05:22.171357Z","iopub.execute_input":"2025-07-30T12:05:22.171621Z","iopub.status.idle":"2025-07-30T12:05:36.552819Z","shell.execute_reply.started":"2025-07-30T12:05:22.171598Z","shell.execute_reply":"2025-07-30T12:05:36.552272Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<div style=\"border-radius: 10px; border: 2px solid #ffd700; padding: 15px; background-color: #001f3f; font-size: 120%; text-align: center; color: #ffd700; font-weight: bold;\">If you found this work helpful or valuable, I would greatly appreciate an upvote.</div>","metadata":{}}]}