{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":86518,"databundleVersionId":9809560,"sourceType":"competition"},{"sourceId":4982782,"sourceType":"datasetVersion","datasetId":2889918,"isSourceIdPinned":false},{"sourceId":6063,"sourceType":"modelInstanceVersion","modelInstanceId":4684,"modelId":2820}],"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### Assigment 2\n\n#### Step 0","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd \nimport tensorflow as tf\nimport torch\nimport keras\nimport keras_hub\nimport re\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import log_loss, accuracy_score, classification_report\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.ensemble import RandomForestClassifier\nimport os\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-06T09:33:11.966246Z","iopub.execute_input":"2025-11-06T09:33:11.967015Z","iopub.status.idle":"2025-11-06T09:33:11.972252Z","shell.execute_reply.started":"2025-11-06T09:33:11.966989Z","shell.execute_reply":"2025-11-06T09:33:11.971281Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"for dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        filepath = os.path.join(dirname, filename)\n        match filename:\n            case \"train.csv\":\n                train = pd.read_csv(filepath)\n            case \"test.csv\":\n                test = pd.read_csv(filepath)\n\nprint(\"Train shape:\", train.shape)\nprint(\"Test shape:\", test.shape)\ntrain.head()","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-11-06T09:33:18.894216Z","iopub.execute_input":"2025-11-06T09:33:18.895068Z","iopub.status.idle":"2025-11-06T09:33:20.756346Z","shell.execute_reply.started":"2025-11-06T09:33:18.895033Z","shell.execute_reply":"2025-11-06T09:33:20.755518Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print('Train columns: ', train.columns.tolist())\nprint('\\nTarget distribution: ')\nprint(train[['winner_model_a', 'winner_model_b', 'winner_tie']].sum())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-06T09:33:24.734476Z","iopub.execute_input":"2025-11-06T09:33:24.735043Z","iopub.status.idle":"2025-11-06T09:33:24.74177Z","shell.execute_reply.started":"2025-11-06T09:33:24.735019Z","shell.execute_reply":"2025-11-06T09:33:24.74104Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#quick check if data is damaged\ntrain.isnull()  #null or missing data\ntest.isnull()\n\nprint(test.duplicated().sum()) #duplicates \nprint(train.duplicated().sum())\n\ntotal_id = len(train['id'])   #duplicates in id\ntotal_unique_id = len(train['id'].unique())\n\nprint(\"Total number of 'id' duplicates: \",(total_id - total_unique_id))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-06T09:33:27.562545Z","iopub.execute_input":"2025-11-06T09:33:27.56332Z","iopub.status.idle":"2025-11-06T09:33:28.014002Z","shell.execute_reply.started":"2025-11-06T09:33:27.563294Z","shell.execute_reply":"2025-11-06T09:33:28.013278Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### Step 1","metadata":{}},{"cell_type":"code","source":"#extraxting features\ndef get_sentence_count(series):\n    return series.map(lambda x: x.count('.') + x.count('!') + x.count('?'))\n\ndef get_avg_word_len(series):\n    return series.map(lambda x: np.mean([len(w) for w in x.split()]) if len(x.split()) > 0 else 0)\n\ndef get_upper_ratio(series):\n    return series.map(lambda x: sum(c.isupper() for c in x) / len(x) if len(x) > 0 else 0)\n\ndef get_num_digits(series):\n    return series.map(lambda x: len(re.findall(r'\\d', x)))\n\ndef get_punct_count(series):\n    return series.map(lambda x: sum(c in \"!?;:,\" for c in x))\n\ndef extract_features(data):\n    response_len_a = data['response_a'].map(len)\n    response_len_b = data['response_b'].map(len)\n    word_count_a = data['response_a'].map(lambda x: len(x.split()))\n    word_count_b = data['response_b'].map(lambda x: len(x.split()))\n    sentence_count_a = get_sentence_count(data['response_a'])\n    sentence_count_b = get_sentence_count(data['response_b'])\n    avg_word_len_a = get_avg_word_len(data['response_a'])\n    avg_word_len_b = get_avg_word_len(data['response_b'])\n    upper_ratio_a = get_upper_ratio(data['response_a'])\n    upper_ratio_b = get_upper_ratio(data['response_b'])\n    num_digits_a = get_num_digits(data['response_a'])\n    num_digits_b = get_num_digits(data['response_b'])\n    punct_count_a = get_punct_count(data['response_a'])\n    punct_count_b = get_punct_count(data['response_b'])\n\n    data['diff_response_len'] = response_len_a - response_len_b\n    data['diff_word_count'] = word_count_a - word_count_b\n    data['diff_sentence'] = sentence_count_a - sentence_count_b\n    data['diff_avg_word_len'] = avg_word_len_a - avg_word_len_b\n    data['diff_upper_ratio'] = upper_ratio_a - upper_ratio_b\n    data['diff_num_digits'] = num_digits_a - num_digits_b\n    data['diff_punct_count'] = punct_count_a - punct_count_b\n    data['prompt_len'] = data['prompt'].map(len)\n\n    return data[['diff_response_len', 'diff_word_count', 'diff_sentence', 'diff_avg_word_len',\n                 'diff_upper_ratio','diff_num_digits','diff_punct_count','prompt_len']]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-06T09:33:34.910182Z","iopub.execute_input":"2025-11-06T09:33:34.910911Z","iopub.status.idle":"2025-11-06T09:33:34.920541Z","shell.execute_reply.started":"2025-11-06T09:33:34.910888Z","shell.execute_reply":"2025-11-06T09:33:34.919883Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def make_class_label(row):\n    if row['winner_tie'] == 1:\n        return 0      # tie\n    elif row['winner_model_a'] == 1:\n        return 1      # model A wins\n    elif row['winner_model_b'] == 1:\n        return 2      # model B wins\n\ntrain['y_class'] = train.apply(make_class_label, axis=1)\n\ny = train['y_class']\n\nX = extract_features(train)\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nfor col in X.columns:\n    sns.boxplot(x=y, y=X[col])\n    plt.title(col)\n    plt.show()\n\nX_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=42)\n\nmodel = LogisticRegression(\n    multi_class='multinomial',\n    solver='lbfgs',\n    C=2.0,\n    max_iter=1000\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-06T09:33:38.269889Z","iopub.execute_input":"2025-11-06T09:33:38.270518Z","iopub.status.idle":"2025-11-06T09:34:03.558094Z","shell.execute_reply.started":"2025-11-06T09:33:38.270494Z","shell.execute_reply":"2025-11-06T09:34:03.55749Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model.fit(X_train, y_train)\n\nprint(\"Validation Accuracy:\", model.score(X_valid, y_valid))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-06T09:36:14.806817Z","iopub.execute_input":"2025-11-06T09:36:14.807639Z","iopub.status.idle":"2025-11-06T09:36:22.321754Z","shell.execute_reply.started":"2025-11-06T09:36:14.807613Z","shell.execute_reply":"2025-11-06T09:36:22.319157Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X_test = extract_features(test)\nproba = model.predict_proba(X_test)\n\nsubmission = pd.DataFrame({'id': test['id'],\n                           'model_a': proba[:, 0],\n                           'model_b': proba[:, 1],\n                           'tie': proba[:, 2],})\n\nsubmission.to_csv('/kaggle/working/submission.csv', index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-06T09:36:24.993647Z","iopub.execute_input":"2025-11-06T09:36:24.994166Z","iopub.status.idle":"2025-11-06T09:36:25.007371Z","shell.execute_reply.started":"2025-11-06T09:36:24.994144Z","shell.execute_reply":"2025-11-06T09:36:25.006511Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### Step 2","metadata":{}},{"cell_type":"code","source":"device = 'cuda' if torch.cuda.is_available() else 'cpu'   #choosing gpu for quicker learning\nprint(f\"Using device: {device}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-06T09:36:28.296298Z","iopub.execute_input":"2025-11-06T09:36:28.296877Z","iopub.status.idle":"2025-11-06T09:36:28.301261Z","shell.execute_reply.started":"2025-11-06T09:36:28.296855Z","shell.execute_reply":"2025-11-06T09:36:28.300304Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sentence_transformers import SentenceTransformer\nfrom sklearn.metrics import log_loss, accuracy_score\n\nemb_model = SentenceTransformer('/kaggle/input/all-minilm-l6-v2/all-MiniLM-L6-v2', device=device) #lightweight model\n\n#for train data\nprompt = emb_model.encode(train['prompt'].tolist(), batch_size=64, convert_to_numpy=True)\nresp_a = emb_model.encode(train['response_a'].tolist(), batch_size=32, convert_to_numpy=True)\nresp_b = emb_model.encode(train['response_b'].tolist(), batch_size=32, convert_to_numpy=True)\n\ndiff_emb = resp_a - resp_b #better for comparsion of those respones\n\nabsdiff_emb = np.abs(resp_a - resp_b) #|absolute| diff to have a magnitude between resps\n\nX_features = np.hstack([prompt, diff_emb, absdiff_emb])  #prod_emb\n\ny_train = train['y_class']\nX_tr, X_val, y_tr, y_val = train_test_split(X_features, y_train, \n                                            test_size=0.2, random_state=42, stratify=y_train)\n\nscaler = StandardScaler()\nX_trsc = scaler.fit_transform(X_tr)\nX_valsc = scaler.transform(X_val)\n\n#choosing which is better\nclassifier = LogisticRegression(C=0.01, max_iter=2000, multi_class='multinomial',solver='lbfgs', random_state=42)\n\n#classifier = RandomForestClassifier(n_estimators=100, max_depth=20, random_state=42, n_jobs=-1)\n\nclassifier.fit(X_trsc, y_tr)\n\n#evaluation\ny_val_pred = classifier.predict_proba(X_valsc)\nval_lloss = log_loss(y_val, y_val_pred)\nemb_acc = accuracy_score(y_val, classifier.predict(X_valsc))\n\n\nprint(f\"Embedding Model Validation Accuracy: {emb_acc:.4f}\")\nprint(f\"Validation Log Loss: {val_lloss:.4f}\")\n\nprint(f\"   Improvement over baseline (1.0871): {1.0871 - val_lloss:.4f}\")\n\n#repeating everything for test data to submit\nprompt_test = emb_model.encode(test['prompt'].tolist(), batch_size=64, convert_to_numpy=True)\nresp_atest = emb_model.encode(test['response_a'].tolist(), batch_size=32, convert_to_numpy=True)\nresp_btest = emb_model.encode(test['response_b'].tolist(), batch_size=32, convert_to_numpy=True)\n\ndiff_test = resp_atest - resp_btest\nabsdiff_test = np.abs(resp_atest - resp_btest)\n\nX_test = np.hstack([prompt_test, diff_test, absdiff_test])\nX_testsc = scaler.transform(X_test)\n\n#submission\ntest_predp = classifier.predict_proba(X_testsc)\nsubmission = pd.DataFrame({'id': test['id'],\n                           'winner_model_a': test_predp[:, 1],\n                           'winner_model_b': test_predp[:, 2],\n                           'winner_tie': test_predp[:, 0]})\n\nsubmission.to_csv('/kaggle/working/submission.csv', index=False)\nprint('Embedding-based submission saved insted of step1')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-06T09:36:30.322352Z","iopub.execute_input":"2025-11-06T09:36:30.322618Z","iopub.status.idle":"2025-11-06T09:36:38.458603Z","shell.execute_reply.started":"2025-11-06T09:36:30.322601Z","shell.execute_reply":"2025-11-06T09:36:38.457638Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"step 3","metadata":{}},{"cell_type":"code","source":"from keras import mixed_precision","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-06T10:47:10.578358Z","iopub.execute_input":"2025-11-06T10:47:10.578944Z","iopub.status.idle":"2025-11-06T10:47:10.58275Z","shell.execute_reply.started":"2025-11-06T10:47:10.578922Z","shell.execute_reply":"2025-11-06T10:47:10.582078Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#data split\ny = train['y_class']\ntrain_df, val_df = train_test_split(train, test_size=0.2, random_state=42, stratify=y)\n\ndef fmt(row):\n    prompt = str(row['prompt'])[:200] if isinstance(row['prompt'], str) else str(row['prompt'])[1:200]\n    resp_a = str(row['response_a'])[:150]\n    resp_b = str(row['response_b'])[:150]\n    return f\"{prompt} [SEP] {resp_a} [SEP] {resp_b}\"\n\ntrain_texts = [fmt(row) for _, row in train_df.iterrows()]\nval_texts = [fmt(row) for _, row in val_df.iterrows()]\ntest_texts = [fmt(row) for _, row in test.iterrows()]\n\ny_tr = train_df['y_class'].values\ny_val = val_df['y_class'].values","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-06T10:55:19.07996Z","iopub.execute_input":"2025-11-06T10:55:19.080456Z","iopub.status.idle":"2025-11-06T10:55:21.552371Z","shell.execute_reply.started":"2025-11-06T10:55:19.080433Z","shell.execute_reply":"2025-11-06T10:55:21.551585Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"mixed_precision.set_global_policy('mixed_float16') \n\nMODEL_NAME = 'deberta_v3_extra_small_en' \nSEQ_LEN = 128     #shorter sequence to speed from 40 min est\nBATCH_SIZE = 16   #smaller batch sizes\nEPOCHS = 3    #early stopping","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-06T10:57:57.213327Z","iopub.execute_input":"2025-11-06T10:57:57.214035Z","iopub.status.idle":"2025-11-06T10:57:57.21769Z","shell.execute_reply.started":"2025-11-06T10:57:57.214012Z","shell.execute_reply":"2025-11-06T10:57:57.216821Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#loading model\ntry:\n    classifier = keras_hub.models.DebertaV3Classifier.from_preset(\n        MODEL_NAME,\n        num_classes=3,\n        sequence_length=SEQ_LEN,\n    )\n    print(\"Loaded DebertaV3Classifier directly\")\nexcept Exception as e:\n    print(f\"Could not load classifier directly: {e}\")\n    print(\"Building custom model...\")\n\n    preprocessor = keras_hub.models.DebertaV3Preprocessor.from_preset(MODEL_NAME, sequence_length=SEQ_LEN)\n    backbone = keras_hub.models.DebertaV3Backbone.from_preset(MODEL_NAME)\n\n    train_inputs = preprocessor(train_texts)\n    val_inputs = preprocessor(val_texts)\n    test_inputs = preprocessor(test_texts)\n\n    inputs = backbone.input  #tokens\n    x = backbone(inputs)\n    x = x[:, 0, :]  #embedding\n    x = keras.layers.Dropout(0.2)(x)\n    outputs = keras.layers.Dense(3, activation='softmax')(x)\n    classifier = keras.Model(inputs, outputs)\n\nprint(f\"Model parameters: {classifier.count_params():,}\")\n\n#freezing backbone for most epochs\nif hasattr(classifier, \"backbone\"):\n    for layer in classifier.backbone.layers[:-2]:  # keep top 2 blocks trainable\n        layer.trainable = False\nelse:\n    for layer in classifier.layers[:-2]:\n        layer.trainable = False\n\n# training\nclassifier.compile(optimizer=keras.optimizers.AdamW(learning_rate=3e-5),\n                   loss='sparse_categorical_crossentropy',\n                   metrics=['accuracy'])\n\n#callbacks\ncallbacks = [\n    keras.callbacks.EarlyStopping(monitor='val_loss', patience=1, restore_best_weights=True, verbose=1),\n    keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=1, min_lr=1e-7, verbose=1),\n]\n\nhist = classifier.fit(x=train_texts, y=y_tr, validation_data=(val_texts, y_val), batch_size=BATCH_SIZE,\n                      epochs=EPOCHS, callbacks=callbacks, verbose=1,)\n\nval_probs = classifier.predict(val_texts, batch_size=BATCH_SIZE, verbose=1)\nval_preds = np.argmax(val_probs, axis=1)\nval_acc = accuracy_score(y_val, val_preds)\nval_loss = log_loss(y_val, val_probs)\n\nprint(f\"\\nValidation Accuracy: {val_acc:.4f} | Log Loss: {val_loss:.4f}\")\nprint(classification_report(y_val, val_preds, target_names=['Tie', 'Model_A', 'Model_B']))\n\n#submission\ntest_probs = classifier.predict(test_texts, batch_size=BATCH_SIZE, verbose=1)\nsubmission = pd.DataFrame({\n    'id': test['id'],\n    'winner_model_a': test_probs[:, 1],\n    'winner_model_b': test_probs[:, 2],\n    'winner_tie': test_probs[:, 0]\n})\nsubmission.to_csv('/kaggle/working/submission.csv', index=False)\nprint('DeBERTa-based fine-tuning submission saved insted of step1')\n\nprint(f\"DeBERTa Fine-tuning after Acc: {val_acc:.3f}, LogLoss: {val_loss:.3f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-06T10:58:00.612913Z","iopub.execute_input":"2025-11-06T10:58:00.613608Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#loading model\ntry:\n    classifier = keras_hub.models.DebertaV3Classifier.from_preset(\n        'deberta_v3_extra_small_en', \n        num_classes=3,\n    )\n    print(\"Loaded DebertaV3Classifier directly\")\nexcept Exception as e:\n    print(f\"Could not load classifier directly: {e}\")\n    print(\"Building custom model...\")\n    \n    #custom model as planB\n    preprocessor = keras_hub.models.DebertaV3Preprocessor.from_preset(\n        'deberta_v3_extra_small_en',\n        sample_size = 5000,\n        sequence_length=256\n    )\n    backbone = keras_hub.models.DebertaV3Backbone.from_preset('deberta_v3_extra_small_en')\n    \n    #text processing\n    train_texts = [preprocessor(text) for text in train_texts]\n    val_texts = [preprocessor(text) for text in val_texts]\n    test_texts = [preprocessor(text) for text in test_texts]\n\n    #model itself\n    inputs = backbone.input\n    x = backbone(inputs)\n    x = keras.layers.GlobalAveragePooling1D()(x)\n    x = keras.layers.Dropout(0.1)(x)\n    outputs = keras.layers.Dense(3, activation='softmax')(x)\n    classifier = keras.Model(inputs, outputs)\n\nprint(f\"Model parameters: {classifier.count_params():,}\")\n\n#training\nclassifier.compile(\n    optimizer=keras.optimizers.AdamW(learning_rate=2e-5),\n    loss='sparse_categorical_crossentropy', \n    metrics=['accuracy']\n)\n\n#callback\ncallbacks = [keras.callbacks.EarlyStopping(monitor='val_loss', patience=1, \n                                           restore_best_weights=True, verbose=1),\n             keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=1, \n                                               min_lr=1e-7, verbose=1)]\n\n\nhist = classifier.fit(np.array(train_texts), y_tr, validation_data=(np.array(val_texts), y_val),\n                      batch_size=8, epochs=3, callbacks=callbacks, verbose=1)\n\n#evaluation\nval_probs = classifier.predict(np.array(val_texts), batch_size=8, verbose=1)\nval_preds = np.argmax(val_probs, axis=1)\nval_acc = accuracy_score(y_val, val_preds)\nval_loss = log_loss(y_val, val_probs)\n\nprint(f\"Validation Accuracy: {val_acc:.4f} | Log Loss: {val_loss:.4f}\")\nprint(classification_report(y_val, val_preds, target_names=['Tie', 'Model_A', 'Model_B']))\n\n#submission\ntest_probs = classifier.predict(np.array(test_texts), batch_size=8, verbose=1)\nsubmission = pd.DataFrame({\n    'id': test['id'],\n    'winner_model_a': test_probs[:, 1],\n    'winner_model_b': test_probs[:, 2],\n    'winner_tie': test_probs[:, 0]\n})\nsubmission.to_csv('/kaggle/working/submission.csv', index=False)\nprint('DeBERTa-based fine-tuning submission saved insted of step1')\n\nprint(f\"DeBERTa Fine-tuning after Acc: {val_acc:.3f}, LogLoss: {val_loss:.3f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-06T09:36:51.006705Z","iopub.execute_input":"2025-11-06T09:36:51.007759Z","iopub.status.idle":"2025-11-06T10:47:04.083185Z","shell.execute_reply.started":"2025-11-06T09:36:51.007725Z","shell.execute_reply":"2025-11-06T10:47:04.082144Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}