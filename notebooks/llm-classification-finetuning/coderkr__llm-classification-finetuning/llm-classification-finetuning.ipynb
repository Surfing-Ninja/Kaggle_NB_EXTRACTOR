{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":86518,"databundleVersionId":9809560,"sourceType":"competition"}],"dockerImageVersionId":31012,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-04-27T08:40:24.372828Z","iopub.execute_input":"2025-04-27T08:40:24.373105Z","iopub.status.idle":"2025-04-27T08:40:24.77947Z","shell.execute_reply.started":"2025-04-27T08:40:24.373082Z","shell.execute_reply":"2025-04-27T08:40:24.778305Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install --upgrade transformers\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-27T09:01:15.207754Z","iopub.execute_input":"2025-04-27T09:01:15.208289Z","iopub.status.idle":"2025-04-27T09:01:32.681244Z","shell.execute_reply.started":"2025-04-27T09:01:15.208254Z","shell.execute_reply":"2025-04-27T09:01:32.680283Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pip install --upgrade transformers\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-27T09:21:12.090608Z","iopub.execute_input":"2025-04-27T09:21:12.091314Z","iopub.status.idle":"2025-04-27T09:21:16.12683Z","shell.execute_reply.started":"2025-04-27T09:21:12.091286Z","shell.execute_reply":"2025-04-27T09:21:16.125632Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nfrom transformers import AutoTokenizer\nfrom datasets import Dataset\nimport pandas as pd\n\n# Verify GPU availability\nprint(f\"Is GPU available? {torch.cuda.is_available()}\")\n\n# Prepare dataset\ntrain = pd.read_csv('/kaggle/input/llm-classification-finetuning/train.csv')\ntest = pd.read_csv('/kaggle/input/llm-classification-finetuning/test.csv')\n\n# Label mapping\nlabel_map = {'winner_model_a': 0, 'winner_model_b': 1, 'winner_tie': 2}\ntrain['label'] = train[['winner_model_a', 'winner_model_b', 'winner_tie']].idxmax(axis=1).map(label_map)\ntrain = train[['prompt', 'response_a', 'response_b', 'label']]\ntest = test[['id', 'prompt', 'response_a', 'response_b']]\n\n# Load tokenizer\nmodel_checkpoint = \"distilbert-base-uncased\"\ntokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n\n# Tokenization function\ndef preprocess(example):\n    return tokenizer(\n        example['prompt'] + tokenizer.sep_token + example['response_a'] + tokenizer.sep_token + example['response_b'],\n        padding=\"max_length\",\n        truncation=True,\n        max_length=512,\n    )\n\n# Tokenize the datasets\ntrain_dataset = Dataset.from_pandas(train)\ntrain_dataset = train_dataset.map(preprocess, batched=False)\n\ntest_dataset = Dataset.from_pandas(test)\ntest_dataset = test_dataset.map(preprocess, batched=False)\n\n# Save tokenized datasets for later use\ntrain_dataset.save_to_disk(\"/kaggle/working/tokenized_train_dataset\")\ntest_dataset.save_to_disk(\"/kaggle/working/tokenized_test_dataset\")\n\nprint(\"Tokenization completed and datasets saved.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-27T09:31:27.582932Z","iopub.execute_input":"2025-04-27T09:31:27.583294Z","iopub.status.idle":"2025-04-27T09:34:59.507791Z","shell.execute_reply.started":"2025-04-27T09:31:27.583266Z","shell.execute_reply":"2025-04-27T09:34:59.506777Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# --- Imports\nimport torch\nfrom transformers import AutoModelForSequenceClassification, Trainer, TrainingArguments\nfrom datasets import load_from_disk\n\n# --- Check CPU/GPU\nprint(f\"Is GPU available? {torch.cuda.is_available()}\")  # Expected False (CPU)\n\n# --- Load tokenized dataset\ntrain_dataset = load_from_disk(\"/kaggle/working/tokenized_train_dataset\")\n\n# --- Fix labels if missing\nif \"label\" not in train_dataset.features:\n    import pandas as pd\n    train_df = pd.read_csv('/kaggle/input/llm-classification-finetuning/train.csv')\n    label_map = {'winner_model_a': 0, 'winner_model_b': 1, 'winner_tie': 2}\n    train_df['label'] = train_df[['winner_model_a', 'winner_model_b', 'winner_tie']].idxmax(axis=1).map(label_map)\n    train_dataset = train_dataset.remove_columns([\"prompt\", \"response_a\", \"response_b\"])\n    train_dataset = train_dataset.add_column(\"label\", train_df[\"label\"].tolist())\n\n# --- Set correct format\ntrain_dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\n\n# --- Load a lightweight model\nmodel_checkpoint = \"prajjwal1/bert-tiny\"\nmodel = AutoModelForSequenceClassification.from_pretrained(model_checkpoint, num_labels=3)\n\n# --- Training arguments\ntraining_args = TrainingArguments(\n    output_dir=\"/kaggle/working/results\",\n    overwrite_output_dir=True,\n    num_train_epochs=5,\n    per_device_train_batch_size=32,\n    learning_rate=2e-4,\n    logging_steps=10,\n    report_to=\"none\",\n    no_cuda=True,\n    disable_tqdm=False,\n)\n\n# --- Trainer\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_dataset,\n)\n\n# --- Start Training\nprint(\"üöÄ Starting Optimized Training...\")\ntrainer.train()\nprint(\"üèÅ Training Complete.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-27T10:32:31.868355Z","iopub.execute_input":"2025-04-27T10:32:31.868693Z","iopub.status.idle":"2025-04-27T13:02:34.256907Z","shell.execute_reply.started":"2025-04-27T10:32:31.868668Z","shell.execute_reply":"2025-04-27T13:02:34.255103Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nimport pandas as pd\nfrom datasets import load_from_disk\n\n# 1. Load your tokenized test set\ntest_dataset = load_from_disk(\"/kaggle/working/tokenized_test_dataset\")\ntest_dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\"])\n\n# 2. Run predictions\nprint(\"üöÄ Predicting on test set‚Ä¶\")\npreds = trainer.predict(test_dataset)\nlogits = preds.predictions                     # shape (n_samples, 3)\nprobs  = torch.softmax(torch.tensor(logits), -1).numpy()\n\n# 3. Build submission DataFrame\ntest_df = pd.read_csv('/kaggle/input/llm-classification-finetuning/test.csv')\nsubmission = pd.DataFrame({\n    \"id\":             test_df[\"id\"],\n    \"winner_model_a\": probs[:, 0],\n    \"winner_model_b\": probs[:, 1],\n    \"winner_tie\":     probs[:, 2],\n})\n\n# 4. Save CSV\nsubmission.to_csv(\"/kaggle/working/submission.csv\", index=False)\nprint(\"‚úÖ submission.csv saved at /kaggle/working/submission.csv\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-27T13:27:09.783451Z","iopub.execute_input":"2025-04-27T13:27:09.783992Z","iopub.status.idle":"2025-04-27T13:27:09.932178Z","shell.execute_reply.started":"2025-04-27T13:27:09.783944Z","shell.execute_reply":"2025-04-27T13:27:09.931259Z"}},"outputs":[],"execution_count":null}]}