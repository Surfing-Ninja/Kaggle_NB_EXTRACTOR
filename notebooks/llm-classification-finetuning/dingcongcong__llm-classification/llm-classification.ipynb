{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":86518,"databundleVersionId":9809560,"sourceType":"competition"}],"dockerImageVersionId":30918,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-04-14T15:06:06.151937Z","iopub.execute_input":"2025-04-14T15:06:06.152498Z","iopub.status.idle":"2025-04-14T15:06:06.162817Z","shell.execute_reply.started":"2025-04-14T15:06:06.152452Z","shell.execute_reply":"2025-04-14T15:06:06.161291Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_df = pd.read_csv(\"/kaggle/input/llm-classification-finetuning/train.csv\")\ntrain_df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-14T15:06:06.164328Z","iopub.execute_input":"2025-04-14T15:06:06.16475Z","iopub.status.idle":"2025-04-14T15:06:08.417611Z","shell.execute_reply.started":"2025-04-14T15:06:06.164714Z","shell.execute_reply":"2025-04-14T15:06:08.416235Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_df = pd.read_csv(\"/kaggle/input/llm-classification-finetuning/test.csv\")\ntest_df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-14T15:06:08.420197Z","iopub.execute_input":"2025-04-14T15:06:08.42058Z","iopub.status.idle":"2025-04-14T15:06:08.435742Z","shell.execute_reply.started":"2025-04-14T15:06:08.420552Z","shell.execute_reply":"2025-04-14T15:06:08.434654Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import unicodedata\nimport re\n# Precompile frequently used regex patterns for performance.\nNEWLINE_TAB_PATTERN = re.compile(r\"[\\r\\n\\t]+\")\nMULTIPLE_SPACES_PATTERN = re.compile(r\"\\s+\")\nALLOWED_CHARS_PATTERN = re.compile(r\"[^a-zA-Z0-9\\s.,!?()]+\")\nNON_ASCII_PATTERN = re.compile(r'[^\\x00-\\x7F]+')\n\ndef text_cleaning(text, remove_non_ascii=True):\n    \"\"\"\n    Clean and standardize a string for text processing.\n    \n    Parameters:\n        text (str): The input string to be cleaned.\n        remove_non_ascii (bool): Flag to determine whether non-ASCII characters should be removed. \n                                 Defaults to True.\n        \n    Returns:\n        str: The cleaned and normalized string.\n    \"\"\"\n    # Normalize unicode characters (NFKD) to decompose combined letters, e.g., converting \"Ã©\" to \"e\"\n    text = unicodedata.normalize(\"NFKD\", text)\n    \n    # Convert text to lowercase.\n    text = text.lower()\n    \n    # Replace newline and tab characters with a space.\n    text = NEWLINE_TAB_PATTERN.sub(\" \", text)\n    \n    # Replace specific escape sequences; here we transform \"\\/\" into \"/\" as needed.\n    text = text.replace(\"\\\\/\", \"/\")\n    \n    # Remove non-ASCII characters if flag is set. This is optional and can be disabled\n    if remove_non_ascii:\n        text = NON_ASCII_PATTERN.sub(\"\", text)\n    \n    # Remove unwanted punctuation and characters.\n    text = ALLOWED_CHARS_PATTERN.sub(\"\", text)\n    \n    # Replace multiple spaces with a single space.\n    text = MULTIPLE_SPACES_PATTERN.sub(\" \", text)\n    \n    # Remove any leading and trailing spaces.\n    return text.strip()\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-14T15:06:08.437301Z","iopub.execute_input":"2025-04-14T15:06:08.437609Z","iopub.status.idle":"2025-04-14T15:06:08.444005Z","shell.execute_reply.started":"2025-04-14T15:06:08.437562Z","shell.execute_reply":"2025-04-14T15:06:08.442848Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#text cleaning\ntrain_df['prompt'] = train_df['prompt'].apply(text_cleaning)\ntrain_df['response_a'] = train_df['response_a'].apply(text_cleaning)\ntrain_df['response_b'] = train_df['response_b'].apply(text_cleaning)\n\ntrain_df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-14T15:06:08.445098Z","iopub.execute_input":"2025-04-14T15:06:08.445454Z","iopub.status.idle":"2025-04-14T15:06:32.534628Z","shell.execute_reply.started":"2025-04-14T15:06:08.44542Z","shell.execute_reply":"2025-04-14T15:06:32.533224Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# test_df['prompt'] = test_df['prompt'].apply(text_cleaning)\ntest_df['response_a'] = test_df['response_a'].apply(text_cleaning)\ntest_df['response_b'] = test_df['response_b'].apply(text_cleaning)\ntest_df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-14T15:06:32.535785Z","iopub.execute_input":"2025-04-14T15:06:32.536147Z","iopub.status.idle":"2025-04-14T15:06:32.550475Z","shell.execute_reply.started":"2025-04-14T15:06:32.536116Z","shell.execute_reply":"2025-04-14T15:06:32.548519Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# train_df['response_a_len'] = train_df['response_a'].apply(lambda x: len(x))\n# train_df['response_b_len'] = train_df['response_b'].apply(lambda x: len(x))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-14T15:06:32.552193Z","iopub.execute_input":"2025-04-14T15:06:32.552637Z","iopub.status.idle":"2025-04-14T15:06:32.573161Z","shell.execute_reply.started":"2025-04-14T15:06:32.552571Z","shell.execute_reply":"2025-04-14T15:06:32.57212Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# test_df['response_a_len'] = test_df['response_a'].apply(lambda x: len(x))\n# test_df['response_b_len'] = test_df['response_b'].apply(lambda x: len(x))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-14T15:06:32.57681Z","iopub.execute_input":"2025-04-14T15:06:32.577128Z","iopub.status.idle":"2025-04-14T15:06:32.59183Z","shell.execute_reply.started":"2025-04-14T15:06:32.577103Z","shell.execute_reply":"2025-04-14T15:06:32.590752Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# train_df['response_a_un'] = train_df['response_a'].apply(lambda x: len(set(x.split(\" \"))))\n# train_df['response_b_un'] = train_df['response_b'].apply(lambda x: len(set(x.split(\" \"))))\n# train_df['prompt_un'] = train_df['prompt'].apply(lambda x: len(set(x.split(\" \"))))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-14T15:06:32.593957Z","iopub.execute_input":"2025-04-14T15:06:32.594362Z","iopub.status.idle":"2025-04-14T15:06:32.609531Z","shell.execute_reply.started":"2025-04-14T15:06:32.594323Z","shell.execute_reply":"2025-04-14T15:06:32.608326Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# test_df['response_a_un'] = test_df['response_a'].apply(lambda x: len(set(x.split(\" \"))))\n# test_df['response_b_un'] = test_df['response_b'].apply(lambda x: len(set(x.split(\" \"))))\n# test_df['prompt_un'] = test_df['prompt'].apply(lambda x: len(set(x.split(\" \"))))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-14T15:06:32.610465Z","iopub.execute_input":"2025-04-14T15:06:32.610795Z","iopub.status.idle":"2025-04-14T15:06:32.626859Z","shell.execute_reply.started":"2025-04-14T15:06:32.610768Z","shell.execute_reply":"2025-04-14T15:06:32.625804Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# def combine_p_r(row): \n#     return (\n#         f\"{row['prompt']}: {row['response_a']}\",\n#         f\"{row['prompt']}: {row['response_b']}\"\n#     )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-14T15:06:32.62782Z","iopub.execute_input":"2025-04-14T15:06:32.628114Z","iopub.status.idle":"2025-04-14T15:06:32.644468Z","shell.execute_reply.started":"2025-04-14T15:06:32.628091Z","shell.execute_reply":"2025-04-14T15:06:32.643441Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# train_df[['combined_a', 'combined_b']] = train_df.apply(combine_p_r, axis=1, result_type='expand')\n# train_df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-14T15:06:32.645617Z","iopub.execute_input":"2025-04-14T15:06:32.645981Z","iopub.status.idle":"2025-04-14T15:06:32.664571Z","shell.execute_reply.started":"2025-04-14T15:06:32.645944Z","shell.execute_reply":"2025-04-14T15:06:32.663494Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# test_df[['combined_a', 'combined_b']] = test_df.apply(combine_p_r, axis=1, result_type='expand')\n# test_df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-14T15:06:32.665636Z","iopub.execute_input":"2025-04-14T15:06:32.665995Z","iopub.status.idle":"2025-04-14T15:06:32.681777Z","shell.execute_reply.started":"2025-04-14T15:06:32.66596Z","shell.execute_reply":"2025-04-14T15:06:32.680676Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_df['winner'] = pd.from_dummies(train_df[['winner_model_a', 'winner_model_b', 'winner_tie']])\ntrain_df['winner'] = train_df['winner'].map({'winner_model_a':0, 'winner_model_b':1, 'winner_tie':2})\ntrain_df.drop(['winner_model_a', 'winner_model_b', 'winner_tie'], axis=1, inplace=True)\ntrain_df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-14T15:06:32.682778Z","iopub.execute_input":"2025-04-14T15:06:32.683105Z","iopub.status.idle":"2025-04-14T15:06:32.804753Z","shell.execute_reply.started":"2025-04-14T15:06:32.683069Z","shell.execute_reply":"2025-04-14T15:06:32.803683Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X = train_df[[\"prompt\", \"response_a\", \"response_b\"]]\ny = train_df[['winner']]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-14T15:06:32.805892Z","iopub.execute_input":"2025-04-14T15:06:32.806272Z","iopub.status.idle":"2025-04-14T15:06:32.822906Z","shell.execute_reply.started":"2025-04-14T15:06:32.806238Z","shell.execute_reply":"2025-04-14T15:06:32.82174Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# X = train_df[[\"prompt\", \"response_a\", \"response_b\", \"response_a_len\", \"response_b_len\", \"response_a_un\", \"response_b_un\", \n#               \"prompt_un\", \"combined_a\", \"combined_b\"]]\n# y = train_df[['winner']]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-14T15:06:32.824034Z","iopub.execute_input":"2025-04-14T15:06:32.824423Z","iopub.status.idle":"2025-04-14T15:06:32.840517Z","shell.execute_reply.started":"2025-04-14T15:06:32.824384Z","shell.execute_reply":"2025-04-14T15:06:32.839178Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.multioutput import MultiOutputClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.preprocessing import StandardScaler\nfrom xgboost import XGBClassifier\nfrom scipy.sparse import hstack, csr_matrix\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.metrics import log_loss\n\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-14T15:06:32.84165Z","iopub.execute_input":"2025-04-14T15:06:32.842037Z","iopub.status.idle":"2025-04-14T15:06:34.265363Z","shell.execute_reply.started":"2025-04-14T15:06:32.842001Z","shell.execute_reply":"2025-04-14T15:06:34.264322Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"numeric_features = [\n    'response_a_len', 'response_b_len', 'response_a_un', 'response_b_un', 'prompt_un'\n]\n\ntext_features = [\n    'prompt', 'response_a', 'response_b', 'combined_a', 'combined_b'\n]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-14T15:06:34.266427Z","iopub.execute_input":"2025-04-14T15:06:34.266935Z","iopub.status.idle":"2025-04-14T15:06:34.272057Z","shell.execute_reply.started":"2025-04-14T15:06:34.266904Z","shell.execute_reply":"2025-04-14T15:06:34.270694Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-14T15:06:34.273201Z","iopub.execute_input":"2025-04-14T15:06:34.27363Z","iopub.status.idle":"2025-04-14T15:06:34.313613Z","shell.execute_reply.started":"2025-04-14T15:06:34.273565Z","shell.execute_reply":"2025-04-14T15:06:34.312692Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"tfidf_prompt = TfidfVectorizer(max_features=1500, stop_words='english')\ntfidf_responses = TfidfVectorizer(max_features=1500, stop_words='english')\n\nprompt_tf = tfidf_prompt.fit_transform(X_train['prompt'])\nresponse_a_tf = tfidf_responses.fit_transform(X_train['response_a'])\nresponse_b_tf = tfidf_responses.fit_transform(X_train['response_b'])\n\nX_train_tf_combined = hstack([\n    prompt_tf, \n    response_a_tf, \n    response_b_tf, \n])\n\n\n\n\nprompt_tf_test = tfidf_prompt.transform(X_test['prompt'])\nresponse_a_tf_test = tfidf_responses.transform(X_test['response_a'])\nresponse_b_tf_test = tfidf_responses.transform(X_test['response_b'])\n\n\nX_test_tf_combined = hstack([\n    prompt_tf_test, \n    response_a_tf_test, \n    response_b_tf_test, \n\n])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-14T15:06:34.314568Z","iopub.execute_input":"2025-04-14T15:06:34.314964Z","iopub.status.idle":"2025-04-14T15:06:58.031715Z","shell.execute_reply.started":"2025-04-14T15:06:34.314926Z","shell.execute_reply":"2025-04-14T15:06:58.030763Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# -------------------------------\n# TF-IDF Vectorization for Text Features\n# -------------------------------\n# tfidf_prompt = TfidfVectorizer(max_features=1500, stop_words='english')\n# tfidf_responses = TfidfVectorizer(max_features=1500, stop_words='english')\n\n# # Fit and transform the training set for prompts and various response fields.\n# prompt_tf = tfidf_prompt.fit_transform(X_train['prompt'])\n# response_a_tf = tfidf_responses.fit_transform(X_train['response_a'])\n# response_b_tf = tfidf_responses.fit_transform(X_train['response_b'])\n# combined_a_tf = tfidf_responses.fit_transform(X_train['combined_a'])\n# combined_b_tf = tfidf_responses.fit_transform(X_train['combined_b'])\n\n# # -------------------------------\n# # Scaling Numeric Features\n# # -------------------------------\n# scaler = StandardScaler()\n# X_train_numeric = scaler.fit_transform(X_train[numeric_features])\n# X_test_numeric = scaler.transform(X_test[numeric_features])\n\n# # Convert numeric features to sparse format so they match the type of TF-IDF matrices.\n# X_train_numeric_sparse = csr_matrix(X_train_numeric)\n# X_test_numeric_sparse = csr_matrix(X_test_numeric)\n\n# # -------------------------------\n# # Combine TF-IDF and Numeric Features for Training Set\n# # -------------------------------\n# X_train_tf_combined = hstack([\n#     prompt_tf, \n#     response_a_tf, \n#     response_b_tf, \n#     combined_a_tf, \n#     combined_b_tf, \n#     X_train_numeric_sparse\n# ])\n\n# # -------------------------------\n# # Transform Test Set Using the Same Vectorizers and Scaler\n# # -------------------------------\n# prompt_tf_test = tfidf_prompt.transform(X_test['prompt'])\n# response_a_tf_test = tfidf_responses.transform(X_test['response_a'])\n# response_b_tf_test = tfidf_responses.transform(X_test['response_b'])\n# combined_a_tf_test = tfidf_responses.transform(X_test['combined_a'])\n# combined_b_tf_test = tfidf_responses.transform(X_test['combined_b'])\n\n# X_test_tf_combined = hstack([\n#     prompt_tf_test, \n#     response_a_tf_test, \n#     response_b_tf_test, \n#     combined_a_tf_test, \n#     combined_b_tf_test, \n#     X_test_numeric_sparse\n# ])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-14T15:06:58.032922Z","iopub.execute_input":"2025-04-14T15:06:58.033251Z","iopub.status.idle":"2025-04-14T15:06:58.038376Z","shell.execute_reply.started":"2025-04-14T15:06:58.033224Z","shell.execute_reply":"2025-04-14T15:06:58.037122Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from xgboost import XGBClassifier\nfrom lightgbm import LGBMClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier, VotingClassifier","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-14T15:06:58.039432Z","iopub.execute_input":"2025-04-14T15:06:58.039877Z","iopub.status.idle":"2025-04-14T15:07:01.229279Z","shell.execute_reply.started":"2025-04-14T15:06:58.039825Z","shell.execute_reply":"2025-04-14T15:07:01.228131Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"xgb_model = XGBClassifier(n_estimators=1000, subsample=0.8, min_child_weight=10, max_depth=3, learning_rate=0.01, gamma=0, colsample_bytree=0.8)\nxgb_model.fit(X_train_tf_combined, y_train)\ny_pred = xgb_model.predict(X_test_tf_combined)\n\nprint(f\"Accuracy: {accuracy_score(y_test, y_pred)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-14T15:07:01.233078Z","iopub.execute_input":"2025-04-14T15:07:01.233777Z","iopub.status.idle":"2025-04-14T15:14:44.983223Z","shell.execute_reply.started":"2025-04-14T15:07:01.233742Z","shell.execute_reply":"2025-04-14T15:14:44.981996Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"prompt_tf = tfidf_prompt.transform(test_df['prompt'])\nresponse_a_tf = tfidf_responses.transform(test_df['response_a'])\nresponse_b_tf = tfidf_responses.transform(test_df['response_b'])\n# combined_a_tf = tfidf_responses.transform(test_df['combined_a'])\n# combined_b_tf = tfidf_responses.transform(test_df['combined_b'])\n\n# Scaling numeric features\n#scaler = StandardScaler()\n#test_numeric = scaler.transform(test_df[numeric_features])\n\n# Combine TF-IDF and scaled numeric features\nX_test_tf = hstack([\n    prompt_tf, \n    response_a_tf, \n    response_b_tf, \n    #combined_a_tf, \n    #combined_b_tf, \n    #test_numeric\n])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-14T15:14:44.98429Z","iopub.execute_input":"2025-04-14T15:14:44.984628Z","iopub.status.idle":"2025-04-14T15:14:44.995487Z","shell.execute_reply.started":"2025-04-14T15:14:44.984574Z","shell.execute_reply":"2025-04-14T15:14:44.994423Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"prediction = xgb_model.predict_proba(X_test_tf)\ndf_sample = pd.DataFrame(data=prediction, columns=['winner_model_a', 'winner_model_b', 'winner_tie'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-14T15:14:44.99634Z","iopub.execute_input":"2025-04-14T15:14:44.996676Z","iopub.status.idle":"2025-04-14T15:14:45.013785Z","shell.execute_reply.started":"2025-04-14T15:14:44.996645Z","shell.execute_reply":"2025-04-14T15:14:45.012887Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"submission = pd.concat([test_df[['id']], df_sample], axis=1)\nsubmission.to_csv('submission.csv', index=False)\nsubmission","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-14T15:14:45.014418Z","iopub.execute_input":"2025-04-14T15:14:45.015183Z","iopub.status.idle":"2025-04-14T15:14:45.043978Z","shell.execute_reply.started":"2025-04-14T15:14:45.015144Z","shell.execute_reply":"2025-04-14T15:14:45.042889Z"}},"outputs":[],"execution_count":null}]}