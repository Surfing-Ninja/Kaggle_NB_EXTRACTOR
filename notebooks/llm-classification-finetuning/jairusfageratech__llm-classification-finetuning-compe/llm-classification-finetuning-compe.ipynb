{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":86518,"databundleVersionId":9809560,"isSourceIdPinned":false,"sourceType":"competition"}],"dockerImageVersionId":31153,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"Finetune LLMs to Predict Human Preference using Chatbot Arena conversations\nThis notebook contain a solution for the LLM Classification Finetuning on Kaggle\nMain objective: Predict which responses users will prefer in a head-to-head battle between chatbots powered by large language models(LLMs).\nData\ntrain.csv\n•\tid - A unique identifier for the row.\n•\tmodel_a/b - The identity of model_a/b. Included in train.csv but not test.csv.\n•\tprompt - The prompt that was given as an input (to both models).\n•\tresponse_a/b - The response from model_a/b to the given prompt.\n•\twinner_model_a/b/tie - Binary columns marking the judge's selection. The ground truth target column.\ntest.csv\n•\tid\n•\tprompt\n•\tresponse_a/b\nsample_submission.csv A submission file in the correct format.\n•\tid\n•\twinner_model_a/b/tie - This is what is predicted from the test set.\n","metadata":{}},{"cell_type":"code","source":"\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2025-11-05T10:44:14.347751Z","iopub.execute_input":"2025-11-05T10:44:14.348149Z","iopub.status.idle":"2025-11-05T10:44:14.357047Z","shell.execute_reply.started":"2025-11-05T10:44:14.348121Z","shell.execute_reply":"2025-11-05T10:44:14.355958Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Import the files \n\nimport numpy as np\nimport pandas as pd\nimport os\n\ntrain = pd.read_csv('/kaggle/input/c/llm-classification-finetuning/train.csv')\ntest = pd.read_csv('/kaggle/input/c/llm-classification-finetuning/test.csv')\nsample_submission = pd.read_csv ('/kaggle/input/c/llm-classification-finetuning/sample_submission.csv')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-05T10:45:53.589522Z","iopub.execute_input":"2025-11-05T10:45:53.589865Z","iopub.status.idle":"2025-11-05T10:45:57.708552Z","shell.execute_reply.started":"2025-11-05T10:45:53.589842Z","shell.execute_reply":"2025-11-05T10:45:57.707396Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Check the structure of the head\n\ntrain.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-05T10:46:28.531993Z","iopub.execute_input":"2025-11-05T10:46:28.53359Z","iopub.status.idle":"2025-11-05T10:46:28.575225Z","shell.execute_reply.started":"2025-11-05T10:46:28.533547Z","shell.execute_reply":"2025-11-05T10:46:28.574133Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Structure of the test  file\n\ntest.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-05T10:46:40.283046Z","iopub.execute_input":"2025-11-05T10:46:40.283722Z","iopub.status.idle":"2025-11-05T10:46:40.293216Z","shell.execute_reply.started":"2025-11-05T10:46:40.283693Z","shell.execute_reply":"2025-11-05T10:46:40.292251Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Any missing values in the structure","metadata":{}},{"cell_type":"code","source":"#Misiing valus\n\ntrain.isnull().sum()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-05T10:46:55.591381Z","iopub.execute_input":"2025-11-05T10:46:55.591708Z","iopub.status.idle":"2025-11-05T10:46:55.649282Z","shell.execute_reply.started":"2025-11-05T10:46:55.591682Z","shell.execute_reply":"2025-11-05T10:46:55.647164Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test.isnull().sum()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-05T10:47:03.306111Z","iopub.execute_input":"2025-11-05T10:47:03.306464Z","iopub.status.idle":"2025-11-05T10:47:03.315694Z","shell.execute_reply.started":"2025-11-05T10:47:03.306434Z","shell.execute_reply":"2025-11-05T10:47:03.314265Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Check the information of the data still under the data exploration\n\ntrain.info()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-05T10:47:10.546374Z","iopub.execute_input":"2025-11-05T10:47:10.546669Z","iopub.status.idle":"2025-11-05T10:47:10.605311Z","shell.execute_reply.started":"2025-11-05T10:47:10.546648Z","shell.execute_reply":"2025-11-05T10:47:10.604249Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Information of the test\ntest.info()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-05T10:47:36.488908Z","iopub.execute_input":"2025-11-05T10:47:36.489293Z","iopub.status.idle":"2025-11-05T10:47:36.500479Z","shell.execute_reply.started":"2025-11-05T10:47:36.489267Z","shell.execute_reply":"2025-11-05T10:47:36.499455Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**converting data (especially categorical or textual data)**","metadata":{}},{"cell_type":"code","source":"#Encoding\n\nfrom sklearn.preprocessing import LabelEncoder\n\n# Working on unique models to use in train and test\nall_models = list(set(train['model_a'].unique()) | set(train['model_b'].unique()))\n\n# Processing and Encoding\nmodel_encoder = LabelEncoder()\n# fit the encoder on all unique models\nmodel_encoder.fit(all_models)\n\n# Encode the names in the training dataset\ntrain['model_a_encoded'] = model_encoder.transform(train['model_a'])\ntrain['model_b_encoded'] = model_encoder.transform(train['model_b'])\n\nprint(f\"Encoded {len(all_models)} unique models from training data:\")\nfor i, model in enumerate(model_encoder.classes_):\n    print(f\"  {i}: {model}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-05T10:50:12.0118Z","iopub.execute_input":"2025-11-05T10:50:12.01222Z","iopub.status.idle":"2025-11-05T10:50:12.80801Z","shell.execute_reply.started":"2025-11-05T10:50:12.01217Z","shell.execute_reply":"2025-11-05T10:50:12.806886Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Test based numeric features in the dataframe**","metadata":{}},{"cell_type":"code","source":"#Create text-based numeric features\n\nimport string\n\ndef create_text_features(df):\n    \n    \n    # Text length features\n    df['prompt_length'] = df['prompt'].str.len()\n    df['response_a_length'] = df['response_a'].str.len()\n    df['response_b_length'] = df['response_b'].str.len()\n    \n    # Word count features\n    df['prompt_word_count'] = df['prompt'].str.split().str.len()\n    df['response_a_word_count'] = df['response_a'].str.split().str.len()\n    df['response_b_word_count'] = df['response_b'].str.split().str.len()\n    \n    # Character count features\n    \n    df['prompt_char_count'] = df['prompt'].str.replace(' ', '').str.len()\n    df['response_a_char_count'] = df['response_a'].str.replace(' ', '').str.len()\n    df['response_b_char_count'] = df['response_b'].str.replace(' ', '').str.len()\n    \n    # Average word length\n    df['prompt_avg_word_length'] = df['prompt_char_count'] / (df['prompt_word_count'] + 1e-8)\n    df['response_a_avg_word_length'] = df['response_a_char_count'] / (df['response_a_word_count'] + 1e-8)\n    df['response_b_avg_word_length'] = df['response_b_char_count'] / (df['response_b_word_count'] + 1e-8)\n    \n    # Response length ratio (response length / prompt length)\n    df['response_a_length_ratio'] = df['response_a_length'] / (df['prompt_length'] + 1e-8)\n    df['response_b_length_ratio'] = df['response_b_length'] / (df['prompt_length'] + 1e-8)\n    \n    # Difference in response lengths\n    df['response_length_diff'] = df['response_a_length'] - df['response_b_length']\n    df['response_word_count_diff'] = df['response_a_word_count'] - df['response_b_word_count']\n    \n    # Punctuation counts\n  \n    df['prompt_punctuation_count'] = df['prompt'].str.count(f'[{string.punctuation}]')\n    df['response_a_punctuation_count'] = df['response_a'].str.count(f'[{string.punctuation}]')\n    df['response_b_punctuation_count'] = df['response_b'].str.count(f'[{string.punctuation}]')\n    \n    # Question marks and exclamation marks\n    df['prompt_question_marks'] = df['prompt'].str.count('\\?')\n    df['response_a_question_marks'] = df['response_a'].str.count('\\?')\n    df['response_b_question_marks'] = df['response_b'].str.count('\\?')\n    \n    df['prompt_exclamation_marks'] = df['prompt'].str.count('!')\n    df['response_a_exclamation_marks'] = df['response_a'].str.count('!')\n    df['response_b_exclamation_marks'] = df['response_b'].str.count('!')\n    \n    # Uppercase ratio\n    df['prompt_uppercase_ratio'] = df['prompt'].str.count(r'[A-Z]') / (df['prompt_length'] + 1e-8)\n    df['response_a_uppercase_ratio'] = df['response_a'].str.count(r'[A-Z]') / (df['response_a_length'] + 1e-8)\n    df['response_b_uppercase_ratio'] = df['response_b'].str.count(r'[A-Z]') / (df['response_b_length'] + 1e-8)\n    \n    # Number count\n    df['prompt_number_count'] = df['prompt'].str.count(r'\\d')\n    df['response_a_number_count'] = df['response_a'].str.count(r'\\d')\n    df['response_b_number_count'] = df['response_b'].str.count(r'\\d')\n    \n    return df\n# Applying feature engineering to both datasets\nprint(\"Creating text-based features for training data...\")\ntrain = create_text_features(train)\n\nprint(\"Creating text-based features for test data...\")\ntest = create_text_features(test)\n\nprint(\"\\n\" + \"*\" * 60)\nprint(\" SUMMARY\")\nprint(\"*\" * 60)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-05T10:52:24.738794Z","iopub.execute_input":"2025-11-05T10:52:24.739163Z","iopub.status.idle":"2025-11-05T10:52:39.195652Z","shell.execute_reply.started":"2025-11-05T10:52:24.739141Z","shell.execute_reply":"2025-11-05T10:52:39.194355Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Converting one-hot to numeric labels in one line**","metadata":{}},{"cell_type":"code","source":"#separate binary column for each category.\n#Training target\ny = train[['winner_model_a', 'winner_model_b', 'winner_tie']].values.argmax(axis=1)\n\n# Now let Droping target columns and other unnecessary columns from training data\n\ndrop_cols = [\n    'id',                    \n    'model_a', 'model_b',    \n    'prompt', 'response_a', 'response_b', \n    'winner_model_a', 'winner_model_b', 'winner_tie'  \n]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-05T10:58:34.969374Z","iopub.execute_input":"2025-11-05T10:58:34.970628Z","iopub.status.idle":"2025-11-05T10:58:34.98025Z","shell.execute_reply.started":"2025-11-05T10:58:34.970584Z","shell.execute_reply":"2025-11-05T10:58:34.979026Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Creating feature  X by dropping unnecessary columns\nX = train.drop(columns=drop_cols)\n\nprint(f'Feature matrix shape:{X.shape}')\nprint(f'Target vector shape:{y.shape}')\nprint(f'Features:{list(X.columns)}')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-05T10:58:47.740466Z","iopub.execute_input":"2025-11-05T10:58:47.740783Z","iopub.status.idle":"2025-11-05T10:58:47.757329Z","shell.execute_reply.started":"2025-11-05T10:58:47.740755Z","shell.execute_reply":"2025-11-05T10:58:47.756199Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Starting building model**","metadata":{}},{"cell_type":"code","source":"#for model building\n\nfrom sklearn.model_selection import train_test_split, cross_val_score\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import classification_report, confusion_matrix, log_loss\n\n# Now Spliting  the data into training and validation sets\n\nX_train, X_val, y_train, y_val = train_test_split(\n    X, y, \n    test_size=0.2,           # taking 20% for validation as per the number of data\n    random_state=42,         # For reproducibility random seed \n    stratify=y               # Maintain class distribution\n)\n\nprint(f\"Training set shape: {X_train.shape}\")\nprint(f\"Validation set shape: {X_val.shape}\")\nprint(f\"Training target distribution: {np.bincount(y_train)}\")\nprint(f\"Validation target distribution: {np.bincount(y_val)}\")\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-05T11:02:52.64737Z","iopub.execute_input":"2025-11-05T11:02:52.648007Z","iopub.status.idle":"2025-11-05T11:02:53.157866Z","shell.execute_reply.started":"2025-11-05T11:02:52.647976Z","shell.execute_reply":"2025-11-05T11:02:53.156504Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\n#Scaling the features by use of important  logistic regression method.\n\nfrom sklearn.linear_model import LogisticRegression\n\nscaler = StandardScaler()\nX_train_done = scaler.fit_transform(X_train)\nX_val_done = scaler.transform(X_val)\n\n#Initialize the regression parameter\n\nmodel = LogisticRegression(\n    random_state=42,       \n    max_iter=1000,          \n    multi_class='ovr',       \n    solver='liblinear',      \n    C=1.0                    \n)\n\nprint(f\"Model parameters: {model.get_params()}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-05T11:08:17.732436Z","iopub.execute_input":"2025-11-05T11:08:17.733196Z","iopub.status.idle":"2025-11-05T11:08:17.78496Z","shell.execute_reply.started":"2025-11-05T11:08:17.733146Z","shell.execute_reply":"2025-11-05T11:08:17.784076Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Confirming if tye model has been trained \n\nprint(\"Training model wait...\")\nmodel.fit(X_train_done, y_train)\nprint(\"Training done!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-05T11:12:35.474268Z","iopub.execute_input":"2025-11-05T11:12:35.475003Z","iopub.status.idle":"2025-11-05T11:12:39.89956Z","shell.execute_reply.started":"2025-11-05T11:12:35.474972Z","shell.execute_reply":"2025-11-05T11:12:39.898546Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Now make predictions**","metadata":{}},{"cell_type":"code","source":"#Making predictions\n\ny_train_pred = model.predict(X_train_done)\ny_val_pred = model.predict(X_val_done)\n\n\n# Getting prediction probabilities for log loss\n\ny_train_proba = model.predict_proba(X_train_done)\ny_val_proba = model.predict_proba(X_val_done)\n\n# Calculating the log loss (the evaluation metric)\n\ntrain_log_loss = log_loss(y_train, y_train_proba)\nval_log_loss = log_loss(y_val, y_val_proba)\n\nprint(f\"Training Log Loss: {train_log_loss:.4f}\")\nprint(f\"Validation Log Loss: {val_log_loss:.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-05T11:12:49.26609Z","iopub.execute_input":"2025-11-05T11:12:49.267287Z","iopub.status.idle":"2025-11-05T11:12:49.321896Z","shell.execute_reply.started":"2025-11-05T11:12:49.26725Z","shell.execute_reply":"2025-11-05T11:12:49.320817Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Classification report\n\nprint(\"\\nValidation Classification Report:\")\nprint(classification_report(y_val, y_val_pred, \n                          target_names=['Model A Wins', 'Model B Wins', 'Tie']))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-05T11:13:12.593793Z","iopub.execute_input":"2025-11-05T11:13:12.595026Z","iopub.status.idle":"2025-11-05T11:13:12.625555Z","shell.execute_reply.started":"2025-11-05T11:13:12.594991Z","shell.execute_reply":"2025-11-05T11:13:12.624488Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Now test column**","metadata":{}},{"cell_type":"code","source":"\n#Now drop the test columns\n\ntest_cols_drops = ['id', 'prompt', 'response_a', 'response_b']\nX_test = test.drop(columns=test_cols_drops)\n\nprint(f\"Test feature matrix shape: {X_test.shape}\")\nprint(f\"Test features: {list(X_test.columns)}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-05T11:13:26.152498Z","iopub.execute_input":"2025-11-05T11:13:26.152836Z","iopub.status.idle":"2025-11-05T11:13:26.1648Z","shell.execute_reply.started":"2025-11-05T11:13:26.152811Z","shell.execute_reply":"2025-11-05T11:13:26.163117Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# What are  missing in the test data?\n\ntrain_features = set(X.columns)\ntest_features = set(X_test.columns)\nmissing_features = train_features - test_features\nextra_features = test_features - train_features\n\nprint(f\"\\nMissing features in test data: {missing_features}\")\nprint(f\"Extra features in test data: {extra_features}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-05T11:13:36.198029Z","iopub.execute_input":"2025-11-05T11:13:36.198548Z","iopub.status.idle":"2025-11-05T11:13:36.205684Z","shell.execute_reply.started":"2025-11-05T11:13:36.198497Z","shell.execute_reply":"2025-11-05T11:13:36.204413Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Missing values by adding missing features to test data with default values (0 for encoded features)\n\nfor feature in missing_features:\n    if 'encoded' in feature:\n        X_test[feature] = 0\n    else:\n        X_test[feature] = 0\n\nX_test = X_test[X.columns]\n\nprint(f\"\\nTest data after manupulating missing features:\")\nprint(f\"Features same as training: {list(X_test.columns) == list(X.columns)}\")\nprint(f\"Shape: {X_test.shape}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-05T11:13:46.896528Z","iopub.execute_input":"2025-11-05T11:13:46.896887Z","iopub.status.idle":"2025-11-05T11:13:46.907449Z","shell.execute_reply.started":"2025-11-05T11:13:46.896864Z","shell.execute_reply":"2025-11-05T11:13:46.906352Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Scale test data using the same scaler\n\nX_test_done = scaler.transform(X_test)\n\n# Make predictions on test set\ntest_predictions = model.predict_proba(X_test_done)\n\nprint(f\"\\nTest predictions shape: {test_predictions.shape}\")\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-05T11:14:06.809441Z","iopub.execute_input":"2025-11-05T11:14:06.809964Z","iopub.status.idle":"2025-11-05T11:14:06.827647Z","shell.execute_reply.started":"2025-11-05T11:14:06.809937Z","shell.execute_reply":"2025-11-05T11:14:06.826621Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Create submission DataFrame\nsubmission = pd.DataFrame({\n    'id': test['id'],\n    'winner_model_a': test_predictions[:, 0],  # Probability for class 0\n    'winner_model_b': test_predictions[:, 1],  # Probability for class 1\n    'winner_tie': test_predictions[:, 2]       # Probability for class 2\n})\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-05T11:14:16.010843Z","iopub.execute_input":"2025-11-05T11:14:16.011574Z","iopub.status.idle":"2025-11-05T11:14:16.018488Z","shell.execute_reply.started":"2025-11-05T11:14:16.011541Z","shell.execute_reply":"2025-11-05T11:14:16.017299Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Display \n\nprint(\"\\nSubmission file:\")\nprint(submission.head())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-05T11:14:25.721984Z","iopub.execute_input":"2025-11-05T11:14:25.722356Z","iopub.status.idle":"2025-11-05T11:14:25.730886Z","shell.execute_reply.started":"2025-11-05T11:14:25.722331Z","shell.execute_reply":"2025-11-05T11:14:25.729254Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Performing cross-validation in the model\nCross_Val_S = cross_val_score(model, X_train_done, y_train, \n                           cv=5, scoring='neg_log_loss')\nCross_Val_log_loss = -Cross_Val_S.mean()\n\nprint(f\"Cross-validation Log Loss: {Cross_Val_log_loss:.4f} (+/- {Cross_Val_S.std() * 2:.4f})\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-05T11:14:36.865583Z","iopub.execute_input":"2025-11-05T11:14:36.865918Z","iopub.status.idle":"2025-11-05T11:14:54.774892Z","shell.execute_reply.started":"2025-11-05T11:14:36.865894Z","shell.execute_reply":"2025-11-05T11:14:54.773818Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Then Make predictions on the test set\n\ntest_predictions = model.predict_proba(X_test_done)\n\nprint(\"Ready for submission perfect!\")\nprint(f\"Test predictions shape: {test_predictions.shape}\")\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-05T11:23:30.269829Z","iopub.execute_input":"2025-11-05T11:23:30.270229Z","iopub.status.idle":"2025-11-05T11:23:30.276547Z","shell.execute_reply.started":"2025-11-05T11:23:30.270195Z","shell.execute_reply":"2025-11-05T11:23:30.275248Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Saved submission file\nsubmission.to_csv('submission.csv', index=False)\nprint(f\"\\nSubmission file saved as 'submission.csv'\")\nprint(f\"File contains {len(submission)} predictions\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-05T11:23:39.330213Z","iopub.execute_input":"2025-11-05T11:23:39.330541Z","iopub.status.idle":"2025-11-05T11:23:39.344063Z","shell.execute_reply.started":"2025-11-05T11:23:39.330516Z","shell.execute_reply":"2025-11-05T11:23:39.342735Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Verify if  the format matches the required format in the compe\n\nprint(submission.head(3).to_string(index=False))\nprint('Perfect prediction and sbmission matche !')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-05T11:23:50.391472Z","iopub.execute_input":"2025-11-05T11:23:50.392437Z","iopub.status.idle":"2025-11-05T11:23:50.400475Z","shell.execute_reply.started":"2025-11-05T11:23:50.392406Z","shell.execute_reply":"2025-11-05T11:23:50.399508Z"}},"outputs":[],"execution_count":null}]}