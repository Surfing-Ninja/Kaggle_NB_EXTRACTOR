{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":86518,"databundleVersionId":9809560,"sourceType":"competition"},{"sourceId":6063,"sourceType":"modelInstanceVersion","modelInstanceId":4684,"modelId":2820}],"dockerImageVersionId":31012,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-05-09T18:31:22.033423Z","iopub.execute_input":"2025-05-09T18:31:22.033869Z","iopub.status.idle":"2025-05-09T18:31:24.199904Z","shell.execute_reply.started":"2025-05-09T18:31:22.033835Z","shell.execute_reply":"2025-05-09T18:31:24.198934Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nprint(os.listdir(\"/kaggle/input\"))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-09T18:31:24.201588Z","iopub.execute_input":"2025-05-09T18:31:24.202122Z","iopub.status.idle":"2025-05-09T18:31:24.207471Z","shell.execute_reply.started":"2025-05-09T18:31:24.202092Z","shell.execute_reply":"2025-05-09T18:31:24.206446Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Set the base path for the dataset\nBASE_PATH = '/kaggle/input/llm-classification-finetuning'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-09T18:39:00.928276Z","iopub.execute_input":"2025-05-09T18:39:00.928941Z","iopub.status.idle":"2025-05-09T18:39:00.932847Z","shell.execute_reply.started":"2025-05-09T18:39:00.928914Z","shell.execute_reply":"2025-05-09T18:39:00.932147Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Load the training data from a CSV file\ndf = pd.read_csv(f'{BASE_PATH}/train.csv') ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-09T18:39:02.932997Z","iopub.execute_input":"2025-05-09T18:39:02.933298Z","iopub.status.idle":"2025-05-09T18:39:06.807752Z","shell.execute_reply.started":"2025-05-09T18:39:02.933275Z","shell.execute_reply":"2025-05-09T18:39:06.806854Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Import necessary libraries\nimport keras\nimport keras_hub\nimport numpy as np","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-09T18:39:07.528139Z","iopub.execute_input":"2025-05-09T18:39:07.528474Z","iopub.status.idle":"2025-05-09T18:39:27.124957Z","shell.execute_reply.started":"2025-05-09T18:39:07.528449Z","shell.execute_reply":"2025-05-09T18:39:27.123887Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Set the Keras backend to JAX\nimport os\nos.environ[\"KERAS_BACKEND\"] = \"jax\"  \n# Import additional libraries\nimport keras_nlp\nimport keras\nimport tensorflow as tf\n\nimport numpy as np \nimport pandas as pd\nfrom tqdm import tqdm\nimport json\n\nimport matplotlib.pyplot as plt\nimport matplotlib as mpl\nimport plotly.express as px","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-09T18:39:27.126238Z","iopub.execute_input":"2025-05-09T18:39:27.126867Z","iopub.status.idle":"2025-05-09T18:39:28.206264Z","shell.execute_reply.started":"2025-05-09T18:39:27.126838Z","shell.execute_reply":"2025-05-09T18:39:28.20534Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Print the versions of the libraries being used\nprint(\"TensorFlow:\", tf.__version__)\nprint(\"Keras:\", keras.__version__)\nprint(\"KerasNLP:\", keras_nlp.__version__)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-09T18:39:31.253186Z","iopub.execute_input":"2025-05-09T18:39:31.25358Z","iopub.status.idle":"2025-05-09T18:39:31.259632Z","shell.execute_reply.started":"2025-05-09T18:39:31.253551Z","shell.execute_reply":"2025-05-09T18:39:31.258605Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Configuration class to hold hyperparameters and settings\nclass CFG:\n    seed = 42  # Random seed\n    preset = \"deberta_v3_extra_small_en\" # Name of pretrained models\n    sequence_length = 512  # Input sequence length\n    epochs = 3 # Training epochs\n    batch_size = 16  # Batch size\n    scheduler = 'cosine'  # Learning rate scheduler\n    label2name = {0: 'winner_model_a', 1: 'winner_model_b', 2: 'winner_tie'}   # Mapping of labels to class names\n    name2label = {v:k for k, v in label2name.items()}   # Reverse mapping for labels\n    class_labels = list(label2name.keys())   # List of class labels\n    class_names = list(label2name.values())   # List of class names","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-09T18:39:33.968267Z","iopub.execute_input":"2025-05-09T18:39:33.968633Z","iopub.status.idle":"2025-05-09T18:39:33.974764Z","shell.execute_reply.started":"2025-05-09T18:39:33.968607Z","shell.execute_reply":"2025-05-09T18:39:33.973424Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Set random seed for Keras\nkeras.utils.set_random_seed(CFG.seed)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-09T18:39:37.588072Z","iopub.execute_input":"2025-05-09T18:39:37.588443Z","iopub.status.idle":"2025-05-09T18:39:37.593509Z","shell.execute_reply.started":"2025-05-09T18:39:37.588408Z","shell.execute_reply":"2025-05-09T18:39:37.592479Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Set mixed precision policy for training\nkeras.mixed_precision.set_global_policy(\"mixed_float16\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-09T18:39:39.628033Z","iopub.execute_input":"2025-05-09T18:39:39.628337Z","iopub.status.idle":"2025-05-09T18:39:39.633037Z","shell.execute_reply.started":"2025-05-09T18:39:39.628315Z","shell.execute_reply":"2025-05-09T18:39:39.632111Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Load the training data again (redundant, can be removed)\nBASE_PATH = '/kaggle/input/llm-classification-finetuning'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-09T18:39:42.828261Z","iopub.execute_input":"2025-05-09T18:39:42.829146Z","iopub.status.idle":"2025-05-09T18:39:42.833354Z","shell.execute_reply.started":"2025-05-09T18:39:42.829115Z","shell.execute_reply":"2025-05-09T18:39:42.832194Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df = pd.read_csv(f'{BASE_PATH}/train.csv') \n# Process the prompt and responses to extract the first element from the evaluated string\n\ndf[\"prompt\"] = df.prompt.map(lambda x: eval(x)[0])\ndf[\"response_a\"] = df.response_a.map(lambda x: eval(x.replace(\"null\",\"''\"))[0])\ndf[\"response_b\"] = df.response_b.map(lambda x: eval(x.replace(\"null\", \"''\"))[0])\n\n# Determine the class name and label based on the maximum winner count\n\ndf[\"class_name\"] = df[[\"winner_model_a\", \"winner_model_b\" , \"winner_tie\"]].idxmax(axis=1)\ndf[\"class_label\"] = df.class_name.map(CFG.name2label)\n\n# Display the first few rows of the processed DataFrame\ndf.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-09T18:39:44.568305Z","iopub.execute_input":"2025-05-09T18:39:44.568715Z","iopub.status.idle":"2025-05-09T18:39:51.169147Z","shell.execute_reply.started":"2025-05-09T18:39:44.568689Z","shell.execute_reply":"2025-05-09T18:39:51.168111Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Load the test data\ntest_df = pd.read_csv(f'{BASE_PATH}/test.csv')\n# Process the test data similarly to the training data\ntest_df[\"prompt\"] = test_df.prompt.map(lambda x: eval(x)[0])\ntest_df[\"response_a\"] = test_df.response_a.map(lambda x: eval(x.replace(\"null\",\"''\"))[0])\ntest_df[\"response_b\"] = test_df.response_b.map(lambda x: eval(x.replace(\"null\", \"''\"))[0])\n\n# Display the first few rows of the test DataFrame\ntest_df.head()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-09T18:39:55.32825Z","iopub.execute_input":"2025-05-09T18:39:55.32864Z","iopub.status.idle":"2025-05-09T18:39:55.347023Z","shell.execute_reply.started":"2025-05-09T18:39:55.328615Z","shell.execute_reply":"2025-05-09T18:39:55.346171Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Function to create pairs of prompts and responses\ndef make_pairs(row):\n    row[\"encode_fail\"] = False\n    try:\n        prompt = row.prompt.encode(\"utf-8\").decode(\"utf-8\")\n    except:\n        prompt = \"\"\n        row[\"encode_fail\"] = True\n\n    try:\n        response_a = row.response_a.encode(\"utf-8\").decode(\"utf-8\")\n    except:\n        response_a = \"\"\n        row[\"encode_fail\"] = True\n\n    try:\n        response_b = row.response_b.encode(\"utf-8\").decode(\"utf-8\")\n    except:\n        response_b = \"\"\n        row[\"encode_fail\"] = True\n        \n    row['options'] = [f\"Prompt: {prompt}\\n\\nResponse: {response_a}\",  # Response from Model A\n                      f\"Prompt: {prompt}\\n\\nResponse: {response_b}\"  # Response from Model B\n                     ]\n    return row","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-09T18:39:58.570152Z","iopub.execute_input":"2025-05-09T18:39:58.570512Z","iopub.status.idle":"2025-05-09T18:39:58.577231Z","shell.execute_reply.started":"2025-05-09T18:39:58.570485Z","shell.execute_reply":"2025-05-09T18:39:58.57624Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df = df.apply(make_pairs, axis=1)  # Generate paired comparisons for training data\ndisplay(df.head(2)) \ntest_df = test_df.apply(make_pairs, axis=1)  # Generate paired comparisons for test data\ndisplay(test_df.head(2))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-09T18:40:02.648049Z","iopub.execute_input":"2025-05-09T18:40:02.648394Z","iopub.status.idle":"2025-05-09T18:40:58.560608Z","shell.execute_reply.started":"2025-05-09T18:40:02.64835Z","shell.execute_reply":"2025-05-09T18:40:58.559728Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Check distribution of encoding failures\ndf.encode_fail.value_counts(normalize=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-09T18:40:58.562135Z","iopub.execute_input":"2025-05-09T18:40:58.562756Z","iopub.status.idle":"2025-05-09T18:40:58.577145Z","shell.execute_reply.started":"2025-05-09T18:40:58.562729Z","shell.execute_reply":"2025-05-09T18:40:58.576267Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Combine models into a single series\nmodel_df = pd.concat([df.model_a, df.model_b])\n# Count occurrences of each LLM\ncounts = model_df.value_counts().reset_index()\ncounts.columns = ['LLM', 'Count']\n# Plot distribution of LLMs\nfig = px.bar(counts, x='LLM', y='Count',\n             title='Distribution of LLMs',\n             color='Count', color_continuous_scale='viridis')\n\nfig.update_layout(xaxis_tickangle=-45)  \nfig.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-09T18:41:07.448235Z","iopub.execute_input":"2025-05-09T18:41:07.448714Z","iopub.status.idle":"2025-05-09T18:41:07.515297Z","shell.execute_reply.started":"2025-05-09T18:41:07.448677Z","shell.execute_reply":"2025-05-09T18:41:07.514436Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":" # Count win occurrences\ncounts = df['class_name'].value_counts().reset_index()\ncounts.columns = ['Winner', 'Win Count']\n# Plot winner distribution\nfig = px.bar(counts, x='Winner', y='Win Count',\n             title='Winner distribution for Train Data',\n             labels={'Winner': 'Winner', 'Win Count': 'Win Count'},\n             color='Winner', color_continuous_scale='viridis')\n\nfig.update_layout(xaxis_title=\"Winner\", yaxis_title=\"Win Count\")\n\nfig.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-09T18:41:11.808085Z","iopub.execute_input":"2025-05-09T18:41:11.808415Z","iopub.status.idle":"2025-05-09T18:41:11.891478Z","shell.execute_reply.started":"2025-05-09T18:41:11.808359Z","shell.execute_reply":"2025-05-09T18:41:11.89053Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split  # Import package\n# Stratified split to maintain label distribution\ntrain_df, valid_df = train_test_split(df, test_size=0.2, stratify=df[\"class_label\"])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-09T18:41:16.073639Z","iopub.execute_input":"2025-05-09T18:41:16.074019Z","iopub.status.idle":"2025-05-09T18:41:17.050256Z","shell.execute_reply.started":"2025-05-09T18:41:16.073995Z","shell.execute_reply":"2025-05-09T18:41:17.049194Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"preprocessor = keras_nlp.models.DebertaV3Preprocessor.from_preset(\n    preset=CFG.preset,\n    sequence_length=CFG.sequence_length,)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-09T18:41:19.408003Z","iopub.execute_input":"2025-05-09T18:41:19.408683Z","iopub.status.idle":"2025-05-09T18:41:22.648006Z","shell.execute_reply.started":"2025-05-09T18:41:19.408655Z","shell.execute_reply":"2025-05-09T18:41:22.64671Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"outs = preprocessor(df.options.iloc[0])  # Process options for the first row\n\n# Display the shape of each processed output for debugging\nfor k, v in outs.items():\n    print(k, \":\", v.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-09T18:41:26.467954Z","iopub.execute_input":"2025-05-09T18:41:26.468932Z","iopub.status.idle":"2025-05-09T18:41:26.602682Z","shell.execute_reply.started":"2025-05-09T18:41:26.46889Z","shell.execute_reply":"2025-05-09T18:41:26.601691Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def preprocess_fn(text, label=None):\n    text = preprocessor(text)  # Tokenize and Preprocess text\n    return (text, label) if label is not None else text","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-09T18:41:29.288316Z","iopub.execute_input":"2025-05-09T18:41:29.288855Z","iopub.status.idle":"2025-05-09T18:41:29.294082Z","shell.execute_reply.started":"2025-05-09T18:41:29.288813Z","shell.execute_reply":"2025-05-09T18:41:29.293143Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Optimize data loading\ndef build_dataset(texts, labels=None, batch_size=32,\n                  cache=True, shuffle=1024):\n    AUTO = tf.data.AUTOTUNE  # AUTOTUNE option\n    slices = (texts,) if labels is None else (texts, keras.utils.to_categorical(labels, num_classes=3))  # Create slices\n    ds = tf.data.Dataset.from_tensor_slices(slices)  # Create dataset from slices\n    ds = ds.cache() if cache else ds  # Cache dataset if enabled\n    ds = ds.map(preprocess_fn, num_parallel_calls=AUTO)  # Map preprocessing function\n    opt = tf.data.Options()  # Create dataset options\n    if shuffle: \n        ds = ds.shuffle(shuffle, seed=CFG.seed)  # Shuffle dataset if enabled\n        opt.experimental_deterministic = False\n    ds = ds.with_options(opt)  # Set dataset options\n    ds = ds.batch(batch_size, drop_remainder=False)  # Batch dataset\n    ds = ds.prefetch(AUTO)  # Prefetch next batch\n    return ds ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-09T18:41:33.708097Z","iopub.execute_input":"2025-05-09T18:41:33.708527Z","iopub.status.idle":"2025-05-09T18:41:33.715831Z","shell.execute_reply.started":"2025-05-09T18:41:33.7085Z","shell.execute_reply":"2025-05-09T18:41:33.71488Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Prepare datasets\ntrain_texts = train_df.options.tolist()  # Extract training texts\ntrain_labels = train_df.class_label.tolist()  # Extract training labels\ntrain_ds = build_dataset(train_texts, train_labels,\n                         batch_size=CFG.batch_size,\n                         shuffle=True)\nvalid_texts = valid_df.options.tolist()  # Extract validation texts\nvalid_labels = valid_df.class_label.tolist()  # Extract validation labels\nvalid_ds = build_dataset(valid_texts, valid_labels,\n                         batch_size=CFG.batch_size,\n                         shuffle=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-09T18:41:43.048139Z","iopub.execute_input":"2025-05-09T18:41:43.048993Z","iopub.status.idle":"2025-05-09T18:41:47.782778Z","shell.execute_reply.started":"2025-05-09T18:41:43.048963Z","shell.execute_reply":"2025-05-09T18:41:47.781668Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import math\n\ndef get_lr_callback(batch_size=8, mode='cos', epochs=10, plot=False):\n    lr_start, lr_max, lr_min = 1.0e-6, 0.6e-6 * batch_size, 1e-6 # Learning rate boundaries\n    lr_ramp_ep, lr_sus_ep, lr_decay = 2, 0, 0.8\n # Initial ramp-up phase\n    def lrfn(epoch):  \n        if epoch < lr_ramp_ep: lr = (lr_max - lr_start) / lr_ramp_ep * epoch + lr_start\n        elif epoch < lr_ramp_ep + lr_sus_ep: lr = lr_max\n        elif mode == 'exp': lr = (lr_max - lr_min) * lr_decay**(epoch - lr_ramp_ep - lr_sus_ep) + lr_min\n        elif mode == 'step': lr = lr_max * lr_decay**((epoch - lr_ramp_ep - lr_sus_ep) // 2)\n        elif mode == 'cos':\n            decay_total_epochs, decay_epoch_index = epochs - lr_ramp_ep - lr_sus_ep + 3, epoch - lr_ramp_ep - lr_sus_ep\n            phase = math.pi * decay_epoch_index / decay_total_epochs\n            lr = (lr_max - lr_min) * 0.5 * (1 + math.cos(phase)) + lr_min\n        return lr\n\n    if plot:  # Plot lr curve if plot is True\n        plt.figure(figsize=(10, 5))\n        plt.plot(np.arange(epochs), [lrfn(epoch) for epoch in np.arange(epochs)], marker='o')\n        plt.xlabel('epoch'); plt.ylabel('lr')\n        plt.title('LR Scheduler')\n        plt.show()\n\n    return keras.callbacks.LearningRateScheduler(lrfn, verbose=False)  ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-09T18:41:50.76828Z","iopub.execute_input":"2025-05-09T18:41:50.768658Z","iopub.status.idle":"2025-05-09T18:41:50.777469Z","shell.execute_reply.started":"2025-05-09T18:41:50.768632Z","shell.execute_reply":"2025-05-09T18:41:50.776393Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"lr_cb = get_lr_callback(CFG.batch_size, plot=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-09T18:41:59.528129Z","iopub.execute_input":"2025-05-09T18:41:59.528493Z","iopub.status.idle":"2025-05-09T18:41:59.79217Z","shell.execute_reply.started":"2025-05-09T18:41:59.528468Z","shell.execute_reply":"2025-05-09T18:41:59.791107Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"ckpt_cb = keras.callbacks.ModelCheckpoint(f'best_model.weights.h5',\n                                          monitor='val_log_loss',\n                                          save_best_only=True,\n                                          save_weights_only=True,\n                                          mode='min')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-09T18:42:03.958296Z","iopub.execute_input":"2025-05-09T18:42:03.959416Z","iopub.status.idle":"2025-05-09T18:42:03.964227Z","shell.execute_reply.started":"2025-05-09T18:42:03.959347Z","shell.execute_reply":"2025-05-09T18:42:03.963189Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"log_loss = keras.metrics.CategoricalCrossentropy(name=\"log_loss\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-09T18:42:06.808362Z","iopub.execute_input":"2025-05-09T18:42:06.808862Z","iopub.status.idle":"2025-05-09T18:42:06.825795Z","shell.execute_reply.started":"2025-05-09T18:42:06.808833Z","shell.execute_reply":"2025-05-09T18:42:06.824663Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"inputs = {\n    \"token_ids\": keras.Input(shape=(2, None), dtype=tf.int32, name=\"token_ids\"),\n    \"padding_mask\": keras.Input(shape=(2, None), dtype=tf.int32, name=\"padding_mask\"),\n}\nbackbone = keras_nlp.models.DebertaV3Backbone.from_preset(\n    CFG.preset,\n)\n\n\nresponse_a = {k: v[:, 0, :] for k, v in inputs.items()}\nembed_a = backbone(response_a)\n\n\nresponse_b = {k: v[:, 1, :] for k, v in inputs.items()}\nembed_b = backbone(response_b)\n\n\nembeds = keras.layers.Concatenate(axis=-1)([embed_a, embed_b])\nembeds = keras.layers.GlobalAveragePooling1D()(embeds)\noutputs = keras.layers.Dense(3, activation=\"softmax\", name=\"classifier\")(embeds)\nmodel = keras.Model(inputs, outputs)\n\n\nmodel.compile(\n    optimizer=keras.optimizers.Adam(5e-6),\n    loss=keras.losses.CategoricalCrossentropy(label_smoothing=0.02),\n    metrics=[\n        log_loss,\n        keras.metrics.CategoricalAccuracy(name=\"accuracy\"),\n    ],\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-09T18:42:10.928009Z","iopub.execute_input":"2025-05-09T18:42:10.929183Z","iopub.status.idle":"2025-05-09T18:42:17.6075Z","shell.execute_reply.started":"2025-05-09T18:42:10.929147Z","shell.execute_reply":"2025-05-09T18:42:17.606575Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model.summary()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-09T18:42:31.028114Z","iopub.execute_input":"2025-05-09T18:42:31.028478Z","iopub.status.idle":"2025-05-09T18:42:31.069405Z","shell.execute_reply.started":"2025-05-09T18:42:31.028452Z","shell.execute_reply":"2025-05-09T18:42:31.068538Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_texts = test_df.options.tolist()\ntest_ds = build_dataset(test_texts,\n                         batch_size=min(len(test_df), CFG.batch_size),\n                         shuffle=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-09T18:42:36.908006Z","iopub.execute_input":"2025-05-09T18:42:36.908326Z","iopub.status.idle":"2025-05-09T18:42:37.702735Z","shell.execute_reply.started":"2025-05-09T18:42:36.908291Z","shell.execute_reply":"2025-05-09T18:42:37.701606Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_preds = model.predict(test_ds, verbose=1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-09T18:42:39.987936Z","iopub.execute_input":"2025-05-09T18:42:39.988235Z","iopub.status.idle":"2025-05-09T18:42:59.234345Z","shell.execute_reply.started":"2025-05-09T18:42:39.988213Z","shell.execute_reply":"2025-05-09T18:42:59.233538Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"sub_df = test_df[[\"id\"]].copy()\nsub_df[CFG.class_names] = test_preds.tolist()\nsub_df.to_csv(\"submission.csv\", index=False)\nsub_df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-09T18:43:45.507928Z","iopub.execute_input":"2025-05-09T18:43:45.508249Z","iopub.status.idle":"2025-05-09T18:43:45.530889Z","shell.execute_reply.started":"2025-05-09T18:43:45.508223Z","shell.execute_reply":"2025-05-09T18:43:45.529952Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}