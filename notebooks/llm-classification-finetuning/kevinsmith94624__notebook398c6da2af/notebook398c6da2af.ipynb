{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":86518,"databundleVersionId":9809560,"sourceType":"competition"}],"dockerImageVersionId":30805,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport json\nimport os\nfrom tqdm.notebook import tqdm\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow.keras.layers import TextVectorization, Embedding, Conv1D, GlobalMaxPooling1D, Dense, Dropout, Input\nfrom tensorflow.keras.models import Sequential\nfrom sklearn.model_selection import train_test_split","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-12-08T12:14:11.265731Z","iopub.execute_input":"2024-12-08T12:14:11.266152Z","iopub.status.idle":"2024-12-08T12:14:23.825487Z","shell.execute_reply.started":"2024-12-08T12:14:11.266122Z","shell.execute_reply":"2024-12-08T12:14:23.824787Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class CFG:\n    seeds = [42, 119, 2020, 2024, 2028]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T12:14:23.826889Z","iopub.execute_input":"2024-12-08T12:14:23.827372Z","iopub.status.idle":"2024-12-08T12:14:23.832144Z","shell.execute_reply.started":"2024-12-08T12:14:23.827326Z","shell.execute_reply":"2024-12-08T12:14:23.830999Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_df = pd.read_csv(\"/kaggle/input/llm-classification-finetuning/train.csv\")\ntrain_df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T12:14:23.833666Z","iopub.execute_input":"2024-12-08T12:14:23.83405Z","iopub.status.idle":"2024-12-08T12:14:27.171447Z","shell.execute_reply.started":"2024-12-08T12:14:23.834009Z","shell.execute_reply":"2024-12-08T12:14:27.170516Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"prompt_list = []\ntargets = []\nfor i in tqdm(range(len(train_df))):\n    prompts = json.loads(train_df.iloc[i][\"prompt\"])\n    response_a = json.loads(train_df.iloc[i][\"response_a\"])\n    response_b = json.loads(train_df.iloc[i][\"response_b\"])\n    conversation_a = \"\"\n    conversation_b = \"\"\n    for j in range(len(prompts)):\n        if response_a[j] is None:\n            response_a[j] = \"None\"\n        if response_b[j] is None:\n            response_b[j] = \"None\"\n        conversation_a += prompts[j] + \"\\n\"\n        conversation_a += response_a[j] + \"\\n\"\n        conversation_b += prompts[j] + \"\\n\"\n        conversation_b += response_b[j] + \"\\n\"\n    prompt_list.append((conversation_a, conversation_b))\n    if train_df.iloc[i][\"winner_tie\"] == 1:\n        targets.append(0)\n    if train_df.iloc[i][\"winner_model_a\"] == 1:\n        targets.append(1)\n    if train_df.iloc[i][\"winner_model_b\"] == 1:\n        targets.append(2)\nlen(prompt_list)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T12:14:27.173724Z","iopub.execute_input":"2024-12-08T12:14:27.174012Z","iopub.status.idle":"2024-12-08T12:14:43.745351Z","shell.execute_reply.started":"2024-12-08T12:14:27.173986Z","shell.execute_reply":"2024-12-08T12:14:43.74454Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Step 2: Define TextVectorization layer\nvocab_size = 20000  # Vocabulary size (tune this as needed)\nmax_length = 1024    # Maximum sequence length (tune this as needed)\ntext_vectorizer = TextVectorization(max_tokens=vocab_size, output_mode='int', output_sequence_length=max_length)\ntext_vectorizer.adapt([item[0] for item in prompt_list] + [item[1] for item in prompt_list]) ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T12:14:43.746546Z","iopub.execute_input":"2024-12-08T12:14:43.746816Z","iopub.status.idle":"2024-12-08T12:14:56.640344Z","shell.execute_reply.started":"2024-12-08T12:14:43.746791Z","shell.execute_reply":"2024-12-08T12:14:56.639595Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def get_dataset(prompt_list, targets, shuffle=True, batch_size=128):\n    part1 = [item[0] for item in prompt_list]\n    part2 = [item[1] for item in prompt_list]\n    dataset = tf.data.Dataset.from_tensor_slices(((part1, part2), targets))\n    if shuffle:\n        dataset = dataset.shuffle(buffer_size=2048)\n    dataset = dataset.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n    return dataset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T12:14:56.648951Z","iopub.execute_input":"2024-12-08T12:14:56.649233Z","iopub.status.idle":"2024-12-08T12:14:56.66058Z","shell.execute_reply.started":"2024-12-08T12:14:56.649208Z","shell.execute_reply":"2024-12-08T12:14:56.659717Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def get_base_model(inputs, embedding):\n    x = text_vectorizer(inputs)\n    x = embedding(x)\n    return x\ndef get_model():\n    inputs1 = tf.keras.Input(shape=(1,), dtype=tf.string)\n    inputs2 = tf.keras.Input(shape=(1,), dtype=tf.string)\n    embedding = tf.keras.layers.Embedding(input_dim=vocab_size, output_dim=64, mask_zero=True)\n    x1 = get_base_model(inputs1, embedding)\n    x2 = get_base_model(inputs2, embedding)\n    x = tf.keras.layers.Concatenate()([x1, x2])\n    x = tf.keras.layers.Conv1D(32, 3, activation=\"relu\")(x)\n    x = tf.keras.layers.Conv1D(32, 3, activation=\"relu\")(x)\n    x = tf.keras.layers.SpatialDropout1D(0.2)(x)\n    x = tf.keras.layers.MaxPooling1D()(x)\n    x = tf.keras.layers.Conv1D(64, 3, activation=\"relu\")(x)\n    x = tf.keras.layers.Conv1D(64, 3, activation=\"relu\")(x)\n    x = tf.keras.layers.SpatialDropout1D(0.2)(x)\n    x = tf.keras.layers.MaxPooling1D()(x)\n    x = tf.keras.layers.GlobalAveragePooling1D()(x)\n    x = tf.keras.layers.Dropout(0.3)(x)\n    x = tf.keras.layers.Dense(128, activation=\"swish\")(x)\n    outputs = tf.keras.layers.Dense(3, activation=\"softmax\")(x)\n    model = tf.keras.Model(inputs=[inputs1, inputs2], outputs=outputs)\n    \n    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n    return model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T12:14:56.661544Z","iopub.execute_input":"2024-12-08T12:14:56.661849Z","iopub.status.idle":"2024-12-08T12:14:56.693601Z","shell.execute_reply.started":"2024-12-08T12:14:56.661814Z","shell.execute_reply":"2024-12-08T12:14:56.693025Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"models = []\nfor seed in CFG.seeds:\n    model_name = f\"model_{seed}.keras\"\n    # Step 1: Split texts and labels into train and test sets\n    train_texts, valid_texts, train_labels, valid_labels = train_test_split(\n        prompt_list, targets, test_size=0.2, random_state=seed\n    )\n    valid_ds = get_dataset(valid_texts, valid_labels, shuffle=False)\n    model_name_path = f\"/kaggle/input/llm-classification-finetuning-with-cnn-model/{model_name}\"\n    if not os.path.exists(model_name_path):\n        train_ds = get_dataset(train_texts, train_labels)\n        model = get_model()\n        checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n            filepath=model_name,  # Filepath to save the best model\n            monitor='val_loss',        # Metric to monitor\n            mode=\"min\",\n            save_best_only=True,       # Save only the best model\n            verbose=1\n        )\n        early_stopping_callback = tf.keras.callbacks.EarlyStopping(\n            monitor='val_loss',        # Metric to monitor\n            patience=5,                # Number of epochs with no improvement to wait before stopping\n            verbose=1,\n            restore_best_weights=True  # Restore weights from the best epoch\n        )\n        model.fit(train_ds, epochs=30, validation_data=valid_ds, callbacks=[checkpoint_callback, early_stopping_callback])\n        model.load_weights(model_name)\n    else:\n        model = tf.keras.models.load_model(model_name_path)\n        model.save(model_name)\n    loss, acc = model.evaluate(valid_ds, verbose=0)\n    print(f\"Validation Loss: {loss: .4f} Validation Accuracy: {acc * 100: .4f}%\")\n    models.append(model)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T12:14:56.694442Z","iopub.execute_input":"2024-12-08T12:14:56.694662Z","iopub.status.idle":"2024-12-08T12:24:08.684997Z","shell.execute_reply.started":"2024-12-08T12:14:56.69464Z","shell.execute_reply":"2024-12-08T12:24:08.684052Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_df = pd.read_csv(\"/kaggle/input/llm-classification-finetuning/test.csv\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T12:24:08.686406Z","iopub.execute_input":"2024-12-08T12:24:08.68727Z","iopub.status.idle":"2024-12-08T12:24:08.698325Z","shell.execute_reply.started":"2024-12-08T12:24:08.687225Z","shell.execute_reply":"2024-12-08T12:24:08.697233Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_prompt_list = []\nfor i in tqdm(range(len(test_df))):\n    prompts = json.loads(test_df.iloc[i][\"prompt\"])\n    response_a = json.loads(test_df.iloc[i][\"response_a\"])\n    response_b = json.loads(test_df.iloc[i][\"response_b\"])\n    conversation_a = \"\"\n    conversation_b = \"\"\n    for j in range(len(prompts)):\n        if response_a[j] is None:\n            response_a[j] = \"None\"\n        if response_b[j] is None:\n            response_b[j] = \"None\"\n        conversation_a += prompts[j] + \"\\n\"\n        conversation_a += response_a[j] + \"\\n\"\n        conversation_b += prompts[j] + \"\\n\"\n        conversation_b += response_b[j] + \"\\n\"\n    test_prompt_list.append((conversation_a, conversation_b))\nlen(test_prompt_list)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T12:24:08.701954Z","iopub.execute_input":"2024-12-08T12:24:08.702599Z","iopub.status.idle":"2024-12-08T12:24:08.72494Z","shell.execute_reply.started":"2024-12-08T12:24:08.70257Z","shell.execute_reply":"2024-12-08T12:24:08.724069Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def get_test_dataset(prompt_list, batch_size=128):\n    part1 = [item[0] for item in prompt_list]\n    part2 = [item[1] for item in prompt_list]\n    dataset = tf.data.Dataset.from_tensor_slices(((part1, part2), [0] * len(prompt_list)))\n    dataset = dataset.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n    return dataset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T12:24:08.725955Z","iopub.execute_input":"2024-12-08T12:24:08.726271Z","iopub.status.idle":"2024-12-08T12:24:08.743401Z","shell.execute_reply.started":"2024-12-08T12:24:08.726244Z","shell.execute_reply":"2024-12-08T12:24:08.742543Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_ds = get_test_dataset(test_prompt_list)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T12:24:08.744365Z","iopub.execute_input":"2024-12-08T12:24:08.744637Z","iopub.status.idle":"2024-12-08T12:24:08.760822Z","shell.execute_reply.started":"2024-12-08T12:24:08.744612Z","shell.execute_reply":"2024-12-08T12:24:08.760004Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"result = np.mean([model.predict(test_ds, verbose=0) for model in models], axis=0)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T12:24:08.761857Z","iopub.execute_input":"2024-12-08T12:24:08.762451Z","iopub.status.idle":"2024-12-08T12:24:10.1454Z","shell.execute_reply.started":"2024-12-08T12:24:08.762413Z","shell.execute_reply":"2024-12-08T12:24:10.144483Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"submission = pd.read_csv(\"/kaggle/input/llm-classification-finetuning/sample_submission.csv\")\nsubmission[\"winner_tie\"] = result[:, 0]\nsubmission[\"winner_model_a\"] = result[:, 1]\nsubmission[\"winner_model_b\"] = result[:, 2]\nsubmission.to_csv(\"submission.csv\", index=False)\nsubmission.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T12:24:10.146589Z","iopub.execute_input":"2024-12-08T12:24:10.146948Z","iopub.status.idle":"2024-12-08T12:24:10.166514Z","shell.execute_reply.started":"2024-12-08T12:24:10.146912Z","shell.execute_reply":"2024-12-08T12:24:10.165537Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}