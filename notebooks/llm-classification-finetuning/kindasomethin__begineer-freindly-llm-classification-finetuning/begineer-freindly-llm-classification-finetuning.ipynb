{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":86518,"databundleVersionId":9809560,"isSourceIdPinned":false,"sourceType":"competition"},{"sourceId":11813172,"sourceType":"datasetVersion","datasetId":7419671},{"sourceId":11813182,"sourceType":"datasetVersion","datasetId":7419681}],"dockerImageVersionId":31040,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"# DO UPVOTE GUYS (THIS WAS MY FIRST CODE TBH)!","metadata":{}},{"cell_type":"code","source":"# import the data\nimport pandas as pd\n\ntraining = pd.read_csv('/kaggle/input/llm-classification-finetuning/train.csv')\ntest = pd.read_csv('/kaggle/input/llm-classification-finetuning/test.csv')\n\ntraining['train_test'] = 1\ntest['train_test'] = 0\nall_data = pd.concat([training,test])\n\nprint(\"Import Data Complete\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-14T18:14:49.175066Z","iopub.execute_input":"2025-05-14T18:14:49.176223Z","iopub.status.idle":"2025-05-14T18:14:51.133825Z","shell.execute_reply.started":"2025-05-14T18:14:49.176186Z","shell.execute_reply":"2025-05-14T18:14:51.132794Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"training.head(10)\ntraining.tail(10)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-14T18:11:37.247513Z","iopub.execute_input":"2025-05-14T18:11:37.24779Z","iopub.status.idle":"2025-05-14T18:11:37.258661Z","shell.execute_reply.started":"2025-05-14T18:11:37.24777Z","shell.execute_reply":"2025-05-14T18:11:37.257943Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer\nimport numpy as np\n\n# Separate vectorizers for each field\nvectorizer_prompt = TfidfVectorizer(max_features=150)\nvectorizer_response_a = TfidfVectorizer(max_features=150)\nvectorizer_response_b = TfidfVectorizer(max_features=150)\n\n# Fit on training data\ntemp_prompt = vectorizer_prompt.fit_transform(training[\"prompt\"])\ntemp_response_a = vectorizer_response_a.fit_transform(training[\"response_a\"])\ntemp_response_b = vectorizer_response_b.fit_transform(training[\"response_b\"])\n\nprint(\"TF-IDF Features for Prompt:\", vectorizer_prompt.get_feature_names_out())\nprint(\"TF-IDF Features for Response A:\", vectorizer_response_a.get_feature_names_out())\nprint(\"TF-IDF Features for Response B:\", vectorizer_response_b.get_feature_names_out())\n\nprint(\"Number of elements for the vectorizer representation for 'prompt':\", temp_prompt.shape)\nprint(\"Number of elements for the vectorizer representation for 'response a':\", temp_response_a.shape)\nprint(\"Number of elements for the vectorizer representation for 'response b':\", temp_response_b.shape)\n\n#selecting the prediction target\ndef get_winner(row):\n    if row['winner_model_a'] == 1:\n        return 0  # response_a wins\n    elif row['winner_model_b'] == 1:\n        return 1  # response_b wins\n    elif row['winner_tie'] == 1:\n        return 2  # tie\n    else:\n        return -1  # unknown or missing\n\ntraining['winner'] = training.apply(get_winner, axis=1)\ntrain_y = training[\"winner\"].values\n\n#choosing \"features\"\ntrain_X = np.concatenate((temp_prompt.toarray(), temp_response_a.toarray(), temp_response_b.toarray()), axis=1)\n\nprint(\"Selecting The Prediction Target and Choosing Features Complete\")\n#use Logistic Regression\nfrom sklearn.linear_model import LogisticRegression\nfrom datetime import datetime\n\n#record start time to calculate the execution time\nstart = datetime.now()\n\n#Logistic Regression\nmodel = LogisticRegression(max_iter=500, multi_class='multinomial', solver='saga') #For large datasets the “saga” solver is usually faster [scikit-learn documentation]\nmodel.fit(train_X, train_y)\n\n#record end time\nend = datetime.now()\n \n#calculate the execution time\nexecution_time = (end - start).total_seconds() / 60\nprint(f\"The time of execution is: {execution_time} minutes\")\n\n\nprint(\"Model Training Complete\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-14T18:11:37.260868Z","iopub.execute_input":"2025-05-14T18:11:37.26118Z","iopub.status.idle":"2025-05-14T18:12:14.92651Z","shell.execute_reply.started":"2025-05-14T18:11:37.261162Z","shell.execute_reply":"2025-05-14T18:12:14.925784Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix, precision_score, recall_score\n\n#split into validation and training data\ntrain_X_train, train_X_val, train_y_train, train_y_val = train_test_split(train_X, train_y, test_size=0.2, random_state=42)\n\n#record start time to calculate the execution time\nstart = datetime.now()\n\n#think about results - comparing predictions (value_y_predict) to the actual winner model (train_y_val)\nvalue_y_predict = model.predict(train_X_val)\nprint('Model winner prediction', value_y_predict)\nprint('Model winner real value', train_y_val)\n\nvalue_y_probabilities = model.predict_proba(train_X_val)\nprint('Model winner prediction, probability', value_y_probabilities) #winner model a | winner model b | winner tie\n\n#confusion matrix\ncm = confusion_matrix(train_y_val, value_y_predict)\nprint(\"Confusion Matrix:\\n\", cm)\n\n#model accuracy\nscore = model.score(train_X_val, train_y_val)\nprint('Model Accuracy Score', score)\n\n#macro and micro averaged Precision and Recall\nmacro_precision = precision_score(train_y_val, value_y_predict, average='macro') #calculate precision for all classes individually and then average them\nmacro_recall = recall_score(train_y_val, value_y_predict, average='macro')\nmicro_precision = precision_score(train_y_val, value_y_predict, average='micro') #calculate class wise true positive and false positive and then use that to calculate overall precision\nmicro_recall = recall_score(train_y_val, value_y_predict, average='micro')\nprint(\"Macro Precision:\", macro_precision)\nprint(\"Macro Recall:\", macro_recall)\nprint(\"Micro Precision:\", micro_precision)\nprint(\"Micro Recall:\", micro_recall)\n\n#record end time\nend = datetime.now()\n \n#calculate the execution time\nexecution_time = (end - start).total_seconds()\nprint(f\"The time of execution is: {execution_time} seconds\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-14T18:12:14.927298Z","iopub.execute_input":"2025-05-14T18:12:14.927524Z","iopub.status.idle":"2025-05-14T18:12:15.066799Z","shell.execute_reply.started":"2025-05-14T18:12:14.927504Z","shell.execute_reply":"2025-05-14T18:12:15.066119Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#model log loss - https://www.kaggle.com/competitions/llm-classification-finetuning/discussion/552103\nfrom sklearn.metrics import log_loss\n\nmodel_log_loss = log_loss(train_y_val, value_y_probabilities)\n\nprint('Model Log loss:', model_log_loss) \n\n# Number of classes = 3 : Logloss = - log(1/3) = 1.10\n# Model Log loss: 1.05, model prediction is considered good for this project","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-14T18:12:15.067584Z","iopub.execute_input":"2025-05-14T18:12:15.067817Z","iopub.status.idle":"2025-05-14T18:12:15.076522Z","shell.execute_reply.started":"2025-05-14T18:12:15.067791Z","shell.execute_reply":"2025-05-14T18:12:15.075866Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#model prediction\n# transform test data using the trained vectorizers\ntemp_test_prompt = vectorizer_prompt.transform(test[\"prompt\"])\ntemp_test_response_a = vectorizer_response_a.transform(test[\"response_a\"])\ntemp_test_response_b = vectorizer_response_b.transform(test[\"response_b\"])\n\ntest_X = np.concatenate((temp_test_prompt.toarray(), temp_test_response_a.toarray(), temp_test_response_b.toarray()), axis=1)\nvalue_test_y_probabilities = model.predict_proba(test_X)\nprint('Model winner prediction, probability', value_test_y_probabilities) #winner model a | winner model b | winner tie","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-14T18:12:15.077532Z","iopub.execute_input":"2025-05-14T18:12:15.07788Z","iopub.status.idle":"2025-05-14T18:12:15.09713Z","shell.execute_reply.started":"2025-05-14T18:12:15.077846Z","shell.execute_reply":"2025-05-14T18:12:15.096391Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"output = pd.DataFrame({'id': test.id,\n                        'winner_model_a': value_test_y_probabilities[:, 0],\n                        'winner_model_b': value_test_y_probabilities[:, 1],\n                        'winner_tie': value_test_y_probabilities[:, 2]})\noutput.to_csv('submission.csv', index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-14T18:12:15.098005Z","iopub.execute_input":"2025-05-14T18:12:15.098274Z","iopub.status.idle":"2025-05-14T18:12:15.111523Z","shell.execute_reply.started":"2025-05-14T18:12:15.098248Z","shell.execute_reply":"2025-05-14T18:12:15.110847Z"}},"outputs":[],"execution_count":null}]}