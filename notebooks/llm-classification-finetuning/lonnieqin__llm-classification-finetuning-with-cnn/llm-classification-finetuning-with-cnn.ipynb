{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":86518,"databundleVersionId":9809560,"sourceType":"competition"},{"sourceId":9857403,"sourceType":"datasetVersion","datasetId":6021077}],"dockerImageVersionId":30786,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# LLM Classification Finetuning with CNN","metadata":{}},{"cell_type":"markdown","source":"## Import Libraries","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport json\nimport os\nfrom tqdm.notebook import tqdm\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow.keras.layers import TextVectorization, Embedding, Conv1D, GlobalMaxPooling1D, Dense, Dropout, Input\nfrom tensorflow.keras.models import Sequential\nfrom sklearn.model_selection import train_test_split","metadata":{"execution":{"iopub.status.busy":"2024-11-06T15:38:04.069318Z","iopub.execute_input":"2024-11-06T15:38:04.069999Z","iopub.status.idle":"2024-11-06T15:38:04.075652Z","shell.execute_reply.started":"2024-11-06T15:38:04.069958Z","shell.execute_reply":"2024-11-06T15:38:04.074755Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Configuration","metadata":{}},{"cell_type":"code","source":"class CFG:\n    seeds = [42, 119, 2020, 2024, 2028]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-06T15:45:20.619413Z","iopub.execute_input":"2024-11-06T15:45:20.620413Z","iopub.status.idle":"2024-11-06T15:45:20.624751Z","shell.execute_reply.started":"2024-11-06T15:45:20.62037Z","shell.execute_reply":"2024-11-06T15:45:20.623775Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Create Training dataset","metadata":{}},{"cell_type":"code","source":"train_df = pd.read_csv(\"/kaggle/input/llm-classification-finetuning/train.csv\")\ntrain_df.head()","metadata":{"execution":{"iopub.status.busy":"2024-11-06T15:38:24.488862Z","iopub.execute_input":"2024-11-06T15:38:24.489252Z","iopub.status.idle":"2024-11-06T15:38:27.768481Z","shell.execute_reply.started":"2024-11-06T15:38:24.489217Z","shell.execute_reply":"2024-11-06T15:38:27.767584Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"prompt_list = []\ntargets = []\nfor i in tqdm(range(len(train_df))):\n    prompts = json.loads(train_df.iloc[i][\"prompt\"])\n    response_a = json.loads(train_df.iloc[i][\"response_a\"])\n    response_b = json.loads(train_df.iloc[i][\"response_b\"])\n    conversation_a = \"\"\n    conversation_b = \"\"\n    for j in range(len(prompts)):\n        if response_a[j] is None:\n            response_a[j] = \"None\"\n        if response_b[j] is None:\n            response_b[j] = \"None\"\n        conversation_a += prompts[j] + \"\\n\"\n        conversation_a += response_a[j] + \"\\n\"\n        conversation_b += prompts[j] + \"\\n\"\n        conversation_b += response_b[j] + \"\\n\"\n    prompt_list.append((conversation_a, conversation_b))\n    if train_df.iloc[i][\"winner_tie\"] == 1:\n        targets.append(0)\n    if train_df.iloc[i][\"winner_model_a\"] == 1:\n        targets.append(1)\n    if train_df.iloc[i][\"winner_model_b\"] == 1:\n        targets.append(2)\nlen(prompt_list)","metadata":{"execution":{"iopub.status.busy":"2024-11-06T15:38:45.474345Z","iopub.execute_input":"2024-11-06T15:38:45.474741Z","iopub.status.idle":"2024-11-06T15:39:08.068573Z","shell.execute_reply.started":"2024-11-06T15:38:45.474705Z","shell.execute_reply":"2024-11-06T15:39:08.067639Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Step 2: Define TextVectorization layer\nvocab_size = 20000  # Vocabulary size (tune this as needed)\nmax_length = 1024    # Maximum sequence length (tune this as needed)\ntext_vectorizer = TextVectorization(max_tokens=vocab_size, output_mode='int', output_sequence_length=max_length)\ntext_vectorizer.adapt([item[0] for item in prompt_list] + [item[1] for item in prompt_list]) ","metadata":{"execution":{"iopub.status.busy":"2024-11-06T15:39:14.095289Z","iopub.execute_input":"2024-11-06T15:39:14.095679Z","iopub.status.idle":"2024-11-06T15:39:26.835407Z","shell.execute_reply.started":"2024-11-06T15:39:14.095639Z","shell.execute_reply":"2024-11-06T15:39:26.834583Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def get_dataset(prompt_list, targets, shuffle=True, batch_size=128):\n    part1 = [item[0] for item in prompt_list]\n    part2 = [item[1] for item in prompt_list]\n    dataset = tf.data.Dataset.from_tensor_slices(((part1, part2), targets))\n    if shuffle:\n        dataset = dataset.shuffle(buffer_size=2048)\n    dataset = dataset.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n    return dataset","metadata":{"execution":{"iopub.status.busy":"2024-11-06T15:42:37.829889Z","iopub.execute_input":"2024-11-06T15:42:37.830313Z","iopub.status.idle":"2024-11-06T15:42:37.837015Z","shell.execute_reply.started":"2024-11-06T15:42:37.830276Z","shell.execute_reply":"2024-11-06T15:42:37.836058Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Modeling","metadata":{}},{"cell_type":"code","source":"def get_base_model(inputs, embedding):\n    x = text_vectorizer(inputs)\n    x = embedding(x)\n    return x\ndef get_model():\n    inputs1 = tf.keras.Input(shape=(1,), dtype=tf.string)\n    inputs2 = tf.keras.Input(shape=(1,), dtype=tf.string)\n    embedding = tf.keras.layers.Embedding(input_dim=vocab_size, output_dim=64, mask_zero=True)\n    x1 = get_base_model(inputs1, embedding)\n    x2 = get_base_model(inputs2, embedding)\n    x = tf.keras.layers.Concatenate()([x1, x2])\n    x = tf.keras.layers.Conv1D(32, 3, activation=\"relu\")(x)\n    x = tf.keras.layers.Conv1D(32, 3, activation=\"relu\")(x)\n    x = tf.keras.layers.SpatialDropout1D(0.2)(x)\n    x = tf.keras.layers.MaxPooling1D()(x)\n    x = tf.keras.layers.Conv1D(64, 3, activation=\"relu\")(x)\n    x = tf.keras.layers.Conv1D(64, 3, activation=\"relu\")(x)\n    x = tf.keras.layers.SpatialDropout1D(0.2)(x)\n    x = tf.keras.layers.MaxPooling1D()(x)\n    x = tf.keras.layers.GlobalAveragePooling1D()(x)\n    x = tf.keras.layers.Dropout(0.3)(x)\n    x = tf.keras.layers.Dense(128, activation=\"swish\")(x)\n    outputs = tf.keras.layers.Dense(3, activation=\"softmax\")(x)\n    model = tf.keras.Model(inputs=[inputs1, inputs2], outputs=outputs)\n    \n    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n    return model","metadata":{"execution":{"iopub.status.busy":"2024-11-06T15:43:29.545391Z","iopub.execute_input":"2024-11-06T15:43:29.54611Z","iopub.status.idle":"2024-11-06T15:43:29.556853Z","shell.execute_reply.started":"2024-11-06T15:43:29.546069Z","shell.execute_reply":"2024-11-06T15:43:29.555938Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"models = []\nfor seed in CFG.seeds:\n    model_name = f\"model_{seed}.keras\"\n    # Step 1: Split texts and labels into train and test sets\n    train_texts, valid_texts, train_labels, valid_labels = train_test_split(\n        prompt_list, targets, test_size=0.2, random_state=seed\n    )\n    valid_ds = get_dataset(valid_texts, valid_labels, shuffle=False)\n    model_name_path = f\"/kaggle/input/llm-classification-finetuning-with-cnn-model/{model_name}\"\n    if not os.path.exists(model_name_path):\n        train_ds = get_dataset(train_texts, train_labels)\n        model = get_model()\n        checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n            filepath=model_name,  # Filepath to save the best model\n            monitor='val_loss',        # Metric to monitor\n            mode=\"min\",\n            save_best_only=True,       # Save only the best model\n            verbose=1\n        )\n        early_stopping_callback = tf.keras.callbacks.EarlyStopping(\n            monitor='val_loss',        # Metric to monitor\n            patience=5,                # Number of epochs with no improvement to wait before stopping\n            verbose=1,\n            restore_best_weights=True  # Restore weights from the best epoch\n        )\n        model.fit(train_ds, epochs=30, validation_data=valid_ds, callbacks=[checkpoint_callback, early_stopping_callback])\n        model.load_weights(model_name)\n    else:\n        model = tf.keras.models.load_model(model_name_path)\n        model.save(model_name)\n    loss, acc = model.evaluate(valid_ds, verbose=0)\n    print(f\"Validation Loss: {loss: .4f} Validation Accuracy: {acc * 100: .4f}%\")\n    models.append(model)","metadata":{"execution":{"iopub.status.busy":"2024-11-06T15:49:48.174044Z","iopub.execute_input":"2024-11-06T15:49:48.174448Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Create Submission","metadata":{}},{"cell_type":"code","source":"test_df = pd.read_csv(\"/kaggle/input/llm-classification-finetuning/test.csv\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Now create load data and create test dataset","metadata":{}},{"cell_type":"code","source":"test_prompt_list = []\nfor i in tqdm(range(len(test_df))):\n    prompts = json.loads(test_df.iloc[i][\"prompt\"])\n    response_a = json.loads(test_df.iloc[i][\"response_a\"])\n    response_b = json.loads(test_df.iloc[i][\"response_b\"])\n    conversation_a = \"\"\n    conversation_b = \"\"\n    for j in range(len(prompts)):\n        if response_a[j] is None:\n            response_a[j] = \"None\"\n        if response_b[j] is None:\n            response_b[j] = \"None\"\n        conversation_a += prompts[j] + \"\\n\"\n        conversation_a += response_a[j] + \"\\n\"\n        conversation_b += prompts[j] + \"\\n\"\n        conversation_b += response_b[j] + \"\\n\"\n    test_prompt_list.append((conversation_a, conversation_b))\nlen(test_prompt_list)","metadata":{"execution":{"iopub.status.busy":"2024-11-06T05:37:12.573942Z","iopub.execute_input":"2024-11-06T05:37:12.574387Z","iopub.status.idle":"2024-11-06T05:37:12.609295Z","shell.execute_reply.started":"2024-11-06T05:37:12.574342Z","shell.execute_reply":"2024-11-06T05:37:12.608322Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def get_test_dataset(prompt_list, batch_size=128):\n    part1 = [item[0] for item in prompt_list]\n    part2 = [item[1] for item in prompt_list]\n    dataset = tf.data.Dataset.from_tensor_slices(((part1, part2), [0] * len(prompt_list)))\n    dataset = dataset.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n    return dataset","metadata":{"execution":{"iopub.status.busy":"2024-11-06T05:37:36.233659Z","iopub.execute_input":"2024-11-06T05:37:36.234114Z","iopub.status.idle":"2024-11-06T05:37:36.24135Z","shell.execute_reply.started":"2024-11-06T05:37:36.234074Z","shell.execute_reply":"2024-11-06T05:37:36.239955Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_ds = get_test_dataset(test_prompt_list)","metadata":{"execution":{"iopub.status.busy":"2024-11-06T05:37:41.679648Z","iopub.execute_input":"2024-11-06T05:37:41.680072Z","iopub.status.idle":"2024-11-06T05:37:41.692547Z","shell.execute_reply.started":"2024-11-06T05:37:41.680033Z","shell.execute_reply":"2024-11-06T05:37:41.691448Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"result = np.mean([model.predict(test_ds, verbose=0) for model in models], axis=0)","metadata":{"execution":{"iopub.status.busy":"2024-11-06T05:37:55.263904Z","iopub.execute_input":"2024-11-06T05:37:55.264355Z","iopub.status.idle":"2024-11-06T05:37:55.604236Z","shell.execute_reply.started":"2024-11-06T05:37:55.264315Z","shell.execute_reply":"2024-11-06T05:37:55.603079Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"submission = pd.read_csv(\"/kaggle/input/llm-classification-finetuning/sample_submission.csv\")\nsubmission[\"winner_tie\"] = result[:, 0]\nsubmission[\"winner_model_a\"] = result[:, 1]\nsubmission[\"winner_model_b\"] = result[:, 2]\nsubmission.to_csv(\"submission.csv\", index=False)\nsubmission.head()","metadata":{"execution":{"iopub.status.busy":"2024-11-06T05:38:46.928889Z","iopub.execute_input":"2024-11-06T05:38:46.929327Z","iopub.status.idle":"2024-11-06T05:38:46.953394Z","shell.execute_reply.started":"2024-11-06T05:38:46.929285Z","shell.execute_reply":"2024-11-06T05:38:46.952207Z"},"trusted":true},"outputs":[],"execution_count":null}]}