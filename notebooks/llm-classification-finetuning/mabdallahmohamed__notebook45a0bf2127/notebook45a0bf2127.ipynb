{"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":86518,"databundleVersionId":9809560,"sourceType":"competition"}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import tensorflow as tf\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n","metadata":{"id":"gUYg5XLva1fZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fashion_mnist = tf.keras.datasets.fashion_mnist\n(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()","metadata":{"id":"vY1CrgVnb4sx","outputId":"cdd5e16f-589d-4564-b7cb-26affd73c0af"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_images.shape\ntest_images.shape","metadata":{"id":"RNOweGpYcJcM","outputId":"62069eca-48aa-44d5-ecea-91706b365397"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_labels","metadata":{"id":"onTjuocKcX3Y","outputId":"e808c36a-4c19-4530-f7e4-fa88fcf46d1c"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"np.unique(train_labels)\nplt.imshow(train_images[50])\n","metadata":{"id":"NttvI2Kacd7u","outputId":"4c27f9b6-c89d-48ec-ffc5-50dcc3aca028"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = tf.keras.Sequential([\n    tf.keras.layers.Flatten(input_shape=(28, 28)),\n    tf.keras.layers.Dense(128, activation='relu'),\n    tf.keras.layers.Dense(64, activation='relu'),\n    tf.keras.layers.Dense(32, activation='relu'),\n    tf.keras.layers.Dense(16, activation='relu'),\n    tf.keras.layers.Dense(8, activation='relu'),\n    tf.keras.layers.Dense(4, activation='relu'),\n    tf.keras.layers.Dense(10, activation='softmax') # Changed 'sofmax' to 'softmax'\n])","metadata":{"id":"PIDPHXXGm7mn","outputId":"79d7c0ef-b9aa-4ccd-b97c-e459f4a7c395"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.compile(optimizer='adam',\n              loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n              metrics=['accuracy'])","metadata":{"id":"u--Jay_xe3uM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.fit(train_images, train_labels, epochs=20)","metadata":{"id":"L10eaczqfXKj","outputId":"25bd3b8a-5729-451c-a0d5-413782707724"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_loss, test_acc = model.evaluate(test_images, test_labels, verbose=2)\nprint('\\nTest accuracy:', test_acc)\n","metadata":{"id":"r7QZsCbBfazr","outputId":"1d2092f1-5850-41d4-eeae-b10970dd35bb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import classification_report\ny_pred = model.predict(test_images)\ny_pred_classes = np.argmax(y_pred, axis=1)\nprint(classification_report(test_labels, y_pred_classes))","metadata":{"id":"5uwd8fLjn8Jl","outputId":"3320d275-4f5f-4855-84a1-5b181efc1e46"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nfrom sklearn.linear_model import LogisticRegression\n\nnum_samples = train_images.shape[0]\ntrain_images_reshaped = train_images.reshape(num_samples, -1)\n\nmodel = LogisticRegression()\nmodel.fit(train_images_reshaped, train_labels)","metadata":{"id":"NNbmWgSkoaCv","outputId":"e82eb2f3-d714-4ccb-c0a8-b44bca52380e"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred = model.predict(test_images.reshape(test_images.shape[0], -1))\nprint(classification_report(test_labels, y_pred))\nprint(model.score(test_images.reshape(test_images.shape[0], -1), test_labels))","metadata":{"id":"YCFrbXJLom5e","outputId":"153709ff-8ce9-4313-f737-498e3140a406"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.random_projection import GaussianRandomProjection\n\n# Explicitly set n_components to a value lower than the original feature space\nmodel = GaussianRandomProjection(n_components=100, random_state=42)  # Example: Reducing to 100 dimensions\n\nmodel.fit(train_images.reshape(train_images.shape[0], -1), train_labels)","metadata":{"id":"3txJ-a-Ktykg","outputId":"fd59b5fd-981c-4c4b-db17-02a293781924"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.random_projection import GaussianRandomProjection\nfrom sklearn.linear_model import LogisticRegression # Importing a classifier\nfrom sklearn.metrics import classification_report\nimport numpy as np\n\n\n# 1. Apply GaussianRandomProjection for dimensionality reduction\ngrp = GaussianRandomProjection(n_components=100, random_state=42)\nreduced_train_images = grp.fit_transform(train_images.reshape(train_images.shape[0], -1))\nreduced_test_images = grp.transform(test_images.reshape(test_images.shape[0], -1))\n\n# 2. Train a classifier (e.g., Logistic Regression) on the reduced data\nmodel = LogisticRegression()\nmodel.fit(reduced_train_images, train_labels)\n\n# 3. Make predictions using the trained classifier\ny_pred = model.predict(reduced_test_images)\n\n# 4. Generate the classification report\nprint(classification_report(test_labels, y_pred))\nprint(model.score(reduced_test_images, test_labels))","metadata":{"id":"Fdslkrbnt_NV","outputId":"2b538c4d-8f53-4bd5-f5ba-f855f9ed50cb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.kernel_approximation import Nystroem # Corrected the class name to Nystroem\n\nmodel = Nystroem()  # Initialize the Nystroem object\nmodel.fit(train_images.reshape(train_images.shape[0], -1), train_labels)","metadata":{"id":"WIf1wHh7uesm","outputId":"05476abe-f1fd-42ce-f74c-8fe6a62f0d9d"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.kernel_approximation import Nystroem\nfrom sklearn.linear_model import LogisticRegression # Importing a classifier\nfrom sklearn.metrics import classification_report\nimport numpy as np\n\n# 1. Apply Nystroem for kernel approximation\nnystroem = Nystroem(kernel='rbf', n_components=100, random_state=42) # Example: Reducing to 100 dimensions with RBF kernel\ntransformed_train_images = nystroem.fit_transform(train_images.reshape(train_images.shape[0], -1))\ntransformed_test_images = nystroem.transform(test_images.reshape(test_images.shape[0], -1))\n\n# 2. Train a classifier (e.g., Logistic Regression) on the transformed data\nmodel = LogisticRegression(max_iter=1000) # Initialize a classifier\nmodel.fit(transformed_train_images, train_labels)  # Train on transformed data\n\n# 3. Make predictions using the trained classifier\ny_pred = model.predict(transformed_test_images)  # Predict using transformed data\n\n# 4. Generate the classification report\nprint(classification_report(test_labels, y_pred))\nprint(model.score(transformed_test_images, test_labels))","metadata":{"id":"y2EyLAp9upOD","outputId":"310cf8c9-7b93-4d5b-ff4c-3f29f121da14"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearm.decomposition import PCA\n\nmodel = PCA(n_components=100)\nmodel.fit(train_images.reshape(train_images.shape[0], -1), train_labels)","metadata":{"id":"rWuNuYRSuscN","outputId":"6f068534-a888-40eb-8e79-c0e4c555dd09"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.decomposition import PCA # Corrected import statement\n\nmodel = PCA(n_components=100)\nmodel.fit(train_images.reshape(train_images.shape[0], -1), train_labels)","metadata":{"id":"d8kzGjbEuzQz","outputId":"6aa84773-fef3-4266-8ef2-4d9f0dbc09a1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.decomposition import PCA\nfrom sklearn.linear_model import LogisticRegression # Importing a classifier\nfrom sklearn.metrics import classification_report\nimport numpy as np\n\n# 1. Apply PCA for dimensionality reduction\npca = PCA(n_components=100)\ntransformed_train_images = pca.fit_transform(train_images.reshape(train_images.shape[0], -1))\ntransformed_test_images = pca.transform(test_images.reshape(test_images.shape[0], -1))\n\n# 2. Train a classifier (e.g., Logistic Regression) on the transformed data\nmodel = LogisticRegression(max_iter=1000) # Initialize a classifier\nmodel.fit(transformed_train_images, train_labels)  # Train on transformed data\n\n# 3. Make predictions using the trained classifier\ny_pred = model.predict(transformed_test_images)  # Predict using transformed data\n\n# 4. Generate the classification report\nprint(classification_report(test_labels, y_pred))\nprint(model.score(transformed_test_images, test_labels))","metadata":{"id":"0TMNSW4mu9WU","outputId":"96005b78-d1cd-4256-c589-908bf3487577"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n\nmodel = LinearDiscriminantAnalysis()\nmodel.fit(train_images.reshape(train_images.shape[0], -1), train_labels)\n","metadata":{"id":"zEz7WimjvPp6","outputId":"5fc15bb5-f018-4453-9e98-81ed2290fc0c"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred = model.predict(test_images.reshape(test_images.shape[0], -1))\nprint(classification_report(test_labels, y_pred))\nprint(model.score(test_images.reshape(test_images.shape[0], -1), test_labels))","metadata":{"id":"aT9j8bgdvYF0","outputId":"92a46737-8b95-4304-9497-d528c8936c22"},"execution_count":null,"outputs":[]}]}