{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":86518,"databundleVersionId":9809560,"isSourceIdPinned":false,"sourceType":"competition"}],"dockerImageVersionId":31090,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\n\ndata_path = \"/kaggle/input/llm-classification-finetuning/\"\n\ntrain_df = pd.read_csv(data_path + \"train.csv\")\ntest_df = pd.read_csv(data_path + \"test.csv\")\nsample_submission = pd.read_csv(data_path + \"sample_submission.csv\")\n\nprint(\"Train shape:\", train_df.shape)\nprint(\"Test shape:\", test_df.shape)\nprint(\"Sample submission shape:\", sample_submission.shape)\n\n# Peek at first few rows\ntrain_df.head()\n\n# Check label distribution\nprint(\"\\nLabel distribution:\")\nprint(train_df['winner_model_a'].sum(), \"A wins\")\nprint(train_df['winner_model_b'].sum(), \"B wins\")\nprint(train_df['winner_tie'].sum(), \"ties\")\n\n# Count NaNs\nprint(\"\\nMissing values in train:\")\nprint(train_df.isnull().sum())\n\n# Check basic stats for response lengths\ntrain_df['len_a'] = train_df['model_a'].str.len()\ntrain_df['len_b'] = train_df['model_b'].str.len()\nprint(\"\\nLength stats for A and B:\")\nprint(train_df[['len_a', 'len_b']].describe())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-10T11:51:20.217639Z","iopub.execute_input":"2025-08-10T11:51:20.217829Z","iopub.status.idle":"2025-08-10T11:51:26.95605Z","shell.execute_reply.started":"2025-08-10T11:51:20.217811Z","shell.execute_reply":"2025-08-10T11:51:26.955174Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.metrics.pairwise import cosine_similarity\nimport lightgbm as lgb\n\n# Paths\ndata_path = \"/kaggle/input/llm-classification-finetuning/\"\n\n# Load\ntrain_df = pd.read_csv(data_path + \"train.csv\")\ntest_df = pd.read_csv(data_path + \"test.csv\")\nsample_submission = pd.read_csv(data_path + \"sample_submission.csv\")\n\nprint(\"Train shape:\", train_df.shape)\nprint(\"Test shape:\", test_df.shape)\n\n# Ensure model_a / model_b exist in test set\nfor col in ['model_a', 'model_b']:\n    if col not in test_df.columns:\n        test_df[col] = \"unknown\"\n\n# Encode model_a, model_b\nohe = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\nmodel_features_train = ohe.fit_transform(train_df[['model_a', 'model_b']])\nmodel_features_test = ohe.transform(test_df[['model_a', 'model_b']])\n\n# TF-IDF similarity between prompt and responses\nvectorizer = TfidfVectorizer(max_features=5000)\n\n# Fit on all text fields to build vocab\nvectorizer.fit(pd.concat([\n    train_df['prompt'], train_df['response_a'], train_df['response_b'],\n    test_df['prompt'], test_df['response_a'], test_df['response_b']\n]))\n\n# Compute cosine similarity features\ndef compute_similarity(df):\n    prompt_vec = vectorizer.transform(df['prompt'])\n    resp_a_vec = vectorizer.transform(df['response_a'])\n    resp_b_vec = vectorizer.transform(df['response_b'])\n    sim_a = [cosine_similarity(prompt_vec[i], resp_a_vec[i])[0,0] for i in range(df.shape[0])]\n    sim_b = [cosine_similarity(prompt_vec[i], resp_b_vec[i])[0,0] for i in range(df.shape[0])]\n    return np.array(sim_a).reshape(-1,1), np.array(sim_b).reshape(-1,1)\n\nsim_a_train, sim_b_train = compute_similarity(train_df)\nsim_a_test, sim_b_test = compute_similarity(test_df)\n\n# Length features\nlen_a_train = train_df['response_a'].str.len().values.reshape(-1,1)\nlen_b_train = train_df['response_b'].str.len().values.reshape(-1,1)\nlen_a_test = test_df['response_a'].str.len().values.reshape(-1,1)\nlen_b_test = test_df['response_b'].str.len().values.reshape(-1,1)\n\n# Final feature matrices\nX_train = np.hstack([model_features_train, sim_a_train, sim_b_train, len_a_train, len_b_train])\nX_test = np.hstack([model_features_test, sim_a_test, sim_b_test, len_a_test, len_b_test])\n\n# Target: winner_model_a=0/1, winner_model_b=0/1, winner_tie=0/1\n# We'll map them into a single class label: 0=A, 1=B, 2=tie\ny_train = np.argmax(train_df[['winner_model_a', 'winner_model_b', 'winner_tie']].values, axis=1)\n\n# Train LightGBM multiclass model\nparams = {\n    'objective': 'multiclass',\n    'num_class': 3,\n    'metric': 'multi_logloss',\n    'learning_rate': 0.05,\n    'num_leaves': 31,\n    'verbose': -1\n}\n\ndtrain = lgb.Dataset(X_train, label=y_train)\nmodel = lgb.train(params, dtrain, num_boost_round=200)\n\n# Predict probabilities\npreds = model.predict(X_test)\n\n# Format submission\nsubmission = pd.DataFrame(preds, columns=['winner_model_a','winner_model_b','winner_tie'])\nsubmission.insert(0, 'id', test_df['id'])\nsubmission.to_csv('submission.csv', index=False)\n\nprint(\"Submission saved to submission.csv\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}