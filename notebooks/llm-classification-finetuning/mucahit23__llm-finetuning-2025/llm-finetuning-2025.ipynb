{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":86518,"databundleVersionId":9809560,"sourceType":"competition"}],"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-01-06T17:02:26.03Z","iopub.execute_input":"2025-01-06T17:02:26.030207Z","iopub.status.idle":"2025-01-06T17:02:26.321347Z","shell.execute_reply.started":"2025-01-06T17:02:26.030186Z","shell.execute_reply":"2025-01-06T17:02:26.320465Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report\nfrom scipy.sparse import hstack\nfrom catboost import CatBoostClassifier\nimport optuna\n\n# Kaggle veri yolları\ntrain_path = '/kaggle/input/llm-classification-finetuning/train.csv'\ntest_path = '/kaggle/input/llm-classification-finetuning/test.csv'\nsubmission_path = '/kaggle/input/llm-classification-finetuning/sample_submission.csv'\n\n# Verileri yükleme\ntrain = pd.read_csv(train_path)\ntest = pd.read_csv(test_path)\nsubmission = pd.read_csv(submission_path)\n\n# Winner sütununu oluşturma\ntrain['winner'] = train[['winner_model_a', 'winner_model_b', 'winner_tie']].idxmax(axis=1).map({\n    'winner_model_a': 0, 'winner_model_b': 1, 'winner_tie': 2\n})\n\n# Giriş ve hedef değişkenleri ayırma\nX = train['prompt'] + \" \" + train['response_a'] + \" \" + train['response_b']\ny = train['winner']\n\n# Eğitim ve doğrulama seti\nX_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# TF-IDF Özellik Çıkarımı\ntfidf_vectorizer = TfidfVectorizer(max_features=5000)\nX_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\nX_val_tfidf = tfidf_vectorizer.transform(X_val)\n\n# Test seti için TF-IDF çıkarımı\ntest_X = test['prompt'] + \" \" + test['response_a'] + \" \" + test['response_b']\ntest_tfidf = tfidf_vectorizer.transform(test_X)\n\n# Optuna ile Hiperparametre Optimizasyonu\ndef objective(trial):\n    # Hiperparametreler\n    params = {\n        \"iterations\": trial.suggest_int(\"iterations\", 100, 1000, step=100),\n        \"depth\": trial.suggest_int(\"depth\", 4, 10),\n        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.3, log=True),\n        \"l2_leaf_reg\": trial.suggest_float(\"l2_leaf_reg\", 1e-3, 10, log=True),\n        \"random_strength\": trial.suggest_float(\"random_strength\", 0.1, 2),\n        \"bagging_temperature\": trial.suggest_float(\"bagging_temperature\", 0, 1),\n        \"task_type\": \"GPU\",\n        \"devices\": \"0\",\n        \"loss_function\": \"MultiClass\",\n        \"eval_metric\": \"Accuracy\",\n        \"verbose\": 0\n    }\n\n    # Model eğitimi\n    cat_model = CatBoostClassifier(**params)\n    cat_model.fit(X_train_tfidf, y_train, eval_set=(X_val_tfidf, y_val), early_stopping_rounds=50, verbose=0)\n    accuracy = cat_model.best_score_[\"validation\"][\"Accuracy\"]\n\n    return accuracy\n\n# Optuna çalıştırma\nstudy = optuna.create_study(direction=\"maximize\")\nstudy.optimize(objective, n_trials=20)\n\n# En iyi hiperparametreler\nbest_params = study.best_params\nprint(\"Best Parameters:\", best_params)\n\n# En iyi model ile eğitim\nfinal_model = CatBoostClassifier(**best_params, task_type=\"GPU\", devices=\"0\", loss_function=\"MultiClass\")\nfinal_model.fit(X_train_tfidf, y_train, eval_set=(X_val_tfidf, y_val), early_stopping_rounds=50)\n\n# Doğrulama seti tahmini\ny_pred = final_model.predict(X_val_tfidf)\nprint(classification_report(y_val, y_pred))\n\n# Test seti tahmini\ntest['winner'] = final_model.predict(test_tfidf)\n\n# Tahminleri yarışma formatına uygun hale getirme\ntest['winner_model_a'] = (test['winner'] == 0).astype(int)\ntest['winner_model_b'] = (test['winner'] == 1).astype(int)\ntest['winner_tie'] = (test['winner'] == 2).astype(int)\n\nsubmission = test[['id', 'winner_model_a', 'winner_model_b', 'winner_tie']]\nsubmission.to_csv('submission.csv', index=False)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-06T17:06:06.164793Z","iopub.execute_input":"2025-01-06T17:06:06.165086Z","iopub.status.idle":"2025-01-06T17:10:56.319014Z","shell.execute_reply.started":"2025-01-06T17:06:06.165064Z","shell.execute_reply":"2025-01-06T17:10:56.318133Z"}},"outputs":[],"execution_count":null}]}