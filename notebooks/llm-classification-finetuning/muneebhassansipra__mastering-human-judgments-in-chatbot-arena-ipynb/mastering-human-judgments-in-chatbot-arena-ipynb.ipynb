{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":86518,"databundleVersionId":9809560,"sourceType":"competition"},{"sourceId":6057,"sourceType":"modelInstanceVersion","modelInstanceId":4678,"modelId":2819},{"sourceId":6058,"sourceType":"modelInstanceVersion","modelInstanceId":4679,"modelId":2819}],"dockerImageVersionId":31089,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# ü§ñ Predicting Human Preferences in Chatbot Arena | LLM Classification Finetuning üß†\n\n<h1 style=\"font-family: 'poppins'; font-weight: bold; color: Green;\">üë®‚ÄçüíªAuthor: Dr. Muneeb Hassan</h1>\n\n[![GitHub](https://img.shields.io/badge/GitHub-Profile-blue?style=for-the-badge&logo=github)](https://github.com/MUNEEB-HASSAN)  \n[![Kaggle](https://img.shields.io/badge/Kaggle-Notebook-blue?style=for-the-badge&logo=kaggle)](https://www.kaggle.com/code/muneebhassansipra)  \n[![LinkedIn](https://img.shields.io/badge/LinkedIn-Profile-blue?style=for-the-badge&logo=linkedin)](https://www.linkedin.com/in/muneebhassansipra)\n\n---\n\n### üìò Competition Overview\nThis competition challenges us to predict which LLM response users will prefer during a head-to-head chatbot battle in the **Chatbot Arena**.\n\nYou'll work with real-world dialogue data and fine-tune models using **Reinforcement Learning from Human Feedback (RLHF)** concepts ‚Äî an essential skill in modern AI alignment.\n\n---\n\n### üéØ Goal\nPredict the preferred response (`model_a`, `model_b`, or `tie`) based on the conversation **prompt** and the two **LLM-generated responses**.\n\n> üìå Evaluation Metric: **Log Loss** on multi-class probabilities:  \n> `winner_model_a`, `winner_model_b`, `winner_tie`\n\n---\n\n### üõ†Ô∏è Solution Approach\n- Text Embedding via `KerasNLP` / `SentenceTransformer`\n- Feature engineering from prompt and responses\n- Deep Learning classifier (Dense NN)\n- Submission ready with log-loss optimized output\n\nLet's get started!\n","metadata":{}},{"cell_type":"markdown","source":"# Importing libraries","metadata":{}},{"cell_type":"code","source":"# Suppress TensorFlow and CUDA warnings\nimport os\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'  # Suppress TensorFlow INFO and WARNING logs\n\n# Optional: disable GPU if not needed\n# os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n\n# Core Libraries\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# NLP & Modeling\nimport tensorflow as tf\nimport keras\nimport keras_nlp\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import log_loss\nfrom tqdm import tqdm\n\n# Miscellaneous\nimport warnings\nwarnings.filterwarnings(\"ignore\")\npd.set_option('display.max_colwidth', None)\n\n# Confirm library versions\nprint(\"‚úÖ TensorFlow version:\", tf.__version__)\nprint(\"‚úÖ KerasNLP version:\", keras_nlp.__version__)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-26T00:34:33.181304Z","iopub.execute_input":"2025-07-26T00:34:33.181598Z","iopub.status.idle":"2025-07-26T00:34:53.831546Z","shell.execute_reply.started":"2025-07-26T00:34:33.181568Z","shell.execute_reply":"2025-07-26T00:34:53.830527Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Load Dataset","metadata":{}},{"cell_type":"code","source":"data_path = \"/kaggle/input/llm-classification-finetuning/\"\n\ntrain_df = pd.read_csv(data_path + \"train.csv\")\ntest_df = pd.read_csv(data_path + \"test.csv\")\nsample_submission = pd.read_csv(data_path + \"sample_submission.csv\")\n\nprint(\"Train shape:\", train_df.shape)\nprint(\"Test shape:\", test_df.shape)\nprint(\"Sample submission shape:\", sample_submission.shape)\n\ntrain_df.head()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-26T00:34:53.832976Z","iopub.execute_input":"2025-07-26T00:34:53.833543Z","iopub.status.idle":"2025-07-26T00:34:57.452751Z","shell.execute_reply.started":"2025-07-26T00:34:53.833519Z","shell.execute_reply":"2025-07-26T00:34:57.451644Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# EDA and Data Wrangling","metadata":{}},{"cell_type":"code","source":"train_df.describe()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-26T00:34:57.4539Z","iopub.execute_input":"2025-07-26T00:34:57.454689Z","iopub.status.idle":"2025-07-26T00:34:57.493865Z","shell.execute_reply.started":"2025-07-26T00:34:57.45466Z","shell.execute_reply":"2025-07-26T00:34:57.492931Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Basic info\ntrain_df.info()\n\n# Check for missing values\nprint(\"\\nüßº Missing values:\\n\", train_df.isnull().sum())\n\n# Check target distribution (multi-label one-hot encoded)\nprint(\"\\nüéØ Winner Distribution:\")\ntarget_counts = train_df[[\"winner_model_a\", \"winner_model_b\", \"winner_tie\"]].sum()\nprint(target_counts)\n\n# Plot target distribution\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nsns.set_style(\"whitegrid\")\nplt.figure(figsize=(6,4))\nsns.barplot(x=target_counts.index, y=target_counts.values, palette=\"viridis\")\nplt.title(\"Distribution of Winner Classes\")\nplt.ylabel(\"Count\")\nplt.xlabel(\"Winner\")\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-26T00:36:12.101557Z","iopub.execute_input":"2025-07-26T00:36:12.101957Z","iopub.status.idle":"2025-07-26T00:36:12.867273Z","shell.execute_reply.started":"2025-07-26T00:36:12.101928Z","shell.execute_reply":"2025-07-26T00:36:12.866335Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Combine prompt and responses into single strings for model input\ntrain_df[\"text_a\"] = train_df[\"prompt\"] + \" \" + train_df[\"response_a\"]\ntrain_df[\"text_b\"] = train_df[\"prompt\"] + \" \" + train_df[\"response_b\"]\ntest_df[\"text_a\"] = test_df[\"prompt\"] + \" \" + test_df[\"response_a\"]\ntest_df[\"text_b\"] = test_df[\"prompt\"] + \" \" + test_df[\"response_b\"]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-26T00:36:34.574437Z","iopub.execute_input":"2025-07-26T00:36:34.574817Z","iopub.status.idle":"2025-07-26T00:36:34.865806Z","shell.execute_reply.started":"2025-07-26T00:36:34.574789Z","shell.execute_reply":"2025-07-26T00:36:34.864866Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Convert one-hot targets to single integer labels\ndef get_winner(row):\n    if row[\"winner_model_a\"] == 1:\n        return 0\n    elif row[\"winner_model_b\"] == 1:\n        return 1\n    else:\n        return 2\n\ntrain_df[\"target\"] = train_df.apply(get_winner, axis=1)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-26T00:36:57.988086Z","iopub.execute_input":"2025-07-26T00:36:57.988971Z","iopub.status.idle":"2025-07-26T00:36:58.387572Z","shell.execute_reply.started":"2025-07-26T00:36:57.98894Z","shell.execute_reply":"2025-07-26T00:36:58.386667Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_df[[\"winner_model_a\", \"winner_model_b\", \"winner_tie\", \"target\"]].head()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-26T00:37:16.179445Z","iopub.execute_input":"2025-07-26T00:37:16.180121Z","iopub.status.idle":"2025-07-26T00:37:16.192145Z","shell.execute_reply.started":"2025-07-26T00:37:16.18009Z","shell.execute_reply":"2025-07-26T00:37:16.191194Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_df[['winner_model_a', 'winner_model_b', 'winner_tie']].sum()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-26T00:37:26.127121Z","iopub.execute_input":"2025-07-26T00:37:26.127431Z","iopub.status.idle":"2025-07-26T00:37:26.136821Z","shell.execute_reply.started":"2025-07-26T00:37:26.127409Z","shell.execute_reply":"2025-07-26T00:37:26.135835Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"sample = train_df.sample(1).iloc[0]\nprint(\"Prompt:\\n\", sample['prompt'])\nprint(\"\\nResponse A:\\n\", sample['response_a'])\nprint(\"\\nResponse B:\\n\", sample['response_b'])\nprint(\"\\nWinner:\", [\"model_a\", \"model_b\", \"tie\"][sample['target']])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-26T00:37:31.753864Z","iopub.execute_input":"2025-07-26T00:37:31.754898Z","iopub.status.idle":"2025-07-26T00:37:31.763426Z","shell.execute_reply.started":"2025-07-26T00:37:31.754857Z","shell.execute_reply":"2025-07-26T00:37:31.762676Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Length-based features\ntrain_df[\"prompt_len\"] = train_df[\"prompt\"].apply(lambda x: len(x.split()))\ntrain_df[\"response_a_len\"] = train_df[\"response_a\"].apply(lambda x: len(x.split()))\ntrain_df[\"response_b_len\"] = train_df[\"response_b\"].apply(lambda x: len(x.split()))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-26T00:37:45.000184Z","iopub.execute_input":"2025-07-26T00:37:45.000929Z","iopub.status.idle":"2025-07-26T00:37:46.543874Z","shell.execute_reply.started":"2025-07-26T00:37:45.0009Z","shell.execute_reply":"2025-07-26T00:37:46.542936Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plt.figure(figsize=(10, 5))\nsns.histplot(train_df[\"prompt_len\"], bins=50, kde=True, color=\"orange\", label=\"Prompt\")\nsns.histplot(train_df[\"response_a_len\"], bins=50, kde=True, color=\"blue\", label=\"Response A\", alpha=0.5)\nsns.histplot(train_df[\"response_b_len\"], bins=50, kde=True, color=\"green\", label=\"Response B\", alpha=0.5)\nplt.legend()\nplt.title(\"Length Distribution (Token Count)\")\nplt.xlabel(\"Token Count\")\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-26T00:37:52.768992Z","iopub.execute_input":"2025-07-26T00:37:52.76983Z","iopub.status.idle":"2025-07-26T00:37:54.347141Z","shell.execute_reply.started":"2025-07-26T00:37:52.7698Z","shell.execute_reply":"2025-07-26T00:37:54.346207Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Create winning response length\ntrain_df[\"winner_len\"] = train_df.apply(\n    lambda row: len(row[\"response_a\"].split()) if row[\"target\"] == 0 \n    else len(row[\"response_b\"].split()) if row[\"target\"] == 1 \n    else (len(row[\"response_a\"].split()) + len(row[\"response_b\"].split())) / 2,\n    axis=1\n)\n\n# Compare winner vs average length\nplt.figure(figsize=(6, 4))\nsns.boxplot(data=train_df, x=\"target\", y=\"winner_len\", palette=\"pastel\")\nplt.title(\"Winning Response Lengths by Target Class\")\nplt.xlabel(\"Winner (0: A, 1: B, 2: Tie)\")\nplt.ylabel(\"Token Length\")\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-26T00:38:06.968161Z","iopub.execute_input":"2025-07-26T00:38:06.968915Z","iopub.status.idle":"2025-07-26T00:38:08.718539Z","shell.execute_reply.started":"2025-07-26T00:38:06.968886Z","shell.execute_reply":"2025-07-26T00:38:08.717692Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import re\n\ndef clean_text(text):\n    text = re.sub(r'\\s+', ' ', text)          # Remove extra spaces\n    text = text.replace('\\n', ' ')            # Remove line breaks\n    text = re.sub(r\"[^a-zA-Z0-9.,;!?()\\[\\]{}'\\\":/\\-‚Äì‚Äî\\s]\", \"\", text)  # Remove weird chars\n    return text.strip()\n\nfor col in [\"prompt\", \"response_a\", \"response_b\"]:\n    train_df[col] = train_df[col].astype(str).apply(clean_text)\n    test_df[col] = test_df[col].astype(str).apply(clean_text)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-26T00:38:20.249571Z","iopub.execute_input":"2025-07-26T00:38:20.250469Z","iopub.status.idle":"2025-07-26T00:38:33.616118Z","shell.execute_reply.started":"2025-07-26T00:38:20.250439Z","shell.execute_reply":"2025-07-26T00:38:33.61524Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Duplicate prompts\nprint(\"üîÅ Duplicate prompts:\", train_df[\"prompt\"].duplicated().sum())\n\n# Any samples where response_a and response_b are the same?\ntrain_df[\"is_same_response\"] = train_df[\"response_a\"] == train_df[\"response_b\"]\nprint(\"üü∞ Identical responses in train:\", train_df[\"is_same_response\"].sum())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-26T00:38:39.856474Z","iopub.execute_input":"2025-07-26T00:38:39.857681Z","iopub.status.idle":"2025-07-26T00:38:39.899172Z","shell.execute_reply.started":"2025-07-26T00:38:39.857641Z","shell.execute_reply":"2025-07-26T00:38:39.898399Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"prompt_counts = train_df[\"prompt\"].value_counts().to_dict()\ntrain_df[\"prompt_freq\"] = train_df[\"prompt\"].map(prompt_counts)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-26T00:38:50.275434Z","iopub.execute_input":"2025-07-26T00:38:50.276268Z","iopub.status.idle":"2025-07-26T00:38:50.40757Z","shell.execute_reply.started":"2025-07-26T00:38:50.276239Z","shell.execute_reply":"2025-07-26T00:38:50.406561Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Check the label distribution for identical responses\nidentical_rows = train_df[train_df[\"is_same_response\"] == True]\nprint(identical_rows[\"target\"].value_counts())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-26T00:38:56.272162Z","iopub.execute_input":"2025-07-26T00:38:56.272833Z","iopub.status.idle":"2025-07-26T00:38:56.285147Z","shell.execute_reply.started":"2025-07-26T00:38:56.272802Z","shell.execute_reply":"2025-07-26T00:38:56.284078Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# OPTION 1 ‚Äî Drop them (recommended)\ntrain_df = train_df[train_df[\"is_same_response\"] == False]\n\n# OPTION 2 ‚Äî Set winner to tie (less preferred)\n# train_df.loc[train_df[\"is_same_response\"] == True, \"target\"] = 2\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-26T00:39:07.766151Z","iopub.execute_input":"2025-07-26T00:39:07.766486Z","iopub.status.idle":"2025-07-26T00:39:07.804213Z","shell.execute_reply.started":"2025-07-26T00:39:07.76646Z","shell.execute_reply":"2025-07-26T00:39:07.803178Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Cosine similarity","metadata":{}},{"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.metrics.pairwise import cosine_similarity\n\n# Create pairwise TF-IDF vectors\ntfidf = TfidfVectorizer(stop_words='english', max_features=5000)\nresponse_pairs = train_df[\"response_a\"] + \" \" + train_df[\"response_b\"]\ntfidf_matrix = tfidf.fit_transform(response_pairs)\n\n# Compute cosine similarity between response_a and response_b\nresponse_a_vecs = tfidf.transform(train_df[\"response_a\"])\nresponse_b_vecs = tfidf.transform(train_df[\"response_b\"])\n\ntrain_df[\"cosine_sim\"] = [\n    cosine_similarity(response_a_vecs[i], response_b_vecs[i])[0][0]\n    for i in range(len(train_df))\n]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-26T00:39:16.722049Z","iopub.execute_input":"2025-07-26T00:39:16.722755Z","iopub.status.idle":"2025-07-26T00:40:24.272579Z","shell.execute_reply.started":"2025-07-26T00:39:16.722725Z","shell.execute_reply":"2025-07-26T00:40:24.271734Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Jaccard Similarity","metadata":{}},{"cell_type":"code","source":"def jaccard_similarity(str1, str2):\n    a = set(str1.lower().split())\n    b = set(str2.lower().split())\n    return len(a & b) / len(a | b)\n\ntrain_df[\"jaccard_sim\"] = train_df.apply(\n    lambda row: jaccard_similarity(row[\"response_a\"], row[\"response_b\"]), axis=1\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-26T00:40:40.546283Z","iopub.execute_input":"2025-07-26T00:40:40.546963Z","iopub.status.idle":"2025-07-26T00:40:45.177099Z","shell.execute_reply.started":"2025-07-26T00:40:40.546933Z","shell.execute_reply":"2025-07-26T00:40:45.175882Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# levenshtein ","metadata":{}},{"cell_type":"code","source":"import seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Only plot cosine and jaccard similarity\nfor col in [\"cosine_sim\", \"jaccard_sim\"]:\n    plt.figure(figsize=(8, 4))\n    sns.boxplot(x=train_df[\"target\"], y=train_df[col])\n    plt.title(f\"{col} by Target (0=A win, 1=B win, 2=Tie)\")\n    plt.xlabel(\"Target\")\n    plt.ylabel(\"Similarity\")\n    plt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-26T00:40:54.714722Z","iopub.execute_input":"2025-07-26T00:40:54.715764Z","iopub.status.idle":"2025-07-26T00:40:55.142901Z","shell.execute_reply.started":"2025-07-26T00:40:54.71573Z","shell.execute_reply":"2025-07-26T00:40:55.141819Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(train_df[[\"cosine_sim\", \"jaccard_sim\", \"target\"]].corr())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-26T00:41:09.243974Z","iopub.execute_input":"2025-07-26T00:41:09.244296Z","iopub.status.idle":"2025-07-26T00:41:09.257792Z","shell.execute_reply.started":"2025-07-26T00:41:09.244274Z","shell.execute_reply":"2025-07-26T00:41:09.256917Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Token overlap","metadata":{}},{"cell_type":"code","source":"def token_overlap(a, b):\n    set_a = set(str(a).lower().split())\n    set_b = set(str(b).lower().split())\n    return len(set_a & set_b)\n\ntrain_df[\"token_overlap_ab\"] = train_df.apply(lambda row: token_overlap(row[\"response_a\"], row[\"response_b\"]), axis=1)\ntrain_df[\"token_overlap_ap\"] = train_df.apply(lambda row: token_overlap(row[\"response_a\"], row[\"prompt\"]), axis=1)\ntrain_df[\"token_overlap_bp\"] = train_df.apply(lambda row: token_overlap(row[\"response_b\"], row[\"prompt\"]), axis=1)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-26T00:41:13.769221Z","iopub.execute_input":"2025-07-26T00:41:13.769852Z","iopub.status.idle":"2025-07-26T00:41:23.259989Z","shell.execute_reply.started":"2025-07-26T00:41:13.769826Z","shell.execute_reply":"2025-07-26T00:41:23.258981Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def normalized_token_overlap(a, b):\n    set_a = set(str(a).lower().split())\n    set_b = set(str(b).lower().split())\n    return len(set_a & set_b) / max(1, len(set_a | set_b))\n\ntrain_df[\"norm_overlap_ab\"] = train_df.apply(lambda row: normalized_token_overlap(row[\"response_a\"], row[\"response_b\"]), axis=1)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-26T00:41:33.714265Z","iopub.execute_input":"2025-07-26T00:41:33.7146Z","iopub.status.idle":"2025-07-26T00:41:38.445445Z","shell.execute_reply.started":"2025-07-26T00:41:33.714574Z","shell.execute_reply":"2025-07-26T00:41:38.44466Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"features = [\n    \"cosine_sim\",\n    \"jaccard_sim\",\n    \"token_overlap_ab\",\n    \"token_overlap_ap\",\n    \"token_overlap_bp\",\n    # Add more features here if you've created them\n]\nX = train_df[features]\ny = train_df[\"target\"]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-26T00:41:44.625211Z","iopub.execute_input":"2025-07-26T00:41:44.626065Z","iopub.status.idle":"2025-07-26T00:41:44.632288Z","shell.execute_reply.started":"2025-07-26T00:41:44.626036Z","shell.execute_reply":"2025-07-26T00:41:44.63162Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Boosting Model comprison","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nX_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-26T00:41:56.872703Z","iopub.execute_input":"2025-07-26T00:41:56.873017Z","iopub.status.idle":"2025-07-26T00:41:56.904967Z","shell.execute_reply.started":"2025-07-26T00:41:56.872994Z","shell.execute_reply":"2025-07-26T00:41:56.903908Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nfrom xgboost import XGBClassifier\nfrom catboost import CatBoostClassifier\nfrom lightgbm import LGBMClassifier\nfrom sklearn.metrics import accuracy_score\n\nmodels = {\n    \"RandomForest\": RandomForestClassifier(n_estimators=100, random_state=42),\n    \"XGBoost\": XGBClassifier(use_label_encoder=False, eval_metric='mlogloss', random_state=42),\n    \"CatBoost\": CatBoostClassifier(verbose=0, random_state=42),\n    \"LightGBM\": LGBMClassifier(random_state=42)\n}\n\nfor name, model in models.items():\n    model.fit(X_train, y_train)\n    preds = model.predict(X_valid)\n    acc = accuracy_score(y_valid, preds)\n    print(f\"{name} Accuracy: {acc:.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-26T00:42:07.008528Z","iopub.execute_input":"2025-07-26T00:42:07.008892Z","iopub.status.idle":"2025-07-26T00:42:39.550638Z","shell.execute_reply.started":"2025-07-26T00:42:07.008869Z","shell.execute_reply":"2025-07-26T00:42:39.549695Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(test_df.columns.tolist())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-26T00:42:44.045372Z","iopub.execute_input":"2025-07-26T00:42:44.045817Z","iopub.status.idle":"2025-07-26T00:42:44.050627Z","shell.execute_reply.started":"2025-07-26T00:42:44.045791Z","shell.execute_reply":"2025-07-26T00:42:44.049829Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nfrom lightgbm import LGBMClassifier\n\n# ‚úÖ Recreate feature columns for both train and test\ntrain_df[\"prompt_len\"] = train_df[\"prompt\"].str.len()\ntrain_df[\"response_a_len\"] = train_df[\"response_a\"].str.len()\ntrain_df[\"response_b_len\"] = train_df[\"response_b\"].str.len()\n\ntest_df[\"prompt_len\"] = test_df[\"prompt\"].str.len()\ntest_df[\"response_a_len\"] = test_df[\"response_a\"].str.len()\ntest_df[\"response_b_len\"] = test_df[\"response_b\"].str.len()\n\n# ‚úÖ Select feature columns\nfeatures = [\"prompt_len\", \"response_a_len\", \"response_b_len\"]\n\n# ‚úÖ Train model\nX_train = train_df[features]\ny_train = train_df[\"target\"]\nlgb_model = LGBMClassifier()\nlgb_model.fit(X_train, y_train)\n\n# ‚úÖ Predict\nX_test = test_df[features]\ny_test_preds = lgb_model.predict(X_test)\n\n# ‚úÖ Submission\nsubmission = pd.read_csv(\"/kaggle/input/llm-classification-finetuning/sample_submission.csv\")\nsubmission[\"target\"] = y_test_preds\nsubmission.to_csv(\"submission.csv\", index=False)\n\nprint(\"‚úÖ submission.csv saved and ready to submit.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-26T00:42:53.835308Z","iopub.execute_input":"2025-07-26T00:42:53.835643Z","iopub.status.idle":"2025-07-26T00:42:54.676417Z","shell.execute_reply.started":"2025-07-26T00:42:53.835598Z","shell.execute_reply":"2025-07-26T00:42:54.675365Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import accuracy_score\nfrom lightgbm import LGBMClassifier\nimport numpy as np\n\n# ‚úÖ Stratified K-Fold setup\nskf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\naccuracies = []\n\n# ‚úÖ Loop over each fold\nfor fold, (train_idx, val_idx) in enumerate(skf.split(X_train, y_train)):\n    print(f\"\\nüìÇ Fold {fold + 1}\")\n    \n    X_tr, X_val_fold = X_train.iloc[train_idx], X_train.iloc[val_idx]\n    y_tr, y_val_fold = y_train.iloc[train_idx], y_train.iloc[val_idx]\n    \n    model = LGBMClassifier()\n    model.fit(X_tr, y_tr)\n    \n    y_pred = model.predict(X_val_fold)\n    acc = accuracy_score(y_val_fold, y_pred)\n    print(f\"‚úÖ Accuracy: {acc:.4f}\")\n    accuracies.append(acc)\n\nprint(f\"\\nüéØ Mean Accuracy across folds: {np.mean(accuracies):.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-26T00:46:17.642128Z","iopub.execute_input":"2025-07-26T00:46:17.642771Z","iopub.status.idle":"2025-07-26T00:46:21.320176Z","shell.execute_reply.started":"2025-07-26T00:46:17.642742Z","shell.execute_reply":"2025-07-26T00:46:21.319133Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ‚úÖ Final model on full training data (using same 3 best features)\nfinal_model = LGBMClassifier()\nfinal_model.fit(X_train, y_train)\n\n# ‚úÖ Predict on test set\ny_test_preds = final_model.predict(X_test)\n\n# ‚úÖ Map predictions to class labels if needed (0, 1, 2 to column names)\nsubmission = pd.DataFrame({\n    \"id\": test_df[\"id\"],\n    \"prediction\": y_test_preds\n})\n\n# ‚úÖ Save to CSV\nsubmission.to_csv(\"/kaggle/working/submission.csv\", index=False)\nprint(\"üìÅ submission.csv saved!\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-26T00:48:29.697078Z","iopub.execute_input":"2025-07-26T00:48:29.698107Z","iopub.status.idle":"2025-07-26T00:48:30.46124Z","shell.execute_reply.started":"2025-07-26T00:48:29.698072Z","shell.execute_reply":"2025-07-26T00:48:30.460171Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# üîÅ Map class indices (0/1/2) to actual labels\nlabel_map = {0: \"model_a\", 1: \"model_b\", 2: \"tie\"}\ny_test_labels = [label_map[i] for i in y_test_preds]\n\n# ‚úÖ Prepare submission DataFrame\nsubmission = pd.DataFrame({\n    \"id\": test_df[\"id\"],\n    \"prediction\": y_test_labels\n})\n\n# ‚úÖ Save to correct CSV\nsubmission.to_csv(\"/kaggle/working/submission.csv\", index=False)\nprint(\"üìÅ Correct submission.csv saved with\", len(submission), \"rows\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-26T01:00:49.074164Z","iopub.execute_input":"2025-07-26T01:00:49.074505Z","iopub.status.idle":"2025-07-26T01:00:49.082994Z","shell.execute_reply.started":"2025-07-26T01:00:49.074481Z","shell.execute_reply":"2025-07-26T01:00:49.082045Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Keras NLP model","metadata":{}},{"cell_type":"markdown","source":"# Combine prompt, response_a and response_b into a single string\ntrain_df[\"text\"] = train_df[\"prompt\"] + \" [SEP] \" + train_df[\"response_a\"] + \" [SEP] \" + train_df[\"response_b\"]\ntest_df[\"text\"] = test_df[\"prompt\"] + \" [SEP] \" + test_df[\"response_a\"] + \" [SEP] \" + test_df[\"response_b\"]\n","metadata":{"execution":{"iopub.status.busy":"2025-07-24T23:37:35.889403Z","iopub.execute_input":"2025-07-24T23:37:35.88975Z","iopub.status.idle":"2025-07-24T23:37:36.183458Z","shell.execute_reply.started":"2025-07-24T23:37:35.889731Z","shell.execute_reply":"2025-07-24T23:37:36.18291Z"}}},{"cell_type":"markdown","source":"import keras_nlp\nimport tensorflow as tf\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.utils import to_categorical\n\n# Load tokenizer and backbone\npretrained_model_name = \"bert_base_en\"\npreprocessor = keras_nlp.models.BertPreprocessor.from_preset(pretrained_model_name)\nbackbone = keras_nlp.models.BertBackbone.from_preset(pretrained_model_name)\n","metadata":{"execution":{"iopub.status.busy":"2025-07-24T23:37:36.184176Z","iopub.execute_input":"2025-07-24T23:37:36.184378Z","iopub.status.idle":"2025-07-24T23:37:45.469658Z","shell.execute_reply.started":"2025-07-24T23:37:36.184363Z","shell.execute_reply":"2025-07-24T23:37:45.469088Z"}}},{"cell_type":"markdown","source":"# Combine text\ntrain_df[\"text\"] = train_df[\"prompt\"] + \" [SEP] \" + train_df[\"response_a\"] + \" [SEP] \" + train_df[\"response_b\"]\ntest_df[\"text\"] = test_df[\"prompt\"] + \" [SEP] \" + test_df[\"response_a\"] + \" [SEP] \" + test_df[\"response_b\"]\n\n# Tokenize inputs using preprocessor\ntrain_tokenized = preprocessor(tf.constant(train_df[\"text\"].tolist()))\ntest_tokenized = preprocessor(tf.constant(test_df[\"text\"].tolist()))\n","metadata":{}},{"cell_type":"markdown","source":"# Convert target\ntrain_df[\"target\"] = train_df[[\"winner_model_a\", \"winner_model_b\", \"winner_tie\"]].idxmax(axis=1).map({\n    \"winner_model_a\": 0,\n    \"winner_model_b\": 1,\n    \"winner_tie\": 2\n})\ny = to_categorical(train_df[\"target\"], num_classes=3)\n\n# Split on token_ids\nX_train, X_val, y_train, y_val = train_test_split(\n    train_tokenized[\"token_ids\"].numpy(), y, test_size=0.2, random_state=42\n)\n","metadata":{}},{"cell_type":"markdown","source":"# BERT \n**BERT (Bidirectional Encoder Representations from Transformers)** is a deep learning model developed by Google that understands the context of words in a sentence by looking at both the left and right sides (bidirectionally).\nIt uses a transformer architecture and is pre-trained on massive text data using tasks like masked language modeling.\nBERT can be fine-tuned for various NLP tasks such as classification, question answering, and sentiment analysis.\n","metadata":{}},{"cell_type":"markdown","source":"# Define 3 inputs as required by BERT\ninput_ids = tf.keras.Input(shape=(None,), dtype=tf.int32, name=\"token_ids\")\nsegment_ids = tf.keras.Input(shape=(None,), dtype=tf.int32, name=\"segment_ids\")\npadding_mask = tf.keras.Input(shape=(None,), dtype=tf.int32, name=\"padding_mask\")\n\n# Get BERT outputs\nbert_outputs = backbone({\n    \"token_ids\": input_ids,\n    \"segment_ids\": segment_ids,\n    \"padding_mask\": padding_mask\n})\n\n# Use pooled_output for classification\nx = tf.keras.layers.Dropout(0.2)(bert_outputs[\"pooled_output\"])\noutput = tf.keras.layers.Dense(3, activation=\"softmax\")(x)\n\n# Define model\nmodel = tf.keras.Model(\n    inputs={\"token_ids\": input_ids, \"segment_ids\": segment_ids, \"padding_mask\": padding_mask},\n    outputs=output\n)\n\nmodel.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\nmodel.summary()\n","metadata":{}},{"cell_type":"markdown","source":"from sklearn.model_selection import train_test_split\nfrom tensorflow.keras.utils import to_categorical\n\n# ‚úÖ One-hot encode target column\ny = train_df[\"target\"].values\ny_cat = to_categorical(y, num_classes=3)\n\n# ‚úÖ Extract individual arrays\ntoken_ids = train_tokenized[\"token_ids\"].numpy()\nsegment_ids = train_tokenized[\"segment_ids\"].numpy()\npadding_mask = train_tokenized[\"padding_mask\"].numpy()\n\n# ‚úÖ Print shapes\nprint(\"token_ids shape:\", token_ids.shape)\nprint(\"segment_ids shape:\", segment_ids.shape)\nprint(\"padding_mask shape:\", padding_mask.shape)\nprint(\"y_cat shape:\", y_cat.shape)  # Should be (57199, 3)\n\n# ‚úÖ Train/test split\nX_token_train, X_token_val, y_train, y_val = train_test_split(\n    token_ids, y_cat, test_size=0.2, random_state=42\n)\nX_seg_train, X_seg_val = train_test_split(segment_ids, test_size=0.2, random_state=42)\nX_pad_train, X_pad_val = train_test_split(padding_mask, test_size=0.2, random_state=42)\n\n# ‚úÖ Assemble input dictionaries\nX_train = {\n    \"token_ids\": X_token_train,\n    \"segment_ids\": X_seg_train,\n    \"padding_mask\": X_pad_train\n}\n\nX_val = {\n    \"token_ids\": X_token_val,\n    \"segment_ids\": X_seg_val,\n    \"padding_mask\": X_pad_val\n}\n","metadata":{"execution":{"iopub.status.busy":"2025-07-20T02:03:54.299419Z","iopub.execute_input":"2025-07-20T02:03:54.299968Z","iopub.status.idle":"2025-07-20T02:03:54.424629Z","shell.execute_reply.started":"2025-07-20T02:03:54.299943Z","shell.execute_reply":"2025-07-20T02:03:54.4237Z"}}},{"cell_type":"markdown","source":"import pandas as pd\nimport tensorflow as tf\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.utils import to_categorical\nimport keras_nlp\n\n# ‚úÖ Reload data\ntrain_df = pd.read_csv(\"/kaggle/input/llm-classification-finetuning/train.csv\")\n\n# ‚úÖ Target column from winner flags\ntrain_df[\"target\"] = train_df[[\"winner_model_a\", \"winner_model_b\", \"winner_tie\"]].idxmax(axis=1)\ntrain_df[\"target\"] = train_df[\"target\"].map({\"winner_model_a\": 0, \"winner_model_b\": 1, \"winner_tie\": 2})\n\n# ‚úÖ Join prompt and responses\ntexts = train_df[\"prompt\"] + \" [SEP] \" + train_df[\"response_a\"] + \" [SEP] \" + train_df[\"response_b\"]\ny_cat = to_categorical(train_df[\"target\"].values, num_classes=3)\n\n# ‚úÖ Use working model: bert_base_en_uncased\npreprocessor = keras_nlp.models.BertPreprocessor.from_preset(\"bert_base_en_uncased\", sequence_length=256)\nbackbone = keras_nlp.models.BertBackbone.from_preset(\"bert_base_en_uncased\")\ntokens = preprocessor(texts.tolist())\n\n# ‚úÖ Prepare inputs and split\nX = {k: tokens[k].numpy() for k in [\"token_ids\", \"segment_ids\", \"padding_mask\"]}\nX_train = {k: v[:45000] for k, v in X.items()}\nX_val = {k: v[45000:] for k, v in X.items()}\ny_train = y_cat[:45000]\ny_val = y_cat[45000:]\n\n# ‚úÖ Build model\ni1 = tf.keras.Input((256,), dtype=tf.int32, name=\"token_ids\")\ni2 = tf.keras.Input((256,), dtype=tf.int32, name=\"segment_ids\")\ni3 = tf.keras.Input((256,), dtype=tf.int32, name=\"padding_mask\")\nx = backbone({\"token_ids\": i1, \"segment_ids\": i2, \"padding_mask\": i3})[\"pooled_output\"]\nx = tf.keras.layers.Dropout(0.3)(x)\nout = tf.keras.layers.Dense(3, activation=\"softmax\")(x)\nmodel = tf.keras.Model(inputs=[i1, i2, i3], outputs=out)\nmodel.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n\n# ‚úÖ Train (small batch for memory)\nhistory = model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=2, batch_size=8)\n","metadata":{"execution":{"iopub.status.busy":"2025-07-20T02:01:38.371148Z","iopub.execute_input":"2025-07-20T02:01:38.371773Z","iopub.status.idle":"2025-07-20T02:03:51.308311Z","shell.execute_reply.started":"2025-07-20T02:01:38.371745Z","shell.execute_reply":"2025-07-20T02:03:51.307121Z"}}},{"cell_type":"markdown","source":"# kerasnlp takes lots of time and dont give best accurcy thats why i have to shift next model of transformer","metadata":{}},{"cell_type":"markdown","source":"# roberta-base model of transformer","metadata":{}},{"cell_type":"markdown","source":"from transformers import AutoTokenizer, TFAutoModelForSequenceClassification\n\nmodel_name = \"roberta-base\"\ntokenizer = AutoTokenizer.from_pretrained(model_name)\nmodel = TFAutoModelForSequenceClassification.from_pretrained(model_name, num_labels=3)\n","metadata":{"execution":{"iopub.status.busy":"2025-07-24T23:38:12.659371Z","iopub.execute_input":"2025-07-24T23:38:12.659616Z","iopub.status.idle":"2025-07-24T23:38:24.545239Z","shell.execute_reply.started":"2025-07-24T23:38:12.659591Z","shell.execute_reply":"2025-07-24T23:38:24.544698Z"}}},{"cell_type":"markdown","source":"from transformers import create_optimizer\n\n# ‚úÖ Set training details\nbatch_size = 16\nnum_epochs = 3\n\n# üîÅ Set number of training steps\nsteps_per_epoch = len(y_train) // batch_size\n\n# ‚úÖ Create HuggingFace-compatible optimizer\noptimizer, _ = create_optimizer(\n    init_lr=2e-5,\n    num_train_steps=steps_per_epoch * num_epochs,\n    num_warmup_steps=0\n)\n\n# ‚úÖ Compile the model\nmodel.compile(\n    optimizer=optimizer,\n    loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n    metrics=[\"accuracy\"]\n)\n","metadata":{"execution":{"iopub.status.busy":"2025-07-24T23:38:24.546024Z","iopub.execute_input":"2025-07-24T23:38:24.546239Z","iopub.status.idle":"2025-07-24T23:38:25.318628Z","shell.execute_reply.started":"2025-07-24T23:38:24.546222Z","shell.execute_reply":"2025-07-24T23:38:25.317843Z"}}},{"cell_type":"markdown","source":"texts = train_df[\"prompt\"] + \" \" + train_df[\"response_a\"] + \" \" + train_df[\"response_b\"]\n","metadata":{"execution":{"iopub.status.busy":"2025-07-20T01:41:51.073714Z","iopub.execute_input":"2025-07-20T01:41:51.074037Z","iopub.status.idle":"2025-07-20T01:41:51.091246Z","shell.execute_reply.started":"2025-07-20T01:41:51.074014Z","shell.execute_reply":"2025-07-20T01:41:51.090375Z"}}},{"cell_type":"markdown","source":"from transformers import AutoTokenizer\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.utils import to_categorical\n\n# ‚úÖ Step 1: Create input texts\ntexts = train_df[\"prompt\"] + \" \" + train_df[\"response_a\"] + \" \" + train_df[\"response_b\"]\n\n# ‚úÖ Step 2: Target labels (0=model_a, 1=model_b, 2=tie)\ny = train_df[\"target\"].values\ny_cat = to_categorical(y, num_classes=3)\n\n# ‚úÖ Step 3: Tokenize using HuggingFace\ntokenizer = AutoTokenizer.from_pretrained(\"roberta-base\")\ntokens = tokenizer(\n    texts.tolist(),\n    padding=\"max_length\",\n    truncation=True,\n    max_length=256,\n    return_tensors=\"np\"  # ‚úÖ convert directly to NumPy for sklearn compatibility\n)\n\n# ‚úÖ Step 4: Train/Val Split\nX_token_train, X_token_val, X_pad_train, X_pad_val, y_train, y_val = train_test_split(\n    tokens[\"input_ids\"], tokens[\"attention_mask\"], y_cat,\n    test_size=0.2, random_state=42\n)\n\n# ‚úÖ Step 5: Format for HuggingFace TF models\nX_train = {\n    \"input_ids\": X_token_train,\n    \"attention_mask\": X_pad_train\n}\nX_val = {\n    \"input_ids\": X_token_val,\n    \"attention_mask\": X_pad_val\n}\n","metadata":{"execution":{"iopub.status.busy":"2025-07-24T23:38:25.319527Z","iopub.execute_input":"2025-07-24T23:38:25.319835Z","iopub.status.idle":"2025-07-24T23:39:12.389315Z","shell.execute_reply.started":"2025-07-24T23:38:25.319814Z","shell.execute_reply":"2025-07-24T23:39:12.388464Z"}}},{"cell_type":"markdown","source":"from transformers import TFRobertaForSequenceClassification\nfrom transformers import create_optimizer\nimport tensorflow as tf\n\n# ‚úÖ Step 1: Load model (Roberta-base for 3-class classification)\nmodel = TFRobertaForSequenceClassification.from_pretrained(\"roberta-base\", num_labels=3)\n\n# ‚úÖ Step 2: Create optimizer with learning rate warmup\nbatch_size = 16\nnum_epochs = 2\nsteps_per_epoch = len(X_train[\"input_ids\"]) // batch_size\ntotal_train_steps = steps_per_epoch * num_epochs\n\noptimizer, schedule = create_optimizer(\n    init_lr=2e-5,\n    num_train_steps=total_train_steps,\n    num_warmup_steps=0\n)\n\n# ‚úÖ Step 3: Compile the model\nmodel.compile(\n    optimizer=optimizer,\n    loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n    metrics=[\"accuracy\"]\n)\n\n# ‚úÖ Step 4: Train the model\nhistory = model.fit(\n    X_train, y_train,\n    validation_data=(X_val, y_val),\n    epochs=num_epochs,\n    batch_size=batch_size\n)\n","metadata":{"execution":{"iopub.status.busy":"2025-07-24T23:39:12.392982Z","iopub.execute_input":"2025-07-24T23:39:12.393188Z"}}},{"cell_type":"markdown","source":"# resulsts\n i run boosting models and compare but lightGBM give best results then kerasNLP and TFReborta these models takes lots of time but low accurcy also have overfitnig problems if pc is best increase epoch,reuglrization and early stoping techniques to avoid overfit,","metadata":{}}]}