{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":86518,"databundleVersionId":9809560,"sourceType":"competition"},{"sourceId":6063,"sourceType":"modelInstanceVersion","modelInstanceId":4684,"modelId":2820}],"dockerImageVersionId":30840,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nos.environ[\"KERAS_BACKEND\"] = \"jax\"  # or \"tensorflow\" or \"torch\"\n\nimport keras_nlp\nimport keras\nimport tensorflow as tf\n\nimport numpy as np \nimport pandas as pd\nfrom tqdm import tqdm\nimport json\n\nimport matplotlib.pyplot as plt\nimport matplotlib as mpl\nimport plotly.express as px","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-01-15T20:44:12.714912Z","iopub.execute_input":"2025-01-15T20:44:12.715183Z","iopub.status.idle":"2025-01-15T20:44:31.672081Z","shell.execute_reply.started":"2025-01-15T20:44:12.715156Z","shell.execute_reply":"2025-01-15T20:44:31.670845Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"TensorFlow:\", tf.__version__)\nprint(\"Keras:\", keras.__version__)\nprint(\"KerasNLP:\", keras_nlp.__version__)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-15T20:56:21.868381Z","iopub.execute_input":"2025-01-15T20:56:21.869158Z","iopub.status.idle":"2025-01-15T20:56:21.879932Z","shell.execute_reply.started":"2025-01-15T20:56:21.869117Z","shell.execute_reply":"2025-01-15T20:56:21.878666Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class CFG:\n    seed = 42  # Random seed\n    preset = \"deberta_v3_extra_small_en\" # Name of pretrained models\n    sequence_length = 512  # Input sequence length\n    epochs = 3 # Training epochs\n    batch_size = 16  # Batch size\n    scheduler = 'cosine'  # Learning rate scheduler\n    label2name = {0: 'winner_model_a', 1: 'winner_model_b', 2: 'winner_tie'}\n    name2label = {v:k for k, v in label2name.items()}\n    class_labels = list(label2name.keys())\n    class_names = list(label2name.values())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-15T20:57:09.004343Z","iopub.execute_input":"2025-01-15T20:57:09.0048Z","iopub.status.idle":"2025-01-15T20:57:09.015224Z","shell.execute_reply.started":"2025-01-15T20:57:09.004753Z","shell.execute_reply":"2025-01-15T20:57:09.013847Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"keras.utils.set_random_seed(CFG.seed)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-15T21:04:58.28211Z","iopub.execute_input":"2025-01-15T21:04:58.282586Z","iopub.status.idle":"2025-01-15T21:04:58.287989Z","shell.execute_reply.started":"2025-01-15T21:04:58.282551Z","shell.execute_reply":"2025-01-15T21:04:58.286426Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"keras.mixed_precision.set_global_policy(\"mixed_float16\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-15T21:05:45.618537Z","iopub.execute_input":"2025-01-15T21:05:45.618996Z","iopub.status.idle":"2025-01-15T21:05:45.625045Z","shell.execute_reply.started":"2025-01-15T21:05:45.618961Z","shell.execute_reply":"2025-01-15T21:05:45.623034Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"BASE_PATH = '/kaggle/input/llm-classification-finetuning'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-15T21:06:22.45222Z","iopub.execute_input":"2025-01-15T21:06:22.452665Z","iopub.status.idle":"2025-01-15T21:06:22.45786Z","shell.execute_reply.started":"2025-01-15T21:06:22.452631Z","shell.execute_reply":"2025-01-15T21:06:22.456354Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Load Train Data\ndf = pd.read_csv(f'{BASE_PATH}/train.csv') \n\n# Sample data\n# df = df.sample(frac=0.10)\n\n# Take the first prompt and its associated response\ndf[\"prompt\"] = df.prompt.map(lambda x: eval(x)[0])\ndf[\"response_a\"] = df.response_a.map(lambda x: eval(x.replace(\"null\",\"''\"))[0])\ndf[\"response_b\"] = df.response_b.map(lambda x: eval(x.replace(\"null\", \"''\"))[0])\n\n# Label conversion\ndf[\"class_name\"] = df[[\"winner_model_a\", \"winner_model_b\" , \"winner_tie\"]].idxmax(axis=1)\ndf[\"class_label\"] = df.class_name.map(CFG.name2label)\n\n# Show Sample\ndf.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-15T22:00:16.516017Z","iopub.execute_input":"2025-01-15T22:00:16.516397Z","iopub.status.idle":"2025-01-15T22:00:22.71926Z","shell.execute_reply.started":"2025-01-15T22:00:16.516369Z","shell.execute_reply":"2025-01-15T22:00:22.718311Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Load Test Data\ntest_df = pd.read_csv(f'{BASE_PATH}/test.csv')\n\n# Take the first prompt and response\ntest_df[\"prompt\"] = test_df.prompt.map(lambda x: eval(x)[0])\ntest_df[\"response_a\"] = test_df.response_a.map(lambda x: eval(x.replace(\"null\",\"''\"))[0])\ntest_df[\"response_b\"] = test_df.response_b.map(lambda x: eval(x.replace(\"null\", \"''\"))[0])\n\n# Show Sample\ntest_df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-15T22:01:02.230143Z","iopub.execute_input":"2025-01-15T22:01:02.230648Z","iopub.status.idle":"2025-01-15T22:01:02.254968Z","shell.execute_reply.started":"2025-01-15T22:01:02.230608Z","shell.execute_reply":"2025-01-15T22:01:02.253451Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Define a function to create options based on the prompt and choices\ndef make_pairs(row):\n    row[\"encode_fail\"] = False\n    try:\n        prompt = row.prompt.encode(\"utf-8\").decode(\"utf-8\")\n    except:\n        prompt = \"\"\n        row[\"encode_fail\"] = True\n\n    try:\n        response_a = row.response_a.encode(\"utf-8\").decode(\"utf-8\")\n    except:\n        response_a = \"\"\n        row[\"encode_fail\"] = True\n\n    try:\n        response_b = row.response_b.encode(\"utf-8\").decode(\"utf-8\")\n    except:\n        response_b = \"\"\n        row[\"encode_fail\"] = True\n        \n    row['options'] = [f\"Prompt: {prompt}\\n\\nResponse: {response_a}\",  # Response from Model A\n                      f\"Prompt: {prompt}\\n\\nResponse: {response_b}\"  # Response from Model B\n                     ]\n    return row","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-15T22:07:25.57853Z","iopub.execute_input":"2025-01-15T22:07:25.579109Z","iopub.status.idle":"2025-01-15T22:07:25.587237Z","shell.execute_reply.started":"2025-01-15T22:07:25.579068Z","shell.execute_reply":"2025-01-15T22:07:25.585674Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df = df.apply(make_pairs, axis=1)  # Apply the make_pairs function to each row in df\ndisplay(df.head(2))  # Display the first 2 rows of df\n\ntest_df = test_df.apply(make_pairs, axis=1)  # Apply the make_pairs function to each row in df\ndisplay(test_df.head(2))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-15T22:17:57.352683Z","iopub.execute_input":"2025-01-15T22:17:57.353117Z","iopub.status.idle":"2025-01-15T22:19:03.110705Z","shell.execute_reply.started":"2025-01-15T22:17:57.353085Z","shell.execute_reply":"2025-01-15T22:19:03.109474Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df.encode_fail.value_counts(normalize=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-15T22:20:23.440902Z","iopub.execute_input":"2025-01-15T22:20:23.441325Z","iopub.status.idle":"2025-01-15T22:20:23.45871Z","shell.execute_reply.started":"2025-01-15T22:20:23.441297Z","shell.execute_reply":"2025-01-15T22:20:23.457513Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split  # Import package\n\ntrain_df, valid_df = train_test_split(df, test_size=0.2, stratify=df[\"class_label\"])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-15T22:23:35.492691Z","iopub.execute_input":"2025-01-15T22:23:35.49394Z","iopub.status.idle":"2025-01-15T22:23:35.625747Z","shell.execute_reply.started":"2025-01-15T22:23:35.493889Z","shell.execute_reply":"2025-01-15T22:23:35.624478Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"preprocessor = keras_nlp.models.DebertaV3Preprocessor.from_preset(\n    preset=CFG.preset, # Name of the model\n    sequence_length=CFG.sequence_length, # Max sequence length, will be padded if shorter\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-15T22:29:54.926195Z","iopub.execute_input":"2025-01-15T22:29:54.926733Z","iopub.status.idle":"2025-01-15T22:29:59.601861Z","shell.execute_reply.started":"2025-01-15T22:29:54.92669Z","shell.execute_reply":"2025-01-15T22:29:59.60071Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"outs = preprocessor(df.options.iloc[0])  # Process options for the first row\n\n# Display the shape of each processed output\nfor k, v in outs.items():\n    print(k, \":\", v.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-15T22:32:35.97748Z","iopub.execute_input":"2025-01-15T22:32:35.978035Z","iopub.status.idle":"2025-01-15T22:32:37.128871Z","shell.execute_reply.started":"2025-01-15T22:32:35.977999Z","shell.execute_reply":"2025-01-15T22:32:37.127777Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def preprocess_fn(text, label=None):\n    text = preprocessor(text)  # Preprocess text\n    return (text, label) if label is not None else text  # Return processed text and label if available","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-15T22:33:08.069705Z","iopub.execute_input":"2025-01-15T22:33:08.070111Z","iopub.status.idle":"2025-01-15T22:33:08.075515Z","shell.execute_reply.started":"2025-01-15T22:33:08.070079Z","shell.execute_reply":"2025-01-15T22:33:08.074158Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def build_dataset(texts, labels=None, batch_size=32,\n                  cache=True, shuffle=1024):\n    AUTO = tf.data.AUTOTUNE  # AUTOTUNE option\n    slices = (texts,) if labels is None else (texts, keras.utils.to_categorical(labels, num_classes=3))  # Create slices\n    ds = tf.data.Dataset.from_tensor_slices(slices)  # Create dataset from slices\n    ds = ds.cache() if cache else ds  # Cache dataset if enabled\n    ds = ds.map(preprocess_fn, num_parallel_calls=AUTO)  # Map preprocessing function\n    opt = tf.data.Options()  # Create dataset options\n    if shuffle: \n        ds = ds.shuffle(shuffle, seed=CFG.seed)  # Shuffle dataset if enabled\n        opt.experimental_deterministic = False\n    ds = ds.with_options(opt)  # Set dataset options\n    ds = ds.batch(batch_size, drop_remainder=False)  # Batch dataset\n    ds = ds.prefetch(AUTO)  # Prefetch next batch\n    return ds  # Return the built dataset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-15T23:32:40.665078Z","iopub.execute_input":"2025-01-15T23:32:40.665584Z","iopub.status.idle":"2025-01-15T23:32:40.673232Z","shell.execute_reply.started":"2025-01-15T23:32:40.665549Z","shell.execute_reply":"2025-01-15T23:32:40.671753Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Train\ntrain_texts = train_df.options.tolist()  # Extract training texts\ntrain_labels = train_df.class_label.tolist()  # Extract training labels\ntrain_ds = build_dataset(train_texts, train_labels,\n                         batch_size=CFG.batch_size,\n                         shuffle=True)\n\n# Valid\nvalid_texts = valid_df.options.tolist()  # Extract validation texts\nvalid_labels = valid_df.class_label.tolist()  # Extract validation labels\nvalid_ds = build_dataset(valid_texts, valid_labels,\n                         batch_size=CFG.batch_size,\n                         shuffle=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-15T23:33:10.631588Z","iopub.execute_input":"2025-01-15T23:33:10.631977Z","iopub.status.idle":"2025-01-15T23:33:15.116124Z","shell.execute_reply.started":"2025-01-15T23:33:10.631947Z","shell.execute_reply":"2025-01-15T23:33:15.11497Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import math\n\ndef get_lr_callback(batch_size=8, mode='cos', epochs=10, plot=False):\n    lr_start, lr_max, lr_min = 1.0e-6, 0.6e-6 * batch_size, 1e-6\n    lr_ramp_ep, lr_sus_ep, lr_decay = 2, 0, 0.8\n\n    def lrfn(epoch):  # Learning rate update function\n        if epoch < lr_ramp_ep: lr = (lr_max - lr_start) / lr_ramp_ep * epoch + lr_start\n        elif epoch < lr_ramp_ep + lr_sus_ep: lr = lr_max\n        elif mode == 'exp': lr = (lr_max - lr_min) * lr_decay**(epoch - lr_ramp_ep - lr_sus_ep) + lr_min\n        elif mode == 'step': lr = lr_max * lr_decay**((epoch - lr_ramp_ep - lr_sus_ep) // 2)\n        elif mode == 'cos':\n            decay_total_epochs, decay_epoch_index = epochs - lr_ramp_ep - lr_sus_ep + 3, epoch - lr_ramp_ep - lr_sus_ep\n            phase = math.pi * decay_epoch_index / decay_total_epochs\n            lr = (lr_max - lr_min) * 0.5 * (1 + math.cos(phase)) + lr_min\n        return lr\n\n    if plot:  # Plot lr curve if plot is True\n        plt.figure(figsize=(10, 5))\n        plt.plot(np.arange(epochs), [lrfn(epoch) for epoch in np.arange(epochs)], marker='o')\n        plt.xlabel('epoch'); plt.ylabel('lr')\n        plt.title('LR Scheduler')\n        plt.show()\n\n    return keras.callbacks.LearningRateScheduler(lrfn, verbose=False)  # Create lr callback\nlr_cb = get_lr_callback(CFG.batch_size, plot=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-15T23:34:14.18181Z","iopub.execute_input":"2025-01-15T23:34:14.182319Z","iopub.status.idle":"2025-01-15T23:34:14.600163Z","shell.execute_reply.started":"2025-01-15T23:34:14.182284Z","shell.execute_reply":"2025-01-15T23:34:14.598036Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"ckpt_cb = keras.callbacks.ModelCheckpoint(f'best_model.weights.h5',\n                                          monitor='val_log_loss',\n                                          save_best_only=True,\n                                          save_weights_only=True,\n                                          mode='min')  # Get Model checkpoint callback","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-15T23:34:40.270776Z","iopub.execute_input":"2025-01-15T23:34:40.271171Z","iopub.status.idle":"2025-01-15T23:34:40.276839Z","shell.execute_reply.started":"2025-01-15T23:34:40.271142Z","shell.execute_reply":"2025-01-15T23:34:40.275307Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"log_loss = keras.metrics.CategoricalCrossentropy(name=\"log_loss\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-15T23:34:58.951583Z","iopub.execute_input":"2025-01-15T23:34:58.952071Z","iopub.status.idle":"2025-01-15T23:34:58.996681Z","shell.execute_reply.started":"2025-01-15T23:34:58.952025Z","shell.execute_reply":"2025-01-15T23:34:58.995431Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"inputs = {\n    \"token_ids\": keras.Input(shape=(2, None), dtype=tf.int32, name=\"token_ids\"),\n    \"padding_mask\": keras.Input(shape=(2, None), dtype=tf.int32, name=\"padding_mask\"),\n}\n# Create a DebertaV3Classifier backbone\nbackbone = keras_nlp.models.DebertaV3Backbone.from_preset(\n    CFG.preset,\n)\n\n# Compute embeddings for first response: (P + R_A) using backbone\nresponse_a = {k: v[:, 0, :] for k, v in inputs.items()}\nembed_a = backbone(response_a)\n\n# Compute embeddings for second response: (P + R_B), using the same backbone\nresponse_b = {k: v[:, 1, :] for k, v in inputs.items()}\nembed_b = backbone(response_b)\n\n# Compute final output\nembeds = keras.layers.Concatenate(axis=-1)([embed_a, embed_b])\nembeds = keras.layers.GlobalAveragePooling1D()(embeds)\noutputs = keras.layers.Dense(3, activation=\"softmax\", name=\"classifier\")(embeds)\nmodel = keras.Model(inputs, outputs)\n\n# Compile the model with optimizer, loss, and metrics\nmodel.compile(\n    optimizer=keras.optimizers.Adam(5e-6),\n    loss=keras.losses.CategoricalCrossentropy(label_smoothing=0.02),\n    metrics=[\n        log_loss,\n        keras.metrics.CategoricalAccuracy(name=\"accuracy\"),\n    ],\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-15T23:35:41.650386Z","iopub.execute_input":"2025-01-15T23:35:41.650948Z","iopub.status.idle":"2025-01-15T23:35:50.52508Z","shell.execute_reply.started":"2025-01-15T23:35:41.650896Z","shell.execute_reply":"2025-01-15T23:35:50.523895Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model.summary()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-15T23:35:58.914449Z","iopub.execute_input":"2025-01-15T23:35:58.91484Z","iopub.status.idle":"2025-01-15T23:35:58.949737Z","shell.execute_reply.started":"2025-01-15T23:35:58.91481Z","shell.execute_reply":"2025-01-15T23:35:58.948456Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Start training the model\nhistory = model.fit(\n    train_ds,\n    epochs=CFG.epochs,\n    validation_data=valid_ds,\n    callbacks=[lr_cb, ckpt_cb]\n)","metadata":{"trusted":true,"execution":{"execution_failed":"2025-01-16T01:06:57.347Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model.load_weights('/kaggle/working/best_model.weights.h5')","metadata":{"trusted":true,"execution":{"execution_failed":"2025-01-16T01:06:57.346Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Build test dataset\ntest_texts = test_df.options.tolist()\ntest_ds = build_dataset(test_texts,\n                         batch_size=min(len(test_df), CFG.batch_size),\n                         shuffle=False)","metadata":{"trusted":true,"execution":{"execution_failed":"2025-01-16T01:06:57.347Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Make predictions using the trained model on test data\ntest_preds = model.predict(test_ds, verbose=1)","metadata":{"trusted":true,"execution":{"execution_failed":"2025-01-16T01:06:57.347Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"sub_df = test_df[[\"id\"]].copy()\nsub_df[CFG.class_names] = test_preds.tolist()\nsub_df.to_csv(\"submission.csv\", index=False)\nsub_df.head()","metadata":{"trusted":true,"execution":{"execution_failed":"2025-01-16T01:06:57.347Z"}},"outputs":[],"execution_count":null}]}