{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":86518,"databundleVersionId":9809560,"isSourceIdPinned":false,"sourceType":"competition"},{"sourceId":261,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":174,"modelId":17}],"dockerImageVersionId":31012,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"pip install keras tensorflow pandas","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-27T18:43:55.78053Z","iopub.execute_input":"2025-06-27T18:43:55.780912Z","iopub.status.idle":"2025-06-27T18:44:02.363138Z","shell.execute_reply.started":"2025-06-27T18:43:55.780859Z","shell.execute_reply":"2025-06-27T18:44:02.361193Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install textblob","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-27T18:44:56.59509Z","iopub.execute_input":"2025-06-27T18:44:56.596359Z","iopub.status.idle":"2025-06-27T18:45:00.983516Z","shell.execute_reply.started":"2025-06-27T18:44:56.596308Z","shell.execute_reply":"2025-06-27T18:45:00.981713Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-06-27T18:47:24.218581Z","iopub.execute_input":"2025-06-27T18:47:24.219283Z","iopub.status.idle":"2025-06-27T18:47:24.67123Z","shell.execute_reply.started":"2025-06-27T18:47:24.219238Z","shell.execute_reply":"2025-06-27T18:47:24.67011Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"BASE_PATH = '/kaggle/input/llm-classification-finetuning'\ntest_data = pd.read_csv(f'{BASE_PATH}/test.csv')\ntrain_data = pd.read_csv(f'{BASE_PATH}/train.csv')\n\ntrain_data.head()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-27T18:47:39.84208Z","iopub.execute_input":"2025-06-27T18:47:39.843506Z","iopub.status.idle":"2025-06-27T18:47:44.772347Z","shell.execute_reply.started":"2025-06-27T18:47:39.843465Z","shell.execute_reply":"2025-06-27T18:47:44.771001Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(train_data['prompt'].dtype)\nprint(train_data['response_a'].dtype)\nprint(train_data['response_b'].dtype)\n\ntrain_data['prompt'] = train_data['prompt'].astype('string')\ntrain_data['response_a'] = train_data['response_a'].astype('string')\ntrain_data['response_b'] = train_data['response_b'].astype('string')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-27T18:48:51.421821Z","iopub.execute_input":"2025-06-27T18:48:51.423192Z","iopub.status.idle":"2025-06-27T18:48:51.460804Z","shell.execute_reply.started":"2025-06-27T18:48:51.423135Z","shell.execute_reply":"2025-06-27T18:48:51.459694Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import keras\nimport keras_hub\nimport numpy as np\nimport tensorflow as tf\nimport re\nfrom textblob import TextBlob\nfrom textblob.np_extractors import ConllExtractor\nfrom textblob.sentiments import NaiveBayesAnalyzer\nfrom textblob import TextBlob\n\nimport re\n\n# Custom disagreement word list (you can expand this)\nDISAGREEMENT_WORDS = [\n    \"no\", \"never\", \"wrong\", \"incorrect\", \"false\", \"not at all\", \"absolutely not\",\n    \"unacceptable\", \"nonsense\", \"ridiculous\", \"invalid\", \"absurd\", \"flawed\", \"misleading\",\n    \"inaccurate\", \"but\", \"however\", \"although\", \"though\", \"yet\", \"still\", \"instead\",\n    \"whereas\", \"nonetheless\", \"dislike\", \"hate\", \"oppose\", \"reject\", \"dispute\", \"disagree\",\n    \"criticize\", \"complain\", \"challenge\", \"resist\", \"object\", \"deny\", \"doubtful\",\n    \"questionable\", \"unclear\", \"unsure\", \"maybe not\", \"possibly wrong\", \"doesn’t seem right\",\n    \"suspicious\", \"sure...\", \"wow\", \"seriously?\", \"really?\", \"whatever\", \"cool story\",\n    \"if you say so\", \"I guess\", \"I don’t think so\", \"I don’t agree\", \"That’s not true\",\n    \"That doesn’t make sense\", \"I beg to differ\", \"That’s debatable\", \"That's incorrect\"\n]\n\ndef disagrability_score(text):\n    blob = TextBlob(text.lower())\n\n    # Count disagreement words/phrases\n    dis_words_found = [word for word in DISAGREEMENT_WORDS if word in text.lower()]\n    disagreement_count = len(dis_words_found)\n    return disagreement_count/(len(blob))\n\n\ndef is_code(text: str) -> bool:\n    if not isinstance(text, str) or len(text.strip()) == 0:\n        return False  # Ignore non-strings or empty text\n\n    code_patterns = [\n        r\"\\bdef\\b\", r\"\\bclass\\b\", r\"\\bimport\\b\",              # Python\n        r\"\\bpublic\\b|\\bprivate\\b|\\bstatic\\b|\\bnew\\b\",         # Java/C++\n        r\"#include\\s*<.*>\", r\"::\", r\";\\s*$\",                  # C/C++\n        r\"console\\.log\", r\"System\\.out\\.println\",             # JS/Java\n        r\"<\\/?\\w+>\",                                          # HTML/XML tags\n        r\"\\bfunction\\b\", r\"\\bvar\\b\", r\"\\bconst\\b\", r\"=>\",     # JS\n        r\"\\s{4,}\\w+\",                                         # Indented lines\n        r\"\\{[\\s\\S]*?\\}\",                                      # Curly-brace blocks\n        r\"=\\s*[^=]\",                                          # Assignment ops\n        r\"\\n.*\\n.*\\n\",                                        # Multiline blocks\n        r\"\\$\\(\", r\"\\bprint\\s*\\(\",                             # Bash, Python\n        r\"^\\s*#.*$\",                                          # Comments\n        r\"\\breturn\\b\", r\"\\btry\\b\", r\"\\bcatch\\b\",              # Control flow\n        r\"translate\",\n    ]\n\n    match_count = sum(bool(re.search(pattern, text, flags=re.MULTILINE)) for pattern in code_patterns)\n    \n    return match_count >= 1  # Adjustable threshold\n\n\nextractor = ConllExtractor()\n\ndef count_syllables(word):\n    word = word.lower()\n    vowels = \"aeiouy\"\n    syllables = 0\n    prev_char_was_vowel = False\n    for char in word:\n        if char in vowels:\n            if not prev_char_was_vowel:\n                syllables += 1\n            prev_char_was_vowel = True\n        else:\n            prev_char_was_vowel = False\n    if word.endswith(\"e\"):\n        syllables = max(1, syllables - 1)\n    return max(1, syllables)\n\ndef readability_scores(text):\n    # split sentences and words\n    sentences = [s for s in re.split(r'[.!?]+', text) if s.strip()]\n    words = re.findall(r'\\w+', text)\n    \n    # ensure no zero counts\n    num_sentences = max(1, len(sentences))\n    num_words     = max(1, len(words))\n    \n    # count syllables\n    syllable_count = sum(count_syllables(w) for w in words)\n    \n    # Flesch Reading Ease (0–100+)\n    fre = (\n        206.835\n        - 1.015 * (num_words / num_sentences)\n        - 84.6  * (syllable_count / num_words)\n    )\n    # return normalized 0–1 score\n    return fre / 100.0\n\ndef find_relevance(A,B):\n    blob = TextBlob(A,np_extractor=extractor)\n    prompt=blob.noun_phrases\n    \n    blob = TextBlob(B, np_extractor=extractor)\n    response=blob.noun_phrases\n    \n    set2= set(response)\n\n    if not prompt:\n        return 0.0\n    \n    not_in_list=[word for word in prompt if word not in set2]\n    \n    percent = (len(not_in_list) / len(prompt))\n    return (1-percent)\n\ndef sentiment(A):\n    text=str(A)\n    blob=TextBlob(A)\n    return blob.sentiment.polarity\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-27T22:05:55.584745Z","iopub.execute_input":"2025-06-27T22:05:55.584983Z","iopub.status.idle":"2025-06-27T22:06:17.321545Z","shell.execute_reply.started":"2025-06-27T22:05:55.584961Z","shell.execute_reply":"2025-06-27T22:06:17.320624Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"inputs = []\ntokenized_winner_model = []\n\n## Reducing the size the dataset to optimize the encoding process\nfor i in range(len(train_data)):\n    inputa = np.zeros(5)\n\n    inputa[0] = (find_relevance(train_data['prompt'].iloc[i],train_data['response_a'].iloc[i])-find_relevance(train_data['prompt'].iloc[i],train_data['response_b'].iloc[i]))\n    inputa[1] = (readability_scores(train_data['response_a'].iloc[i])-readability_scores(train_data['response_b'].iloc[i]))\n    inputa[2] = (len(train_data['response_a'].iloc[i])/len((train_data['response_b'].iloc[i])))\n    inputa[3] = (sentiment((train_data['response_a'].iloc[i]))-sentiment((train_data['response_b'].iloc[i])))\n    inputa[4] = (disagrability_score(train_data['response_a'].iloc[i]))-(disagrability_score(train_data['response_b'].iloc[i]))\n\n    if not is_code(train_data['response_a'].iloc[i]) and not is_code(train_data['response_b'].iloc[i]):\n        inputs.append(inputa)\n        \n        if train_data['winner_model_a'].iloc[i]==1:\n            tokenized_winner_model.append(0)\n        elif train_data['winner_model_b'].iloc[i]==1:\n            tokenized_winner_model.append(1)\n        else:\n            tokenized_winner_model.append(2)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-27T18:51:07.666013Z","iopub.execute_input":"2025-06-27T18:51:07.666497Z","iopub.status.idle":"2025-06-27T19:03:59.165149Z","shell.execute_reply.started":"2025-06-27T18:51:07.666466Z","shell.execute_reply":"2025-06-27T19:03:59.164005Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print (len(tokenized_winner_model))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-27T19:23:13.9458Z","iopub.execute_input":"2025-06-27T19:23:13.946397Z","iopub.status.idle":"2025-06-27T19:23:13.953916Z","shell.execute_reply.started":"2025-06-27T19:23:13.946365Z","shell.execute_reply":"2025-06-27T19:23:13.95237Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.layers import Input, Dense, Concatenate, Flatten\nfrom tensorflow.keras.models import Model, Sequential\nfrom tensorflow.keras.callbacks import LearningRateScheduler\nimport numpy as np\nimport tensorflow as tf\n\ninitial_learning_rate = 0.00001\nlr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n    initial_learning_rate,\n    decay_steps=1000,        # after how many steps to decay\n    decay_rate=0.96,         # multiply learning rate by this amount\n    staircase=True           # whether to apply decay in discrete steps\n)\n\noptimizer = tf.keras.optimizers.Adam(learning_rate=lr_schedule)\n\n\n# === INPUTS ===\nmodel = keras.Sequential ([\n    keras.layers.Dense(8, input_shape=(5,), activation='relu'),\n    keras.layers.Dense(64, activation='relu'),\n    keras.layers.Dense(64, activation='relu'),\n    keras.layers.Dense(64, activation='relu'),\n    keras.layers.Dense(16, activation='relu'),\n    keras.layers.Dense(8, activation='relu'),\n    keras.layers.Dense(4, activation='relu'),\n    keras.layers.Dense(3, activation='sigmoid')\n])\n\nmodel.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n\n\n# === FIT THE MODEL ===\ninputs_np = np.array(inputs)\ntokenized_winner_model_np = np.array(tokenized_winner_model)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-27T19:35:27.526088Z","iopub.execute_input":"2025-06-27T19:35:27.527358Z","iopub.status.idle":"2025-06-27T19:35:27.639322Z","shell.execute_reply.started":"2025-06-27T19:35:27.527301Z","shell.execute_reply":"2025-06-27T19:35:27.638172Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# === FIT THE MODEL ===\nmodel.fit(\n    inputs_np,\n    tokenized_winner_model_np,\n    epochs=1000, \n    batch_size=32\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-27T19:35:39.760283Z","iopub.execute_input":"2025-06-27T19:35:39.76076Z","iopub.status.idle":"2025-06-27T20:15:56.31111Z","shell.execute_reply.started":"2025-06-27T19:35:39.760725Z","shell.execute_reply":"2025-06-27T20:15:56.309521Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Now use the vectorizer to transform your data\ntest_inputs = []\n\nfor i in range(len(test_data)):\n    inputa = np.zeros(5)\n\n    inputa[0] = (find_relevance(test_data['prompt'].iloc[i],test_data['response_a'].iloc[i])-find_relevance(test_data['prompt'].iloc[i],test_data['response_b'].iloc[i]))\n    inputa[1] = (readability_scores(test_data['response_a'].iloc[i])-readability_scores(test_data['response_b'].iloc[i]))\n    inputa[2] = (len(test_data['response_a'].iloc[i])/len((test_data['response_b'].iloc[i])))\n    inputa[3] = (sentiment((test_data['response_a'].iloc[i]))-sentiment((test_data['response_b'].iloc[i])))\n    inputa[4] = (disagrability_score(test_data['response_a'].iloc[i]))-(disagrability_score(test_data['response_b'].iloc[i]))\n\n    test_inputs.append(inputa)    \n    \ntest_inputs_np = np.array(test_inputs)\n\n# Create a DataFrame for the submission\nsubmission_df = pd.read_csv(f'{BASE_PATH}/sample_submission.csv')\nsubmission_df['id'] = test_data['id']\nsubmission_df['winner_model_a'] = 0.0\nsubmission_df['winner_model_b'] = 0.0\nsubmission_df['winner_tie'] = 0.0\n\n# Fill the DataFrame with predictions\nfor i in range(len(test_data)):\n    prediction = model.predict([\n        test_inputs_np[i:i+1]\n    ])\n    \n    submission_df.loc[i, 'winner_model_a'] = prediction[0][0]\n    print(prediction[0][0])\n    submission_df.loc[i, 'winner_model_b'] = prediction[0][1]\n    print(prediction[0][1])\n    submission_df.loc[i, 'winner_tie'] = prediction[0][2]\n    print(prediction[0][2])\n\n# Save to CSV file\nsubmission_df.to_csv('submission.csv', index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-27T20:30:01.741125Z","iopub.execute_input":"2025-06-27T20:30:01.741775Z","iopub.status.idle":"2025-06-27T20:30:02.346824Z","shell.execute_reply.started":"2025-06-27T20:30:01.741746Z","shell.execute_reply":"2025-06-27T20:30:02.34524Z"}},"outputs":[],"execution_count":null}]}