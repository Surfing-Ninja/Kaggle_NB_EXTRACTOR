{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":86518,"databundleVersionId":9809560,"sourceType":"competition"}],"dockerImageVersionId":31040,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport os\n\n# List files to ensure correct path\n:contentReference[oaicite:2]{index=2}\n\n# Load data\n:contentReference[oaicite:3]{index=3}\n:contentReference[oaicite:4]{index=4}\n:contentReference[oaicite:5]{index=5}\n\n:contentReference[oaicite:6]{index=6}\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import re\nimport nltk\nfrom nltk.corpus import stopwords\nfrom nltk.stem import WordNetLemmatizer\nfrom sklearn.feature_extraction.text import TfidfVectorizer\n\nnltk.download('punkt')\nnltk.download('stopwords')\nnltk.download('wordnet')\n\nle = WordNetLemmatizer()\nstops = set(stopwords.words('english'))\n\ndef clean_text(txt):\n    txt = txt.lower()\n    txt = re.sub(r'\\d+','', txt)\n    txt = re.sub(r'[^\\w\\s]','', txt)\n    tokens = nltk.word_tokenize(txt)\n    tokens = [le.lemmatize(t) for t in tokens if t not in stops]\n    return \" \".join(tokens)\n\nfor col in ['prompt', 'response_a', 'response_b']:\n    train[col] = train[col].astype(str).apply(clean_text)\n    test[col] = test[col].astype(str).apply(clean_text)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"MAX_FEAT = 300\n\ntfidf_prompt = TfidfVectorizer(max_features=MAX_FEAT)\nX_prompt = tfidf_prompt.fit_transform(train['prompt'])\nX_prompt_test = tfidf_prompt.transform(test['prompt'])\n\ntfidf_resp = TfidfVectorizer(max_features=MAX_FEAT)\nX_a = tfidf_resp.fit_transform(train['response_a'])\nX_b = tfidf_resp.transform(train['response_b'])\nX_a_test = tfidf_resp.transform(test['response_a'])\nX_b_test = tfidf_resp.transform(test['response_b'])\n\nfrom scipy.sparse import hstack\nX_train = hstack([X_prompt, X_a, X_b])\nX_test = hstack([X_prompt_test, X_a_test, X_b_test])\n\ny_train = train['winner_model'].map({'a':0,'b':1,'tie':2}).values\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import log_loss\n\nX_tr, X_val, y_tr, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n\nmodel = LogisticRegression(max_iter=500, multi_class='multinomial', solver='saga')\nmodel.fit(X_tr, y_tr)\n\ny_pred_proba = model.predict_proba(X_val)\nprint(\"Validation Log Loss:\", log_loss(y_val, y_pred_proba))\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_pred_proba = model.predict_proba(X_test)\nsub = pd.DataFrame({\n    'id': test['id'],\n    'winner_model_a': test_pred_proba[:, 0],\n    'winner_model_b': test_pred_proba[:, 1],\n    'winner_tie': test_pred_proba[:, 2]\n})\nsub.to_csv('submission.csv', index=False)\nprint(\"submission.csv saved.\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}