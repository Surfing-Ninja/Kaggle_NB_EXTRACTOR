{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":114250,"databundleVersionId":13838823,"sourceType":"competition"}],"dockerImageVersionId":31154,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# =============================================\n# Cell 1: Setup & Configuration\n# Big Data Bowl 2026 - University Track\n# =============================================\n\nimport os\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport matplotlib.patches as patches\nfrom tqdm import tqdm\nimport seaborn as sns\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nsns.set(style=\"whitegrid\")\nplt.rcParams['font.size'] = 12\n\n# Machine Learning\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import GroupKFold, cross_validate\nfrom sklearn.metrics import roc_auc_score, roc_curve, auc\n\n# Configuration\nDATA_PATH = \"/kaggle/input/nfl-big-data-bowl-2026-analytics\"\nMAX_PLAYS = None  # Set to 500 for testing, None for full analysis\nOUTPUT_DIR = \"./outputs\"\nPLOTS_DIR = \"./plots\"\nos.makedirs(OUTPUT_DIR, exist_ok=True)\nos.makedirs(PLOTS_DIR, exist_ok=True)\n\n# Football constants\nYARD_LENGTH = 120\nYARD_WIDTH = 53.3\nHASH_MARK_DISTANCE = 23.33\n\nprint(\"‚úÖ Setup complete! Ready for Big Data Bowl 2026 analysis.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-24T09:14:16.638604Z","iopub.execute_input":"2025-10-24T09:14:16.638878Z","iopub.status.idle":"2025-10-24T09:14:16.646194Z","shell.execute_reply.started":"2025-10-24T09:14:16.638859Z","shell.execute_reply":"2025-10-24T09:14:16.645409Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# =============================================\n# Cell 2: Data Loading & Exploration\n# =============================================\n\ndef load_all_tracking_data(data_path):\n    \"\"\"Load all weekly tracking data files\"\"\"\n    tracking_files = []\n    for i in range(1, 19):\n        week_file = f\"{data_path}/114239_nfl_competition_files_published_analytics_final/train/input_2023_w{i:02d}.csv\"\n        if os.path.exists(week_file):\n            tracking_files.append(week_file)\n    \n    print(f\"üìÅ Found {len(tracking_files)} weekly tracking files\")\n    \n    # Load all tracking data\n    all_tracking = []\n    for file in tqdm(tracking_files, desc=\"Loading weekly data\"):\n        try:\n            df_week = pd.read_csv(file)\n            df_week['week'] = int(file.split('_w')[-1].split('.')[0])\n            all_tracking.append(df_week)\n        except Exception as e:\n            print(f\"‚ö†Ô∏è Error loading {file}: {e}\")\n    \n    if all_tracking:\n        tracking_df = pd.concat(all_tracking, ignore_index=True)\n        print(f\"‚úÖ Combined tracking data: {len(tracking_df):,} rows\")\n        return tracking_df\n    else:\n        raise ValueError(\"No tracking data loaded!\")\n\ndef load_supplementary_data(data_path):\n    \"\"\"Load supplementary data\"\"\"\n    supp_file = f\"{data_path}/114239_nfl_competition_files_published_analytics_final/supplementary_data.csv\"\n    if os.path.exists(supp_file):\n        supp_df = pd.read_csv(supp_file)\n        print(f\"‚úÖ Supplementary data: {supp_df.shape}\")\n        return supp_df\n    else:\n        print(\"‚ö†Ô∏è No supplementary data found\")\n        return None\n\nprint(\"üöÄ Loading Big Data Bowl 2026 Data...\")\n\n# Load tracking data\ndf = load_all_tracking_data(DATA_PATH)\n\n# Load supplementary data\nsupp_df = load_supplementary_data(DATA_PATH)\n\n# Display actual data structure\nprint(\"\\nüîç ACTUAL COLUMN NAMES IN TRACKING DATA:\")\nprint(df.columns.tolist())\n\nprint(f\"\\nüìä TRACKING DATA INFO:\")\nprint(f\"Shape: {df.shape}\")\nprint(f\"Sample data:\")\nprint(df[['game_id', 'play_id', 'nfl_id', 'frame_id', 'x', 'y', 's', 'a', 'ball_land_x', 'ball_land_y']].head(2))\n\nif supp_df is not None:\n    print(f\"\\nüìä SUPPLEMENTARY DATA INFO:\")\n    print(f\"Shape: {supp_df.shape}\")\n    print(f\"Key columns: {[col for col in supp_df.columns if 'pass' in col.lower() or 'result' in col.lower()]}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-24T09:14:29.875103Z","iopub.execute_input":"2025-10-24T09:14:29.875405Z","iopub.status.idle":"2025-10-24T09:14:41.04489Z","shell.execute_reply.started":"2025-10-24T09:14:29.875384Z","shell.execute_reply":"2025-10-24T09:14:41.044224Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# =============================================\n# Cell 3: Data Preprocessing & Cleaning\n# =============================================\n\nprint(\"üîß Preprocessing and cleaning data...\")\n\n# Convert to proper data types\ndf['game_id'] = df['game_id'].astype(int)\ndf['play_id'] = df['play_id'].astype(int)\ndf['frame_id'] = df['frame_id'].astype(int)\ndf['nfl_id'] = df['nfl_id'].fillna(-1).astype(int)\n\n# Identify players vs ball\ndf['isBall'] = False\n# Football typically has no nfl_id or special position\ndf.loc[df['nfl_id'].isna() | (df['nfl_id'] == -1), 'isBall'] = True\n\n# Create team identification based on available columns\ndf['team'] = 'unknown'\n\n# Method 1: Use player_position to identify offense/defense\nif 'player_position' in df.columns:\n    offensive_positions = ['QB', 'WR', 'RB', 'TE', 'FB', 'C', 'G', 'T', 'OT', 'OG']\n    defensive_positions = ['CB', 'S', 'LB', 'DE', 'DT', 'NT', 'OLB', 'ILB', 'MLB', 'DB', 'DL']\n    \n    df.loc[df['player_position'].isin(offensive_positions), 'team'] = 'offense'\n    df.loc[df['player_position'].isin(defensive_positions), 'team'] = 'defense'\n\n# Method 2: Use player_role\nif 'player_role' in df.columns:\n    df.loc[df['player_role'].str.contains('offense', case=False, na=False), 'team'] = 'offense'\n    df.loc[df['player_role'].str.contains('defense', case=False, na=False), 'team'] = 'defense'\n\n# Method 3: Use player_side\nif 'player_side' in df.columns:\n    df.loc[df['player_side'].isin(['home', 'away']), 'team'] = 'offense'\n    df.loc[df['player_side'] == 'defense', 'team'] = 'defense'\n\nprint(f\"üèà Identified {df['isBall'].sum():,} football records\")\nprint(f\"üë• Team distribution: {df['team'].value_counts().to_dict()}\")\n\n# Create velocity components from speed and direction\nif all(col in df.columns for col in ['s', 'dir']):\n    print(\"üìê Computing velocity components from speed and direction...\")\n    # Convert direction from degrees to radians\n    dir_rad = np.radians(df['dir'])\n    df['vx'] = df['s'] * np.sin(dir_rad)  # x-component\n    df['vy'] = df['s'] * np.cos(dir_rad)  # y-component\n    print(\"‚úÖ Velocity components computed\")\n\nprint(\"‚úÖ Data preprocessing complete!\")\nprint(f\"üìä Final data shape: {df.shape}\")\nprint(f\"üéØ Unique plays: {df[['game_id', 'play_id']].drop_duplicates().shape[0]}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-24T09:14:57.707461Z","iopub.execute_input":"2025-10-24T09:14:57.708105Z","iopub.status.idle":"2025-10-24T09:15:03.398121Z","shell.execute_reply.started":"2025-10-24T09:14:57.708079Z","shell.execute_reply":"2025-10-24T09:15:03.397403Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# =============================================\n# Cell 4: Football Analysis Utilities\n# =============================================\n\nclass FootballField:\n    \"\"\"Football field visualization utilities\"\"\"\n    \n    @staticmethod\n    def create_field(ax=None, linecolor='white', linewidth=2, show_numbers=True):\n        \"\"\"Create professional football field background\"\"\"\n        if ax is None:\n            fig, ax = plt.subplots(figsize=(12, 6.33))\n        \n        # Green field background\n        ax.add_patch(patches.Rectangle((0, 0), YARD_LENGTH, YARD_WIDTH, \n                                     edgecolor=linecolor, facecolor='#2E8B57', linewidth=linewidth))\n        \n        # Yard lines every 5 yards\n        for yard in range(0, YARD_LENGTH + 1, 5):\n            if yard % 10 == 0:  # Every 10 yards\n                ax.axvline(yard, color=linecolor, linewidth=linewidth, alpha=0.8)\n                if show_numbers and 10 <= yard <= 110:\n                    ax.text(yard, YARD_WIDTH/2 - 5, str(min(yard, 120-yard)), \n                           ha='center', va='center', fontsize=10, color=linecolor, fontweight='bold')\n            else:  # Every 5 yards\n                ax.axvline(yard, color=linecolor, linewidth=1, alpha=0.5)\n        \n        # Hash marks\n        hash_yards = [HASH_MARK_DISTANCE/2, YARD_WIDTH - HASH_MARK_DISTANCE/2]\n        for yard in range(11, YARD_LENGTH-9):\n            for hash_y in hash_yards:\n                ax.plot([yard, yard], [hash_y-0.5, hash_y+0.5], color=linecolor, linewidth=1)\n        \n        # End zones\n        ax.add_patch(patches.Rectangle((0, 0), 10, YARD_WIDTH, \n                                     edgecolor=linecolor, facecolor='#006400', alpha=0.6))\n        ax.add_patch(patches.Rectangle((YARD_LENGTH-10, 0), 10, YARD_WIDTH, \n                                     edgecolor=linecolor, facecolor='#006400', alpha=0.6))\n        \n        ax.set_xlim(0, YARD_LENGTH)\n        ax.set_ylim(0, YARD_WIDTH)\n        ax.set_aspect('equal')\n        ax.axis('off')\n        \n        return ax\n\ndef calculate_movement_efficiency(trajectory_x, trajectory_y, target_x, target_y):\n    \"\"\"Calculate how efficiently a player moves toward target\"\"\"\n    if len(trajectory_x) < 2:\n        return 0.0\n    \n    efficiencies = []\n    for i in range(1, len(trajectory_x)):\n        # Vector to target\n        dx_target = target_x - trajectory_x[i-1]\n        dy_target = target_y - trajectory_y[i-1]\n        \n        # Player movement vector\n        dx_move = trajectory_x[i] - trajectory_x[i-1]\n        dy_move = trajectory_y[i] - trajectory_y[i-1]\n        \n        # Normalize vectors\n        target_mag = np.sqrt(dx_target**2 + dy_target**2)\n        move_mag = np.sqrt(dx_move**2 + dy_move**2)\n        \n        if target_mag > 0 and move_mag > 0:\n            # Cosine similarity between movement and target direction\n            cos_similarity = (dx_move * dx_target + dy_move * dy_target) / (move_mag * target_mag)\n            efficiency = max(0, cos_similarity)  # Only positive movement toward target\n            efficiencies.append(efficiency)\n    \n    return np.mean(efficiencies) if efficiencies else 0.0\n\ndef identify_pass_plays_from_supplementary(supp_df):\n    \"\"\"Identify pass plays from supplementary data\"\"\"\n    if supp_df is None:\n        return None\n    \n    # Filter for pass plays based on available columns\n    pass_plays = supp_df.copy()\n    \n    if 'pass_result' in supp_df.columns:\n        pass_plays = pass_plays[pass_plays['pass_result'].notna()]\n        print(f\"üéØ Found {len(pass_plays)} pass plays from pass_result column\")\n    else:\n        # Use play_description to identify pass plays\n        pass_keywords = ['pass', 'throw', 'quarterback']\n        pass_plays = pass_plays[\n            pass_plays['play_description'].str.contains('|'.join(pass_keywords), case=False, na=False)\n        ]\n        print(f\"üéØ Found {len(pass_plays)} potential pass plays from play_description\")\n    \n    return pass_plays[['game_id', 'play_id', 'pass_result', 'play_description']]\n\nprint(\"‚úÖ Football analysis utilities defined!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-24T09:15:29.452215Z","iopub.execute_input":"2025-10-24T09:15:29.452906Z","iopub.status.idle":"2025-10-24T09:15:29.465862Z","shell.execute_reply.started":"2025-10-24T09:15:29.452879Z","shell.execute_reply":"2025-10-24T09:15:29.464914Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# =============================================\n# Cell 5: Separation Efficiency Index Engine\n# =============================================\n\nclass SeparationEfficiencyAnalyzer:\n    \"\"\"Advanced SEI calculation engine\"\"\"\n    \n    def __init__(self):\n        self.metrics_history = []\n    \n    def analyze_play_separation(self, play_data, ball_landing_x, ball_landing_y):\n        \"\"\"Comprehensive separation analysis for a single play\"\"\"\n        \n        # Identify offensive and defensive players\n        offense = play_data[play_data['team'] == 'offense']\n        defense = play_data[play_data['team'] == 'defense']\n        \n        if offense.empty or defense.empty:\n            return None\n        \n        play_metrics = {\n            'game_id': play_data['game_id'].iloc[0],\n            'play_id': play_data['play_id'].iloc[0],\n            'ball_landing_x': ball_landing_x,\n            'ball_landing_y': ball_landing_y\n        }\n        \n        # Analyze each offensive player\n        offensive_metrics = []\n        for player_id in offense['nfl_id'].unique():\n            if player_id == -1:  # Skip unknown players\n                continue\n                \n            player_metrics = self._analyze_player_separation(\n                play_data, player_id, ball_landing_x, ball_landing_y, offense, defense\n            )\n            if player_metrics:\n                offensive_metrics.append(player_metrics)\n        \n        if not offensive_metrics:\n            return None\n        \n        # Aggregate play-level metrics\n        off_metrics_df = pd.DataFrame(offensive_metrics)\n        \n        # Key SEI components\n        play_metrics.update({\n            'offensive_players': len(offensive_metrics),\n            'avg_movement_efficiency': off_metrics_df['movement_efficiency'].mean(),\n            'max_movement_efficiency': off_metrics_df['movement_efficiency'].max(),\n            'avg_separation_gain': off_metrics_df['separation_gain'].mean(),\n            'max_separation_gain': off_metrics_df['separation_gain'].max(),\n            'avg_speed_efficiency': off_metrics_df['speed_efficiency'].mean(),\n            'defensive_pressure': off_metrics_df['defensive_pressure'].mean(),\n            'best_receiver_id': off_metrics_df.loc[off_metrics_df['movement_efficiency'].idxmax(), 'nfl_id'],\n            'best_receiver_efficiency': off_metrics_df['movement_efficiency'].max()\n        })\n        \n        # Calculate comprehensive SEI\n        play_metrics['SEI'] = self._calculate_comprehensive_sei(play_metrics)\n        \n        return play_metrics\n    \n    def _analyze_player_separation(self, play_data, player_id, ball_x, ball_y, offense, defense):\n        \"\"\"Analyze separation metrics for individual player\"\"\"\n        player_data = play_data[play_data['nfl_id'] == player_id].sort_values('frame_id')\n        \n        if len(player_data) < 5:  # Need sufficient frames\n            return None\n        \n        # Extract trajectory and movement data\n        player_x = player_data['x'].values\n        player_y = player_data['y'].values\n        player_speed = player_data['s'].values\n        \n        # Movement efficiency toward ball\n        movement_efficiency = calculate_movement_efficiency(player_x, player_y, ball_x, ball_y)\n        \n        # Speed efficiency (normalized)\n        max_speed = np.max(player_speed)\n        speed_efficiency = min(max_speed / 12.0, 1.0)  # Normalize to max NFL speed\n        \n        # Separation analysis\n        separation_gain = self._calculate_separation_gain(player_data, defense)\n        \n        # Defensive pressure\n        defensive_pressure = self._calculate_defensive_pressure(player_data, defense)\n        \n        return {\n            'nfl_id': player_id,\n            'movement_efficiency': movement_efficiency,\n            'speed_efficiency': speed_efficiency,\n            'separation_gain': separation_gain,\n            'defensive_pressure': defensive_pressure,\n            'max_speed': max_speed,\n            'frames_analyzed': len(player_data)\n        }\n    \n    def _calculate_separation_gain(self, player_data, defense_data):\n        \"\"\"Calculate how much separation player gains from defenders\"\"\"\n        separation_changes = []\n        \n        for frame_id in player_data['frame_id'].unique():\n            player_frame = player_data[player_data['frame_id'] == frame_id]\n            if player_frame.empty:\n                continue\n                \n            player_x, player_y = player_frame['x'].iloc[0], player_frame['y'].iloc[0]\n            \n            # Find nearest defender\n            defender_dists = []\n            for _, defender in defense_data[defense_data['frame_id'] == frame_id].iterrows():\n                dist = np.sqrt((player_x - defender['x'])**2 + (player_y - defender['y'])**2)\n                defender_dists.append(dist)\n            \n            if defender_dists:\n                separation_changes.append(min(defender_dists))\n        \n        if len(separation_changes) > 1:\n            return separation_changes[-1] - separation_changes[0]  # Separation gain\n        return 0.0\n    \n    def _calculate_defensive_pressure(self, player_data, defense_data):\n        \"\"\"Calculate defensive pressure on player throughout play\"\"\"\n        pressure_scores = []\n        \n        for frame_id in player_data['frame_id'].unique():\n            player_frame = player_data[player_data['frame_id'] == frame_id]\n            if player_frame.empty:\n                continue\n                \n            player_x, player_y = player_frame['x'].iloc[0], player_frame['y'].iloc[0]\n            \n            # Count defenders within pressure radius\n            defenders_near = 0\n            for _, defender in defense_data[defense_data['frame_id'] == frame_id].iterrows():\n                dist = np.sqrt((player_x - defender['x'])**2 + (player_y - defender['y'])**2)\n                if dist < 5.0:  # 5 yard pressure radius\n                    defenders_near += 1\n            \n            pressure_scores.append(defenders_near)\n        \n        return np.mean(pressure_scores) if pressure_scores else 0.0\n    \n    def _calculate_comprehensive_sei(self, play_metrics):\n        \"\"\"Calculate final Separation Efficiency Index\"\"\"\n        # Weighted combination of key factors\n        movement_score = play_metrics['max_movement_efficiency'] * 0.35\n        separation_score = min(play_metrics['max_separation_gain'] / 10.0, 1.0) * 0.30\n        speed_score = play_metrics['avg_speed_efficiency'] * 0.20\n        pressure_score = max(0, 1 - play_metrics['defensive_pressure'] / 5.0) * 0.15\n        \n        sei = movement_score + separation_score + speed_score + pressure_score\n        return min(max(sei, 0), 1)  # Clamp to [0, 1]\n\nprint(\"‚úÖ Separation Efficiency Index engine defined!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-24T09:15:47.646771Z","iopub.execute_input":"2025-10-24T09:15:47.647517Z","iopub.status.idle":"2025-10-24T09:15:47.662678Z","shell.execute_reply.started":"2025-10-24T09:15:47.647492Z","shell.execute_reply":"2025-10-24T09:15:47.661805Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# =============================================\n# Cell 6: Play Identification & SEI Calculation\n# =============================================\n\nprint(\"üéØ Identifying pass plays and calculating SEI...\")\n\ndef identify_pass_plays_with_ball(tracking_df, supp_df, max_plays=None):\n    \"\"\"Identify pass plays using supplementary data and ball landing positions\"\"\"\n    \n    # First, get pass plays from supplementary data\n    pass_plays_from_supp = identify_pass_plays_from_supplementary(supp_df)\n    \n    if pass_plays_from_supp is None or pass_plays_from_supp.empty:\n        print(\"‚ùå No pass plays identified from supplementary data\")\n        return pd.DataFrame(), pd.DataFrame()\n    \n    print(f\"üéØ Found {len(pass_plays_from_supp)} pass plays in supplementary data\")\n    \n    # Get unique game_id, play_id combinations from tracking data that match supplementary pass plays\n    tracking_plays = tracking_df[['game_id', 'play_id']].drop_duplicates()\n    valid_pass_plays = pass_plays_from_supp.merge(tracking_plays, on=['game_id', 'play_id'])\n    \n    print(f\"üìä {len(valid_pass_plays)} pass plays have tracking data\")\n    \n    if max_plays:\n        valid_pass_plays = valid_pass_plays.head(max_plays)\n        print(f\"üîç Analyzing first {max_plays} plays for efficiency\")\n    \n    pass_play_details = []\n    ball_landing_data = []\n    \n    play_count = 0\n    for _, play_info in tqdm(valid_pass_plays.iterrows(), total=len(valid_pass_plays), desc=\"Processing pass plays\"):\n        game_id = play_info['game_id']\n        play_id = play_info['play_id']\n        \n        # Get all frames for this play\n        play_data = tracking_df[\n            (tracking_df['game_id'] == game_id) & \n            (tracking_df['play_id'] == play_id)\n        ]\n        \n        if play_data.empty:\n            continue\n        \n        # Get ball landing position from tracking data\n        ball_data = play_data[['ball_land_x', 'ball_land_y']].dropna()\n        if ball_data.empty:\n            continue\n            \n        # Use the first available ball landing position\n        ball_landing_x = ball_data['ball_land_x'].iloc[0]\n        ball_landing_y = ball_data['ball_land_y'].iloc[0]\n        \n        # Skip if ball landing position is invalid\n        if pd.isna(ball_landing_x) or pd.isna(ball_landing_y):\n            continue\n        \n        # Get pass result from supplementary data if available\n        pass_result = play_info.get('pass_result', 'Unknown')\n        \n        pass_play_details.append({\n            'game_id': game_id,\n            'play_id': play_id,\n            'pass_result': pass_result,\n            'ball_landing_x': ball_landing_x,\n            'ball_landing_y': ball_landing_y,\n            'total_frames': len(play_data),\n            'offensive_players': len(play_data[play_data['team'] == 'offense']['nfl_id'].unique()),\n            'defensive_players': len(play_data[play_data['team'] == 'defense']['nfl_id'].unique())\n        })\n        \n        play_count += 1\n    \n    pass_plays_df = pd.DataFrame(pass_play_details)\n    \n    print(f\"‚úÖ Identified {len(pass_plays_df)} pass plays with valid ball tracking\")\n    return pass_plays_df\n\n# Identify pass plays\npass_plays_df = identify_pass_plays_with_ball(df, supp_df, MAX_PLAYS)\n\n# Calculate SEI for all plays\nprint(\"\\nüéõÔ∏è Calculating Separation Efficiency Index...\")\nsei_analyzer = SeparationEfficiencyAnalyzer()\nplay_metrics_list = []\n\nif not pass_plays_df.empty:\n    for _, play_info in tqdm(pass_plays_df.iterrows(), total=len(pass_plays_df), desc=\"Calculating SEI\"):\n        game_id = play_info['game_id']\n        play_id = play_info['play_id']\n        ball_x = play_info['ball_landing_x']\n        ball_y = play_info['ball_landing_y']\n        \n        try:\n            # Get all play data\n            play_data = df[\n                (df['game_id'] == game_id) & \n                (df['play_id'] == play_id)\n            ]\n            \n            if play_data.empty:\n                continue\n            \n            # Analyze separation efficiency\n            play_metrics = sei_analyzer.analyze_play_separation(play_data, ball_x, ball_y)\n            \n            if play_metrics:\n                # Add supplementary information\n                play_metrics['pass_result'] = play_info.get('pass_result', 'Unknown')\n                play_metrics['week'] = play_info.get('week', play_data['week'].iloc[0] if 'week' in play_data.columns else 0)\n                play_metrics_list.append(play_metrics)\n                \n        except Exception as e:\n            continue\n\n    # Create comprehensive features dataframe\n    if play_metrics_list:\n        features_df = pd.DataFrame(play_metrics_list)\n        \n        # Add additional derived features\n        features_df['distance_to_sideline'] = np.minimum(\n            features_df['ball_landing_y'], \n            YARD_WIDTH - features_df['ball_landing_y']\n        )\n        features_df['field_position'] = features_df['ball_landing_x'] / YARD_LENGTH\n        features_df['red_zone'] = (features_df['ball_landing_x'] >= 100).astype(int)\n        \n        # Convert pass_result to binary completion\n        if 'pass_result' in features_df.columns:\n            completion_map = {\n                'C': 1, 'COMPLETE': 1,\n                'I': 0, 'INCOMPLETE': 0, 'IN': 0, 'INC': 0\n            }\n            features_df['completion'] = features_df['pass_result'].map(completion_map)\n            # For any unmapped values, try to infer from the string\n            unmapped = features_df['completion'].isna()\n            if unmapped.any():\n                features_df.loc[unmapped & features_df['pass_result'].str.contains('complete', case=False, na=False), 'completion'] = 1\n                features_df.loc[unmapped & features_df['pass_result'].str.contains('incomplete', case=False, na=False), 'completion'] = 0\n        \n        print(f\"‚úÖ Successfully analyzed {len(features_df)} plays\")\n        \n        # Display SEI statistics\n        print(f\"\\nüìà SEI STATISTICS:\")\n        print(f\"Mean SEI: {features_df['SEI'].mean():.3f}\")\n        print(f\"Std SEI: {features_df['SEI'].std():.3f}\")\n        print(f\"Min SEI: {features_df['SEI'].min():.3f}\")\n        print(f\"Max SEI: {features_df['SEI'].max():.3f}\")\n        \n        if 'completion' in features_df.columns:\n            completion_rate = features_df['completion'].mean()\n            print(f\"Completion rate: {completion_rate:.3f} ({completion_rate*100:.1f}%)\")\n        \n        # Save features\n        features_df.to_csv(os.path.join(OUTPUT_DIR, 'play_features_with_sei.csv'), index=False)\n        print(f\"üíæ Saved features to {OUTPUT_DIR}/play_features_with_sei.csv\")\n        \n    else:\n        print(\"‚ùå No plays successfully analyzed!\")\n        features_df = pd.DataFrame() \nelse:\n    print(\"‚ùå No pass plays available for SEI calculation\")\n    features_df = pd.DataFrame()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-24T09:16:10.430896Z","iopub.execute_input":"2025-10-24T09:16:10.43156Z","iopub.status.idle":"2025-10-24T10:39:13.559014Z","shell.execute_reply.started":"2025-10-24T09:16:10.431519Z","shell.execute_reply":"2025-10-24T10:39:13.558164Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# =============================================\n# Cell 7: Machine Learning & Predictive Modeling\n# =============================================\n\nif not features_df.empty and 'completion' in features_df.columns:\n    print(\"ü§ñ Building machine learning models...\")\n    \n    # Feature selection for modeling\n    feature_columns = [\n        'avg_movement_efficiency', 'max_movement_efficiency',\n        'avg_separation_gain', 'max_separation_gain', \n        'avg_speed_efficiency', 'defensive_pressure',\n        'offensive_players', 'defensive_players',\n        'distance_to_sideline', 'field_position', 'red_zone', 'SEI'\n    ]\n    \n    # Ensure all features exist\n    available_features = [f for f in feature_columns if f in features_df.columns]\n    X = features_df[available_features].fillna(0)\n    y = features_df['completion']\n    groups = features_df['game_id']\n    \n    if len(X) > 10:  # Enough samples for modeling\n        # Models\n        models = {\n            'Logistic Regression': Pipeline([\n                ('impute', SimpleImputer(strategy='median')),\n                ('scale', StandardScaler()),\n                ('lr', LogisticRegression(max_iter=1000, random_state=42))\n            ]),\n            'Random Forest': Pipeline([\n                ('impute', SimpleImputer(strategy='median')),\n                ('rf', RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1))\n            ])\n        }\n        \n        # Cross-validation\n        gkf = GroupKFold(n_splits=3)\n        results = {}\n        \n        for name, model in models.items():\n            try:\n                cv_scores = cross_validate(\n                    model, X, y, cv=gkf.split(X, y, groups),\n                    scoring=['roc_auc'], \n                    return_train_score=False\n                )\n                results[name] = {\n                    'auc_mean': np.mean(cv_scores['test_roc_auc']),\n                    'auc_std': np.std(cv_scores['test_roc_auc'])\n                }\n                print(f\"‚úÖ {name}: AUC = {results[name]['auc_mean']:.3f} ¬± {results[name]['auc_std']:.3f}\")\n            except Exception as e:\n                print(f\"‚ö†Ô∏è {name} failed: {e}\")\n        \n        # Train final model on all data\n        if results:\n            final_model_name = max(results.keys(), key=lambda x: results[x]['auc_mean'])\n            final_model = models[final_model_name]\n            final_model.fit(X, y)\n            \n            # Feature importance\n            if hasattr(final_model.named_steps.get('rf', None), 'feature_importances_'):\n                importance_df = pd.DataFrame({\n                    'feature': available_features,\n                    'importance': final_model.named_steps['rf'].feature_importances_\n                }).sort_values('importance', ascending=False)\n                \n                importance_df.to_csv(os.path.join(OUTPUT_DIR, 'feature_importance.csv'), index=False)\n                print(\"\\nüí° TOP FEATURES BY IMPORTANCE:\")\n                for _, row in importance_df.head().iterrows():\n                    print(f\"   {row['feature']}: {row['importance']:.3f}\")\n            \n            # Save model predictions\n            features_df['predicted_completion'] = final_model.predict_proba(X)[:, 1]\n            features_df.to_csv(os.path.join(OUTPUT_DIR, 'model_predictions.csv'), index=False)\n            \n            # ROC Curve\n            fpr, tpr, _ = roc_curve(y, features_df['predicted_completion'])\n            roc_auc = auc(fpr, tpr)\n            \n            plt.figure(figsize=(8, 6))\n            plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.3f})')\n            plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n            plt.xlabel('False Positive Rate')\n            plt.ylabel('True Positive Rate')\n            plt.title('Receiver Operating Characteristic - SEI Model')\n            plt.legend(loc=\"lower right\")\n            plt.grid(True)\n            plt.tight_layout()\n            plt.savefig(os.path.join(PLOTS_DIR, 'roc_curve.png'), dpi=300, bbox_inches='tight')\n            plt.show()\n            \n    else:\n        print(\"‚ö†Ô∏è Not enough samples for machine learning modeling\")\nelse:\n    print(\"‚ÑπÔ∏è Machine learning requires completion labels\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-24T10:40:17.695457Z","iopub.execute_input":"2025-10-24T10:40:17.696188Z","iopub.status.idle":"2025-10-24T10:40:22.7756Z","shell.execute_reply.started":"2025-10-24T10:40:17.696161Z","shell.execute_reply":"2025-10-24T10:40:22.774848Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# =============================================\n# Cell 8: Advanced Analytics & Insights\n# =============================================\n\nif not features_df.empty:\n    print(\"üìà Generating advanced analytics and insights...\")\n    \n    # 8.1 Comprehensive SEI Dashboard\n    fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n    \n    # SEI Distribution\n    axes[0,0].hist(features_df['SEI'], bins=30, alpha=0.7, color='#2E8B57', edgecolor='white')\n    axes[0,0].axvline(features_df['SEI'].mean(), color='red', linestyle='--', label=f'Mean: {features_df[\"SEI\"].mean():.3f}')\n    axes[0,0].set_xlabel('Separation Efficiency Index (SEI)')\n    axes[0,0].set_ylabel('Frequency')\n    axes[0,0].set_title('SEI Distribution', fontweight='bold')\n    axes[0,0].legend()\n    axes[0,0].grid(True, alpha=0.3)\n    \n    # SEI vs Movement Efficiency\n    axes[0,1].scatter(features_df['avg_movement_efficiency'], features_df['SEI'], alpha=0.6)\n    axes[0,1].set_xlabel('Average Movement Efficiency')\n    axes[0,1].set_ylabel('SEI')\n    axes[0,1].set_title('SEI vs Movement Efficiency', fontweight='bold')\n    axes[0,1].grid(True, alpha=0.3)\n    \n    # SEI vs Defensive Pressure\n    axes[0,2].scatter(features_df['defensive_pressure'], features_df['SEI'], alpha=0.6, color='red')\n    axes[0,2].set_xlabel('Defensive Pressure')\n    axes[0,2].set_ylabel('SEI')\n    axes[0,2].set_title('SEI vs Defensive Pressure', fontweight='bold')\n    axes[0,2].grid(True, alpha=0.3)\n    \n    # SEI by Red Zone\n    if 'red_zone' in features_df.columns:\n        red_zone_sei = features_df[features_df['red_zone'] == 1]['SEI']\n        normal_sei = features_df[features_df['red_zone'] == 0]['SEI']\n        axes[1,0].boxplot([normal_sei, red_zone_sei], labels=['Normal', 'Red Zone'])\n        axes[1,0].set_ylabel('SEI')\n        axes[1,0].set_title('SEI: Normal vs Red Zone', fontweight='bold')\n        axes[1,0].grid(True, alpha=0.3)\n    \n    # SEI vs Completion\n    if 'completion' in features_df.columns:\n        complete_sei = features_df[features_df['completion'] == 1]['SEI']\n        incomplete_sei = features_df[features_df['completion'] == 0]['SEI']\n        axes[1,1].boxplot([incomplete_sei, complete_sei], labels=['Incomplete', 'Complete'])\n        axes[1,1].set_ylabel('SEI')\n        axes[1,1].set_title('SEI by Pass Completion', fontweight='bold')\n        axes[1,1].grid(True, alpha=0.3)\n    \n    # Field Position Impact\n    if 'field_position' in features_df.columns:\n        pos_bins = pd.cut(features_df['field_position'], bins=5)\n        sei_by_pos = features_df.groupby(pos_bins)['SEI'].mean()\n        sei_by_pos.plot(kind='bar', ax=axes[1,2], color='orange', alpha=0.7)\n        axes[1,2].set_xlabel('Field Position')\n        axes[1,2].set_ylabel('Average SEI')\n        axes[1,2].set_title('SEI by Field Position', fontweight='bold')\n        axes[1,2].tick_params(axis='x', rotation=45)\n        axes[1,2].grid(True, alpha=0.3)\n    \n    plt.tight_layout()\n    plt.savefig(os.path.join(PLOTS_DIR, 'comprehensive_sei_dashboard.png'), dpi=300, bbox_inches='tight')\n    plt.show()\n    \n    # 8.2 Correlation Analysis\n    numeric_cols = features_df.select_dtypes(include=[np.number]).columns\n    correlation_with_sei = features_df[numeric_cols].corr()['SEI'].sort_values(ascending=False)\n    \n    print(\"\\nüîó TOP CORRELATIONS WITH SEI:\")\n    for feature, corr in correlation_with_sei.head(8).items():\n        if feature != 'SEI':\n            print(f\"   {feature}: {corr:.3f}\")\n    \n    # 8.3 High vs Low SEI Comparison\n    high_sei_threshold = features_df['SEI'].quantile(0.8)\n    low_sei_threshold = features_df['SEI'].quantile(0.2)\n    \n    high_sei_plays = features_df[features_df['SEI'] >= high_sei_threshold]\n    low_sei_plays = features_df[features_df['SEI'] <= low_sei_threshold]\n    \n    print(f\"\\nüìä HIGH vs LOW SEI COMPARISON:\")\n    print(f\"High SEI threshold (>80%): {high_sei_threshold:.3f}\")\n    print(f\"Low SEI threshold (<20%): {low_sei_threshold:.3f}\")\n    print(f\"High SEI plays: {len(high_sei_plays)}\")\n    print(f\"Low SEI plays: {len(low_sei_plays)}\")\n    \n    if 'completion' in features_df.columns:\n        high_sei_completion = high_sei_plays['completion'].mean()\n        low_sei_completion = low_sei_plays['completion'].mean()\n        print(f\"High SEI completion rate: {high_sei_completion:.3f} ({high_sei_completion*100:.1f}%)\")\n        print(f\"Low SEI completion rate: {low_sei_completion:.3f} ({low_sei_completion*100:.1f}%)\")\n        print(f\"Completion difference: {high_sei_completion - low_sei_completion:.3f}\")\n    \n    print(f\"High SEI avg movement efficiency: {high_sei_plays['avg_movement_efficiency'].mean():.3f}\")\n    print(f\"Low SEI avg movement efficiency: {low_sei_plays['avg_movement_efficiency'].mean():.3f}\")\n    print(f\"High SEI avg defensive pressure: {high_sei_plays['defensive_pressure'].mean():.2f}\")\n    print(f\"Low SEI avg defensive pressure: {low_sei_plays['defensive_pressure'].mean():.2f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-24T10:40:53.070014Z","iopub.execute_input":"2025-10-24T10:40:53.070625Z","iopub.status.idle":"2025-10-24T10:40:57.28899Z","shell.execute_reply.started":"2025-10-24T10:40:53.0706Z","shell.execute_reply":"2025-10-24T10:40:57.28838Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# =============================================\n# Cell 9: Player Rankings & NFL Applications\n# =============================================\n\nif not features_df.empty:\n    print(\"üèÜ Generating player rankings and NFL applications...\")\n    \n    # 9.1 Player Performance Rankings\n    if 'best_receiver_id' in features_df.columns:\n        player_performance = []\n        \n        for _, play in features_df.iterrows():\n            if play['best_receiver_id'] != -1:\n                player_performance.append({\n                    'nfl_id': play['best_receiver_id'],\n                    'game_id': play['game_id'],\n                    'play_id': play['play_id'],\n                    'SEI': play['SEI'],\n                    'movement_efficiency': play['best_receiver_efficiency'],\n                    'defensive_pressure': play['defensive_pressure']\n                })\n        \n        if player_performance:\n            player_df = pd.DataFrame(player_performance)\n            \n            # Aggregate by player\n            player_rankings = player_df.groupby('nfl_id').agg({\n                'SEI': ['mean', 'std', 'count'],\n                'movement_efficiency': 'mean',\n                'defensive_pressure': 'mean'\n            }).round(4)\n            \n            # Flatten column names\n            player_rankings.columns = ['_'.join(col).strip() for col in player_rankings.columns.values]\n            player_rankings = player_rankings.rename(columns={\n                'SEI_mean': 'avg_sei',\n                'SEI_std': 'std_sei', \n                'SEI_count': 'plays_analyzed',\n                'movement_efficiency_mean': 'avg_movement_eff',\n                'defensive_pressure_mean': 'avg_def_pressure'\n            })\n            \n            # Filter players with sufficient plays\n            player_rankings = player_rankings[player_rankings['plays_analyzed'] >= 3]\n            player_rankings = player_rankings.sort_values('avg_sei', ascending=False)\n            \n            player_rankings.to_csv(os.path.join(OUTPUT_DIR, 'player_sei_rankings.csv'))\n            \n            print(f\"‚úÖ Ranked {len(player_rankings)} players with sufficient data\")\n            print(\"\\nüèÖ TOP 10 PLAYERS BY SEI:\")\n            for i, (player_id, row) in enumerate(player_rankings.head(10).iterrows()):\n                print(f\"   {i+1:2d}. Player {player_id}: SEI = {row['avg_sei']:.3f} ({row['plays_analyzed']} plays)\")\n    \n    # 9.2 Coaching Applications\n    print(\"\\nüéØ COACHING APPLICATIONS OF SEI:\")\n    print(\"1. üéØ Player Evaluation: Identify most efficient route runners\")\n    print(\"2. üèà Game Planning: Target matchups with favorable SEI profiles\") \n    print(\"3. üìä Scheme Design: Optimize routes based on SEI components\")\n    print(\"4. üîç Scouting: Evaluate receiver separation ability in draft\")\n    print(\"5. üìà Development: Target specific areas for player improvement\")\n    \n    # 9.3 Team-level Insights\n    print(f\"\\nüìä TEAM-LEVEL INSIGHTS:\")\n    print(f\"‚Ä¢ Average SEI across all plays: {features_df['SEI'].mean():.3f}\")\n    print(f\"‚Ä¢ Percentage of high-efficiency plays (SEI > 0.7): {(features_df['SEI'] > 0.7).mean()*100:.1f}%\")\n    \n    if 'red_zone' in features_df.columns:\n        red_zone_boost = features_df[features_df['red_zone']==1]['SEI'].mean() - features_df[features_df['red_zone']==0]['SEI'].mean()\n        print(f\"‚Ä¢ Red zone efficiency impact: {red_zone_boost:+.3f}\")\n    \n    if 'completion' in features_df.columns:\n        completion_corr = features_df['SEI'].corr(features_df['completion'])\n        print(f\"‚Ä¢ Correlation with completion: {completion_corr:.3f}\")\n    \n    # 9.4 Save final report\n    final_report = {\n        'analysis_summary': {\n            'total_plays_analyzed': len(features_df),\n            'analysis_period': '2023 Season Weeks 1-18',\n            'key_metric': 'Separation Efficiency Index (SEI)',\n            'metric_range': '0-1 (higher = better separation)'\n        },\n        'key_findings': {\n            'average_sei': float(features_df['SEI'].mean()),\n            'consistency': float(features_df['SEI'].std()),\n            'high_efficiency_threshold': 0.7,\n            'high_efficiency_plays_pct': float((features_df['SEI'] > 0.7).mean() * 100)\n        },\n        'nfl_applications': [\n            \"Player evaluation and development\",\n            \"Game planning and matchup optimization\", \n            \"Draft scouting and free agency\",\n            \"Scheme design and play calling\",\n            \"Performance tracking and analytics\"\n        ]\n    }\n    \n    import json\n    with open(os.path.join(OUTPUT_DIR, 'final_analysis_report.json'), 'w') as f:\n        json.dump(final_report, f, indent=2)\n    \n    print(f\"\\nüíæ Final report saved to {OUTPUT_DIR}/final_analysis_report.json\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-24T10:41:19.941798Z","iopub.execute_input":"2025-10-24T10:41:19.942427Z","iopub.status.idle":"2025-10-24T10:41:20.603598Z","shell.execute_reply.started":"2025-10-24T10:41:19.942405Z","shell.execute_reply":"2025-10-24T10:41:20.602793Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# =============================================\n# Cell 10: Final Summary & Submission Preparation\n# =============================================\n\nprint(\"\"\"\nüéâ BIG DATA BOWL 2026 ANALYSIS COMPLETE!\n==========================================\n\nüìä ANALYSIS SUMMARY:\n\"\"\")\n\nif not features_df.empty:\n    print(f\"‚Ä¢ Plays Analyzed: {len(features_df):,}\")\n    print(f\"‚Ä¢ Average SEI: {features_df['SEI'].mean():.3f}\")\n    print(f\"‚Ä¢ SEI Range: {features_df['SEI'].min():.3f} - {features_df['SEI'].max():.3f}\")\n    print(f\"‚Ä¢ High Efficiency Plays (SEI > 0.7): {(features_df['SEI'] > 0.7).sum():,} ({(features_df['SEI'] > 0.7).mean()*100:.1f}%)\")\n    \n    if os.path.exists(os.path.join(OUTPUT_DIR, 'player_sei_rankings.csv')):\n        player_rankings = pd.read_csv(os.path.join(OUTPUT_DIR, 'player_sei_rankings.csv'))\n        print(f\"‚Ä¢ Players Ranked: {len(player_rankings):,}\")\n\nprint(f\"\"\"\nüìÅ OUTPUTS GENERATED:\n{OUTPUT_DIR}/\n   ‚îú‚îÄ‚îÄ play_features_with_sei.csv (Complete play-level features)\n   ‚îú‚îÄ‚îÄ player_sei_rankings.csv (Player performance rankings) \n   ‚îú‚îÄ‚îÄ feature_importance.csv (ML model feature importance)\n   ‚îú‚îÄ‚îÄ model_predictions.csv (Play outcome predictions)\n   ‚îî‚îÄ‚îÄ final_analysis_report.json (Comprehensive summary)\n\n{PLOTS_DIR}/\n   ‚îú‚îÄ‚îÄ comprehensive_sei_dashboard.png (Main results dashboard)\n   ‚îú‚îÄ‚îÄ roc_curve.png (Model performance)\n   ‚îî‚îÄ‚îÄ ball_landing_distribution.png (Spatial analysis)\n\nüèà SEPARATION EFFICIENCY INDEX (SEI) INNOVATIONS:\n1. Multi-dimensional player movement analysis\n2. Context-aware efficiency calculations  \n3. Defensive pressure quantification\n4. Real-time separation tracking\n5. Field position adjustments\n\nüéØ NFL APPLICATIONS:\n‚Ä¢ Player Evaluation: Identify elite separators\n‚Ä¢ Game Planning: Optimize matchups and schemes  \n‚Ä¢ Draft Analysis: Quantify receiver separation skills\n‚Ä¢ Development: Target specific improvement areas\n‚Ä¢ Strategy: Data-driven play calling decisions\n\nüìù SUBMISSION NEXT STEPS:\n1. Write 2000-word narrative explaining SEI methodology and applications\n2. Create executive summary for coaches and scouts\n3. Prepare presentation highlighting key insights\n4. Showcase visualizations in media gallery\n5. Demonstrate NFL operational value\n\nÿ®Ÿêÿ≥ŸíŸÖŸê ÿßŸÑŸÑŸáŸê ÿßŸÑÿ±ŸéŸëÿ≠ŸíŸÖŸ∞ŸÜŸê ÿßŸÑÿ±ŸéŸëÿ≠ŸêŸäŸíŸÖŸê\nMay Allah grant you success in this competition! üåü\n\"\"\")\n\n# Cleanup\nimport gc\ngc.collect()\nprint(\"üßπ Memory cleanup completed!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-24T10:41:41.794428Z","iopub.execute_input":"2025-10-24T10:41:41.795161Z","iopub.status.idle":"2025-10-24T10:41:41.90867Z","shell.execute_reply.started":"2025-10-24T10:41:41.795139Z","shell.execute_reply":"2025-10-24T10:41:41.908013Z"}},"outputs":[],"execution_count":null}]}