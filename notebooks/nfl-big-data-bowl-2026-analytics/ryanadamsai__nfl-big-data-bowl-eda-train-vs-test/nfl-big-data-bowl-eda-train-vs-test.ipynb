{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":114239,"databundleVersionId":13825858,"isSourceIdPinned":false,"sourceType":"competition"},{"sourceId":114250,"databundleVersionId":13838823,"sourceType":"competition"}],"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"\"\"\"\nNFL Big Data Bowl 2026 - Data Exploration\nLet's understand what we're actually predicting!\n\"\"\"\n\nimport pandas as pd\nimport numpy as np\nimport os\n\nprint(\"=\" * 80)\nprint(\"üèà NFL BIG DATA BOWL 2026 - DATA EXPLORATION üèà\")\nprint(\"=\" * 80)\n\n# Base path\nbase_path = '/kaggle/input/nfl-big-data-bowl-2026-prediction'\n\nprint(\"\\nüìÇ DATASET STRUCTURE:\")\nprint(f\"Base path: {base_path}\")\n\n# Check what files exist\nif os.path.exists(base_path):\n    print(\"\\n‚úÖ Dataset found!\")\n    \n    # List top-level files\n    print(\"\\nüìÅ Top-level files:\")\n    top_files = [f for f in os.listdir(base_path) if os.path.isfile(os.path.join(base_path, f))]\n    for f in sorted(top_files):\n        size = os.path.getsize(os.path.join(base_path, f))\n        print(f\"  - {f} ({size:,} bytes)\")\n    \n    # Check train folder\n    train_path = os.path.join(base_path, 'train')\n    if os.path.exists(train_path):\n        print(\"\\nüìÅ Train folder files:\")\n        train_files = os.listdir(train_path)\n        input_files = [f for f in train_files if f.startswith('input_')]\n        output_files = [f for f in train_files if f.startswith('output_')]\n        print(f\"  - Input files: {len(input_files)} weeks\")\n        print(f\"  - Output files: {len(output_files)} weeks\")\n\nprint(\"\\n\" + \"=\" * 80)\nprint(\"üìä EXAMINING SAMPLE FILES\")\nprint(\"=\" * 80)\n\n# Load sample submission to understand the task\nprint(\"\\n1Ô∏è‚É£ SAMPLE SUBMISSION:\")\nsample_sub = pd.read_csv(os.path.join(base_path, 'sample_submission.csv'))\nprint(f\"  Shape: {sample_sub.shape}\")\nprint(f\"  Columns: {list(sample_sub.columns)}\")\nprint(f\"\\n  First few rows:\")\nprint(sample_sub.head())\nprint(f\"\\n  Sample values:\")\nprint(sample_sub.describe())\n\n# Load test input to see what we're predicting from\nprint(\"\\n2Ô∏è‚É£ TEST INPUT:\")\ntest_input = pd.read_csv(os.path.join(base_path, 'test_input.csv'))\nprint(f\"  Shape: {test_input.shape}\")\nprint(f\"  Columns: {list(test_input.columns)}\")\nprint(f\"\\n  First few rows:\")\nprint(test_input.head())\nprint(f\"\\n  Data types:\")\nprint(test_input.dtypes)\n\n# Load one training input file\nprint(\"\\n3Ô∏è‚É£ TRAINING INPUT (Week 1):\")\ntrain_input = pd.read_csv(os.path.join(base_path, 'train', 'input_2023_w01.csv'))\nprint(f\"  Shape: {train_input.shape}\")\nprint(f\"  Columns: {list(train_input.columns)}\")\nprint(f\"\\n  First few rows:\")\nprint(train_input.head())\nprint(f\"\\n  Summary stats:\")\nprint(train_input.describe())\n\n# Load corresponding training output file\nprint(\"\\n4Ô∏è‚É£ TRAINING OUTPUT (Week 1):\")\ntrain_output = pd.read_csv(os.path.join(base_path, 'train', 'output_2023_w01.csv'))\nprint(f\"  Shape: {train_output.shape}\")\nprint(f\"  Columns: {list(train_output.columns)}\")\nprint(f\"\\n  First few rows:\")\nprint(train_output.head())\nprint(f\"\\n  Summary stats:\")\nprint(train_output.describe())\n\n# Check if there are any ID columns to link input and output\nprint(\"\\n5Ô∏è‚É£ LINKING INPUT TO OUTPUT:\")\ninput_cols = set(train_input.columns)\noutput_cols = set(train_output.columns)\ncommon_cols = input_cols & output_cols\nprint(f\"  Common columns: {common_cols}\")\n\n# Check shapes\nprint(f\"\\n  Input rows: {len(train_input):,}\")\nprint(f\"  Output rows: {len(train_output):,}\")\nprint(f\"  Rows match: {len(train_input) == len(train_output)}\")\n\nprint(\"\\n\" + \"=\" * 80)\nprint(\"üéØ UNDERSTANDING THE TASK\")\nprint(\"=\" * 80)\n\n# Try to understand what we're predicting\nprint(\"\\nBased on the data structure:\")\nprint(f\"  - We have {len(input_files)} weeks of training data\")\nprint(f\"  - Input files contain: {len(train_input.columns)} features\")\nprint(f\"  - Output files contain: {len(train_output.columns)} targets\")\nprint(f\"  - Sample submission has: {len(sample_sub)} predictions to make\")\n\n# Identify prediction targets\nnon_id_output_cols = [col for col in train_output.columns if col not in ['id', 'gameId', 'playId', 'nflId', 'frameId']]\nprint(f\"\\n  Prediction targets: {non_id_output_cols}\")\n\nprint(\"\\n\" + \"=\" * 80)\nprint(\"‚úÖ DATA EXPLORATION COMPLETE!\")\nprint(\"=\" * 80)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null}]}