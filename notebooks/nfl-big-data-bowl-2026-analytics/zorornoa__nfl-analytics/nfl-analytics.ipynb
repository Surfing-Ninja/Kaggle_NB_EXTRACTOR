{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":114250,"databundleVersionId":13838823,"sourceType":"competition"}],"dockerImageVersionId":31154,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-10-27T14:01:30.433961Z","iopub.execute_input":"2025-10-27T14:01:30.434224Z","iopub.status.idle":"2025-10-27T14:01:30.456939Z","shell.execute_reply.started":"2025-10-27T14:01:30.434206Z","shell.execute_reply":"2025-10-27T14:01:30.456304Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom pathlib import Path\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-27T14:01:30.457552Z","iopub.execute_input":"2025-10-27T14:01:30.457725Z","iopub.status.idle":"2025-10-27T14:01:30.461881Z","shell.execute_reply.started":"2025-10-27T14:01:30.457711Z","shell.execute_reply":"2025-10-27T14:01:30.460999Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor\nfrom sklearn.model_selection import train_test_split, cross_val_score\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder\nimport xgboost as xgb\nfrom sklearn.cluster import KMeans","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-27T14:01:30.462573Z","iopub.execute_input":"2025-10-27T14:01:30.462795Z","iopub.status.idle":"2025-10-27T14:01:30.477643Z","shell.execute_reply.started":"2025-10-27T14:01:30.462755Z","shell.execute_reply":"2025-10-27T14:01:30.477084Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import matplotlib.animation as animation\nfrom matplotlib.patches import Rectangle, Circle, Arc\nimport plotly.express as px\nimport plotly.graph_objects as go\nfrom plotly.subplots import make_subplots","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-27T14:01:30.478392Z","iopub.execute_input":"2025-10-27T14:01:30.478562Z","iopub.status.idle":"2025-10-27T14:01:30.494519Z","shell.execute_reply.started":"2025-10-27T14:01:30.478548Z","shell.execute_reply":"2025-10-27T14:01:30.49392Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import LSTM, Dense, Dropout, BatchNormalization\n\nprint(\"All libraries imported successfully!\")\nprint(f\"TensorFlow version: {tf.__version__}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-27T14:01:30.495323Z","iopub.execute_input":"2025-10-27T14:01:30.495658Z","iopub.status.idle":"2025-10-27T14:01:30.510055Z","shell.execute_reply.started":"2025-10-27T14:01:30.49564Z","shell.execute_reply":"2025-10-27T14:01:30.50935Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Data loading and Exploration","metadata":{}},{"cell_type":"code","source":"def load_nfl_data():\n    \"\"\"Load and explore the NFL Big Data Bowl 2026 dataset\"\"\"\n    \n    # Load supplementary data\n    supplementary_path = '/kaggle/input/nfl-big-data-bowl-2026-analytics/114239_nfl_competition_files_published_analytics_final/supplementary_data.csv'\n    supplementary_data = pd.read_csv(supplementary_path)\n    \n    # Load sample input and output files\n    input_files = [\n        '/kaggle/input/nfl-big-data-bowl-2026-analytics/114239_nfl_competition_files_published_analytics_final/train/input_2023_w01.csv',\n        '/kaggle/input/nfl-big-data-bowl-2026-analytics/114239_nfl_competition_files_published_analytics_final/train/input_2023_w02.csv'\n    ]\n    \n    output_files = [\n        '/kaggle/input/nfl-big-data-bowl-2026-analytics/114239_nfl_competition_files_published_analytics_final/train/output_2023_w01.csv',\n        '/kaggle/input/nfl-big-data-bowl-2026-analytics/114239_nfl_competition_files_published_analytics_final/train/output_2023_w02.csv'\n    ]\n    \n    # Load multiple weeks of data\n    input_data = pd.concat([pd.read_csv(f) for f in input_files], ignore_index=True)\n    output_data = pd.concat([pd.read_csv(f) for f in output_files], ignore_index=True)\n    \n    return supplementary_data, input_data, output_data","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-27T14:01:30.510943Z","iopub.execute_input":"2025-10-27T14:01:30.511213Z","iopub.status.idle":"2025-10-27T14:01:30.528697Z","shell.execute_reply.started":"2025-10-27T14:01:30.511186Z","shell.execute_reply":"2025-10-27T14:01:30.528085Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"Loading NFL data...\")\nsupplementary_data, input_data, output_data = load_nfl_data()\n\nprint(\"Dataset shapes:\")\nprint(f\"Supplementary Data: {supplementary_data.shape}\")\nprint(f\"Input Data: {input_data.shape}\")\nprint(f\"Output Data: {output_data.shape}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-27T14:01:30.52963Z","iopub.execute_input":"2025-10-27T14:01:30.529909Z","iopub.status.idle":"2025-10-27T14:01:32.168628Z","shell.execute_reply.started":"2025-10-27T14:01:30.52989Z","shell.execute_reply":"2025-10-27T14:01:32.167918Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"\\nSupplementary Data Columns:\")\nprint(supplementary_data.columns.tolist())\n\nprint(\"\\nInput Data Columns:\")\nprint(input_data.columns.tolist())\n\nprint(\"\\nOutput Data Columns:\")\nprint(output_data.columns.tolist())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-27T14:01:32.172317Z","iopub.execute_input":"2025-10-27T14:01:32.172631Z","iopub.status.idle":"2025-10-27T14:01:32.177739Z","shell.execute_reply.started":"2025-10-27T14:01:32.172612Z","shell.execute_reply":"2025-10-27T14:01:32.176822Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"\\nSupplementary Data Info:\")\nprint(supplementary_data.info())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-27T14:01:32.178652Z","iopub.execute_input":"2025-10-27T14:01:32.179008Z","iopub.status.idle":"2025-10-27T14:01:32.219414Z","shell.execute_reply.started":"2025-10-27T14:01:32.178982Z","shell.execute_reply":"2025-10-27T14:01:32.218418Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"Missing values in Supplementary Data:\")\nmissing_supp = supplementary_data.isnull().sum()\nprint(missing_supp[missing_supp > 0])\n\nprint(\"\\nMissing values in Input Data:\")\nmissing_input = input_data.isnull().sum()\nprint(missing_input[missing_input > 0])\n\nprint(\"\\nMissing values in Output Data:\")\nprint(output_data.isnull().sum())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-27T14:01:32.220555Z","iopub.execute_input":"2025-10-27T14:01:32.220884Z","iopub.status.idle":"2025-10-27T14:01:32.479173Z","shell.execute_reply.started":"2025-10-27T14:01:32.220853Z","shell.execute_reply":"2025-10-27T14:01:32.478183Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# DATA PREPROCESSING AND CLEANING","metadata":{}},{"cell_type":"code","source":"def clean_nfl_data(supplementary_data, input_data, output_data):\n    \"\"\"Clean and preprocess the NFL data\"\"\"\n    \n    # Create copies to avoid modifying original data\n    supp_clean = supplementary_data.copy()\n    input_clean = input_data.copy()\n    output_clean = output_data.copy()\n    \n    # Handle missing values in supplementary data\n    supp_clean['yardline_side'] = supp_clean['yardline_side'].fillna('UNK')\n    supp_clean['route_of_targeted_receiver'] = supp_clean['route_of_targeted_receiver'].fillna('UNKNOWN')\n    supp_clean['play_action'] = supp_clean['play_action'].fillna('UNK')\n    supp_clean['dropback_type'] = supp_clean['dropback_type'].fillna('UNK')\n    supp_clean['pass_location_type'] = supp_clean['pass_location_type'].fillna('UNK')\n    supp_clean['team_coverage_man_zone'] = supp_clean['team_coverage_man_zone'].fillna('UNK')\n    supp_clean['team_coverage_type'] = supp_clean['team_coverage_type'].fillna('UNK')\n    supp_clean['penalty_yards'] = supp_clean['penalty_yards'].fillna(0)\n    \n    # Clean input data - handle numeric conversions\n    numeric_columns = ['player_height', 'player_weight', 's', 'a', 'dir', 'o', 'x', 'y']\n    for col in numeric_columns:\n        if col in input_clean.columns:\n            input_clean[f'{col}_clean'] = pd.to_numeric(input_clean[col], errors='coerce')\n    \n    # Remove rows with critical missing values\n    input_clean = input_clean.dropna(subset=['x_clean', 'y_clean', 's_clean'])\n    \n    return supp_clean, input_clean, output_clean","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-27T14:01:32.480201Z","iopub.execute_input":"2025-10-27T14:01:32.480527Z","iopub.status.idle":"2025-10-27T14:01:32.487691Z","shell.execute_reply.started":"2025-10-27T14:01:32.480505Z","shell.execute_reply":"2025-10-27T14:01:32.486914Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"Cleaning data...\")\nsupp_clean, input_clean, output_clean = clean_nfl_data(supplementary_data, input_data, output_data)\n\nprint(f\"Cleaned Input Data Shape: {input_clean.shape}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-27T14:01:32.488553Z","iopub.execute_input":"2025-10-27T14:01:32.488928Z","iopub.status.idle":"2025-10-27T14:01:33.272642Z","shell.execute_reply.started":"2025-10-27T14:01:32.488906Z","shell.execute_reply":"2025-10-27T14:01:33.271806Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# EXPLORATORY DATA ANALYSIS","metadata":{}},{"cell_type":"code","source":"def create_football_field(ax=None):\n    \"\"\"Create a football field for visualization\"\"\"\n    if ax is None:\n        ax = plt.gca()\n    \n    # Create rectangle representing the field\n    rect = Rectangle((0, 0), 120, 53.3, linewidth=2, edgecolor='black', facecolor='green', alpha=0.2)\n    ax.add_patch(rect)\n    \n    # Add yard lines\n    for x in range(10, 120, 10):\n        ax.axvline(x=x, color='white', alpha=0.5, linestyle='-', linewidth=1)\n    \n    # Add 50-yard line\n    ax.axvline(x=60, color='white', alpha=1, linestyle='-', linewidth=2)\n    \n    # Add end zones\n    endzone1 = Rectangle((0, 0), 10, 53.3, linewidth=2, edgecolor='black', facecolor='darkblue', alpha=0.3)\n    endzone2 = Rectangle((110, 0), 10, 53.3, linewidth=2, edgecolor='black', facecolor='darkblue', alpha=0.3)\n    ax.add_patch(endzone1)\n    ax.add_patch(endzone2)\n    \n    ax.set_xlim(0, 120)\n    ax.set_ylim(0, 53.3)\n    ax.set_aspect('equal')\n    ax.set_facecolor('green')\n    \n    return ax","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-27T14:01:33.273522Z","iopub.execute_input":"2025-10-27T14:01:33.273809Z","iopub.status.idle":"2025-10-27T14:01:33.280313Z","shell.execute_reply.started":"2025-10-27T14:01:33.273764Z","shell.execute_reply":"2025-10-27T14:01:33.279494Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 1 Player Position Distribution\nplt.figure(figsize=(12, 6))\nposition_counts = input_clean['player_position'].value_counts()\ncolors = plt.cm.Set3(np.linspace(0, 1, len(position_counts)))\n\nbars = plt.bar(position_counts.index, position_counts.values, color=colors)\nplt.title('Player Position Distribution', fontsize=16, fontweight='bold')\nplt.xlabel('Position', fontsize=12)\nplt.ylabel('Count', fontsize=12)\nplt.xticks(rotation=45)\n\n# Add value labels on bars\nfor bar in bars:\n    height = bar.get_height()\n    plt.text(bar.get_x() + bar.get_width()/2., height,\n             f'{int(height)}', ha='center', va='bottom')\n\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-27T14:01:33.281209Z","iopub.execute_input":"2025-10-27T14:01:33.281462Z","iopub.status.idle":"2025-10-27T14:01:33.611194Z","shell.execute_reply.started":"2025-10-27T14:01:33.281435Z","shell.execute_reply":"2025-10-27T14:01:33.610278Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 2 Player Movement Analysis\nfig, axes = plt.subplots(2, 2, figsize=(15, 10))\n\n# Speed distribution\naxes[0,0].hist(input_clean['s_clean'].dropna(), bins=50, color='skyblue', alpha=0.7)\naxes[0,0].set_title('Player Speed Distribution', fontweight='bold')\naxes[0,0].set_xlabel('Speed (yards/s)')\naxes[0,0].set_ylabel('Frequency')\n\n# Acceleration distribution\naxes[0,1].hist(input_clean['a_clean'].dropna(), bins=50, color='lightcoral', alpha=0.7)\naxes[0,1].set_title('Player Acceleration Distribution', fontweight='bold')\naxes[0,1].set_xlabel('Acceleration (yards/sÂ²)')\naxes[0,1].set_ylabel('Frequency')\n\n# Speed by position\nspeed_by_pos = input_clean.groupby('player_position')['s_clean'].mean().sort_values(ascending=False)\naxes[1,0].bar(speed_by_pos.index, speed_by_pos.values, color='lightgreen')\naxes[1,0].set_title('Average Speed by Position', fontweight='bold')\naxes[1,0].set_xlabel('Position')\naxes[1,0].set_ylabel('Average Speed (yards/s)')\naxes[1,0].tick_params(axis='x', rotation=45)\n\n# Direction distribution\naxes[1,1].hist(input_clean['dir_clean'].dropna(), bins=50, color='gold', alpha=0.7)\naxes[1,1].set_title('Player Direction Distribution', fontweight='bold')\naxes[1,1].set_xlabel('Direction (degrees)')\naxes[1,1].set_ylabel('Frequency')\n\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-27T14:01:33.612063Z","iopub.execute_input":"2025-10-27T14:01:33.612397Z","iopub.status.idle":"2025-10-27T14:01:34.701549Z","shell.execute_reply.started":"2025-10-27T14:01:33.612362Z","shell.execute_reply":"2025-10-27T14:01:34.700643Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 3 Field Position Heatmap\nplt.figure(figsize=(15, 8))\nax = create_football_field()\n\n# Create heatmap of player positions\nvalid_positions = input_clean.dropna(subset=['x_clean', 'y_clean'])\nheatmap = ax.hexbin(valid_positions['x_clean'], valid_positions['y_clean'], \n                    gridsize=50, cmap='YlOrRd', alpha=0.8, mincnt=1)\nplt.colorbar(heatmap, ax=ax, label='Player Density')\n\nax.set_title('Player Position Heatmap on Football Field', fontsize=16, fontweight='bold')\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-27T14:01:34.702501Z","iopub.execute_input":"2025-10-27T14:01:34.702808Z","iopub.status.idle":"2025-10-27T14:01:35.163468Z","shell.execute_reply.started":"2025-10-27T14:01:34.702755Z","shell.execute_reply":"2025-10-27T14:01:35.162656Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 4 Game Situation Analysis\nfig, axes = plt.subplots(2, 2, figsize=(15, 10))\n\n# Down distribution\ndown_counts = supp_clean['down'].value_counts().sort_index()\naxes[0,0].bar(down_counts.index, down_counts.values, color='lightblue')\naxes[0,0].set_title('Play Distribution by Down', fontweight='bold')\naxes[0,0].set_xlabel('Down')\naxes[0,0].set_ylabel('Number of Plays')\n\n# Yards to go distribution\naxes[0,1].hist(supp_clean['yards_to_go'], bins=20, color='lightgreen', alpha=0.7)\naxes[0,1].set_title('Yards to Go Distribution', fontweight='bold')\naxes[0,1].set_xlabel('Yards to Go')\naxes[0,1].set_ylabel('Frequency')\n\n# Quarter distribution\nquarter_counts = supp_clean['quarter'].value_counts().sort_index()\naxes[1,0].bar(quarter_counts.index, quarter_counts.values, color='lightcoral')\naxes[1,0].set_title('Play Distribution by Quarter', fontweight='bold')\naxes[1,0].set_xlabel('Quarter')\naxes[1,0].set_ylabel('Number of Plays')\n\n# Pass result distribution\nif 'pass_result' in supp_clean.columns:\n    pass_results = supp_clean['pass_result'].value_counts()\n    axes[1,1].bar(pass_results.index, pass_results.values, color='gold')\n    axes[1,1].set_title('Pass Result Distribution', fontweight='bold')\n    axes[1,1].set_xlabel('Pass Result')\n    axes[1,1].set_ylabel('Frequency')\n    axes[1,1].tick_params(axis='x', rotation=45)\n\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-27T14:01:35.164416Z","iopub.execute_input":"2025-10-27T14:01:35.164993Z","iopub.status.idle":"2025-10-27T14:01:35.868604Z","shell.execute_reply.started":"2025-10-27T14:01:35.164958Z","shell.execute_reply":"2025-10-27T14:01:35.867842Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def create_advanced_features(input_data, supplementary_data):\n    \"\"\"Create advanced features for player movement prediction\"\"\"\n    \n    # Merge input and supplementary data\n    merged_data = input_data.merge(\n        supplementary_data[['game_id', 'play_id', 'down', 'yards_to_go', 'quarter', \n                          'possession_team', 'defensive_team', 'pass_result']],\n        on=['game_id', 'play_id'], \n        how='left'\n    )\n    \n    # Position-based features\n    merged_data['is_defensive_player'] = merged_data['player_side'] == 'defense'\n    merged_data['is_offensive_player'] = merged_data['player_side'] == 'offense'\n    \n    # Distance to ball features (if ball position available)\n    if all(col in merged_data.columns for col in ['ball_land_x', 'ball_land_y', 'x_clean', 'y_clean']):\n        merged_data['distance_to_ball_land'] = np.sqrt(\n            (merged_data['x_clean'] - merged_data['ball_land_x'])**2 + \n            (merged_data['y_clean'] - merged_data['ball_land_y'])**2\n        )\n    \n    # Game situation features\n    merged_data['is_third_down'] = (merged_data['down'] == 3).astype(int)\n    merged_data['is_fourth_down'] = (merged_data['down'] == 4).astype(int)\n    merged_data['is_short_yards'] = (merged_data['yards_to_go'] <= 3).astype(int)\n    merged_data['is_long_yards'] = (merged_data['yards_to_go'] >= 10).astype(int)\n    \n    # Player role encoding\n    role_encoder = LabelEncoder()\n    merged_data['player_role_encoded'] = role_encoder.fit_transform(merged_data['player_role'].fillna('UNK'))\n    \n    # Position grouping\n    position_groups = {\n        'QB': 'QB', 'RB': 'RB', 'FB': 'RB',\n        'WR': 'WR', 'TE': 'TE',\n        'T': 'OL', 'G': 'OL', 'C': 'OL',\n        'DE': 'DL', 'DT': 'DL', 'NT': 'DL',\n        'LB': 'LB', 'MLB': 'LB', 'OLB': 'LB',\n        'CB': 'DB', 'FS': 'DB', 'SS': 'DB', 'S': 'DB'\n    }\n    \n    merged_data['position_group'] = merged_data['player_position'].map(position_groups).fillna('OTHER')\n    \n    # Encode position groups\n    pos_group_encoder = LabelEncoder()\n    merged_data['position_group_encoded'] = pos_group_encoder.fit_transform(merged_data['position_group'])\n    \n    return merged_data\n\nprint(\"Creating advanced features...\")\nfeatured_data = create_advanced_features(input_clean, supp_clean)\nprint(f\"Featured data shape: {featured_data.shape}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-27T14:01:35.86962Z","iopub.execute_input":"2025-10-27T14:01:35.870491Z","iopub.status.idle":"2025-10-27T14:01:36.38799Z","shell.execute_reply.started":"2025-10-27T14:01:35.870467Z","shell.execute_reply":"2025-10-27T14:01:36.387304Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def prepare_model_data(featured_data, output_data):\n    \"\"\"Prepare data for machine learning models - CORRECTED VERSION\"\"\"\n    \n    # Merge with output data to get target positions\n    model_data = featured_data.merge(\n        output_data[['game_id', 'play_id', 'nfl_id', 'frame_id', 'x', 'y']],\n        on=['game_id', 'play_id', 'nfl_id', 'frame_id'],\n        how='inner',\n        suffixes=('', '_target')\n    )\n    \n    # Feature columns for modeling\n    feature_columns = [\n        'x_clean', 'y_clean', 's_clean', 'a_clean', 'dir_clean', 'o_clean',\n        'player_role_encoded', 'position_group_encoded',\n        'is_defensive_player', 'is_offensive_player',\n        'down', 'yards_to_go', 'quarter', 'is_third_down', 'is_fourth_down',\n        'is_short_yards', 'is_long_yards'\n    ]\n    \n    # Add distance features if available\n    if 'distance_to_ball_land' in model_data.columns:\n        feature_columns.append('distance_to_ball_land')\n    \n    # Target columns - ONLY x and y coordinates\n    target_columns = ['x', 'y']  # Using the original column names from output data\n    \n    # Remove rows with missing values in features or targets\n    available_features = [col for col in feature_columns if col in model_data.columns]\n    model_data_clean = model_data[available_features + target_columns].dropna()\n    \n    X = model_data_clean[available_features]\n    y = model_data_clean[target_columns]\n    \n    print(f\"Target columns: {target_columns}\")\n    print(f\"Target shape: {y.shape}\")\n    print(f\"Target sample:\\n{y.head()}\")\n    \n    return X, y, available_features","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-27T14:01:36.388653Z","iopub.execute_input":"2025-10-27T14:01:36.388929Z","iopub.status.idle":"2025-10-27T14:01:36.39593Z","shell.execute_reply.started":"2025-10-27T14:01:36.388908Z","shell.execute_reply":"2025-10-27T14:01:36.395079Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"Preparing model data...\")\nX, y, feature_columns = prepare_model_data(featured_data, output_clean)\n\nprint(f\"Features shape: {X.shape}\")\nprint(f\"Targets shape: {y.shape}\")\nprint(f\"Feature columns: {feature_columns}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-27T14:01:36.396811Z","iopub.execute_input":"2025-10-27T14:01:36.397071Z","iopub.status.idle":"2025-10-27T14:01:36.555793Z","shell.execute_reply.started":"2025-10-27T14:01:36.397051Z","shell.execute_reply":"2025-10-27T14:01:36.555086Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.2, random_state=42\n)\n\nprint(f\"Training set - X: {X_train.shape}, y: {y_train.shape}\")\nprint(f\"Testing set - X: {X_test.shape}, y: {y_test.shape}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-27T14:02:00.432864Z","iopub.execute_input":"2025-10-27T14:02:00.433824Z","iopub.status.idle":"2025-10-27T14:02:00.449685Z","shell.execute_reply.started":"2025-10-27T14:02:00.433768Z","shell.execute_reply":"2025-10-27T14:02:00.448909Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(f\"y_train columns: {y_train.columns.tolist()}\")\nprint(f\"y_train sample:\\n{y_train.head()}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-27T14:02:12.355955Z","iopub.execute_input":"2025-10-27T14:02:12.356815Z","iopub.status.idle":"2025-10-27T14:02:12.363643Z","shell.execute_reply.started":"2025-10-27T14:02:12.356756Z","shell.execute_reply":"2025-10-27T14:02:12.363009Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"scaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-27T14:02:22.169714Z","iopub.execute_input":"2025-10-27T14:02:22.170035Z","iopub.status.idle":"2025-10-27T14:02:22.228013Z","shell.execute_reply.started":"2025-10-27T14:02:22.170006Z","shell.execute_reply":"2025-10-27T14:02:22.227127Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"target_scaler = StandardScaler()\ny_train_scaled = target_scaler.fit_transform(y_train)\ny_test_scaled = target_scaler.transform(y_test)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-27T14:02:30.649478Z","iopub.execute_input":"2025-10-27T14:02:30.649765Z","iopub.status.idle":"2025-10-27T14:02:30.659363Z","shell.execute_reply.started":"2025-10-27T14:02:30.649743Z","shell.execute_reply":"2025-10-27T14:02:30.658823Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 6.1 Random Forest Model\nprint(\"Training Random Forest Model...\")\nrf_model = RandomForestRegressor(\n    n_estimators=100,\n    max_depth=15,\n    min_samples_split=5,\n    min_samples_leaf=2,\n    random_state=42,\n    n_jobs=-1\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-27T14:02:41.925764Z","iopub.execute_input":"2025-10-27T14:02:41.926388Z","iopub.status.idle":"2025-10-27T14:02:41.931011Z","shell.execute_reply.started":"2025-10-27T14:02:41.92636Z","shell.execute_reply":"2025-10-27T14:02:41.9301Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"rf_model.fit(X_train_scaled, y_train)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-27T14:02:50.201187Z","iopub.execute_input":"2025-10-27T14:02:50.201797Z","iopub.status.idle":"2025-10-27T14:03:03.512375Z","shell.execute_reply.started":"2025-10-27T14:02:50.201754Z","shell.execute_reply":"2025-10-27T14:03:03.511547Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"y_pred_rf = rf_model.predict(X_test_scaled)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-27T14:03:03.513625Z","iopub.execute_input":"2025-10-27T14:03:03.513906Z","iopub.status.idle":"2025-10-27T14:03:03.629426Z","shell.execute_reply.started":"2025-10-27T14:03:03.513886Z","shell.execute_reply":"2025-10-27T14:03:03.628822Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"rf_mae = mean_absolute_error(y_test, y_pred_rf)\nrf_rmse = np.sqrt(mean_squared_error(y_test, y_pred_rf))\n\nprint(f\"Random Forest Performance:\")\nprint(f\"MAE: {rf_mae:.4f}\")\nprint(f\"RMSE: {rf_rmse:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-27T14:03:06.078079Z","iopub.execute_input":"2025-10-27T14:03:06.078417Z","iopub.status.idle":"2025-10-27T14:03:06.087821Z","shell.execute_reply.started":"2025-10-27T14:03:06.07839Z","shell.execute_reply":"2025-10-27T14:03:06.086932Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"Training XGBoost Model...\")\n\n# XGBoost for multi-output regression\nxgb_model = xgb.XGBRegressor(\n    n_estimators=100,\n    max_depth=8,\n    learning_rate=0.1,\n    random_state=42,\n    n_jobs=-1\n)\n\nxgb_model.fit(X_train_scaled, y_train)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-27T14:03:22.198189Z","iopub.execute_input":"2025-10-27T14:03:22.198471Z","iopub.status.idle":"2025-10-27T14:03:23.63648Z","shell.execute_reply.started":"2025-10-27T14:03:22.198453Z","shell.execute_reply":"2025-10-27T14:03:23.635818Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"y_pred_xgb = xgb_model.predict(X_test_scaled)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-27T14:03:31.069727Z","iopub.execute_input":"2025-10-27T14:03:31.070289Z","iopub.status.idle":"2025-10-27T14:03:31.108632Z","shell.execute_reply.started":"2025-10-27T14:03:31.070265Z","shell.execute_reply":"2025-10-27T14:03:31.108058Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"xgb_mae = mean_absolute_error(y_test, y_pred_xgb)\nxgb_rmse = np.sqrt(mean_squared_error(y_test, y_pred_xgb))\n\nprint(f\"XGBoost Performance:\")\nprint(f\"MAE: {xgb_mae:.4f}\")\nprint(f\"RMSE: {xgb_rmse:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-27T14:03:39.463137Z","iopub.execute_input":"2025-10-27T14:03:39.463737Z","iopub.status.idle":"2025-10-27T14:03:39.472891Z","shell.execute_reply.started":"2025-10-27T14:03:39.463713Z","shell.execute_reply":"2025-10-27T14:03:39.472051Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"Training Neural Network Model...\")\n\n# Get the correct input and output dimensions\ninput_dim = X_train_scaled.shape[1]\noutput_dim = y_train_scaled.shape[1]  # This should be 2 (x, y)\n\nprint(f\"Neural Network - Input dimension: {input_dim}, Output dimension: {output_dim}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-27T14:03:55.276128Z","iopub.execute_input":"2025-10-27T14:03:55.276795Z","iopub.status.idle":"2025-10-27T14:03:55.28145Z","shell.execute_reply.started":"2025-10-27T14:03:55.276755Z","shell.execute_reply":"2025-10-27T14:03:55.280498Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"nn_model = Sequential([\n    Dense(128, activation='relu', input_shape=(input_dim,)),\n    BatchNormalization(),\n    Dropout(0.3),\n    Dense(64, activation='relu'),\n    BatchNormalization(),\n    Dropout(0.3),\n    Dense(32, activation='relu'),\n    Dense(output_dim)  # Output: x and y coordinates\n])\n\nnn_model.compile(\n    optimizer='adam',\n    loss='mse',\n    metrics=['mae']\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-27T14:04:08.390897Z","iopub.execute_input":"2025-10-27T14:04:08.391657Z","iopub.status.idle":"2025-10-27T14:04:09.525926Z","shell.execute_reply.started":"2025-10-27T14:04:08.39163Z","shell.execute_reply":"2025-10-27T14:04:09.525063Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"nn_model.summary()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-27T14:04:22.413298Z","iopub.execute_input":"2025-10-27T14:04:22.414114Z","iopub.status.idle":"2025-10-27T14:04:22.431737Z","shell.execute_reply.started":"2025-10-27T14:04:22.414086Z","shell.execute_reply":"2025-10-27T14:04:22.431083Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"Training neural network...\")\nhistory = nn_model.fit(\n    X_train_scaled, y_train_scaled,\n    validation_data=(X_test_scaled, y_test_scaled),\n    epochs=50,\n    batch_size=32,\n    verbose=1,\n    callbacks=[\n        tf.keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True),\n        tf.keras.callbacks.ReduceLROnPlateau(patience=5, factor=0.5)\n    ]\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-27T14:04:36.708042Z","iopub.execute_input":"2025-10-27T14:04:36.708344Z","iopub.status.idle":"2025-10-27T14:06:16.186205Z","shell.execute_reply.started":"2025-10-27T14:04:36.70832Z","shell.execute_reply":"2025-10-27T14:06:16.18535Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"y_pred_nn_scaled = nn_model.predict(X_test_scaled)\ny_pred_nn = target_scaler.inverse_transform(y_pred_nn_scaled)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-27T14:06:16.187935Z","iopub.execute_input":"2025-10-27T14:06:16.188179Z","iopub.status.idle":"2025-10-27T14:06:17.516871Z","shell.execute_reply.started":"2025-10-27T14:06:16.188158Z","shell.execute_reply":"2025-10-27T14:06:17.515979Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"nn_mae = mean_absolute_error(y_test, y_pred_nn)\nnn_rmse = np.sqrt(mean_squared_error(y_test, y_pred_nn))\n\nprint(f\"Neural Network Performance:\")\nprint(f\"MAE: {nn_mae:.4f}\")\nprint(f\"RMSE: {nn_rmse:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-27T14:06:17.517853Z","iopub.execute_input":"2025-10-27T14:06:17.518173Z","iopub.status.idle":"2025-10-27T14:06:17.528082Z","shell.execute_reply.started":"2025-10-27T14:06:17.518146Z","shell.execute_reply":"2025-10-27T14:06:17.527266Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Plot training history for neural network\nplt.figure(figsize=(12, 4))\n\nplt.subplot(1, 2, 1)\nplt.plot(history.history['loss'], label='Training Loss')\nplt.plot(history.history['val_loss'], label='Validation Loss')\nplt.title('Model Loss')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.legend()\n\nplt.subplot(1, 2, 2)\nplt.plot(history.history['mae'], label='Training MAE')\nplt.plot(history.history['val_mae'], label='Validation MAE')\nplt.title('Model MAE')\nplt.xlabel('Epoch')\nplt.ylabel('MAE')\nplt.legend()\n\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-27T14:06:17.529501Z","iopub.execute_input":"2025-10-27T14:06:17.52975Z","iopub.status.idle":"2025-10-27T14:06:17.94343Z","shell.execute_reply.started":"2025-10-27T14:06:17.529721Z","shell.execute_reply":"2025-10-27T14:06:17.942598Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Compare model performance\nmodels_comparison = pd.DataFrame({\n    'Model': ['Random Forest', 'XGBoost', 'Neural Network'],\n    'MAE': [rf_mae, xgb_mae, nn_mae],\n    'RMSE': [rf_rmse, xgb_rmse, nn_rmse]\n})\n\nprint(\"Model Performance Comparison:\")\nprint(models_comparison)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-27T14:06:17.944227Z","iopub.execute_input":"2025-10-27T14:06:17.944519Z","iopub.status.idle":"2025-10-27T14:06:17.952251Z","shell.execute_reply.started":"2025-10-27T14:06:17.944487Z","shell.execute_reply":"2025-10-27T14:06:17.951559Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Plot model comparison\nfig, axes = plt.subplots(1, 2, figsize=(15, 6))\n\n# MAE comparison\nbars1 = axes[0].bar(models_comparison['Model'], models_comparison['MAE'], \n                   color=['skyblue', 'lightgreen', 'lightcoral'])\naxes[0].set_title('Model Comparison - Mean Absolute Error (MAE)', fontweight='bold')\naxes[0].set_ylabel('MAE (yards)')\naxes[0].tick_params(axis='x', rotation=45)\n\n# Add value labels on bars\nfor bar in bars1:\n    height = bar.get_height()\n    axes[0].text(bar.get_x() + bar.get_width()/2., height,\n                f'{height:.3f}', ha='center', va='bottom')\n\n# RMSE comparison\nbars2 = axes[1].bar(models_comparison['Model'], models_comparison['RMSE'], \n                   color=['skyblue', 'lightgreen', 'lightcoral'])\naxes[1].set_title('Model Comparison - Root Mean Squared Error (RMSE)', fontweight='bold')\naxes[1].set_ylabel('RMSE (yards)')\naxes[1].tick_params(axis='x', rotation=45)\n\n# Add value labels on bars\nfor bar in bars2:\n    height = bar.get_height()\n    axes[1].text(bar.get_x() + bar.get_width()/2., height,\n                f'{height:.3f}', ha='center', va='bottom')\n\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-27T14:06:17.952847Z","iopub.execute_input":"2025-10-27T14:06:17.953042Z","iopub.status.idle":"2025-10-27T14:06:18.300026Z","shell.execute_reply.started":"2025-10-27T14:06:17.953026Z","shell.execute_reply":"2025-10-27T14:06:18.299211Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Feature importance from Random Forest\nfeature_importance = pd.DataFrame({\n    'feature': feature_columns,\n    'importance': rf_model.feature_importances_\n}).sort_values('importance', ascending=False)\n\nplt.figure(figsize=(10, 8))\nsns.barplot(data=feature_importance.head(15), x='importance', y='feature')\nplt.title('Top 15 Feature Importances (Random Forest)', fontweight='bold')\nplt.xlabel('Feature Importance')\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-27T14:06:18.301654Z","iopub.execute_input":"2025-10-27T14:06:18.301893Z","iopub.status.idle":"2025-10-27T14:06:18.628604Z","shell.execute_reply.started":"2025-10-27T14:06:18.301875Z","shell.execute_reply":"2025-10-27T14:06:18.627732Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def visualize_predictions_comparison(y_true, y_pred, model_name, sample_size=100):\n    \"\"\"Visualize actual vs predicted positions\"\"\"\n    \n    # Sample data for visualization\n    if len(y_true) > sample_size:\n        indices = np.random.choice(len(y_true), sample_size, replace=False)\n        y_true_sample = y_true.iloc[indices] if hasattr(y_true, 'iloc') else y_true[indices]\n        y_pred_sample = y_pred[indices]\n    else:\n        y_true_sample = y_true\n        y_pred_sample = y_pred\n    \n    fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n    \n    # Plot 1: Actual vs Predicted X coordinates\n    axes[0].scatter(y_true_sample.iloc[:, 0], y_pred_sample[:, 0], alpha=0.6, color='blue')\n    axes[0].plot([y_true_sample.iloc[:, 0].min(), y_true_sample.iloc[:, 0].max()],\n                [y_true_sample.iloc[:, 0].min(), y_true_sample.iloc[:, 0].max()], \n                'r--', linewidth=2)\n    axes[0].set_xlabel('Actual X Position')\n    axes[0].set_ylabel('Predicted X Position')\n    axes[0].set_title(f'{model_name} - X Coordinate Prediction')\n    axes[0].grid(True, alpha=0.3)\n    \n    # Plot 2: Actual vs Predicted Y coordinates\n    axes[1].scatter(y_true_sample.iloc[:, 1], y_pred_sample[:, 1], alpha=0.6, color='green')\n    axes[1].plot([y_true_sample.iloc[:, 1].min(), y_true_sample.iloc[:, 1].max()],\n                [y_true_sample.iloc[:, 1].min(), y_true_sample.iloc[:, 1].max()], \n                'r--', linewidth=2)\n    axes[1].set_xlabel('Actual Y Position')\n    axes[1].set_ylabel('Predicted Y Position')\n    axes[1].set_title(f'{model_name} - Y Coordinate Prediction')\n    axes[1].grid(True, alpha=0.3)\n    \n    plt.tight_layout()\n    plt.show()\n    \n    # Calculate error statistics\n    x_error = np.abs(y_true_sample.iloc[:, 0] - y_pred_sample[:, 0])\n    y_error = np.abs(y_true_sample.iloc[:, 1] - y_pred_sample[:, 1])\n    total_error = np.sqrt(x_error**2 + y_error**2)\n    \n    print(f\"{model_name} Error Analysis:\")\n    print(f\"X Error - Mean: {x_error.mean():.3f}, Std: {x_error.std():.3f}\")\n    print(f\"Y Error - Mean: {y_error.mean():.3f}, Std: {y_error.std():.3f}\")\n    print(f\"Total Distance Error - Mean: {total_error.mean():.3f}, Std: {total_error.std():.3f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-27T14:06:40.409422Z","iopub.execute_input":"2025-10-27T14:06:40.409736Z","iopub.status.idle":"2025-10-27T14:06:40.42283Z","shell.execute_reply.started":"2025-10-27T14:06:40.409712Z","shell.execute_reply":"2025-10-27T14:06:40.422136Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"Random Forest Prediction Analysis:\")\nvisualize_predictions_comparison(y_test, y_pred_rf, \"Random Forest\")\n\nprint(\"\\nXGBoost Prediction Analysis:\")\nvisualize_predictions_comparison(y_test, y_pred_xgb, \"XGBoost\")\n\nprint(\"\\nNeural Network Prediction Analysis:\")\nvisualize_predictions_comparison(y_test, y_pred_nn, \"Neural Network\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-27T14:06:50.414411Z","iopub.execute_input":"2025-10-27T14:06:50.415165Z","iopub.status.idle":"2025-10-27T14:06:51.683677Z","shell.execute_reply.started":"2025-10-27T14:06:50.41514Z","shell.execute_reply":"2025-10-27T14:06:51.682921Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def analyze_position_performance(featured_data, y_test, y_pred, test_indices):\n    \"\"\"Analyze model performance by player position\"\"\"\n    \n    # Get the original indices from the test set\n    if hasattr(X_test, 'index'):\n        test_data = featured_data.loc[X_test.index[test_indices]]\n    else:\n        # If we don't have indices, use the first n rows\n        test_data = featured_data.iloc[test_indices]\n    \n    # Add predictions to test data\n    test_data = test_data.copy()\n    test_data['pred_x'] = y_pred[:, 0]\n    test_data['pred_y'] = y_pred[:, 1]\n    test_data['actual_x'] = y_test.iloc[test_indices, 0].values if hasattr(y_test, 'iloc') else y_test[test_indices, 0]\n    test_data['actual_y'] = y_test.iloc[test_indices, 1].values if hasattr(y_test, 'iloc') else y_test[test_indices, 1]\n    \n    # Calculate errors\n    test_data['x_error'] = np.abs(test_data['pred_x'] - test_data['actual_x'])\n    test_data['y_error'] = np.abs(test_data['pred_y'] - test_data['actual_y'])\n    test_data['distance_error'] = np.sqrt(test_data['x_error']**2 + test_data['y_error']**2)\n    \n    # Analyze by position\n    position_performance = test_data.groupby('player_position').agg({\n        'distance_error': ['mean', 'std', 'count'],\n        'x_error': 'mean',\n        'y_error': 'mean'\n    }).round(3)\n    \n    position_performance.columns = ['_'.join(col).strip() for col in position_performance.columns.values]\n    position_performance = position_performance.sort_values('distance_error_mean')\n    \n    return position_performance, test_data","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-27T14:07:14.564345Z","iopub.execute_input":"2025-10-27T14:07:14.565041Z","iopub.status.idle":"2025-10-27T14:07:14.571966Z","shell.execute_reply.started":"2025-10-27T14:07:14.565014Z","shell.execute_reply":"2025-10-27T14:07:14.571244Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"sample_indices = np.arange(min(12709, len(y_test)))\nposition_perf, test_data_with_pred = analyze_position_performance(featured_data, y_test, y_pred_rf, sample_indices)\n\nprint(\"Position-Specific Performance (Random Forest):\")\nprint(position_perf)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-27T14:08:18.180313Z","iopub.execute_input":"2025-10-27T14:08:18.180571Z","iopub.status.idle":"2025-10-27T14:08:18.220184Z","shell.execute_reply.started":"2025-10-27T14:08:18.180554Z","shell.execute_reply":"2025-10-27T14:08:18.219443Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Plot position performance\nplt.figure(figsize=(12, 6))\npositions = position_perf.index\nerrors = position_perf['distance_error_mean']\nstd_errors = position_perf['distance_error_std']\n\nplt.bar(positions, errors, yerr=std_errors, capsize=5, color='lightblue', alpha=0.7)\nplt.title('Average Prediction Error by Player Position', fontweight='bold')\nplt.xlabel('Player Position')\nplt.ylabel('Average Distance Error (yards)')\nplt.xticks(rotation=45)\nplt.grid(True, alpha=0.3)\n\n# Add value labels\nfor i, (pos, error) in enumerate(zip(positions, errors)):\n    plt.text(i, error + 0.05, f'{error:.2f}', ha='center', va='bottom')\n\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-27T14:08:41.539984Z","iopub.execute_input":"2025-10-27T14:08:41.540658Z","iopub.status.idle":"2025-10-27T14:08:41.816188Z","shell.execute_reply.started":"2025-10-27T14:08:41.540632Z","shell.execute_reply":"2025-10-27T14:08:41.815318Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}