{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":114239,"databundleVersionId":13825858,"sourceType":"competition"},{"sourceId":13406222,"sourceType":"datasetVersion","datasetId":8508032},{"sourceId":13423458,"sourceType":"datasetVersion","datasetId":8519819}],"dockerImageVersionId":31154,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# -------------------------------\n# Global imports + cuDF accelerator\n# -------------------------------\nimport os\nUSE_CUDF = False\ntry:\n    # zero/low-code GPU acceleration for DataFrame ops\n    os.environ[\"CUDF_PANDAS_BACKEND\"] = \"cudf\"\n    import pandas as pd\n    import numpy as np\n    import cupy as cp  # optional (not strictly required below)\n    USE_CUDF = True\n    print(\"using cuda_backend pandas for faster parallel data processing\")\nexcept Exception:\n    print(\"cuda df not used\")\n    import pandas as pd\n    import numpy as np\n\nimport torch\nimport torch.nn as nn\nfrom pathlib import Path\nfrom tqdm.auto import tqdm\nfrom sklearn.preprocessing import StandardScaler\n\nfrom sklearn.model_selection import GroupKFold\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nfrom glob import glob\nimport json, pickle, re\nimport torch.nn.functional as F\n\n# ===============================\n# RUN MODE FLAGS\n# ===============================\nTRAIN = int(os.environ.get(\"TRAIN\", \"0\"))   # 1=train, 0=off\nSUB   = int(os.environ.get(\"SUB\",   \"1\"))   # 1=submission(infer), 0=off\nassert (TRAIN + SUB) == 1, \"Set exactly one of TRAIN=1 or SUB=1\"\n\n\n\n\n# -------------------------------\n# Constants & helpers\n# -------------------------------\nYARDS_TO_METERS = 0.9144\nFPS = 10.0 \nFIELD_LENGTH, FIELD_WIDTH = 120.0, 53.3\n\ndef set_seed(seed=42):\n    import random\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\nprint(\"environment set up!\")\ndef wrap_angle_deg(s):\n    # map to (-180, 180]\n    return ((s + 180.0) % 360.0) - 180.0\n\ndef unify_left_direction(df: pd.DataFrame) -> pd.DataFrame:\n    \"\"\"Mirror rightward plays so all samples are 'left' oriented (x,y, dir, o, ball_land).\"\"\"\n    if 'play_direction' not in df.columns:\n        return df\n    df = df.copy()\n    right = df['play_direction'].eq('right')\n    # positions\n    if 'x' in df.columns: df.loc[right, 'x'] = FIELD_LENGTH - df.loc[right, 'x']\n    if 'y' in df.columns: df.loc[right, 'y'] = FIELD_WIDTH  - df.loc[right, 'y']\n    # angles in degrees\n    for col in ('dir','o'):\n        if col in df.columns:\n            df.loc[right, col] = (df.loc[right, col] + 180.0) % 360.0\n    # ball landing\n    if 'ball_land_x' in df.columns:\n        df.loc[right, 'ball_land_x'] = FIELD_LENGTH - df.loc[right, 'ball_land_x']\n    if 'ball_land_y' in df.columns:\n        df.loc[right, 'ball_land_y'] = FIELD_WIDTH  - df.loc[right, 'ball_land_y']\n    return df\n\ndef invert_to_original_direction(x_u, y_u, play_dir_right: bool):\n    \"\"\"Invert unified (left) coordinates back to original play direction.\"\"\"\n    if not play_dir_right:\n        return float(x_u), float(y_u)\n    return float(FIELD_LENGTH - x_u), float(FIELD_WIDTH - y_u)\n\n# -------------------------------\n# Config\n# -------------------------------\nclass Config:\n    DATA_DIR = Path(\"/kaggle/input/nfl-big-data-bowl-2026-prediction/\")\n    OUTPUT_DIR = Path(\"./outputs\"); OUTPUT_DIR.mkdir(exist_ok=True)\n\n    MODEL_BUNDLE_DIR_TRAIN = OUTPUT_DIR / \"bundle\"           # 训练期写出\n\n    env_bundle = os.environ.get(\"MODEL_BUNDLE_DIR\")\n    MODEL_BUNDLE_DIR_SUB = Path(env_bundle) if env_bundle else Path(\"/kaggle/input/trans-my-test/outputs/bundle\")\n\n    DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n    SEED = 42\n    N_FOLDS = 5\n    BATCH_SIZE = 256\n    EPOCHS = 200\n    PATIENCE = 30\n    LEARNING_RATE = 1e-3\n\n    WINDOW_SIZE = 10\n    HIDDEN_DIM = 128\n    MAX_FUTURE_HORIZON = 94  # 不要改动这个！！！\n\n    #KNeighbours\n    N_NEIGHBORS = 7  #每帧选K个最近邻(不含自己)->兜底用\n    NEIGHBOR_RADIUS = 12.0     #近邻半径（码）\n    ADAPTIVE_NEIGHBORS = True    #开启半径优先的自适应邻接\n\n    #物理先验权重\n    W_BOUNDARY = 1e-4     # 出界惩罚\n    W_SPEED    = 1e-4     # 超速惩罚（软）\n    W_JERK     = 1e-4     # 二阶差分平滑（jerk）\n\n    MAX_SPEED_YPS = 12.0  # 每秒最大位移（码/秒）\n\nset_seed(Config.SEED)","metadata":{"_uuid":"0f17aa9a-6dc5-4a45-8065-5515f9cd9175","_cell_guid":"4f1ee572-ed92-4677-a8a9-9494c909f602","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-10-18T11:46:17.004705Z","iopub.execute_input":"2025-10-18T11:46:17.005257Z","iopub.status.idle":"2025-10-18T11:46:24.230645Z","shell.execute_reply.started":"2025-10-18T11:46:17.005222Z","shell.execute_reply":"2025-10-18T11:46:24.229929Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ===============================\n# I/O helpers for model bundle\n# ===============================\ndef _mkdir(p: Path):\n    p.mkdir(parents=True, exist_ok=True)\n\ndef _save_json(obj, path: Path):\n    with open(path, \"w\") as f:\n        json.dump(obj, f, indent=2)\n\ndef _load_json(path: Path):\n    with open(path, \"r\") as f:\n        return json.load(f)\n\ndef _save_pickle(obj, path: Path):\n    with open(path, \"wb\") as f:\n        pickle.dump(obj, f)\n\ndef _load_pickle(path: Path):\n    with open(path, \"rb\") as f:\n        return pickle.load(f)\n\ndef ensure_bundle_dirs(cfg):\n    root = cfg.MODEL_BUNDLE_DIR_TRAIN\n    _mkdir(root / \"models\")\n    _mkdir(root / \"scalers\")\n    _mkdir(root / \"meta\")\n    return root\n\ndef save_fold_artifacts(cfg, seed, fold, model_x, model_y, scaler):\n    root = ensure_bundle_dirs(cfg)\n    # models\n    torch.save(model_x.state_dict(), root / \"models\" / f\"dx_seed{seed}_fold{fold}.pth\")\n    torch.save(model_y.state_dict(), root / \"models\" / f\"dy_seed{seed}_fold{fold}.pth\")\n    # scaler\n    _save_pickle(scaler, root / \"scalers\" / f\"scaler_seed{seed}_fold{fold}.pkl\")\n\ndef save_meta(cfg, feature_cols, dir_map, fold_rmse_list, fold_assign=None):\n    root = ensure_bundle_dirs(cfg)\n    (dir_map.reset_index()\n            .to_parquet(root / \"meta\" / \"dir_map.parquet\", index=False))\n    _save_json({\n        \"feature_cols\": feature_cols,\n        \"MAX_FUTURE_HORIZON\": cfg.MAX_FUTURE_HORIZON,\n        \"WINDOW_SIZE\": cfg.WINDOW_SIZE,\n        \"SEEDS\": getattr(cfg, \"SEEDS\", [cfg.SEED]),\n        \"N_FOLDS\": cfg.N_FOLDS,\n        \"rmse_per_fold\": fold_rmse_list,\n        \"model_type\": \"st\",                # 新增\n        \"n_neighbors\": getattr(cfg, \"N_NEIGHBORS\", 7),  # 新增\n    }, root / \"meta\" / \"meta.json\")\n    if fold_assign is not None:\n        fold_assign.to_parquet(root / \"meta\" / \"train_folds.parquet\", index=False)\n\n\ndef _parse_sf(p):  # p 是 Path('.../dx_seed42_fold5.pth')\n    m = re.search(r\"seed(\\d+)_fold(\\d+)\", p.name)\n    return (int(m.group(1)), int(m.group(2))) if m else (-1, -1)\n\ndef discover_bundle_for_sub(cfg):\n    root = cfg.MODEL_BUNDLE_DIR_SUB\n    assert root and root.exists(), f\"MODEL_BUNDLE_DIR_SUB 无效: {root}\"\n    meta = _load_json(root / \"meta\" / \"meta.json\")\n    feat_cols = meta[\"feature_cols\"]\n    # 列出所有 (dx,dy,scaler) 三元组\n    model_x_paths = sorted((root/\"models\").glob(\"dx_seed*_fold*.pth\"), key=_parse_sf)\n    model_y_paths = sorted((root/\"models\").glob(\"dy_seed*_fold*.pth\"), key=_parse_sf)\n    scaler_paths  = sorted((root/\"scalers\").glob(\"scaler_seed*_fold*.pkl\"), key=_parse_sf)\n    # 简单对齐：按同样的排序顺序配对（命名规范保证顺序一一对应）\n    assert len(model_x_paths)==len(model_y_paths)==len(scaler_paths)>0, \"bundle 内文件不完整\"\n    return root, meta, feat_cols, model_x_paths, model_y_paths, scaler_paths","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-18T11:46:24.231911Z","iopub.execute_input":"2025-10-18T11:46:24.232371Z","iopub.status.idle":"2025-10-18T11:46:24.243707Z","shell.execute_reply.started":"2025-10-18T11:46:24.232352Z","shell.execute_reply":"2025-10-18T11:46:24.24284Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def compute_val_rmse(pred_dx, pred_dy, y_dx_list, y_dy_list, max_h):\n    \"\"\"\n    RMSE = sqrt( (1/(2N)) * sum( (x_true-x_pred)^2 + (y_true-y_pred)^2 ) )\n    其中 N 为所有样本在有效时间步上的总数。\n    \"\"\"\n    total_sse = 0.0\n    total_n = 0\n\n    for i in range(len(pred_dx)):\n        # 目标按 horizon 填充，并拿到 mask（哪些时间步有效）\n        tdx_full, m_dx = prepare_targets([y_dx_list[i]], max_h)\n        tdy_full, m_dy = prepare_targets([y_dy_list[i]], max_h)\n\n        # 都转成 numpy，mask 取交集更保险\n        m = (m_dx[0].cpu().numpy().astype(bool) &\n             m_dy[0].cpu().numpy().astype(bool))\n\n        tx = tdx_full[0].cpu().numpy()[m]\n        ty = tdy_full[0].cpu().numpy()[m]\n        px = pred_dx[i][m]\n        py = pred_dy[i][m]\n\n        total_sse += np.sum((px - tx)**2 + (py - ty)**2)\n        total_n   += int(m.sum())\n\n    if total_n == 0:\n        return float(\"nan\")\n    return float(np.sqrt(total_sse / (2.0 * total_n)))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-18T11:46:24.244353Z","iopub.execute_input":"2025-10-18T11:46:24.24453Z","iopub.status.idle":"2025-10-18T11:46:24.265108Z","shell.execute_reply.started":"2025-10-18T11:46:24.244516Z","shell.execute_reply":"2025-10-18T11:46:24.264539Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 仅保留你指定的 ST 特征组合（不做交互/对齐/滚动/曲率等）\nST_FEATURE_GROUPS = [\n    'time_features',     # 只保留归一化时间\n]\n\n# 严格白名单：最终送入模型的列只允许这些\nFEATURE_WHITELIST = {\n    # 基础运动学\n    'x','y','s','a','velocity_x','velocity_y','acceleration_x','acceleration_y',\n    # 角色\n    'is_offense','is_defense','is_receiver','is_coverage','is_passer',\n    # 球落点几何\n    'distance_to_ball','ball_direction_x','ball_direction_y',\n    # 时间（二选一，这里选择归一化时间，跨回合更稳）\n    'normalized_time',\n}\n\n\n\n# -------------------------------\n# Feature Engineering\n# -------------------------------\nclass FeatureEngineer:\n    \"\"\"\n    Modular, ablation-friendly feature builder (pandas or cuDF pandas-API).\n    \"\"\"\n    def __init__(self, feature_groups_to_create):\n        self.gcols = ['game_id', 'play_id', 'nfl_id']\n        self.active_groups = feature_groups_to_create\n        self.feature_creators = {\n            'distance_rate': self._create_distance_rate_features,\n            'target_alignment': self._create_target_alignment_features,\n            'multi_window_rolling': self._create_multi_window_rolling_features,\n            'extended_lags': self._create_extended_lag_features,\n            'velocity_changes': self._create_velocity_change_features,\n            'field_position': self._create_field_position_features,\n            'role_specific': self._create_role_specific_features,\n            'time_features': self._create_time_features,\n            'jerk_features': self._create_jerk_features,\n            'curvature_land_features': self._create_curvature_land_features,\n            'interaction': self._create_interaction_features,\n        }\n        self.created_feature_cols = []\n\n    def _height_to_feet(self, height_str):\n        try:\n            ft, inches = map(int, str(height_str).split('-'))\n            return ft + inches / 12\n        except Exception:\n            return 6.0\n\n    def _create_basic_features(self, df):\n        print(\"Step 1/3: Adding basic features (slim)...\")\n        df = df.copy()\n    \n        # 运动学：由 dir 推出 vx, vy, ax, ay\n        dir_rad = np.deg2rad(df['dir'].fillna(0.0).astype('float32'))\n        df['velocity_x']     = df['s'] * np.cos(dir_rad)\n        df['velocity_y']     = df['s'] * np.sin(dir_rad)\n        df['acceleration_x'] = df['a'] * np.cos(dir_rad)\n        df['acceleration_y'] = df['a'] * np.sin(dir_rad)\n    \n        # 角色\n        df['is_offense']  = (df['player_side'] == 'Offense').astype(np.int8)\n        df['is_defense']  = (df['player_side'] == 'Defense').astype(np.int8)\n        df['is_receiver'] = (df['player_role'] == 'Targeted Receiver').astype(np.int8)\n        df['is_coverage'] = (df['player_role'] == 'Defensive Coverage').astype(np.int8)\n        df['is_passer']   = (df['player_role'] == 'Passer').astype(np.int8)\n    \n        # 球落点几何（不再计算 momentum/energy/closing_speed）\n        if {'ball_land_x','ball_land_y'}.issubset(df.columns):\n            ball_dx = df['ball_land_x'] - df['x']\n            ball_dy = df['ball_land_y'] - df['y']\n            dist = np.hypot(ball_dx, ball_dy)\n            df['distance_to_ball'] = dist\n            inv = 1.0 / (dist + 1e-6)\n            df['ball_direction_x'] = ball_dx * inv\n            df['ball_direction_y'] = ball_dy * inv\n    \n        # 仅把可能作为输入的列加入 created_feature_cols（其后再做白名单过滤）\n        base = [\n            'x','y','s','a','dir','frame_id',\n            'velocity_x','velocity_y','acceleration_x','acceleration_y',\n            'is_offense','is_defense','is_receiver','is_coverage','is_passer',\n            'distance_to_ball','ball_direction_x','ball_direction_y',\n        ]\n        self.created_feature_cols.extend([c for c in base if c in df.columns])\n        return df\n\n\n    # ---- feature groups ----\n    def _create_distance_rate_features(self, df):\n        new_cols = []\n        if 'distance_to_ball' in df.columns:\n            d = df.groupby(self.gcols)['distance_to_ball'].diff()\n            df['d2ball_dt']  = d.fillna(0.0) * FPS\n            df['d2ball_ddt'] = df.groupby(self.gcols)['d2ball_dt'].diff().fillna(0.0) * FPS\n            df['time_to_intercept'] = (df['distance_to_ball'] /\n                                       (df['d2ball_dt'].abs() + 1e-3)).clip(0, 10)\n            new_cols = ['d2ball_dt','d2ball_ddt','time_to_intercept']\n        return df, new_cols\n\n    def _create_target_alignment_features(self, df):\n        new_cols = []\n        if {'ball_direction_x','ball_direction_y','velocity_x','velocity_y'}.issubset(df.columns):\n            df['velocity_alignment'] = df['velocity_x']*df['ball_direction_x'] + df['velocity_y']*df['ball_direction_y']\n            df['velocity_perpendicular'] = df['velocity_x']*(-df['ball_direction_y']) + df['velocity_y']*df['ball_direction_x']\n            new_cols.extend(['velocity_alignment','velocity_perpendicular'])\n            if {'acceleration_x','acceleration_y'}.issubset(df.columns):\n                df['accel_alignment'] = df['acceleration_x']*df['ball_direction_x'] + df['acceleration_y']*df['ball_direction_y']\n                new_cols.append('accel_alignment')\n        return df, new_cols\n\n    def _create_multi_window_rolling_features(self, df):\n        # keep it simple & compatible (works with cuDF pandas-API); vectorized rolling per group\n        new_cols = []\n        for window in (3, 5, 10):\n            for col in ('velocity_x','velocity_y','s','a'):\n                if col in df.columns:\n                    r_mean = df.groupby(self.gcols)[col].rolling(window, min_periods=1).mean()\n                    r_std  = df.groupby(self.gcols)[col].rolling(window, min_periods=1).std()\n                    # align indices\n                    r_mean = r_mean.reset_index(level=list(range(len(self.gcols))), drop=True)\n                    r_std  = r_std.reset_index(level=list(range(len(self.gcols))), drop=True)\n                    df[f'{col}_roll{window}'] = r_mean\n                    df[f'{col}_std{window}']  = r_std.fillna(0.0)\n                    new_cols.extend([f'{col}_roll{window}', f'{col}_std{window}'])\n        return df, new_cols\n\n    def _create_extended_lag_features(self, df):\n        new_cols = []\n        for lag in (1,2,3,4,5):\n            for col in ('x','y','velocity_x','velocity_y'):\n                if col in df.columns:\n                    g = df.groupby(self.gcols)[col]\n                    lagv = g.shift(lag)\n                    # safe fill for first frames (no \"future\" leakage)\n                    df[f'{col}_lag{lag}'] = lagv.fillna(g.transform('first'))\n                    new_cols.append(f'{col}_lag{lag}')\n        return df, new_cols\n\n    def _create_velocity_change_features(self, df):\n        new_cols = []\n        if 'velocity_x' in df.columns:\n            df['velocity_x_change'] = df.groupby(self.gcols)['velocity_x'].diff().fillna(0.0)\n            df['velocity_y_change'] = df.groupby(self.gcols)['velocity_y'].diff().fillna(0.0)\n            df['speed_change']      = df.groupby(self.gcols)['s'].diff().fillna(0.0)\n            d = df.groupby(self.gcols)['dir'].diff().fillna(0.0)\n            df['direction_change']  = wrap_angle_deg(d)\n            new_cols = ['velocity_x_change','velocity_y_change','speed_change','direction_change']\n        return df, new_cols\n\n    def _create_field_position_features(self, df):\n        df['dist_from_left'] = df['y']\n        df['dist_from_right'] = FIELD_WIDTH - df['y']\n        df['dist_from_sideline'] = np.minimum(df['dist_from_left'], df['dist_from_right'])\n        df['dist_from_endzone']  = np.minimum(df['x'], FIELD_LENGTH - df['x'])\n        return df, ['dist_from_sideline','dist_from_endzone']\n\n    def _create_role_specific_features(self, df):\n        new_cols = []\n        if {'is_receiver','velocity_alignment'}.issubset(df.columns):\n            df['receiver_optimality'] = df['is_receiver'] * df['velocity_alignment']\n            df['receiver_deviation']  = df['is_receiver'] * np.abs(df.get('velocity_perpendicular', 0.0))\n            new_cols.extend(['receiver_optimality','receiver_deviation'])\n        if {'is_coverage','closing_speed'}.issubset(df.columns):\n            df['defender_closing_speed'] = df['is_coverage'] * df['closing_speed']\n            new_cols.append('defender_closing_speed')\n        return df, new_cols\n\n    def _create_time_features(self, df):\n        df['frames_elapsed']  = df.groupby(self.gcols).cumcount()\n        df['normalized_time'] = df.groupby(self.gcols)['frames_elapsed'].transform(\n            lambda x: x / (x.max() + 1e-9)\n        )\n        # 只保留 normalized_time 作为模型输入（frames_elapsed 仅用于计算）\n        return df, ['normalized_time']\n\n\n    def _create_jerk_features(self, df):\n        new_cols = []\n        if 'a' in df.columns:\n            df['jerk'] = df.groupby(self.gcols)['a'].diff().fillna(0.0) * FPS\n            new_cols.append('jerk')\n        if {'acceleration_x','acceleration_y'}.issubset(df.columns):\n            df['jerk_x'] = df.groupby(self.gcols)['acceleration_x'].diff().fillna(0.0) * FPS\n            df['jerk_y'] = df.groupby(self.gcols)['acceleration_y'].diff().fillna(0.0) * FPS\n            new_cols.extend(['jerk_x','jerk_y'])\n        return df, new_cols\n    def _create_curvature_land_features(self, df):\n        \"\"\"\n        -落点侧向偏差（符号）：landing_point 相对“当前运动方向”的左右偏离\n          lateral = cross(u_dir, vector_to_land)（>0 表示落点在运动方向左侧）\n        -bearing_to_land_signed: 运动方向 vs 落点方位角\n        -速度归一化曲率： wrap(Δdir)/ (s*Δt) ，窗口化(3/5) 的均值/绝对值\n        \"\"\"\n        import numpy as np\n        # 侧向偏差 & bearing_to_land\n        if {'ball_land_x','ball_land_y'}.issubset(df.columns):\n            dx = df['ball_land_x'] - df['x']\n            dy = df['ball_land_y'] - df['y']\n            bearing = np.arctan2(dy, dx)\n            a_dir = np.deg2rad(df['dir'].fillna(0.0).values)\n            # 有符号方位差\n            df['bearing_to_land_signed'] = np.rad2deg(np.arctan2(np.sin(bearing - a_dir), np.cos(bearing - a_dir)))\n            # 侧向偏差：d × u (2D cross, z 分量)\n            ux, uy = np.cos(a_dir), np.sin(a_dir)\n            df['land_lateral_offset'] = dy*ux - dx*uy  # >0 落点在左侧\n    \n        # 曲率（按序列）\n        ddir = df.groupby(self.gcols)['dir'].diff().fillna(0.0)\n        ddir = ((ddir + 180.0) % 360.0) - 180.0\n        curvature = np.deg2rad(ddir).astype('float32') / (df['s'].replace(0, np.nan).astype('float32') * 0.1 + 1e-6)\n        df['curvature_signed'] = curvature.fillna(0.0)\n        df['curvature_abs'] = df['curvature_signed'].abs()\n    \n        # 窗口均值（3/5）\n        for w in (3,5):\n            r = df.groupby(self.gcols)['curvature_signed'].rolling(w, min_periods=1).mean().reset_index(level=[0,1,2], drop=True)\n            df[f'curv_signed_roll{w}'] = r\n            r2 = df.groupby(self.gcols)['curvature_abs'].rolling(w, min_periods=1).mean().reset_index(level=[0,1,2], drop=True)\n            df[f'curv_abs_roll{w}'] = r2\n    \n        new_cols = ['bearing_to_land_signed','land_lateral_offset',\n                    'curvature_signed','curvature_abs','curv_signed_roll3','curv_abs_roll3',\n                    'curv_signed_roll5','curv_abs_roll5']\n        return df, [c for c in new_cols if c in df.columns]\n\n    def _create_interaction_features(self, df, speed_eps=0.5):\n        \"\"\"\n        Receiver–Defender 轻量交互特征（K=1最近对手）：\n          - opp_dmin       : 与最近对手距离（裁剪到[0,30]）\n          - opp_close_rate : 相对速度在“对手→自身”方向的投影（裁剪到[-10,10]）\n          - opp_leverage   : 杠杆位符号（{-1,0,1}），当自身速度过小则置0\n        只对 player_to_predict==True 的行计算（若该列存在），其余留 NaN。\n        \"\"\"\n        need = ['x','y','velocity_x','velocity_y','player_side','frame_id']\n        if any(c not in df.columns for c in need):\n            return df, []\n        import numpy as np\n    \n        out_cols = ['opp_dmin','opp_close_rate','opp_leverage']\n        for c in out_cols:\n            if c not in df.columns:\n                df[c] = np.nan\n    \n        key = ['game_id','play_id','frame_id']\n        use_mask_global = ('player_to_predict' in df.columns)\n    \n        for _, g in df.groupby(key, sort=False):\n            if len(g) <= 1: \n                continue\n            idx = g.index.values\n            pos = g[['x','y']].values.astype('float32')\n            vel = g[['velocity_x','velocity_y']].values.astype('float32')\n            side_off = (g['player_side'].values == 'Offense')\n            side_def = ~side_off\n            tgt_mask = g['player_to_predict'].astype(bool).values if use_mask_global else np.ones(len(g), bool)\n    \n            def _assign(A_mask, B_mask):\n                A_mask = A_mask & tgt_mask\n                A_idx = np.where(A_mask)[0]\n                B_idx = np.where(B_mask)[0]\n                if len(A_idx)==0 or len(B_idx)==0:\n                    return\n                Apos, Bpos = pos[A_idx], pos[B_idx]\n                Avel, Bvel = vel[A_idx], vel[B_idx]\n    \n                dx = Apos[:,None,0] - Bpos[None,:,0]\n                dy = Apos[:,None,1] - Bpos[None,:,1]\n                D  = np.sqrt(dx*dx + dy*dy) + 1e-6\n                j  = np.argmin(D, axis=1)\n    \n                dmin = np.clip(D[np.arange(len(A_idx)), j], 0.0, 30.0)\n    \n                r   = Apos - Bpos[j]                      # opp -> self\n                u   = r / (np.linalg.norm(r, axis=1, keepdims=True) + 1e-6)\n                v_rel = Bvel[j] - Avel\n                close = np.clip(np.einsum('ij,ij->i', v_rel, u), -10.0, 10.0)\n    \n                speed   = np.linalg.norm(Avel, axis=1)\n                to_opp  = Bpos[j] - Apos                  # self -> opp\n                cross_z = to_opp[:,0]*Avel[:,1] - to_opp[:,1]*Avel[:,0]\n                lever   = np.where(speed > speed_eps, np.sign(cross_z), 0).astype('int8')\n    \n                rows = idx[A_idx]\n                df.loc[rows, 'opp_dmin']       = dmin\n                df.loc[rows, 'opp_close_rate'] = close\n                df.loc[rows, 'opp_leverage']   = lever\n    \n            _assign(side_off, side_def)   # Offense w.r.t Defense\n            _assign(side_def, side_off)   # Defense w.r.t Offense\n    \n        return df, out_cols\n\n\n    def transform(self, df):\n        df = df.copy().sort_values(['game_id','play_id','nfl_id','frame_id'])\n        df = self._create_basic_features(df)\n\n        print(\"\\nStep 2/3: Adding selected advanced features...\")\n        for group_name in self.active_groups:\n            if group_name in self.feature_creators:\n                creator = self.feature_creators[group_name]\n                df, new_cols = creator(df)\n                self.created_feature_cols.extend(new_cols)\n                print(f\"  [+] Added '{group_name}' ({len(new_cols)} cols)\")\n            else:\n                print(f\"  [!] Unknown feature group: {group_name}\")\n\n        final_cols = sorted(set(self.created_feature_cols))\n        # 白名单过滤 —— 只让指定列进入模型\n        final_cols = [c for c in final_cols if c in FEATURE_WHITELIST]\n        print(f\"\\nTotal features used (whitelist): {len(final_cols)} -> {final_cols}\")\n        return df, final_cols\n","metadata":{"_uuid":"e5c16db3-f9a3-4576-937c-a051125c999e","_cell_guid":"b6992e5d-b44e-4bd7-982e-69dff1718229","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-10-18T11:46:24.266654Z","iopub.execute_input":"2025-10-18T11:46:24.266873Z","iopub.status.idle":"2025-10-18T11:46:24.418585Z","shell.execute_reply.started":"2025-10-18T11:46:24.266858Z","shell.execute_reply":"2025-10-18T11:46:24.417784Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# -------------------------------\n# Sequence builder (unified frame + safe targets)\n# -------------------------------\ndef build_play_direction_map(df_in: pd.DataFrame) -> pd.Series:\n    \"\"\"\n    Return a Series indexed by (game_id, play_id) with values 'left'/'right'.\n    This keeps a clean MultiIndex that works for both pandas and cuDF pandas-API.\n    \"\"\"\n    s = (\n        df_in[['game_id','play_id','play_direction']]\n        .drop_duplicates()\n        .set_index(['game_id','play_id'])['play_direction']\n    )\n    return s  # MultiIndex Series\n\n\ndef apply_direction_to_df(df: pd.DataFrame, dir_map: pd.Series) -> pd.DataFrame:\n    \"\"\"\n    Attach play_direction (if missing) and then unify to 'left'.\n    dir_map must be the MultiIndex Series produced by build_play_direction_map.\n    \"\"\"\n    if 'play_direction' not in df.columns:\n        dir_df = dir_map.reset_index()  # -> columns: game_id, play_id, play_direction\n        df = df.merge(dir_df, on=['game_id','play_id'], how='left', validate='many_to_one')\n    return unify_left_direction(df)\n\ndef prepare_sequences_with_advanced_features(\n        input_df, output_df=None, test_template=None, \n        is_training=True, window_size=10, feature_groups=None):\n\n    print(f\"\\n{'='*80}\")\n    print(f\"PREPARING SEQUENCES WITH ADVANCED FEATURES (UNIFIED FRAME)\")\n    print(f\"{'='*80}\")\n    print(f\"Window size: {window_size}\")\n\n    if feature_groups is None:\n        feature_groups = ST_FEATURE_GROUPS   # 只保留 time_features\n    \n\n    # Direction map and unify\n    # inside prepare_sequences_with_advanced_features(...)\n    dir_map = build_play_direction_map(input_df)\n    input_df_u = unify_left_direction(input_df)\n    \n    if is_training:\n        out_u = apply_direction_to_df(output_df, dir_map)  # <-- 用新的函数\n        target_rows = out_u\n        target_groups = out_u[['game_id','play_id','nfl_id']].drop_duplicates()\n    else:\n        # ensure test_template has play_direction via safe merge\n        if 'play_direction' not in test_template.columns:\n            dir_df = dir_map.reset_index()\n            test_template = test_template.merge(dir_df, on=['game_id','play_id'], how='left', validate='many_to_one')\n        target_rows = test_template\n        target_groups = target_rows[['game_id','play_id','nfl_id','play_direction']].drop_duplicates()\n        \n    #after merging play_direction into outputs / test_template:\n    assert target_rows[['game_id','play_id','play_direction']].isna().sum().sum() == 0, \\\n        \"play_direction merge failed; check (game_id, play_id) coverage\"\n    print(\"play_direction merge OK:\", target_rows['play_direction'].value_counts(dropna=False).to_dict())\n    # --- FE ---\n\n    fe = FeatureEngineer(feature_groups)\n    processed_df, feature_cols = fe.transform(input_df_u)\n\n    # --- Build sequences ---\n    print(\"\\nStep 3/3: Creating sequences...\")\n    processed_df = processed_df.set_index(['game_id','play_id','nfl_id']).sort_index()\n    grouped = processed_df.groupby(level=['game_id','play_id','nfl_id'])\n\n    # helpful indices for last x,y in unified frame\n    idx_x = feature_cols.index('x')\n    idx_y = feature_cols.index('y')\n\n    sequences, targets_dx, targets_dy, targets_fids, seq_meta = [], [], [], [], []\n\n    it = target_groups.itertuples(index=False)\n    it = tqdm(list(it), total=len(target_groups), desc=\"Creating sequences\")\n\n    for row in it:\n        gid = row[0]; pid = row[1]; nid = row[2]\n        play_dir = row[3] if (not is_training and len(row) >= 4) else None\n        key = (gid, pid, nid)\n\n        try:\n            group_df = grouped.get_group(key)\n        except KeyError:\n            continue\n\n        input_window = group_df.tail(window_size)\n        if len(input_window) < window_size:\n            if is_training:\n                continue\n            pad_len = window_size - len(input_window)\n            pad_df = pd.DataFrame(np.nan, index=range(pad_len), columns=input_window.columns)\n            input_window = pd.concat([pad_df, input_window], ignore_index=True)\n\n        # simple impute with group means\n        input_window = input_window.fillna(group_df.mean(numeric_only=True))\n        seq = input_window[feature_cols].values\n\n        if np.isnan(seq).any():\n            if is_training:\n                continue\n            seq = np.nan_to_num(seq, nan=0.0)\n\n        sequences.append(seq)\n\n        # training targets from unified outputs (dx, dy from last unified x,y)\n        if is_training:\n            out_grp = target_rows[\n                (target_rows['game_id']==gid) &\n                (target_rows['play_id']==pid) &\n                (target_rows['nfl_id']==nid)\n            ].sort_values('frame_id')\n            if len(out_grp)==0:\n                continue\n\n            last_x = seq[-1, idx_x]\n            last_y = seq[-1, idx_y]\n            dx = out_grp['x'].values - last_x\n            dy = out_grp['y'].values - last_y\n\n            targets_dx.append(dx.astype(np.float32))\n            targets_dy.append(dy.astype(np.float32))\n            targets_fids.append(out_grp['frame_id'].values.astype(np.int32))\n\n        seq_meta.append({\n            'game_id': gid,\n            'play_id': pid,\n            'nfl_id': nid,\n            'frame_id': int(input_window.iloc[-1]['frame_id']),\n            'play_direction': (None if is_training else play_dir),\n        })\n\n    print(f\"Created {len(sequences)} sequences with {len(feature_cols)} features each\")\n\n    if is_training:\n        return sequences, targets_dx, targets_dy, targets_fids, seq_meta, feature_cols, dir_map\n    return sequences, seq_meta, feature_cols, dir_map\n\ndef prepare_sequences_spatiotemporal(\n        input_df, output_df=None, test_template=None,\n        is_training=True, window_size=10, feature_groups=None,\n        K_neighbors=7, neighbor_radius=None, adaptive_neighbors=True):\n    \"\"\"\n    返回：\n      sequences : List[np.ndarray]，每个 (T, 1+K, D) ；token0 是目标球员，其余是最近邻\n      spatial_masks : List[np.ndarray]，每个 (T, 1+K) ，真实=1，pad=0\n      targets_dx, targets_dy, targets_fids, seq_meta, feature_cols, dir_map （训练时）\n      或 sequences, spatial_masks, seq_meta, feature_cols, dir_map（推理时）\n    \"\"\"\n    print(f\"\\n{'='*80}\")\n    print(f\"PREPARING SPATIOTEMPORAL SEQUENCES (UNIFIED FRAME)\")\n    print(f\"{'='*80}\")\n    print(f\"Window size: {window_size}, K_neighbors: {K_neighbors}\")\n\n    if feature_groups is None:\n        feature_groups = ST_FEATURE_GROUPS  # 只保留你定义的精简特征组\n\n    # 方向统一 & 特征\n    dir_map = build_play_direction_map(input_df)\n    input_df_u = unify_left_direction(input_df)\n\n    if is_training:\n        out_u = apply_direction_to_df(output_df, dir_map)\n        target_rows = out_u\n        target_groups = out_u[['game_id','play_id','nfl_id']].drop_duplicates()\n    else:\n        if 'play_direction' not in test_template.columns:\n            dir_df = dir_map.reset_index()\n            test_template = test_template.merge(dir_df, on=['game_id','play_id'], how='left', validate='many_to_one')\n        target_rows = test_template\n        target_groups = target_rows[['game_id','play_id','nfl_id','play_direction']].drop_duplicates()\n\n    assert target_rows[['game_id','play_id','play_direction']].isna().sum().sum() == 0, \\\n        \"play_direction merge failed; check (game_id, play_id) coverage\"\n    print(\"play_direction merge OK:\", target_rows['play_direction'].value_counts(dropna=False).to_dict())\n\n    fe = FeatureEngineer(feature_groups)\n    processed_df, feature_cols = fe.transform(input_df_u)\n\n    # 为了按帧拿同回合的所有球员，建一个 (gid,pid,frame_id) -> 该帧 DataFrame 的简易索引\n    # 注意：此处不设索引，直接布尔筛选，保证兼容性\n    sequences, spatial_masks = [], []\n    targets_dx, targets_dy, targets_fids, seq_meta = [], [], [], []\n\n    # 需要 x,y 列用于最近邻选择\n    assert 'x' in feature_cols and 'y' in feature_cols, \"x,y 必须在特征列中用于最近邻选择\"\n\n    # helper: 从一帧里取目标 + K 最近邻，返回 (1+K, D) 和 mask (1+K,)\n    def build_tokens_for_frame(play_df, frame_id, target_id, cols, K, radius, adaptive=True):\n        fdf = play_df[play_df['frame_id'] == frame_id]\n        if len(fdf) == 0:\n            return np.zeros((1+K, len(cols)), np.float32), np.zeros((1+K,), np.float32)\n    \n        # 目标行\n        tgt = fdf[fdf['nfl_id'] == target_id]\n        if len(tgt) == 0:\n            return np.zeros((1+K, len(cols)), np.float32), np.zeros((1+K,), np.float32)\n        tgt_row = tgt.iloc[-1]\n        tx, ty = float(tgt_row['x']), float(tgt_row['y'])\n    \n        # 候选邻居（去掉自己）\n        others = fdf[fdf['nfl_id'] != target_id]\n        sel = []\n        if len(others) > 0:\n            dx = others['x'].astype('float32').values - tx\n            dy = others['y'].astype('float32').values - ty\n            d  = np.sqrt(dx*dx + dy*dy)\n    \n            if adaptive and (radius is not None):\n                within = np.where(d <= float(radius))[0]               # 半径内\n                if len(within) >= K:\n                    order = within[np.argsort(d[within])[:K]]          # 半径内再截K\n                elif len(within) > 0:\n                    rest  = np.argsort(d)                              # 半径外补足\n                    rest  = [i for i in rest if i not in within][: (K - len(within))]\n                    order = np.concatenate([within, np.array(rest, dtype=int)])\n                else:\n                    order = np.argsort(d)[:K]                          # 全靠最近的K\n            else:\n                order = np.argsort(d)[:K]\n    \n            sel = others.iloc[order]\n    \n        # 组装 tokens\n        tokens = [tgt_row[cols].values.astype('float32')]\n        if len(sel) > 0:\n            tokens.append(sel[cols].values.astype('float32'))\n        tokens = np.vstack(tokens) if len(tokens) > 1 else np.array(tokens, dtype='float32')\n\n        # >>> 关键：在 pad 前保存有效 token 数\n        n_valid = tokens.shape[0]\n\n        # pad 到 1+K\n        if tokens.shape[0] < 1+K:\n            pad = np.zeros((1+K - tokens.shape[0], tokens.shape[1]), dtype='float32')\n            tokens = np.vstack([tokens, pad])\n\n        mask = np.zeros((1+K,), dtype='float32')\n        mask[:n_valid] = 1.0\n        return tokens, mask\n\n\n\n    # 遍历目标\n    it = target_groups.itertuples(index=False)\n    it = tqdm(list(it), total=len(target_groups), desc=\"Creating ST sequences\")\n\n    # 为了高效：预先把 processed_df 分成回合粒度\n    #（避免每次循环都全表筛选）\n    # key: (gid,pid) -> 该回合 df（含所有球员、所有帧）\n    play_cache = {}\n    for row in it:\n        gid = row[0]; pid = row[1]; nid = row[2]\n        play_dir = row[3] if (not is_training and len(row) >= 4) else None\n\n        key_play = (gid, pid)\n        if key_play not in play_cache:\n            pdf = processed_df[(processed_df['game_id']==gid) & (processed_df['play_id']==pid)].copy()\n            # 缺失填充（按回合均值）\n            pdf = pdf.fillna(pdf.mean(numeric_only=True))\n            play_cache[key_play] = pdf\n        play_df = play_cache[key_play]\n\n        # 该目标的时间序列（为了拿最近 window_size 个帧号）\n        try:\n            tgt_series = play_df[play_df['nfl_id']==nid].sort_values('frame_id')\n            if len(tgt_series) == 0:\n                continue\n        except KeyError:\n            continue\n\n        frames = tgt_series['frame_id'].values\n        if len(frames) < window_size:\n            if is_training:\n                continue\n            # 测试期允许 pad 开头\n            pad_len = window_size - len(frames)\n            frames = np.concatenate([np.full(pad_len, frames[0], dtype=frames.dtype), frames])\n\n        frames = frames[-window_size:]  # 取最后 window\n\n        # 构建 (T,1+K,D)\n        T = window_size\n        D = len(feature_cols)\n        N = 1 + K_neighbors\n        seq = np.zeros((T, N, D), dtype='float32')\n        msk = np.zeros((T, N), dtype='float32')\n\n        for t_idx, fid in enumerate(frames):\n            tokens, m = build_tokens_for_frame(\n                play_df, fid, nid, feature_cols, K_neighbors,\n                radius=neighbor_radius, adaptive=adaptive_neighbors\n            )\n            seq[t_idx] = tokens\n            msk[t_idx] = m\n\n        sequences.append(seq)\n        spatial_masks.append(msk)\n\n        # 训练目标：从统一坐标的 out_u 里取真实未来坐标 → dx,dy\n        if is_training:\n            out_grp = target_rows[\n                (target_rows['game_id']==gid) &\n                (target_rows['play_id']==pid) &\n                (target_rows['nfl_id']==nid)\n            ].sort_values('frame_id')\n            if len(out_grp)==0:\n                # 没有可用的未来\n                sequences.pop(); spatial_masks.pop()\n                continue\n\n            last_x = tgt_series['x'].values[-1]\n            last_y = tgt_series['y'].values[-1]\n            dx = out_grp['x'].values - last_x\n            dy = out_grp['y'].values - last_y\n\n            targets_dx.append(dx.astype(np.float32))\n            targets_dy.append(dy.astype(np.float32))\n            targets_fids.append(out_grp['frame_id'].values.astype(np.int32))\n\n        seq_meta.append({\n            'game_id': gid,\n            'play_id': pid,\n            'nfl_id': nid,\n            'frame_id': int(frames[-1]),\n            'play_direction': (None if is_training else play_dir),\n        })\n\n    print(f\"Created {len(sequences)} ST sequences with shape (T={window_size}, N={1+K_neighbors}, D={len(feature_cols)})\")\n\n    if is_training:\n        return sequences, spatial_masks, targets_dx, targets_dy, targets_fids, seq_meta, feature_cols, dir_map\n    return sequences, spatial_masks, seq_meta, feature_cols, dir_map\n","metadata":{"_uuid":"7ce6ba09-32db-402c-accc-4dd05ccba59a","_cell_guid":"4b958933-d29e-4865-9595-be8100ede912","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-10-18T11:46:24.419508Z","iopub.execute_input":"2025-10-18T11:46:24.419768Z","iopub.status.idle":"2025-10-18T11:46:24.450605Z","shell.execute_reply.started":"2025-10-18T11:46:24.419741Z","shell.execute_reply":"2025-10-18T11:46:24.450057Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# -------------------------------\n# Model & training (same spirit as your version)\n# -------------------------------\nclass TemporalHuber(nn.Module):\n    def __init__(self, delta=0.5, time_decay=0.03):\n        super().__init__()\n        self.delta = delta\n        self.time_decay = time_decay\n\n    def forward(self, pred, target, mask,\n                last_pos=None, lower=None, upper=None,\n                step_cap=None, w_boundary=0.0, w_speed=0.0, w_jerk=0.0):\n        # --- 主 Huber ---\n        err = pred - target\n        abs_err = torch.abs(err)\n        huber = torch.where(abs_err <= self.delta,\n                            0.5 * err * err,\n                            self.delta * (abs_err - 0.5 * self.delta))\n        if self.time_decay > 0:\n            L = pred.size(1)\n            t = torch.arange(L, device=pred.device, dtype=pred.dtype)\n            w = torch.exp(-self.time_decay * t).view(1, L)\n            huber = huber * w\n            mask  = mask  * w\n        main_loss = (huber * mask).sum() / (mask.sum() + 1e-8)\n\n        # --- 速度上限（软惩罚） ---\n        speed_pen = 0.0\n        if w_speed > 0.0:\n            step = torch.cat([pred[:, :1], pred[:, 1:] - pred[:, :-1]], dim=1)\n            step_mask = torch.zeros_like(mask)\n            step_mask[:, 0] = mask[:, 0]\n            step_mask[:, 1:] = mask[:, 1:] * mask[:, :-1]\n            if step_cap is not None:\n                overflow = F.relu(torch.abs(step) - float(step_cap))\n                speed_pen = (overflow.pow(2) * step_mask).sum() / (step_mask.sum() + 1e-8)\n                speed_pen = w_speed * speed_pen\n\n        # --- jerk 平滑（二阶差分） ---\n        jerk_pen = 0.0\n        if w_jerk > 0.0 and pred.size(1) > 2:\n            step = torch.cat([pred[:, :1], pred[:, 1:] - pred[:, :-1]], dim=1)   # (B,L)\n            jerk1 = step[:, 1:] - step[:, :-1]                                   # (B,L-1)\n            jerk  = jerk1[:, 1:]                                                 # (B,L-2)\n            jerk_mask = mask[:, 2:] * mask[:, 1:-1] * mask[:, :-2]               # (B,L-2)\n            jerk_pen = (jerk.pow(2) * jerk_mask).sum() / (jerk_mask.sum() + 1e-8)\n            jerk_pen = w_jerk * jerk_pen\n\n        # --- 边界惩罚（对绝对位置） ---\n        boundary_pen = 0.0\n        if w_boundary > 0.0 and (last_pos is not None) and (lower is not None) and (upper is not None):\n            abs_pos = last_pos.unsqueeze(1) + pred\n            lower_vi = F.relu(float(lower) - abs_pos)\n            upper_vi = F.relu(abs_pos - float(upper))\n            boundary_pen = ((lower_vi.pow(2) + upper_vi.pow(2)) * mask).sum() / (mask.sum() + 1e-8)\n            boundary_pen = w_boundary * boundary_pen\n\n        return main_loss + speed_pen + jerk_pen + boundary_pen\n\n\n\nclass RelPosSpatialSelfAttn(nn.Module):\n    \"\"\"\n    x: (B, N, H) 一帧内 N 个 token（目标+近邻）\n    edge_attr: (B, N, N, E) 每对 (i,j) 的边特征\n    key_padding_mask: (B, N)  1=valid, 0=pad\n    \"\"\"\n    def __init__(self, H, heads=4, edge_dim=8, dropout=0.1):\n        super().__init__()\n        self.H, self.heads = H, heads\n        self.dk = H // heads\n        self.q = nn.Linear(H, H, bias=False)\n        self.k = nn.Linear(H, H, bias=False)\n        self.v = nn.Linear(H, H, bias=False)\n        # 边特征 -> attention bias（标量），对每个 head 共享一个标量就足够\n        self.edge_mlp = nn.Sequential(\n            nn.Linear(edge_dim, H // 4),\n            nn.GELU(),\n            nn.Linear(H // 4, 1)   # 标量 bias\n        )\n        self.out = nn.Linear(H, H)\n        self.dropout = nn.Dropout(dropout)\n\n    def forward(self, x, edge_attr, key_padding_mask=None):\n        B, N, H = x.shape\n        q = self.q(x).reshape(B, N, self.heads, self.dk).transpose(1,2)  # (B,heads,N,dk)\n        k = self.k(x).reshape(B, N, self.heads, self.dk).transpose(1,2)  # (B,heads,N,dk)\n        v = self.v(x).reshape(B, N, self.heads, self.dk).transpose(1,2)  # (B,heads,N,dk)\n\n        attn_logits = torch.matmul(q, k.transpose(-2, -1)) / (self.dk ** 0.5)  # (B,heads,N,N)\n\n        # 计算边偏置：edge_attr -> (B,N,N,1) -> broadcast 到 heads\n        bias = self.edge_mlp(edge_attr).squeeze(-1)  # (B,N,N)\n        attn_logits = attn_logits + bias.unsqueeze(1)  # (B,heads,N,N)\n\n        if key_padding_mask is not None:\n            # 将 pad 的列（被作为 key）置为 -inf\n            # key_padding_mask: 1=valid, 0=pad\n            mask = (key_padding_mask == 0).unsqueeze(1).unsqueeze(2)  # (B,1,1,N)\n            attn_logits = attn_logits.masked_fill(mask, float('-inf'))\n\n        attn = F.softmax(attn_logits, dim=-1)\n        attn = self.dropout(attn)\n        out = torch.matmul(attn, v)                      # (B,heads,N,dk)\n        out = out.transpose(1,2).reshape(B, N, H)        # (B,N,H)\n        return self.out(out)                             # (B,N,H)\n\nclass SeqModel(nn.Module):\n    def __init__(self, input_dim, horizon):\n        super().__init__()\n        # 投影到可被num_heads整除的维度\n        self.hidden_dim = 128\n        self.input_proj = nn.Linear(input_dim, self.hidden_dim)\n        \n        # 时序卷积提取局部特征\n        self.temporal_conv = nn.Sequential(\n            nn.Conv1d(self.hidden_dim, self.hidden_dim, kernel_size=3, padding=1),\n            nn.GELU(),\n            nn.BatchNorm1d(self.hidden_dim)\n        )\n        \n        # 位置编码\n        self.pos_encoding = nn.Parameter(torch.randn(1, 10, self.hidden_dim) * 0.02)\n        \n        # Transformer Encoder（更深层）\n        encoder_layer = nn.TransformerEncoderLayer(\n            d_model=self.hidden_dim,\n            nhead=4,\n            dim_feedforward=512,  # 更大的FFN\n            dropout=0.1,\n            activation='gelu',\n            batch_first=True,\n            norm_first=True\n        )\n        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=3)  # 3层\n        \n        # 双重池化：全局平均 + 注意力\n        self.pool_ln = nn.LayerNorm(self.hidden_dim)\n        self.pool_attn = nn.MultiheadAttention(\n            self.hidden_dim, \n            num_heads=4, \n            batch_first=True,\n            dropout=0.1\n        )\n        self.pool_query = nn.Parameter(torch.randn(1, 1, self.hidden_dim))\n        \n        # 融合层\n        self.fusion = nn.Linear(self.hidden_dim * 2, self.hidden_dim)\n        \n        # 输出头（更深）\n        self.head = nn.Sequential(\n            nn.Linear(self.hidden_dim, 256),\n            nn.GELU(),\n            nn.Dropout(0.2),\n            nn.Linear(256, 128),\n            nn.GELU(),\n            nn.Dropout(0.2),\n            nn.Linear(128, horizon)\n        )\n    \n    def forward(self, x):\n        # x: (B, seq_len, input_dim)\n        B, seq_len, _ = x.shape\n        \n        # 投影输入\n        x = self.input_proj(x)  # (B, seq_len, hidden_dim)\n        \n        # 时序卷积（提取局部模式）\n        x_conv = self.temporal_conv(x.transpose(1, 2)).transpose(1, 2)  # (B, seq_len, hidden_dim)\n        \n        # 残差连接 + 位置编码\n        x = x + x_conv + self.pos_encoding[:, :seq_len, :]\n        \n        # Transformer编码\n        h = self.transformer(x)  # (B, seq_len, hidden_dim)\n        \n        # 双重池化\n        # 1. 全局平均池化\n        global_pool = h.mean(dim=1)  # (B, hidden_dim)\n        \n        # 2. 注意力池化\n        q = self.pool_query.expand(B, -1, -1)  # (B, 1, hidden_dim)\n        h_norm = self.pool_ln(h)  # (B, seq_len, hidden_dim)\n        attn_pool, _ = self.pool_attn(q, h_norm, h_norm)  # (B, 1, hidden_dim)\n        attn_pool = attn_pool.squeeze(1)  # (B, hidden_dim)\n        \n        # 融合两种池化结果\n        ctx = self.fusion(torch.cat([global_pool, attn_pool], dim=1))  # (B, hidden_dim)\n        \n        # 预测\n        out = self.head(ctx)  # (B, horizon)\n        \n        # 累积和\n        return torch.cumsum(out, dim=1)  # (B, horizon)\n\nclass STModel(nn.Module):\n    def __init__(self, input_dim, horizon, hidden_dim=128, nheads=4, dropout=0.1, T_max=200,idx_offense=None):\n        super().__init__()\n        self.hidden_dim = hidden_dim\n        self.in_proj = nn.Linear(input_dim, hidden_dim)\n\n        # === 用 RelPosSpatialSelfAttn 替换原“空间 TransformerEncoder” ===\n        # 我们仍然“逐帧”做空间注意力（跟你原来一样），只是加了边偏置\n        self.spatial_attn = RelPosSpatialSelfAttn(hidden_dim, heads=nheads, edge_dim=6, dropout=dropout)\n\n        # 时间位置编码 + 时间 Transformer 保持不变\n        self.time_pos = nn.Parameter(torch.randn(1, T_max, hidden_dim) * 0.02)\n        enc = nn.TransformerEncoderLayer(d_model=hidden_dim, nhead=nheads,\n                                         dim_feedforward=hidden_dim*4, dropout=dropout,\n                                         activation='gelu', batch_first=True, norm_first=True)\n        self.temporal_encoder = nn.TransformerEncoder(enc, num_layers=2)\n\n        self.pool_ln = nn.LayerNorm(hidden_dim)\n        self.pool_attn = nn.MultiheadAttention(hidden_dim, num_heads=nheads, batch_first=True, dropout=dropout)\n        self.pool_query = nn.Parameter(torch.randn(1, 1, hidden_dim))\n\n        self.head = nn.Sequential(\n            nn.Linear(hidden_dim, 256), nn.GELU(), nn.Dropout(0.2),\n            nn.Linear(256, 128), nn.GELU(), nn.Dropout(0.2),\n            nn.Linear(128, horizon)\n        )\n        self.idx_offense = idx_offense\n\n    def _edge_features(self, tokens):\n        \"\"\"\n        tokens: (B, N, D) —— 单帧的 N 个 token（已经 in_proj 之后）\n        需要同时访问原始几何构造边特征。简化做法：\n          - 你当前的 X 序列里 feature_cols 包含 ['x','y','velocity_x','velocity_y','is_offense','is_defense',...]\n          - 下面演示只用 (Δx, Δy, d, bearing_sin, bearing_cos, same_side, role_pair)\n          - 为了最小化改动：我们从 tokens 旁路拿“原始几何”，在调用处把 raw_xy 传进来更干净。\n        \"\"\"\n        raise NotImplementedError  # 我们在 forward 里直接构造，见下\n        # 返回 (B, N, N, E)\n\n    def forward(self, x, spatial_mask=None):\n        \"\"\"\n        x: (B, T, N, D)  你现有的数据形状\n        spatial_mask: (B, T, N)  1=valid, 0=pad\n        \"\"\"\n        B, T, N, D = x.shape\n        h = self.in_proj(x)  # (B,T,N,H)\n\n        # === 逐帧做带边偏置的空间注意力 ===\n        out_frames = []\n        for t in range(T):\n            h_t = h[:, t]  # (B,N,H)\n            m_t = spatial_mask[:, t] if spatial_mask is not None else None  # (B,N)\n\n            # —— 构造边特征（E=8）——\n            # 从原始输入 x 里取几何（注意：这里假设 feature_cols 前两个是 x,y；如果不是，请用索引找到）\n            xy = x[:, t, :, -2:]                # (B,N,2) -> x,y\n            dx = xy[:, :, None, 0] - xy[:, None, :, 0]    # (B,N,N)\n            dy = xy[:, :, None, 1] - xy[:, None, :, 1]    # (B,N,N)\n            dist = torch.sqrt(dx*dx + dy*dy + 1e-6)\n            ux = dx / (dist + 1e-6); uy = dy / (dist + 1e-6)\n            # bearing 用 sin/cos 更稳定\n            edge_bearing = torch.stack([ux, uy], dim=-1)  # (B,N,N,2)\n\n            # 角色侧别（建议：把 is_offense 放在 feature_cols，下面通过索引拿）\n            # 这里假设第 idx_off 是 is_offense\n            # 如果不好拿索引，也可以在构建序列时额外输出一份 side 标记\n            # 为演示，尝试从 x 里抓：is_offense 在第 k 个维度\n            # 简洁起见先容错：取不到就全 1（都当进攻）\n            if (self.idx_offense is not None) and (0 <= self.idx_offense < x.shape[-1]):\n                is_off = x[:, t, :, self.idx_offense]  # (B,N)\n                same_side = (is_off[:, :, None] == is_off[:, None, :]).float().unsqueeze(-1)  # (B,N,N,1)\n            else:\n                same_side = torch.ones(B, N, N, 1, device=x.device)\n\n            # 距离裁剪/标准化（更稳）\n            d_feat = torch.clamp(dist, 0.0, 30.0) / 30.0\n            edge_attr = torch.cat([dx.unsqueeze(-1)/30.0, dy.unsqueeze(-1)/30.0,\n                                   d_feat.unsqueeze(-1), edge_bearing, same_side], dim=-1)  # (B,N,N,1+1+1+2+1=6~8)\n\n            # 做注意力\n            h_sp = self.spatial_attn(h_t, edge_attr, key_padding_mask=m_t)  # (B,N,H)\n            out_frames.append(h_sp)\n\n        z = torch.stack(out_frames, dim=1)  # (B,T,N,H)\n        tgt_seq = z[:, :, 0, :]             # 仍然只取目标 token（index=0）的时间序列 (B,T,H)\n\n        # === 时间编码保持不变 ===\n        pos = self.time_pos[:, :T, :]\n        zt = tgt_seq + pos\n        zt = self.temporal_encoder(zt)\n\n        # 池化（平均 + 注意力）\n        global_pool = zt.mean(dim=1)\n        q = self.pool_query.expand(B, -1, -1)\n        z_norm = self.pool_ln(zt)\n        attn_pool, _ = self.pool_attn(q, z_norm, z_norm)\n        attn_pool = attn_pool.squeeze(1)\n\n        ctx = 0.5 * (global_pool + attn_pool)\n        out = self.head(ctx)\n        return torch.cumsum(out, dim=1)\n\n\n\ndef prepare_targets(batch_axis, max_h):\n    tensors, masks = [], []\n    for arr in batch_axis:\n        L = len(arr)\n        padded = np.pad(arr, (0, max_h - L), constant_values=0).astype(np.float32)\n        mask = np.zeros(max_h, dtype=np.float32)\n        mask[:L] = 1.0\n        tensors.append(torch.tensor(padded))\n        masks.append(torch.tensor(mask))\n    return torch.stack(tensors), torch.stack(masks)\n\ndef train_model(X_train, y_train, X_val, y_val, input_dim, horizon, config):\n    device = config.DEVICE\n    model = SeqModel(input_dim, horizon).to(device)\n    criterion = TemporalHuber(delta=0.5, time_decay=0.03)\n    optimizer = torch.optim.AdamW(model.parameters(), lr=config.LEARNING_RATE, weight_decay=1e-5)\n    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=5, factor=0.5, verbose=False)\n\n    # build batches (keep numpy → torch)\n    def build_batches(X, Y):\n        batches = []\n        B = config.BATCH_SIZE\n        for i in range(0, len(X), B):\n            end = min(i + B, len(X))\n            xs = torch.tensor(np.stack(X[i:end]).astype(np.float32))\n            ys, ms = prepare_targets([Y[j] for j in range(i, end)], horizon)\n            batches.append((xs, ys, ms))\n        return batches\n\n    tr_batches = build_batches(X_train, y_train)\n    va_batches = build_batches(X_val,   y_val)\n\n    best_loss, best_state, bad = float('inf'), None, 0\n    for epoch in range(1, config.EPOCHS + 1):\n        model.train()\n        train_losses = []\n        for bx, by, bm in tr_batches:\n            bx, by, bm = bx.to(device), by.to(device), bm.to(device)\n            pred = model(bx)\n            loss = criterion(pred, by, bm)\n            optimizer.zero_grad()\n            loss.backward()\n            nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n            optimizer.step()\n            train_losses.append(loss.item())\n\n        model.eval()\n        val_losses = []\n        with torch.no_grad():\n            for bx, by, bm in va_batches:\n                bx, by, bm = bx.to(device), by.to(device), bm.to(device)\n                pred = model(bx)\n                val_losses.append(criterion(pred, by, bm).item())\n\n        trl, val = float(np.mean(train_losses)), float(np.mean(val_losses))\n        scheduler.step(val)\n        if epoch % 10 == 0:\n            print(f\"  Epoch {epoch}: train={trl:.4f}, val={val:.4f}\")\n\n        if val < best_loss:\n            best_loss, bad = val, 0\n            best_state = {k: v.detach().cpu().clone() for k, v in model.state_dict().items()}\n        else:\n            bad += 1\n            if bad >= config.PATIENCE:\n                print(f\"  Early stop at epoch {epoch}\")\n                break\n\n    if best_state:\n        model.load_state_dict(best_state)\n    return model, best_loss\n\n\ndef train_model_st(X_train, M_train, y_train, lastpos_train,\n                   X_val,   M_val,   y_val,   lastpos_val,\n                   input_dim, horizon, config, axis='x', idx_offense=None):\n    device = config.DEVICE\n    model = STModel(input_dim, horizon, hidden_dim=config.HIDDEN_DIM, idx_offense=idx_offense).to(device)\n    criterion = TemporalHuber(delta=0.5, time_decay=0.03)\n    optimizer = torch.optim.AdamW(model.parameters(), lr=config.LEARNING_RATE, weight_decay=1e-5)\n    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=5, factor=0.5, verbose=False)\n\n    # 场地边界 & 速度上限（每帧）\n    if axis == 'x':\n        lower, upper = 0.0, FIELD_LENGTH\n    else:\n        lower, upper = 0.0, FIELD_WIDTH\n    step_cap = config.MAX_SPEED_YPS / FPS  # ≈ 1.2 码/帧 (FPS=10)\n\n    def build_batches(X, M, Y, L):\n        batches = []\n        B = config.BATCH_SIZE\n        for i in range(0, len(X), B):\n            end = min(i + B, len(X))\n            xs = torch.tensor(np.stack(X[i:end]).astype(np.float32))      # (b,T,N,D)\n            ms = torch.tensor(np.stack(M[i:end]).astype(np.float32))      # (b,T,N)\n            ys, mm = prepare_targets([Y[j] for j in range(i, end)], horizon)  # (b,L),(b,L)\n            lp = torch.tensor(L[i:end], dtype=torch.float32)              # (b,)\n            batches.append((xs, ms, ys, mm, lp))\n        return batches\n\n    tr_batches = build_batches(X_train, M_train, y_train, lastpos_train)\n    va_batches = build_batches(X_val,   M_val,   y_val,   lastpos_val)\n\n    best_loss, best_state, bad = float('inf'), None, 0\n    for epoch in range(1, config.EPOCHS + 1):\n        model.train(); train_losses = []\n        for bx, bm_sp, by, bm, blp in tr_batches:\n            bx, bm_sp, by, bm, blp = bx.to(device), bm_sp.to(device), by.to(device), bm.to(device), blp.to(device)\n            pred = model(bx, spatial_mask=bm_sp)\n            loss = criterion(\n                pred, by, bm,\n                last_pos=blp, lower=lower, upper=upper, step_cap=step_cap,\n                w_boundary=config.W_BOUNDARY, w_speed=config.W_SPEED, w_jerk=config.W_JERK\n            )\n            optimizer.zero_grad()\n            loss.backward()\n            nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n            optimizer.step()\n            train_losses.append(loss.item())\n\n        model.eval(); val_losses = []\n        with torch.no_grad():\n            for bx, bm_sp, by, bm, blp in va_batches:\n                bx, bm_sp, by, bm, blp = bx.to(device), bm_sp.to(device), by.to(device), bm.to(device), blp.to(device)\n                pred = model(bx, spatial_mask=bm_sp)\n                val_loss = criterion(\n                    pred, by, bm,\n                    last_pos=blp, lower=lower, upper=upper, step_cap=step_cap,\n                    w_boundary=config.W_BOUNDARY, w_speed=config.W_SPEED, w_jerk=config.W_JERK\n                )\n                val_losses.append(val_loss.item())\n\n        trl, val = float(np.mean(train_losses)), float(np.mean(val_losses))\n        scheduler.step(val)\n        if epoch % 10 == 0:\n            print(f\"  Epoch {epoch}: train={trl:.4f}, val={val:.4f}\")\n\n        if val < best_loss:\n            best_loss, bad = val, 0\n            best_state = {k: v.detach().cpu().clone() for k, v in model.state_dict().items()}\n        else:\n            bad += 1\n            if bad >= config.PATIENCE:\n                print(f\"  Early stop at epoch {epoch}\")\n                break\n\n    if best_state:\n        model.load_state_dict(best_state)\n    return model, best_loss\n","metadata":{"_uuid":"158e79c8-cacf-4d2b-bbfc-378c46386b84","_cell_guid":"82b97ef0-b19a-44a5-ac09-83100a5a1882","trusted":true,"execution":{"iopub.status.busy":"2025-10-18T11:46:24.451501Z","iopub.execute_input":"2025-10-18T11:46:24.451706Z","iopub.status.idle":"2025-10-18T11:46:24.498581Z","shell.execute_reply.started":"2025-10-18T11:46:24.45169Z","shell.execute_reply":"2025-10-18T11:46:24.497841Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ------------------------------_\n# Main pipeline (MODIFICADO PARA ENSEMBLE DE SEMILLAS)\n# ------------------------------_\nclass CFG(Config):\n    # Añadimos la lista de semillas para el ensemble\n    SEEDS = [42, 19, 89,64] # ¡Puedes cambiar o añadir más semillas aquí!\n\ndef train_mode(cfg):\n    print(\"=\"*80)\n    print(f\"TRAIN MODE: seeds={getattr(cfg,'SEEDS',[cfg.SEED])}, folds={cfg.N_FOLDS}\")\n    print(\"=\"*80)\n\n    # [1] 读训练数据（仅 train 模式才需要全量训练集）\n    train_input_files  = [cfg.DATA_DIR / f\"train/input_2023_w{w:02d}.csv\"  for w in range(1, 19)]\n    train_output_files = [cfg.DATA_DIR / f\"train/output_2023_w{w:02d}.csv\" for w in range(1, 19)]\n    train_input  = pd.concat([pd.read_csv(f) for f in train_input_files  if f.exists()], ignore_index=True)\n    train_output = pd.concat([pd.read_csv(f) for f in train_output_files if f.exists()], ignore_index=True)\n\n    # [2] FE + 序列构建\n    seqs, smasks, tdx, tdy, tfids, seq_meta, feature_cols, dir_map = prepare_sequences_spatiotemporal(\n        train_input, output_df=train_output, is_training=True,\n        window_size=cfg.WINDOW_SIZE, K_neighbors=cfg.N_NEIGHBORS,\n        neighbor_radius=cfg.NEIGHBOR_RADIUS, adaptive_neighbors=cfg.ADAPTIVE_NEIGHBORS\n    )\n    sequences = list(seqs); targets_dx = list(tdx); targets_dy = list(tdy)\n\n    # === last_pos（统一坐标系）用于物理先验 ===\n    idx_x = feature_cols.index('x')\n    idx_y = feature_cols.index('y')\n    last_x_all = np.array([seqs[i][-1, 0, idx_x] for i in range(len(seqs))], dtype=np.float32)\n    last_y_all = np.array([seqs[i][-1, 0, idx_y] for i in range(len(seqs))], dtype=np.float32)\n\n\n    # 记录每个样本的 fold 分配（可复现实验）\n    groups = np.array([d['game_id'] for d in seq_meta])\n    fold_assign_rows = []\n\n    fold_rmse_list = []\n    for seed in getattr(cfg, \"SEEDS\", [cfg.SEED]):\n        set_seed(seed)\n        gkf = GroupKFold(n_splits=cfg.N_FOLDS)\n        for fold, (tr, va) in enumerate(gkf.split(sequences, groups=groups), 1):\n            print(f\"\\n=== Seed {seed} | Fold {fold}/{cfg.N_FOLDS} ===\")\n            # 记录样本→fold（只记录一次即可）\n            if seed == getattr(cfg, \"SEEDS\", [cfg.SEED])[0]:\n                for idx in va:\n                    fold_assign_rows.append({\n                        \"game_id\": seq_meta[idx]['game_id'],\n                        \"play_id\": seq_meta[idx]['play_id'],\n                        \"nfl_id\" : seq_meta[idx]['nfl_id'],\n                        \"fold\": fold\n                    })\n\n            # X_tr = [sequences[i] for i in tr]; X_va = [sequences[i] for i in va]\n            # X 是 List[(T,N,D)]，把 (T*N,D) 拼起来做 scaler\n            def _stack_for_fit(X):\n                mats = []\n                for s in X:\n                    TN, D = s.shape[0]*s.shape[1], s.shape[2]\n                    mats.append(s.reshape(TN, D))\n                return np.vstack(mats)\n            \n            X_tr, X_va = [seqs[i] for i in tr], [seqs[i] for i in va]\n            M_tr, M_va = [smasks[i] for i in tr], [smasks[i] for i in va]\n            \n            scaler = StandardScaler().fit(_stack_for_fit(X_tr))\n            def _transform(X):\n                out = []\n                for s in X:\n                    T,N,D = s.shape\n                    ss = scaler.transform(s.reshape(T*N, D)).reshape(T,N,D)\n                    out.append(ss.astype(np.float32))\n                return np.stack(out)\n            \n            X_tr_sc = _transform(X_tr)\n            X_va_sc = _transform(X_va)\n            # --- 追加未标准化的 is_offense / x / y 通道 ---\n            idx_x = feature_cols.index('x')\n            idx_y = feature_cols.index('y')\n            idx_off = feature_cols.index('is_offense') if 'is_offense' in feature_cols else None\n            \n            def augment_with_raw(X_sc, X_raw, idx_x, idx_y, idx_off):\n                out = []\n                for s_sc, s_raw in zip(list(X_sc), X_raw):  # X_raw 是 list，X_sc 是 np.ndarray\n                    raw_xy  = s_raw[..., [idx_x, idx_y]].astype(np.float32)          # (T,N,2)\n                    parts = [s_sc]\n                    if idx_off is not None:\n                        raw_off = s_raw[..., [idx_off]].astype(np.float32)           # (T,N,1)\n                        parts.append(raw_off)                                        # 先拼 raw_off\n                        raw_off_idx = s_sc.shape[-1]                                 # 追加后的索引用它\n                    else:\n                        raw_off_idx = None\n                    parts.append(raw_xy)                                             # 最后拼 raw_x, raw_y\n                    out.append(np.concatenate(parts, axis=-1))\n                X_aug = np.stack(out)\n                return X_aug, raw_off_idx\n            \n            X_tr_aug, idx_off_raw = augment_with_raw(X_tr_sc, X_tr, idx_x, idx_y, idx_off)\n            X_va_aug, _           = augment_with_raw(X_va_sc, X_va, idx_x, idx_y, idx_off)\n\n            \n            # idx_off = feature_cols.index('is_offense') if 'is_offense' in feature_cols else None\n            \n            mx, loss_x = train_model_st(\n                X_tr_aug, M_tr, [tdx[i] for i in tr], last_x_all[tr],\n                X_va_aug, M_va, [tdx[i] for i in va], last_x_all[va],\n                X_tr_aug.shape[-1], cfg.MAX_FUTURE_HORIZON, cfg, axis='x',\n                idx_offense=idx_off_raw  # <-- 用原始 is_offense 的通道索引\n            )\n            my, loss_y = train_model_st(\n                X_tr_aug, M_tr, [tdy[i] for i in tr], last_y_all[tr],\n                X_va_aug, M_va, [tdy[i] for i in va], last_y_all[va],\n                X_tr_aug.shape[-1], cfg.MAX_FUTURE_HORIZON, cfg, axis='y',\n                idx_offense=idx_off_raw\n            )\n\n\n            # 计算验证 RMSE（与你原来一样）\n            mx.eval(); my.eval()\n            with torch.no_grad():\n                # X_va_t = torch.tensor(X_va_sc).to(cfg.DEVICE)\n                X_va_t = torch.tensor(X_va_aug).to(cfg.DEVICE)\n                M_va_t = torch.tensor(np.stack(M_va).astype(np.float32)).to(cfg.DEVICE)\n                with torch.no_grad():\n                    pred_dx = mx(X_va_t, spatial_mask=M_va_t).cpu().numpy()\n                    pred_dy = my(X_va_t, spatial_mask=M_va_t).cpu().numpy()\n\n            y_va_dx = [targets_dx[i] for i in va]\n            y_va_dy = [targets_dy[i] for i in va]\n            # sqe = []\n            # for i in range(len(pred_dx)):\n            #     tdx_full, m_dx = prepare_targets([y_va_dx[i]], cfg.MAX_FUTURE_HORIZON)\n            #     tdy_full, m_dy = prepare_targets([y_va_dy[i]], cfg.MAX_FUTURE_HORIZON)\n            #     m = m_dx[0].cpu().numpy().astype(bool)\n            #     dx_err = (pred_dx[i][m] - tdx_full[0].cpu().numpy()[m])**2\n            #     dy_err = (pred_dy[i][m] - tdy_full[0].cpu().numpy()[m])**2\n            #     sqe.extend(dx_err + dy_err)\n            rmse = compute_val_rmse(pred_dx, pred_dy, y_va_dx, y_va_dy, cfg.MAX_FUTURE_HORIZON)\n            fold_rmse_list.append(rmse)\n            print(f\"[Fold {fold} | Seed {seed}] val_huber: dx={loss_x:.4f}, dy={loss_y:.4f} | RMSE={rmse:.5f}\")\n\n\n\n            # [保存本 fold/seed 的模型与 scaler]\n            save_fold_artifacts(cfg, seed, fold, mx, my, scaler)\n            \n    print(\"\\n\" + \"=\"*80)\n    print(\"VALID RMSE by fold (all seeds × folds)\")\n    print(\"=\"*80)\n    for i, r in enumerate(fold_rmse_list, 1):\n        print(f\"{i:02d}: RMSE = {r:.5f}\")\n    rmse_mean = float(np.mean(fold_rmse_list)) if len(fold_rmse_list) else float(\"nan\")\n    rmse_std  = float(np.std(fold_rmse_list))  if len(fold_rmse_list) else float(\"nan\")\n    print(\"-\"*80)\n    print(f\"Mean RMSE: {rmse_mean:.5f} | Std: {rmse_std:.5f}\")\n    print(\"=\"*80)\n    # 保存元信息\n    fold_assign_df = pd.DataFrame(fold_assign_rows) if fold_assign_rows else None\n    save_meta(cfg, feature_cols, dir_map, fold_rmse_list, fold_assign=fold_assign_df)\n\n    print(\"\\nBundle 已写出到:\", cfg.MODEL_BUNDLE_DIR_TRAIN.resolve())\n\ndef sub_mode(cfg):\n    print(\"=\"*80)\n    print(\"SUB MODE: 仅推理（从 bundle 读取模型与scaler）\")\n    print(\"=\"*80)\n\n    # [1] 读测试数据\n    test_input    = pd.read_csv(cfg.DATA_DIR / \"test_input.csv\")\n    test_template = pd.read_csv(cfg.DATA_DIR / \"test.csv\")\n\n    # [2] 读取 bundle 元信息 + 模型/Scaler 列表\n    root, meta, feat_cols, model_x_paths, model_y_paths, scaler_paths = discover_bundle_for_sub(cfg)\n\n    # [3] 用“时空”构建器拿 (T,N,D) 和 mask\n    test_seqs, test_smasks, test_meta, feat_cols_t, dir_map_test = prepare_sequences_spatiotemporal(\n        test_input, test_template=test_template, is_training=False,\n        window_size=meta[\"WINDOW_SIZE\"], K_neighbors=cfg.N_NEIGHBORS,\n        neighbor_radius=cfg.NEIGHBOR_RADIUS, adaptive_neighbors=cfg.ADAPTIVE_NEIGHBORS\n    )\n    assert feat_cols_t == feat_cols, \"Train/Test 特征列不一致，请检查 bundle 的 feature_cols\"\n\n    # [3.1] 取 idx_x/idx_y，并在 unified frame 下取“目标 token(0)”的最后一帧位置\n    idx_x = feat_cols.index('x'); idx_y = feat_cols.index('y')\n    X_test_raw = list(test_seqs)\n    x_last_uni = np.array([s[-1, 0, idx_x] for s in X_test_raw], dtype=np.float32)  # 注意 N 维度取 0\n    y_last_uni = np.array([s[-1, 0, idx_y] for s in X_test_raw], dtype=np.float32)\n\n    # [4] 标准化函数（对 T*N 维一起做）\n    def _transform_list(X_list, scaler):\n        out = []\n        for s in X_list:\n            T,N,D = s.shape\n            out.append(scaler.transform(s.reshape(T*N, D)).reshape(T,N,D).astype(np.float32))\n        return np.stack(out)\n\n    # [4.1] 逐个 (模型, scaler) 推理并集成\n    all_preds_dx, all_preds_dy = [], []\n    for mx_path, my_path, sc_path in zip(model_x_paths, model_y_paths, scaler_paths):\n        scaler = _load_pickle(sc_path)\n        X_sc = _transform_list(X_test_raw, scaler)\n        # 追加未标准化通道（保持最后两维是 raw_x, raw_y；并返回 raw_is_offense 的索引）\n        idx_x = feat_cols.index('x'); idx_y = feat_cols.index('y')\n        idx_off = feat_cols.index('is_offense') if 'is_offense' in feat_cols else None\n        \n        def augment_with_raw_list(X_sc, X_raw_list, idx_x, idx_y, idx_off):\n            out = []\n            for s_sc, s_raw in zip(list(X_sc), X_raw_list):\n                raw_xy = s_raw[..., [idx_x, idx_y]].astype(np.float32)\n                parts = [s_sc]\n                if idx_off is not None:\n                    raw_off = s_raw[..., [idx_off]].astype(np.float32)\n                    parts.append(raw_off)\n                    raw_off_idx = s_sc.shape[-1]\n                else:\n                    raw_off_idx = None\n                parts.append(raw_xy)\n                out.append(np.concatenate(parts, axis=-1))\n            X_aug = np.stack(out)\n            return X_aug, raw_off_idx\n        \n        X_aug, idx_off_raw = augment_with_raw_list(X_sc, X_test_raw, idx_x, idx_y, idx_off)\n        \n        X_t  = torch.tensor(X_aug).to(cfg.DEVICE)\n        M_t  = torch.tensor(np.stack(test_smasks).astype(np.float32)).to(cfg.DEVICE)\n        \n        input_dim = X_aug.shape[-1]; horizon = meta[\"MAX_FUTURE_HORIZON\"]\n        m_dx = STModel(input_dim, horizon, hidden_dim=cfg.HIDDEN_DIM, idx_offense=idx_off_raw).to(cfg.DEVICE)\n        m_dy = STModel(input_dim, horizon, hidden_dim=cfg.HIDDEN_DIM, idx_offense=idx_off_raw).to(cfg.DEVICE)\n        m_dx.load_state_dict(torch.load(mx_path, map_location=cfg.DEVICE))\n        m_dy.load_state_dict(torch.load(my_path, map_location=cfg.DEVICE))\n        m_dx.eval(); m_dy.eval()\n        with torch.no_grad():\n            all_preds_dx.append(m_dx(X_t, spatial_mask=M_t).cpu().numpy())\n            all_preds_dy.append(m_dy(X_t, spatial_mask=M_t).cpu().numpy())\n\n    ens_dx = np.mean(all_preds_dx, axis=0)\n    ens_dy = np.mean(all_preds_dy, axis=0)\n    H = ens_dx.shape[1]\n\n    # [5] 组装 submission（把 unified 坐标反变换回原方向）\n    rows = []\n    tt_idx = test_template.set_index(['game_id','play_id','nfl_id']).sort_index()\n    for i, meta_row in enumerate(test_meta):\n        gid = meta_row['game_id']; pid = meta_row['play_id']; nid = meta_row['nfl_id']\n        play_dir = meta_row['play_direction']; play_is_right = (play_dir == 'right')\n        try:\n            fids = tt_idx.loc[(gid,pid,nid),'frame_id']\n            fids = fids.sort_values().tolist() if isinstance(fids, pd.Series) else [int(fids)]\n        except KeyError:\n            continue\n        for t, fid in enumerate(fids):\n            tt = min(t, H-1)\n            x_uni = np.clip(x_last_uni[i] + ens_dx[i, tt], 0, FIELD_LENGTH)\n            y_uni = np.clip(y_last_uni[i] + ens_dy[i, tt], 0, FIELD_WIDTH)\n            x_out, y_out = invert_to_original_direction(x_uni, y_uni, play_is_right)\n            rows.append({'id': f\"{gid}_{pid}_{nid}_{int(fid)}\", 'x': x_out, 'y': y_out})\n\n    sub = pd.DataFrame(rows)\n    sub.to_csv(\"submission.csv\", index=False)\n    print(f\"submission.csv 生成完毕，行数={len(sub)}\")\n\n\n\n\ndef main():\n    cfg = CFG()\n    if TRAIN == 1 and SUB == 0:\n        cfg.MODEL_BUNDLE_DIR_TRAIN = cfg.OUTPUT_DIR / \"bundle\"\n        train_mode(cfg)\n    elif TRAIN == 0 and SUB == 1:\n        # 在 Kaggle “Add Input” 里把你上传的 bundle 数据集挂上来，\n        # 然后设置环境变量 MODEL_BUNDLE_DIR 指向那个目录（或这里手动写死）\n        if not cfg.MODEL_BUNDLE_DIR_SUB:\n            # 回退：尝试自动探测唯一的 /kaggle/input/*-bundle*\n            candidates = [Path(p) for p in glob(\"/kaggle/input/*\")]\n            # 选择带 bundle 关键字的，或只有一个输入目录时就用它\n            bundles = [c for c in candidates if \"bundle\" in c.name.lower()]\n            cfg.MODEL_BUNDLE_DIR_SUB = bundles[0] if bundles else candidates[0]\n            print(\"自动选择 MODEL_BUNDLE_DIR_SUB =\", cfg.MODEL_BUNDLE_DIR_SUB)\n        sub_mode(cfg)\n    else:\n        raise ValueError(\"Set exactly one of TRAIN=1 or SUB=1\")\n\nif __name__ == \"__main__\":\n    main()\n\n","metadata":{"_uuid":"3ca303d2-ec2b-4690-a186-3f93c8638529","_cell_guid":"725dcc39-caed-4588-a453-ab09e6294699","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-10-18T11:46:24.499214Z","iopub.execute_input":"2025-10-18T11:46:24.499416Z","iopub.status.idle":"2025-10-18T11:46:47.397717Z","shell.execute_reply.started":"2025-10-18T11:46:24.499401Z","shell.execute_reply":"2025-10-18T11:46:47.396877Z"}},"outputs":[],"execution_count":null}]}