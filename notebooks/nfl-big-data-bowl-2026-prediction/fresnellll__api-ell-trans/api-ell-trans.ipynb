{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":114239,"databundleVersionId":14210809,"isSourceIdPinned":false,"sourceType":"competition"},{"sourceId":13474701,"sourceType":"datasetVersion","datasetId":8554179},{"sourceId":13495568,"sourceType":"datasetVersion","datasetId":8568508},{"sourceId":13495864,"sourceType":"datasetVersion","datasetId":8568709}],"dockerImageVersionId":31154,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# =============================================================================\n# Kaggle NFL 2026 - API Submission Script for Model v4.9_2D (Joint Prediction)\n#\n# 基于 trans_v4_9_2D_copy.py 的训练脚本生成。\n#\n# 变更日志:\n# - [架构] 从两个独立的 x, y 模型切换为单一的联合预测 (dx, dy) 模型。\n# - [特征] 完全同步了 v4.9_2D 脚本中所有最新的特征工程逻辑。\n# - [推理] 简化了 5 折集成流程，现在对 (dx, dy) 向量直接进行平均。\n# - [配置] 更新了所有模型超参数以匹配新的训练配置。\n# - [修正] 修复了 invert_to_original_direction 函数中的一个变量名错误。\n# =============================================================================\n\n# =============================================================================\n# 1. 全局导入与环境设置\n# =============================================================================\nimport os\nimport gc\nimport time\nimport pickle\nimport pandas as pd\nimport numpy as np\nimport torch\nimport torch.nn as nn\nfrom pathlib import Path\nfrom sklearn.preprocessing import StandardScaler\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nimport polars as pl\nimport kaggle_evaluation.nfl_inference_server\n\n# =============================================================================\n# 2. 核心逻辑定义 (与 trans_v4_9_2D_copy.py 保持一致)\n# =============================================================================\n\n# -------------------------------\n# 配置类\n# -------------------------------\nclass Config:\n    # [重要] 确保这个路径指向您上传的包含模型和scaler的数据集\n    MODEL_DIR = Path(\"/kaggle/input/trans-v4-9-2d-copy/outputs_v4_9_2D_copy\") \n    DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    INFERENCE_BATCH_SIZE = 256\n    N_FOLDS = 5\n    WINDOW_SIZE = 25\n    MAX_FUTURE_HORIZON = 94\n    MAX_PLAYERS = 24\n    D_MODEL = 192\n    NHEAD = 6\n    NUM_ENCODER_LAYERS = 3\n    DIM_FEEDFORWARD = 768\n    TRANSFORMER_DROPOUT = 0.15\n    PLAYER_STATIC_HIDDEN_DIM = 64\n    PLAYER_STATIC_DROPOUT = 0.2\n    GNN_HIDDEN_DIM = 64\n    GNN_DROPOUT = 0.2\n    HEAD_DROPOUT = 0.2\n    K_NEIGH = 8\n    RADIUS = 30.0\n    TAU = 8.0\n\n# -------------------------------\n# 辅助函数\n# -------------------------------\nYARDS_TO_METERS = 0.9144\nFPS = 10.0\nFIELD_LENGTH, FIELD_WIDTH = 120.0, 53.3\n\ndef wrap_angle_deg(s):\n    return ((s + 180.0) % 360.0) - 180.0\n\ndef wrap_angle_rad(angle):\n    return (angle + np.pi) % (2 * np.pi) - np.pi\n\ndef unify_left_direction(df: pd.DataFrame) -> pd.DataFrame:\n    if 'play_direction' not in df.columns: return df\n    df = df.copy()\n    right = df['play_direction'].eq('right')\n    if 'x' in df.columns: df.loc[right, 'x'] = FIELD_LENGTH - df.loc[right, 'x']\n    if 'y' in df.columns: df.loc[right, 'y'] = FIELD_WIDTH  - df.loc[right, 'y']\n    for col in ('dir','o'):\n        if col in df.columns:\n            df.loc[right, col] = (df.loc[right, col].astype(float) + 180.0) % 360.0\n    if 'ball_land_x' in df.columns:\n        df.loc[right, 'ball_land_x'] = FIELD_LENGTH - df.loc[right, 'ball_land_x']\n    if 'ball_land_y' in df.columns:\n        df.loc[right, 'ball_land_y'] = FIELD_WIDTH  - df.loc[right, 'ball_land_y']\n    return df\n\ndef invert_to_original_direction(x_u, y_u, play_dir_right: bool):\n    if not play_dir_right:\n        return float(x_u), float(y_u)\n    # [修正] 修复了训练代码中的 WIDTH -> FIELD_WIDTH 错误\n    return float(FIELD_LENGTH - x_u), float(FIELD_WIDTH - y_u)\n\n# -------------------------------\n# 特征工程 (v4.9_2D)\n# -------------------------------\nclass FeatureEngineer:\n    def __init__(self, feature_groups_to_create):\n        self.gcols = ['game_id', 'play_id', 'nfl_id']\n        self.active_groups = feature_groups_to_create\n        self.feature_creators = {\n            'distance_rate': self._create_distance_rate_features,\n            'target_alignment': self._create_target_alignment_features,\n            'multi_window_rolling': self._create_multi_window_rolling_features,\n            'extended_lags': self._create_extended_lag_features,\n            'velocity_changes': self._create_velocity_change_features,\n            'field_position': self._create_field_position_features,\n            'role_specific': self._create_role_specific_features,\n            'time_features': self._create_time_features,\n            'jerk_features': self._create_jerk_features,\n            'curvature_land_features': self._create_curvature_land_features,\n        }\n        self.created_feature_cols = []\n\n    def _height_to_feet(self, height_str):\n        try:\n            ft, inches = map(int, str(height_str).split('-'))\n            return ft + inches / 12\n        except Exception:\n            return 6.0\n\n    def _create_basic_features(self, df):\n        df = df.copy()\n        df['player_height_feet'] = df['player_height'].apply(self._height_to_feet)\n        dir_rad = np.deg2rad(df['dir'].fillna(0.0).astype('float32'))\n        df['velocity_x'] = df['s'] * np.cos(dir_rad)\n        df['velocity_y'] = df['s'] * np.sin(dir_rad)\n        df['acceleration_x'] = df['a'] * np.cos(dir_rad)\n        df['acceleration_y'] = df['a'] * np.sin(dir_rad)\n        df['is_offense']  = (df['player_side'] == 'Offense').astype(np.int8)\n        df['is_defense']  = (df['player_side'] == 'Defense').astype(np.int8)\n        df['is_receiver'] = (df['player_role'] == 'Targeted Receiver').astype(np.int8)\n        df['is_coverage'] = (df['player_role'] == 'Defensive Coverage').astype(np.int8)\n        mass_kg = df['player_weight'].fillna(200.0) / 2.20462\n        v_ms = df['s'] * YARDS_TO_METERS\n        df['momentum_x'] = mass_kg * df['velocity_x'] * YARDS_TO_METERS\n        df['momentum_y'] = mass_kg * df['velocity_y'] * YARDS_TO_METERS\n        df['kinetic_energy'] = 0.5 * mass_kg * (v_ms ** 2)\n        df['momentum_magnitude'] = np.hypot(df['momentum_x'], df['momentum_y'])\n        df['momentum_direction'] = np.arctan2(df['momentum_y'], df['momentum_x'])\n        height_m = df['player_height_feet'] * 0.3048\n        df['player_bmi'] = mass_kg / (height_m ** 2 + 1e-6)\n        df['power_weight_ratio'] = df['kinetic_energy'] / (mass_kg + 1e-6)\n\n        if {'ball_land_x','ball_land_y'}.issubset(df.columns):\n            ball_dx = df['ball_land_x'] - df['x']\n            ball_dy = df['ball_land_y'] - df['y']\n            dist = np.hypot(ball_dx, ball_dy)\n            df['distance_to_ball'] = dist\n            inv = 1.0 / (dist + 1e-6)\n            df['ball_direction_x'] = ball_dx * inv\n            df['ball_direction_y'] = ball_dy * inv\n            df['closing_speed'] = (df['velocity_x'] * df['ball_direction_x'] + df['velocity_y'] * df['ball_direction_y'])\n            df['ball_angle'] = np.arctan2(ball_dy, ball_dx)\n            df['approach_angle'] = wrap_angle_rad(df['ball_angle'] - np.arctan2(df['velocity_y'], df['velocity_x']))\n            df['distance_to_ball_squared'] = dist ** 2\n            df['ball_distance_log'] = np.log1p(dist)\n\n        base = ['x','s','a','dir','frame_id','ball_land_x','ball_land_y','player_height_feet','player_weight',\n                'velocity_x','velocity_y','acceleration_x','acceleration_y','momentum_x','momentum_y','kinetic_energy',\n                'momentum_magnitude','momentum_direction','player_bmi','power_weight_ratio','is_offense','is_defense',\n                'is_receiver','is_coverage','distance_to_ball','ball_direction_x','ball_direction_y',\n                'closing_speed','ball_angle','approach_angle','distance_to_ball_squared','ball_distance_log']\n        self.created_feature_cols.extend([c for c in base if c in df.columns])\n        return df\n\n    def _create_distance_rate_features(self, df):\n        new_cols = []\n        if 'distance_to_ball' in df.columns:\n            d = df.groupby(self.gcols)['distance_to_ball'].diff()\n            df['d2ball_dt']  = d.fillna(0.0) * FPS\n            df['d2ball_ddt'] = df.groupby(self.gcols)['d2ball_dt'].diff().fillna(0.0) * FPS\n            df['time_to_intercept'] = (df['distance_to_ball'] / (df['d2ball_dt'].abs() + 1e-3)).clip(0, 10)\n            df['d2ball_d3t'] = df.groupby(self.gcols)['d2ball_ddt'].diff().fillna(0.0) * FPS\n            df['closing_efficiency'] = df['d2ball_dt'] / (df['s'] + 1e-3)\n            df['intercept_urgency'] = 1.0 / (df['time_to_intercept'] + 0.1)\n            df['distance_ema3'] = df.groupby(self.gcols)['distance_to_ball'].transform(lambda x: x.ewm(span=3, adjust=False).mean())\n            new_cols = ['d2ball_dt','d2ball_ddt','time_to_intercept','d2ball_d3t','closing_efficiency','intercept_urgency','distance_ema3']\n        return df, new_cols\n\n    def _create_target_alignment_features(self, df):\n        new_cols = []\n        if {'ball_direction_x','ball_direction_y','velocity_x','velocity_y'}.issubset(df.columns):\n            df['velocity_alignment'] = df['velocity_x']*df['ball_direction_x'] + df['velocity_y']*df['ball_direction_y']\n            df['velocity_perpendicular'] = df['velocity_x']*(-df['ball_direction_y']) + df['velocity_y']*df['ball_direction_x']\n            new_cols.extend(['velocity_alignment','velocity_perpendicular'])\n            if {'acceleration_x','acceleration_y'}.issubset(df.columns):\n                df['accel_alignment'] = df['acceleration_x']*df['ball_direction_x'] + df['acceleration_y']*df['ball_direction_y']\n                df['accel_perpendicular'] = df['acceleration_x']*(-df['ball_direction_y']) + df['acceleration_y']*df['ball_direction_x']\n                new_cols.extend(['accel_alignment','accel_perpendicular'])\n        return df, new_cols\n\n    def _create_multi_window_rolling_features(self, df):\n        new_cols = []\n        for window in (3, 5, 10, 20):\n            for col in ('velocity_x','velocity_y','s'):\n                if col in df.columns:\n                    r_mean = df.groupby(self.gcols)[col].rolling(window, min_periods=1).mean().reset_index(level=list(range(len(self.gcols))), drop=True)\n                    r_std  = df.groupby(self.gcols)[col].rolling(window, min_periods=1).std().reset_index(level=list(range(len(self.gcols))), drop=True)\n                    df[f'{col}_roll{window}'] = r_mean\n                    df[f'{col}_std{window}']  = r_std.fillna(0.0)\n                    df[f'{col}_dev{window}'] = df[col] - r_mean\n                    new_cols.extend([f'{col}_roll{window}', f'{col}_std{window}', f'{col}_dev{window}'])\n        if 's_roll3' in df.columns and 's_roll20' in df.columns:\n            df['speed_trend_ratio'] = df['s_roll3'] / (df['s_roll20'] + 1e-3)\n            new_cols.append('speed_trend_ratio')\n        return df, new_cols\n\n    def _create_extended_lag_features(self, df):\n        new_cols = []\n        for lag in (1, 2, 3, 5, 10):\n            for col in ('velocity_x','velocity_y','s'):\n                if col in df.columns:\n                    g = df.groupby(self.gcols)[col]\n                    lagv = g.shift(lag)\n                    df[f'{col}_lag{lag}'] = lagv.fillna(g.transform('first'))\n                    new_cols.append(f'{col}_lag{lag}')\n                    if lag <= 3:\n                        df[f'{col}_diff_lag{lag}'] = df[col] - lagv.fillna(df[col])\n                        new_cols.append(f'{col}_diff_lag{lag}')\n        return df, new_cols\n\n    def _create_velocity_change_features(self, df):\n        new_cols = []\n        if 'velocity_x' in df.columns:\n            df['velocity_x_change'] = df.groupby(self.gcols)['velocity_x'].diff().fillna(0.0)\n            df['velocity_y_change'] = df.groupby(self.gcols)['velocity_y'].diff().fillna(0.0)\n            df['speed_change']      = df.groupby(self.gcols)['s'].diff().fillna(0.0)\n            d = df.groupby(self.gcols)['dir'].diff().fillna(0.0)\n            df['direction_change']  = wrap_angle_deg(d)\n            df['o_change_rate'] = wrap_angle_deg(df.groupby(self.gcols)['o'].diff().fillna(0.0)) * FPS\n            new_cols = ['velocity_x_change','velocity_y_change','speed_change','direction_change', 'o_change_rate']\n        return df, new_cols\n\n    def _create_field_position_features(self, df):\n        df['dist_from_left'] = df['y']\n        df['dist_from_right'] = FIELD_WIDTH - df['y']\n        df['dist_from_sideline'] = np.minimum(df['dist_from_left'], df['dist_from_right'])\n        df['dist_from_endzone']  = np.minimum(df['x'], FIELD_LENGTH - df['x'])\n        df['field_zone_x'] = (df['x'] / FIELD_LENGTH * 5).astype(int).clip(0, 4)\n        df['field_zone_y'] = (df['y'] / FIELD_WIDTH * 3).astype(int).clip(0, 2)\n        df['in_red_zone'] = (df['dist_from_endzone'] < 20).astype(np.int8)\n        df['near_sideline'] = (df['dist_from_sideline'] < 5).astype(np.int8)\n        df['dist_from_center'] = np.hypot(df['x'] - FIELD_LENGTH / 2, df['y'] - FIELD_WIDTH / 2)\n        return df, ['dist_from_sideline','dist_from_endzone','field_zone_x','field_zone_y','in_red_zone','near_sideline','dist_from_center']\n\n    def _create_role_specific_features(self, df):\n        new_cols = []\n        if {'is_receiver','velocity_alignment'}.issubset(df.columns):\n            df['receiver_optimality'] = df['is_receiver'] * df['velocity_alignment']\n            df['receiver_deviation']  = df['is_receiver'] * np.abs(df.get('velocity_perpendicular', 0.0))\n            df['receiver_speed_usage'] = df['is_receiver'] * df['s'] / (df['s'].max() + 1e-3)\n            new_cols.extend(['receiver_optimality','receiver_deviation','receiver_speed_usage'])\n        if {'is_coverage','closing_speed'}.issubset(df.columns):\n            df['defender_closing_speed'] = df['is_coverage'] * df['closing_speed']\n            df['defender_pressure'] = df['is_coverage'] / (df.get('distance_to_ball', 10.0) + 1e-3)\n            new_cols.extend(['defender_closing_speed', 'defender_pressure'])\n        return df, new_cols\n\n    def _create_time_features(self, df):\n        df['frames_elapsed']  = df.groupby(self.gcols).cumcount()\n        return df, ['frames_elapsed']\n\n    def _create_jerk_features(self, df):\n        new_cols = []\n        if 'a' in df.columns:\n            df['jerk'] = df.groupby(self.gcols)['a'].diff().fillna(0.0) * FPS\n            df['jerk_smoothed'] = df.groupby(self.gcols)['jerk'].rolling(3, min_periods=1).mean().reset_index(level=list(range(len(self.gcols))), drop=True)\n            new_cols.extend(['jerk','jerk_smoothed'])\n        if {'acceleration_x','acceleration_y'}.issubset(df.columns):\n            df['jerk_y'] = df.groupby(self.gcols)['acceleration_y'].diff().fillna(0.0) * FPS\n            _jerk_x_temp = df.groupby(self.gcols)['acceleration_x'].diff().fillna(0.0) * FPS\n            df['jerk_magnitude'] = np.hypot(_jerk_x_temp, df['jerk_y'])\n            df['jerk_direction'] = np.arctan2(df['jerk_y'], _jerk_x_temp)\n            df['cumulative_jerk'] = df.groupby(self.gcols)['jerk_magnitude'].cumsum()\n            new_cols.extend(['jerk_y','jerk_magnitude','jerk_direction','cumulative_jerk'])\n        return df, new_cols\n\n    def _create_curvature_land_features(self, df):\n        if {'ball_land_x','ball_land_y'}.issubset(df.columns):\n            dx, dy = df['ball_land_x'] - df['x'], df['ball_land_y'] - df['y']\n            bearing = np.arctan2(dy, dx)\n            a_dir = np.deg2rad(df['dir'].fillna(0.0).values)\n            df['bearing_to_land_signed'] = np.rad2deg(np.arctan2(np.sin(bearing - a_dir), np.cos(bearing - a_dir)))\n            ux, uy = np.cos(a_dir), np.sin(a_dir)\n            df['land_lateral_offset'] = dy*ux - dx*uy\n\n        ddir = df.groupby(self.gcols)['dir'].diff().fillna(0.0)\n        ddir = ((ddir + 180.0) % 360.0) - 180.0\n        curvature_val = np.deg2rad(ddir).astype('float32') / (df['s'].replace(0, np.nan).astype('float32') * 0.1 + 1e-6)\n        df['curvature_abs'] = curvature_val.fillna(0.0).abs()\n        r2 = df.groupby(self.gcols)['curvature_abs'].rolling(3, min_periods=1).mean().reset_index(level=[0,1,2], drop=True)\n        df['curv_abs_roll3'] = r2\n\n        accel_angle_rad = np.arctan2(df['acceleration_y'], df['acceleration_x'])\n        dir_rad = np.deg2rad(df['dir'].fillna(0.0))\n        delta_angle_rad = wrap_angle_rad(accel_angle_rad - dir_rad)\n        df['a_tangential'] = df['a'] * np.cos(delta_angle_rad)\n\n        new_cols = ['bearing_to_land_signed','land_lateral_offset', 'curvature_abs', 'curv_abs_roll3', 'a_tangential']\n        return df, [c for c in new_cols if c in df.columns]\n\n    def transform(self, df):\n        df = df.copy().sort_values(['game_id','play_id','nfl_id','frame_id'])\n        df = self._create_basic_features(df)\n        for group_name in self.active_groups:\n            if group_name in self.feature_creators:\n                df, new_cols = self.feature_creators[group_name](df)\n                self.created_feature_cols.extend(new_cols)\n        return df, sorted(list(set(self.created_feature_cols)))\n\n# -------------------------------\n# GNN-lite 特征函数 (v4.9_2D)\n# -------------------------------\ndef compute_neighbor_embeddings(input_df, cfg):\n    k_neigh, radius, tau = cfg.K_NEIGH, cfg.RADIUS, cfg.TAU\n    cols_needed = [\"game_id\", \"play_id\", \"nfl_id\", \"frame_id\", \"x\", \"y\", \"velocity_x\", \"velocity_y\", \"player_side\", \"player_role\"]\n    src = input_df[cols_needed].copy()\n    last = (src.sort_values([\"game_id\", \"play_id\", \"nfl_id\", \"frame_id\"]).groupby([\"game_id\", \"play_id\", \"nfl_id\"], as_index=False).tail(1).rename(columns={\"frame_id\": \"last_frame_id\"}).reset_index(drop=True))\n    nb_cols = {c: f\"{c}_nb\" for c in src.columns if c not in [\"game_id\", \"play_id\"]}; nb_cols[\"frame_id\"] = \"nb_frame_id\"\n    tmp = last.merge(src.rename(columns=nb_cols), left_on=[\"game_id\", \"play_id\", \"last_frame_id\"], right_on=[\"game_id\", \"play_id\", \"nb_frame_id\"], how=\"left\")\n    tmp = tmp[tmp[\"nfl_id_nb\"] != tmp[\"nfl_id\"]]\n    tmp[\"dx\"] = tmp[\"x_nb\"] - tmp[\"x\"]; tmp[\"dy\"] = tmp[\"y_nb\"] - tmp[\"y\"]\n    tmp[\"dvx\"] = tmp[\"velocity_x_nb\"] - tmp[\"velocity_x\"]; tmp[\"dvy\"] = tmp[\"velocity_y_nb\"] - tmp[\"velocity_y\"]\n    tmp[\"dist\"] = np.sqrt(tmp[\"dx\"]**2 + tmp[\"dy\"]**2)\n    tmp = tmp[np.isfinite(tmp[\"dist\"]) & (tmp[\"dist\"] > 1e-6)]\n    if radius is not None: tmp = tmp[tmp[\"dist\"] <= radius]\n    tmp[\"is_ally\"] = (tmp[\"player_side_nb\"] == tmp[\"player_side\"]).astype(np.float32)\n    tmp['is_dc_nb'] = (tmp['player_role_nb'] == 'Defensive Coverage').astype(np.float32)\n    tmp['is_tr_nb'] = (tmp['player_role_nb'] == 'Targeted Receiver').astype(np.float32)\n    keys = [\"game_id\", \"play_id\", \"nfl_id\"]\n    tmp[\"rnk\"] = tmp.groupby(keys)[\"dist\"].rank(method=\"first\")\n    if k_neigh is not None: tmp = tmp[tmp[\"rnk\"] <= float(k_neigh)]\n    tmp[\"w\"] = np.exp(-tmp[\"dist\"] / float(tau)); sum_w = tmp.groupby(keys)[\"w\"].transform(\"sum\"); tmp[\"wn\"] = np.where(sum_w > 0, tmp[\"w\"] / sum_w, 0.0)\n    tmp[\"wn_opp\"] = tmp[\"wn\"] * (1.0 - tmp[\"is_ally\"]); tmp[\"wn_opp_dc\"] = tmp[\"wn_opp\"] * tmp['is_dc_nb']; tmp[\"wn_opp_tr\"] = tmp[\"wn_opp\"] * tmp['is_tr_nb']\n    for col in [\"dx\", \"dy\", \"dvx\", \"dvy\"]:\n        tmp[f\"{col}_opp_w\"] = tmp[col] * tmp[\"wn_opp\"]; tmp[f\"{col}_opp_dc_w\"] = tmp[col] * tmp[\"wn_opp_dc\"]; tmp[f\"{col}_opp_tr_w\"] = tmp[col] * tmp[\"wn_opp_tr\"]\n    tmp[\"dist_opp_dc\"] = np.where((tmp[\"is_ally\"] < 0.5) & (tmp['is_dc_nb'] > 0.5), tmp[\"dist\"], np.nan)\n    tmp[\"dist_opp_tr\"] = np.where((tmp[\"is_ally\"] < 0.5) & (tmp['is_tr_nb'] > 0.5), tmp[\"dist\"], np.nan)\n    agg_dict = {\n        'gnn_opp_dx_mean': ('dx_opp_w', 'sum'), 'gnn_opp_dy_mean': ('dy_opp_w', 'sum'),\n        'gnn_opp_dvx_mean': ('dvx_opp_w', 'sum'), 'gnn_opp_dvy_mean': ('dvy_opp_w', 'sum'),\n        'gnn_dc_dx_mean': ('dx_opp_dc_w', 'sum'), 'gnn_dc_dy_mean': ('dy_opp_dc_w', 'sum'),\n        'gnn_dc_dvx_mean': ('dvx_opp_dc_w', 'sum'), 'gnn_dc_dvy_mean': ('dvy_opp_dc_w', 'sum'),\n        'gnn_dc_dmin': ('dist_opp_dc', 'min'), 'gnn_dc_cnt': ('is_dc_nb', lambda s: (s * (1 - tmp.loc[s.index, 'is_ally'])).sum()),\n        'gnn_tr_dx_mean': ('dx_opp_tr_w', 'sum'), 'gnn_tr_dy_mean': ('dy_opp_tr_w', 'sum'),\n        'gnn_tr_dmin': ('dist_opp_tr', 'min'), 'gnn_tr_cnt': ('is_tr_nb', lambda s: (s * (1 - tmp.loc[s.index, 'is_ally'])).sum())\n    }\n    ag = tmp.groupby(keys).agg(**agg_dict).reset_index()\n    near = tmp.loc[tmp[\"rnk\"] <= 3, keys + [\"rnk\", \"dist\"]].copy(); near[\"rnk\"] = near[\"rnk\"].astype(int)\n    dwide = near.pivot_table(index=keys, columns=\"rnk\", values=\"dist\", aggfunc=\"first\").rename(columns={1: \"gnn_d1\", 2: \"gnn_d2\", 3: \"gnn_d3\"}).reset_index()\n    ag = ag.merge(dwide, on=keys, how=\"left\")\n    fill_val = radius if radius is not None else 30.0\n    for c in ag.columns:\n        if c.startswith(\"gnn_\"):\n            if \"cnt\" in c: ag[c] = ag[c].fillna(0.0)\n            elif \"dmin\" in c or c in [\"gnn_d1\", \"gnn_d2\", \"gnn_d3\"]: ag[c] = ag[c].fillna(fill_val)\n            else: ag[c] = ag[c].fillna(0.0)\n    return ag\n\n# -------------------------------\n# 序列构建与特征划分 (v4.9_2D)\n# -------------------------------\ndef build_play_direction_map(df_in: pd.DataFrame) -> pd.Series:\n    return df_in[['game_id','play_id','play_direction']].drop_duplicates().set_index(['game_id','play_id'])['play_direction']\n\ndef split_features_v5(feature_cols: list) -> (list, list, list):\n    base_static_features = ['ball_land_x', 'ball_land_y', 'player_height_feet', 'player_weight', 'player_bmi', 'power_weight_ratio',\n                            'is_offense', 'is_defense', 'is_receiver', 'is_coverage']\n    gnn_cols = [c for c in feature_cols if c.startswith('gnn_')]\n    player_static_cols = [col for col in feature_cols if col in base_static_features]\n    dynamic_cols = [c for c in feature_cols if c not in player_static_cols and c not in gnn_cols]\n    return dynamic_cols, player_static_cols, gnn_cols\n\ndef split_dynamic_features(dynamic_cols: list) -> (list, list):\n    CONTEXTUAL_BASE_FEATURES = ['distance_to_ball','ball_direction','closing_speed','time_to_intercept','velocity_alignment',\n                                'velocity_perpendicular','accel_alignment', 'accel_perpendicular', 'dist_from_','receiver_',\n                                'defender_','frames_elapsed','bearing_to_land','land_lateral_offset',\n                                'ball_angle', 'approach_angle', 'd2ball_d3t', 'closing_efficiency', 'intercept_urgency', 'distance_ema3',\n                                'field_zone', 'in_red_zone', 'near_sideline', 'dist_from_center']\n    kinematic_cols, contextual_cols = [], []\n    for col in dynamic_cols:\n        is_contextual = any(col.startswith(base) for base in CONTEXTUAL_BASE_FEATURES)\n        if is_contextual:\n            contextual_cols.append(col)\n        else:\n            kinematic_cols.append(col)\n    if not contextual_cols: warnings.warn(\"警告：上下文特征列表为空！\")\n    return kinematic_cols, contextual_cols\n\ndef prepare_sequences_for_multistream(input_df, cfg):\n    if len(input_df) == 0: return [], [], [], [], [], [], [], [], [], []\n\n    feature_groups = ['distance_rate','target_alignment','multi_window_rolling','extended_lags','velocity_changes','field_position','role_specific','time_features','jerk_features',\"curvature_land_features\"]\n    \n    dir_map = build_play_direction_map(input_df)\n    input_df_u = unify_left_direction(input_df)\n\n    # 在推理时，'ball_land_x/y' 可能不存在，需要创建\n    if 'ball_land_x' not in input_df_u.columns:\n        last_pos_self = input_df_u.groupby(['game_id', 'play_id', 'nfl_id'])[['x', 'y']].last().reset_index()\n        last_pos_self.rename(columns={'x': 'ball_land_x', 'y': 'ball_land_y'}, inplace=True)\n        input_df_u = input_df_u.merge(last_pos_self, on=['game_id', 'play_id', 'nfl_id'], how='left')\n        \n        # 确保填充所有可能的NaN\n        input_df_u['ball_land_x'].fillna(method='ffill', inplace=True)\n        input_df_u['ball_land_y'].fillna(method='ffill', inplace=True)\n        input_df_u['ball_land_x'].fillna(method='bfill', inplace=True)\n        input_df_u['ball_land_y'].fillna(method='bfill', inplace=True)\n        input_df_u.fillna({'ball_land_x': 0, 'ball_land_y': 0}, inplace=True)\n\n    fe = FeatureEngineer(feature_groups)\n    processed_df, feature_cols = fe.transform(input_df_u)\n\n    gnn_features_df = compute_neighbor_embeddings(processed_df, cfg)\n    processed_df = processed_df.merge(gnn_features_df, on=['game_id', 'play_id', 'nfl_id'], how='left')\n    gnn_cols = list(gnn_features_df.columns.drop(['game_id', 'play_id', 'nfl_id']))\n    feature_cols.extend(gnn_cols)\n    \n    dynamic_cols, player_static_cols, gnn_static_cols = split_features_v5(feature_cols)\n    kinematic_cols, contextual_cols = split_dynamic_features(dynamic_cols)\n\n    plays_grouped = processed_df.groupby(['game_id', 'play_id'])\n    \n    all_player_kin_seqs, all_player_ctx_seqs = [], []\n    target_p_sta_feats, target_g_sta_feats, play_masks = [], [], []\n    seq_meta = []\n\n    players_to_predict = processed_df[['game_id', 'play_id', 'nfl_id']].drop_duplicates()\n\n    for _, row in players_to_predict.iterrows():\n        gid, pid, target_nfl_id = row['game_id'], row['play_id'], row['nfl_id']\n        try:\n            play_df = plays_grouped.get_group((gid, pid))\n        except KeyError:\n            continue\n        \n        players_in_play = play_df['nfl_id'].unique()\n        \n        play_kin_features, play_ctx_features, play_p_sta_features, play_g_sta_features = {}, {}, {}, {}\n\n        for nfl_id in players_in_play:\n            player_df = play_df[play_df['nfl_id'] == nfl_id].sort_values('frame_id')\n            input_window = player_df.tail(cfg.WINDOW_SIZE)\n            seq_len = len(input_window)\n            pad_len = cfg.WINDOW_SIZE - seq_len\n\n            kin_window_np = input_window[kinematic_cols].values\n            ctx_window_np = input_window[contextual_cols].values\n            padded_kin_seq_np = np.vstack([np.zeros((pad_len, len(kinematic_cols))), kin_window_np]) if pad_len > 0 else kin_window_np\n            padded_ctx_seq_np = np.vstack([np.zeros((pad_len, len(contextual_cols))), ctx_window_np]) if pad_len > 0 else ctx_window_np\n\n            play_kin_features[nfl_id] = np.nan_to_num(padded_kin_seq_np, nan=0.0)\n            play_ctx_features[nfl_id] = np.nan_to_num(padded_ctx_seq_np, nan=0.0)\n            \n            p_static_vector_np = input_window[player_static_cols].iloc[-1].values\n            g_static_vector_np = input_window[gnn_static_cols].iloc[-1].values\n            play_p_sta_features[nfl_id] = np.nan_to_num(p_static_vector_np, nan=0.0)\n            play_g_sta_features[nfl_id] = np.nan_to_num(g_static_vector_np, nan=0.0)\n\n        all_kin_seq_np = np.zeros((cfg.MAX_PLAYERS, cfg.WINDOW_SIZE, len(kinematic_cols)), dtype=np.float32)\n        all_ctx_seq_np = np.zeros((cfg.MAX_PLAYERS, cfg.WINDOW_SIZE, len(contextual_cols)), dtype=np.float32)\n        play_mask_np = np.zeros(cfg.MAX_PLAYERS, dtype=np.float32)\n\n        all_kin_seq_np[0, :, :] = play_kin_features[target_nfl_id]\n        all_ctx_seq_np[0, :, :] = play_ctx_features[target_nfl_id]\n        play_mask_np[0] = 1.0\n        \n        context_players = [p for p in players_in_play if p != target_nfl_id]\n        for j, context_nfl_id in enumerate(context_players):\n            if (j + 1) < cfg.MAX_PLAYERS:\n                all_kin_seq_np[j + 1, :, :] = play_kin_features[context_nfl_id]\n                all_ctx_seq_np[j + 1, :, :] = play_ctx_features[context_nfl_id]\n                play_mask_np[j + 1] = 1.0\n        \n        all_player_kin_seqs.append(all_kin_seq_np)\n        all_player_ctx_seqs.append(all_ctx_seq_np)\n        target_p_sta_feats.append(play_p_sta_features[target_nfl_id])\n        target_g_sta_feats.append(play_g_sta_features[target_nfl_id])\n        play_masks.append(play_mask_np)\n\n        play_dir_val = dir_map.loc[(gid, pid)]\n        seq_meta.append({'game_id': gid, 'play_id': pid, 'nfl_id': target_nfl_id, 'play_direction': play_dir_val})\n            \n    return (all_player_kin_seqs, all_player_ctx_seqs, target_p_sta_feats, target_g_sta_feats, play_masks, \n            seq_meta, kinematic_cols, contextual_cols, player_static_cols, gnn_static_cols)\n\n# -------------------------------\n# 模型架构 (v4.9_2D)\n# -------------------------------\nclass SEBlock(nn.Module):\n    def __init__(self, in_channels, reduction_ratio=8):\n        super().__init__()\n        self.squeeze = nn.AdaptiveAvgPool1d(1)\n        self.excitation = nn.Sequential(nn.Linear(in_channels, in_channels // reduction_ratio), nn.GELU(), nn.Linear(in_channels // reduction_ratio, in_channels), nn.Sigmoid())\n    def forward(self, x):\n        weights = self.excitation(self.squeeze(x).squeeze(-1)).unsqueeze(-1)\n        return x * weights\n\nclass ConvBNGELU(nn.Module):\n    def __init__(self, in_channels, out_channels, kernel_size):\n        super().__init__()\n        self.main = nn.Sequential(nn.Conv1d(in_channels, out_channels, kernel_size, padding=(kernel_size - 1) // 2, bias=False), nn.BatchNorm1d(out_channels), nn.GELU())\n    def forward(self, x): return self.main(x)\n\nclass ResidualSECNNBlock(nn.Module):\n    def __init__(self, in_channels, out_channels, kernel_size, pool_size=1, dropout=0.2):\n        super().__init__()\n        self.conv1 = ConvBNGELU(in_channels, out_channels, kernel_size)\n        self.conv2 = ConvBNGELU(out_channels, out_channels, kernel_size)\n        self.se = SEBlock(out_channels)\n        self.shortcut = nn.Identity() if in_channels == out_channels else nn.Sequential(nn.Conv1d(in_channels, out_channels, kernel_size=1, bias=False), nn.BatchNorm1d(out_channels))\n        self.pool = nn.MaxPool1d(pool_size) if pool_size > 1 else nn.Identity()\n        self.dropout = nn.Dropout(dropout)\n        self.final_act = nn.GELU()\n    def forward(self, x):\n        residual = self.shortcut(x)\n        x = self.conv1(x); x = self.conv2(x); x = self.se(x)\n        x += residual; x = self.final_act(x); x = self.pool(x)\n        return self.dropout(x)\n\nclass MultiStreamCrossAttentionModel(nn.Module):\n    def __init__(self, kin_dim, ctx_dim, player_sta_dim, gnn_sta_dim, horizon, cfg):\n        super().__init__()\n        self.cfg = cfg\n        kin_branch_dim = int(cfg.D_MODEL * 0.75)\n        self.kin_proj = nn.Linear(kin_dim, kin_branch_dim)\n        self.kin_cnn = nn.Sequential(\n            ResidualSECNNBlock(kin_branch_dim, kin_branch_dim, kernel_size=3, dropout=0.1),\n            ResidualSECNNBlock(kin_branch_dim, kin_branch_dim, kernel_size=5, dropout=0.1)\n        )\n        ctx_branch_dim = cfg.D_MODEL - kin_branch_dim\n        self.ctx_proj = nn.Linear(ctx_dim, ctx_branch_dim)\n        self.ctx_cnn = nn.Sequential(ConvBNGELU(ctx_branch_dim, ctx_branch_dim, kernel_size=3), nn.Dropout(0.1))\n        self.pos_encoding = nn.Parameter(torch.randn(1, cfg.WINDOW_SIZE, cfg.D_MODEL) * 0.02)\n        encoder_layer = nn.TransformerEncoderLayer(d_model=cfg.D_MODEL, nhead=cfg.NHEAD, dim_feedforward=cfg.DIM_FEEDFORWARD, dropout=cfg.TRANSFORMER_DROPOUT, activation='gelu', batch_first=True, norm_first=True)\n        self.self_attention_encoder = nn.TransformerEncoder(encoder_layer, num_layers=cfg.NUM_ENCODER_LAYERS)\n        self.cross_attention = nn.MultiheadAttention(embed_dim=cfg.D_MODEL, num_heads=cfg.NHEAD, dropout=cfg.TRANSFORMER_DROPOUT, batch_first=True)\n        self.cross_attn_norm = nn.LayerNorm(cfg.D_MODEL)\n        self.cross_attn_ffn = nn.Sequential(nn.Linear(cfg.D_MODEL, cfg.D_MODEL * 2), nn.GELU(), nn.Dropout(cfg.TRANSFORMER_DROPOUT), nn.Linear(cfg.D_MODEL * 2, cfg.D_MODEL))\n        self.cross_attn_ffn_norm = nn.LayerNorm(cfg.D_MODEL)\n        self.player_static_encoder = nn.Sequential(nn.Linear(player_sta_dim, cfg.PLAYER_STATIC_HIDDEN_DIM), nn.LayerNorm(cfg.PLAYER_STATIC_HIDDEN_DIM), nn.GELU(), nn.Dropout(cfg.PLAYER_STATIC_DROPOUT))\n        self.gnn_static_encoder = nn.Sequential(nn.Linear(gnn_sta_dim, cfg.GNN_HIDDEN_DIM), nn.LayerNorm(cfg.GNN_HIDDEN_DIM), nn.GELU(), nn.Dropout(cfg.GNN_DROPOUT))\n        fusion_input_dim = cfg.D_MODEL + cfg.PLAYER_STATIC_HIDDEN_DIM + cfg.GNN_HIDDEN_DIM\n        self.head = nn.Sequential(\n            nn.Linear(fusion_input_dim, 256), nn.GELU(), nn.Dropout(cfg.HEAD_DROPOUT), \n            nn.Linear(256, 128), nn.GELU(), nn.Dropout(cfg.HEAD_DROPOUT), \n            nn.Linear(128, horizon * 2)\n        )\n\n    def forward(self, all_kin_seq, all_ctx_seq, player_sta_feat, gnn_sta_feat, play_mask):\n        B, N_Players, Seq_Len, _ = all_kin_seq.shape\n        kin_seq_flat = all_kin_seq.view(B * N_Players, Seq_Len, -1); ctx_seq_flat = all_ctx_seq.view(B * N_Players, Seq_Len, -1)\n        kin_embed = self.kin_proj(kin_seq_flat).transpose(1, 2); kin_features = self.kin_cnn(kin_embed).transpose(1, 2)\n        ctx_embed = self.ctx_proj(ctx_seq_flat).transpose(1, 2); ctx_features = self.ctx_cnn(ctx_embed).transpose(1, 2)\n        dyn_embed = torch.cat([kin_features, ctx_features], dim=-1)\n        dyn_embed += self.pos_encoding[:, :Seq_Len, :]\n        self_attn_out_flat = self.self_attention_encoder(dyn_embed)\n        player_repr_flat = self_attn_out_flat.mean(dim=1)\n        all_player_repr = player_repr_flat.view(B, N_Players, -1)\n        target_repr = all_player_repr[:, 0:1, :]\n        cross_attn_mask = (play_mask == 0)\n        cross_attn_out, _ = self.cross_attention(query=target_repr, key=all_player_repr, value=all_player_repr, key_padding_mask=cross_attn_mask)\n        fused_dyn_repr = self.cross_attn_norm(target_repr + cross_attn_out)\n        fused_dyn_repr = fused_dyn_repr + self.cross_attn_ffn(fused_dyn_repr)\n        fused_dyn_repr = self.cross_attn_ffn_norm(fused_dyn_repr).squeeze(1)\n        player_static_repr = self.player_static_encoder(player_sta_feat); gnn_static_repr = self.gnn_static_encoder(gnn_sta_feat)\n        final_repr = torch.cat([fused_dyn_repr, player_static_repr, gnn_static_repr], dim=1)\n        out_flat = self.head(final_repr)\n        out_reshaped = out_flat.view(-1, self.cfg.MAX_FUTURE_HORIZON, 2)\n        return torch.cumsum(out_reshaped, dim=1)\n\n# =============================================================================\n# 3. 全局资产加载\n# =============================================================================\nprint(\"--- [API] 启动全局加载流程 ---\")\nstart_time = time.time()\ncfg = Config()\n\nMODELS_JOINT, SCALERS = [], []\nKIN_DIM, CTX_DIM, P_STA_DIM, G_STA_DIM = 0, 0, 0, 0\n\ntry:\n    print(f\"从 {cfg.MODEL_DIR} 加载 Scalers 和模型...\")\n    # 通过加载第一个 fold 的 scaler 来动态确定特征维度\n    with open(cfg.MODEL_DIR / \"scaler_kin_fold1.pkl\", 'rb') as f: KIN_DIM = pickle.load(f).n_features_in_\n    with open(cfg.MODEL_DIR / \"scaler_ctx_fold1.pkl\", 'rb') as f: CTX_DIM = pickle.load(f).n_features_in_\n    with open(cfg.MODEL_DIR / \"scaler_psta_fold1.pkl\", 'rb') as f: P_STA_DIM = pickle.load(f).n_features_in_\n    with open(cfg.MODEL_DIR / \"scaler_gsta_fold1.pkl\", 'rb') as f: G_STA_DIM = pickle.load(f).n_features_in_\n    \n    print(f\"检测到特征维度: Kinematic={KIN_DIM}, Contextual={CTX_DIM}, PlayerStatic={P_STA_DIM}, GNN={G_STA_DIM}\")\n\n    for fold in range(1, cfg.N_FOLDS + 1):\n        model = MultiStreamCrossAttentionModel(KIN_DIM, CTX_DIM, P_STA_DIM, G_STA_DIM, cfg.MAX_FUTURE_HORIZON, cfg)\n        \n        # 推荐做法: 先加载到CPU，再整体移动到目标设备\n        model.load_state_dict(torch.load(cfg.MODEL_DIR / f\"model_joint_fold{fold}.pth\", map_location='cpu'))\n        \n        # 明确地将整个模型移动到GPU并设置为评估模式\n        model.to(cfg.DEVICE).eval()\n        \n        MODELS_JOINT.append(model)\n\n        with open(cfg.MODEL_DIR / f\"scaler_kin_fold{fold}.pkl\", 'rb') as f: sc_kin = pickle.load(f)\n        with open(cfg.MODEL_DIR / f\"scaler_ctx_fold{fold}.pkl\", 'rb') as f: sc_ctx = pickle.load(f)\n        with open(cfg.MODEL_DIR / f\"scaler_psta_fold{fold}.pkl\", 'rb') as f: sc_ps = pickle.load(f)\n        with open(cfg.MODEL_DIR / f\"scaler_gsta_fold{fold}.pkl\", 'rb') as f: sc_gs = pickle.load(f)\n        SCALERS.append((sc_kin, sc_ctx, sc_ps, sc_gs))\n    \n    print(f\"✅ 成功加载 {len(MODELS_JOINT)} 折模型和 scalers。耗时: {time.time() - start_time:.2f} 秒。\")\n\nexcept Exception as e:\n    print(f\"!!!!!! [错误] 全局加载失败: {e} !!!!!!\")\n    MODELS_JOINT, SCALERS = [], []\n\n# =============================================================================\n# 4. 'predict' 函数\n# =============================================================================\ndef predict(test_df_pl: pl.DataFrame, test_input_df_pl: pl.DataFrame) -> pd.DataFrame:\n    if not all([MODELS_JOINT, SCALERS]):\n        print(\"错误: predict 被调用，但全局模型/scalers未加载。返回零预测。\")\n        return pd.DataFrame({'x': [0.0] * len(test_df_pl), 'y': [0.0] * len(test_df_pl)})\n\n    try:\n        # --- 1. 数据准备 ---\n        test_df = test_df_pl.to_pandas()\n        test_input_df = test_input_df_pl.to_pandas()\n\n        if test_input_df.empty or test_df.empty:\n            return pd.DataFrame({'x': [0.0] * len(test_df), 'y': [0.0] * len(test_df)})\n\n        # --- 2. 特征工程 & 序列构建 ---\n        (all_kin, all_ctx, tar_p_sta, tar_g_sta, play_m, seq_meta, \n         _, _, _, _) = prepare_sequences_for_multistream(test_input_df, cfg=cfg)\n\n        if not all_kin:\n            return pd.DataFrame({'x': [0.0] * len(test_df), 'y': [0.0] * len(test_df)})\n            \n        # --- 3. 5折集成预测 ---\n        all_folds_preds_xy = []\n        num_samples = len(all_kin)\n\n        for fold in range(cfg.N_FOLDS):\n            model = MODELS_JOINT[fold]\n            sc_kin, sc_ctx, sc_ps, sc_gs = SCALERS[fold]\n            \n            fold_xy_batches = []\n\n            for i in range(0, num_samples, cfg.INFERENCE_BATCH_SIZE):\n                end = min(i + cfg.INFERENCE_BATCH_SIZE, num_samples)\n                batch_kin_raw = all_kin[i:end]\n                batch_ctx_raw = all_ctx[i:end]\n                batch_p_sta_raw = tar_p_sta[i:end]\n                batch_g_sta_raw = tar_g_sta[i:end]\n                batch_mask = play_m[i:end]\n\n                kin_sc = [np.stack([sc_kin.transform(p_seq) for p_seq in seq]).astype(np.float32) for seq in batch_kin_raw]\n                ctx_sc = [np.stack([sc_ctx.transform(p_seq) for p_seq in seq]).astype(np.float32) for seq in batch_ctx_raw]\n                p_sta_sc = sc_ps.transform(np.array(batch_p_sta_raw)).astype(np.float32)\n                g_sta_sc = sc_gs.transform(np.array(batch_g_sta_raw)).astype(np.float32)\n\n                kin_tensor = torch.tensor(np.stack(kin_sc)).to(cfg.DEVICE)\n                ctx_tensor = torch.tensor(np.stack(ctx_sc)).to(cfg.DEVICE)\n                p_sta_tensor = torch.tensor(p_sta_sc).to(cfg.DEVICE)\n                g_sta_tensor = torch.tensor(g_sta_sc).to(cfg.DEVICE)\n                mask_tensor = torch.tensor(np.stack(batch_mask)).to(cfg.DEVICE)\n\n                with torch.no_grad():\n                    batch_pred_xy = model(kin_tensor, ctx_tensor, p_sta_tensor, g_sta_tensor, mask_tensor)\n                \n                fold_xy_batches.append(batch_pred_xy.cpu().numpy())\n\n            all_folds_preds_xy.append(np.vstack(fold_xy_batches))\n\n        avg_xy = np.mean(all_folds_preds_xy, axis=0)\n        \n        # --- 4. 后处理与格式化输出 ---\n        unified_test_df = unify_left_direction(test_input_df.copy())\n        last_known_positions = unified_test_df.groupby(['game_id', 'play_id', 'nfl_id'])[['x', 'y']].last().reset_index()\n\n        meta_df = pd.DataFrame(seq_meta)\n        meta_df = meta_df.merge(last_known_positions, on=['game_id', 'play_id', 'nfl_id'], how='left')\n\n        pred_map = {}\n        for i, row in meta_df.iterrows():\n            key = (int(row['game_id']), int(row['play_id']), int(row['nfl_id']))\n            pred_map[key] = {\n                'dxy': avg_xy[i],\n                'last_x': row['x'],\n                'last_y': row['y'],\n                'play_dir_right': row['play_direction'] == 'right'\n            }\n            \n        results = []\n        for _, row in test_df.iterrows():\n            key = (int(row['game_id']), int(row['play_id']), int(row['nfl_id']))\n            if key in pred_map:\n                preds = pred_map[key]\n                frame_idx = min(int(row['frame_id']) - 1, len(preds['dxy']) - 1)\n                \n                pred_dx, pred_dy = preds['dxy'][frame_idx]\n                \n                pred_abs_x_u = preds['last_x'] + pred_dx\n                pred_abs_y_u = preds['last_y'] + pred_dy\n                \n                x_orig, y_orig = invert_to_original_direction(pred_abs_x_u, pred_abs_y_u, preds['play_dir_right'])\n                results.append({'x': x_orig, 'y': y_orig})\n            else:\n                # 如果某个球员因为某种原因没有生成序列，则返回 (0,0)\n                results.append({'x': 0.0, 'y': 0.0})\n\n        predictions_df = pd.DataFrame(results)\n        \n        assert len(predictions_df) == len(test_df)\n        return predictions_df[['x', 'y']]\n\n    except Exception as e:\n        print(f\"!!!!!! [错误] 'predict' 函数执行时发生异常: {e} !!!!!!\")\n        import traceback\n        traceback.print_exc()\n        # 在任何错误情况下，返回一个符合格式要求的零预测DataFrame\n        return pd.DataFrame({'x': [0.0] * len(test_df_pl), 'y': [0.0] * len(test_df_pl)})\n\n# =============================================================================\n# 5. API 服务器启动\n# =============================================================================\ninference_server = kaggle_evaluation.nfl_inference_server.NFLInferenceServer(predict)\n\n# 判断是在Kaggle真实提交环境还是本地调试环境\nif os.getenv('KAGGLE_IS_COMPETITION_RERUN'):\n    print(\"--- [API] 启动 NFLInferenceServer (竞赛重跑模式) ---\")\n    inference_server.serve()\nelse:\n    print(\"--- [API] 启动本地网关模拟 ---\")\n    # 此处路径指向Kaggle平台上的竞赛数据路径\n    inference_server.run_local_gateway(('/kaggle/input/nfl-big-data-bowl-2026-prediction/',))\n    print(\"--- [API] 本地网关模拟完成。\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-25T09:05:03.979215Z","iopub.execute_input":"2025-10-25T09:05:03.979538Z","iopub.status.idle":"2025-10-25T09:07:01.192621Z","shell.execute_reply.started":"2025-10-25T09:05:03.979515Z","shell.execute_reply":"2025-10-25T09:07:01.191847Z"}},"outputs":[],"execution_count":null}]}