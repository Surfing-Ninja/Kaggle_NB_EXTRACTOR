{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":114239,"databundleVersionId":14210809,"isSourceIdPinned":false,"sourceType":"competition"},{"sourceId":13522768,"sourceType":"datasetVersion","datasetId":8586430},{"sourceId":13523015,"sourceType":"datasetVersion","datasetId":8586599}],"dockerImageVersionId":31153,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"\"\"\"\nNFL Big Data Bowl 2026 - INFERENCE ONLY\n使用已训练好的权重进行预测\n\"\"\"\n\nimport torch\nimport torch.nn as nn\nimport numpy as np\nimport pandas as pd\nfrom pathlib import Path\nfrom tqdm.auto import tqdm\nfrom datetime import datetime\nimport warnings\nimport os\nimport pickle\nimport polars as pl\nimport kaggle_evaluation.nfl_inference_server\n\n# ============================================================================\n# CONFIG\n# ============================================================================\n\nclass Config:\n    DATA_DIR = Path(\"/kaggle/input/nfl-big-data-bowl-2026-prediction/\")\n    \n    SEED = 42\n    N_FOLDS = 5\n    BATCH_SIZE = 256\n    WINDOW_SIZE = 8\n    HIDDEN_DIM = 128\n    MAX_FUTURE_HORIZON = 94\n    \n    FIELD_X_MIN, FIELD_X_MAX = 0.0, 120.0\n    FIELD_Y_MIN, FIELD_Y_MAX = 0.0, 53.3\n    \n    DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\ndef set_seed(seed=42):\n    import random\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n\nset_seed(Config.SEED)\n\n# ============================================================================\n# FEATURE ENGINEERING (与训练时保持一致)\n# ============================================================================\n\ndef height_to_feet(height_str):\n    try:\n        ft, inches = map(int, str(height_str).split('-'))\n        return ft + inches/12\n    except:\n        return 6.0\n\ndef prepare_sequences_fixed(input_df, output_df=None, test_template=None, is_training=True, window_size=8):\n    \"\"\"\n    与训练时完全相同的特征工程\n    \"\"\"\n    print(f\"Preparing sequences (window_size={window_size})...\")\n    \n    input_df = input_df.copy()\n    \n    # Basic features\n    input_df['player_height_feet'] = input_df['player_height'].apply(height_to_feet)\n    \n    # Velocity\n    dir_rad = np.deg2rad(input_df['dir'].fillna(0))\n    delta_t = 0.1\n    input_df['velocity_x'] = (input_df['s'] + 0.5 * input_df['a'] * delta_t) * np.sin(dir_rad)\n    input_df['velocity_y'] = (input_df['s'] + 0.5 * input_df['a'] * delta_t) * np.cos(dir_rad)\n    \n    # Acceleration\n    input_df['acceleration_x'] = input_df['a'] * np.sin(dir_rad)\n    input_df['acceleration_y'] = input_df['a'] * np.cos(dir_rad)\n    \n    # Roles\n    input_df['is_offense'] = (input_df['player_side'] == 'Offense').astype(int)\n    input_df['is_defense'] = (input_df['player_side'] == 'Defense').astype(int)\n    input_df['is_receiver'] = (input_df['player_role'] == 'Targeted Receiver').astype(int)\n    input_df['is_coverage'] = (input_df['player_role'] == 'Defensive Coverage').astype(int)\n    input_df['is_passer'] = (input_df['player_role'] == 'Passer').astype(int)\n    \n    # Physics\n    mass_kg = input_df['player_weight'].fillna(200.0) / 2.20462\n    input_df['momentum_x'] = input_df['velocity_x'] * mass_kg\n    input_df['momentum_y'] = input_df['velocity_y'] * mass_kg\n    input_df['kinetic_energy'] = 0.5 * mass_kg * (input_df['s'] ** 2)\n    \n    # Ball features\n    if 'ball_land_x' in input_df.columns:\n        ball_dx = input_df['ball_land_x'] - input_df['x']\n        ball_dy = input_df['ball_land_y'] - input_df['y']\n        input_df['distance_to_ball'] = np.sqrt(ball_dx**2 + ball_dy**2)\n        input_df['angle_to_ball'] = np.arctan2(ball_dy, ball_dx)\n        input_df['ball_direction_x'] = ball_dx / (input_df['distance_to_ball'] + 1e-6)\n        input_df['ball_direction_y'] = ball_dy / (input_df['distance_to_ball'] + 1e-6)\n        input_df['closing_speed'] = (\n            input_df['velocity_x'] * input_df['ball_direction_x'] +\n            input_df['velocity_y'] * input_df['ball_direction_y']\n        )\n    \n    # Sort for temporal features\n    input_df = input_df.sort_values(['game_id', 'play_id', 'nfl_id', 'frame_id'])\n    gcols = ['game_id', 'play_id', 'nfl_id']\n    \n    # Lag features\n    for lag in [1, 2, 3]:\n        input_df[f'x_lag{lag}'] = input_df.groupby(gcols)['x'].shift(lag)\n        input_df[f'y_lag{lag}'] = input_df.groupby(gcols)['y'].shift(lag)\n        input_df[f'velocity_x_lag{lag}'] = input_df.groupby(gcols)['velocity_x'].shift(lag)\n        input_df[f'velocity_y_lag{lag}'] = input_df.groupby(gcols)['velocity_y'].shift(lag)\n    \n    # EMA features\n    input_df['velocity_x_ema'] = input_df.groupby(gcols)['velocity_x'].transform(\n        lambda x: x.ewm(alpha=0.3, adjust=False).mean()\n    )\n    input_df['velocity_y_ema'] = input_df.groupby(gcols)['velocity_y'].transform(\n        lambda x: x.ewm(alpha=0.3, adjust=False).mean()\n    )\n    input_df['speed_ema'] = input_df.groupby(gcols)['s'].transform(\n        lambda x: x.ewm(alpha=0.3, adjust=False).mean()\n    )\n    \n    # Rolling features\n    input_df['velocity_x_roll'] = input_df.groupby(gcols)['velocity_x'].transform(\n        lambda x: x.rolling(window_size, min_periods=1).mean()\n    )\n    input_df['velocity_y_roll'] = input_df.groupby(gcols)['velocity_y'].transform(\n        lambda x: x.rolling(window_size, min_periods=1).mean()\n    )\n    \n    # Feature list\n    feature_cols = [\n        'x', 'y', 's', 'a', 'o', 'dir', 'frame_id',\n        'ball_land_x', 'ball_land_y',\n        'player_height_feet', 'player_weight',\n        'velocity_x', 'velocity_y', 'acceleration_x', 'acceleration_y',\n        'momentum_x', 'momentum_y', 'kinetic_energy',\n        'is_offense', 'is_defense', 'is_receiver', 'is_coverage', 'is_passer',\n        'distance_to_ball', 'angle_to_ball', 'ball_direction_x', 'ball_direction_y', 'closing_speed',\n        'x_lag1', 'y_lag1', 'velocity_x_lag1', 'velocity_y_lag1',\n        'x_lag2', 'y_lag2', 'velocity_x_lag2', 'velocity_y_lag2',\n        'x_lag3', 'y_lag3', 'velocity_x_lag3', 'velocity_y_lag3',\n        'velocity_x_ema', 'velocity_y_ema', 'speed_ema',\n        'velocity_x_roll', 'velocity_y_roll',\n    ]\n    \n    feature_cols = [c for c in feature_cols if c in input_df.columns]\n    print(f\"Using {len(feature_cols)} features\")\n    \n    # Create sequences\n    input_df.set_index(['game_id', 'play_id', 'nfl_id'], inplace=True)\n    grouped = input_df.groupby(level=['game_id', 'play_id', 'nfl_id'])\n    \n    target_rows = output_df if is_training else test_template\n    target_groups = target_rows[['game_id', 'play_id', 'nfl_id']].drop_duplicates()\n    \n    sequences, targets_dx, targets_dy, targets_frame_ids, sequence_ids = [], [], [], [], []\n    \n    for _, row in tqdm(target_groups.iterrows(), total=len(target_groups)):\n        key = (row['game_id'], row['play_id'], row['nfl_id'])\n        \n        try:\n            group_df = grouped.get_group(key)\n        except KeyError:\n            continue\n        \n        input_window = group_df.tail(window_size)\n        \n        if len(input_window) < window_size:\n            if is_training:\n                continue\n            pad_len = window_size - len(input_window)\n            pad_df = pd.DataFrame(np.nan, index=range(pad_len), columns=input_window.columns)\n            input_window = pd.concat([pad_df, input_window], ignore_index=True)\n        \n        input_window = input_window.fillna(group_df.mean(numeric_only=True))\n        seq = input_window[feature_cols].values\n        \n        if np.isnan(seq).any():\n            seq = np.nan_to_num(seq, nan=0.0)\n        \n        sequences.append(seq)\n        \n        if is_training:\n            out_grp = output_df[\n                (output_df['game_id']==row['game_id']) &\n                (output_df['play_id']==row['play_id']) &\n                (output_df['nfl_id']==row['nfl_id'])\n            ].sort_values('frame_id')\n            \n            last_x = input_window.iloc[-1]['x']\n            last_y = input_window.iloc[-1]['y']\n            \n            dx = out_grp['x'].values - last_x\n            dy = out_grp['y'].values - last_y\n            \n            targets_dx.append(dx)\n            targets_dy.append(dy)\n            targets_frame_ids.append(out_grp['frame_id'].values)\n        \n        sequence_ids.append({\n            'game_id': key[0],\n            'play_id': key[1],\n            'nfl_id': key[2],\n            'frame_id': input_window.iloc[-1]['frame_id']\n        })\n    \n    print(f\"Created {len(sequences)} sequences\")\n    \n    if is_training:\n        return sequences, targets_dx, targets_dy, targets_frame_ids, sequence_ids\n    return sequences, sequence_ids\n\n# ============================================================================\n# LOSS (与训练时相同)\n# ============================================================================\n\nclass TemporalHuber(nn.Module):\n    def __init__(self, delta=0.5, time_decay=0.03):\n        super().__init__()\n        self.delta = delta\n        self.time_decay = time_decay\n    \n    def forward(self, pred, target, mask):\n        err = pred - target\n        abs_err = torch.abs(err)\n        \n        huber = torch.where(\n            abs_err <= self.delta,\n            0.5 * err * err,\n            self.delta * (abs_err - 0.5 * self.delta)\n        )\n        \n        if self.time_decay > 0:\n            L = pred.size(1)\n            t = torch.arange(L, device=pred.device).float()\n            weight = torch.exp(-self.time_decay * t).view(1, L)\n            huber = huber * weight\n            mask = mask * weight\n        \n        return (huber * mask).sum() / (mask.sum() + 1e-8)\n\n# ============================================================================\n# MODEL (与训练时相同)\n# ============================================================================\n\nclass ImprovedSeqModel(nn.Module):\n    def __init__(self, input_dim, horizon):\n        super().__init__()\n        self.horizon = horizon\n        \n        self.gru = nn.GRU(input_dim, 128, num_layers=2, batch_first=True, dropout=0.1)\n        \n        self.pool_ln = nn.LayerNorm(128)\n        self.pool_attn = nn.MultiheadAttention(128, num_heads=4, batch_first=True)\n        self.pool_query = nn.Parameter(torch.randn(1, 1, 128))\n        \n        self.head = nn.Sequential(\n            nn.Linear(128, 128),\n            nn.GELU(),\n            nn.Dropout(0.2),\n            nn.Linear(128, horizon)\n        )\n    \n    def forward(self, x):\n        h, _ = self.gru(x)\n        \n        B = h.size(0)\n        q = self.pool_query.expand(B, -1, -1)\n        h_norm = self.pool_ln(h)\n        ctx, _ = self.pool_attn(q, h_norm, h_norm)\n        ctx = ctx.squeeze(1)\n        \n        out = self.head(ctx)\n        out = torch.cumsum(out, dim=1)\n        \n        return out\n\n# ============================================================================\n# INFERENCE ONLY - 加载已有模型和scaler\n# ============================================================================\n\ndef load_models_once():\n    global _models_x, _models_y, _scalers, _feature_cols, _models_loaded\n    \n    print(\"Loading pre-trained models and scalers...\")\n    \n    # 模型路径\n    model_x_paths = [\n        \"/kaggle/input/nflllll/kaggle/working/models/model_x_fold1.pth\",\n        \"/kaggle/input/nflllll/kaggle/working/models/model_x_fold2.pth\",\n        \"/kaggle/input/nflllll/kaggle/working/models/model_x_fold3.pth\",\n        \"/kaggle/input/nflllll/kaggle/working/models/model_x_fold4.pth\",\n        \"/kaggle/input/nflllll/kaggle/working/models/model_x_fold5.pth\"\n    ]\n    \n    model_y_paths = [\n        \"/kaggle/input/nflllll/kaggle/working/models/model_y_fold1.pth\",\n        \"/kaggle/input/nflllll/kaggle/working/models/model_y_fold2.pth\",\n        \"/kaggle/input/nflllll/kaggle/working/models/model_y_fold3.pth\",\n        \"/kaggle/input/nflllll/kaggle/working/models/model_y_fold4.pth\",\n        \"/kaggle/input/nflllll/kaggle/working/models/model_y_fold5.pth\"\n    ]\n    \n    scaler_paths = [\n        \"/kaggle/input/nflllll/kaggle/working/models/scaler_fold1.pkl\",\n        \"/kaggle/input/nflllll/kaggle/working/models/scaler_fold2.pkl\",\n        \"/kaggle/input/nflllll/kaggle/working/models/scaler_fold3.pkl\",\n        \"/kaggle/input/nflllll/kaggle/working/models/scaler_fold4.pkl\",\n        \"/kaggle/input/nflllll/kaggle/working/models/scaler_fold5.pkl\",\n    ]\n    \n    # 确保路径存在\n    for path in model_x_paths + model_y_paths + scaler_paths:\n        if not os.path.exists(path):\n            # 如果在/kaggle/input/nfllll/不存在，尝试在/kaggle/working/models/\n            alt_path = path.replace('/kaggle/input/nfllll/', '/kaggle/working/models/')\n            if os.path.exists(alt_path):\n                path = alt_path\n            else:\n                raise FileNotFoundError(f\"Model file not found: {path}\")\n    \n    _models_x = []\n    _models_y = []\n    _scalers = []\n    \n    for i in range(Config.N_FOLDS):\n        # 加载模型X\n        model_x = ImprovedSeqModel(input_dim=45, horizon=Config.MAX_FUTURE_HORIZON).to(Config.DEVICE)\n        model_x.load_state_dict(torch.load(model_x_paths[i], map_location=Config.DEVICE))\n        model_x.eval()\n        _models_x.append(model_x)\n        \n        # 加载模型Y\n        model_y = ImprovedSeqModel(input_dim=45, horizon=Config.MAX_FUTURE_HORIZON).to(Config.DEVICE)\n        model_y.load_state_dict(torch.load(model_y_paths[i], map_location=Config.DEVICE))\n        model_y.eval()\n        _models_y.append(model_y)\n        \n        # 加载scaler\n        with open(scaler_paths[i], 'rb') as f:\n            scaler = pickle.load(f)\n        _scalers.append(scaler)\n    \n    _models_loaded = True\n    print(\"✅ All models and scalers loaded successfully!\")\n\n_models_x = []\n_models_y = []\n_scalers = []\n_models_loaded = False\n_feature_cols = None\n\nload_models_once()\n# ============================================================================\n# PREDICT FUNCTION\n# ============================================================================\n\ndef predict(test: pl.DataFrame, test_input: pl.DataFrame) -> pl.DataFrame | pd.DataFrame:\n    global _models_x, _models_y, _scalers, _models_loaded, _feature_cols\n    \n    # 第一次调用时加载模型\n    if not _models_loaded:\n        load_models_once()\n    \n    test_pd = test.to_pandas()\n    test_input_pd = test_input.to_pandas()\n    \n    print(\"\\nPreparing test sequences...\")\n    sequences, sequence_ids = prepare_sequences_fixed(\n        test_input_pd, test_template=test_pd, is_training=False, window_size=Config.WINDOW_SIZE\n    )\n    \n    X_test = np.array(sequences, dtype=object)\n    \n    # 获取最后一帧的位置作为基准\n    x_last = np.array([s[-1, 0] for s in X_test])\n    y_last = np.array([s[-1, 1] for s in X_test])\n    \n    # 预测\n    all_dx, all_dy = [], []\n    \n    for mx, my, sc in zip(_models_x, _models_y, _scalers):\n        # 特征缩放\n        X_scaled = np.stack([sc.transform(s) for s in X_test])\n        X_tensor = torch.tensor(X_scaled.astype(np.float32)).to(Config.DEVICE)\n        \n        # 预测\n        mx.eval()\n        my.eval()\n        \n        with torch.no_grad():\n            dx = mx(X_tensor).cpu().numpy()\n            dy = my(X_tensor).cpu().numpy()\n        \n        all_dx.append(dx)\n        all_dy.append(dy)\n    \n    # 平均预测结果\n    ens_dx = np.mean(all_dx, axis=0)\n    ens_dy = np.mean(all_dy, axis=0)\n    \n    # 创建提交结果\n    rows = []\n    H = ens_dx.shape[1]\n    \n    for i, sid in enumerate(sequence_ids):\n        # 获取该球员在测试集中的所有frame_id\n        fids = test_template[\n            (test_template['game_id'] == sid['game_id']) &\n            (test_template['play_id'] == sid['play_id']) &\n            (test_template['nfl_id'] == sid['nfl_id'])\n        ]['frame_id'].sort_values().tolist()\n        \n        for t, fid in enumerate(fids):\n            tt = min(t, H - 1)  # 确保不越界\n            px = np.clip(x_last[i] + ens_dx[i, tt], 0, 120)\n            py = np.clip(y_last[i] + ens_dy[i, tt], 0, 53.3)\n            \n            rows.append({\n                'x': px,\n                'y': py\n            })\n    \n    predictions = pl.DataFrame(rows)\n    \n    assert isinstance(predictions, (pd.DataFrame, pl.DataFrame))\n    assert len(predictions) == len(test)  # 确保预测数量与输入一致\n    return predictions\n\n# 加载测试模板（用于获取frame_id）\ntest_template = pd.read_csv(Config.DATA_DIR / \"test.csv\")\n\n# 设置推理服务器\ninference_server = kaggle_evaluation.nfl_inference_server.NFLInferenceServer(predict)\n\nif os.getenv('KAGGLE_IS_COMPETITION_RERUN'):\n    inference_server.serve()\nelse:\n    inference_server.run_local_gateway()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-27T18:32:21.625103Z","iopub.execute_input":"2025-10-27T18:32:21.625424Z"}},"outputs":[],"execution_count":null}]}