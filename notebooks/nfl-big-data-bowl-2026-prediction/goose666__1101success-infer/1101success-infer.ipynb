{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":114239,"databundleVersionId":14210809,"isSourceIdPinned":false,"sourceType":"competition"},{"sourceId":625928,"sourceType":"modelInstanceVersion","isSourceIdPinned":false,"modelInstanceId":471160,"modelId":487066},{"sourceId":625996,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":471219,"modelId":487125},{"sourceId":626046,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":471262,"modelId":487167},{"sourceId":626048,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":471264,"modelId":487169}],"dockerImageVersionId":31153,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# \"\"\"\n# NFL Big Data Bowl 2026 - KAGGLE INFERENCE\n# é€‚é…Kaggleè¯„åˆ†ç³»ç»Ÿçš„ç‹¬ç«‹predictå‡½æ•°\n# ä¿è¯predictå‡½æ•°ä¸ä¾èµ–å‰é¢cellçš„çŠ¶æ€ï¼Œå¯ç‹¬ç«‹è¿è¡Œ\n# \"\"\"\n\n# import torch\n# import torch.nn as nn\n# import numpy as np\n# import pandas as pd\n# import polars as pl\n# from pathlib import Path\n# from tqdm.auto import tqdm\n# import warnings\n# import os\n# import pickle\n# import joblib\n\n# from torch.utils.data import TensorDataset, DataLoader\n\n# warnings.filterwarnings('ignore')\n\n# # ============================================================================\n# # CONFIGï¼ˆå…¨éƒ¨æ”¾åœ¨å‡½æ•°å†…æˆ–å…¨å±€å¸¸é‡ï¼Œä¸ä¾èµ–å¤–éƒ¨cellï¼‰\n# # ============================================================================\n\n# class Config:\n#     DATA_DIR = Path(\"/kaggle/input/nfl-big-data-bowl-2026-prediction/\")\n    \n#     SEED = 42\n#     N_FOLDS = 5\n#     BATCH_SIZE = 256\n#     WINDOW_SIZE = 12\n#     HIDDEN_DIM = 128\n#     MAX_FUTURE_HORIZON = 94\n#     USE_PLAYERS_INTERACTIONS = True\n    \n#     FIELD_X_MIN, FIELD_X_MAX = 0.0, 120.0\n#     FIELD_Y_MIN, FIELD_Y_MAX = 0.0, 53.3\n    \n#     DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# def set_seed(seed=42):\n#     import random\n#     random.seed(seed)\n#     np.random.seed(seed)\n#     torch.manual_seed(seed)\n#     torch.cuda.manual_seed_all(seed)\n#     os.environ['PYTHONHASHSEED'] = str(seed)\n\n# set_seed(Config.SEED)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-11-01T07:25:28.266517Z","iopub.execute_input":"2025-11-01T07:25:28.267118Z","iopub.status.idle":"2025-11-01T07:25:28.273041Z","shell.execute_reply.started":"2025-11-01T07:25:28.267092Z","shell.execute_reply":"2025-11-01T07:25:28.272088Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\n# # ============================================================================\n# # FEATURE ENGINEERING MODULES\n# # ============================================================================\n\n# def height_to_feet(height_str):\n#     \"\"\"èº«é«˜è½¬æ¢å·¥å…·å‡½æ•°\"\"\"\n#     try:\n#         ft, inches = map(int, str(height_str).split('-'))\n#         return ft + inches/12\n#     except:\n#         return 6.0\n\n\n# def create_base_features(input_df):\n#     \"\"\"\n#     åŸºç¡€ç‰¹å¾å·¥ç¨‹ï¼šç‰©ç†å±æ€§ã€è¿åŠ¨å­¦ã€è§’è‰²ç­‰åŸºç¡€ç‰¹å¾\n#     \"\"\"\n#     df = input_df.copy()\n    \n#     # åŸºç¡€ç‰©ç†ç‰¹å¾\n#     df['player_height_feet'] = df['player_height'].apply(height_to_feet)\n    \n#     # è¿åŠ¨å­¦ç‰¹å¾\n#     dir_rad = np.deg2rad(df['dir'].fillna(0))\n#     delta_t = 0.1\n#     df['velocity_x'] = (df['s'] + 0.5 * df['a'] * delta_t) * np.sin(dir_rad)\n#     df['velocity_y'] = (df['s'] + 0.5 * df['a'] * delta_t) * np.cos(dir_rad)\n#     df['acceleration_x'] = df['a'] * np.sin(dir_rad)\n#     df['acceleration_y'] = df['a'] * np.cos(dir_rad)\n    \n#     # è§’è‰²ç‰¹å¾\n#     df['is_offense'] = (df['player_side'] == 'Offense').astype(int)\n#     df['is_defense'] = (df['player_side'] == 'Defense').astype(int)\n#     df['is_receiver'] = (df['player_role'] == 'Targeted Receiver').astype(int)\n#     df['is_coverage'] = (df['player_role'] == 'Defensive Coverage').astype(int)\n#     df['is_passer'] = (df['player_role'] == 'Passer').astype(int)\n    \n#     # ç‰©ç†é‡ç‰¹å¾\n#     mass_kg = df['player_weight'].fillna(200.0) / 2.20462\n#     df['momentum_x'] = df['velocity_x'] * mass_kg\n#     df['momentum_y'] = df['velocity_y'] * mass_kg\n#     df['kinetic_energy'] = 0.5 * mass_kg * (df['s'] ** 2)\n    \n#     # çƒç›¸å…³ç‰¹å¾\n#     if 'ball_land_x' in df.columns:\n#         ball_dx = df['ball_land_x'] - df['x']\n#         ball_dy = df['ball_land_y'] - df['y']\n#         df['distance_to_ball'] = np.sqrt(ball_dx**2 + ball_dy**2)\n#         df['angle_to_ball'] = np.arctan2(ball_dy, ball_dx)\n#         df['ball_direction_x'] = ball_dx / (df['distance_to_ball'] + 1e-6)\n#         df['ball_direction_y'] = ball_dy / (df['distance_to_ball'] + 1e-6)\n#         df['closing_speed'] = (\n#             df['velocity_x'] * df['ball_direction_x'] +\n#             df['velocity_y'] * df['ball_direction_y']\n#         )\n    \n#     return df\n\n\n# def create_lag_features(df, window_size=8):\n#     \"\"\"\n#     æ—¶åºç‰¹å¾ï¼šæ»åç‰¹å¾ã€EMAã€æ»‘åŠ¨çª—å£ç‰¹å¾\n#     \"\"\"\n#     df = df.copy()\n    \n#     # æŒ‰åˆ†ç»„æ’åº\n#     df = df.sort_values(['game_id', 'play_id', 'nfl_id', 'frame_id'])\n#     gcols = ['game_id', 'play_id', 'nfl_id']\n    \n#     # Lag Features\n#     for lag in [1, 2, 3, 4, 5]:\n#         df[f'x_lag{lag}'] = df.groupby(gcols)['x'].shift(lag)\n#         df[f'y_lag{lag}'] = df.groupby(gcols)['y'].shift(lag)\n#         df[f'velocity_x_lag{lag}'] = df.groupby(gcols)['velocity_x'].shift(lag)\n#         df[f'velocity_y_lag{lag}'] = df.groupby(gcols)['velocity_y'].shift(lag)\n    \n#     # EMA Features\n#     df['velocity_x_ema'] = df.groupby(gcols)['velocity_x'].transform(\n#         lambda x: x.ewm(alpha=0.3, adjust=False).mean()\n#     )\n#     df['velocity_y_ema'] = df.groupby(gcols)['velocity_y'].transform(\n#         lambda x: x.ewm(alpha=0.3, adjust=False).mean()\n#     )\n#     df['speed_ema'] = df.groupby(gcols)['s'].transform(\n#         lambda x: x.ewm(alpha=0.3, adjust=False).mean()\n#     )\n    \n#     # Rolling Features\n#     df['velocity_x_roll'] = df.groupby(gcols)['velocity_x'].transform(\n#         lambda x: x.rolling(window_size, min_periods=1).mean()\n#     )\n#     df['velocity_y_roll'] = df.groupby(gcols)['velocity_y'].transform(\n#         lambda x: x.rolling(window_size, min_periods=1).mean()\n#     )\n    \n#     return df\n\n\n# def add_advanced_features(df):\n#     \"\"\"\n#     é«˜çº§ç‰¹å¾ï¼šè¡ç”Ÿç‰¹å¾ã€äº¤äº’ç‰¹å¾ã€æˆ˜æœ¯ç‰¹å¾\n#     \"\"\"\n#     print(\"Adding advanced features...\")\n#     df = df.copy()\n#     df = df.sort_values(['game_id', 'play_id', 'nfl_id', 'frame_id'])\n#     gcols = ['game_id', 'play_id', 'nfl_id']\n\n#     # ä½ç½®å·®åˆ†ç‰¹å¾\n#     if 'distance_to_ball' in df.columns:\n#         df['distance_to_ball_change'] = df.groupby(gcols)['distance_to_ball'].diff().fillna(0)\n#         df['distance_to_ball_accel'] = df.groupby(gcols)['distance_to_ball_change'].diff().fillna(0)\n#         df['time_to_intercept'] = (df['distance_to_ball'] / \n#                                   (np.abs(df['distance_to_ball_change']) + 0.1)).clip(0, 10)\n\n#     # æœå‘çƒçš„ç‰¹å¾\n#     if 'ball_direction_x' in df.columns:\n#         df['velocity_alignment'] = (\n#             df['velocity_x'] * df['ball_direction_x'] +\n#             df['velocity_y'] * df['ball_direction_y']\n#         )\n#         df['velocity_perpendicular'] = (\n#             df['velocity_x'] * (-df['ball_direction_y']) +\n#             df['velocity_y'] * df['ball_direction_x']\n#         )\n#         if 'acceleration_x' in df.columns:\n#             df['accel_alignment'] = (\n#                 df['acceleration_x'] * df['ball_direction_x'] +\n#                 df['acceleration_y'] * df['ball_direction_y']\n#             )\n\n#     # é€Ÿåº¦å·®åˆ†ç‰¹å¾\n#     if 'velocity_x' in df.columns:\n#         df['velocity_x_change'] = df.groupby(gcols)['velocity_x'].diff().fillna(0)\n#         df['velocity_y_change'] = df.groupby(gcols)['velocity_y'].diff().fillna(0)\n#         df['speed_change'] = df.groupby(gcols)['s'].diff().fillna(0)\n#         df['direction_change'] = df.groupby(gcols)['dir'].diff().fillna(0)\n#         df['direction_change'] = df['direction_change'].apply(\n#             lambda x: x if abs(x) < 180 else x - 360 * np.sign(x)\n#         )\n\n#     # åœºåœ°ä½ç½®ç‰¹å¾\n#     df['dist_from_left'] = df['y']\n#     df['dist_from_right'] = 53.3 - df['y']\n#     df['dist_from_sideline'] = np.minimum(df['dist_from_left'], df['dist_from_right'])\n#     df['dist_from_endzone'] = np.minimum(df['x'], 120 - df['x'])\n\n#     # è§’è‰²ç‰¹å®šç‰¹å¾\n#     if 'is_receiver' in df.columns and 'velocity_alignment' in df.columns:\n#         df['receiver_optimality'] = df['is_receiver'] * df['velocity_alignment']\n#         df['receiver_deviation'] = df['is_receiver'] * np.abs(df.get('velocity_perpendicular', 0))\n#     if 'is_coverage' in df.columns and 'closing_speed' in df.columns:\n#         df['defender_closing_speed'] = df['is_coverage'] * df['closing_speed']\n\n#     # æ—¶é—´ç‰¹å¾\n#     df['frames_elapsed'] = df.groupby(gcols).cumcount()\n#     df['normalized_time'] = df.groupby(gcols)['frames_elapsed'].transform(\n#         lambda x: x / (x.max() + 1)\n#     )\n\n#     # åŸºç¡€ç‰©ç†è¡ç”Ÿç‰¹å¾\n#     df['speed_squared'] = df['s'] ** 2\n#     df['accel_magnitude'] = np.sqrt(df['acceleration_x'] ** 2 + df['acceleration_y'] ** 2)\n#     df['orientation_diff'] = np.abs(df['o'] - df['dir'])\n#     df['orientation_diff'] = np.minimum(df['orientation_diff'], 360 - df['orientation_diff'])\n\n#     if 'nearest_opp_dist' in df.columns:\n#         df['pressure'] = 1 / np.maximum(df['nearest_opp_dist'], 0.5)\n#         df['under_pressure'] = (df['nearest_opp_dist'] < 3).astype(int)\n#         df['pressure_x_speed'] = df['pressure'] * df['s']\n\n#     if 'mirror_wr_vx' in df.columns:\n#         s_safe = np.maximum(df['s'], 0.1)\n#         df['mirror_similarity'] = (\n#                 df['velocity_x'] * df['mirror_wr_vx'] +\n#                 df['velocity_y'] * df['mirror_wr_vy']\n#         ) / s_safe\n#         df['mirror_offset_dist'] = np.sqrt(\n#             df['mirror_offset_x'] ** 2 + df['mirror_offset_y'] ** 2\n#         )\n#         df['mirror_alignment'] = df['mirror_similarity'] * df['is_coverage']\n\n#     return df\n\n\n# def get_opponent_features(input_df):\n#     \"\"\"\n#     å¯¹æ‰‹äº¤äº’ç‰¹å¾ï¼šè®¡ç®—çƒå‘˜ä¸å¯¹æ‰‹ä¹‹é—´çš„ç©ºé—´å’Œè¿åŠ¨å…³ç³»\n#     \"\"\"\n#     features = []\n    \n#     for (gid, pid), group in tqdm(input_df.groupby(['game_id', 'play_id']),\n#                                 desc=\"ğŸˆ Opponents\", leave=False):\n#         last = group.sort_values('frame_id').groupby('nfl_id').last()\n\n#         if len(last) < 2:\n#             continue\n\n#         positions = last[['x', 'y']].values\n#         sides = last['player_side'].values\n#         speeds = last['s'].values\n#         directions = last['dir'].values\n#         roles = last['player_role'].values\n\n#         receiver_mask = np.isin(roles, ['Targeted Receiver', 'Other Route Runner'])\n\n#         for i, (nid, side, role) in enumerate(zip(last.index, sides, roles)):\n#             opp_mask = sides != side\n\n#             feat = {\n#                 'game_id': gid, 'play_id': pid, 'nfl_id': nid,\n#                 'nearest_opp_dist': 50.0, 'closing_speed': 0.0,\n#                 'num_nearby_opp_3': 0, 'num_nearby_opp_5': 0,\n#                 'mirror_wr_vx': 0.0, 'mirror_wr_vy': 0.0,\n#                 'mirror_offset_x': 0.0, 'mirror_offset_y': 0.0,\n#                 'mirror_wr_dist': 50.0,\n#             }\n\n#             if not opp_mask.any():\n#                 features.append(feat)\n#                 continue\n\n#             opp_positions = positions[opp_mask]\n#             distances = np.sqrt(((positions[i] - opp_positions) ** 2).sum(axis=1))\n\n#             if len(distances) == 0:\n#                 features.append(feat)\n#                 continue\n\n#             nearest_idx = distances.argmin()\n#             feat['nearest_opp_dist'] = distances[nearest_idx]\n#             feat['num_nearby_opp_3'] = (distances < 3.0).sum()\n#             feat['num_nearby_opp_5'] = (distances < 5.0).sum()\n\n#             # è®¡ç®—ç›¸å¯¹é€Ÿåº¦\n#             my_vx = speeds[i] * np.sin(np.deg2rad(directions[i]))\n#             my_vy = speeds[i] * np.cos(np.deg2rad(directions[i]))\n#             opp_speeds = speeds[opp_mask]\n#             opp_dirs = directions[opp_mask]\n#             opp_vx = opp_speeds[nearest_idx] * np.sin(np.deg2rad(opp_dirs[nearest_idx]))\n#             opp_vy = opp_speeds[nearest_idx] * np.cos(np.deg2rad(opp_dirs[nearest_idx]))\n\n#             rel_vx = my_vx - opp_vx\n#             rel_vy = my_vy - opp_vy\n#             to_me = positions[i] - opp_positions[nearest_idx]\n#             to_me_norm = to_me / (np.linalg.norm(to_me) + 0.1)\n#             feat['closing_speed'] = -(rel_vx * to_me_norm[0] + rel_vy * to_me_norm[1])\n\n#             # é˜²å®ˆçƒå‘˜ä¸æ¥çƒæ‰‹çš„é•œåƒå…³ç³»\n#             if role == 'Defensive Coverage' and receiver_mask.any():\n#                 rec_positions = positions[receiver_mask]\n#                 rec_distances = np.sqrt(((positions[i] - rec_positions) ** 2).sum(axis=1))\n\n#                 if len(rec_distances) > 0:\n#                     closest_rec_idx = rec_distances.argmin()\n#                     rec_indices = np.where(receiver_mask)[0]\n#                     actual_rec_idx = rec_indices[closest_rec_idx]\n\n#                     rec_vx = speeds[actual_rec_idx] * np.sin(np.deg2rad(directions[actual_rec_idx]))\n#                     rec_vy = speeds[actual_rec_idx] * np.cos(np.deg2rad(directions[actual_rec_idx]))\n\n#                     feat['mirror_wr_vx'] = rec_vx\n#                     feat['mirror_wr_vy'] = rec_vy\n#                     feat['mirror_wr_dist'] = rec_distances[closest_rec_idx]\n#                     feat['mirror_offset_x'] = positions[i][0] - rec_positions[closest_rec_idx][0]\n#                     feat['mirror_offset_y'] = positions[i][1] - rec_positions[closest_rec_idx][1]\n\n#             features.append(feat)\n\n#     return pd.DataFrame(features)\n\n# def create_multi_window_rolling_features(df):\n#     \"\"\"å¤šçª—å£æ»šåŠ¨ç‰¹å¾ï¼ˆ3,5,10çª—å£çš„æ»šåŠ¨å¹³å‡å’Œæ ‡å‡†å·®ï¼‰\"\"\"\n#     new_cols = []\n#     gcols = ['game_id', 'play_id', 'nfl_id']\n    \n#     for window in (3, 6, 9):\n#         for col in ('velocity_x', 'velocity_y', 's', 'a'):\n#             if col in df.columns:\n#                 r_mean = df.groupby(gcols)[col].rolling(window, min_periods=1).mean()\n#                 r_std = df.groupby(gcols)[col].rolling(window, min_periods=1).std()\n#                 # å¯¹é½ç´¢å¼•\n#                 r_mean = r_mean.reset_index(level=gcols, drop=True)\n#                 r_std = r_std.reset_index(level=gcols, drop=True)\n#                 df[f'{col}_roll{window}'] = r_mean\n#                 df[f'{col}_std{window}'] = r_std.fillna(0.0)\n#                 new_cols.extend([f'{col}_roll{window}', f'{col}_std{window}'])\n#     return df, new_cols\n\n# def create_qb_relative_features(df):\n#     \"\"\"å››åˆ†å«ç›¸å¯¹ç‰¹å¾ï¼ˆä¸å››åˆ†å«çš„è·ç¦»å’Œæ–¹å‘å…³ç³»ï¼‰\"\"\"\n#     need = ['x', 'y', 'velocity_x', 'velocity_y', 'dir', 'player_role', 'frame_id']\n#     for c in need:\n#         if c not in df.columns:\n#             return df, []  # ç¼ºåˆ—åˆ™å®‰å…¨è·³è¿‡\n    \n#     out_cols = [\n#         'qb_distance', 'vel_to_qb_alignment', 'vel_to_qb_perp',\n#         'bearing_to_qb_signed', 'bearing_to_qb_sin', 'bearing_to_qb_cos'\n#     ]\n#     for c in out_cols:\n#         if c not in df.columns:\n#             df[c] = np.nan\n    \n#     key = ['game_id', 'play_id', 'frame_id']\n#     for _, g in df.groupby(key, sort=False):\n#         idx = g.index.values\n        \n#         # æ‰¾æœ¬å¸§ QB\n#         qb_rows = g[g['player_role'] == 'Passer']\n#         if qb_rows.empty:\n#             continue\n#         qb_x = float(qb_rows.iloc[0]['x'])\n#         qb_y = float(qb_rows.iloc[0]['y'])\n    \n#         dx = g['x'].values.astype('float32') - qb_x\n#         dy = g['y'].values.astype('float32') - qb_y\n#         dist = np.sqrt(dx * dx + dy * dy) + 1e-6\n#         ux, uy = dx / dist, dy / dist  # QB->player å•ä½å‘é‡\n    \n#         vx = g['velocity_x'].values.astype('float32')\n#         vy = g['velocity_y'].values.astype('float32')\n    \n#         align = vx * ux + vy * uy\n#         perp = vx * (-uy) + vy * ux\n    \n#         # bearing å·®\n#         dir_rad = np.deg2rad(g['dir'].fillna(0.0).astype('float32').values)\n#         to_qb_angle = np.arctan2(-dy, -dx)  # player->QB\n#         bearing = np.rad2deg(np.arctan2(np.sin(to_qb_angle - dir_rad), np.cos(to_qb_angle - dir_rad)))\n    \n#         df.loc[idx, 'qb_distance'] = dist\n#         df.loc[idx, 'vel_to_qb_alignment'] = align\n#         df.loc[idx, 'vel_to_qb_perp'] = perp\n#         df.loc[idx, 'bearing_to_qb_signed'] = bearing\n#         df.loc[idx, 'bearing_to_qb_sin'] = np.sin(np.deg2rad(bearing))\n#         df.loc[idx, 'bearing_to_qb_cos'] = np.cos(np.deg2rad(bearing))\n    \n#     return df, out_cols\n\n# def create_jerk_features(df):\n#     \"\"\"æ€¥åŠ¨ç‰¹å¾ï¼ˆåŠ é€Ÿåº¦çš„å˜åŒ–ç‡ï¼‰\"\"\"\n#     new_cols = []\n#     gcols = ['game_id', 'play_id', 'nfl_id']\n    \n#     if 'a' in df.columns:\n#         df['jerk'] = df.groupby(gcols)['a'].diff().fillna(0.0) * 0.1  # å‡è®¾delta_t=0.1\n#         new_cols.append('jerk')\n    \n#     if {'acceleration_x', 'acceleration_y'}.issubset(df.columns):\n#         df['jerk_x'] = df.groupby(gcols)['acceleration_x'].diff().fillna(0.0) * 0.1\n#         df['jerk_y'] = df.groupby(gcols)['acceleration_y'].diff().fillna(0.0) * 0.1\n#         new_cols.extend(['jerk_x', 'jerk_y'])\n    \n#     return df, new_cols\n\n# def create_curvature_land_features(df):\n#     \"\"\"è½ç‚¹æ›²ç‡ç‰¹å¾ï¼ˆä¾§å‘åå·®ã€è§’åº¦å·®ã€æ›²ç‡ï¼‰\"\"\"\n#     import numpy as np\n#     new_cols = []\n    \n#     if {'ball_land_x', 'ball_land_y'}.issubset(df.columns):\n#         # ä¾§å‘åå·®å’Œbearing_to_land\n#         dx = df['ball_land_x'] - df['x']\n#         dy = df['ball_land_y'] - df['y']\n#         bearing = np.arctan2(dy, dx)\n#         a_dir = np.deg2rad(df['dir'].fillna(0.0).values)\n#         # æœ‰ç¬¦å·æ–¹ä½å·®\n#         df['bearing_to_land_signed'] = np.rad2deg(np.arctan2(np.sin(bearing - a_dir), np.cos(bearing - a_dir)))\n#         # ä¾§å‘åå·®\n#         ux, uy = np.cos(a_dir), np.sin(a_dir)\n#         df['land_lateral_offset'] = dy * ux - dx * uy  # >0 è½ç‚¹åœ¨å·¦ä¾§\n    \n#     # æ›²ç‡\n#     ddir = df.groupby(['game_id', 'play_id', 'nfl_id'])['dir'].diff().fillna(0.0)\n#     ddir = ((ddir + 180.0) % 360.0) - 180.0\n#     curvature = np.deg2rad(ddir).astype('float32') / (df['s'].replace(0, np.nan).astype('float32') * 0.1 + 1e-6)\n#     df['curvature_signed'] = curvature.fillna(0.0)\n#     df['curvature_abs'] = df['curvature_signed'].abs()\n    \n#     # çª—å£å‡å€¼\n#     for w in (3, 5):\n#         if 'curvature_signed' in df.columns:\n#             r = df.groupby(['game_id', 'play_id', 'nfl_id'])['curvature_signed'].rolling(w, min_periods=1).mean().reset_index(level=['game_id', 'play_id', 'nfl_id'], drop=True)\n#             df[f'curv_signed_roll{w}'] = r\n#         if 'curvature_abs' in df.columns:\n#             r2 = df.groupby(['game_id', 'play_id', 'nfl_id'])['curvature_abs'].rolling(w, min_periods=1).mean().reset_index(level=['game_id', 'play_id', 'nfl_id'], drop=True)\n#             df[f'curv_abs_roll{w}'] = r2\n    \n#     new_cols.extend([\n#         'bearing_to_land_signed', 'land_lateral_offset',\n#         'curvature_signed', 'curvature_abs',\n#         'curv_signed_roll3', 'curv_abs_roll3',\n#         'curv_signed_roll5', 'curv_abs_roll5'\n#     ])\n    \n#     return df, [c for c in new_cols if c in df.columns]\n\n# def get_feature_columns(df):\n#     \"\"\"\n#     è·å–ç‰¹å¾åˆ—åˆ—è¡¨ï¼ˆåŒ…å«æ‰€æœ‰ç‰¹å¾ï¼‰\n#     \"\"\"\n#     base_feature_cols = [\n#         'x', 'y', 's', 'a', 'o', 'dir', 'frame_id',\n#         'ball_land_x', 'ball_land_y',\n#         'player_height_feet', 'player_weight',\n#         'velocity_x', 'velocity_y', 'acceleration_x', 'acceleration_y',\n#         'momentum_x', 'momentum_y', 'kinetic_energy',\n#         'is_offense', 'is_defense', 'is_receiver', 'is_coverage', 'is_passer',\n#         'distance_to_ball', 'angle_to_ball', 'ball_direction_x', 'ball_direction_y', 'closing_speed',\n#         'x_lag1', 'y_lag1', 'velocity_x_lag1', 'velocity_y_lag1',\n#         'x_lag2', 'y_lag2', 'velocity_x_lag2', 'velocity_y_lag2',\n#         'x_lag3', 'y_lag3', 'velocity_x_lag3', 'velocity_y_lag3',\n#         'x_lag4', 'y_lag4', 'velocity_x_lag4', 'velocity_y_lag4',\n#         'x_lag5', 'y_lag5', 'velocity_x_lag5', 'velocity_y_lag5',\n#         'velocity_x_ema', 'velocity_y_ema', 'speed_ema',\n#         'velocity_x_roll', 'velocity_y_roll',\n\n#         'distance_to_ball_change', 'distance_to_ball_accel', 'time_to_intercept',\n#         'velocity_alignment', 'velocity_perpendicular', 'accel_alignment',\n#         'velocity_x_change', 'velocity_y_change', 'speed_change', 'direction_change',\n#         'dist_from_sideline', 'dist_from_endzone',\n#         'receiver_optimality', 'receiver_deviation', 'defender_closing_speed',\n#         'frames_elapsed', 'normalized_time', 'velocity_x_delta', 'velocity_y_delta',\n\n#         # æ·»åŠ å¯¹æ‰‹äº¤äº’ç‰¹å¾\n#         'nearest_opp_dist', 'closing_speed', 'num_nearby_opp_3', 'num_nearby_opp_5',\n#         'mirror_wr_vx', 'mirror_wr_vy', 'mirror_offset_x', 'mirror_offset_y', 'mirror_wr_dist',\n#         'pressure', 'under_pressure', 'pressure_x_speed',\n#         'mirror_similarity', 'mirror_offset_dist', 'mirror_alignment'\n\n#         # 'velocity_x_roll3', 'velocity_x_roll6', 'velocity_x_roll9', 'velocity_x_std3', 'velocity_x_std6', 'velocity_x_std9'\n#         # 'velocity_y_roll3', 'velocity_y_roll6', 'velocity_y_roll9', 'velocity_y_std3', 'velocity_y_std6', 'velocity_y_std9',\n#         # 's_roll3', 's_roll6', 's_roll9', 's_std3', 's_std6', 's_std9'\n#         # 'a_roll3', 'a_roll6', 'a_roll9', 'a_std3', 'a_std6', 'a_std9'\n#         # 'qb_distance', 'vel_to_qb_alignment', 'vel_to_qb_perp',\n#         # 'bearing_to_qb_signed', 'bearing_to_qb_sin', 'bearing_to_qb_cos'\n#                 # æ€¥åŠ¨ç‰¹å¾\n#         'jerk', 'jerk_x', 'jerk_y',\n        \n#         # è½ç‚¹æ›²ç‡ç‰¹å¾\n#         'bearing_to_land_signed', 'land_lateral_offset', 'curvature_signed', 'curvature_abs',\n#         'curv_signed_roll3', 'curv_abs_roll3', 'curv_signed_roll5', 'curv_abs_roll5',\n#     ]\n    \n#     # åˆå¹¶æ‰€æœ‰ç‰¹å¾åˆ—ï¼Œåªè¿”å›æ•°æ®é›†ä¸­å­˜åœ¨çš„\n#     all_feature_cols = base_feature_cols\n#     return [c for c in all_feature_cols if c in df.columns]\n\n\n# # ============================================================================\n# # MAIN SEQUENCE PREPARATION FUNCTION\n# # ============================================================================\n\n# def prepare_sequences_fixed(input_df, output_df=None, test_template=None, is_training=True, window_size=Config.WINDOW_SIZE):\n#     \"\"\"\n#     å‡†å¤‡åºåˆ—æ•°æ®çš„ä¸»å‡½æ•°ï¼ˆåŒ…å«æ‰€æœ‰ç‰¹å¾å·¥ç¨‹ï¼‰\n#     \"\"\"\n#     # åˆ†æ­¥åº”ç”¨ç‰¹å¾å·¥ç¨‹\n#     input_df = create_base_features(input_df)\n#     input_df = create_lag_features(input_df, window_size)\n#     opponent_features = get_opponent_features(input_df)\n#     input_df = input_df.merge(opponent_features, on=['game_id', 'play_id', 'nfl_id'], how='left')\n#     input_df = add_advanced_features(input_df)\n#     # input_df, _ = create_multi_window_rolling_features(input_df)\n#     # input_df, _ = create_qb_relative_features(input_df)\n#         # æ€¥åŠ¨ç‰¹å¾\n#     input_df, _ = create_jerk_features(input_df)\n#     # è½ç‚¹æ›²ç‡ç‰¹å¾\n#     input_df, _ = create_curvature_land_features(input_df)\n\n#     # è·å–ç‰¹å¾åˆ—\n#     feature_cols = get_feature_columns(input_df)\n#     print(f\"ä½¿ç”¨ {len(feature_cols)} ä¸ªç‰¹å¾\" + (\" (è®­ç»ƒ)\" if is_training else \"\"))\n    \n#     # è®¾ç½®ç´¢å¼•ç”¨äºåˆ†ç»„æ“ä½œ\n#     input_df.set_index(['game_id', 'play_id', 'nfl_id'], inplace=True)\n#     grouped = input_df.groupby(level=['game_id', 'play_id', 'nfl_id'])\n    \n#     if is_training:\n#         target_rows = output_df\n#         target_groups = target_rows[['game_id', 'play_id', 'nfl_id']].drop_duplicates()\n#         sequences, targets_dx, targets_dy, targets_frame_ids, sequence_ids = [], [], [], [], []\n        \n#         for _, row in tqdm(target_groups.iterrows(), total=len(target_groups)):\n#             key = (row['game_id'], row['play_id'], row['nfl_id'])\n#             try:\n#                 group_df = grouped.get_group(key)\n#             except KeyError:\n#                 continue\n            \n#             # åˆ›å»ºè¾“å…¥çª—å£\n#             input_window = group_df.tail(window_size)\n#             if len(input_window) < window_size:\n#                 if is_training:\n#                     continue\n#                 pad_len = window_size - len(input_window)\n#                 pad_df = pd.DataFrame(np.nan, index=range(pad_len), columns=input_window.columns)\n#                 input_window = pd.concat([pad_df, input_window], ignore_index=True)\n            \n#             # å¡«å……ç¼ºå¤±å€¼\n#             input_window = input_window.fillna(group_df.mean(numeric_only=True))\n#             seq = input_window[feature_cols].values\n            \n#             # å¤„ç†NaNå€¼\n#             if np.isnan(seq).any():\n#                 if is_training:\n#                     continue\n#                 seq = np.nan_to_num(seq, nan=0.0)\n            \n#             sequences.append(seq)\n            \n#             # è·å–å¯¹åº”çš„ç›®æ ‡å€¼\n#             out_grp = target_rows[\n#                 (target_rows['game_id'] == row['game_id']) &\n#                 (target_rows['play_id'] == row['play_id']) &\n#                 (target_rows['nfl_id'] == row['nfl_id'])\n#             ].sort_values('frame_id')\n            \n#             last_x = input_window.iloc[-1]['x']\n#             last_y = input_window.iloc[-1]['y']\n#             dx = out_grp['x'].values - last_x\n#             dy = out_grp['y'].values - last_y\n#             targets_dx.append(dx)\n#             targets_dy.append(dy)\n#             targets_frame_ids.append(out_grp['frame_id'].values)\n            \n#             sequence_ids.append({\n#                 'game_id': key[0],\n#                 'play_id': key[1],\n#                 'nfl_id': key[2],\n#                 'frame_id': input_window.iloc[-1]['frame_id']\n#             })\n        \n#         return sequences, targets_dx, targets_dy, targets_frame_ids, sequence_ids\n    \n#     else:\n#         # æ¨ç†æ¨¡å¼\n#         target_groups = test_template[['game_id', 'play_id', 'nfl_id']].drop_duplicates()\n#         sequences, sequence_ids = [], []\n        \n#         for _, row in target_groups.iterrows():\n#             key = (row['game_id'], row['play_id'], row['nfl_id'])\n#             try:\n#                 group_df = grouped.get_group(key)\n#             except KeyError:\n#                 continue\n            \n#             # åˆ›å»ºè¾“å…¥çª—å£\n#             input_window = group_df.tail(window_size)\n#             if len(input_window) < window_size:\n#                 pad_len = window_size - len(input_window)\n#                 pad_df = pd.DataFrame(np.nan, index=range(pad_len), columns=input_window.columns)\n#                 input_window = pd.concat([pad_df, input_window], ignore_index=True)\n            \n#             # å¡«å……ç¼ºå¤±å€¼\n#             input_window = input_window.fillna(group_df.mean(numeric_only=True))\n#             seq = input_window[feature_cols].values\n            \n#             # å¤„ç†NaNå€¼\n#             if np.isnan(seq).any():\n#                 seq = np.nan_to_num(seq, nan=0.0)\n            \n#             sequences.append(seq)\n#             sequence_ids.append({\n#                 'game_id': key[0],\n#                 'play_id': key[1],\n#                 'nfl_id': key[2],\n#                 'frame_id': input_window.iloc[-1]['frame_id']\n#             })\n        \n#         return sequences, sequence_ids","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-11-01T07:25:28.696641Z","iopub.execute_input":"2025-11-01T07:25:28.696996Z","iopub.status.idle":"2025-11-01T07:25:28.717085Z","shell.execute_reply.started":"2025-11-01T07:25:28.696972Z","shell.execute_reply":"2025-11-01T07:25:28.716033Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# # ============================================================================\n# # MODELï¼ˆä¸è®­ç»ƒä¸€è‡´ï¼Œå®šä¹‰åœ¨å‡½æ•°å¤–ä½†ä»£ç å®Œæ•´ï¼‰\n# # ============================================================================\n\n# class ImprovedSeqModel(nn.Module):\n#     def __init__(self, input_dim, horizon):\n#         super().__init__()\n#         self.horizon = horizon\n#         self.gru = nn.GRU(input_dim, 128, num_layers=2, batch_first=True, dropout=0.1)\n#         self.pool_ln = nn.LayerNorm(128)\n#         self.pool_attn = nn.MultiheadAttention(128, num_heads=4, batch_first=True)\n#         self.pool_query = nn.Parameter(torch.randn(1, 1, 128))\n#         self.head = nn.Sequential(\n#             nn.Linear(128, 128),\n#             nn.GELU(),\n#             nn.Dropout(0.2),\n#             nn.Linear(128, horizon)\n#         )\n    \n#     def forward(self, x):\n#         h, _ = self.gru(x)\n#         B = h.size(0)\n#         q = self.pool_query.expand(B, -1, -1)\n#         h_norm = self.pool_ln(h)\n#         ctx, _ = self.pool_attn(q, h_norm, h_norm)\n#         ctx = ctx.squeeze(1)\n#         out = self.head(ctx)\n#         out = torch.cumsum(out, dim=1)\n#         return out\n\n# # ============================================================================\n# # INFERENCE æ ¸å¿ƒï¼špredictå‡½æ•°ï¼ˆç‹¬ç«‹è¿è¡Œï¼Œä¸ä¾èµ–å¤–éƒ¨çŠ¶æ€ï¼‰\n# # ============================================================================\n\n# def predict(test: pl.DataFrame, test_input: pl.DataFrame) -> pl.DataFrame:\n#     # ===== 1. å‡†å¤‡æ•°æ® =====\n#     test_pd = test.to_pandas()\n#     test_input_pd = test_input.to_pandas()\n    \n#     # ===== 2. ç‰¹å¾å·¥ç¨‹ï¼ˆä¸è®­ç»ƒå®Œå…¨ä¸€è‡´ï¼‰=====\n#     sequences, sequence_ids = prepare_sequences_fixed(\n#         test_input_pd, test_template=test_pd, is_training=False, window_size=Config.WINDOW_SIZE\n#     )\n    \n#     if not sequences:\n#         return pl.DataFrame({\"x\": [], \"y\": []})\n    \n#     X_test = np.array(sequences, dtype=object)\n#     x_last = np.array([s[-1, 0] for s in X_test])\n#     y_last = np.array([s[-1, 1] for s in X_test])\n    \n#     # ===== 3. åŠ è½½æ¨¡å‹ & Scalerï¼ˆé¦–æ¬¡è¿è¡Œæ—¶åŠ è½½ï¼‰=====\n#     # æ¨¡å‹è·¯å¾„ â€”â€” è¯·æ ¹æ®ä½ å®é™…ä¸Šä¼ çš„æ¨¡å‹è·¯å¾„ä¿®æ”¹ï¼ï¼ï¼\n#     MODEL_DIR = Path(\"/kaggle/input/1101addjerk/pytorch/default/1/1101addjerk\")  # å¿…é¡»ä¸Šä¼ æ¨¡å‹åˆ° input ç›®å½•ï¼Œå¦‚ /kaggle/input/nfl-models/\n    \n#     model_x_paths = [\n#         MODEL_DIR / f\"model_x_fold{i+1}.pth\" for i in range(Config.N_FOLDS)\n#     ]\n#     model_y_paths = [\n#         MODEL_DIR / f\"model_y_fold{i+1}.pth\" for i in range(Config.N_FOLDS)\n#     ]\n#     scaler_paths = [\n#         MODEL_DIR / f\"scaler_fold{i+1}.pkl\" for i in range(Config.N_FOLDS)\n#     ]\n    \n#     # æ£€æŸ¥è·¯å¾„æ˜¯å¦å­˜åœ¨ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™æŠ¥é”™æç¤ºç”¨æˆ·ä¸Šä¼ \n#     for p in model_x_paths + model_y_paths + scaler_paths:\n#         if not p.exists():\n#             raise FileNotFoundError(f\"è¯·ä¸Šä¼ æ¨¡å‹æ–‡ä»¶åˆ° /kaggle/input/nfl-models/ ï¼Œç¼ºå¤±: {p.name}\")\n\n#     models_x = []\n#     models_y = []\n#     scalers = []\n    \n#     for i in range(Config.N_FOLDS):\n#         # æ¨¡å‹X\n#         model_x = ImprovedSeqModel(input_dim=X_test[0].shape[1], horizon=Config.MAX_FUTURE_HORIZON).to(Config.DEVICE)\n#         model_x.load_state_dict(torch.load(model_x_paths[i], map_location=Config.DEVICE))\n#         model_x.eval()\n#         models_x.append(model_x)\n        \n#         # æ¨¡å‹Y\n#         model_y = ImprovedSeqModel(input_dim=X_test[0].shape[1], horizon=Config.MAX_FUTURE_HORIZON).to(Config.DEVICE)\n#         model_y.load_state_dict(torch.load(model_y_paths[i], map_location=Config.DEVICE))\n#         model_y.eval()\n#         models_y.append(model_y)\n        \n#         # Scaler\n#         scaler = joblib.load(scaler_paths[i])\n#         scalers.append(scaler)\n    \n#     # ===== 4. é¢„æµ‹ =====\n#     all_dx, all_dy = [], []\n#     for mx, my, sc in zip(models_x, models_y, scalers):\n#         X_scaled = np.stack([sc.transform(s) for s in X_test])\n#         X_tensor = torch.tensor(X_scaled.astype(np.float32)).to(Config.DEVICE)\n        \n#         mx.eval()\n#         my.eval()\n#         with torch.no_grad():\n#             dx = mx(X_tensor).cpu().numpy()\n#             dy = my(X_tensor).cpu().numpy()\n#         all_dx.append(dx)\n#         all_dy.append(dy)\n    \n#     ens_dx = np.mean(all_dx, axis=0)\n#     ens_dy = np.mean(all_dy, axis=0)\n    \n#     # ===== 5. æ„é€ æäº¤ç»“æœ =====\n#     rows = []\n#     H = ens_dx.shape[1]  # é¢„æµ‹æ­¥æ•°\n    \n#     for i, sid in enumerate(sequence_ids):\n#         fids = test_pd[\n#             (test_pd['game_id'] == sid['game_id']) &\n#             (test_pd['play_id'] == sid['play_id']) &\n#             (test_pd['nfl_id'] == sid['nfl_id'])\n#         ]['frame_id'].sort_values().tolist()\n        \n#         for t, fid in enumerate(fids):\n#             tt = min(t, H - 1)\n#             px = np.clip(x_last[i] + ens_dx[i, tt], 0, 120)\n#             py = np.clip(y_last[i] + ens_dy[i, tt], 0, 53.3)\n#             rows.append({'x': px, 'y': py})\n    \n#     return pl.DataFrame(rows)\n\n# # ============================================================================\n# # Kaggle æ¨ç†æœåŠ¡å™¨ï¼ˆè‡ªåŠ¨è°ƒç”¨predictï¼‰\n# # ============================================================================\n\n# # ç¡®ä¿å¯¼å…¥å®˜æ–¹è¯„ä¼°åº“\n# try:\n#     from kaggle_evaluation.nfl_inference_server import NFLInferenceServer\n# except ImportError as e:\n#     raise ImportError(\"è¯·ç¡®ä¿ä½¿ç”¨ Kaggle çš„ NFL Inference è¯„æµ‹å†…æ ¸\")\n\n# # åˆ›å»ºæ¨ç†æœåŠ¡å™¨å¹¶è¿è¡Œ\n# inference_server = NFLInferenceServer(predict)\n\n# if os.getenv('KAGGLE_IS_COMPETITION_RERUN'):\n#     inference_server.serve()\n# else:\n#     inference_server.run_local_gateway(('/kaggle/input/nfl-big-data-bowl-2026-prediction/',))","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-11-01T07:25:29.202677Z","iopub.execute_input":"2025-11-01T07:25:29.203274Z","execution_failed":"2025-11-01T07:25:46.273Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\"\"\"\nNFL Big Data Bowl 2026 - KAGGLE INFERENCE\né€‚é…Kaggleè¯„åˆ†ç³»ç»Ÿçš„ç‹¬ç«‹predictå‡½æ•°\nä¿è¯predictå‡½æ•°ä¸ä¾èµ–å‰é¢cellçš„çŠ¶æ€ï¼Œå¯ç‹¬ç«‹è¿è¡Œ\n\"\"\"\n\nimport torch\nimport torch.nn as nn\nimport numpy as np\nimport pandas as pd\nimport polars as pl\nfrom pathlib import Path\nfrom tqdm.auto import tqdm\nimport warnings\nimport os\nimport pickle\nimport joblib\n\nfrom torch.utils.data import TensorDataset, DataLoader\n\nwarnings.filterwarnings('ignore')\n\n# ============================================================================\n# CONFIGï¼ˆå…¨éƒ¨æ”¾åœ¨å‡½æ•°å†…æˆ–å…¨å±€å¸¸é‡ï¼Œä¸ä¾èµ–å¤–éƒ¨cellï¼‰\n# ============================================================================\n\nclass Config:\n    DATA_DIR = Path(\"/kaggle/input/nfl-big-data-bowl-2026-prediction/\")\n    \n    SEED = 42\n    N_FOLDS = 5\n    BATCH_SIZE = 256\n    WINDOW_SIZE = 12\n    HIDDEN_DIM = 128\n    MAX_FUTURE_HORIZON = 94\n    USE_PLAYERS_INTERACTIONS = True\n    \n    FIELD_X_MIN, FIELD_X_MAX = 0.0, 120.0\n    FIELD_Y_MIN, FIELD_Y_MAX = 0.0, 53.3\n    \n    DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\ndef set_seed(seed=42):\n    import random\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n\nset_seed(Config.SEED)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-01T07:26:44.629145Z","iopub.execute_input":"2025-11-01T07:26:44.629408Z","iopub.status.idle":"2025-11-01T07:26:51.164619Z","shell.execute_reply.started":"2025-11-01T07:26:44.629391Z","shell.execute_reply":"2025-11-01T07:26:51.16358Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\n# ============================================================================\n# FEATURE ENGINEERING MODULES\n# ============================================================================\n\ndef height_to_feet(height_str):\n    \"\"\"èº«é«˜è½¬æ¢å·¥å…·å‡½æ•°\"\"\"\n    try:\n        ft, inches = map(int, str(height_str).split('-'))\n        return ft + inches/12\n    except:\n        return 6.0\n\n\ndef create_base_features(input_df):\n    \"\"\"\n    åŸºç¡€ç‰¹å¾å·¥ç¨‹ï¼šç‰©ç†å±æ€§ã€è¿åŠ¨å­¦ã€è§’è‰²ç­‰åŸºç¡€ç‰¹å¾\n    \"\"\"\n    df = input_df.copy()\n    \n    # åŸºç¡€ç‰©ç†ç‰¹å¾\n    df['player_height_feet'] = df['player_height'].apply(height_to_feet)\n    \n    # è¿åŠ¨å­¦ç‰¹å¾\n    dir_rad = np.deg2rad(df['dir'].fillna(0))\n    delta_t = 0.1\n    df['velocity_x'] = (df['s'] + 0.5 * df['a'] * delta_t) * np.sin(dir_rad)\n    df['velocity_y'] = (df['s'] + 0.5 * df['a'] * delta_t) * np.cos(dir_rad)\n    df['acceleration_x'] = df['a'] * np.sin(dir_rad)\n    df['acceleration_y'] = df['a'] * np.cos(dir_rad)\n    \n    # è§’è‰²ç‰¹å¾\n    df['is_offense'] = (df['player_side'] == 'Offense').astype(int)\n    df['is_defense'] = (df['player_side'] == 'Defense').astype(int)\n    df['is_receiver'] = (df['player_role'] == 'Targeted Receiver').astype(int)\n    df['is_coverage'] = (df['player_role'] == 'Defensive Coverage').astype(int)\n    df['is_passer'] = (df['player_role'] == 'Passer').astype(int)\n    \n    # ç‰©ç†é‡ç‰¹å¾\n    mass_kg = df['player_weight'].fillna(200.0) / 2.20462\n    df['momentum_x'] = df['velocity_x'] * mass_kg\n    df['momentum_y'] = df['velocity_y'] * mass_kg\n    df['kinetic_energy'] = 0.5 * mass_kg * (df['s'] ** 2)\n    \n    # çƒç›¸å…³ç‰¹å¾\n    if 'ball_land_x' in df.columns:\n        ball_dx = df['ball_land_x'] - df['x']\n        ball_dy = df['ball_land_y'] - df['y']\n        df['distance_to_ball'] = np.sqrt(ball_dx**2 + ball_dy**2)\n        df['angle_to_ball'] = np.arctan2(ball_dy, ball_dx)\n        df['ball_direction_x'] = ball_dx / (df['distance_to_ball'] + 1e-6)\n        df['ball_direction_y'] = ball_dy / (df['distance_to_ball'] + 1e-6)\n        df['closing_speed'] = (\n            df['velocity_x'] * df['ball_direction_x'] +\n            df['velocity_y'] * df['ball_direction_y']\n        )\n    \n    return df\n\n\ndef create_lag_features(df, window_size=8):\n    \"\"\"\n    æ—¶åºç‰¹å¾ï¼šæ»åç‰¹å¾ã€EMAã€æ»‘åŠ¨çª—å£ç‰¹å¾\n    \"\"\"\n    df = df.copy()\n    \n    # æŒ‰åˆ†ç»„æ’åº\n    df = df.sort_values(['game_id', 'play_id', 'nfl_id', 'frame_id'])\n    gcols = ['game_id', 'play_id', 'nfl_id']\n    \n    # Lag Features\n    for lag in [1, 2, 3, 4, 5]:\n        df[f'x_lag{lag}'] = df.groupby(gcols)['x'].shift(lag)\n        df[f'y_lag{lag}'] = df.groupby(gcols)['y'].shift(lag)\n        df[f'velocity_x_lag{lag}'] = df.groupby(gcols)['velocity_x'].shift(lag)\n        df[f'velocity_y_lag{lag}'] = df.groupby(gcols)['velocity_y'].shift(lag)\n    \n    # EMA Features\n    df['velocity_x_ema'] = df.groupby(gcols)['velocity_x'].transform(\n        lambda x: x.ewm(alpha=0.3, adjust=False).mean()\n    )\n    df['velocity_y_ema'] = df.groupby(gcols)['velocity_y'].transform(\n        lambda x: x.ewm(alpha=0.3, adjust=False).mean()\n    )\n    df['speed_ema'] = df.groupby(gcols)['s'].transform(\n        lambda x: x.ewm(alpha=0.3, adjust=False).mean()\n    )\n    \n    # Rolling Features\n    df['velocity_x_roll'] = df.groupby(gcols)['velocity_x'].transform(\n        lambda x: x.rolling(window_size, min_periods=1).mean()\n    )\n    df['velocity_y_roll'] = df.groupby(gcols)['velocity_y'].transform(\n        lambda x: x.rolling(window_size, min_periods=1).mean()\n    )\n    \n    return df\n\n\ndef add_advanced_features(df):\n    \"\"\"\n    é«˜çº§ç‰¹å¾ï¼šè¡ç”Ÿç‰¹å¾ã€äº¤äº’ç‰¹å¾ã€æˆ˜æœ¯ç‰¹å¾\n    \"\"\"\n    print(\"Adding advanced features...\")\n    df = df.copy()\n    df = df.sort_values(['game_id', 'play_id', 'nfl_id', 'frame_id'])\n    gcols = ['game_id', 'play_id', 'nfl_id']\n\n    # ä½ç½®å·®åˆ†ç‰¹å¾\n    if 'distance_to_ball' in df.columns:\n        df['distance_to_ball_change'] = df.groupby(gcols)['distance_to_ball'].diff().fillna(0)\n        df['distance_to_ball_accel'] = df.groupby(gcols)['distance_to_ball_change'].diff().fillna(0)\n        df['time_to_intercept'] = (df['distance_to_ball'] / \n                                  (np.abs(df['distance_to_ball_change']) + 0.1)).clip(0, 10)\n\n    # æœå‘çƒçš„ç‰¹å¾\n    if 'ball_direction_x' in df.columns:\n        df['velocity_alignment'] = (\n            df['velocity_x'] * df['ball_direction_x'] +\n            df['velocity_y'] * df['ball_direction_y']\n        )\n        df['velocity_perpendicular'] = (\n            df['velocity_x'] * (-df['ball_direction_y']) +\n            df['velocity_y'] * df['ball_direction_x']\n        )\n        if 'acceleration_x' in df.columns:\n            df['accel_alignment'] = (\n                df['acceleration_x'] * df['ball_direction_x'] +\n                df['acceleration_y'] * df['ball_direction_y']\n            )\n\n    # é€Ÿåº¦å·®åˆ†ç‰¹å¾\n    if 'velocity_x' in df.columns:\n        df['velocity_x_change'] = df.groupby(gcols)['velocity_x'].diff().fillna(0)\n        df['velocity_y_change'] = df.groupby(gcols)['velocity_y'].diff().fillna(0)\n        df['speed_change'] = df.groupby(gcols)['s'].diff().fillna(0)\n        df['direction_change'] = df.groupby(gcols)['dir'].diff().fillna(0)\n        df['direction_change'] = df['direction_change'].apply(\n            lambda x: x if abs(x) < 180 else x - 360 * np.sign(x)\n        )\n\n    # åœºåœ°ä½ç½®ç‰¹å¾\n    df['dist_from_left'] = df['y']\n    df['dist_from_right'] = 53.3 - df['y']\n    df['dist_from_sideline'] = np.minimum(df['dist_from_left'], df['dist_from_right'])\n    df['dist_from_endzone'] = np.minimum(df['x'], 120 - df['x'])\n\n    # è§’è‰²ç‰¹å®šç‰¹å¾\n    if 'is_receiver' in df.columns and 'velocity_alignment' in df.columns:\n        df['receiver_optimality'] = df['is_receiver'] * df['velocity_alignment']\n        df['receiver_deviation'] = df['is_receiver'] * np.abs(df.get('velocity_perpendicular', 0))\n    if 'is_coverage' in df.columns and 'closing_speed' in df.columns:\n        df['defender_closing_speed'] = df['is_coverage'] * df['closing_speed']\n\n    # æ—¶é—´ç‰¹å¾\n    df['frames_elapsed'] = df.groupby(gcols).cumcount()\n    df['normalized_time'] = df.groupby(gcols)['frames_elapsed'].transform(\n        lambda x: x / (x.max() + 1)\n    )\n\n    # åŸºç¡€ç‰©ç†è¡ç”Ÿç‰¹å¾\n    df['speed_squared'] = df['s'] ** 2\n    df['accel_magnitude'] = np.sqrt(df['acceleration_x'] ** 2 + df['acceleration_y'] ** 2)\n    df['orientation_diff'] = np.abs(df['o'] - df['dir'])\n    df['orientation_diff'] = np.minimum(df['orientation_diff'], 360 - df['orientation_diff'])\n\n    if 'nearest_opp_dist' in df.columns:\n        df['pressure'] = 1 / np.maximum(df['nearest_opp_dist'], 0.5)\n        df['under_pressure'] = (df['nearest_opp_dist'] < 3).astype(int)\n        df['pressure_x_speed'] = df['pressure'] * df['s']\n\n    if 'mirror_wr_vx' in df.columns:\n        s_safe = np.maximum(df['s'], 0.1)\n        df['mirror_similarity'] = (\n                df['velocity_x'] * df['mirror_wr_vx'] +\n                df['velocity_y'] * df['mirror_wr_vy']\n        ) / s_safe\n        df['mirror_offset_dist'] = np.sqrt(\n            df['mirror_offset_x'] ** 2 + df['mirror_offset_y'] ** 2\n        )\n        df['mirror_alignment'] = df['mirror_similarity'] * df['is_coverage']\n\n    return df\n\n\ndef get_opponent_features(input_df):\n    \"\"\"\n    å¯¹æ‰‹äº¤äº’ç‰¹å¾ï¼šè®¡ç®—çƒå‘˜ä¸å¯¹æ‰‹ä¹‹é—´çš„ç©ºé—´å’Œè¿åŠ¨å…³ç³»\n    \"\"\"\n    features = []\n    \n    for (gid, pid), group in tqdm(input_df.groupby(['game_id', 'play_id']),\n                                desc=\"ğŸˆ Opponents\", leave=False):\n        last = group.sort_values('frame_id').groupby('nfl_id').last()\n\n        if len(last) < 2:\n            continue\n\n        positions = last[['x', 'y']].values\n        sides = last['player_side'].values\n        speeds = last['s'].values\n        directions = last['dir'].values\n        roles = last['player_role'].values\n\n        receiver_mask = np.isin(roles, ['Targeted Receiver', 'Other Route Runner'])\n\n        for i, (nid, side, role) in enumerate(zip(last.index, sides, roles)):\n            opp_mask = sides != side\n\n            feat = {\n                'game_id': gid, 'play_id': pid, 'nfl_id': nid,\n                'nearest_opp_dist': 50.0, 'closing_speed': 0.0,\n                'num_nearby_opp_3': 0, 'num_nearby_opp_5': 0,\n                'mirror_wr_vx': 0.0, 'mirror_wr_vy': 0.0,\n                'mirror_offset_x': 0.0, 'mirror_offset_y': 0.0,\n                'mirror_wr_dist': 50.0,\n            }\n\n            if not opp_mask.any():\n                features.append(feat)\n                continue\n\n            opp_positions = positions[opp_mask]\n            distances = np.sqrt(((positions[i] - opp_positions) ** 2).sum(axis=1))\n\n            if len(distances) == 0:\n                features.append(feat)\n                continue\n\n            nearest_idx = distances.argmin()\n            feat['nearest_opp_dist'] = distances[nearest_idx]\n            feat['num_nearby_opp_3'] = (distances < 3.0).sum()\n            feat['num_nearby_opp_5'] = (distances < 5.0).sum()\n\n            # è®¡ç®—ç›¸å¯¹é€Ÿåº¦\n            my_vx = speeds[i] * np.sin(np.deg2rad(directions[i]))\n            my_vy = speeds[i] * np.cos(np.deg2rad(directions[i]))\n            opp_speeds = speeds[opp_mask]\n            opp_dirs = directions[opp_mask]\n            opp_vx = opp_speeds[nearest_idx] * np.sin(np.deg2rad(opp_dirs[nearest_idx]))\n            opp_vy = opp_speeds[nearest_idx] * np.cos(np.deg2rad(opp_dirs[nearest_idx]))\n\n            rel_vx = my_vx - opp_vx\n            rel_vy = my_vy - opp_vy\n            to_me = positions[i] - opp_positions[nearest_idx]\n            to_me_norm = to_me / (np.linalg.norm(to_me) + 0.1)\n            feat['closing_speed'] = -(rel_vx * to_me_norm[0] + rel_vy * to_me_norm[1])\n\n            # é˜²å®ˆçƒå‘˜ä¸æ¥çƒæ‰‹çš„é•œåƒå…³ç³»\n            if role == 'Defensive Coverage' and receiver_mask.any():\n                rec_positions = positions[receiver_mask]\n                rec_distances = np.sqrt(((positions[i] - rec_positions) ** 2).sum(axis=1))\n\n                if len(rec_distances) > 0:\n                    closest_rec_idx = rec_distances.argmin()\n                    rec_indices = np.where(receiver_mask)[0]\n                    actual_rec_idx = rec_indices[closest_rec_idx]\n\n                    rec_vx = speeds[actual_rec_idx] * np.sin(np.deg2rad(directions[actual_rec_idx]))\n                    rec_vy = speeds[actual_rec_idx] * np.cos(np.deg2rad(directions[actual_rec_idx]))\n\n                    feat['mirror_wr_vx'] = rec_vx\n                    feat['mirror_wr_vy'] = rec_vy\n                    feat['mirror_wr_dist'] = rec_distances[closest_rec_idx]\n                    feat['mirror_offset_x'] = positions[i][0] - rec_positions[closest_rec_idx][0]\n                    feat['mirror_offset_y'] = positions[i][1] - rec_positions[closest_rec_idx][1]\n\n            features.append(feat)\n\n    return pd.DataFrame(features)\n\ndef create_multi_window_rolling_features(df):\n    \"\"\"å¤šçª—å£æ»šåŠ¨ç‰¹å¾ï¼ˆ3,5,10çª—å£çš„æ»šåŠ¨å¹³å‡å’Œæ ‡å‡†å·®ï¼‰\"\"\"\n    new_cols = []\n    gcols = ['game_id', 'play_id', 'nfl_id']\n    \n    for window in (3, 6, 9):\n        for col in ('velocity_x', 'velocity_y', 's', 'a'):\n            if col in df.columns:\n                r_mean = df.groupby(gcols)[col].rolling(window, min_periods=1).mean()\n                r_std = df.groupby(gcols)[col].rolling(window, min_periods=1).std()\n                # å¯¹é½ç´¢å¼•\n                r_mean = r_mean.reset_index(level=gcols, drop=True)\n                r_std = r_std.reset_index(level=gcols, drop=True)\n                df[f'{col}_roll{window}'] = r_mean\n                df[f'{col}_std{window}'] = r_std.fillna(0.0)\n                new_cols.extend([f'{col}_roll{window}', f'{col}_std{window}'])\n    return df, new_cols\n\ndef create_qb_relative_features(df):\n    \"\"\"å››åˆ†å«ç›¸å¯¹ç‰¹å¾ï¼ˆä¸å››åˆ†å«çš„è·ç¦»å’Œæ–¹å‘å…³ç³»ï¼‰\"\"\"\n    need = ['x', 'y', 'velocity_x', 'velocity_y', 'dir', 'player_role', 'frame_id']\n    for c in need:\n        if c not in df.columns:\n            return df, []  # ç¼ºåˆ—åˆ™å®‰å…¨è·³è¿‡\n    \n    out_cols = [\n        'qb_distance', 'vel_to_qb_alignment', 'vel_to_qb_perp',\n        'bearing_to_qb_signed', 'bearing_to_qb_sin', 'bearing_to_qb_cos'\n    ]\n    for c in out_cols:\n        if c not in df.columns:\n            df[c] = np.nan\n    \n    key = ['game_id', 'play_id', 'frame_id']\n    for _, g in df.groupby(key, sort=False):\n        idx = g.index.values\n        \n        # æ‰¾æœ¬å¸§ QB\n        qb_rows = g[g['player_role'] == 'Passer']\n        if qb_rows.empty:\n            continue\n        qb_x = float(qb_rows.iloc[0]['x'])\n        qb_y = float(qb_rows.iloc[0]['y'])\n    \n        dx = g['x'].values.astype('float32') - qb_x\n        dy = g['y'].values.astype('float32') - qb_y\n        dist = np.sqrt(dx * dx + dy * dy) + 1e-6\n        ux, uy = dx / dist, dy / dist  # QB->player å•ä½å‘é‡\n    \n        vx = g['velocity_x'].values.astype('float32')\n        vy = g['velocity_y'].values.astype('float32')\n    \n        align = vx * ux + vy * uy\n        perp = vx * (-uy) + vy * ux\n    \n        # bearing å·®\n        dir_rad = np.deg2rad(g['dir'].fillna(0.0).astype('float32').values)\n        to_qb_angle = np.arctan2(-dy, -dx)  # player->QB\n        bearing = np.rad2deg(np.arctan2(np.sin(to_qb_angle - dir_rad), np.cos(to_qb_angle - dir_rad)))\n    \n        df.loc[idx, 'qb_distance'] = dist\n        df.loc[idx, 'vel_to_qb_alignment'] = align\n        df.loc[idx, 'vel_to_qb_perp'] = perp\n        df.loc[idx, 'bearing_to_qb_signed'] = bearing\n        df.loc[idx, 'bearing_to_qb_sin'] = np.sin(np.deg2rad(bearing))\n        df.loc[idx, 'bearing_to_qb_cos'] = np.cos(np.deg2rad(bearing))\n    \n    return df, out_cols\n\ndef create_jerk_features(df):\n    \"\"\"æ€¥åŠ¨ç‰¹å¾ï¼ˆåŠ é€Ÿåº¦çš„å˜åŒ–ç‡ï¼‰\"\"\"\n    new_cols = []\n    gcols = ['game_id', 'play_id', 'nfl_id']\n    \n    if 'a' in df.columns:\n        df['jerk'] = df.groupby(gcols)['a'].diff().fillna(0.0) * 0.1  # å‡è®¾delta_t=0.1\n        new_cols.append('jerk')\n    \n    if {'acceleration_x', 'acceleration_y'}.issubset(df.columns):\n        df['jerk_x'] = df.groupby(gcols)['acceleration_x'].diff().fillna(0.0) * 0.1\n        df['jerk_y'] = df.groupby(gcols)['acceleration_y'].diff().fillna(0.0) * 0.1\n        new_cols.extend(['jerk_x', 'jerk_y'])\n    \n    return df, new_cols\n\ndef create_curvature_land_features(df):\n    \"\"\"è½ç‚¹æ›²ç‡ç‰¹å¾ï¼ˆä¾§å‘åå·®ã€è§’åº¦å·®ã€æ›²ç‡ï¼‰\"\"\"\n    import numpy as np\n    new_cols = []\n    \n    if {'ball_land_x', 'ball_land_y'}.issubset(df.columns):\n        # ä¾§å‘åå·®å’Œbearing_to_land\n        dx = df['ball_land_x'] - df['x']\n        dy = df['ball_land_y'] - df['y']\n        bearing = np.arctan2(dy, dx)\n        a_dir = np.deg2rad(df['dir'].fillna(0.0).values)\n        # æœ‰ç¬¦å·æ–¹ä½å·®\n        df['bearing_to_land_signed'] = np.rad2deg(np.arctan2(np.sin(bearing - a_dir), np.cos(bearing - a_dir)))\n        # ä¾§å‘åå·®\n        ux, uy = np.cos(a_dir), np.sin(a_dir)\n        df['land_lateral_offset'] = dy * ux - dx * uy  # >0 è½ç‚¹åœ¨å·¦ä¾§\n    \n    # æ›²ç‡\n    ddir = df.groupby(['game_id', 'play_id', 'nfl_id'])['dir'].diff().fillna(0.0)\n    ddir = ((ddir + 180.0) % 360.0) - 180.0\n    curvature = np.deg2rad(ddir).astype('float32') / (df['s'].replace(0, np.nan).astype('float32') * 0.1 + 1e-6)\n    df['curvature_signed'] = curvature.fillna(0.0)\n    df['curvature_abs'] = df['curvature_signed'].abs()\n    \n    # çª—å£å‡å€¼\n    for w in (3, 5):\n        if 'curvature_signed' in df.columns:\n            r = df.groupby(['game_id', 'play_id', 'nfl_id'])['curvature_signed'].rolling(w, min_periods=1).mean().reset_index(level=['game_id', 'play_id', 'nfl_id'], drop=True)\n            df[f'curv_signed_roll{w}'] = r\n        if 'curvature_abs' in df.columns:\n            r2 = df.groupby(['game_id', 'play_id', 'nfl_id'])['curvature_abs'].rolling(w, min_periods=1).mean().reset_index(level=['game_id', 'play_id', 'nfl_id'], drop=True)\n            df[f'curv_abs_roll{w}'] = r2\n    \n    new_cols.extend([\n        'bearing_to_land_signed', 'land_lateral_offset',\n        'curvature_signed', 'curvature_abs',\n        'curv_signed_roll3', 'curv_abs_roll3',\n        'curv_signed_roll5', 'curv_abs_roll5'\n    ])\n    \n    return df, [c for c in new_cols if c in df.columns]\n\ndef get_feature_columns(df):\n    \"\"\"\n    è·å–ç‰¹å¾åˆ—åˆ—è¡¨ï¼ˆåŒ…å«æ‰€æœ‰ç‰¹å¾ï¼‰\n    \"\"\"\n    base_feature_cols = [\n        'x', 'y', 's', 'a', 'o', 'dir', 'frame_id',\n        'ball_land_x', 'ball_land_y',\n        'player_height_feet', 'player_weight',\n        'velocity_x', 'velocity_y', 'acceleration_x', 'acceleration_y',\n        'momentum_x', 'momentum_y', 'kinetic_energy',\n        'is_offense', 'is_defense', 'is_receiver', 'is_coverage', 'is_passer',\n        'distance_to_ball', 'angle_to_ball', 'ball_direction_x', 'ball_direction_y', 'closing_speed',\n        'x_lag1', 'y_lag1', 'velocity_x_lag1', 'velocity_y_lag1',\n        'x_lag2', 'y_lag2', 'velocity_x_lag2', 'velocity_y_lag2',\n        'x_lag3', 'y_lag3', 'velocity_x_lag3', 'velocity_y_lag3',\n        'x_lag4', 'y_lag4', 'velocity_x_lag4', 'velocity_y_lag4',\n        'x_lag5', 'y_lag5', 'velocity_x_lag5', 'velocity_y_lag5',\n        'velocity_x_ema', 'velocity_y_ema', 'speed_ema',\n        'velocity_x_roll', 'velocity_y_roll',\n\n        'distance_to_ball_change', 'distance_to_ball_accel', 'time_to_intercept',\n        'velocity_alignment', 'velocity_perpendicular', 'accel_alignment',\n        'velocity_x_change', 'velocity_y_change', 'speed_change', 'direction_change',\n        'dist_from_sideline', 'dist_from_endzone',\n        'receiver_optimality', 'receiver_deviation', 'defender_closing_speed',\n        'frames_elapsed', 'normalized_time', 'velocity_x_delta', 'velocity_y_delta',\n\n        # æ·»åŠ å¯¹æ‰‹äº¤äº’ç‰¹å¾\n        'nearest_opp_dist', 'closing_speed', 'num_nearby_opp_3', 'num_nearby_opp_5',\n        'mirror_wr_vx', 'mirror_wr_vy', 'mirror_offset_x', 'mirror_offset_y', 'mirror_wr_dist',\n        'pressure', 'under_pressure', 'pressure_x_speed',\n        'mirror_similarity', 'mirror_offset_dist', 'mirror_alignment'\n\n        # 'velocity_x_roll3', 'velocity_x_roll6', 'velocity_x_roll9', 'velocity_x_std3', 'velocity_x_std6', 'velocity_x_std9'\n        # 'velocity_y_roll3', 'velocity_y_roll6', 'velocity_y_roll9', 'velocity_y_std3', 'velocity_y_std6', 'velocity_y_std9',\n        # 's_roll3', 's_roll6', 's_roll9', 's_std3', 's_std6', 's_std9'\n        # 'a_roll3', 'a_roll6', 'a_roll9', 'a_std3', 'a_std6', 'a_std9'\n        # 'qb_distance', 'vel_to_qb_alignment', 'vel_to_qb_perp',\n        # 'bearing_to_qb_signed', 'bearing_to_qb_sin', 'bearing_to_qb_cos'\n                # æ€¥åŠ¨ç‰¹å¾\n        # 'jerk', 'jerk_x', 'jerk_y',\n        \n        # # è½ç‚¹æ›²ç‡ç‰¹å¾\n        # 'bearing_to_land_signed', 'land_lateral_offset', 'curvature_signed', 'curvature_abs',\n        # 'curv_signed_roll3', 'curv_abs_roll3', 'curv_signed_roll5', 'curv_abs_roll5',\n    ]\n    \n    # åˆå¹¶æ‰€æœ‰ç‰¹å¾åˆ—ï¼Œåªè¿”å›æ•°æ®é›†ä¸­å­˜åœ¨çš„\n    all_feature_cols = base_feature_cols\n    return [c for c in all_feature_cols if c in df.columns]\n\n\n# ============================================================================\n# MAIN SEQUENCE PREPARATION FUNCTION\n# ============================================================================\n# ============================================================================\n# æ–¹å‘ç»Ÿä¸€å·¥å…·å‡½æ•°ï¼ˆä¸è®­ç»ƒä¸€è‡´ï¼‰\n# ============================================================================\n\nYARDS_TO_METERS = 0.9144\nFPS = 10.0 \nFIELD_LENGTH, FIELD_WIDTH = 120.0, 53.3\n\ndef wrap_angle_deg(s):\n    # map to (-180, 180]\n    return ((s + 180.0) % 360.0) - 180.0\n\ndef unify_left_direction(df: pd.DataFrame) -> pd.DataFrame:\n    \"\"\"Mirror rightward plays so all samples are 'left' oriented (x,y, dir, o, ball_land).\"\"\"\n    if 'play_direction' not in df.columns:\n        return df\n    df = df.copy()\n    right = df['play_direction'].eq('right')\n    # positions\n    if 'x' in df.columns: df.loc[right, 'x'] = FIELD_LENGTH - df.loc[right, 'x']\n    if 'y' in df.columns: df.loc[right, 'y'] = FIELD_WIDTH  - df.loc[right, 'y']\n    # angles in degrees\n    for col in ('dir','o'):\n        if col in df.columns:\n            df.loc[right, col] = (df.loc[right, col] + 180.0) % 360.0\n    # ball landing\n    if 'ball_land_x' in df.columns:\n        df.loc[right, 'ball_land_x'] = FIELD_LENGTH - df.loc[right, 'ball_land_x']\n    if 'ball_land_y' in df.columns:\n        df.loc[right, 'ball_land_y'] = FIELD_WIDTH  - df.loc[right, 'ball_land_y']\n    return df\n\ndef build_play_direction_map(df_in: pd.DataFrame) -> pd.Series:\n    \"\"\"\n    Return a Series indexed by (game_id, play_id) with values 'left'/'right'.\n    \"\"\"\n    s = (\n        df_in[['game_id','play_id','play_direction']]\n        .drop_duplicates()\n        .set_index(['game_id','play_id'])['play_direction']\n    )\n    return s\n\ndef apply_direction_to_df(df: pd.DataFrame, dir_map: pd.Series) -> pd.DataFrame:\n    \"\"\"\n    Attach play_direction (if missing) and then unify to 'left'.\n    \"\"\"\n    if 'play_direction' not in df.columns:\n        dir_df = dir_map.reset_index()  # -> columns: game_id, play_id, play_direction\n        df = df.merge(dir_df, on=['game_id','play_id'], how='left', validate='many_to_one')\n    return unify_left_direction(df)\n\ndef invert_to_original_direction(x_u, y_u, play_dir_right: bool):\n    \"\"\"Invert unified (left) coordinates back to original play direction.\"\"\"\n    if not play_dir_right:\n        return float(x_u), float(y_u)\n    return float(FIELD_LENGTH - x_u), float(FIELD_WIDTH - y_u)\n\n# ============================================================================\n# ä¿®æ”¹åçš„ MAIN SEQUENCE PREPARATION FUNCTIONï¼ˆåŒ…å«æ–¹å‘ç»Ÿä¸€ï¼‰\n# ============================================================================\n\ndef prepare_sequences_fixed(input_df, output_df=None, test_template=None, is_training=True, window_size=Config.WINDOW_SIZE):\n    \"\"\"\n    å‡†å¤‡åºåˆ—æ•°æ®çš„ä¸»å‡½æ•°ï¼ˆåŒ…å«æ–¹å‘ç»Ÿä¸€å’Œæ‰€æœ‰ç‰¹å¾å·¥ç¨‹ï¼‰\n    \"\"\"\n    # ===== 1. æ–¹å‘ç»Ÿä¸€å¤„ç† =====\n    print(\"åº”ç”¨æ–¹å‘ç»Ÿä¸€...\")\n    dir_map = build_play_direction_map(input_df)\n    \n    # ç»Ÿä¸€è¾“å…¥æ•°æ®æ–¹å‘\n    input_df_u = apply_direction_to_df(input_df, dir_map)\n    \n    if is_training:\n        # ç»Ÿä¸€è¾“å‡ºæ•°æ®æ–¹å‘\n        out_u = apply_direction_to_df(output_df, dir_map)\n        target_rows = out_u\n        target_groups = out_u[['game_id','play_id','nfl_id']].drop_duplicates()\n    else:\n        # ç¡®ä¿æµ‹è¯•æ¨¡æ¿æœ‰play_direction\n        if 'play_direction' not in test_template.columns:\n            dir_df = dir_map.reset_index()\n            test_template = test_template.merge(dir_df, on=['game_id','play_id'], how='left', validate='many_to_one')\n        target_rows = test_template\n        target_groups = target_rows[['game_id','play_id','nfl_id']].drop_duplicates()\n    \n    # éªŒè¯æ–¹å‘ç»Ÿä¸€æ˜¯å¦æˆåŠŸ\n    assert target_rows[['game_id','play_id','play_direction']].isna().sum().sum() == 0, \\\n        \"play_direction merge failed; check (game_id, play_id) coverage\"\n    print(\"æ–¹å‘ç»Ÿä¸€å®Œæˆ:\", target_rows['play_direction'].value_counts(dropna=False).to_dict())\n    \n    # ===== 2. ç‰¹å¾å·¥ç¨‹ =====\n    print(\"å¼€å§‹ç‰¹å¾å·¥ç¨‹...\")\n    input_df_u = create_base_features(input_df_u)\n    input_df_u = create_lag_features(input_df_u, window_size)\n    opponent_features = get_opponent_features(input_df_u)\n    input_df_u = input_df_u.merge(opponent_features, on=['game_id', 'play_id', 'nfl_id'], how='left')\n    input_df_u = add_advanced_features(input_df_u)\n    \n    # è·å–ç‰¹å¾åˆ—\n    feature_cols = get_feature_columns(input_df_u)\n    print(f\"ä½¿ç”¨ {len(feature_cols)} ä¸ªç‰¹å¾\" + (\" (è®­ç»ƒ)\" if is_training else \"\"))\n    \n    # è®¾ç½®ç´¢å¼•ç”¨äºåˆ†ç»„æ“ä½œ\n    input_df_u.set_index(['game_id', 'play_id', 'nfl_id'], inplace=True)\n    grouped = input_df_u.groupby(level=['game_id', 'play_id', 'nfl_id'])\n    \n    if is_training:\n        sequences, targets_dx, targets_dy, targets_frame_ids, sequence_ids = [], [], [], [], []\n        \n        for _, row in tqdm(target_groups.iterrows(), desc=\"å¤„ç†è®­ç»ƒåºåˆ—\"):\n            key = (row['game_id'], row['play_id'], row['nfl_id'])\n            try:\n                group_df = grouped.get_group(key)\n            except KeyError:\n                continue\n            \n            # åˆ›å»ºè¾“å…¥çª—å£\n            input_window = group_df.tail(window_size)\n            if len(input_window) < window_size:\n                continue  # è®­ç»ƒæ—¶è·³è¿‡é•¿åº¦ä¸è¶³çš„åºåˆ—\n            \n            # å¡«å……ç¼ºå¤±å€¼\n            input_window = input_window.fillna(group_df.mean(numeric_only=True))\n            seq = input_window[feature_cols].values\n            \n            # å¤„ç†NaNå€¼\n            if np.isnan(seq).any():\n                continue  # è®­ç»ƒæ—¶è·³è¿‡æœ‰NaNçš„åºåˆ—\n            \n            sequences.append(seq)\n            \n            # è·å–å¯¹åº”çš„ç›®æ ‡å€¼ï¼ˆæ³¨æ„ï¼šç›®æ ‡å€¼å·²ç»æ˜¯ç»Ÿä¸€æ–¹å‘åçš„ï¼‰\n            out_grp = target_rows[\n                (target_rows['game_id'] == row['game_id']) &\n                (target_rows['play_id'] == row['play_id']) &\n                (target_rows['nfl_id'] == row['nfl_id'])\n            ].sort_values('frame_id')\n            \n            last_x = input_window.iloc[-1]['x']\n            last_y = input_window.iloc[-1]['y']\n            dx = out_grp['x'].values - last_x\n            dy = out_grp['y'].values - last_y\n            targets_dx.append(dx)\n            targets_dy.append(dy)\n            targets_frame_ids.append(out_grp['frame_id'].values)\n            \n            sequence_ids.append({\n                'game_id': key[0],\n                'play_id': key[1],\n                'nfl_id': key[2],\n                'frame_id': input_window.iloc[-1]['frame_id'],\n                'play_direction': input_window.iloc[-1]['play_direction']  # ä¿å­˜æ–¹å‘ä¿¡æ¯ç”¨äºæ¨ç†æ—¶è¿˜åŸ\n            })\n        \n        return sequences, targets_dx, targets_dy, targets_frame_ids, sequence_ids\n    \n    else:\n        # æ¨ç†æ¨¡å¼\n        sequences, sequence_ids = [], []\n        \n        for _, row in tqdm(target_groups.iterrows(), desc=\"å¤„ç†æ¨ç†åºåˆ—\"):\n            key = (row['game_id'], row['play_id'], row['nfl_id'])\n            try:\n                group_df = grouped.get_group(key)\n            except KeyError:\n                continue\n            \n            # åˆ›å»ºè¾“å…¥çª—å£\n            input_window = group_df.tail(window_size)\n            if len(input_window) < window_size:\n                pad_len = window_size - len(input_window)\n                pad_df = pd.DataFrame(np.nan, index=range(pad_len), columns=input_window.columns)\n                input_window = pd.concat([pad_df, input_window], ignore_index=True)\n            \n            # å¡«å……ç¼ºå¤±å€¼\n            input_window = input_window.fillna(group_df.mean(numeric_only=True))\n            seq = input_window[feature_cols].values\n            \n            # å¤„ç†NaNå€¼\n            if np.isnan(seq).any():\n                seq = np.nan_to_num(seq, nan=0.0)\n            \n            sequences.append(seq)\n            sequence_ids.append({\n                'game_id': key[0],\n                'play_id': key[1],\n                'nfl_id': key[2],\n                'frame_id': input_window.iloc[-1]['frame_id'],\n                'play_direction': input_window.iloc[-1]['play_direction'],  # ä¿å­˜æ–¹å‘ä¿¡æ¯\n                'last_x': input_window.iloc[-1]['x'],  # ä¿å­˜æœ€åä½ç½®ç”¨äºæ¨ç†æ—¶è¿˜åŸ\n                'last_y': input_window.iloc[-1]['y']\n            })\n        \n        return sequences, sequence_ids","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-01T07:26:51.166285Z","iopub.execute_input":"2025-11-01T07:26:51.166741Z","iopub.status.idle":"2025-11-01T07:26:51.369562Z","shell.execute_reply.started":"2025-11-01T07:26:51.166717Z","shell.execute_reply":"2025-11-01T07:26:51.368647Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ============================================================================\n# MODELï¼ˆä¸è®­ç»ƒä¸€è‡´ï¼Œå®šä¹‰åœ¨å‡½æ•°å¤–ä½†ä»£ç å®Œæ•´ï¼‰\n# ============================================================================\n\nclass ImprovedSeqModel(nn.Module):\n    def __init__(self, input_dim, horizon):\n        super().__init__()\n        self.horizon = horizon\n        self.gru = nn.GRU(input_dim, 128, num_layers=2, batch_first=True, dropout=0.1)\n        self.pool_ln = nn.LayerNorm(128)\n        self.pool_attn = nn.MultiheadAttention(128, num_heads=4, batch_first=True)\n        self.pool_query = nn.Parameter(torch.randn(1, 1, 128))\n        self.head = nn.Sequential(\n            nn.Linear(128, 128),\n            nn.GELU(),\n            nn.Dropout(0.2),\n            nn.Linear(128, horizon)\n        )\n    \n    def forward(self, x):\n        h, _ = self.gru(x)\n        B = h.size(0)\n        q = self.pool_query.expand(B, -1, -1)\n        h_norm = self.pool_ln(h)\n        ctx, _ = self.pool_attn(q, h_norm, h_norm)\n        ctx = ctx.squeeze(1)\n        out = self.head(ctx)\n        out = torch.cumsum(out, dim=1)\n        return out\n\n# ============================================================================\n# INFERENCE æ ¸å¿ƒï¼špredictå‡½æ•°ï¼ˆç‹¬ç«‹è¿è¡Œï¼Œä¸ä¾èµ–å¤–éƒ¨çŠ¶æ€ï¼‰\n# ============================================================================\n\n# ============================================================================\n# INFERENCE æ ¸å¿ƒï¼šä¿®æ”¹åçš„predictå‡½æ•°ï¼ˆåŒ…å«æ–¹å‘è¿˜åŸï¼‰\n# ============================================================================\n\ndef predict(test: pl.DataFrame, test_input: pl.DataFrame) -> pl.DataFrame:\n    # ===== 1. å‡†å¤‡æ•°æ® =====\n    test_pd = test.to_pandas()\n    test_input_pd = test_input.to_pandas()\n    \n    # ===== 2. ç‰¹å¾å·¥ç¨‹ï¼ˆåŒ…å«æ–¹å‘ç»Ÿä¸€ï¼‰=====\n    sequences, sequence_ids = prepare_sequences_fixed(\n        test_input_pd, test_template=test_pd, is_training=False, window_size=Config.WINDOW_SIZE\n    )\n    \n    if not sequences:\n        return pl.DataFrame({\"x\": [], \"y\": []})\n    \n    X_test = np.array(sequences, dtype=object)\n    \n    # ä¿å­˜ç»Ÿä¸€æ–¹å‘åçš„æœ€åä½ç½®\n    x_last_u = np.array([s[-1, 0] for s in X_test])  # ç»Ÿä¸€æ–¹å‘åçš„x\n    y_last_u = np.array([s[-1, 1] for s in X_test])  # ç»Ÿä¸€æ–¹å‘åçš„y\n    \n    # ===== 3. åŠ è½½æ¨¡å‹ & Scaler =====\n    MODEL_DIR = Path(\"/kaggle/input/1101adddirec/pytorch/default/1/adddirec\")  # æ ¹æ®å®é™…è·¯å¾„ä¿®æ”¹\n    \n    model_x_paths = [\n        MODEL_DIR / f\"model_x_fold{i+1}.pth\" for i in range(Config.N_FOLDS)\n    ]\n    model_y_paths = [\n        MODEL_DIR / f\"model_y_fold{i+1}.pth\" for i in range(Config.N_FOLDS)\n    ]\n    scaler_paths = [\n        MODEL_DIR / f\"scaler_fold{i+1}.pkl\" for i in range(Config.N_FOLDS)\n    ]\n    \n    # æ£€æŸ¥è·¯å¾„æ˜¯å¦å­˜åœ¨\n    for p in model_x_paths + model_y_paths + scaler_paths:\n        if not p.exists():\n            raise FileNotFoundError(f\"è¯·ä¸Šä¼ æ¨¡å‹æ–‡ä»¶ï¼Œç¼ºå¤±: {p.name}\")\n\n    models_x = []\n    models_y = []\n    scalers = []\n    \n    for i in range(Config.N_FOLDS):\n        # æ¨¡å‹X\n        model_x = ImprovedSeqModel(input_dim=X_test[0].shape[1], horizon=Config.MAX_FUTURE_HORIZON).to(Config.DEVICE)\n        model_x.load_state_dict(torch.load(model_x_paths[i], map_location=Config.DEVICE))\n        model_x.eval()\n        models_x.append(model_x)\n        \n        # æ¨¡å‹Y\n        model_y = ImprovedSeqModel(input_dim=X_test[0].shape[1], horizon=Config.MAX_FUTURE_HORIZON).to(Config.DEVICE)\n        model_y.load_state_dict(torch.load(model_y_paths[i], map_location=Config.DEVICE))\n        model_y.eval()\n        models_y.append(model_y)\n        \n        # Scaler\n        scaler = joblib.load(scaler_paths[i])\n        scalers.append(scaler)\n    \n    # ===== 4. é¢„æµ‹ï¼ˆåœ¨ç»Ÿä¸€æ–¹å‘åæ ‡ç³»ä¸­ï¼‰ =====\n    all_dx, all_dy = [], []\n    for mx, my, sc in zip(models_x, models_y, scalers):\n        X_scaled = np.stack([sc.transform(s) for s in X_test])\n        X_tensor = torch.tensor(X_scaled.astype(np.float32)).to(Config.DEVICE)\n        \n        mx.eval()\n        my.eval()\n        with torch.no_grad():\n            dx = mx(X_tensor).cpu().numpy()  # ç»Ÿä¸€æ–¹å‘åæ ‡ç³»ä¸­çš„dx\n            dy = my(X_tensor).cpu().numpy()  # ç»Ÿä¸€æ–¹å‘åæ ‡ç³»ä¸­çš„dy\n        all_dx.append(dx)\n        all_dy.append(dy)\n    \n    ens_dx = np.mean(all_dx, axis=0)\n    ens_dy = np.mean(all_dy, axis=0)\n    \n    # ===== 5. æ–¹å‘è¿˜åŸ + æ„é€ æäº¤ç»“æœ =====\n    rows = []\n    H = ens_dx.shape[1]  # é¢„æµ‹æ­¥æ•°\n    \n    for i, sid in enumerate(sequence_ids):\n        # è·å–è¯¥åºåˆ—å¯¹åº”çš„æ‰€æœ‰frame_id\n        fids = test_pd[\n            (test_pd['game_id'] == sid['game_id']) &\n            (test_pd['play_id'] == sid['play_id']) &\n            (test_pd['nfl_id'] == sid['nfl_id'])\n        ]['frame_id'].sort_values().tolist()\n        \n        play_dir_right = (sid['play_direction'] == 'right')\n        \n        for t, fid in enumerate(fids):\n            tt = min(t, H - 1)\n            \n            # åœ¨ç»Ÿä¸€æ–¹å‘åæ ‡ç³»ä¸­çš„ç»å¯¹ä½ç½®\n            x_u = np.clip(x_last_u[i] + ens_dx[i, tt], 0, 120)\n            y_u = np.clip(y_last_u[i] + ens_dy[i, tt], 0, 53.3)\n            \n            # è½¬æ¢å›åŸå§‹æ–¹å‘åæ ‡ç³»\n            x_orig, y_orig = invert_to_original_direction(x_u, y_u, play_dir_right)\n            \n            # ç¡®ä¿åœ¨åœºåœ°èŒƒå›´å†…\n            x_orig = np.clip(x_orig, 0, 120)\n            y_orig = np.clip(y_orig, 0, 53.3)\n            \n            rows.append({\n                'x': float(x_orig),\n                'y': float(y_orig)\n            })\n    \n    return pl.DataFrame(rows)\n\n# ============================================================================\n# Kaggle æ¨ç†æœåŠ¡å™¨ï¼ˆä¿æŒä¸å˜ï¼‰\n# ============================================================================\n\n# ç¡®ä¿å¯¼å…¥å®˜æ–¹è¯„ä¼°åº“\ntry:\n    from kaggle_evaluation.nfl_inference_server import NFLInferenceServer\nexcept ImportError as e:\n    raise ImportError(\"è¯·ç¡®ä¿ä½¿ç”¨ Kaggle çš„ NFL Inference è¯„æµ‹å†…æ ¸\")\n\n# åˆ›å»ºæ¨ç†æœåŠ¡å™¨å¹¶è¿è¡Œ\ninference_server = NFLInferenceServer(predict)\n\nif os.getenv('KAGGLE_IS_COMPETITION_RERUN'):\n    inference_server.serve()\nelse:\n    inference_server.run_local_gateway(('/kaggle/input/nfl-big-data-bowl-2026-prediction/',))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-01T07:27:08.59885Z","iopub.execute_input":"2025-11-01T07:27:08.599174Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}