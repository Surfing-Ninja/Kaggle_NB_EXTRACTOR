{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":114239,"databundleVersionId":13825858,"sourceType":"competition"}],"dockerImageVersionId":31153,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"\"\"\"\nNFL Big Data Bowl 2026 - Elite Solution\nAdvanced multi-model ensemble with player interactions\nTarget: RMSE < 0.55 (Top 5%)\n\"\"\"\n\nimport pandas as pd\nimport numpy as np\nimport lightgbm as lgb\nimport xgboost as xgb\nfrom catboost import CatBoostRegressor, Pool\nimport warnings\nimport glob\nimport gc\nfrom sklearn.model_selection import KFold\nfrom sklearn.metrics import mean_squared_error\nfrom scipy.spatial.distance import cdist\nfrom tqdm import tqdm\n\nwarnings.filterwarnings('ignore')\npd.set_option('display.max_columns', None)\n\nRANDOM_SEED = 42\nnp.random.seed(RANDOM_SEED)\n\nDATA_PATH = '/kaggle/input/nfl-big-data-bowl-2026-prediction/train'\nTEST_INPUT_PATH = '/kaggle/input/nfl-big-data-bowl-2026-prediction/test_input.csv'\nSAMPLE_SUB_PATH = '/kaggle/input/nfl-big-data-bowl-2026-prediction/sample_submission.csv'\n\nprint(\"Elite Pipeline Initialized\")\nprint(f\"Target RMSE: < 0.55\")\nprint(\"=\"*80)\n\n# =============================================================================\n# ADVANCED DATA LOADING WITH SAMPLING\n# =============================================================================\n\ndef load_data_efficient(sample_weeks=None):\n    \"\"\"Load data with optional week sampling for speed\"\"\"\n    print(\"\\nLoading training data...\")\n    \n    input_files = sorted(glob.glob(f\"{DATA_PATH}/input_2023_w*.csv\"))\n    output_files = sorted(glob.glob(f\"{DATA_PATH}/output_2023_w*.csv\"))\n    \n    if sample_weeks:\n        input_files = input_files[:sample_weeks]\n        output_files = output_files[:sample_weeks]\n    \n    print(f\"Loading {len(input_files)} weeks of data\")\n    \n    input_dfs = []\n    for file in tqdm(input_files, desc=\"Inputs\"):\n        week = int(file.split('_w')[-1].split('.')[0])\n        df = pd.read_csv(file)\n        df['week'] = week\n        input_dfs.append(df)\n    \n    all_inputs = pd.concat(input_dfs, ignore_index=True)\n    \n    output_dfs = []\n    for file in tqdm(output_files, desc=\"Outputs\"):\n        week = int(file.split('_w')[-1].split('.')[0])\n        df = pd.read_csv(file)\n        df['week'] = week\n        output_dfs.append(df)\n    \n    all_outputs = pd.concat(output_dfs, ignore_index=True)\n    \n    print(f\"Loaded {len(all_inputs):,} input records\")\n    print(f\"Loaded {len(all_outputs):,} output records\")\n    \n    return all_inputs, all_outputs\n\n# =============================================================================\n# ELITE FEATURE ENGINEERING WITH PLAYER INTERACTIONS\n# =============================================================================\n\ndef create_elite_features(df):\n    \"\"\"Elite feature engineering with player interactions\"\"\"\n    df = df.copy()\n    \n    print(\"Creating elite features...\")\n    \n    # Basic features\n    df['dist_to_ball'] = np.sqrt(\n        (df['x'] - df['ball_land_x'])**2 + \n        (df['y'] - df['ball_land_y'])**2\n    )\n    df['angle_to_ball'] = np.arctan2(\n        df['ball_land_y'] - df['y'],\n        df['ball_land_x'] - df['x']\n    )\n    df['speed_to_ball'] = df['s'] * np.cos(np.radians(df['dir']) - df['angle_to_ball'])\n    \n    df['delta_x'] = df['ball_land_x'] - df['x']\n    df['delta_y'] = df['ball_land_y'] - df['y']\n    \n    # Velocity components\n    df['vx'] = df['s'] * np.cos(np.radians(df['dir']))\n    df['vy'] = df['s'] * np.sin(np.radians(df['dir']))\n    df['ax'] = df['a'] * np.cos(np.radians(df['dir']))\n    df['ay'] = df['a'] * np.sin(np.radians(df['dir']))\n    \n    # Role encoding\n    role_map = {'Targeted Receiver': 4, 'Defensive Coverage': 3, \n                'Other Route Runner': 2, 'Passer': 1}\n    df['role_enc'] = df['player_role'].map(role_map).fillna(0)\n    df['is_target'] = (df['player_role'] == 'Targeted Receiver').astype(int)\n    df['is_defender'] = (df['player_role'] == 'Defensive Coverage').astype(int)\n    df['is_offense'] = (df['player_side'] == 'Offense').astype(int)\n    \n    # Field features\n    df['dist_sideline'] = np.minimum(df['y'], 53.3 - df['y'])\n    df['dist_endzone'] = np.minimum(df['x'], 120 - df['x'])\n    \n    # Physics\n    df['time_to_ball'] = df['dist_to_ball'] / (df['s'] + 0.1)\n    df['speed_sq'] = df['s'] ** 2\n    df['orientation_diff'] = np.abs(df['o'] - df['dir'])\n    df['orientation_diff'] = np.where(\n        df['orientation_diff'] > 180, \n        360 - df['orientation_diff'], \n        df['orientation_diff']\n    )\n    \n    return df\n\ndef add_player_interactions(df):\n    \"\"\"Add critical player interaction features\"\"\"\n    print(\"Adding player interactions (this takes time)...\")\n    \n    interaction_features = []\n    \n    for (game_id, play_id), play_df in tqdm(df.groupby(['game_id', 'play_id'])):\n        play_features = play_df.copy()\n        \n        # Get player positions\n        positions = play_df[['x', 'y']].values\n        roles = play_df['player_role'].values\n        \n        # Calculate all pairwise distances efficiently\n        distances = cdist(positions, positions, metric='euclidean')\n        \n        # For each player\n        for idx, (_, player) in enumerate(play_df.iterrows()):\n            player_dists = distances[idx]\n            \n            # Distance to targeted receiver\n            target_mask = roles == 'Targeted Receiver'\n            if target_mask.any():\n                play_features.loc[play_features.index[idx], 'dist_to_target'] = player_dists[target_mask].min()\n            else:\n                play_features.loc[play_features.index[idx], 'dist_to_target'] = 0\n            \n            # Nearest defender\n            defender_mask = roles == 'Defensive Coverage'\n            if defender_mask.any() and player['player_role'] != 'Defensive Coverage':\n                play_features.loc[play_features.index[idx], 'nearest_defender'] = player_dists[defender_mask].min()\n                play_features.loc[play_features.index[idx], 'defenders_nearby'] = (player_dists[defender_mask] < 5).sum()\n            else:\n                play_features.loc[play_features.index[idx], 'nearest_defender'] = 0\n                play_features.loc[play_features.index[idx], 'defenders_nearby'] = 0\n            \n            # Average distance to all players\n            play_features.loc[play_features.index[idx], 'avg_player_dist'] = player_dists[player_dists > 0].mean()\n        \n        interaction_features.append(play_features)\n    \n    result = pd.concat(interaction_features, ignore_index=True)\n    print(\"Player interactions added\")\n    return result\n\n# =============================================================================\n# MULTI-MODEL TRAINING\n# =============================================================================\n\ndef train_lgb(X_train, y_train, X_val, y_val):\n    \"\"\"Train LightGBM with optimal parameters\"\"\"\n    params = {\n        'objective': 'regression',\n        'metric': 'rmse',\n        'boosting_type': 'gbdt',\n        'num_leaves': 150,\n        'learning_rate': 0.015,\n        'feature_fraction': 0.8,\n        'bagging_fraction': 0.8,\n        'bagging_freq': 5,\n        'max_depth': 12,\n        'min_child_samples': 20,\n        'reg_alpha': 0.1,\n        'reg_lambda': 0.1,\n        'verbose': -1,\n        'device': 'gpu',\n        'gpu_platform_id': 0,\n        'gpu_device_id': 0,\n    }\n    \n    lgb_train = lgb.Dataset(X_train, y_train)\n    lgb_val = lgb.Dataset(X_val, y_val, reference=lgb_train)\n    \n    model = lgb.train(\n        params, lgb_train,\n        num_boost_round=2000,\n        valid_sets=[lgb_val],\n        callbacks=[\n            lgb.early_stopping(stopping_rounds=100),\n            lgb.log_evaluation(period=200)\n        ]\n    )\n    \n    return model\n\ndef train_xgb(X_train, y_train, X_val, y_val):\n    \"\"\"Train XGBoost\"\"\"\n    params = {\n        'objective': 'reg:squarederror',\n        'eval_metric': 'rmse',\n        'max_depth': 10,\n        'learning_rate': 0.02,\n        'subsample': 0.8,\n        'colsample_bytree': 0.8,\n        'min_child_weight': 3,\n        'gamma': 0.1,\n        'reg_alpha': 0.1,\n        'reg_lambda': 0.1,\n        'tree_method': 'gpu_hist',\n        'gpu_id': 0,\n    }\n    \n    dtrain = xgb.DMatrix(X_train, label=y_train)\n    dval = xgb.DMatrix(X_val, label=y_val)\n    \n    model = xgb.train(\n        params, dtrain,\n        num_boost_round=2000,\n        evals=[(dval, 'valid')],\n        early_stopping_rounds=100,\n        verbose_eval=200\n    )\n    \n    return model\n\ndef train_catboost(X_train, y_train, X_val, y_val):\n    \"\"\"Train CatBoost\"\"\"\n    model = CatBoostRegressor(\n        iterations=2000,\n        learning_rate=0.02,\n        depth=10,\n        loss_function='RMSE',\n        eval_metric='RMSE',\n        task_type='GPU',\n        devices='0',\n        verbose=200,\n        early_stopping_rounds=100\n    )\n    \n    model.fit(\n        X_train, y_train,\n        eval_set=(X_val, y_val),\n        use_best_model=True\n    )\n    \n    return model\n\ndef train_ensemble(X_train, X_val, y_x_train, y_x_val, y_y_train, y_y_val):\n    \"\"\"Train ensemble of models\"\"\"\n    print(\"\\n\" + \"=\"*80)\n    print(\"TRAINING ELITE ENSEMBLE\")\n    print(\"=\"*80)\n    \n    models = {}\n    \n    # Train X coordinate models\n    print(\"\\n[1/6] Training LightGBM for X...\")\n    models['lgb_x'] = train_lgb(X_train, y_x_train, X_val, y_x_val)\n    \n    print(\"\\n[2/6] Training XGBoost for X...\")\n    models['xgb_x'] = train_xgb(X_train, y_x_train, X_val, y_x_val)\n    \n    print(\"\\n[3/6] Training CatBoost for X...\")\n    models['cat_x'] = train_catboost(X_train, y_x_train, X_val, y_x_val)\n    \n    # Train Y coordinate models\n    print(\"\\n[4/6] Training LightGBM for Y...\")\n    models['lgb_y'] = train_lgb(X_train, y_y_train, X_val, y_y_val)\n    \n    print(\"\\n[5/6] Training XGBoost for Y...\")\n    models['xgb_y'] = train_xgb(X_train, y_y_train, X_val, y_y_val)\n    \n    print(\"\\n[6/6] Training CatBoost for Y...\")\n    models['cat_y'] = train_catboost(X_train, y_y_train, X_val, y_y_val)\n    \n    # Evaluate ensemble\n    print(\"\\nEvaluating ensemble...\")\n    \n    pred_x_lgb = models['lgb_x'].predict(X_val)\n    pred_x_xgb = models['xgb_x'].predict(xgb.DMatrix(X_val))\n    pred_x_cat = models['cat_x'].predict(X_val)\n    pred_x_ensemble = 0.4 * pred_x_lgb + 0.35 * pred_x_xgb + 0.25 * pred_x_cat\n    \n    pred_y_lgb = models['lgb_y'].predict(X_val)\n    pred_y_xgb = models['xgb_y'].predict(xgb.DMatrix(X_val))\n    pred_y_cat = models['cat_y'].predict(X_val)\n    pred_y_ensemble = 0.4 * pred_y_lgb + 0.35 * pred_y_xgb + 0.25 * pred_y_cat\n    \n    rmse_x = np.sqrt(mean_squared_error(y_x_val, pred_x_ensemble))\n    rmse_y = np.sqrt(mean_squared_error(y_y_val, pred_y_ensemble))\n    combined_rmse = np.sqrt((rmse_x**2 + rmse_y**2) / 2)\n    \n    print(f\"\\nEnsemble Validation RMSE:\")\n    print(f\"  X: {rmse_x:.4f}\")\n    print(f\"  Y: {rmse_y:.4f}\")\n    print(f\"  Combined: {combined_rmse:.4f}\")\n    \n    return models, combined_rmse\n\n# =============================================================================\n# ELITE PREDICTION WITH PHYSICS\n# =============================================================================\n\ndef predict_elite(input_df, models, feature_cols):\n    \"\"\"Elite prediction with ensemble and physics\"\"\"\n    predictions = []\n    groups = input_df.groupby(['game_id', 'play_id', 'nfl_id'])\n    total = len(groups)\n    \n    print(f\"\\nGenerating elite predictions for {total:,} players...\")\n    \n    for idx, ((gid, pid, nid), group) in enumerate(groups, 1):\n        if idx % 500 == 0 or idx == total:\n            print(f\"  {idx}/{total} ({idx/total*100:.1f}%)\", end='\\r')\n        \n        last = group.sort_values('frame_id').iloc[-1]\n        n_frames = int(last['num_frames_output'])\n        state = last.copy()\n        \n        # Role-based parameters\n        role = state['player_role']\n        if role == 'Passer':\n            decay, pull = 0.99, 0.0\n        elif role == 'Targeted Receiver':\n            decay, pull = 0.965, 0.08\n        elif role == 'Defensive Coverage':\n            decay, pull = 0.96, 0.04\n        else:\n            decay, pull = 0.97, 0.02\n        \n        init_vx, init_vy = state['vx'], state['vy']\n        \n        for frame in range(1, n_frames + 1):\n            X_pred = state[feature_cols].values.reshape(1, -1)\n            X_pred = np.nan_to_num(X_pred, 0)\n            \n            # Ensemble prediction\n            pred_x_lgb = models['lgb_x'].predict(X_pred)[0]\n            pred_x_xgb = models['xgb_x'].predict(xgb.DMatrix(X_pred))[0]\n            pred_x_cat = models['cat_x'].predict(X_pred)[0]\n            next_x = 0.4 * pred_x_lgb + 0.35 * pred_x_xgb + 0.25 * pred_x_cat\n            \n            pred_y_lgb = models['lgb_y'].predict(X_pred)[0]\n            pred_y_xgb = models['xgb_y'].predict(xgb.DMatrix(X_pred))[0]\n            pred_y_cat = models['cat_y'].predict(X_pred)[0]\n            next_y = 0.4 * pred_y_lgb + 0.35 * pred_y_xgb + 0.25 * pred_y_cat\n            \n            # Ball pull\n            if pull > 0:\n                dx_ball = state['ball_land_x'] - next_x\n                dy_ball = state['ball_land_y'] - next_y\n                next_x += dx_ball * pull\n                next_y += dy_ball * pull\n            \n            # Temporal smoothing\n            if frame > 1:\n                next_x = 0.8 * next_x + 0.2 * predictions[-1]['x']\n                next_y = 0.8 * next_y + 0.2 * predictions[-1]['y']\n            \n            # Boundaries\n            next_x = np.clip(next_x, 0, 120)\n            next_y = np.clip(next_y, 0, 53.3)\n            \n            predictions.append({\n                'id': f\"{gid}_{pid}_{nid}_{frame}\",\n                'x': next_x,\n                'y': next_y\n            })\n            \n            # Update state\n            state['x'], state['y'] = next_x, next_y\n            state['vx'] = init_vx * (decay ** frame)\n            state['vy'] = init_vy * (decay ** frame)\n            state['s'] = np.sqrt(state['vx']**2 + state['vy']**2)\n            \n            # Key features\n            state['dist_to_ball'] = np.sqrt(\n                (next_x - state['ball_land_x'])**2 + \n                (next_y - state['ball_land_y'])**2\n            )\n            state['angle_to_ball'] = np.arctan2(\n                state['ball_land_y'] - next_y,\n                state['ball_land_x'] - next_x\n            )\n            state['speed_to_ball'] = state['s'] * np.cos(\n                np.radians(state['dir']) - state['angle_to_ball']\n            )\n            state['delta_x'] = state['ball_land_x'] - next_x\n            state['delta_y'] = state['ball_land_y'] - next_y\n            state['time_to_ball'] = state['dist_to_ball'] / (state['s'] + 0.1)\n            state['speed_sq'] = state['s'] ** 2\n            state['dist_sideline'] = min(next_y, 53.3 - next_y)\n            state['dist_endzone'] = min(next_x, 120 - next_x)\n    \n    print(f\"\\n  Complete!\")\n    return pd.DataFrame(predictions)\n\n# =============================================================================\n# MAIN PIPELINE\n# =============================================================================\n\ndef main():\n    print(\"=\"*80)\n    print(\"ELITE SOLUTION PIPELINE\")\n    print(\"Target: Top 3% (RMSE < 0.55)\")\n    print(\"=\"*80)\n    \n    # Load data (use all weeks for best performance)\n    train_input, train_output = load_data_efficient(sample_weeks=None)\n    \n    # Feature engineering\n    print(\"\\nPhase 1: Feature Engineering\")\n    train_input_fe = create_elite_features(train_input)\n    \n    # Add player interactions (computationally expensive but critical)\n    train_input_fe = add_player_interactions(train_input_fe)\n    \n    del train_input\n    gc.collect()\n    \n    # Prepare training\n    print(\"\\nPhase 2: Preparing Training Data\")\n    last_input = train_input_fe.sort_values('frame_id').groupby(\n        ['game_id', 'play_id', 'nfl_id']\n    ).tail(1).reset_index(drop=True)\n    \n    first_output = train_output.sort_values('frame_id').groupby(\n        ['game_id', 'play_id', 'nfl_id']\n    ).first().reset_index()\n    \n    train_data = last_input.merge(\n        first_output[['game_id', 'play_id', 'nfl_id', 'x', 'y']],\n        on=['game_id', 'play_id', 'nfl_id'],\n        suffixes=('', '_target'),\n        how='inner'\n    )\n    \n    train_data = train_data[train_data['player_to_predict'] == True].copy()\n    \n    del train_input_fe, train_output, last_input, first_output\n    gc.collect()\n    \n    print(f\"Training samples: {len(train_data):,}\")\n    \n    # Features\n    feature_cols = [\n        'x', 'y', 'ball_land_x', 'ball_land_y',\n        'dist_to_ball', 'angle_to_ball', 'speed_to_ball',\n        'delta_x', 'delta_y', 's', 'a', 'dir', 'o',\n        'vx', 'vy', 'ax', 'ay', 'speed_sq',\n        'role_enc', 'is_target', 'is_defender', 'is_offense',\n        'dist_sideline', 'dist_endzone', 'time_to_ball', 'orientation_diff',\n        'dist_to_target', 'nearest_defender', 'defenders_nearby', 'avg_player_dist',\n        'num_frames_output'\n    ]\n    \n    X = train_data[feature_cols].fillna(0)\n    y_x = train_data['x_target']\n    y_y = train_data['y_target']\n    \n    # Split\n    from sklearn.model_selection import train_test_split\n    X_train, X_val, y_x_train, y_x_val = train_test_split(\n        X, y_x, test_size=0.15, random_state=RANDOM_SEED\n    )\n    _, _, y_y_train, y_y_val = train_test_split(\n        X, y_y, test_size=0.15, random_state=RANDOM_SEED\n    )\n    \n    del train_data\n    gc.collect()\n    \n    # Train ensemble\n    print(\"\\nPhase 3: Training Elite Ensemble\")\n    models, val_rmse = train_ensemble(\n        X_train, X_val, y_x_train, y_x_val, y_y_train, y_y_val\n    )\n    \n    del X_train, X_val, y_x_train, y_x_val, y_y_train, y_y_val\n    gc.collect()\n    \n    # Test data\n    print(\"\\nPhase 4: Processing Test Data\")\n    test_input = pd.read_csv(TEST_INPUT_PATH)\n    test_input_fe = create_elite_features(test_input)\n    test_input_fe = add_player_interactions(test_input_fe)\n    \n    del test_input\n    gc.collect()\n    \n    # Predict\n    print(\"\\nPhase 5: Generating Predictions\")\n    predictions_df = predict_elite(test_input_fe, models, feature_cols)\n    \n    del test_input_fe\n    gc.collect()\n    \n    # Submission\n    print(\"\\nPhase 6: Creating Submission\")\n    sample_sub = pd.read_csv(SAMPLE_SUB_PATH)\n    submission = sample_sub[['id']].merge(predictions_df, on='id', how='left')\n    submission.fillna(0, inplace=True)\n    \n    submission.to_csv('submission.csv', index=False)\n    \n    print(\"\\n\" + \"=\"*80)\n    print(\"ELITE PIPELINE COMPLETE\")\n    print(\"=\"*80)\n    print(f\"Validation RMSE: {val_rmse:.4f}\")\n    print(f\"Expected Kaggle Score: {val_rmse * 1.05:.3f} - {val_rmse * 1.15:.3f}\")\n    print(\"Submission saved: submission.csv\")\n    print(\"=\"*80)\n    \n    return submission\n\nif __name__ == \"__main__\":\n    submission = main()","metadata":{"_uuid":"1024f8ab-306a-4f38-af31-3dc40c3d675b","_cell_guid":"e4c0f862-344e-4d62-be54-3b7c04087936","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null}]}