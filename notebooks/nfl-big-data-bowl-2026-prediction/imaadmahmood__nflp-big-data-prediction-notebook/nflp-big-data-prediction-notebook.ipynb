{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":114239,"databundleVersionId":13825858,"sourceType":"competition"}],"dockerImageVersionId":31090,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<div style=\"\n    background: linear-gradient(145deg, rgba(0, 71, 171, 0.98), rgba(255, 215, 0, 0.98));\n    backdrop-filter: blur(10px);\n    color: #e6f3ff;\n    font-size: 2.2em;\n    font-family: 'Montserrat', sans-serif;\n    font-weight: 700;\n    text-align: center;\n    border-radius: 30px;\n    border: 3px solid #000000;\n    padding: 30px 50px;\n    margin: 40px auto;\n    line-height: 1.6;\n    letter-spacing: 2px;\n    width: 85%;\n    text-transform: uppercase;\n    box-shadow: \n        0 0 25px rgba(0, 0, 0, 0.6), \n        0 0 45px rgba(0, 0, 0, 0.35), \n        inset 0 0 15px rgba(0, 0, 0, 0.3),\n        0 6px 28px rgba(0, 0, 0, 0.2);\n    position: relative;\n    overflow: hidden;\n    transition: all 0.4s cubic-bezier(0.4, 0, 0.2, 1);\">\n    <div style=\"\n        position: absolute;\n        top: -50%;\n        left: -50%;\n        width: 200%;\n        height: 200%;\n        background: radial-gradient(circle, rgba(0, 0, 0, 0.2) 0%, transparent 70%);\n        animation: rotateGradient 8s infinite ease-in-out;\">\n    </div>\n    üöÄ NFL Big Data Bowl 2026 - Prediction\n</div>\n\n<style>\ndiv:hover {\n    transform: translateY(-5px) scale(1.02);\n    box-shadow: \n        0 0 35px rgba(0, 0, 0, 0.8), \n        0 0 60px rgba(0, 0, 0, 0.5), \n        inset 0 0 20px rgba(0, 0, 0, 0.35),\n        0 10px 40px rgba(0, 0, 0, 0.25);\n    border-color: #000000;\n}\n\n@keyframes rotateGradient {\n    0% { transform: rotate(0deg); opacity: 0.3; }\n    50% { opacity: 0.5; }\n    100% { transform: rotate(360deg); opacity: 0.3; }\n}\n</style>","metadata":{}},{"cell_type":"markdown","source":"# NFL Big Data Bowl 2026: Predicting Player Movement During Pass Plays\n\n## Competition Overview\n\nThe NFL Big Data Bowl 2026, hosted by the National Football League (NFL) in collaboration with Kaggle, is a premier data science competition aimed at advancing football analytics through innovative modeling. This year's competition features two tracks: **Analytics** and **Prediction**. This report details the **Prediction Competition**, which focuses on forecasting NFL player movements (x, y coordinates) during the time a pass is in the air, from the quarterback's release until the ball is caught or ruled incomplete.\n\n- **Objective**: Predict the frame-by-frame (x, y) positions of players marked `player_to_predict=True` during the pass flight, using pre-throw Next Gen Stats (NGS) tracking data, the identity of the targeted receiver, and the ball's landing location.\n- **Timeline**:\n  - **Training Phase**: September 25, 2025 ‚Äì December 3, 2025.\n    - Team merger and entry deadline: November 26, 2025.\n    - Final submission deadline: December 3, 2025, 11:59 PM UTC.\n  - **Forecasting Phase**: December 4, 2025 ‚Äì January 5, 2026, with a live leaderboard updated weekly based on NFL games from the final five weeks of the 2025 season (starting December 4, 7, 8; ending January 4, 2026). Final results published January 6, 2026.\n- **Evaluation**: Root Mean Squared Error (RMSE) between predicted and actual player positions (x, y) across frames:\n  \\[\n  \\text{RMSE} = \\sqrt{\\frac{1}{N} \\sum_{i=1}^N \\left( (x_{\\text{pred},i} - x_{\\text{true},i})^2 + (y_{\\text{pred},i} - y_{\\text{true},i})^2 \\right)}\n  \\]\n  Exclusions: Quick passes (<0.5 seconds), deflected passes, and throwaways.\n- **Prizes**: \n  - 1st Place: $25,000\n  - 2nd Place: $15,000\n  - 3rd Place: $10,000\n- **Constraints**: \n  - Submissions via Kaggle Notebooks (CPU/GPU runtime ‚â§9 hours, internet disabled).\n  - Freely available external data and pre-trained models permitted.\n  - Submission file: `submission.csv` with columns `id` (`{game_id}_{play_id}_{nfl_id}_{frame_id}`), `x`, `y`.\n- **Citation**: Michael Lopez, Tom Bliss, Ally Blake, Yao Yan, Martyna Plomecka, and Addison Howard. *NFL Big Data Bowl 2026 - Prediction*. https://kaggle.com/competitions/nfl-big-data-bowl-2026-prediction, 2025. Kaggle.\n\n## Key Terms\n\n- **Next Gen Stats (NGS)**: NFL's advanced tracking system capturing player and ball positions, speeds (y/s), accelerations (y/s¬≤), directions (degrees), and orientations (degrees) at 10 Hz (10 frames/second).\n- **Pass Play**: An offensive play where the quarterback throws the ball toward a receiver, analyzed from throw to catch or incompletion.\n- **Frame**: A data snapshot every 0.1 seconds. Prediction horizons vary (e.g., ~25 frames for a 2.5-second pass).\n- **Targeted Receiver**: The offensive player intended to catch the pass, identified in the dataset.\n- **Ball Landing Location**: The (x, y) coordinates where the pass is expected to land (0‚Äì120 yards long axis, 0‚Äì53.3 yards short axis).\n- **Player Role**: Specific role during the play (e.g., Targeted Receiver, Defensive Coverage, Passer, Other Route Runner).\n- **RMSE**: The evaluation metric measuring prediction accuracy across x and y coordinates.\n\n## Dataset Description\n\nThe dataset comprises historical training data (2023 season, weeks 1‚Äì18) and test data for live evaluation (~60k rows). Key files:\n\n- **train/input_2023_w[01-18].csv** (~4,625,662 rows):\n  - Pre-throw tracking data for ~22 players per play, ~20‚Äì40 frames each.\n  - **Key Columns**:\n    - `game_id`: Unique game identifier (numeric, 256 games).\n    - `play_id`: Play identifier, not unique across games (13,358 plays).\n    - `nfl_id`: Unique player identifier (numeric).\n    - `frame_id`: Frame number within play (starts at 1).\n    - `player_to_predict`: Boolean indicating if player‚Äôs predictions are scored (26.74% True, ~1,236,979 rows).\n    - `x`, `y`: Player position (x: 0‚Äì120 yards, y: 0‚Äì53.3 yards).\n    - `s`, `a`: Speed (y/s), acceleration (y/s¬≤).\n    - `dir`, `o`: Motion angle, orientation (degrees).\n    - `player_role`, `player_side`: Role (e.g., Targeted Receiver), side (Offense/Defense).\n    - `play_direction`: Offense direction (left/right).\n    - `absolute_yardline_number`: Distance to possession team‚Äôs endzone.\n    - `player_height` (ft-in), `player_weight` (lbs), `player_birth_date`.\n    - `num_frames_output`: Number of post-throw frames to predict.\n    - `ball_land_x`, `ball_land_y`: Pass landing coordinates.\n- **train/output_2023_w[01-18].csv** (~533,254 rows):\n  - Post-throw ground truth positions for validation.\n  - Columns: `game_id`, `play_id`, `nfl_id`, `frame_id`, `x` (target), `y` (target).\n  - `frame_id` starts at 1 (post-throw), max equals `num_frames_output`.\n- **test_input.csv** (~49,753 rows): Pre-throw tracking data for test plays, same structure as input files.\n- **test.csv** (~5,837 rows): Mock test set with `game_id`, `play_id`, `nfl_id`, `frame_id`.\n- **sample_submission.csv**: Submission template with `id`, `x`, `y` (dummy zeros).\n\n**Joining**: Match input/output on `game_id`, `play_id`, `nfl_id`. Input ends at throw; output starts at frame 1 (throw+1). Analytics track data (e.g., play formations) can supplement context.\n\n## Objective\n\nThe primary objective is to develop a robust model to predict player (x, y) positions for each frame while the ball is in the air, minimizing RMSE. Key challenges:\n- **Multi-agent dynamics**: Players (e.g., receivers, defenders) move interdependently, reacting to the ball, each other, and play context.\n- **Variable prediction horizons**: 5‚Äì25+ frames, depending on pass duration.\n- **Physics constraints**: Predictions must respect realistic speeds (<20 mph) and field boundaries (x: 0‚Äì120, y: 0‚Äì53.3).\n- **Data limitations**: Only pre-throw tracking is provided; post-throw intent must be inferred from kinematics, roles, and ball landing.\n\n## Approach and Strategies\n\nWe developed the `NFLPlayerMovementPredictor` class, a comprehensive solution combining ensemble tree-based models and sequence modeling with LSTMs. Below is a detailed breakdown of the approach, implemented in Python using pandas, scikit-learn, XGBoost, LightGBM, CatBoost, and PyTorch.\n\n### Code Overview\n\nThe provided code implements a sophisticated pipeline for data loading, feature engineering, model training, and prediction generation. Key components:\n\n","metadata":{}},{"cell_type":"markdown","source":"<div style=\"\n    background: linear-gradient(145deg, rgba(0, 71, 171, 0.98), rgba(255, 215, 0, 0.98));\n    backdrop-filter: blur(10px);\n    color: #e6f3ff;\n    font-size: 2.2em;\n    font-family: 'Montserrat', sans-serif;\n    font-weight: 700;\n    text-align: center;\n    border-radius: 30px;\n    border: 3px solid #000000;\n    padding: 30px 50px;\n    margin: 40px auto;\n    line-height: 1.6;\n    letter-spacing: 2px;\n    width: 85%;\n    text-transform: uppercase;\n    box-shadow: \n        0 0 25px rgba(0, 0, 0, 0.6), \n        0 0 45px rgba(0, 0, 0, 0.35), \n        inset 0 0 15px rgba(0, 0, 0, 0.3),\n        0 6px 28px rgba(0, 0, 0, 0.2);\n    position: relative;\n    overflow: hidden;\n    transition: all 0.4s cubic-bezier(0.4, 0, 0.2, 1);\">\n    <div style=\"\n        position: absolute;\n        top: -50%;\n        left: -50%;\n        width: 200%;\n        height: 200%;\n        background: radial-gradient(circle, rgba(0, 0, 0, 0.2) 0%, transparent 70%);\n        animation: rotateGradient 8s infinite ease-in-out;\">\n    </div>\n    üìÇ Files Loading\n</div>\n\n<style>\ndiv:hover {\n    transform: translateY(-5px) scale(1.02);\n    box-shadow: \n        0 0 35px rgba(0, 0, 0, 0.8), \n        0 0 60px rgba(0, 0, 0, 0.5), \n        inset 0 0 20px rgba(0, 0, 0, 0.35),\n        0 10px 40px rgba(0, 0, 0, 0.25);\n    border-color: #000000;\n}\n\n@keyframes rotateGradient {\n    0% { transform: rotate(0deg); opacity: 0.3; }\n    50% { opacity: 0.5; }\n    100% { transform: rotate(360deg); opacity: 0.3; }\n}\n</style>","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-09-27T08:57:49.352525Z","iopub.execute_input":"2025-09-27T08:57:49.352744Z","iopub.status.idle":"2025-09-27T08:57:51.960182Z","shell.execute_reply.started":"2025-09-27T08:57:49.352717Z","shell.execute_reply":"2025-09-27T08:57:51.959547Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<div style=\"\n    background: linear-gradient(145deg, rgba(0, 71, 171, 0.98), rgba(255, 215, 0, 0.98));\n    backdrop-filter: blur(10px);\n    color: #e6f3ff;\n    font-size: 2.2em;\n    font-family: 'Montserrat', sans-serif;\n    font-weight: 700;\n    text-align: center;\n    border-radius: 30px;\n    border: 3px solid #000000;\n    padding: 30px 50px;\n    margin: 40px auto;\n    line-height: 1.6;\n    letter-spacing: 2px;\n    width: 85%;\n    text-transform: uppercase;\n    box-shadow: \n        0 0 25px rgba(0, 0, 0, 0.6), \n        0 0 45px rgba(0, 0, 0, 0.35), \n        inset 0 0 15px rgba(0, 0, 0, 0.3),\n        0 6px 28px rgba(0, 0, 0, 0.2);\n    position: relative;\n    overflow: hidden;\n    transition: all 0.4s cubic-bezier(0.4, 0, 0.2, 1);\">\n    <div style=\"\n        position: absolute;\n        top: -50%;\n        left: -50%;\n        width: 200%;\n        height: 200%;\n        background: radial-gradient(circle, rgba(0, 0, 0, 0.2) 0%, transparent 70%);\n        animation: rotateGradient 8s infinite ease-in-out;\">\n    </div>\n    ‚öôÔ∏è Full Pipeline Execution\n</div>\n\n<style>\ndiv:hover {\n    transform: translateY(-5px) scale(1.02);\n    box-shadow: \n        0 0 35px rgba(0, 0, 0, 0.8), \n        0 0 60px rgba(0, 0, 0, 0.5), \n        inset 0 0 20px rgba(0, 0, 0, 0.35),\n        0 10px 40px rgba(0, 0, 0, 0.25);\n    border-color: #000000;\n}\n\n@keyframes rotateGradient {\n    0% { transform: rotate(0deg); opacity: 0.3; }\n    50% { opacity: 0.5; }\n    100% { transform: rotate(360deg); opacity: 0.3; }\n}\n</style>","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom pathlib import Path\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder\nfrom sklearn.model_selection import GroupKFold\nfrom sklearn.linear_model import RidgeCV\nfrom xgboost import XGBRegressor\nfrom lightgbm import LGBMRegressor\nfrom catboost import CatBoostRegressor\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nimport warnings\nwarnings.filterwarnings('ignore')\n\nclass NFLPlayerMovementPredictor:\n    \"\"\"NFL Big Data Bowl 2026 Predictor with Ensemble and Sequence Modeling\"\"\"\n    \n    def __init__(self, data_dir, seed=42, device='cuda' if torch.cuda.is_available() else 'cpu'):\n        self.data_dir = Path(data_dir)\n        self.seed = seed\n        self.device = device\n        self.weeks = list(range(1, 18))\n        self.models_dx = {}\n        self.models_dy = {}\n        self.scalers = {}\n        self.label_encoders = {}\n        self.sequence_model = None\n        self.test_input = None\n\n    # ========== Data Loading and Inspection ==========\n    def load_and_combine_datasets(self):\n        \"\"\"Load and combine weekly training data, inspect file structure\"\"\"\n        print(\"===== Loading and Inspecting Data =====\")\n        input_paths = [self.data_dir / f\"train/input_2023_w{w:02d}.csv\" for w in self.weeks]\n        output_paths = [self.data_dir / f\"train/output_2023_w{w:02d}.csv\" for w in self.weeks]\n        \n        train_input = pd.concat([pd.read_csv(p) for p in input_paths], ignore_index=True)\n        print(f\"Training Input Shape: {train_input.shape}\")\n        print(f\"Training Input Columns: {train_input.columns.tolist()}\")\n        print(f\"Unique Games: {train_input['game_id'].nunique()}, Unique Plays: {train_input[['game_id', 'play_id']].drop_duplicates().shape[0]}\")\n        if 'player_to_predict' in train_input.columns:\n            print(f\"Players to Predict (Input): {train_input['player_to_predict'].sum()} ({train_input['player_to_predict'].mean():.2%})\")\n        else:\n            print(\"Warning: 'player_to_predict' not found in training input\")\n        \n        train_output = pd.concat([pd.read_csv(p) for p in output_paths], ignore_index=True)\n        print(f\"Training Output Shape: {train_output.shape}\")\n        print(f\"Training Output Columns: {train_output.columns.tolist()}\")\n        \n        test_input = pd.read_csv(self.data_dir / \"test_input.csv\")\n        test_template = pd.read_csv(self.data_dir / \"test.csv\")\n        print(f\"Test Input Shape: {test_input.shape}\")\n        print(f\"Test Input Columns: {test_input.columns.tolist()}\")\n        print(f\"Test Template Shape: {test_template.shape}\")\n        print(f\"Test Template Columns: {test_template.columns.tolist()}\")\n        if 'player_to_predict' in test_template.columns:\n            print(f\"Test Players to Predict: {test_template['player_to_predict'].sum()} ({test_template['player_to_predict'].mean():.2%})\")\n        else:\n            print(\"Warning: 'player_to_predict' not found in test template. Assuming all rows need predictions.\")\n        \n        self.test_input = test_input\n        return train_input, train_output, test_input, test_template\n    \n    # ========== Utility Functions ==========\n    def _convert_height_to_inches(self, height_str):\n        \"\"\"Convert height from 'ft-in' format to total inches\"\"\"\n        if not isinstance(height_str, str) or '-' not in height_str:\n            return np.nan\n        try:\n            feet, inches = map(int, height_str.split('-'))\n            return feet * 12 + inches\n        except (ValueError, AttributeError):\n            return np.nan\n    \n    def _extract_sequence_observations(self, tracking_data, k_in=10, is_test=False, test_template=None):\n        \"\"\"Extract last k_in frames before pass for each player for sequence modeling\"\"\"\n        required_cols = ['x', 'y', 's', 'a', 'dir', 'o']\n        missing_cols = [col for col in required_cols if col not in tracking_data.columns]\n        if missing_cols:\n            raise KeyError(f\"Missing required columns for sequence modeling: {missing_cols}\")\n        \n        sorted_data = tracking_data.sort_values(['game_id', 'play_id', 'nfl_id', 'frame_id'])\n        if is_test and test_template is not None:\n            # Filter tracking_data to match test_template\n            sorted_data = sorted_data.merge(\n                test_template[['game_id', 'play_id', 'nfl_id', 'frame_id']],\n                on=['game_id', 'play_id', 'nfl_id', 'frame_id'],\n                how='inner'\n            )\n            print(f\"Aligned test input with test template: {len(sorted_data)} rows\")\n        \n        grouped = sorted_data.groupby(['game_id', 'play_id', 'nfl_id'])\n        sequences = []\n        sequence_keys = []\n        for key, group in grouped:\n            if len(group) >= k_in:\n                seq = group.tail(k_in)[required_cols].values\n            else:\n                seq = np.pad(group[required_cols].values, \n                            ((k_in - len(group), 0), (0, 0)), mode='edge')\n            sequences.append(seq)\n            sequence_keys.append(key)  # Store (game_id, play_id, nfl_id)\n        \n        print(f\"Extracted {len(sequences)} sequences of shape {sequences[0].shape}\")\n        return np.array(sequences), sequence_keys\n    \n    def _neighbor_pooling(self, data, n_neighbors=3):\n        \"\"\"Calculate mean relative position and velocity of n nearest neighbors\"\"\"\n        required_cols = ['final_pre_throw_x', 'final_pre_throw_y', 'velocity_x', 'velocity_y']\n        missing_cols = [col for col in required_cols if col not in data.columns]\n        if missing_cols:\n            raise KeyError(f\"Missing required columns for neighbor pooling: {missing_cols}\")\n        \n        neighbor_features = []\n        for _, play in data.groupby(['game_id', 'play_id', 'frame_id']):\n            coords = play[['final_pre_throw_x', 'final_pre_throw_y']].values\n            velocities = play[['velocity_x', 'velocity_y']].values\n            for i in range(len(coords)):\n                distances = np.sqrt(((coords - coords[i])**2).sum(axis=1))\n                nearest_idx = np.argsort(distances)[1:n_neighbors+1]\n                mean_rel_pos = np.mean(coords[nearest_idx] - coords[i], axis=0)\n                mean_rel_vel = np.mean(velocities[nearest_idx], axis=0)\n                neighbor_features.append(np.concatenate([mean_rel_pos, mean_rel_vel]))\n        print(f\"Computed neighbor features for {len(neighbor_features)} player-frames\")\n        return np.array(neighbor_features)\n    \n    def _incorporate_target_receiver_data(self, player_data):\n        \"\"\"Add target receiver position data\"\"\"\n        required_cols = ['game_id', 'play_id', 'player_role', 'final_pre_throw_x', 'final_pre_throw_y']\n        missing_cols = [col for col in required_cols if col not in player_data.columns]\n        if missing_cols:\n            raise KeyError(f\"Missing required columns for target receiver data: {missing_cols}\")\n        \n        target_receivers = player_data[player_data['player_role'] == \"Targeted Receiver\"][\n            ['game_id', 'play_id', 'final_pre_throw_x', 'final_pre_throw_y']\n        ].rename(columns={\n            'final_pre_throw_x': 'target_receiver_x', \n            'final_pre_throw_y': 'target_receiver_y'\n        })\n        target_receivers = target_receivers.drop_duplicates(['game_id', 'play_id'])\n        print(f\"Found {len(target_receivers)} unique target receivers\")\n        return player_data.merge(target_receivers, on=['game_id', 'play_id'], how='left')\n    \n    # ========== Feature Engineering ==========\n    def _calculate_advanced_features(self, data_frame, training_mode=False):\n        \"\"\"Create comprehensive feature set for player movement prediction\"\"\"\n        print(\"===== Feature Engineering =====\")\n        df = data_frame.copy()\n        \n        if 'frame_id' in df.columns:\n            df['time_seconds'] = df['frame_id'] / 10.0\n            frame_max = df.groupby(['game_id', 'play_id', 'nfl_id'])['frame_id'].transform('max')\n            df['normalized_frame'] = df['frame_id'] / frame_max\n            df['time_weight'] = df['normalized_frame'] ** 2\n        else:\n            df['time_seconds'] = 0.0\n            df['normalized_frame'] = 0.0\n            df['time_weight'] = 1.0\n        \n        if all(col in df.columns for col in ['ball_land_x', 'ball_land_y', 'final_pre_throw_x', 'final_pre_throw_y']):\n            ball_dx = df['ball_land_x'] - df['final_pre_throw_x']\n            ball_dy = df['ball_land_y'] - df['final_pre_throw_y']\n            df['distance_to_ball_landing'] = np.sqrt(ball_dx**2 + ball_dy**2)\n            df['angle_to_ball_landing'] = np.arctan2(ball_dy, ball_dx)\n        else:\n            df['distance_to_ball_landing'] = 0.0\n            df['angle_to_ball_landing'] = 0.0\n        \n        if all(col in df.columns for col in ['target_receiver_x', 'target_receiver_y', 'final_pre_throw_x', 'final_pre_throw_y']):\n            target_dx = df['target_receiver_x'] - df['final_pre_throw_x']\n            target_dy = df['target_receiver_y'] - df['final_pre_throw_y']\n            df['distance_to_target'] = np.sqrt(target_dx**2 + target_dy**2)\n            df['angle_to_target'] = np.arctan2(target_dy, target_dx)\n        else:\n            df['distance_to_target'] = 0.0\n            df['angle_to_target'] = 0.0\n        \n        if 'player_role' in df.columns:\n            df['is_target_receiver'] = (df['player_role'] == \"Targeted Receiver\").astype(int)\n            df['sample_weight'] = df['is_target_receiver'] * 2.0 + df['time_weight']\n        else:\n            df['is_target_receiver'] = 0\n            df['sample_weight'] = df['time_weight']\n        \n        if all(col in df.columns for col in ['s', 'dir']):\n            direction_radians = np.deg2rad(df['dir'])\n            df['velocity_x'] = df['s'] * np.sin(direction_radians)\n            df['velocity_y'] = df['s'] * np.cos(direction_radians)\n        else:\n            df['velocity_x'] = 0.0\n            df['velocity_y'] = 0.0\n        if 'a' in df.columns:\n            df['acceleration_magnitude'] = np.abs(df['a'])\n        else:\n            df['acceleration_magnitude'] = 0.0\n        \n        if 'final_pre_throw_x' in df.columns:\n            df['normalized_x'] = df['final_pre_throw_x'] / 120.0\n        else:\n            df['normalized_x'] = 0.0\n        if 'final_pre_throw_y' in df.columns:\n            df['normalized_y'] = df['final_pre_throw_y'] / 53.3\n            df['lateral_position_importance'] = np.abs(df['final_pre_throw_y'] - 26.65) / 26.65\n        else:\n            df['normalized_y'] = 0.0\n            df['lateral_position_importance'] = 0.0\n        if all(col in df.columns for col in ['final_pre_throw_x', 'absolute_yardline_number']):\n            df['downfield_progress'] = df['final_pre_throw_x'] - df['absolute_yardline_number']\n        else:\n            df['downfield_progress'] = 0.0\n        \n        if 'player_height' in df.columns:\n            df['height_inches'] = df['player_height'].apply(self._convert_height_to_inches)\n        else:\n            df['height_inches'] = np.nan\n        if all(col in df.columns for col in ['player_weight', 'height_inches']):\n            df['bmi'] = np.where(df['height_inches'] > 0, \n                                (df['player_weight'] * 0.453592) / ((df['height_inches'] * 0.0254) ** 2), np.nan)\n        else:\n            df['bmi'] = np.nan\n        \n        if all(col in df.columns for col in ['dir', 'o']):\n            df['speed_orientation_discrepancy'] = np.abs(df['dir'] - df['o'])\n        else:\n            df['speed_orientation_discrepancy'] = 0.0\n        if all(col in df.columns for col in ['s', 'a']):\n            df['speed_times_acceleration'] = df['s'] * df['a']\n        else:\n            df['speed_times_acceleration'] = 0.0\n        if all(col in df.columns for col in ['distance_to_ball_landing', 's']):\n            df['distance_speed_ratio'] = df['distance_to_ball_landing'] / (df['s'] + 1.0)\n        else:\n            df['distance_speed_ratio'] = 0.0\n        \n        if training_mode and all(col in df.columns for col in ['x', 'final_pre_throw_x', 'y', 'final_pre_throw_y']):\n            df['displacement_x'] = df['x'] - df['final_pre_throw_x']\n            df['displacement_y'] = df['y'] - df['final_pre_throw_y']\n        \n        print(f\"Generated {len(df.columns)} features: {df.columns.tolist()}\")\n        return df\n    \n    def prepare_features(self, input_data, output_data, training_mode=False):\n        \"\"\"Complete feature engineering pipeline\"\"\"\n        print(\"Extracting final pre-throw observations...\")\n        required_cols = ['game_id', 'play_id', 'nfl_id', 'frame_id', 'x', 'y']\n        missing_cols = [col for col in required_cols if col not in input_data.columns]\n        if missing_cols:\n            raise KeyError(f\"Missing required columns in input data: {missing_cols}\")\n        \n        final_observations = input_data.sort_values(['game_id', 'play_id', 'nfl_id', 'frame_id'])\\\n            .groupby(['game_id', 'play_id', 'nfl_id'], as_index=False).last()\n        final_observations = final_observations.rename(columns={'x': 'final_pre_throw_x', 'y': 'final_pre_throw_y'})\n        print(\"Incorporating target receiver data...\")\n        final_observations = self._incorporate_target_receiver_data(final_observations)\n        \n        merge_columns = ['game_id', 'play_id', 'nfl_id', 'final_pre_throw_x', 'final_pre_throw_y', \n                        's', 'a', 'o', 'dir', 'player_role', 'player_side', 'num_frames_output', \n                        'ball_land_x', 'ball_land_y', 'target_receiver_x', 'target_receiver_y',\n                        'play_direction', 'absolute_yardline_number', 'player_height', 'player_weight']\n        if 'player_to_predict' in input_data.columns:\n            merge_columns.append('player_to_predict')\n        merge_columns = [col for col in merge_columns if col in final_observations.columns]\n        print(f\"Merging with columns: {merge_columns}\")\n        merged_data = output_data.merge(final_observations[merge_columns], \n                                      on=['game_id', 'play_id', 'nfl_id'], how='left')\n        return self._calculate_advanced_features(merged_data, training_mode)\n    \n    def _encode_categorical_features(self, data_frame):\n        \"\"\"Encode categorical variables with LabelEncoder\"\"\"\n        encoded_df = data_frame.copy()\n        categorical_columns = ['player_role', 'player_side', 'play_direction']\n        for col in categorical_columns:\n            if col in encoded_df.columns:\n                encoded_df[col] = encoded_df[col].fillna('Unknown')\n                if col not in self.label_encoders:\n                    self.label_encoders[col] = LabelEncoder()\n                    encoded_df[col] = self.label_encoders[col].fit_transform(encoded_df[col])\n                else:\n                    encoded_df[col] = encoded_df[col].apply(\n                        lambda x: x if x in self.label_encoders[col].classes_ else 'Unknown')\n                    encoded_df[col] = self.label_encoders[col].transform(encoded_df[col])\n            else:\n                encoded_df[col] = 0\n        return encoded_df\n    \n    # ========== Sequence Modeling ==========\n    class NFLSequenceDataset(Dataset):\n        \"\"\"PyTorch Dataset for sequence data\"\"\"\n        def __init__(self, sequences, targets=None):\n            self.sequences = sequences\n            self.targets = targets\n        \n        def __len__(self):\n            return len(self.sequences)\n        \n        def __getitem__(self, idx):\n            if self.targets is not None:\n                return self.sequences[idx], self.targets[idx]\n            return self.sequences[idx]\n    \n    class NFLSequenceModel(nn.Module):\n        \"\"\"LSTM model for predicting dx, dy from sequence data\"\"\"\n        def __init__(self, input_size=6, hidden_size=128, num_layers=2):\n            super().__init__()\n            self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n            self.fc = nn.Linear(hidden_size, 2)\n        \n        def forward(self, x):\n            _, (hn, _) = self.lstm(x)\n            return self.fc(hn[-1])\n    \n    def train_sequence_model(self, sequences, targets, batch_size=32, epochs=20):\n        \"\"\"Train LSTM model for sequence data\"\"\"\n        print(\"===== Training Sequence Model =====\")\n        dataset = self.NFLSequenceDataset(sequences, targets)\n        dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n        self.sequence_model = self.NFLSequenceModel().to(self.device)\n        optimizer = optim.Adam(self.sequence_model.parameters(), lr=0.001)\n        criterion = nn.MSELoss()\n        \n        for epoch in range(epochs):\n            self.sequence_model.train()\n            total_loss = 0\n            for batch_seq, batch_target in dataloader:\n                batch_seq, batch_target = batch_seq.float().to(self.device), batch_target.float().to(self.device)\n                optimizer.zero_grad()\n                output = self.sequence_model(batch_seq)\n                loss = criterion(output, batch_target)\n                loss.backward()\n                optimizer.step()\n                total_loss += loss.item()\n            print(f\"Epoch {epoch+1}/{epochs}, Loss: {total_loss/len(dataloader):.4f}\")\n    \n    # ========== Model Training ==========\n    def train_models(self):\n        \"\"\"Train ensemble and sequence models with GroupKFold\"\"\"\n        print(\"===== Model Training =====\")\n        train_input, train_output, test_input, test_template = self.load_and_combine_datasets()\n        \n        self.train_data = self.prepare_features(train_input, train_output, training_mode=True)\n        self.test_data = self.prepare_features(test_input, test_template, training_mode=False)\n        \n        if 'player_to_predict' in self.train_data.columns:\n            self.train_data = self.train_data[self.train_data['player_to_predict'] == True]\n            print(f\"Filtered training data to {len(self.train_data)} rows with player_to_predict=True\")\n        else:\n            print(\"Warning: 'player_to_predict' not found in training data. Using all rows.\")\n        \n        numerical_features = [\n            'final_pre_throw_x', 'final_pre_throw_y', 's', 'a', 'o', 'dir', 'time_seconds', \n            'normalized_frame', 'distance_to_ball_landing', 'angle_to_ball_landing', \n            'distance_to_target', 'angle_to_target', 'is_target_receiver', 'velocity_x', \n            'velocity_y', 'acceleration_magnitude', 'normalized_x', 'normalized_y', \n            'lateral_position_importance', 'downfield_progress', 'bmi', \n            'speed_orientation_discrepancy', 'speed_times_acceleration', 'distance_speed_ratio'\n        ]\n        categorical_features = ['player_role', 'player_side', 'play_direction']\n        self.numerical_features = [f for f in numerical_features if f in self.train_data.columns]\n        self.categorical_features = [f for f in categorical_features if f in self.train_data.columns]\n        print(f\"Using numerical features: {self.numerical_features}\")\n        print(f\"Using categorical features: {self.categorical_features}\")\n        \n        X_train = self.train_data[self.numerical_features + self.categorical_features].copy()\n        X_train = self._encode_categorical_features(X_train)\n        X_train = X_train.fillna(0)\n        self.scalers['numerical'] = StandardScaler()\n        X_train[self.numerical_features] = self.scalers['numerical'].fit_transform(X_train[self.numerical_features])\n        \n        y_dx = self.train_data['displacement_x'].values\n        y_dy = self.train_data['displacement_y'].values\n        weights = self.train_data['sample_weight'].values\n        \n        if 'player_to_predict' in train_input.columns:\n            seq_input = train_input[train_input['player_to_predict'] == True]\n        else:\n            seq_input = train_input\n        sequences, _ = self._extract_sequence_observations(seq_input)\n        seq_targets = np.stack([y_dx, y_dy], axis=-1)\n        self.train_sequence_model(sequences, seq_targets)\n        \n        gkf = GroupKFold(n_splits=5)\n        groups = self.train_data['game_id']\n        meta_features_dx = np.zeros(len(X_train))\n        meta_features_dy = np.zeros(len(X_train))\n        \n        xgb_params = {'n_estimators': 2000, 'learning_rate': 0.05, 'max_depth': 8, 'subsample': 0.8, \n                      'colsample_bytree': 0.8, 'random_state': self.seed, 'tree_method': 'gpu_hist'}\n        lgb_params = {'n_estimators': 2000, 'learning_rate': 0.045, 'max_depth': 8, 'num_leaves': 100, \n                      'subsample': 0.8, 'colsample_bytree': 0.8, 'random_state': self.seed, \n                      'device': 'gpu', 'verbose': -1}\n        cat_params = {'iterations': 2000, 'learning_rate': 0.035, 'depth': 8, 'random_seed': self.seed, \n                      'task_type': 'GPU', 'verbose': False}\n        \n        for fold, (train_idx, val_idx) in enumerate(gkf.split(X_train, groups=groups)):\n            X_tr, X_val = X_train.iloc[train_idx], X_train.iloc[val_idx]\n            y_dx_tr, y_dx_val = y_dx[train_idx], y_dx[val_idx]\n            y_dy_tr, y_dy_val = y_dy[train_idx], y_dy[val_idx]\n            w_tr = weights[train_idx]\n            \n            for model_name, model_class, params in [\n                ('xgb', XGBRegressor, xgb_params),\n                ('lgb', LGBMRegressor, lgb_params),\n                ('cat', CatBoostRegressor, cat_params)\n            ]:\n                print(f\"Training {model_name} fold {fold+1}/5...\")\n                self.models_dx[f'{model_name}_{fold}'] = model_class(**params).fit(X_tr, y_dx_tr, sample_weight=w_tr)\n                self.models_dy[f'{model_name}_{fold}'] = model_class(**params).fit(X_tr, y_dy_tr, sample_weight=w_tr)\n                meta_features_dx[val_idx] += self.models_dx[f'{model_name}_{fold}'].predict(X_val) / 3\n                meta_features_dy[val_idx] += self.models_dy[f'{model_name}_{fold}'].predict(X_val) / 3\n        \n        print(\"Training meta-learner...\")\n        self.models_dx['meta'] = RidgeCV().fit(meta_features_dx.reshape(-1, 1), y_dx)\n        self.models_dy['meta'] = RidgeCV().fit(meta_features_dy.reshape(-1, 1), y_dy)\n    \n    # ========== Prediction ==========\n    def generate_predictions(self):\n        \"\"\"Generate ensemble predictions with sequence model blending\"\"\"\n        print(\"===== Generating Predictions =====\")\n        X_test = self.test_data[self.numerical_features + self.categorical_features].copy()\n        X_test = self._encode_categorical_features(X_test)\n        X_test = X_test.fillna(0)\n        X_test[self.numerical_features] = self.scalers['numerical'].transform(X_test[self.numerical_features])\n        \n        if self.test_input is None:\n            raise ValueError(\"test_input not initialized. Run train_models first.\")\n        seq_input = self.test_input\n        if 'player_to_predict' in seq_input.columns:\n            seq_input = seq_input[seq_input['player_to_predict'] == True]\n            print(f\"Filtered test input to {len(seq_input)} rows with player_to_predict=True\")\n        \n        sequences, sequence_keys = self._extract_sequence_observations(seq_input, is_test=True, test_template=self.test_data)\n        dataset = self.NFLSequenceDataset(sequences)\n        dataloader = DataLoader(dataset, batch_size=32, shuffle=False)\n        seq_preds = []\n        self.sequence_model.eval()\n        with torch.no_grad():\n            for batch_seq in dataloader:\n                batch_seq = batch_seq.float().to(self.device)\n                seq_preds.append(self.sequence_model(batch_seq).cpu().numpy())\n        seq_preds = np.concatenate(seq_preds)\n        print(f\"Generated {len(seq_preds)} sequence predictions\")\n        \n        # Map sequence predictions to test_data rows\n        seq_pred_df = pd.DataFrame({\n            'game_id': [k[0] for k in sequence_keys],\n            'play_id': [k[1] for k in sequence_keys],\n            'nfl_id': [k[2] for k in sequence_keys],\n            'seq_dx': seq_preds[:, 0],\n            'seq_dy': seq_preds[:, 1]\n        })\n        test_data_with_seq = self.test_data.merge(\n            seq_pred_df, on=['game_id', 'play_id', 'nfl_id'], how='left'\n        )\n        test_data_with_seq[['seq_dx', 'seq_dy']] = test_data_with_seq[['seq_dx', 'seq_dy']].fillna(0)\n        print(f\"Aligned sequence predictions with test data: {len(test_data_with_seq)} rows\")\n        \n        pred_dx = np.zeros(len(X_test))\n        pred_dy = np.zeros(len(X_test))\n        for fold in range(5):\n            for model_name in ['xgb', 'lgb', 'cat']:\n                pred_dx += self.models_dx[f'{model_name}_{fold}'].predict(X_test) / 15\n                pred_dy += self.models_dy[f'{model_name}_{fold}'].predict(X_test) / 15\n        \n        pred_dx = self.models_dx['meta'].predict(pred_dx.reshape(-1, 1))\n        pred_dy = self.models_dy['meta'].predict(pred_dy.reshape(-1, 1))\n        \n        pred_dx = 0.8 * pred_dx + 0.2 * test_data_with_seq['seq_dx'].values\n        pred_dy = 0.8 * pred_dy + 0.2 * test_data_with_seq['seq_dy'].values\n        \n        self.test_data['predicted_x'] = self.test_data['final_pre_throw_x'] + pred_dx\n        self.test_data['predicted_y'] = self.test_data['final_pre_throw_y'] + pred_dy\n        self.test_data['predicted_x'] = self.test_data['predicted_x'].clip(0.0, 120.0)\n        self.test_data['predicted_y'] = self.test_data['predicted_y'].clip(0.0, 53.3)\n        print(f\"Generated predictions for {len(self.test_data)} player-frames\")\n        return self.test_data\n    \n    # ========== Submission ==========\n    def create_submission_file(self, output_path=\"submission.csv\"):\n        \"\"\"Create submission file in required format\"\"\"\n        print(\"===== Creating Submission File =====\")\n        self.test_data['unique_id'] = (\n            self.test_data['game_id'].astype(str) + \"_\" +\n            self.test_data['play_id'].astype(str) + \"_\" +\n            self.test_data['nfl_id'].astype(str) + \"_\" +\n            self.test_data['frame_id'].astype(str)\n        )\n        submission_df = self.test_data[['unique_id', 'predicted_x', 'predicted_y']].rename(\n            columns={'predicted_x': 'x', 'predicted_y': 'y', 'unique_id': 'id'}\n        )\n        submission_df.to_csv(output_path, index=False)\n        print(f\"Submission saved to {output_path}, Shape: {submission_df.shape}\")\n        return submission_df\n\nif __name__ == \"__main__\":\n    try:\n        predictor = NFLPlayerMovementPredictor(data_dir=\"/kaggle/input/nfl-big-data-bowl-2026-prediction/\")\n        predictor.train_models()\n        predictions = predictor.generate_predictions()\n        submission = predictor.create_submission_file(\"/kaggle/working/submission.csv\")\n        print(\"===== Pipeline Completed Successfully =====\")\n        print(submission.head())\n    except Exception as e:\n        print(f\"Error occurred: {e}\")\n        import traceback\n        traceback.print_exc()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-27T10:10:54.12095Z","iopub.execute_input":"2025-09-27T10:10:54.121602Z","iopub.status.idle":"2025-09-27T10:27:38.421163Z","shell.execute_reply.started":"2025-09-27T10:10:54.121577Z","shell.execute_reply":"2025-09-27T10:27:38.420417Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<div style=\"\n    background: linear-gradient(145deg, rgba(0, 71, 171, 0.98), rgba(255, 215, 0, 0.98));\n    backdrop-filter: blur(10px);\n    color: #e6f3ff;\n    font-size: 2.2em;\n    font-family: 'Montserrat', sans-serif;\n    font-weight: 700;\n    text-align: center;\n    border-radius: 30px;\n    border: 3px solid #000000;\n    padding: 30px 50px;\n    margin: 40px auto;\n    line-height: 1.6;\n    letter-spacing: 2px;\n    width: 85%;\n    text-transform: uppercase;\n    box-shadow: \n        0 0 25px rgba(0, 0, 0, 0.6), \n        0 0 45px rgba(0, 0, 0, 0.35), \n        inset 0 0 15px rgba(0, 0, 0, 0.3),\n        0 6px 28px rgba(0, 0, 0, 0.2);\n    position: relative;\n    overflow: hidden;\n    transition: all 0.4s cubic-bezier(0.4, 0, 0.2, 1);\">\n    <div style=\"\n        position: absolute;\n        top: -50%;\n        left: -50%;\n        width: 200%;\n        height: 200%;\n        background: radial-gradient(circle, rgba(0, 0, 0, 0.2) 0%, transparent 70%);\n        animation: rotateGradient 8s infinite ease-in-out;\">\n    </div>\n    üëç If Liked My Work, Kindly Share and Upvote\n</div>\n\n<style>\ndiv:hover {\n    transform: translateY(-5px) scale(1.02);\n    box-shadow: \n        0 0 35px rgba(0, 0, 0, 0.8), \n        0 0 60px rgba(0, 0, 0, 0.5), \n        inset 0 0 20px rgba(0, 0, 0, 0.35),\n        0 10px 40px rgba(0, 0, 0, 0.25);\n    border-color: #000000;\n}\n\n@keyframes rotateGradient {\n    0% { transform: rotate(0deg); opacity: 0.3; }\n    50% { opacity: 0.5; }\n    100% { transform: rotate(360deg); opacity: 0.3; }\n}\n</style>","metadata":{}}]}