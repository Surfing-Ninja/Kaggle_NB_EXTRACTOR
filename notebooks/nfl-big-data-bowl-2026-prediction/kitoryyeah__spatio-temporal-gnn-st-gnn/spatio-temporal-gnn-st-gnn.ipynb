{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":114239,"databundleVersionId":13825858,"sourceType":"competition"}],"dockerImageVersionId":31090,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"id":"c69ede26","cell_type":"markdown","source":"# NFL Big Data Bowl 2026 — Spatio‑Temporal GNN (ST‑GNN) Notebook (Explained)\n\n**What you’ll see:**  \n- Data loading (train/test)\n- Feature building & graph construction (KNN + role‑aware edges + ball node)\n- ST‑Encoder (edge‑attention, GRU) and Temporal Decoder\n- Training loop with physics‑aware regularization\n- Validation, Inference, and `submission.csv` generation\n\n> Tip: If you run this on Kaggle, the notebook will automatically use the Kaggle dataset path when detected.\n","metadata":{}},{"id":"71961721","cell_type":"markdown","source":"## 1. Environment, Imports, and Global Config\n\n**EN:** We import all libraries and define the global configuration (`CFG`) as a dataclass. The `_resolve_paths()` function tries multiple data locations (local, env, Kaggle). AMP and multi‑GPU are supported.\n\n**JP:** ライブラリの読み込みと `CFG`（設定）を定義します。`_resolve_paths()` がデータの場所を自動検出します。AMP/複数GPU対応です。","metadata":{}},{"id":"850c492c","cell_type":"code","source":"\n# ============================================================\n# NFL Big Data Bowl 2026 - ST-GNN 改訂版 (AMP安全/全体書き換え)\n# - 直近Lフレームの時空間要約 + Edge Attention (FP32計算でAMP衝突回避)\n# - Ballノード注入 / 物理残差補助 / 終端重み / 速度違反ペナルティ\n# - 学習→検証→推論→submission まで一気通貫\n# ============================================================\n\nimport os, gc, math, warnings, random\nfrom pathlib import Path\nfrom glob import glob\nfrom dataclasses import dataclass\nimport numpy as np\nimport pandas as pd\nfrom tqdm.auto import tqdm\nfrom scipy.ndimage import gaussian_filter1d\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\n\nwarnings.filterwarnings(\"ignore\")\n\n# ------------------\n# Config\n# ------------------\n@dataclass\nclass CFG:\n    SEED: int = 42\n    USE_CUDA: bool = torch.cuda.is_available()\n    DEVICE: torch.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n    TRAIN_WEEKS: tuple = tuple(range(1, 19))\n    L_HIST: int = 5\n    K_NEIGHBORS: int = 6\n    K_ROLE: int = 2\n    BATCH_PLAYS: int = 8\n    CAP_T: int = 60\n    FPS: float = 10.0\n\n    FIELD_X_MIN: float = 0.0\n    FIELD_X_MAX: float = 120.0\n    FIELD_Y_MIN: float = 0.0\n    FIELD_Y_MAX: float = 53.3\n    MAX_SPEED: float = 12.0\n\n    NODE_HID: int = 128\n    EDGE_HID: int = 64\n    MP_LAYERS: int = 2\n    DEC_HID: int = 128\n    ROLE_EMB: int = 8\n    SIDE_EMB: int = 4\n    BALL_EDGE_WEIGHT: float = 1.0\n\n    EPOCHS: int = 8\n    LR: float = 7e-4\n    WEIGHT_DECAY: float = 1e-4\n    GRAD_CLIP: float|None = 0.5\n    AMP: bool = True\n    ACCUM_STEPS: int = 4\n\n    END_WEIGHTED: bool = True\n    PHYS_RESID_ALPHA: float = 0.2\n    SPEED_PENALTY: float = 0.01\n\n    SMOOTH_SIGMA: float = 0.6\n\n    BASE_DIR: Path = Path.cwd()\n    TRAIN_DIR: Path|None = Path(os.getenv(\"NFL_TRAIN_DIR\", \"\")) if os.getenv(\"NFL_TRAIN_DIR\") else None\n    TEST_DIR: Path|None  = Path(os.getenv(\"NFL_TEST_DIR\",  \"\")) if os.getenv(\"NFL_TEST_DIR\")  else None\n    DATA_DIR: Path|None  = Path(os.getenv(\"NFL_DATA_DIR\",  \"\")) if os.getenv(\"NFL_DATA_DIR\")  else None\n    OUT_DIR: Path = Path(os.getenv(\"NFL_OUT_DIR\", \"\")) if os.getenv(\"NFL_OUT_DIR\") else (Path.cwd() / \"runs\")\n\nCFG = CFG()\n\ndef _resolve_paths():\n    CFG.OUT_DIR.mkdir(parents=True, exist_ok=True)\n    if CFG.TRAIN_DIR and CFG.TEST_DIR and CFG.TRAIN_DIR.exists() and CFG.TEST_DIR.exists():\n        print(f\"[Path] Using TRAIN_DIR={CFG.TRAIN_DIR}, TEST_DIR={CFG.TEST_DIR}\"); return\n    lt, ls = CFG.BASE_DIR/\"train\", CFG.BASE_DIR/\"test\"\n    if lt.exists() and ls.exists():\n        CFG.TRAIN_DIR, CFG.TEST_DIR = lt, ls\n        print(\"[Path] Using ./train and ./test\"); return\n    kag = Path(\"/kaggle/input/nfl-big-data-bowl-2026-prediction\")\n    if kag.exists():\n        CFG.DATA_DIR = kag; CFG.TRAIN_DIR = kag/\"train\"; CFG.TEST_DIR = kag\n        print(f\"[Path] Using Kaggle dataset under {kag}\"); return\n    raise FileNotFoundError(\"データが見つかりません。env or ./train ./test or Kaggle path を用意してください。\")\n\n_resolve_paths()\nrandom.seed(CFG.SEED); np.random.seed(CFG.SEED); torch.manual_seed(CFG.SEED)\nif CFG.USE_CUDA: torch.cuda.manual_seed_all(CFG.SEED)\n","metadata":{},"outputs":[],"execution_count":null},{"id":"d320a7a3","cell_type":"markdown","source":"## 2. Small Utilities and Physics Helpers\n\n**EN:** Utility helpers for unit conversion, optional field normalization, field boundary clipping, and simple temporal positional encoding.\n\n**JP:** 単位変換・フィールド境界クリップ・時間PEなど、補助的な関数群です。","metadata":{}},{"id":"4f725408","cell_type":"code","source":"\n# ------------------\n# Utils / Physics\n# ------------------\ndef height_ftin_to_in(h):\n    if isinstance(h, str) and \"-\" in h:\n        try:\n            ft, inch = h.split(\"-\"); return int(ft)*12 + int(inch)\n        except: return 70\n    return 70\n\ndef maybe_flip_direction(df):  # 必要なら左右正規化を実装\n    return df\n\ndef clip_to_field(xy):\n    return torch.stack([\n        xy[...,0].clamp(CFG.FIELD_X_MIN, CFG.FIELD_X_MAX),\n        xy[...,1].clamp(CFG.FIELD_Y_MIN, CFG.FIELD_Y_MAX)\n    ], dim=-1)\n\ndef time_pos_encoding(t_norm):\n    t = t_norm.unsqueeze(-1)\n    return torch.cat([\n        torch.sin(2*math.pi*t), torch.cos(2*math.pi*t),\n        torch.sin(4*math.pi*t), torch.cos(4*math.pi*t)\n    ], dim=-1)\n","metadata":{},"outputs":[],"execution_count":null},{"id":"c0fba5f4","cell_type":"markdown","source":"## 3. CSV Loading (Train/Test)\n\n**EN:** We search for weekly `input_*.csv`/`output_*.csv` files; fall back to globs if the week‑pattern is not present. For test, we look for `test_input.csv`, `test.csv`, and `sample_submission.csv`.\n\n**JP:** 週別の `input_*.csv` / `output_*.csv` を優先し、なければグロブで探索。テストは `test_input.csv`・`test.csv`・`sample_submission.csv` を読み込みます。","metadata":{}},{"id":"3d79f5ee","cell_type":"code","source":"\n# ------------------\n# Loaders\n# ------------------\ndef _week_candidates(train_dir, w):\n    return [\n        train_dir / f\"input_2023_w{w:02d}.csv\",\n        train_dir / f\"input_w{w:02d}.csv\",\n        train_dir / f\"input_week{w:02d}.csv\",\n    ], [\n        train_dir / f\"output_2023_w{w:02d}.csv\",\n        train_dir / f\"output_w{w:02d}.csv\",\n        train_dir / f\"output_week{w:02d}.csv\",\n    ]\n\ndef load_train_input_output():\n    tdir = CFG.TRAIN_DIR\n    ins, outs = [], []\n    for w in CFG.TRAIN_WEEKS:\n        a, b = _week_candidates(tdir, w); ins += [p for p in a if p.exists()]; outs += [p for p in b if p.exists()]\n    if not ins:  ins  = [Path(p) for p in sorted(glob(str(tdir / \"input_*.csv\")))]\n    if not outs: outs = [Path(p) for p in sorted(glob(str(tdir / \"output_*.csv\")))]\n    if not ins or not outs: raise FileNotFoundError(\"[Load] input/output CSV not found\")\n    print(f\"[Load] input={len(ins)} files, output={len(outs)} files\")\n    tin  = pd.concat([pd.read_csv(p) for p in tqdm(ins, desc=\"read input\")], ignore_index=True)\n    tout = pd.concat([pd.read_csv(p) for p in tqdm(outs, desc=\"read output\")], ignore_index=True)\n    return tin, tout\n\ndef load_test_input_and_templates():\n    tdir = CFG.TEST_DIR\n    def _first_exists(cands): \n        for c in cands:\n            if c.exists(): return pd.read_csv(c)\n        return None\n    test_in = _first_exists([tdir/\"test_input.csv\", CFG.BASE_DIR/\"test_input.csv\"])\n    test_tpl= _first_exists([tdir/\"test.csv\", CFG.BASE_DIR/\"test.csv\"])\n    sub     = _first_exists([tdir/\"sample_submission.csv\", CFG.BASE_DIR/\"sample_submission.csv\"])\n    if test_in is None or test_tpl is None or sub is None:\n        raise FileNotFoundError(\"[Load] test_input/test.csv/sample_submission.csv not found\")\n    return test_in, test_tpl, sub\n","metadata":{},"outputs":[],"execution_count":null},{"id":"21c5073e","cell_type":"markdown","source":"## 4. Graph Construction (KNN, Role‑aware Edges, Ball Edges)\n\n**EN:** We form:  \n- **KNN** edges among all players  \n- **Role/side‑aware** cross‑team edges (top‑k per player)  \n- **Ball node edges** to/from all players\n\nEdge features include relative positions, velocity diffs, distances, and simple team indicators.\n\n**JP:** KNNエッジ、役割/サイド跨ぎのエッジ、ボールとの全双方向エッジを構築します。エッジ特徴量は相対位置/速度/距離/チーム指標などを含みます。","metadata":{}},{"id":"e6732756","cell_type":"code","source":"\n# ------------------\n# Graph utils\n# ------------------\ndef knn_edges(xy, k):\n    N = xy.size(0)\n    if N <= 1:\n        dev = xy.device\n        return (torch.empty(2,0,dtype=torch.long,device=dev),\n                torch.empty(0,dtype=xy.dtype,device=dev))\n    k_eff = min(k, N-1)\n    d = torch.cdist(xy, xy, p=2)\n    idx = torch.topk(-d, k_eff+1, dim=1).indices[:,1:]\n    rows = torch.arange(N, device=xy.device).unsqueeze(1).expand(N, k_eff)\n    eidx = torch.stack([rows.reshape(-1), idx.reshape(-1)], dim=0)\n    dist = d[rows, idx].reshape(-1)\n    return eidx, dist\n\ndef role_knn_edges(xy, roles, sides, k_role):\n    N = xy.size(0); dev=xy.device; dt=xy.dtype\n    if N <= 1:\n        return (torch.empty(2,0,dtype=torch.long,device=dev),\n                torch.empty(0,dtype=dt,device=dev))\n    e_src=[]; e_dst=[]; e_d=[]\n    for s in [0,1]:\n        src_idx = (sides==s).nonzero(as_tuple=False).squeeze(-1)\n        dst_idx = (sides!=s).nonzero(as_tuple=False).squeeze(-1)\n        if src_idx.numel()==0 or dst_idx.numel()==0: continue\n        xy_src = xy[src_idx]; xy_dst=xy[dst_idx]\n        d = torch.cdist(xy_src, xy_dst, p=2)\n        k_eff = min(k_role, xy_dst.size(0))\n        idx = torch.topk(-d, k_eff, dim=1).indices\n        e_src.append(src_idx.unsqueeze(1).expand_as(idx).reshape(-1))\n        e_dst.append(dst_idx[idx].reshape(-1))\n        e_d.append(d.gather(1, idx).reshape(-1))\n    if not e_src:\n        return (torch.empty(2,0,dtype=torch.long,device=dev),\n                torch.empty(0,dtype=dt,device=dev))\n    src = torch.cat(e_src); dst=torch.cat(e_dst); dist=torch.cat(e_d)\n    return torch.stack([src,dst],dim=0), dist\n\ndef build_ball_edges(N, ball_idx, weight=1.0, device=\"cpu\", dtype=torch.float32):\n    players = torch.arange(N, device=device)\n    players = players[players != ball_idx]\n    src1 = torch.full_like(players, ball_idx)\n    dst1 = players.clone()\n    src2 = players.clone()\n    dst2 = torch.full_like(players, ball_idx)\n    edge_index = torch.cat([torch.stack([src1,dst1],dim=0), torch.stack([src2,dst2],dim=0)], dim=1)\n    edge_w = torch.full((edge_index.size(1),), float(weight), device=device, dtype=dtype)\n    return edge_index, edge_w\n","metadata":{},"outputs":[],"execution_count":null},{"id":"96230b9b","cell_type":"markdown","source":"## 5. Dataset and Collate\n\n**EN:** `STPlayDataset` collects the last **L** frames per player and computes static per‑player features at the final observed frame. When training labels are present, it builds the (N × T × 2) future displacement tensor and mask.\n\n**JP:** 最終観測フレームに対する特徴を作成し、学習時は将来位置差分 `(N, T, 2)` とマスクを組み立てます。","metadata":{}},{"id":"e322625c","cell_type":"code","source":"\n# ------------------\n# Dataset\n# ------------------\nclass STPlayDataset(Dataset):\n    def __init__(self, train_input, train_output, L=5, for_train=True):\n        self.L = L\n        self.for_train = for_train\n        df = maybe_flip_direction(train_input.copy())\n        df[\"height_inches\"] = df[\"player_height\"].apply(height_ftin_to_in)\n        self.keys = df.groupby([\"game_id\",\"play_id\"]).size().reset_index()[[\"game_id\",\"play_id\"]].values.tolist()\n        self.tin = df.sort_values([\"game_id\",\"play_id\",\"nfl_id\",\"frame_id\"]).reset_index(drop=True)\n        self.tout = train_output.sort_values([\"game_id\",\"play_id\",\"nfl_id\",\"frame_id\"]).reset_index(drop=True) if for_train else None\n        self.role2id = {k:i for i,k in enumerate(sorted(self.tin[\"player_role\"].fillna(\"Unknown\").unique()))}\n        self.side2id = {k:i for i,k in enumerate(sorted(self.tin[\"player_side\"].fillna(\"Unknown\").unique()))}\n        self.role_dim = len(self.role2id); self.side_dim = len(self.side2id)\n\n    def __len__(self): return len(self.keys)\n\n    def _stack_L(self, g):\n        g = g.sort_values(\"frame_id\")\n        def get(col): return g[col].values if col in g.columns else np.zeros(len(g), np.float32)\n        x,y = get(\"x\"),get(\"y\")\n        s = get(\"s\"); a=get(\"a\")\n        dir_deg = get(\"dir\")\n        vx,vy = s*np.cos(np.deg2rad(dir_deg)), s*np.sin(np.deg2rad(dir_deg))\n        arr = np.stack([x[-self.L:], y[-self.L:], vx[-self.L:], vy[-self.L:], s[-self.L:], a[-self.L:]], 0)\n        if arr.shape[1] < self.L:\n            pad = np.zeros((arr.shape[0], self.L-arr.shape[1]), np.float32)\n            arr = np.concatenate([pad, arr], 1)\n        return arr.astype(np.float32)\n\n    def __getitem__(self, idx):\n        gid, pid = self.keys[idx]\n        tin_gp = self.tin[(self.tin.game_id==gid)&(self.tin.play_id==pid)]\n        last = tin_gp.groupby(\"nfl_id\", as_index=False).last()\n        nfl_ids = last[\"nfl_id\"].values; N=len(nfl_ids)\n\n        seq = [self._stack_L(tin_gp[tin_gp.nfl_id==nid]) for nid in nfl_ids]\n        seq = np.stack(seq, 0)  # (N,6,L)\n\n        final_xy = last[[\"x\",\"y\"]].values.astype(np.float32)\n        s = last[\"s\"].fillna(0).values.astype(np.float32) if \"s\" in last else np.zeros(N,np.float32)\n        a = last[\"a\"].fillna(0).values.astype(np.float32) if \"a\" in last else np.zeros(N,np.float32)\n        dir_deg = last[\"dir\"].fillna(0).values.astype(np.float32) if \"dir\" in last else np.zeros(N,np.float32)\n        o_deg   = last[\"o\"].fillna(0).values.astype(np.float32) if \"o\" in last else np.zeros(N,np.float32)\n        ds, dc = np.sin(np.deg2rad(dir_deg)), np.cos(np.deg2rad(dir_deg))\n        os_, oc= np.sin(np.deg2rad(o_deg)),   np.cos(np.deg2rad(o_deg))\n        height = last[\"height_inches\"].values.astype(np.float32)\n        weight = last[\"player_weight\"].fillna(200).values.astype(np.float32)\n        bmi = (weight/(np.clip(height,1,300)**2))*703.0\n        yardln = last[\"absolute_yardline_number\"].fillna(50).values.astype(np.float32) if \"absolute_yardline_number\" in last else np.full(N,50.0,np.float32)\n        ball_xy = last[[\"ball_land_x\",\"ball_land_y\"]].fillna(0.0).values.astype(np.float32) if {\"ball_land_x\",\"ball_land_y\"}.issubset(last.columns) else np.tile(final_xy.mean(0,keepdims=True),(N,1)).astype(np.float32)\n\n        role_id = np.array([self.role2id.get(v if isinstance(v,str) else \"Unknown\",0) for v in last.get(\"player_role\", pd.Series([\"Unknown\"]*N))], np.int64)\n        side_id = np.array([self.side2id.get(v if isinstance(v,str) else \"Unknown\",0) for v in last.get(\"player_side\", pd.Series([\"Unknown\"]*N))], np.int64)\n\n        out={}\n        if self.for_train:\n            tout = self.tout[(self.tout.game_id==gid)&(self.tout.play_id==pid)].sort_values([\"nfl_id\",\"frame_id\"])\n            groups = tout.groupby(\"nfl_id\")\n            per=[]; Tmax=0\n            for nid in nfl_ids:\n                g = groups.get_group(nid) if nid in groups.groups else None\n                if g is None: per.append(np.zeros((0,2),np.float32)); continue\n                arr = g[[\"x\",\"y\"]].values.astype(np.float32)\n                dxy = arr - final_xy[nfl_ids==nid][0][None,:]\n                per.append(dxy); Tmax=max(Tmax,dxy.shape[0])\n            if CFG.CAP_T and Tmax>CFG.CAP_T: Tmax=CFG.CAP_T\n            tgt=np.zeros((N,Tmax,2),np.float32); msk=np.zeros((N,Tmax),np.float32)\n            for i,d in enumerate(per):\n                t=min(len(d),Tmax)\n                if t>0: tgt[i,:t,:]=d[:t]; msk[i,:t]=1.0\n            out[\"target_dxy\"]=torch.from_numpy(tgt); out[\"tgt_mask\"]=torch.from_numpy(msk); out[\"T_max\"]=Tmax\n\n        batch = {\n            \"game_id\": int(gid), \"play_id\": int(pid), \"nfl_ids\": nfl_ids,\n            \"seq\": torch.from_numpy(seq),\n            \"final_xy\": torch.from_numpy(final_xy),\n            \"s\": torch.from_numpy(s), \"a\": torch.from_numpy(a),\n            \"dir_sin\": torch.from_numpy(ds), \"dir_cos\": torch.from_numpy(dc),\n            \"o_sin\": torch.from_numpy(os_), \"o_cos\": torch.from_numpy(oc),\n            \"height\": torch.from_numpy(height), \"weight\": torch.from_numpy(weight), \"bmi\": torch.from_numpy(bmi),\n            \"yardln\": torch.from_numpy(yardln),\n            \"ball_xy\": torch.from_numpy(ball_xy),\n            \"role_id\": torch.from_numpy(role_id), \"side_id\": torch.from_numpy(side_id),\n        }\n        batch.update(out); return batch\n\ndef st_collate_fn(blist):\n    keys = [\"seq\",\"final_xy\",\"s\",\"a\",\"dir_sin\",\"dir_cos\",\"o_sin\",\"o_cos\",\"height\",\"weight\",\"bmi\",\"yardln\",\"ball_xy\",\"role_id\",\"side_id\"]\n    out={k:torch.cat([b[k] for b in blist],0) for k in keys}\n    out[\"metas\"]=[(b[\"game_id\"],b[\"play_id\"],b[\"nfl_ids\"]) for b in blist]\n    if \"target_dxy\" in blist[0]:\n        Tm=max(b[\"T_max\"] for b in blist); tgt=[]; msk=[]\n        for b in blist:\n            if b[\"target_dxy\"].shape[1]<Tm:\n                pad=(0,0,0,Tm-b[\"target_dxy\"].shape[1]); tgt.append(F.pad(b[\"target_dxy\"],pad)); msk.append(F.pad(b[\"tgt_mask\"],(0,Tm-b[\"tgt_mask\"].shape[1])))\n            else: tgt.append(b[\"target_dxy\"]); msk.append(b[\"tgt_mask\"])\n        out[\"target_dxy\"]=torch.cat(tgt,0); out[\"tgt_mask\"]=torch.cat(msk,0); out[\"T_max\"]=Tm\n    return out\n","metadata":{},"outputs":[],"execution_count":null},{"id":"edcbed56","cell_type":"markdown","source":"## 6. Model: Edge‑Attention Encoder and Temporal Decoder\n\n**EN:** The encoder:  \n- Embeds role/side  \n- Applies **EdgeAttentionLayer** (GATv2‑like) with FP32 inside to avoid AMP instabilities  \n- Aggregates **L** steps via a GRU  \n\nThe decoder:  \n- Conditions on encoder’s last state and predicts future `(x,y)` displacements\n\n**JP:** エンコーダは役割/サイド埋め込み→エッジ注意→GRUで時系列要約。デコーダは将来の `(x,y)` 差分を生成します。","metadata":{}},{"id":"f96dee83","cell_type":"code","source":"\n# ------------------\n# Model\n# ------------------\nclass EdgeAttentionLayer(nn.Module):\n    \"\"\"GATv2風：このレイヤ内部は常にFP32で計算してAMP衝突を回避\"\"\"\n    def __init__(self, node_dim, edge_in, edge_hid):\n        super().__init__()\n        self.edge_mlp = nn.Sequential(\n            nn.Linear(edge_in, edge_hid), nn.ReLU(),\n            nn.Linear(edge_hid, edge_hid), nn.ReLU()\n        )\n        self.msg_mlp = nn.Sequential(\n            nn.Linear(node_dim*2 + edge_hid, node_dim), nn.ReLU(),\n            nn.Linear(node_dim, node_dim)\n        )\n        self.attn = nn.Linear(node_dim, 1)\n\n    def forward(self, h, edge_index, edge_feat):\n        src, dst = edge_index\n        # --- ここからはFP32固定 ---\n        with torch.cuda.amp.autocast(False):\n            h32 = h.float()\n            e32 = edge_feat.float()\n            e = self.edge_mlp(e32)                          # (E, Eh)\n            pair = torch.cat([h32[src], h32[dst], e], -1)   # (E, 2H+Eh)\n            m_ij = self.msg_mlp(pair)                       # (E, H)\n            score = self.attn(torch.tanh(m_ij))             # (E, 1)\n\n            N = h32.size(0)\n            max_per_dst = torch.full((N,1), -float('inf'), dtype=torch.float32, device=h.device)\n            max_per_dst.index_reduce_(0, dst, score, reduce=\"amax\")\n\n            norm = torch.exp(score - max_per_dst[dst])\n            sum_per_dst = torch.zeros(N,1, dtype=torch.float32, device=h.device)\n            sum_per_dst.index_add_(0, dst, norm)\n            alpha = norm / (sum_per_dst[dst] + 1e-9)        # (E,1)\n\n            agg32 = torch.zeros(N, h32.size(1), dtype=torch.float32, device=h.device)\n            agg32.index_add_(0, dst, alpha * m_ij)\n        # 戻りは元のdtypeに合わせる\n        return agg32.to(h.dtype)\n\nclass STEncoder(nn.Module):\n    def __init__(self, node_in, role_dim, side_dim, hid, edge_in, edge_hid, L):\n        super().__init__()\n        self.emb_role = nn.Embedding(role_dim, CFG.ROLE_EMB)\n        self.emb_side = nn.Embedding(side_dim, CFG.SIDE_EMB)\n        self.pre = nn.Sequential(\n            nn.Linear(node_in + CFG.ROLE_EMB + CFG.SIDE_EMB, hid),\n            nn.ReLU(), nn.Linear(hid, hid), nn.ReLU()\n        )\n        self.layers = nn.ModuleList([EdgeAttentionLayer(hid, edge_in, edge_hid) for _ in range(CFG.MP_LAYERS)])\n        self.gru = nn.GRU(input_size=hid, hidden_size=hid, num_layers=1, batch_first=True)\n        self.L = L\n\n    def forward(self, node_feat_t_list, role_id, side_id, edges_t_list, efeat_t_list):\n        e_role = self.emb_role(role_id); e_side = self.emb_side(side_id)\n        hs=[]\n        for t in range(self.L):\n            x = torch.cat([node_feat_t_list[t], e_role, e_side], dim=-1)\n            h = self.pre(x)\n            for layer in self.layers:\n                h = h + layer(h, edges_t_list[t], efeat_t_list[t])  # residual\n            hs.append(h.unsqueeze(1))\n        seq = torch.cat(hs, dim=1)         # (N, L, H)\n        out, _ = self.gru(seq)             # (N, L, H)\n        return out[:, -1, :], out\n\nclass TemporalDecoder(nn.Module):\n    def __init__(self, hid, dec_hid):\n        super().__init__()\n        self.h0 = nn.Linear(hid, dec_hid)\n        self.gru = nn.GRU(input_size=hid, hidden_size=dec_hid, num_layers=1, batch_first=True)\n        self.head = nn.Sequential(nn.Linear(dec_hid, dec_hid), nn.ReLU(), nn.Linear(dec_hid, 2))\n    def forward(self, cond_seq, H_last):\n        h0 = self.h0(H_last).unsqueeze(0)\n        out, _ = self.gru(cond_seq, h0)\n        return self.head(out)\n\nclass STGNNModel(nn.Module):\n    def __init__(self):\n        super().__init__()\n        # 直近Lフレームの粗い運動埋め込み (6,L)->16\n        self.seq_conv = nn.Sequential(\n            nn.Conv1d(6, 16, kernel_size=3, padding=1),\n            nn.ReLU(),\n            nn.Conv1d(16, 16, kernel_size=3, padding=1),\n            nn.ReLU(),\n            nn.AdaptiveAvgPool1d(1)\n        )\n        # Edge feature 次元（build_edges_one_tと合わせる）\n        self.edge_in = 10\n        self.encoder=None; self.decoder=None  # 遅延初期化\n\n    def build_node_feat(self, batch):\n        seq = batch[\"seq\"].to(CFG.DEVICE)                 # (N,6,L)\n        emb = self.seq_conv(seq).squeeze(-1)              # (N,16)\n        final_xy = batch[\"final_xy\"].to(CFG.DEVICE)\n        s = batch[\"s\"].to(CFG.DEVICE).unsqueeze(-1)\n        a = batch[\"a\"].to(CFG.DEVICE).unsqueeze(-1)\n        ds = batch[\"dir_sin\"].to(CFG.DEVICE).unsqueeze(-1)\n        dc = batch[\"dir_cos\"].to(CFG.DEVICE).unsqueeze(-1)\n        os_ = batch[\"o_sin\"].to(CFG.DEVICE).unsqueeze(-1)\n        oc = batch[\"o_cos\"].to(CFG.DEVICE).unsqueeze(-1)\n        height = batch[\"height\"].to(CFG.DEVICE).unsqueeze(-1)\n        weight = batch[\"weight\"].to(CFG.DEVICE).unsqueeze(-1)\n        bmi    = batch[\"bmi\"].to(CFG.DEVICE).unsqueeze(-1)\n        yardln = batch[\"yardln\"].to(CFG.DEVICE).unsqueeze(-1)\n        ball_xy= batch[\"ball_xy\"].to(CFG.DEVICE)\n\n        ball_vec = ball_xy - final_xy\n        ball_dist = ball_vec.norm(dim=-1, keepdim=True).clamp(min=1e-6)\n        ball_dir = ball_vec / ball_dist\n        bdx, bdy = ball_vec[...,0:1], ball_vec[...,1:2]\n        bds, bdc = ball_dir[...,0:1], ball_dir[...,1:2]\n\n        # + 時間PE（末時刻tのPEを定数として結合）\n        pe = time_pos_encoding(torch.tensor([1.0], device=final_xy.device)).repeat(final_xy.size(0),1)  # (N,8)\n\n        node = torch.cat([\n            final_xy, s, a, ds, dc, os_, oc, height, weight, bmi, yardln,\n            bdx, bdy, ball_dist, bds, bdc, emb, pe\n        ], dim=-1)\n        return node  # (N, Din)\n\n    def build_edges_one_t(self, final_xy, s, dir_sin, dir_cos, side_id, role_id):\n        e_knn, d_knn = knn_edges(final_xy, CFG.K_NEIGHBORS)\n        e_role, d_role = role_knn_edges(final_xy, role_id, side_id, CFG.K_ROLE)\n        if e_role.numel()>0:\n            eidx = torch.cat([e_knn, e_role], dim=1); dist = torch.cat([d_knn, d_role], dim=0)\n        else:\n            eidx, dist = e_knn, d_knn\n\n        vx = s*dir_cos; vy = s*dir_sin\n        src, dst = eidx\n        dx = (final_xy[src,0] - final_xy[dst,0]).unsqueeze(-1)\n        dy = (final_xy[src,1] - final_xy[dst,1]).unsqueeze(-1)\n        dvx = (vx[src] - vx[dst]).unsqueeze(-1)\n        dvy = (vy[src] - vy[dst]).unsqueeze(-1)\n        distv = dist.unsqueeze(-1).clamp(min=1e-6)\n\n        rel = torch.cat([dx,dy], -1)\n        rel_n = rel / (rel.norm(dim=-1, keepdim=True).clamp(min=1e-6))\n        vdst = torch.cat([vx[dst].unsqueeze(-1), vy[dst].unsqueeze(-1)], -1)\n        vdst_n = vdst / (vdst.norm(dim=-1, keepdim=True).clamp(min=1e-6))\n        cos_pos = (rel_n * vdst_n).sum(-1, keepdim=True)\n\n        vsrc = torch.cat([vx[src].unsqueeze(-1), vy[src].unsqueeze(-1)], -1)\n        vsrc_n = vsrc / (vsrc.norm(dim=-1, keepdim=True).clamp(min=1e-6))\n        cos_vel = (vsrc_n * vdst_n).sum(-1, keepdim=True)\n\n        same_team = (side_id[src]==side_id[dst]).float().unsqueeze(-1)\n        off_to_def = ((side_id[src]==1)&(side_id[dst]==0)).float().unsqueeze(-1)\n        def_to_off = ((side_id[src]==0)&(side_id[dst]==1)).float().unsqueeze(-1)\n\n        efeat = torch.cat([dx,dy,dvx,dvy,distv,cos_pos,cos_vel,same_team,off_to_def,def_to_off], -1)\n        return eidx.to(CFG.DEVICE), efeat.to(CFG.DEVICE)\n\n    def add_ball_node(self, node, final_xy):\n        ball_xy = final_xy.mean(dim=0, keepdim=True)\n        ball_feat = torch.zeros_like(node[:1])\n        ball_feat[:, :2] = ball_xy\n        node2 = torch.cat([node, ball_feat], dim=0)\n        ball_idx = node2.size(0)-1\n        return node2, ball_idx\n\n    def forward(self, batch, T):\n        role_id = batch[\"role_id\"].to(CFG.DEVICE)\n        side_id = batch[\"side_id\"].to(CFG.DEVICE)\n        dir_sin = batch[\"dir_sin\"].to(CFG.DEVICE)\n        dir_cos = batch[\"dir_cos\"].to(CFG.DEVICE)\n        s = batch[\"s\"].to(CFG.DEVICE)\n        final_xy = batch[\"final_xy\"].to(CFG.DEVICE)\n\n        node = self.build_node_feat(batch)              # (N, Din)\n        Din = node.size(-1)\n\n        eidx, efeat = self.build_edges_one_t(final_xy, s, dir_sin, dir_cos, side_id, role_id)\n\n        node_ball, ball_idx = self.add_ball_node(node, final_xy)   # (N+1, Din)\n        e_ball, _ = build_ball_edges(node_ball.size(0), ball_idx, weight=CFG.BALL_EDGE_WEIGHT,\n                                     device=node_ball.device, dtype=node_ball.dtype)\n        efeat_ball = torch.zeros((e_ball.size(1), self.edge_in), device=node_ball.device, dtype=node_ball.dtype)\n\n        eidx = torch.cat([eidx, e_ball], dim=1)\n        efeat = torch.cat([efeat, efeat_ball], dim=0)\n\n        # Lスライスに同一ノード（簡易）。必要なら各tで再構築に拡張可\n        node_t_list = [node_ball for _ in range(CFG.L_HIST)]\n        edges_t_list = [eidx for _ in range(CFG.L_HIST)]\n        efeat_t_list = [efeat for _ in range(CFG.L_HIST)]\n\n        # 遅延初期化（role/sideの語彙数は+1でballを含める）\n        if self.encoder is None:\n            node_in = Din\n            self.encoder = STEncoder(node_in=node_in,\n                                     role_dim=int(role_id.max().item())+2,\n                                     side_dim=int(side_id.max().item())+2,\n                                     hid=CFG.NODE_HID, edge_in=self.edge_in, edge_hid=CFG.EDGE_HID, L=CFG.L_HIST).to(CFG.DEVICE)\n            self.decoder = TemporalDecoder(hid=CFG.NODE_HID, dec_hid=CFG.DEC_HID).to(CFG.DEVICE)\n\n        # ballノードのIDをrole/sideに追加（0番をball想定）\n        role_ext = torch.cat([role_id, torch.zeros(1, device=role_id.device, dtype=role_id.dtype)], dim=0)\n        side_ext = torch.cat([side_id, torch.zeros(1, device=side_id.device, dtype=side_id.dtype)], dim=0)\n\n        H_last, _ = self.encoder(node_t_list, role_ext, side_ext, edges_t_list, efeat_t_list)\n\n        tt = torch.arange(1, T+1, device=H_last.device, dtype=H_last.dtype)\n        pe = time_pos_encoding(tt/T).unsqueeze(0).repeat(H_last.size(0),1,1)   # (N+1,T,8)\n        node_cond = H_last.unsqueeze(1).repeat(1, T, 1)                         # (N+1,T,H)\n        cond_seq = node_cond  # 必要に応じて pe を結合: torch.cat([node_cond, pe], -1)\n\n        dxy = self.decoder(cond_seq, H_last)  # (N+1,T,2)\n        dxy = dxy[:-1]  # drop ball\n        return dxy\n","metadata":{},"outputs":[],"execution_count":null},{"id":"075e7c04","cell_type":"markdown","source":"## 7. Losses and Training / Evaluation Loops\n\n**EN:**  \n- Base loss: MSE on future displacements (optionally end‑weighted).  \n- Physics residual (optional): compares against linear motion from current velocity.  \n- Speed penalty (optional): penalizes speeds above `MAX_SPEED`.\n\n**JP:**  \n- 基本損失は将来差分のMSE（終端重み付け可）  \n- 物理残差（線形速度との差）と速度違反ペナルティを加算可能  \n","metadata":{}},{"id":"8d87954e","cell_type":"code","source":"\n# ------------------\n# Loss & Train/Eval\n# ------------------\ndef end_weights(T, dtype=torch.float32):\n    w = torch.arange(1, T+1, device=CFG.DEVICE, dtype=dtype) / T\n    return w / w.mean()\n\ndef velocity_clip(pred_dxy, fps, max_speed):\n    v = pred_dxy.norm(dim=-1) * fps\n    over = (v - max_speed).clamp(min=0.0)\n    return over.mean()\n\ndef train_one_epoch(model, loader, optim, scaler):\n    model.train(); total=0.0\n    optim.zero_grad(set_to_none=True)\n    for step, batch in enumerate(tqdm(loader, leave=False), start=1):\n        for k in [\"seq\",\"final_xy\",\"s\",\"a\",\"dir_sin\",\"dir_cos\",\"o_sin\",\"o_cos\",\n                  \"height\",\"weight\",\"bmi\",\"yardln\",\"ball_xy\",\"role_id\",\"side_id\",\n                  \"target_dxy\",\"tgt_mask\"]:\n            batch[k] = batch[k].to(CFG.DEVICE, non_blocking=True)\n        T = batch[\"T_max\"]\n        if CFG.CAP_T and T>CFG.CAP_T:\n            batch[\"target_dxy\"]=batch[\"target_dxy\"][:,:CFG.CAP_T,...]\n            batch[\"tgt_mask\"]=batch[\"tgt_mask\"][:,:CFG.CAP_T,...]\n            T = CFG.CAP_T\n\n        with torch.cuda.amp.autocast(enabled=CFG.AMP):\n            pred = model(batch, T)                    # (N,T,2)\n            msk = batch[\"tgt_mask\"].unsqueeze(-1)    # (N,T,1)\n\n            diff = (pred - batch[\"target_dxy\"]) * msk\n            core = (diff**2).sum() / (msk.sum()*2 + 1e-6)\n            if CFG.END_WEIGHTED:\n                w = end_weights(T, dtype=pred.dtype).view(1,-1,1)\n                core = ((diff**2)*w).sum() / (msk.sum()*2 + 1e-6)\n\n            if CFG.PHYS_RESID_ALPHA>0:\n                vx = batch[\"s\"]*batch[\"dir_cos\"]; vy=batch[\"s\"]*batch[\"dir_sin\"]\n                vxy = torch.stack([vx,vy], dim=-1)           # (N,2)\n                ts = torch.arange(1, T+1, device=pred.device, dtype=pred.dtype)\n                base = vxy.unsqueeze(1) * (ts.view(1,-1,1)/CFG.FPS)\n                resid = (((pred - base) - (batch[\"target_dxy\"] - base))*msk)**2\n                resid = resid.sum() / (msk.sum()*2 + 1e-6)\n                core = core + CFG.PHYS_RESID_ALPHA*resid\n\n            if CFG.SPEED_PENALTY>0:\n                pen = velocity_clip(pred, fps=CFG.FPS, max_speed=CFG.MAX_SPEED)\n                core = core + CFG.SPEED_PENALTY*pen\n\n        scaler.scale(core/CFG.ACCUM_STEPS).backward()\n        if step % CFG.ACCUM_STEPS == 0:\n            if CFG.GRAD_CLIP:\n                scaler.unscale_(optim)\n                nn.utils.clip_grad_norm_(model.parameters(), CFG.GRAD_CLIP)\n            scaler.step(optim); scaler.update()\n            optim.zero_grad(set_to_none=True)\n        total += core.item()\n    return total / max(len(loader),1)\n\n@torch.no_grad()\ndef evaluate(model, loader, max_batches=30):\n    model.eval(); rmse_sum=0.0; cnt=0\n    ys=[]; ps=[]\n    for bi, batch in enumerate(tqdm(loader, leave=False)):\n        for k in [\"seq\",\"final_xy\",\"s\",\"a\",\"dir_sin\",\"dir_cos\",\"o_sin\",\"o_cos\",\n                  \"height\",\"weight\",\"bmi\",\"yardln\",\"ball_xy\",\"role_id\",\"side_id\",\n                  \"target_dxy\",\"tgt_mask\"]:\n            batch[k] = batch[k].to(CFG.DEVICE, non_blocking=True)\n        T = batch[\"T_max\"]\n        if CFG.CAP_T and T>CFG.CAP_T:\n            batch[\"target_dxy\"]=batch[\"target_dxy\"][:,:CFG.CAP_T,...]\n            batch[\"tgt_mask\"]=batch[\"tgt_mask\"][:,:CFG.CAP_T,...]\n            T = CFG.CAP_T\n        pred = model(batch, T)\n        diff = (pred - batch[\"target_dxy\"]) * batch[\"tgt_mask\"].unsqueeze(-1)\n        mse = (diff**2).sum() / (batch[\"tgt_mask\"].sum()*2 + 1e-6)\n        rmse = torch.sqrt(mse).item()\n        rmse_sum += rmse; cnt += 1\n        if bi < max_batches:\n            ys.append(batch[\"target_dxy\"][batch[\"tgt_mask\"].bool()].view(-1,2).detach().cpu().numpy())\n            ps.append(pred[batch[\"tgt_mask\"].bool()].view(-1,2).detach().cpu().numpy())\n    y = np.concatenate(ys,0) if ys else np.zeros((0,2))\n    p = np.concatenate(ps,0) if ps else np.zeros((0,2))\n    return rmse_sum/max(cnt,1), y, p\n","metadata":{},"outputs":[],"execution_count":null},{"id":"309b20fc","cell_type":"markdown","source":"## 8. Train/Validation Split and Dataloaders\n\n**EN:** Randomly split plays into train/validation and build PyTorch dataloaders with the custom collate.  \n\n**JP:** プレイ単位でランダム分割し、`st_collate_fn` を用いた DataLoader を作成します。","metadata":{}},{"id":"f5d28650","cell_type":"code","source":"\n# ------------------\n# Split / Loader\n# ------------------\ndef split_train_valid_keys(all_keys, valid_ratio=0.1):\n    idx = np.arange(len(all_keys)); rng=np.random.RandomState(CFG.SEED); rng.shuffle(idx)\n    n_valid=max(1,int(len(idx)*valid_ratio)); va=set(idx[:n_valid].tolist())\n    tr,vl=[],[]\n    for i,k in enumerate(all_keys): (vl if i in va else tr).append(k)\n    return tr,vl\n\nclass SubsetPlay(Dataset):\n    def __init__(self, base, keys): self.base=base; self.keys=keys; self.map={tuple(k):i for i,k in enumerate(base.keys)}\n    def __len__(self): return len(self.keys)\n    def __getitem__(self,i): return self.base[self.map[tuple(self.keys[i])]]\n\ndef make_loader(ds, bsz, shuffle):\n    return DataLoader(ds, batch_size=bsz, shuffle=shuffle, collate_fn=st_collate_fn, num_workers=0, pin_memory=CFG.USE_CUDA)\n","metadata":{},"outputs":[],"execution_count":null},{"id":"9b738c49","cell_type":"markdown","source":"## 9. Main: Training → Validation → Test Inference → Submission\n\n**EN:**  \n- Warm forward pass triggers lazy initialization (embeddings depend on observed role/side vocab).  \n- Optional `DataParallel` when ≥2 GPUs are available.  \n- Test phase follows the template to produce `submission.csv` (also saved under `runs/`).\n\n**JP:**  \n- ウォーム実行で遅延初期化（役割/サイド辞書サイズが観測に依存）  \n- 2GPU以上なら自動DP化  \n- テストはテンプレ構造に従って `submission.csv` を生成します。","metadata":{}},{"id":"374d84cd","cell_type":"code","source":"\n# ------------------\n# Train → Eval → Predict → Submission\n# ------------------\ndef main():\n    print(\"Loading train/test...\")\n    train_in, train_out = load_train_input_output()\n    test_in, test_tpl, sample_sub = load_test_input_and_templates()\n\n    full = STPlayDataset(train_in, train_out, L=CFG.L_HIST, for_train=True)\n    tr_keys, va_keys = split_train_valid_keys(full.keys, valid_ratio=0.1)\n    tr_ds, va_ds = SubsetPlay(full, tr_keys), SubsetPlay(full, va_keys)\n    tr_loader = make_loader(tr_ds, CFG.BATCH_PLAYS, True)\n    va_loader = make_loader(va_ds, CFG.BATCH_PLAYS, False)\n\n    print(f\"roles={full.role_dim}, sides={full.side_dim}\")\n    warm = next(iter(tr_loader))\n\n    model = STGNNModel().to(CFG.DEVICE)\n    # Warm forward（遅延初期化）\n    with torch.cuda.amp.autocast(enabled=CFG.AMP):\n        _ = model({k:(v.to(CFG.DEVICE) if torch.is_tensor(v) else v) for k,v in warm.items()}, T=warm[\"T_max\"])\n\n    if torch.cuda.device_count()>=2:\n        print(f\"Using {torch.cuda.device_count()} GPUs (DP)\")\n        model = nn.DataParallel(model)\n\n    optim = torch.optim.AdamW(model.parameters(), lr=CFG.LR, weight_decay=CFG.WEIGHT_DECAY)\n    scaler = torch.cuda.amp.GradScaler(enabled=CFG.AMP)\n\n    print(\"Start training...\")\n    for ep in range(1, CFG.EPOCHS+1):\n        tr_loss = train_one_epoch(model, tr_loader, optim, scaler)\n        val_rmse, y_true, y_pred = evaluate(model, va_loader, max_batches=20)\n        print(f\"[Epoch {ep}] train={tr_loss:.5f}  valid_RMSE={val_rmse:.5f}\")\n        gc.collect(); \n        if CFG.USE_CUDA: torch.cuda.empty_cache()\n\n    # ---- Test inference ----\n    print(\"Preparing test...\")\n    tin = maybe_flip_direction(test_in.copy())\n    tin[\"height_inches\"] = tin[\"player_height\"].apply(height_ftin_to_in) if \"player_height\" in tin.columns else 70\n    pred_rows=[]; collect=[]\n\n    plays = test_tpl.groupby([\"game_id\",\"play_id\"])[\"frame_id\"].max().reset_index().values.tolist()\n    for gid, pid, Tmax in tqdm(plays, desc=\"test plays\"):\n        g = tin[(tin.game_id==gid)&(tin.play_id==pid)].sort_values([\"nfl_id\",\"frame_id\"])\n        if g.empty: continue\n        last = g.groupby(\"nfl_id\", as_index=False).last()\n        nfl_ids = last[\"nfl_id\"].values; N=len(nfl_ids)\n\n        seq=[]\n        for nid in nfl_ids:\n            gg = g[g.nfl_id==nid].sort_values(\"frame_id\")\n            x,y = gg[\"x\"].values, gg[\"y\"].values\n            s = gg[\"s\"].values if \"s\" in gg else np.zeros(len(gg),np.float32)\n            a = gg[\"a\"].values if \"a\" in gg else np.zeros(len(gg),np.float32)\n            dir_deg = gg[\"dir\"].values if \"dir\" in gg else np.zeros(len(gg),np.float32)\n            vx,vy = s*np.cos(np.deg2rad(dir_deg)), s*np.sin(np.deg2rad(dir_deg))\n            arr = np.stack([x[-CFG.L_HIST:],y[-CFG.L_HIST:],vx[-CFG.L_HIST:],vy[-CFG.L_HIST:],s[-CFG.L_HIST:],a[-CFG.L_HIST:]],0)\n            if arr.shape[1]<CFG.L_HIST:\n                pad=np.zeros((arr.shape[0], CFG.L_HIST-arr.shape[1]), np.float32)\n                arr=np.concatenate([pad,arr],1)\n            seq.append(arr.astype(np.float32))\n        seq=np.stack(seq,0)\n\n        final_xy = last[[\"x\",\"y\"]].values.astype(np.float32)\n        s = last[\"s\"].fillna(0).values.astype(np.float32) if \"s\" in last else np.zeros(N,np.float32)\n        a = last[\"a\"].fillna(0).values.astype(np.float32) if \"a\" in last else np.zeros(N,np.float32)\n        dir_deg = last[\"dir\"].fillna(0).values.astype(np.float32) if \"dir\" in last else np.zeros(N,np.float32)\n        o_deg   = last[\"o\"].fillna(0).values.astype(np.float32) if \"o\" in last else np.zeros(N,np.float32)\n        ds,dc = np.sin(np.deg2rad(dir_deg)), np.cos(np.deg2rad(dir_deg))\n        os_,oc= np.sin(np.deg2rad(o_deg)),   np.cos(np.deg2rad(o_deg))\n        height = last[\"height_inches\"].values.astype(np.float32) if \"height_inches\" in last else np.full(N,70,np.float32)\n        weight = last[\"player_weight\"].fillna(200).values.astype(np.float32) if \"player_weight\" in last else np.full(N,200,np.float32)\n        bmi = (weight/(np.clip(height,1,300)**2))*703.0\n        yardln = last[\"absolute_yardline_number\"].fillna(50).values.astype(np.float32) if \"absolute_yardline_number\" in last else np.full(N,50,np.float32)\n        ball_xy = last[[\"ball_land_x\",\"ball_land_y\"]].fillna(0.0).values.astype(np.float32) if {\"ball_land_x\",\"ball_land_y\"}.issubset(last.columns) else np.tile(final_xy.mean(0,keepdims=True),(N,1)).astype(np.float32)\n\n        # role/side ID（test側は未知を0でOK）\n        role_map = {k:i for i,k in enumerate(sorted(tin[\"player_role\"].fillna(\"Unknown\").unique()))} if \"player_role\" in tin else {\"Unknown\":0}\n        side_map = {k:i for i,k in enumerate(sorted(tin[\"player_side\"].fillna(\"Unknown\").unique()))} if \"player_side\" in tin else {\"Unknown\":0}\n        role_id = np.array([role_map.get(v if isinstance(v,str) else \"Unknown\",0) for v in last.get(\"player_role\", pd.Series([\"Unknown\"]*N))], np.int64)\n        side_id = np.array([side_map.get(v if isinstance(v,str) else \"Unknown\",0) for v in last.get(\"player_side\", pd.Series([\"Unknown\"]*N))], np.int64)\n\n        batch = {\n            \"seq\": torch.from_numpy(seq).to(CFG.DEVICE),\n            \"final_xy\": torch.from_numpy(final_xy).to(CFG.DEVICE),\n            \"s\": torch.from_numpy(s).to(CFG.DEVICE),\n            \"a\": torch.from_numpy(a).to(CFG.DEVICE),\n            \"dir_sin\": torch.from_numpy(ds).to(CFG.DEVICE),\n            \"dir_cos\": torch.from_numpy(dc).to(CFG.DEVICE),\n            \"o_sin\": torch.from_numpy(os_).to(CFG.DEVICE),\n            \"o_cos\": torch.from_numpy(oc).to(CFG.DEVICE),\n            \"height\": torch.from_numpy(height).to(CFG.DEVICE),\n            \"weight\": torch.from_numpy(weight).to(CFG.DEVICE),\n            \"bmi\": torch.from_numpy(bmi).to(CFG.DEVICE),\n            \"yardln\": torch.from_numpy(yardln).to(CFG.DEVICE),\n            \"ball_xy\": torch.from_numpy(ball_xy).to(CFG.DEVICE),\n            \"role_id\": torch.from_numpy(role_id).to(CFG.DEVICE),\n            \"side_id\": torch.from_numpy(side_id).to(CFG.DEVICE),\n        }\n        model.eval()\n        T = int(Tmax); \n        if CFG.CAP_T and T>CFG.CAP_T: T=CFG.CAP_T\n        with torch.no_grad():\n            dxy = model(batch, T)              # (N,T,2)\n        abs_xy = clip_to_field(torch.from_numpy(final_xy).to(CFG.DEVICE).unsqueeze(1) + dxy).cpu().numpy()\n        for i in range(abs_xy.shape[0]):\n            abs_xy[i,:,0] = gaussian_filter1d(abs_xy[i,:,0], sigma=CFG.SMOOTH_SIGMA)\n            abs_xy[i,:,1] = gaussian_filter1d(abs_xy[i,:,1], sigma=CFG.SMOOTH_SIGMA)\n\n        collect.append(abs_xy.reshape(-1,2))\n        gtpl = test_tpl[(test_tpl.game_id==gid)&(test_tpl.play_id==pid)].sort_values([\"nfl_id\",\"frame_id\"])\n        mapping = {nid:i for i,nid in enumerate(nfl_ids)}\n        for _, r in gtpl.iterrows():\n            i = mapping.get(r[\"nfl_id\"], None)\n            if i is None: x,y = final_xy[0,0], final_xy[0,1]\n            else:\n                f = int(r[\"frame_id\"])-1; f = max(0, min(f, abs_xy.shape[1]-1))\n                x,y = abs_xy[i,f,0], abs_xy[i,f,1]\n            rid = f\"{int(r['game_id'])}_{int(r['play_id'])}_{int(r['nfl_id'])}_{int(r['frame_id'])}\"\n            pred_rows.append((rid, x, y))\n\n    pred_df = pd.DataFrame(pred_rows, columns=[\"id\",\"x\",\"y\"])\n    submission = sample_sub[[\"id\"]].merge(pred_df, on=\"id\", how=\"left\")\n    mean_x = float(submission[\"x\"].mean(skipna=True)) if submission[\"x\"].notna().any() else (CFG.FIELD_X_MIN+CFG.FIELD_X_MAX)/2\n    mean_y = float(submission[\"y\"].mean(skipna=True)) if submission[\"y\"].notna().any() else (CFG.FIELD_Y_MIN+CFG.FIELD_Y_MAX)/2\n    submission[\"x\"] = submission[\"x\"].fillna(mean_x).clip(CFG.FIELD_X_MIN, CFG.FIELD_X_MAX)\n    submission[\"y\"] = submission[\"y\"].fillna(mean_y).clip(CFG.FIELD_Y_MIN, CFG.FIELD_Y_MAX)\n    Path(\"/kaggle/working\").mkdir(parents=True, exist_ok=True)\n    kaggle_out = \"/kaggle/working/submission.csv\"\n    submission[[\"id\",\"x\",\"y\"]].to_csv(kaggle_out, index=False)\n    local_out = CFG.OUT_DIR / \"submission.csv\"\n    submission[[\"id\",\"x\",\"y\"]].to_csv(local_out, index=False)\n    print(f\"✅ Saved: {kaggle_out} / {local_out}  shape={submission.shape}\")\n\nif __name__ == \"__main__\":\n    main()\n","metadata":{},"outputs":[],"execution_count":null},{"id":"3e8ee994","cell_type":"markdown","source":"---\n\n### 10. Notes / Tips\n\n- **Reproducibility:** Seeds are set for Python, NumPy, and Torch.  \n- **AMP Safety:** Edge‑attention runs in FP32 internally to avoid AMP over/underflow artifacts.  \n- **Scalability:** You can increase `BATCH_PLAYS` and `ACCUM_STEPS` based on GPU memory.  \n- **Physics priors:** `PHYS_RESID_ALPHA` and `SPEED_PENALTY` can be tuned per roster/play style.\n\n**JP補足:** 物理正則化や速度ペナルティは汎用的な安全バイアスです。ドメインに合わせて係数を微調整してください。\n","metadata":{}}]}