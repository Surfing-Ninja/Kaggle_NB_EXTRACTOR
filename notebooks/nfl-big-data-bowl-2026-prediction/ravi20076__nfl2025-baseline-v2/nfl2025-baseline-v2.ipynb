{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":114239,"databundleVersionId":13825858,"sourceType":"competition"}],"dockerImageVersionId":31089,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **FOREWORD**\n\nThis is my version of the NFL Big Data Bowl 2026 Prediction baseline model, developing from the source [here](https://www.kaggle.com/code/hiwe0305/nfl-big-data-baseline). This one scores 0.94 on the leaderboard. \n\nWhat I do here-\n- I extend this work by customizing the seed. This is a good way to add a bit of diversity to the solution.","metadata":{}},{"cell_type":"code","source":"%%time \n\nimport torch\nimport os, math, gc, random\nimport numpy as np, pandas as pd\nimport numpy as np\nimport pandas as pd\nfrom tqdm.notebook import tqdm\n\nfrom sklearn.model_selection import GroupKFold\nfrom sklearn.linear_model import RidgeCV\nfrom sklearn.metrics import mean_squared_error\n\ntry:\n    from lightgbm import LGBMRegressor\n    HAS_LGBM = True\nexcept Exception:\n    LGBMRegressor = None\n    HAS_LGBM = False\n\ntry:\n    from xgboost import XGBRegressor\n    HAS_XGB = True\nexcept Exception:\n    XGBRegressor = None\n    HAS_XGB = False\n\ntry:\n    from catboost import CatBoostRegressor\n    HAS_CAT = True\nexcept Exception:\n    CatBoostRegressor = None\n    HAS_CAT = False\n\nprint(f\"HAS_LGBM={HAS_LGBM}  HAS_XGB={HAS_XGB}  HAS_CAT={HAS_CAT}\")","metadata":{"trusted":true,"_kg_hide-input":true,"execution":{"iopub.status.busy":"2025-09-26T09:15:11.656564Z","iopub.execute_input":"2025-09-26T09:15:11.656823Z","iopub.status.idle":"2025-09-26T09:15:30.710943Z","shell.execute_reply.started":"2025-09-26T09:15:11.656799Z","shell.execute_reply":"2025-09-26T09:15:30.710241Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"SEED = 42\nrng  = np.random.default_rng(SEED)\nrandom.seed(SEED) \nnp.random.seed(SEED)\n\ntest_req = False\nif test_req :\n    nest = 10\nelse:\n    nest = 2500","metadata":{"trusted":true,"_kg_hide-input":true,"execution":{"iopub.status.busy":"2025-09-26T09:15:30.711834Z","iopub.execute_input":"2025-09-26T09:15:30.71236Z","iopub.status.idle":"2025-09-26T09:15:30.71723Z","shell.execute_reply.started":"2025-09-26T09:15:30.712338Z","shell.execute_reply":"2025-09-26T09:15:30.716405Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **PREPROCESSING**","metadata":{}},{"cell_type":"code","source":"%%time \n\nFIELD_X_MIN, FIELD_X_MAX = 0.0, 120.0\nFIELD_Y_MIN, FIELD_Y_MAX = 0.0, 53.3\n\nDATA_DIR = \"/kaggle/input/nfl-big-data-bowl-2026-prediction/\"\nTRAIN_IN_FILES  = [f\"{DATA_DIR}train/input_2023_w{w:02d}.csv\"  for w in range(1,19)]\nTRAIN_OUT_FILES = [f\"{DATA_DIR}train/output_2023_w{w:02d}.csv\" for w in range(1,19)]\nTEST_INPUT_PATH   = f\"{DATA_DIR}test_input.csv\"\nTEST_TARGETS_PATH = f\"{DATA_DIR}test.csv\"\n\ndef height_to_inches(ht):\n    if isinstance(ht, str) and \"-\" in ht:\n        f, ins = ht.split(\"-\")\n        return int(f)*12 + int(ins)\n    return np.nan\n\ndef prepareLast(df_in: pd.DataFrame) -> pd.DataFrame:\n    df_last = df_in.sort_values([\"game_id\",\"play_id\",\"nfl_id\",\"frame_id\"]) \\\n                   .groupby([\"game_id\",\"play_id\",\"nfl_id\"], as_index=False).last()\n    return df_last.rename(columns={\"x\":\"x_last\",\"y\":\"y_last\"})\n\ndef inject_target_receiver_xy(df_last: pd.DataFrame) -> pd.DataFrame:\n    trg = df_last[df_last[\"player_role\"]==\"Targeted Receiver\"] \\\n            [[\"game_id\",\"play_id\",\"x_last\",\"y_last\"]] \\\n            .rename(columns={\"x_last\":\"target_x\",\"y_last\":\"target_y\"})\n    return df_last.merge(trg, on=[\"game_id\",\"play_id\"], how=\"left\")\n\ndef add_features(df: pd.DataFrame, is_train=True) -> pd.DataFrame:\n    # time\n    df[\"frame_offset\"] = df[\"frame_id\"].astype(float)\n    df[\"time_offset\"]  = df[\"frame_offset\"] / 10.0\n    df[\"T\"] = np.clip(df[\"num_frames_output\"].astype(float), 1.0, None)\n    df[\"t_rel\"] = df[\"frame_offset\"] / df[\"T\"]\n\n    # dist/angle to ball\n    dx_ball = df[\"ball_land_x\"] - df[\"x_last\"]\n    dy_ball = df[\"ball_land_y\"] - df[\"y_last\"]\n    dist = np.sqrt(dx_ball**2 + dy_ball**2).astype(float)\n    ang  = np.arctan2(dy_ball, dx_ball).astype(float)\n    df[\"dist_to_ball\"] = dist\n    df[\"sin_ab\"] = np.sin(ang); df[\"cos_ab\"] = np.cos(ang)\n\n    # target receiver\n    df[\"dist_to_target\"] = np.sqrt((df[\"target_x\"]-df[\"x_last\"])**2 + (df[\"target_y\"]-df[\"y_last\"])**2)\n    df[\"is_target\"] = (df[\"player_role\"]==\"Targeted Receiver\").astype(int)\n\n    # velocity components (dir in degrees with data convention)\n    dir_rad = np.deg2rad(df[\"dir\"].astype(float))\n    df[\"speed_x\"] = df[\"s\"] * np.sin(dir_rad)\n    df[\"speed_y\"] = df[\"s\"] * np.cos(dir_rad)\n\n    # unit vec to ball & closing/perp speeds\n    den = df[\"dist_to_ball\"].replace(0, 1e-6)\n    ux = dx_ball / den; uy = dy_ball / den\n    df[\"v_par\"]  = df[\"speed_x\"]*ux + df[\"speed_y\"]*uy\n    df[\"v_perp\"] = df[\"speed_x\"]*uy - df[\"speed_y\"]*ux\n\n    # normalized pos + logs\n    df[\"x_norm\"] = df[\"x_last\"]/120.0\n    df[\"y_norm\"] = df[\"y_last\"]/53.3\n    df[\"log_dist_ball\"]   = np.log1p(df[\"dist_to_ball\"])\n    df[\"log_dist_target\"] = np.log1p(df[\"dist_to_target\"].fillna(0.0))\n\n    if is_train:\n        df[\"dx\"] = df[\"x\"] - df[\"x_last\"]\n        df[\"dy\"] = df[\"y\"] - df[\"y_last\"]\n    return df\n\nNUM_FEATURES = [\n    \"x_last\",\"y_last\",\"s\",\"a\",\"o\",\"dir\",\n    \"frame_offset\",\"time_offset\",\"t_rel\",\"T\",\n    \"dist_to_ball\",\"sin_ab\",\"cos_ab\",\"dist_to_target\",\n    \"speed_x\",\"speed_y\",\"v_par\",\"v_perp\",\n    \"x_norm\",\"y_norm\",\"log_dist_ball\",\"log_dist_target\",\n    \"absolute_yardline_number\",\"player_height\",\"player_weight\"\n]\nCAT_FEATURES = [\"player_role\",\"player_side\",\"play_direction\"]\nTARGETS = [\"dx\",\"dy\"]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T09:15:30.719272Z","iopub.execute_input":"2025-09-26T09:15:30.719738Z","iopub.status.idle":"2025-09-26T09:15:30.746371Z","shell.execute_reply.started":"2025-09-26T09:15:30.719694Z","shell.execute_reply":"2025-09-26T09:15:30.74567Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%%time \n\nif 'DATA_DIR' not in globals():\n    DATA_DIR = \"/kaggle/input/nfl-big-data-bowl-2026-prediction/\"\nif 'TRAIN_IN_FILES' not in globals():\n    TRAIN_IN_FILES  = [f\"{DATA_DIR}train/input_2023_w{w:02d}.csv\"  for w in range(1,19)]\nif 'TRAIN_OUT_FILES' not in globals():\n    TRAIN_OUT_FILES = [f\"{DATA_DIR}train/output_2023_w{w:02d}.csv\" for w in range(1,19)]\nif 'TEST_INPUT_PATH' not in globals():\n    TEST_INPUT_PATH   = f\"{DATA_DIR}test_input.csv\"\nif 'TEST_TARGETS_PATH' not in globals():\n    TEST_TARGETS_PATH = f\"{DATA_DIR}test.csv\"\n\nFIELD_X_MIN, FIELD_X_MAX = 0.0, 120.0\nFIELD_Y_MIN, FIELD_Y_MAX = 0.0, 53.3\n\ndef height_to_inches(ht):\n    if isinstance(ht, str) and \"-\" in ht:\n        f, ins = ht.split(\"-\")\n        try:\n            return int(f)*12 + int(ins)\n        except:\n            return np.nan\n    return np.nan\n\ndef prepareLast(df_in: pd.DataFrame) -> pd.DataFrame:\n    \"\"\"Lấy frame cuối trước ném cho mỗi (game, play, player) từ input_*.\"\"\"\n    df_last = df_in.sort_values([\"game_id\",\"play_id\",\"nfl_id\",\"frame_id\"]) \\\n                   .groupby([\"game_id\",\"play_id\",\"nfl_id\"], as_index=False).last()\n    return df_last.rename(columns={\"x\":\"x_last\",\"y\":\"y_last\"})\n\ndef inject_target_receiver_xy(df_last: pd.DataFrame) -> pd.DataFrame:\n    \"\"\"Gắn vị trí Targeted Receiver tại lúc ném cho tất cả cầu thủ trong play.\"\"\"\n    trg = df_last[df_last[\"player_role\"]==\"Targeted Receiver\"][[\"game_id\",\"play_id\",\"x_last\",\"y_last\"]] \\\n          .rename(columns={\"x_last\":\"target_x\",\"y_last\":\"target_y\"})\n    return df_last.merge(trg, on=[\"game_id\",\"play_id\"], how=\"left\")\n\ndef add_features(df: pd.DataFrame, is_train=True) -> pd.DataFrame:\n    # time\n    df[\"frame_offset\"] = df[\"frame_id\"].astype(float)\n    df[\"time_offset\"]  = df[\"frame_offset\"] / 10.0\n    df[\"T\"] = np.clip(df[\"num_frames_output\"].astype(float), 1.0, None)\n    df[\"t_rel\"] = df[\"frame_offset\"] / df[\"T\"]\n\n    # geometry to ball\n    dxb = df[\"ball_land_x\"] - df[\"x_last\"]\n    dyb = df[\"ball_land_y\"] - df[\"y_last\"]\n    dist = np.sqrt(dxb**2 + dyb**2).astype(float)\n    ang  = np.arctan2(dyb, dxb).astype(float)\n    df[\"dist_to_ball\"] = dist\n    df[\"sin_ab\"] = np.sin(ang); df[\"cos_ab\"] = np.cos(ang)\n\n    # target receiver\n    df[\"dist_to_target\"] = np.sqrt((df[\"target_x\"]-df[\"x_last\"])**2 + (df[\"target_y\"]-df[\"y_last\"])**2)\n    df[\"is_target\"] = (df[\"player_role\"]==\"Targeted Receiver\").astype(int)\n\n    # velocity (data convention)\n    dir_rad = np.deg2rad(df[\"dir\"].astype(float))\n    df[\"speed_x\"] = df[\"s\"] * np.sin(dir_rad)\n    df[\"speed_y\"] = df[\"s\"] * np.cos(dir_rad)\n\n    # closing/perp speed\n    den = df[\"dist_to_ball\"].replace(0, 1e-6)\n    ux = dxb / den; uy = dyb / den\n    df[\"v_par\"]  = df[\"speed_x\"]*ux + df[\"speed_y\"]*uy\n    df[\"v_perp\"] = df[\"speed_x\"]*uy - df[\"speed_y\"]*ux\n\n    # normalizations + logs\n    df[\"x_norm\"] = df[\"x_last\"]/120.0\n    df[\"y_norm\"] = df[\"y_last\"]/53.3\n    df[\"log_dist_ball\"]   = np.log1p(df[\"dist_to_ball\"])\n    df[\"log_dist_target\"] = np.log1p(df[\"dist_to_target\"].fillna(0.0))\n\n    if is_train:\n        df[\"dx\"] = df[\"x\"] - df[\"x_last\"]\n        df[\"dy\"] = df[\"y\"] - df[\"y_last\"]\n    return df\n\n# Feature lists (đặt lại để dùng downstream)\nNUM_FEATURES = [\n    \"x_last\",\"y_last\",\"s\",\"a\",\"o\",\"dir\",\n    \"frame_offset\",\"time_offset\",\"t_rel\",\"T\",\n    \"dist_to_ball\",\"sin_ab\",\"cos_ab\",\"dist_to_target\",\n    \"speed_x\",\"speed_y\",\"v_par\",\"v_perp\",\n    \"x_norm\",\"y_norm\",\"log_dist_ball\",\"log_dist_target\",\n    \"absolute_yardline_number\",\"player_height\",\"player_weight\"\n]\nCAT_FEATURES = [\"player_role\",\"player_side\",\"play_direction\"]\n\ndf_in  = pd.concat([pd.read_csv(p) for p in TRAIN_IN_FILES],  ignore_index=True)\ndf_out = pd.concat([pd.read_csv(p) for p in TRAIN_OUT_FILES], ignore_index=True)\n\n# last pre-throw per player (no frame_id in merge key)\nlast_all = prepareLast(df_in)\n# convert height if column exists\nif \"player_height\" in last_all.columns:\n    last_all[\"player_height\"] = last_all[\"player_height\"].apply(height_to_inches)\nlast_all = inject_target_receiver_xy(last_all)\n\ncols_keep_no_fid = [\n    \"game_id\",\"play_id\",\"nfl_id\",\n    \"x_last\",\"y_last\",\"s\",\"a\",\"o\",\"dir\",\n    \"player_role\",\"player_side\",\"num_frames_output\",\"ball_land_x\",\"ball_land_y\",\n    \"target_x\",\"target_y\",\"play_direction\",\"absolute_yardline_number\",\n    \"player_height\",\"player_weight\"\n]\n\n# Merge output_* với last_* KHÔNG theo frame_id (tránh NaN anchor)\ntrain = df_out.merge(last_all[cols_keep_no_fid],\n                     on=[\"game_id\",\"play_id\",\"nfl_id\"], how=\"left\", validate=\"many_to_one\")\n\n# Features + targets\ntrain = add_features(train, is_train=True)\n\n# Clean labels (XGB/LGBM cần nhãn hữu hạn)\nlbl_mask = np.isfinite(train[\"dx\"].values) & np.isfinite(train[\"dy\"].values)\nn_bad = int((~lbl_mask).sum())\nif n_bad > 0:\n    print(f\"[Hotfix] Drop rows with NaN/Inf dx,dy: {n_bad}\")\n    train = train.loc[lbl_mask].reset_index(drop=True)\n\nanc_mask = np.isfinite(train[\"x_last\"].values) & np.isfinite(train[\"y_last\"].values)\nif (~anc_mask).any():\n    print(f\"[Hotfix] Drop rows with NaN anchor: {int((~anc_mask).sum())}\")\n    train = train.loc[anc_mask].reset_index(drop=True)\n\nfor c in CAT_FEATURES:\n    if c in train.columns:\n        train[c] = train[c].astype(\"category\")\n\nw_time = train[\"frame_offset\"] / train[\"T\"].clip(lower=1.0)\nw_time = 1.0 + 0.6*(w_time - w_time.min())/(w_time.max()-w_time.min() + 1e-9)  # 1.0→1.6\nw_role = np.where(train[\"player_role\"].astype(str)==\"Targeted Receiver\", 2.0, 1.0)\ntrain[\"sample_weight\"] = w_time * w_role\n\nprint(\"Train rows (clean):\", len(train))\n\n# ---------- Load test ----------\ntest_in   = pd.read_csv(TEST_INPUT_PATH)\ntest_tmpl = pd.read_csv(TEST_TARGETS_PATH)\n\nlast_test = prepareLast(test_in)\nif \"player_height\" in last_test.columns:\n    last_test[\"player_height\"] = last_test[\"player_height\"].apply(height_to_inches)\nlast_test = inject_target_receiver_xy(last_test)\n\ntest_rows = test_tmpl.merge(last_test[cols_keep_no_fid],\n                            on=[\"game_id\",\"play_id\",\"nfl_id\"], how=\"left\", validate=\"many_to_one\")\ntest = add_features(test_rows, is_train=False)\n\nfor c in CAT_FEATURES:\n    if c in test.columns:\n        test[c] = test[c].astype(\"category\")\n\nprint(\"Test rows (rebuilt):\", len(test))","metadata":{"trusted":true,"_kg_hide-input":true,"execution":{"iopub.status.busy":"2025-09-26T09:15:30.747067Z","iopub.execute_input":"2025-09-26T09:15:30.747272Z","iopub.status.idle":"2025-09-26T09:15:55.956256Z","shell.execute_reply.started":"2025-09-26T09:15:30.747256Z","shell.execute_reply":"2025-09-26T09:15:55.955564Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **MODEL TRAINING**","metadata":{}},{"cell_type":"code","source":"%%time \n\ndef make_base_models(SEED, nest):\n   \n    models = []\n    if HAS_LGBM:\n        models.append((\"lgbm\",\n            LGBMRegressor(\n                n_estimators=  nest, \n                learning_rate=0.05, \n                max_depth=9, \n                num_leaves=64,\n                subsample=0.8, \n                colsample_bytree=0.8, \n                random_state=SEED, \n                verbose = -1,\n                device = \"gpu\" if torch.cuda.is_available() else \"cpu\"\n            )\n        ))\n    if HAS_XGB:\n        models.append((\"xgb\",\n            XGBRegressor(\n                n_estimators=nest, \n                learning_rate=0.06, \n                max_depth=9,\n                subsample=0.8, \n                colsample_bytree=0.8, \n                random_state=SEED,\n                tree_method=\"hist\", \n                enable_categorical=True, \n                verbosity=0,\n                device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n            )\n        ))\n    if HAS_CAT:\n        models.append((\"cat\",\n            CatBoostRegressor(\n                iterations=nest, \n                learning_rate=0.05, \n                depth=8,\n                random_seed=SEED, \n                verbose=False,\n                task_type = \"GPU\" if torch.cuda.is_available() else \"CPU\"\n            )\n        ))\n    if not models:\n        raise RuntimeError(\"Không có base model nào sẵn. Cần ít nhất 1 trong LightGBM / XGBoost / CatBoost.\")\n    return models\n\ndef encode_for_model(X: pd.DataFrame, model_name: str):\n    \"\"\"Chuẩn hóa đầu vào tùy model (giữ category cho LGBM/Cat; XGB có thể dùng enable_categorical).\n       Nếu môi trường XGB không hỗ trợ categorical, fallback one-hot.\n    \"\"\"\n    Xc = X.copy()\n    if model_name in (\"lgbm\", \"cat\"):\n        return Xc\n    elif model_name == \"xgb\":\n        return Xc\n    else:\n        return pd.get_dummies(Xc, columns=CAT_FEATURES, dummy_na=True)\n\ndef fit_stacked_oof(\n    train_df, \n    features, \n    cat_features, \n    target, \n    groups, \n    n_splits=5,\n    SEED : int = 42,\n    nest : int = 10,\n):\n    gkf         = GroupKFold(n_splits=n_splits)\n    base_models = make_base_models(SEED = SEED, nest = nest)\n\n    oof         = np.zeros(len(train_df), dtype=np.float32)\n    preds_each  = {name: np.zeros(len(train_df), dtype=np.float32) for name,_ in base_models}\n    fold_models = {name: [] for name,_ in base_models}\n\n    X_full = train_df[features + cat_features].copy()\n    y_full = train_df[target].values\n    w_full = train_df.get(\"sample_weight\", pd.Series(np.ones(len(train_df)))).values\n\n    for fold, (tr_idx, va_idx) in tqdm( enumerate(gkf.split(train_df, groups=groups)) ):\n\n        print(f\"---> Fold {fold + 1}\")\n        \n        X_tr = X_full.iloc[tr_idx].copy(); \n        y_tr = y_full[tr_idx]; \n        w_tr = w_full[tr_idx]\n        X_va = X_full.iloc[va_idx].copy(); \n        y_va = y_full[va_idx]\n\n        for name, mdl in make_base_models(SEED = SEED, nest = nest) :\n            Xtr_enc = encode_for_model(X_tr, name)\n            Xva_enc = encode_for_model(X_va, name)\n\n            mdl2 = mdl.__class__(**mdl.get_params())\n            try:\n                if name == \"cat\":\n                    mdl2.fit(\n                        Xtr_enc,\n                        y_tr, \n                        sample_weight=w_tr, \n                        cat_features=[Xtr_enc.columns.get_loc(c) for c in cat_features]\n                    )\n                    \n                elif name == \"lgbm\":\n                    mdl2.fit(Xtr_enc, y_tr, sample_weight=w_tr, categorical_feature=cat_features)\n                    \n                else: \n                    mdl2.fit(Xtr_enc, y_tr, sample_weight=w_tr)\n                    \n            except Exception:\n                Xtr_enc = pd.get_dummies(X_tr, columns=cat_features, dummy_na=True)\n                Xva_enc = pd.get_dummies(X_va, columns=cat_features, dummy_na=True)\n                Xva_enc = Xva_enc.reindex(columns=Xtr_enc.columns, fill_value=0)\n                mdl2.fit(Xtr_enc, y_tr, sample_weight=w_tr)\n\n            pred_va = mdl2.predict(Xva_enc).astype(np.float32)\n            preds_each[name][va_idx] = pred_va\n            fold_models[name].append(mdl2)\n\n        meta_va = np.vstack([preds_each[name][va_idx] for name,_ in base_models]).T\n        meta = RidgeCV(alphas=(0.01, 0.1, 1.0, 10.0))\n        meta.fit(meta_va, y_va)\n        oof[va_idx] = meta.predict(meta_va).astype(np.float32)\n\n    meta_full = np.vstack([preds_each[name] for name,_ in base_models]).T\n    meta_full_learner = RidgeCV(alphas=(0.01, 0.1, 1.0, 10.0)).fit(meta_full, y_full)\n\n    return {\n        \"base_models\": base_models,\n        \"fold_models\": fold_models,\n        \"meta_learner\": meta_full_learner,\n        \"oof_pred\": oof,\n        \"preds_each\": preds_each,\n    }\n\ndef predict_stacked(models_pack, X_df, cat_features):\n    base_models = models_pack[\"base_models\"]\n    fold_models = models_pack[\"fold_models\"]\n    meta        = models_pack[\"meta_learner\"]\n\n    base_preds = []\n    for name,_ in base_models:\n        X_enc = encode_for_model(X_df, name)\n        preds = []\n        for m in fold_models[name]:\n            try:\n                preds.append(m.predict(X_enc))\n            except Exception:\n                X_oh = pd.get_dummies(X_df, columns=cat_features, dummy_na=True)\n                X_oh = X_oh.reindex(columns=m.feature_names_in_, fill_value=0) if hasattr(m, \"feature_names_in_\") else X_oh\n                preds.append(m.predict(X_oh))\n        base_preds.append(np.mean(np.column_stack(preds), axis=1))\n    meta_infer = np.vstack(base_preds).T\n    return meta.predict(meta_infer)","metadata":{"trusted":true,"_kg_hide-input":true,"execution":{"iopub.status.busy":"2025-09-26T09:15:55.957119Z","iopub.execute_input":"2025-09-26T09:15:55.957407Z","iopub.status.idle":"2025-09-26T09:15:55.972113Z","shell.execute_reply.started":"2025-09-26T09:15:55.957379Z","shell.execute_reply":"2025-09-26T09:15:55.971265Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%%time \n\ngames = train[\"game_id\"].to_numpy()\nMdl_Preds_x = []\nMdl_Preds_y = []\n\nfor myseed in tqdm( [1, 42, 55, 1000, 61846,] , \"Random seeds\"):\n\n    if test_req == True:\n        print(f\"\\n\\n---> Test run for syntax check - Seed = {myseed}\")\n    else:\n        print(f\"\\n\\n---> Seed = {myseed}\")\n\n    print(f\"\\n---> Models for x\")\n    pack_dx = fit_stacked_oof(\n        train_df=train,\n        features=NUM_FEATURES, \n        cat_features=CAT_FEATURES,\n        target=\"dx\", \n        groups=games, \n        n_splits=5,\n        SEED = myseed, \n        nest = nest,\n    )\n    \n    print(f\"\\n---> Models for y\")\n    pack_dy = fit_stacked_oof(\n        train_df=train,\n        features=NUM_FEATURES, \n        cat_features=CAT_FEATURES,\n        target=\"dy\", \n        groups=games, \n        n_splits=5,\n        SEED = myseed, \n        nest = nest,\n    )\n    \n    x_pred_oof = train[\"x_last\"].values + pack_dx[\"oof_pred\"]\n    y_pred_oof = train[\"y_last\"].values + pack_dy[\"oof_pred\"]\n    rmse_2d    = np.sqrt(\n        ((x_pred_oof - train[\"x\"].values)**2 + \n         (y_pred_oof - train[\"y\"].values)**2\n        ).mean() / 2.0\n    )\n    print(f\"---> Score = {rmse_2d:.8f}\")\n\n    X_test       = test[NUM_FEATURES + CAT_FEATURES].copy()\n    pred_dx_test = predict_stacked(pack_dx, X_test, CAT_FEATURES)\n    pred_dy_test = predict_stacked(pack_dy, X_test, CAT_FEATURES)\n    \n    pred_x = np.clip(test[\"x_last\"].values + pred_dx_test, FIELD_X_MIN, FIELD_X_MAX)\n    pred_y = np.clip(test[\"y_last\"].values + pred_dy_test, FIELD_Y_MIN, FIELD_Y_MAX)\n\n    Mdl_Preds_x.append(pred_x)\n    Mdl_Preds_y.append(pred_y)","metadata":{"trusted":true,"_kg_hide-input":true,"execution":{"iopub.status.busy":"2025-09-26T09:15:55.973098Z","iopub.execute_input":"2025-09-26T09:15:55.973408Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **SUBMISSION**","metadata":{}},{"cell_type":"code","source":"%%time \n\npred_x = np.mean( np.stack(Mdl_Preds_x, axis=1), axis = 1)\npred_y = np.mean( np.stack(Mdl_Preds_y, axis=1), axis = 1)\n\nsub = test[[\"game_id\",\"play_id\",\"nfl_id\",\"frame_id\"]].copy()\n\nsub[\"id\"] = (\n    sub[\"game_id\"].astype(str) + \"_\" +\n    sub[\"play_id\"].astype(str) + \"_\" +\n    sub[\"nfl_id\"].astype(str)  + \"_\" +\n    sub[\"frame_id\"].astype(str)\n)\n\nsubmission = sub[[\"id\"]].copy()\nsubmission[\"x\"] = pred_x\nsubmission[\"y\"] = pred_y\n\nsubmission.to_csv(\"submission.csv\", index=False)\nprint(\"Saved submission.csv:\", len(submission))\n\nprint()\n!head submission.csv","metadata":{"trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"outputs":[],"execution_count":null}]}