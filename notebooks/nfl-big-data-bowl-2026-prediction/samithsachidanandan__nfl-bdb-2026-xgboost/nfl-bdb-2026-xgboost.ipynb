{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":114239,"databundleVersionId":13825858,"sourceType":"competition"}],"dockerImageVersionId":31090,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.metrics import mean_squared_error\nimport xgboost as xgb\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import KFold\nimport warnings\nwarnings.filterwarnings('ignore')\n\nfrom multiprocessing import Pool as MultiprocessingPool, cpu_count\nfrom tqdm.auto import tqdm\nimport pickle\n\nbasedir = '/kaggle/input/nfl-big-data-bowl-2026-prediction'\n\ndef load_weekly_data(week_num):\n    input_df = pd.read_csv(f'{basedir}/train/input_2023_w{week_num:02d}.csv')\n    output_df = pd.read_csv(f'{basedir}/train/output_2023_w{week_num:02d}.csv')\n    return input_df, output_df\n\ndef load_all_train_data():\n    print(\"Loading training data...\")\n    with MultiprocessingPool(min(cpu_count(), 18)) as pool:\n        results = list(tqdm(pool.imap(load_weekly_data, range(1, 19)), total=18))\n    \n    input_dfs = [r[0] for r in results]\n    output_dfs = [r[1] for r in results]\n    \n    input_data = pd.concat(input_dfs, ignore_index=True)\n    output_data = pd.concat(output_dfs, ignore_index=True)\n    \n    print(f\"Input data shape: {input_data.shape}\")\n    print(f\"Output data shape: {output_data.shape}\")\n    \n    return input_data, output_data\n\ndef engineer_advanced_features(df):\n    \"\"\"Advanced feature engineering with sequence and interaction features\"\"\"\n    df = df.copy()\n    \n    df['velocity_x'] = df['s'] * np.cos(np.radians(df['dir']))\n    df['velocity_y'] = df['s'] * np.sin(np.radians(df['dir']))\n    \n    df['dist_to_ball'] = np.sqrt(\n        (df['x'] - df['ball_land_x'])**2 + \n        (df['y'] - df['ball_land_y'])**2\n    )\n    \n    df['angle_to_ball'] = np.arctan2(\n        df['ball_land_y'] - df['y'],\n        df['ball_land_x'] - df['x']\n    )\n    \n    df['velocity_toward_ball'] = (\n        df['velocity_x'] * np.cos(df['angle_to_ball']) + \n        df['velocity_y'] * np.sin(df['angle_to_ball'])\n    )\n    \n    df['time_to_ball'] = df['num_frames_output'] / 10.0\n    \n    df['orientation_diff'] = np.abs(df['o'] - df['dir'])\n    df['orientation_diff'] = np.minimum(df['orientation_diff'], 360 - df['orientation_diff'])\n    \n    df['role_targeted_receiver'] = (df['player_role'] == 'Targeted Receiver').astype(int)\n    df['role_defensive_coverage'] = (df['player_role'] == 'Defensive Coverage').astype(int)\n    df['role_passer'] = (df['player_role'] == 'Passer').astype(int)\n    df['side_offense'] = (df['player_side'] == 'Offense').astype(int)\n    \n    height_parts = df['player_height'].str.split('-', expand=True)\n    df['height_inches'] = height_parts[0].astype(float) * 12 + height_parts[1].astype(float)\n    df['bmi'] = (df['player_weight'] / (df['height_inches']**2)) * 703\n    \n    df['acceleration_x'] = df['a'] * np.cos(np.radians(df['dir']))\n    df['acceleration_y'] = df['a'] * np.sin(np.radians(df['dir']))\n    \n    df['distance_to_target_x'] = df['ball_land_x'] - df['x']\n    df['distance_to_target_y'] = df['ball_land_y'] - df['y']\n    \n    df['speed_squared'] = df['s'] ** 2\n    df['accel_magnitude'] = np.sqrt(df['acceleration_x']**2 + df['acceleration_y']**2)\n    \n    df['velocity_alignment'] = np.cos(df['angle_to_ball'] - np.radians(df['dir']))\n    \n    df['expected_x_at_ball'] = df['x'] + df['velocity_x'] * df['time_to_ball']\n    df['expected_y_at_ball'] = df['y'] + df['velocity_y'] * df['time_to_ball']\n    \n    df['error_from_ball_x'] = df['expected_x_at_ball'] - df['ball_land_x']\n    df['error_from_ball_y'] = df['expected_y_at_ball'] - df['ball_land_y']\n    df['error_from_ball'] = np.sqrt(df['error_from_ball_x']**2 + df['error_from_ball_y']**2)\n    \n    df['momentum_x'] = df['player_weight'] * df['velocity_x']\n    df['momentum_y'] = df['player_weight'] * df['velocity_y']\n    \n    df['kinetic_energy'] = 0.5 * df['player_weight'] * df['speed_squared']\n    \n    df['angle_diff'] = np.abs(df['o'] - np.degrees(df['angle_to_ball']))\n    df['angle_diff'] = np.minimum(df['angle_diff'], 360 - df['angle_diff'])\n    \n    df['time_squared'] = df['time_to_ball'] ** 2\n    df['dist_squared'] = df['dist_to_ball'] ** 2\n    \n    df['weighted_dist_by_time'] = df['dist_to_ball'] / (df['time_to_ball'] + 0.1)\n    \n    return df\n\ndef add_sequence_features(df):\n    \"\"\"Add temporal lag and rolling features\"\"\"\n    df = df.sort_values(['game_id', 'play_id', 'nfl_id', 'frame_id'])\n    \n    group_cols = ['game_id', 'play_id', 'nfl_id']\n    \n    for lag in [1, 2, 3, 4, 5]:\n        for col in ['x', 'y', 'velocity_x', 'velocity_y', 's', 'a']:\n            if col in df.columns:\n                df[f'{col}_lag{lag}'] = df.groupby(group_cols)[col].shift(lag)\n    \n    for window in [3, 5]:\n        for col in ['x', 'y', 'velocity_x', 'velocity_y', 's']:\n            if col in df.columns:\n                df[f'{col}_rolling_mean_{window}'] = df.groupby(group_cols)[col].rolling(window, min_periods=1).mean().reset_index(level=[0,1,2], drop=True)\n                df[f'{col}_rolling_std_{window}'] = df.groupby(group_cols)[col].rolling(window, min_periods=1).std().reset_index(level=[0,1,2], drop=True)\n    \n    for col in ['velocity_x', 'velocity_y']:\n        if col in df.columns:\n            df[f'{col}_delta'] = df.groupby(group_cols)[col].diff()\n    \n    return df\n\ndef create_training_dataset(input_df, output_df):\n    output_df = output_df.copy()\n    output_df['id'] = (output_df['game_id'].astype(str) + '_' + \n                       output_df['play_id'].astype(str) + '_' + \n                       output_df['nfl_id'].astype(str) + '_' + \n                       output_df['frame_id'].astype(str))\n    \n    output_df = output_df.rename(columns={'x': 'target_x', 'y': 'target_y'})\n    \n    input_agg = input_df.groupby(['game_id', 'play_id', 'nfl_id']).last().reset_index()\n    \n    if 'frame_id' in input_agg.columns:\n        input_agg = input_agg.drop('frame_id', axis=1)\n    \n    merged = output_df.merge(\n        input_agg,\n        on=['game_id', 'play_id', 'nfl_id'],\n        how='left',\n        suffixes=('', '_input')\n    )\n    \n    return merged\n\ndef physics_baseline_prediction(x, y, velocity_x, velocity_y, frame_id):\n    time_delta = frame_id / 10.0\n    pred_x = x + velocity_x * time_delta\n    pred_y = y + velocity_y * time_delta\n    pred_x = np.clip(pred_x, 0, 120)\n    pred_y = np.clip(pred_y, 0, 53.3)\n    return pred_x, pred_y\n\ndef main():\n    print(f\"CPU cores: {cpu_count()}\")\n    \n    input_data, output_data = load_all_train_data()\n    \n    print(\"\\n=== Advanced Feature Engineering ===\")\n    print(\"Step 1: Engineering advanced physics features...\")\n    input_features = engineer_advanced_features(input_data)\n    \n    print(\"Step 2: Adding sequence and rolling features...\")\n    input_features = add_sequence_features(input_features)\n    \n    print(f\"Feature engineered data shape: {input_features.shape}\")\n    print(f\"Total features: {input_features.shape[1]}\")\n    \n    print(\"\\nStep 3: Creating training dataset...\")\n    train_df = create_training_dataset(input_features, output_data)\n    print(f\"Training dataset shape: {train_df.shape}\")\n    \n    feature_cols = [\n        'x', 'y', 's', 'a', 'o', 'dir',\n        'velocity_x', 'velocity_y', 'dist_to_ball', 'angle_to_ball',\n        'velocity_toward_ball', 'time_to_ball', 'orientation_diff',\n        'role_targeted_receiver', 'role_defensive_coverage', 'role_passer',\n        'side_offense', 'height_inches', 'player_weight', 'bmi',\n        'ball_land_x', 'ball_land_y', 'num_frames_output', 'frame_id',\n        'acceleration_x', 'acceleration_y', 'distance_to_target_x', 'distance_to_target_y',\n        'speed_squared', 'accel_magnitude', 'velocity_alignment',\n        'expected_x_at_ball', 'expected_y_at_ball',\n        'error_from_ball_x', 'error_from_ball_y', 'error_from_ball',\n        'momentum_x', 'momentum_y', 'kinetic_energy',\n        'angle_diff', 'time_squared', 'dist_squared', 'weighted_dist_by_time'\n    ]\n    \n    for lag in [1, 2, 3, 4, 5]:\n        for col in ['x', 'y', 'velocity_x', 'velocity_y', 's', 'a']:\n            feature_cols.append(f'{col}_lag{lag}')\n    \n    for window in [3, 5]:\n        for col in ['x', 'y', 'velocity_x', 'velocity_y', 's']:\n            feature_cols.append(f'{col}_rolling_mean_{window}')\n            feature_cols.append(f'{col}_rolling_std_{window}')\n    \n    feature_cols.extend(['velocity_x_delta', 'velocity_y_delta'])\n    \n    available_features = [col for col in feature_cols if col in train_df.columns]\n    print(f\"Available features: {len(available_features)}\")\n    \n    train_df = train_df.dropna(subset=available_features + ['target_x', 'target_y'])\n    print(f\"Training data after removing NaNs: {train_df.shape}\")\n    \n    print(\"\\n=== Physics Baseline ===\")\n    baseline_x, baseline_y = physics_baseline_prediction(\n        train_df['x'].values,\n        train_df['y'].values,\n        train_df['velocity_x'].values,\n        train_df['velocity_y'].values,\n        train_df['frame_id'].values\n    )\n    \n    baseline_rmse = np.sqrt(\n        0.5 * (mean_squared_error(train_df['target_x'], baseline_x) +\n               mean_squared_error(train_df['target_y'], baseline_y))\n    )\n    print(f\"Physics Baseline RMSE: {baseline_rmse:.4f}\")\n    \n    # Prepare data for XGBoost\n    X = train_df[available_features].values\n    y_x = train_df['target_x'].values\n    y_y = train_df['target_y'].values\n    \n    # Initialize 5-fold cross-validation\n    n_folds = 5\n    kf = KFold(n_splits=n_folds, shuffle=True, random_state=42)\n    \n    models_x = []\n    models_y = []\n    val_rmse_scores = []\n    \n    print(f\"\\n=== Training Ultra-Optimized XGBoost with 5-Fold CV ===\")\n    \n    for fold, (train_idx, val_idx) in enumerate(kf.split(X), 1):\n        print(f\"\\nFold {fold}/{n_folds}\")\n        \n        # Split data\n        X_train, X_val = X[train_idx], X[val_idx]\n        y_x_train, y_x_val = y_x[train_idx], y_x[val_idx]\n        y_y_train, y_y_val = y_y[train_idx], y_y[val_idx]\n        \n        print(f\"Training set: {X_train.shape}, Validation set: {X_val.shape}\")\n        \n        # Train X-coordinate model\n        print(f\"Training X coordinate model for fold {fold}...\")\n        model_x = xgb.XGBRegressor(\n            n_estimators=10000,\n            learning_rate=0.02,\n            max_depth=10,\n            reg_lambda=3.0,  \n            random_state=42,\n            tree_method='gpu_hist',  \n            gpu_id=0,\n            early_stopping_rounds=500,\n            verbosity=1,  \n            objective='reg:squarederror',  \n            n_jobs=-1 \n        )\n        \n        model_x.fit(\n            X_train, y_x_train,\n            eval_set=[(X_val, y_x_val)],\n            verbose=200\n        )\n        models_x.append(model_x)\n        \n        # Train Y-coordinate model\n        print(f\"Training Y coordinate model for fold {fold}...\")\n        model_y = xgb.XGBRegressor(\n            n_estimators=10000,\n            learning_rate=0.02,\n            max_depth=10,\n            reg_lambda=3.0,  \n            random_state=42,\n            tree_method='gpu_hist', \n            gpu_id=0,\n            early_stopping_rounds=500,\n            verbosity=1,  \n            objective='reg:squarederror', \n            n_jobs=-1  \n        )\n        \n        model_y.fit(\n            X_train, y_y_train,\n            eval_set=[(X_val, y_y_val)],\n            verbose=200\n        )\n        models_y.append(model_y)\n        \n        # Validation predictions\n        pred_x = model_x.predict(X_val)\n        pred_y = model_y.predict(X_val)\n        \n        pred_x = np.clip(pred_x, 0, 120)\n        pred_y = np.clip(pred_y, 0, 53.3)\n        \n        # Compute RMSE for this fold\n        fold_rmse = np.sqrt(\n            0.5 * (mean_squared_error(y_x_val, pred_x) +\n                   mean_squared_error(y_y_val, pred_y))\n        )\n        val_rmse_scores.append(fold_rmse)\n        print(f\"Fold {fold} RMSE: {fold_rmse:.4f}\")\n    \n    # Average RMSE across folds\n    xgboost_rmse = np.mean(val_rmse_scores)\n    print(f\"\\nAverage XGBoost RMSE across {n_folds} folds: {xgboost_rmse:.4f}\")\n    print(f\"Standard Deviation of RMSE: {np.std(val_rmse_scores):.4f}\")\n    \n    print(f\"\\n{'='*60}\")\n    print(f\"ULTRA-OPTIMIZED XGBOOST PERFORMANCE (5-FOLD CV)\")\n    print(f\"{'='*60}\")\n    print(f\"Physics Baseline RMSE:     {baseline_rmse:.4f}\")\n    print(f\"Ultra-Optimized XGBoost:   {xgboost_rmse:.4f}\")\n    print(f\"Improvement:               {((baseline_rmse - xgboost_rmse) / baseline_rmse * 100):.2f}%\")\n    print(f\"Target RMSE:               0.9000\")\n    target_met = 'YES - TARGET ACHIEVED!' if xgboost_rmse < 0.9 else 'NO - Continuing optimization...'\n    print(f\"Target Met:                {target_met}\")\n    print(f\"{'='*60}\")\n    \n    # Feature importance (averaged across folds)\n    importance_x = np.mean([model.feature_importances_ for model in models_x], axis=0)\n    importance_y = np.mean([model.feature_importances_ for model in models_y], axis=0)\n    \n    feature_importance = pd.DataFrame({\n        'feature': available_features,\n        'importance_x': importance_x,\n        'importance_y': importance_y\n    })\n    feature_importance['importance_avg'] = (feature_importance['importance_x'] + \n                                            feature_importance['importance_y']) / 2\n    feature_importance = feature_importance.sort_values('importance_avg', ascending=False)\n    \n    print(\"\\nTop 30 Most Important Features (Averaged across folds):\")\n    print(feature_importance.head(30).to_string())\n    \n    # Save models\n    with open('xgboost_5fold_models.pkl', 'wb') as f:\n        pickle.dump({\n            'models_x': models_x,\n            'models_y': models_y,\n            'features': available_features,\n            'rmse': xgboost_rmse\n        }, f)\n    print(\"\\nModels saved to xgboost_5fold_models.pkl\")\n    \n    print(\"\\n=== Generating Submission ===\")\n    test_input = pd.read_csv(f'{basedir}/test_input.csv')\n    test_data = pd.read_csv(f'{basedir}/test.csv')\n    \n    print(\"Engineering features for test data...\")\n    test_features = engineer_advanced_features(test_input)\n    test_features = add_sequence_features(test_features)\n    \n    test_agg = test_features.groupby(['game_id', 'play_id', 'nfl_id']).last().reset_index()\n    \n    if 'frame_id' in test_agg.columns:\n        test_agg = test_agg.drop('frame_id', axis=1)\n    \n    test_merged = test_data.merge(\n        test_agg,\n        on=['game_id', 'play_id', 'nfl_id'],\n        how='left'\n    )\n    \n    test_merged['id'] = (test_merged['game_id'].astype(str) + '_' + \n                         test_merged['play_id'].astype(str) + '_' + \n                         test_merged['nfl_id'].astype(str) + '_' + \n                         test_merged['frame_id'].astype(str))\n    \n    for col in available_features:\n        if col not in test_merged.columns:\n            test_merged[col] = 0\n    \n    X_test = test_merged[available_features].fillna(0).values\n    \n    # Ensemble predictions across all folds\n    pred_x_test = np.mean([model.predict(X_test) for model in models_x], axis=0)\n    pred_y_test = np.mean([model.predict(X_test) for model in models_y], axis=0)\n    \n    pred_x_test = np.clip(pred_x_test, 0, 120)\n    pred_y_test = np.clip(pred_y_test, 0, 53.3)\n    \n    submission = pd.DataFrame({\n        'id': test_merged['id'],\n        'x': pred_x_test,\n        'y': pred_y_test\n    })\n    \n    submission.to_csv('submission.csv', index=False)\n    print(f\"\\n[SUCCESS] Submission saved: submission.csv\")\n    print(f\"Shape: {submission.shape}\")\n    \n    print(\"\\n=== Submission Validation ===\")\n    print(f\"No NaN values: {submission.isnull().sum().sum() == 0}\")\n    print(f\"X range: [{submission['x'].min():.2f}, {submission['x'].max():.2f}]\")\n    print(f\"Y range: [{submission['y'].min():.2f}, {submission['y'].max():.2f}]\")\n    print(f\"Unique IDs: {submission['id'].nunique()}\")\n    \n    return xgboost_rmse\n\nif __name__ == \"__main__\":\n    final_rmse = main()\n    print(f\"\\n[FINAL] Validation RMSE: {final_rmse:.4f}\")\n    achievement = 'ACHIEVED!' if final_rmse < 0.9 else 'Not yet - need further optimization'\n    print(f\"[FINAL] Target RMSE < 0.9: {achievement}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-05T11:49:44.426556Z","iopub.execute_input":"2025-10-05T11:49:44.426861Z","iopub.status.idle":"2025-10-05T12:32:29.420558Z","shell.execute_reply.started":"2025-10-05T11:49:44.426836Z","shell.execute_reply":"2025-10-05T12:32:29.419609Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}