{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.13"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":114239,"databundleVersionId":13825858,"sourceType":"competition"}],"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true},"papermill":{"default_parameters":{},"duration":1770.039996,"end_time":"2025-10-12T03:01:23.014716","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2025-10-12T02:31:52.97472","version":"2.6.0"},"widgets":{"application/vnd.jupyter.widget-state+json":{"state":{"048369c4d604463088e30e7eff77ae7b":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"05ce951504474ba2be71dad53547f79c":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"ProgressView","bar_style":"success","description":"","description_allow_html":false,"layout":"IPY_MODEL_57ff465c62e54afea05a647ca2db4104","max":46045,"min":0,"orientation":"horizontal","style":"IPY_MODEL_8685e043388140e989cb2caddce61819","tabbable":null,"tooltip":null,"value":46045}},"1457956951244d0b9adf835e9841d1a5":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"261834607f394018a6ace67b4e51dba5":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_3d6853995c2440c5a7b117344d613910","placeholder":"​","style":"IPY_MODEL_273e13fb5658483198e9f2d2edc761a7","tabbable":null,"tooltip":null,"value":"100%"}},"273e13fb5658483198e9f2d2edc761a7":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"30a0f55c7ad6471eb303d0a200ed423e":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_261834607f394018a6ace67b4e51dba5","IPY_MODEL_600ee6cb1898495eb82f7ffdbd2e21d0","IPY_MODEL_9885ad72b1594231968c78d29f53b50e"],"layout":"IPY_MODEL_a5206e62a9d04d7c893abdac13a80448","tabbable":null,"tooltip":null}},"3c8cf8190a7f4e3bad61a0cf8793697d":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"3cebbcb760da46fd875700ef3063bc4b":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"3d6853995c2440c5a7b117344d613910":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"48567287866d43a2bbac7b402a285662":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"556e4a1aeb6d4f27848f1ed15d66765e":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_d9170d893ece43b2a3c2f008fd9e94e6","placeholder":"​","style":"IPY_MODEL_1457956951244d0b9adf835e9841d1a5","tabbable":null,"tooltip":null,"value":"100%"}},"57ff465c62e54afea05a647ca2db4104":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5b549d31122f407293756b5a6f6764b8":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"600ee6cb1898495eb82f7ffdbd2e21d0":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"ProgressView","bar_style":"success","description":"","description_allow_html":false,"layout":"IPY_MODEL_62daa73ce43a40a798d9561728d5d401","max":472,"min":0,"orientation":"horizontal","style":"IPY_MODEL_3cebbcb760da46fd875700ef3063bc4b","tabbable":null,"tooltip":null,"value":472}},"62daa73ce43a40a798d9561728d5d401":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8685e043388140e989cb2caddce61819":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"96a9808e26f94a988f940f6b196d2a7a":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_556e4a1aeb6d4f27848f1ed15d66765e","IPY_MODEL_05ce951504474ba2be71dad53547f79c","IPY_MODEL_a1df6685251b4600a02cd836c0f6b0df"],"layout":"IPY_MODEL_5b549d31122f407293756b5a6f6764b8","tabbable":null,"tooltip":null}},"9885ad72b1594231968c78d29f53b50e":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_048369c4d604463088e30e7eff77ae7b","placeholder":"​","style":"IPY_MODEL_3c8cf8190a7f4e3bad61a0cf8793697d","tabbable":null,"tooltip":null,"value":" 472/472 [00:05&lt;00:00, 88.90it/s]"}},"a1df6685251b4600a02cd836c0f6b0df":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_48567287866d43a2bbac7b402a285662","placeholder":"​","style":"IPY_MODEL_c04e514418564ac5a55ab1662c7d212c","tabbable":null,"tooltip":null,"value":" 46045/46045 [10:23&lt;00:00, 75.13it/s]"}},"a5206e62a9d04d7c893abdac13a80448":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c04e514418564ac5a55ab1662c7d212c":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"d9170d893ece43b2a3c2f008fd9e94e6":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}}},"version_major":2,"version_minor":0}}},"nbformat_minor":4,"nbformat":4,"cells":[{"id":"29e8e991","cell_type":"code","source":"\"\"\"\nNFL Big Data Bowl 2026 - DEBUGGED PIPELINE\nFixing the 0.63 version to actually improve to 0.60\n\nBUGS FIXED:\n1. Cumsum was applied correctly BUT predictions were still wrong\n2. Feature scaling was breaking test predictions (train/test distribution mismatch)\n3. Too simple model (removed too much from baseline)\n4. Missing critical features\n\nIMPROVEMENTS ADDED:\n1. Proper feature engineering (matching baseline)\n2. Correct architecture (matching what worked)\n3. Better validation\n4. Lag features (proven improvement)\n\"\"\"\n\nimport torch\nimport torch.nn as nn\nimport numpy as np\nimport pandas as pd\nfrom pathlib import Path\nfrom tqdm.auto import tqdm\nfrom datetime import datetime\nimport warnings\nimport os\n\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import GroupKFold\nfrom torch.utils.data import TensorDataset, DataLoader\n\nwarnings.filterwarnings('ignore')\n\n# ============================================================================\n# CONFIG\n# ============================================================================\n\nclass Config:\n    DATA_DIR = Path(\"/kaggle/input/nfl-big-data-bowl-2026-prediction/\")\n    \n    SEED = 42\n    N_FOLDS = 5\n    BATCH_SIZE = 256\n    EPOCHS = 200\n    PATIENCE = 30\n    LEARNING_RATE = 1e-3\n    \n    WINDOW_SIZE = 8  # Keep what worked\n    HIDDEN_DIM = 128\n    MAX_FUTURE_HORIZON = 94\n    \n    FIELD_X_MIN, FIELD_X_MAX = 0.0, 120.0\n    FIELD_Y_MIN, FIELD_Y_MAX = 0.0, 53.3\n    \n    DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\ndef set_seed(seed=42):\n    import random\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n\nset_seed(Config.SEED)\n\n# ============================================================================\n# FEATURE ENGINEERING (FIXED - Keep baseline + add lags)\n# ============================================================================\n\ndef height_to_feet(height_str):\n    try:\n        ft, inches = map(int, str(height_str).split('-'))\n        return ft + inches/12\n    except:\n        return 6.0\n\ndef prepare_sequences_fixed(input_df, output_df=None, test_template=None, is_training=True, window_size=8):\n    \"\"\"\n    FIXED: Proper feature engineering matching baseline + lag features\n    \"\"\"\n    print(f\"Preparing sequences (window_size={window_size})...\")\n    \n    input_df = input_df.copy()\n    \n    # Basic features\n    input_df['player_height_feet'] = input_df['player_height'].apply(height_to_feet)\n    \n    # Velocity\n    dir_rad = np.deg2rad(input_df['dir'].fillna(0))\n    delta_t = 0.1\n    input_df['velocity_x'] = (input_df['s'] + 0.5 * input_df['a'] * delta_t) * np.sin(dir_rad)\n    input_df['velocity_y'] = (input_df['s'] + 0.5 * input_df['a'] * delta_t) * np.cos(dir_rad)\n    \n    # Acceleration\n    input_df['acceleration_x'] = input_df['a'] * np.sin(dir_rad)\n    input_df['acceleration_y'] = input_df['a'] * np.cos(dir_rad)\n    \n    # Roles\n    input_df['is_offense'] = (input_df['player_side'] == 'Offense').astype(int)\n    input_df['is_defense'] = (input_df['player_side'] == 'Defense').astype(int)\n    input_df['is_receiver'] = (input_df['player_role'] == 'Targeted Receiver').astype(int)\n    input_df['is_coverage'] = (input_df['player_role'] == 'Defensive Coverage').astype(int)\n    input_df['is_passer'] = (input_df['player_role'] == 'Passer').astype(int)\n    \n    # Physics\n    mass_kg = input_df['player_weight'].fillna(200.0) / 2.20462\n    input_df['momentum_x'] = input_df['velocity_x'] * mass_kg\n    input_df['momentum_y'] = input_df['velocity_y'] * mass_kg\n    input_df['kinetic_energy'] = 0.5 * mass_kg * (input_df['s'] ** 2)\n    \n    # Ball features\n    if 'ball_land_x' in input_df.columns:\n        ball_dx = input_df['ball_land_x'] - input_df['x']\n        ball_dy = input_df['ball_land_y'] - input_df['y']\n        input_df['distance_to_ball'] = np.sqrt(ball_dx**2 + ball_dy**2)\n        input_df['angle_to_ball'] = np.arctan2(ball_dy, ball_dx)\n        input_df['ball_direction_x'] = ball_dx / (input_df['distance_to_ball'] + 1e-6)\n        input_df['ball_direction_y'] = ball_dy / (input_df['distance_to_ball'] + 1e-6)\n        input_df['closing_speed'] = (\n            input_df['velocity_x'] * input_df['ball_direction_x'] +\n            input_df['velocity_y'] * input_df['ball_direction_y']\n        )\n    \n    # Sort for temporal features\n    input_df = input_df.sort_values(['game_id', 'play_id', 'nfl_id', 'frame_id'])\n    gcols = ['game_id', 'play_id', 'nfl_id']\n    \n    # IMPROVEMENT 1: Add lag features (proven to help)\n    for lag in [1, 2, 3]:\n        input_df[f'x_lag{lag}'] = input_df.groupby(gcols)['x'].shift(lag)\n        input_df[f'y_lag{lag}'] = input_df.groupby(gcols)['y'].shift(lag)\n        input_df[f'velocity_x_lag{lag}'] = input_df.groupby(gcols)['velocity_x'].shift(lag)\n        input_df[f'velocity_y_lag{lag}'] = input_df.groupby(gcols)['velocity_y'].shift(lag)\n    \n    # IMPROVEMENT 2: Add EMA features (exponential moving average)\n    input_df['velocity_x_ema'] = input_df.groupby(gcols)['velocity_x'].transform(\n        lambda x: x.ewm(alpha=0.3, adjust=False).mean()\n    )\n    input_df['velocity_y_ema'] = input_df.groupby(gcols)['velocity_y'].transform(\n        lambda x: x.ewm(alpha=0.3, adjust=False).mean()\n    )\n    input_df['speed_ema'] = input_df.groupby(gcols)['s'].transform(\n        lambda x: x.ewm(alpha=0.3, adjust=False).mean()\n    )\n    \n    # Simple rolling features\n    input_df['velocity_x_roll'] = input_df.groupby(gcols)['velocity_x'].transform(\n        lambda x: x.rolling(window_size, min_periods=1).mean()\n    )\n    input_df['velocity_y_roll'] = input_df.groupby(gcols)['velocity_y'].transform(\n        lambda x: x.rolling(window_size, min_periods=1).mean()\n    )\n    \n    # Feature list (keep it reasonable, not too many)\n    feature_cols = [\n        # Core\n        'x', 'y', 's', 'a', 'o', 'dir', 'frame_id',\n        'ball_land_x', 'ball_land_y',\n        # Player\n        'player_height_feet', 'player_weight',\n        # Motion\n        'velocity_x', 'velocity_y', 'acceleration_x', 'acceleration_y',\n        'momentum_x', 'momentum_y', 'kinetic_energy',\n        # Roles\n        'is_offense', 'is_defense', 'is_receiver', 'is_coverage', 'is_passer',\n        # Ball\n        'distance_to_ball', 'angle_to_ball', 'ball_direction_x', 'ball_direction_y', 'closing_speed',\n        # Temporal (NEW - improvements)\n        'x_lag1', 'y_lag1', 'velocity_x_lag1', 'velocity_y_lag1',\n        'x_lag2', 'y_lag2', 'velocity_x_lag2', 'velocity_y_lag2',\n        'x_lag3', 'y_lag3', 'velocity_x_lag3', 'velocity_y_lag3',\n        'velocity_x_ema', 'velocity_y_ema', 'speed_ema',\n        'velocity_x_roll', 'velocity_y_roll',\n    ]\n    \n    feature_cols = [c for c in feature_cols if c in input_df.columns]\n    print(f\"Using {len(feature_cols)} features (baseline + lag + EMA)\")\n    \n    # Create sequences\n    input_df.set_index(['game_id', 'play_id', 'nfl_id'], inplace=True)\n    grouped = input_df.groupby(level=['game_id', 'play_id', 'nfl_id'])\n    \n    target_rows = output_df if is_training else test_template\n    target_groups = target_rows[['game_id', 'play_id', 'nfl_id']].drop_duplicates()\n    \n    sequences, targets_dx, targets_dy, targets_frame_ids, sequence_ids = [], [], [], [], []\n    \n    for _, row in tqdm(target_groups.iterrows(), total=len(target_groups)):\n        key = (row['game_id'], row['play_id'], row['nfl_id'])\n        \n        try:\n            group_df = grouped.get_group(key)\n        except KeyError:\n            continue\n        \n        input_window = group_df.tail(window_size)\n        \n        if len(input_window) < window_size:\n            if is_training:\n                continue\n            pad_len = window_size - len(input_window)\n            pad_df = pd.DataFrame(np.nan, index=range(pad_len), columns=input_window.columns)\n            input_window = pd.concat([pad_df, input_window], ignore_index=True)\n        \n        # Fill NaN with group mean (better than global mean)\n        input_window = input_window.fillna(group_df.mean(numeric_only=True))\n        seq = input_window[feature_cols].values\n        \n        if np.isnan(seq).any():\n            if is_training:\n                continue\n            seq = np.nan_to_num(seq, nan=0.0)\n        \n        sequences.append(seq)\n        \n        if is_training:\n            out_grp = output_df[\n                (output_df['game_id']==row['game_id']) &\n                (output_df['play_id']==row['play_id']) &\n                (output_df['nfl_id']==row['nfl_id'])\n            ].sort_values('frame_id')\n            \n            last_x = input_window.iloc[-1]['x']\n            last_y = input_window.iloc[-1]['y']\n            \n            dx = out_grp['x'].values - last_x\n            dy = out_grp['y'].values - last_y\n            \n            targets_dx.append(dx)\n            targets_dy.append(dy)\n            targets_frame_ids.append(out_grp['frame_id'].values)\n        \n        sequence_ids.append({\n            'game_id': key[0],\n            'play_id': key[1],\n            'nfl_id': key[2],\n            'frame_id': input_window.iloc[-1]['frame_id']\n        })\n    \n    print(f\"Created {len(sequences)} sequences\")\n    \n    if is_training:\n        return sequences, targets_dx, targets_dy, targets_frame_ids, sequence_ids\n    return sequences, sequence_ids\n\n# ============================================================================\n# LOSS (Same as baseline)\n# ============================================================================\n\nclass TemporalHuber(nn.Module):\n    def __init__(self, delta=0.5, time_decay=0.03):\n        super().__init__()\n        self.delta = delta\n        self.time_decay = time_decay\n    \n    def forward(self, pred, target, mask):\n        err = pred - target\n        abs_err = torch.abs(err)\n        \n        huber = torch.where(\n            abs_err <= self.delta,\n            0.5 * err * err,\n            self.delta * (abs_err - 0.5 * self.delta)\n        )\n        \n        if self.time_decay > 0:\n            L = pred.size(1)\n            t = torch.arange(L, device=pred.device).float()\n            weight = torch.exp(-self.time_decay * t).view(1, L)\n            huber = huber * weight\n            mask = mask * weight\n        \n        return (huber * mask).sum() / (mask.sum() + 1e-8)\n\n# ============================================================================\n# MODEL (Match baseline architecture)\n# ============================================================================\n\nclass ImprovedSeqModel(nn.Module):\n    \"\"\"\n    Architecture matching the 0.62 baseline\n    GRU + Attention pooling\n    \"\"\"\n    def __init__(self, input_dim, horizon):\n        super().__init__()\n        self.horizon = horizon\n        \n        # GRU encoder\n        self.gru = nn.GRU(input_dim, 128, num_layers=2, batch_first=True, dropout=0.1)\n        \n        # Attention pooling\n        self.pool_ln = nn.LayerNorm(128)\n        self.pool_attn = nn.MultiheadAttention(128, num_heads=4, batch_first=True)\n        self.pool_query = nn.Parameter(torch.randn(1, 1, 128))\n        \n        # Prediction head\n        self.head = nn.Sequential(\n            nn.Linear(128, 128),\n            nn.GELU(),\n            nn.Dropout(0.2),\n            nn.Linear(128, horizon)\n        )\n    \n    def forward(self, x):\n        # Encode\n        h, _ = self.gru(x)\n        \n        # Pool\n        B = h.size(0)\n        q = self.pool_query.expand(B, -1, -1)\n        h_norm = self.pool_ln(h)\n        ctx, _ = self.pool_attn(q, h_norm, h_norm)\n        ctx = ctx.squeeze(1)\n        \n        # Predict cumulative displacement\n        out = self.head(ctx)\n        out = torch.cumsum(out, dim=1)\n        \n        return out\n\n# ============================================================================\n# TRAINING\n# ============================================================================\n\ndef prepare_targets(batch_axis, max_h):\n    tensors, masks = [], []\n    for arr in batch_axis:\n        L = len(arr)\n        padded = np.pad(arr, (0, max_h - L), constant_values=0).astype(np.float32)\n        mask = np.zeros(max_h, dtype=np.float32)\n        mask[:L] = 1.0\n        tensors.append(torch.tensor(padded))\n        masks.append(torch.tensor(mask))\n    return torch.stack(tensors), torch.stack(masks)\n\ndef train_model(X_train, y_train, X_val, y_val, input_dim, horizon, config):\n    device = config.DEVICE\n    model = ImprovedSeqModel(input_dim, horizon).to(device)\n    \n    criterion = TemporalHuber(delta=0.5, time_decay=0.03)\n    optimizer = torch.optim.AdamW(model.parameters(), lr=config.LEARNING_RATE, weight_decay=1e-5)\n    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=5, factor=0.5, verbose=False)\n    \n    # Batches\n    train_batches = []\n    for i in range(0, len(X_train), config.BATCH_SIZE):\n        end = min(i + config.BATCH_SIZE, len(X_train))\n        bx = torch.tensor(np.stack(X_train[i:end]).astype(np.float32))\n        by, bm = prepare_targets([y_train[j] for j in range(i, end)], horizon)\n        train_batches.append((bx, by, bm))\n    \n    val_batches = []\n    for i in range(0, len(X_val), config.BATCH_SIZE):\n        end = min(i + config.BATCH_SIZE, len(X_val))\n        bx = torch.tensor(np.stack(X_val[i:end]).astype(np.float32))\n        by, bm = prepare_targets([y_val[j] for j in range(i, end)], horizon)\n        val_batches.append((bx, by, bm))\n    \n    best_loss, best_state, bad = float('inf'), None, 0\n    \n    for epoch in range(1, config.EPOCHS + 1):\n        model.train()\n        train_losses = []\n        \n        for bx, by, bm in train_batches:\n            bx, by, bm = bx.to(device), by.to(device), bm.to(device)\n            pred = model(bx)\n            loss = criterion(pred, by, bm)\n            \n            optimizer.zero_grad()\n            loss.backward()\n            nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n            optimizer.step()\n            train_losses.append(loss.item())\n        \n        model.eval()\n        val_losses = []\n        with torch.no_grad():\n            for bx, by, bm in val_batches:\n                bx, by, bm = bx.to(device), by.to(device), bm.to(device)\n                pred = model(bx)\n                loss = criterion(pred, by, bm)\n                val_losses.append(loss.item())\n        \n        train_loss = np.mean(train_losses)\n        val_loss = np.mean(val_losses)\n        scheduler.step(val_loss)\n        \n        if epoch % 10 == 0:\n            print(f\"  Epoch {epoch}: train={train_loss:.4f}, val={val_loss:.4f}\")\n        \n        if val_loss < best_loss:\n            best_loss = val_loss\n            best_state = {k: v.cpu().clone() for k, v in model.state_dict().items()}\n            bad = 0\n        else:\n            bad += 1\n            if bad >= config.PATIENCE:\n                print(f\"  Early stop at epoch {epoch}\")\n                break\n    \n    if best_state:\n        model.load_state_dict(best_state)\n    \n    return model, best_loss\n\n# ============================================================================\n# MAIN\n# ============================================================================\n\ndef main():\n    config = Config()\n    \n    print(\"=\"*80)\n    print(\"NFL DEBUGGED PIPELINE (Fixing 0.63 → Target 0.60)\")\n    print(\"=\"*80)\n    \n    # Load\n    print(\"\\n[1/4] Loading...\")\n    train_input_files = [config.DATA_DIR / f\"train/input_2023_w{w:02d}.csv\" for w in range(1, 19)]\n    train_output_files = [config.DATA_DIR / f\"train/output_2023_w{w:02d}.csv\" for w in range(1, 19)]\n    \n    train_input = pd.concat([pd.read_csv(f) for f in train_input_files if f.exists()])\n    train_output = pd.concat([pd.read_csv(f) for f in train_output_files if f.exists()])\n    \n    test_input = pd.read_csv(config.DATA_DIR / \"test_input.csv\")\n    test_template = pd.read_csv(config.DATA_DIR / \"test.csv\")\n    \n    # Prepare\n    print(\"\\n[2/4] Preparing (with lag + EMA features)...\")\n    sequences, targets_dx, targets_dy, targets_frame_ids, sequence_ids = prepare_sequences_fixed(\n        train_input, train_output, is_training=True, window_size=config.WINDOW_SIZE\n    )\n    \n    sequences = np.array(sequences, dtype=object)\n    targets_dx = np.array(targets_dx, dtype=object)\n    targets_dy = np.array(targets_dy, dtype=object)\n    \n    # Train\n    print(\"\\n[3/4] Training...\")\n    groups = np.array([d['game_id'] for d in sequence_ids])\n    gkf = GroupKFold(n_splits=config.N_FOLDS)\n    \n    models_x, models_y, scalers = [], [], []\n    \n    for fold, (tr, va) in enumerate(gkf.split(sequences, groups=groups), 1):\n        print(f\"\\nFold {fold}/{config.N_FOLDS}\")\n        \n        X_tr = sequences[tr]\n        X_va = sequences[va]\n        \n        # FIX: Proper scaling (fit on train only)\n        scaler = StandardScaler()\n        scaler.fit(np.vstack([s for s in X_tr]))\n        \n        X_tr_scaled = np.stack([scaler.transform(s) for s in X_tr])\n        X_va_scaled = np.stack([scaler.transform(s) for s in X_va])\n        \n        # Train X\n        print(\"Training X...\")\n        mx, _ = train_model(X_tr_scaled, targets_dx[tr], X_va_scaled, targets_dx[va],\n                           X_tr[0].shape[-1], config.MAX_FUTURE_HORIZON, config)\n        \n        # Train Y  \n        print(\"Training Y...\")\n        my, _ = train_model(X_tr_scaled, targets_dy[tr], X_va_scaled, targets_dy[va],\n                           X_tr[0].shape[-1], config.MAX_FUTURE_HORIZON, config)\n        \n        models_x.append(mx)\n        models_y.append(my)\n        scalers.append(scaler)\n    \n    # Predict\n    print(\"\\n[4/4] Predicting...\")\n    test_sequences, test_ids = prepare_sequences_fixed(\n        test_input, test_template=test_template, is_training=False, window_size=config.WINDOW_SIZE\n    )\n    \n    X_test = np.array(test_sequences, dtype=object)\n    x_last = np.array([s[-1, 0] for s in X_test])\n    y_last = np.array([s[-1, 1] for s in X_test])\n    \n    # Ensemble\n    all_dx, all_dy = [], []\n    \n    for mx, my, sc in zip(models_x, models_y, scalers):\n        X_scaled = np.stack([sc.transform(s) for s in X_test])\n        X_tensor = torch.tensor(X_scaled.astype(np.float32)).to(config.DEVICE)\n        \n        mx.eval()\n        my.eval()\n        \n        with torch.no_grad():\n            dx = mx(X_tensor).cpu().numpy()\n            dy = my(X_tensor).cpu().numpy()\n        \n        all_dx.append(dx)\n        all_dy.append(dy)\n    \n    ens_dx = np.mean(all_dx, axis=0)\n    ens_dy = np.mean(all_dy, axis=0)\n    \n    # Create submission\n    rows = []\n    H = ens_dx.shape[1]\n    \n    for i, sid in enumerate(test_ids):\n        fids = test_template[\n            (test_template['game_id'] == sid['game_id']) &\n            (test_template['play_id'] == sid['play_id']) &\n            (test_template['nfl_id'] == sid['nfl_id'])\n        ]['frame_id'].sort_values().tolist()\n        \n        for t, fid in enumerate(fids):\n            tt = min(t, H - 1)\n            px = np.clip(x_last[i] + ens_dx[i, tt], 0, 120)\n            py = np.clip(y_last[i] + ens_dy[i, tt], 0, 53.3)\n            \n            rows.append({\n                'id': f\"{sid['game_id']}_{sid['play_id']}_{sid['nfl_id']}_{fid}\",\n                'x': px,\n                'y': py\n            })\n    \n    submission = pd.DataFrame(rows)\n    submission.to_csv(\"submission.csv\", index=False)\n    \n    print(f\"\\n✓ Saved submission.csv\")\n    print(f\"  Rows: {len(submission)}\")\n    print(f\"  Improvements: lag features + EMA + better architecture\")\n    print(f\"  Expected: ~0.60-0.61 RMSE (from 0.63)\")\n    \n    return submission\n\nif __name__ == \"__main__\":\n    main()","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2025-10-12T02:31:56.456662Z","iopub.status.busy":"2025-10-12T02:31:56.456441Z","iopub.status.idle":"2025-10-12T03:01:21.384309Z","shell.execute_reply":"2025-10-12T03:01:21.383531Z"},"papermill":{"duration":1764.932717,"end_time":"2025-10-12T03:01:21.385812","exception":false,"start_time":"2025-10-12T02:31:56.453095","status":"completed"},"tags":[]},"outputs":[],"execution_count":null}]}