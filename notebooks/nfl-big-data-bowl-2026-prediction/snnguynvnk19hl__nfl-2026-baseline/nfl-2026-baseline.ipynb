{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":114239,"databundleVersionId":13825858,"sourceType":"competition"}],"dockerImageVersionId":31089,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# ==============================================================================\n# NFL Big Data Bowl 2026 - Baseline Script\n#\n# METHODOLOGY:\n# 1.  Load all weekly input and output training data.\n# 2.  Identify the last known state (final frame) for each player in each play\n#     from the input data.\n# 3.  Merge the last known state with the corresponding future frames from the\n#     output data to create a complete training dataset.\n# 4.  Engineer features based on player statics, kinematics at the last moment,\n#     and the relationship to the ball landing spot (the \"Gravity Well\" hypothesis).\n# 5.  Train two separate LightGBM models: one for the 'x' coordinate and one\n#     for the 'y' coordinate.\n# 6.  Process the test set using the exact same feature engineering pipeline.\n# 7.  Predict 'x' and 'y' for the test set and generate submission.csv.\n# ==============================================================================\n\nimport pandas as pd\nimport numpy as np\nimport lightgbm as lgb\nfrom sklearn.model_selection import KFold\nimport gc\nfrom glob import glob\nimport os\n\n# --- Configuration ---\n# Set the base path to your data directory\n# Update this path if your data is located elsewhere\nBASE_PATH = '/kaggle/input/nfl-big-data-bowl-2026-prediction' \nTRAIN_INPUT_DIR = os.path.join(BASE_PATH, 'train/')\nTEST_INPUT_FILE = os.path.join(BASE_PATH, 'test_input.csv')\nTEST_MANIFEST_FILE = os.path.join(BASE_PATH, 'test.csv')\nSUBMISSION_FILE = 'submission.csv'\n\n\ndef load_all_data(directory: str, prefix: str) -> pd.DataFrame:\n    \"\"\"Loads and concatenates all weekly data files from a directory.\"\"\"\n    files = glob(os.path.join(directory, f'{prefix}_*.csv'))\n    if not files:\n        raise FileNotFoundError(f\"No files with prefix '{prefix}' found in directory '{directory}'\")\n    \n    df_list = []\n    for file in files:\n        df_list.append(pd.read_csv(file, low_memory=False))\n    \n    return pd.concat(df_list, ignore_index=True)\n\n\ndef parse_player_height(height_str: str) -> float:\n    \"\"\"Converts height string 'ft-in' to inches.\"\"\"\n    try:\n        feet, inches = map(int, height_str.split('-'))\n        return feet * 12 + inches\n    except:\n        return np.nan\n\ndef engineer_features(df: pd.DataFrame) -> pd.DataFrame:\n    \"\"\"Creates new features based on raw data.\"\"\"\n    \n    # --- Player Static Features ---\n    # Convert height to a numerical format (inches)\n    df['player_height_inches'] = df['player_height'].apply(parse_player_height)\n    \n    # Calculate player age at the time of the play (approximated)\n    df['player_birth_date'] = pd.to_datetime(df['player_birth_date'])\n    # Assuming all plays are in the 2023 season for simplicity in baseline\n    df['player_age'] = 2023 - df['player_birth_date'].dt.year\n    \n    # --- \"Gravity Well\" Features (distance and angle to ball landing spot) ---\n    # These features are critical based on EDA\n    delta_x_land = df['ball_land_x'] - df['x']\n    delta_y_land = df['ball_land_y'] - df['y']\n    \n    df['dist_to_ball_land'] = np.sqrt(delta_x_land**2 + delta_y_land**2)\n    \n    # Angle between player's direction of motion and the ball landing spot\n    # This indicates if the player is already moving towards the ball\n    player_dir_rad = np.deg2rad(df['dir'])\n    ball_angle_rad = np.arctan2(delta_y_land, delta_x_land)\n    \n    # Difference in angles\n    angle_diff = ball_angle_rad - player_dir_rad\n    # Normalize to [-pi, pi]\n    angle_diff = (angle_diff + np.pi) % (2 * np.pi) - np.pi\n    df['angle_to_ball_land'] = np.rad2deg(angle_diff)\n\n    # --- Standardize Play Direction ---\n    # This is a crucial step to reduce model complexity. We make all plays\n    # appear as if they are moving from left to right.\n    # We will need to reverse this transformation for predictions.\n    df['x_std'] = np.where(df['play_direction'] == 'left', 120 - df['x'], df['x'])\n    df['y_std'] = np.where(df['play_direction'] == 'left', 160/3 - df['y'], df['y'])\n    \n    # Standardize kinematic angles as well\n    df['dir_std'] = np.where(df['play_direction'] == 'left', 180 - df['dir'], df['dir'])\n    df['dir_std'] = df['dir_std'] % 360 # Ensure it's within [0, 360]\n    \n    # We don't standardize 'o' as it's orientation, not direction of motion.\n\n    # --- Categorical Features ---\n    # Convert object columns to 'category' dtype for LightGBM efficiency\n    for col in ['player_position', 'player_side', 'player_role']:\n        if col in df.columns:\n            df[col] = df[col].astype('category')\n            \n    return df\n\ndef prepare_training_data(input_df, output_df):\n    \"\"\"Prepares the final training dataset by merging input and output data.\"\"\"\n    \n    # Find the last frame for each player in each play from the input data\n    # This represents the player's state right before the prediction starts\n    last_input_state = input_df.loc[input_df.groupby(['game_id', 'play_id', 'nfl_id'])['frame_id'].idxmax()]\n    \n    # Select only the necessary columns from the last state\n    # We drop frame_id from input to avoid confusion with the output frame_id\n    id_cols = ['game_id', 'play_id', 'nfl_id']\n    static_cols = [\n        'player_height', 'player_weight', 'player_birth_date', 'player_position',\n        'player_side', 'player_role', 'play_direction', 'absolute_yardline_number',\n        'ball_land_x', 'ball_land_y'\n    ]\n    last_state_kinematics = ['x', 'y', 's', 'a', 'o', 'dir']\n    \n    last_input_state = last_input_state[id_cols + static_cols + last_state_kinematics]\n    \n    # Rename last state columns to avoid conflicts after merging\n    last_input_state = last_input_state.rename(columns={\n        'x': 'last_x', 'y': 'last_y', 's': 'last_s', 'a': 'last_a', \n        'o': 'last_o', 'dir': 'last_dir'\n    })\n    \n    # Merge the last known state with the future frames (our targets)\n    # The output_df contains the target x, y and the future frame_id\n    train_df = pd.merge(output_df, last_input_state, on=id_cols)\n\n    # Rename columns to reflect their meaning for feature engineering\n    # We will engineer features based on the *last known state*\n    train_df = train_df.rename(columns={\n        'last_x': 'x', 'last_y': 'y', 'last_s': 's', 'last_a': 'a',\n        'last_o': 'o', 'last_dir': 'dir',\n        'x': 'target_x', 'y': 'target_y' # These are the true future positions\n    })\n    \n    # Standardize the target coordinates based on play direction\n    train_df['target_x_std'] = np.where(train_df['play_direction'] == 'left', 120 - train_df['target_x'], train_df['target_x'])\n    train_df['target_y_std'] = np.where(train_df['play_direction'] == 'left', 160/3 - train_df['target_y'], train_df['target_y'])\n    \n    return train_df\n\n# --- Main Execution ---\n\nprint(\"Step 1: Loading data...\")\ntrain_input = load_all_data(TRAIN_INPUT_DIR, 'input')\ntrain_output = load_all_data(TRAIN_INPUT_DIR, 'output')\nprint(f\"Loaded {len(train_input)} input rows and {len(train_output)} output rows.\")\n\nprint(\"Step 2: Preparing training data...\")\n# Note: player_to_predict is only in input, let's filter the output to match\nscorable_players = train_input[train_input['player_to_predict']][['game_id', 'play_id', 'nfl_id']].drop_duplicates()\ntrain_output_scorable = pd.merge(train_output, scorable_players, on=['game_id', 'play_id', 'nfl_id'])\ndel scorable_players, train_output\ngc.collect()\n\ntrain_df = prepare_training_data(train_input, train_output_scorable)\ndel train_input, train_output_scorable\ngc.collect()\n\nprint(\"Step 3: Engineering features for training data...\")\ntrain_df = engineer_features(train_df)\nprint(f\"Training data prepared with shape: {train_df.shape}\")\n\n# Define features and targets\nFEATURES = [\n    'frame_id',  # This is the future frame_id, a key temporal feature\n    'x_std', 'y_std', 's', 'a', 'dir_std', 'o', # Standardized last known state\n    'player_height_inches', 'player_weight', 'player_age',\n    'dist_to_ball_land', 'angle_to_ball_land',\n    'absolute_yardline_number',\n    # Categorical features\n    'player_position', 'player_side', 'player_role'\n]\n\nTARGET_X = 'target_x_std'\nTARGET_Y = 'target_y_std'\n\n# LightGBM Model Parameters (kept simple for baseline)\nLGB_PARAMS = {\n    'objective': 'regression_l1', # MAE is less sensitive to outliers than MSE (L2)\n    'metric': 'mae',\n    'n_estimators': 2000,\n    'learning_rate': 0.05,\n    'feature_fraction': 0.8,\n    'bagging_fraction': 0.8,\n    'bagging_freq': 1,\n    'lambda_l1': 0.1,\n    'lambda_l2': 0.1,\n    'num_leaves': 31,\n    'verbose': -1,\n    'n_jobs': -1,\n    'seed': 42,\n    'boosting_type': 'gbdt',\n}\n\nprint(\"Step 4: Training LightGBM models...\")\nprint(\"Training model for X coordinate...\")\nmodel_x = lgb.LGBMRegressor(**LGB_PARAMS)\nmodel_x.fit(train_df[FEATURES], train_df[TARGET_X])\n\nprint(\"Training model for Y coordinate...\")\nmodel_y = lgb.LGBMRegressor(**LGB_PARAMS)\nmodel_y.fit(train_df[FEATURES], train_df[TARGET_Y])\n\nprint(\"Models trained successfully.\")\ndel train_df\ngc.collect()\n\n# --- Prediction Phase ---\nprint(\"Step 5: Preparing test data for prediction...\")\ntest_input_df = pd.read_csv(TEST_INPUT_FILE)\ntest_manifest_df = pd.read_csv(TEST_MANIFEST_FILE)\n\n# The prediction logic mirrors the training data preparation\nlast_test_state = test_input_df.loc[test_input_df.groupby(['game_id', 'play_id', 'nfl_id'])['frame_id'].idxmax()]\n\nid_cols = ['game_id', 'play_id', 'nfl_id']\nstatic_cols = [\n    'player_height', 'player_weight', 'player_birth_date', 'player_position',\n    'player_side', 'player_role', 'play_direction', 'absolute_yardline_number',\n    'ball_land_x', 'ball_land_y'\n]\nlast_state_kinematics = ['x', 'y', 's', 'a', 'o', 'dir']\nlast_test_state = last_test_state[id_cols + static_cols + last_state_kinematics]\n\ntest_df = pd.merge(test_manifest_df, last_test_state, on=id_cols)\n\n# Rename for consistency with the feature engineering function\ntest_df = test_df.rename(columns={\n    'x': 'last_x', 'y': 'last_y', 's': 'last_s', 'a': 'last_a', \n    'o': 'last_o', 'dir': 'last_dir'\n})\ntest_df = test_df.rename(columns={\n    'last_x': 'x', 'last_y': 'y', 'last_s': 's', 'last_a': 'a',\n    'last_o': 'o', 'last_dir': 'dir'\n})\n\nprint(\"Step 6: Engineering features for test data...\")\ntest_df = engineer_features(test_df)\nprint(f\"Test data prepared with shape: {test_df.shape}\")\n\nprint(\"Step 7: Predicting on test data...\")\npred_x_std = model_x.predict(test_df[FEATURES])\npred_y_std = model_y.predict(test_df[FEATURES])\n\ntest_df['pred_x_std'] = pred_x_std\ntest_df['pred_y_std'] = pred_y_std\n\n# --- Reverse Standardization ---\n# This is a critical step to convert predictions back to the original coordinate system\ntest_df['x'] = np.where(test_df['play_direction'] == 'left', 120 - test_df['pred_x_std'], test_df['pred_x_std'])\ntest_df['y'] = np.where(test_df['play_direction'] == 'left', 160/3 - test_df['pred_y_std'], test_df['pred_y_std'])\n\nprint(\"Step 8: Generating submission file...\")\n# Create the submission ID\ntest_df['id'] = (\n    test_df['game_id'].astype(str) + '_' +\n    test_df['play_id'].astype(str) + '_' +\n    test_df['nfl_id'].astype(str) + '_' +\n    test_df['frame_id'].astype(str)\n)\n\nsubmission_df = test_df[['id', 'x', 'y']]\nsubmission_df.to_csv(SUBMISSION_FILE, index=False)\n\nprint(f\"Submission file '{SUBMISSION_FILE}' created successfully!\")\nprint(\"Baseline script finished.\")\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-09-25T18:08:49.955593Z","iopub.execute_input":"2025-09-25T18:08:49.955978Z","iopub.status.idle":"2025-09-25T18:10:11.516286Z","shell.execute_reply.started":"2025-09-25T18:08:49.955919Z","shell.execute_reply":"2025-09-25T18:10:11.515206Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd \n\ndf = pd.read_csv('submission.csv')\ndf.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-25T18:10:14.8256Z","iopub.execute_input":"2025-09-25T18:10:14.825955Z","iopub.status.idle":"2025-09-25T18:10:14.844444Z","shell.execute_reply.started":"2025-09-25T18:10:14.825929Z","shell.execute_reply":"2025-09-25T18:10:14.84361Z"}},"outputs":[],"execution_count":null}]}