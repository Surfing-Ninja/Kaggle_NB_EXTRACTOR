{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":114239,"databundleVersionId":13825858,"sourceType":"competition"}],"dockerImageVersionId":31089,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom pathlib import Path\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import KFold\nfrom sklearn.linear_model import Ridge\nimport warnings\nwarnings.filterwarnings('ignore')\n\nfrom multiprocessing import Pool, cpu_count\nfrom tqdm.auto import tqdm\nimport pickle\n\nfrom lightgbm import LGBMRegressor\nfrom xgboost import XGBRegressor\n# CatBoost đã được loại bỏ\n# from catboost import CatBoostRegressor\n\n\nBASE_DIR = Path('/kaggle/input/nfl-big-data-bowl-2026-prediction')\nFIELD_X_MAX, FIELD_Y_MAX = 120.0, 53.3\nTRAIN_VAL_SPLIT = 0.90\nN_FOLDS = 5\nRANDOM_STATE = 42\n\n\ndef load_weekly_data(week_num):\n    input_path = BASE_DIR / f'train/input_2023_w{week_num:02d}.csv'\n    output_path = BASE_DIR / f'train/output_2023_w{week_num:02d}.csv'\n    return pd.read_csv(input_path), pd.read_csv(output_path)\n\n\ndef load_all_training_data():\n    train_input_files = [BASE_DIR / f'train/input_2023_w{w:02d}.csv' for w in range(1, 19)]\n    train_output_files = [BASE_DIR / f'train/output_2023_w{w:02d}.csv' for w in range(1, 19)]\n    \n    train_input_files = [f for f in train_input_files if f.exists()]\n    train_output_files = [f for f in train_output_files if f.exists()]\n    \n    print(f'Found {len(train_input_files)} weeks of data')\n    \n    with Pool(min(cpu_count(), 18)) as pool:\n        results = list(tqdm(pool.imap(load_weekly_data, range(1, 19)), \n                           total=18, desc='Loading data'))\n    \n    input_dfs = [r[0] for r in results]\n    output_dfs = [r[1] for r in results]\n    \n    input_data = pd.concat(input_dfs, ignore_index=True)\n    output_data = pd.concat(output_dfs, ignore_index=True)\n    \n    test_input = pd.read_csv(BASE_DIR / 'test_input.csv')\n    test_template = pd.read_csv(BASE_DIR / 'test.csv')\n    \n    print(f'Input: {input_data.shape}, Output: {output_data.shape}')\n    return input_data, output_data, test_input, test_template\n\n\ndef create_physics_features(df):\n    df = df.copy()\n    \n    dir_rad = np.radians(df['dir'])\n    df['velocity_x'] = df['s'] * np.cos(dir_rad)\n    df['velocity_y'] = df['s'] * np.sin(dir_rad)\n    \n    df['acceleration_x'] = df['a'] * np.cos(dir_rad)\n    df['acceleration_y'] = df['a'] * np.sin(dir_rad)\n    \n    df['dist_to_ball'] = np.sqrt(\n        (df['x'] - df['ball_land_x'])**2 + \n        (df['y'] - df['ball_land_y'])**2\n    )\n    \n    df['angle_to_ball'] = np.arctan2(\n        df['ball_land_y'] - df['y'],\n        df['ball_land_x'] - df['x']\n    )\n    \n    df['velocity_toward_ball'] = (\n        df['velocity_x'] * np.cos(df['angle_to_ball']) + \n        df['velocity_y'] * np.sin(df['angle_to_ball'])\n    )\n    \n    df['time_to_ball'] = df['num_frames_output'] / 10.0\n    \n    df['expected_x_at_ball'] = df['x'] + df['velocity_x'] * df['time_to_ball']\n    df['expected_y_at_ball'] = df['y'] + df['velocity_y'] * df['time_to_ball']\n    \n    df['error_from_ball_x'] = df['expected_x_at_ball'] - df['ball_land_x']\n    df['error_from_ball_y'] = df['expected_y_at_ball'] - df['ball_land_y']\n    df['error_from_ball'] = np.sqrt(\n        df['error_from_ball_x']**2 + df['error_from_ball_y']**2\n    )\n    \n    return df\n\n\ndef create_player_features(df):\n    df = df.copy()\n    \n    df['orientation_diff'] = np.abs(df['o'] - df['dir'])\n    df['orientation_diff'] = np.minimum(df['orientation_diff'], 360 - df['orientation_diff'])\n    \n    df['angle_diff'] = np.abs(df['o'] - np.degrees(df['angle_to_ball']))\n    df['angle_diff'] = np.minimum(df['angle_diff'], 360 - df['angle_diff'])\n    \n    height_parts = df['player_height'].str.split('-', expand=True)\n    df['height_inches'] = height_parts[0].astype(float) * 12 + height_parts[1].astype(float)\n    df['bmi'] = (df['player_weight'] / (df['height_inches']**2)) * 703\n    \n    df['momentum_x'] = df['player_weight'] * df['velocity_x']\n    df['momentum_y'] = df['player_weight'] * df['velocity_y']\n    df['kinetic_energy'] = 0.5 * df['player_weight'] * df['s']**2\n    \n    df['role_targeted_receiver'] = (df['player_role'] == 'Targeted Receiver').astype(int)\n    df['role_defensive_coverage'] = (df['player_role'] == 'Defensive Coverage').astype(int)\n    df['role_passer'] = (df['player_role'] == 'Passer').astype(int)\n    df['side_offense'] = (df['player_side'] == 'Offense').astype(int)\n    \n    return df\n\n\ndef create_derived_features(df):\n    df = df.copy()\n    \n    df['distance_to_target_x'] = df['ball_land_x'] - df['x']\n    df['distance_to_target_y'] = df['ball_land_y'] - df['y']\n    \n    df['speed_squared'] = df['s'] ** 2\n    df['accel_magnitude'] = np.sqrt(df['acceleration_x']**2 + df['acceleration_y']**2)\n    df['velocity_alignment'] = np.cos(df['angle_to_ball'] - np.radians(df['dir']))\n    \n    df['time_squared'] = df['time_to_ball'] ** 2\n    df['dist_squared'] = df['dist_to_ball'] ** 2\n    df['weighted_dist_by_time'] = df['dist_to_ball'] / (df['time_to_ball'] + 0.1)\n    \n    return df\n\n\ndef create_sequence_features(df):\n    df = df.sort_values(['game_id', 'play_id', 'nfl_id', 'frame_id'])\n    group_cols = ['game_id', 'play_id', 'nfl_id']\n    \n    lag_features = ['x', 'y', 'velocity_x', 'velocity_y', 's', 'a']\n    for lag in range(1, 6):\n        for col in lag_features:\n            if col in df.columns:\n                df[f'{col}_lag{lag}'] = df.groupby(group_cols)[col].shift(lag)\n    \n    rolling_features = ['x', 'y', 'velocity_x', 'velocity_y', 's']\n    for window in [3, 5]:\n        for col in rolling_features:\n            if col in df.columns:\n                rolling_mean = df.groupby(group_cols)[col].rolling(\n                    window, min_periods=1\n                ).mean().reset_index(level=[0,1,2], drop=True)\n                \n                rolling_std = df.groupby(group_cols)[col].rolling(\n                    window, min_periods=1\n                ).std().reset_index(level=[0,1,2], drop=True)\n                \n                df[f'{col}_rolling_mean_{window}'] = rolling_mean\n                df[f'{col}_rolling_std_{window}'] = rolling_std\n    \n    for col in ['velocity_x', 'velocity_y']:\n        if col in df.columns:\n            df[f'{col}_delta'] = df.groupby(group_cols)[col].diff()\n    \n    return df\n\n\ndef create_training_dataset(input_df, output_df):\n    output_df = output_df.copy()\n    output_df['id'] = (\n        output_df['game_id'].astype(str) + '_' + \n        output_df['play_id'].astype(str) + '_' + \n        output_df['nfl_id'].astype(str) + '_' + \n        output_df['frame_id'].astype(str)\n    )\n    output_df = output_df.rename(columns={'x': 'target_x', 'y': 'target_y'})\n    \n    input_agg = input_df.groupby(['game_id', 'play_id', 'nfl_id']).last().reset_index()\n    if 'frame_id' in input_agg.columns:\n        input_agg = input_agg.drop('frame_id', axis=1)\n    \n    merged = output_df.merge(\n        input_agg,\n        on=['game_id', 'play_id', 'nfl_id'],\n        how='left',\n        suffixes=('', '_input')\n    )\n    \n    return merged\n\n\n# THAY ĐỔI 1: Loại bỏ CatBoost khỏi hàm get_base_models\ndef get_base_models():\n    lgbm = LGBMRegressor(\n        n_estimators=1500, learning_rate=0.03, max_depth=12, num_leaves=150,\n        subsample=0.85, colsample_bytree=0.85, min_child_samples=50,\n        reg_alpha=0.1, reg_lambda=0.1, n_jobs=-1, verbose=-1, random_state=RANDOM_STATE\n    )\n    \n    xgb = XGBRegressor(\n        n_estimators=1500, learning_rate=0.03, max_depth=10, min_child_weight=50,\n        subsample=0.85, colsample_bytree=0.85, reg_alpha=0.1, reg_lambda=0.1,\n        tree_method='hist', n_jobs=-1, verbosity=0, random_state=RANDOM_STATE\n    )\n    \n    # CatBoost đã bị loại bỏ\n    return {'lgbm': lgbm, 'xgb': xgb}\n\n\ndef train_stacking_ensemble(X, y, X_val, n_folds=N_FOLDS):\n    kf = KFold(n_splits=n_folds, shuffle=True, random_state=RANDOM_STATE)\n    base_models = get_base_models()\n    \n    oof_train = {k: np.zeros(len(X)) for k in base_models}\n    test_preds = {k: [] for k in base_models}\n    \n    print(f'Training {n_folds}-fold stacking ensemble')\n    \n    for fold, (train_idx, val_idx) in enumerate(kf.split(X), 1):\n        X_tr, X_fold_val = X[train_idx], X[val_idx]\n        y_tr, y_fold_val = y[train_idx], y[val_idx]\n        \n        for name, model in base_models.items():\n            model.fit(X_tr, y_tr)\n            oof_train[name][val_idx] = model.predict(X_fold_val)\n            test_preds[name].append(model.predict(X_val))\n            \n            fold_rmse = np.sqrt(mean_squared_error(y_fold_val, oof_train[name][val_idx]))\n            print(f'  Fold {fold} {name.upper()}: {fold_rmse:.4f}')\n    \n    for name in base_models:\n        test_preds[name] = np.mean(test_preds[name], axis=0)\n    \n    meta_X_train = np.column_stack([oof_train[k] for k in base_models])\n    meta_X_val = np.column_stack([test_preds[k] for k in base_models])\n    \n    oof_rmse = {k: np.sqrt(mean_squared_error(y, oof_train[k])) for k in base_models}\n    print(f'OOF RMSE - LGBM: {oof_rmse[\"lgbm\"]:.4f}, XGB: {oof_rmse[\"xgb\"]:.4f}')\n    \n    return meta_X_train, meta_X_val\n\n\ndef main():\n    print('NFL Big Data Bowl 2026 - Stacking Ensemble Pipeline (Fixed)')\n    print(f'CPU cores: {cpu_count()}')\n    \n    input_data, output_data, test_input, test_template = load_all_training_data()\n    \n    print('\\nFeature engineering')\n    input_features = create_physics_features(input_data)\n    input_features = create_player_features(input_features)\n    input_features = create_derived_features(input_features)\n    input_features = create_sequence_features(input_features)\n    \n    print(f'Total features: {input_features.shape[1]}')\n    \n    train_df = create_training_dataset(input_features, output_data)\n    print(f'Training dataset: {train_df.shape}')\n    \n    feature_cols = [\n        'x', 'y', 's', 'a', 'o', 'dir', 'velocity_x', 'velocity_y',\n        'dist_to_ball', 'angle_to_ball', 'velocity_toward_ball', 'time_to_ball',\n        'orientation_diff', 'role_targeted_receiver', 'role_defensive_coverage',\n        'role_passer', 'side_offense', 'height_inches', 'player_weight', 'bmi',\n        'ball_land_x', 'ball_land_y', 'num_frames_output', 'frame_id',\n        'acceleration_x', 'acceleration_y', 'distance_to_target_x', 'distance_to_target_y',\n        'speed_squared', 'accel_magnitude', 'velocity_alignment',\n        'expected_x_at_ball', 'expected_y_at_ball',\n        'error_from_ball_x', 'error_from_ball_y', 'error_from_ball',\n        'momentum_x', 'momentum_y', 'kinetic_energy',\n        'angle_diff', 'time_squared', 'dist_squared', 'weighted_dist_by_time'\n    ]\n    \n    for lag in range(1, 6):\n        for col in ['x', 'y', 'velocity_x', 'velocity_y', 's', 'a']:\n            feature_cols.append(f'{col}_lag{lag}')\n    \n    for window in [3, 5]:\n        for col in ['x', 'y', 'velocity_x', 'velocity_y', 's']:\n            feature_cols.extend([\n                f'{col}_rolling_mean_{window}',\n                f'{col}_rolling_std_{window}'\n            ])\n    \n    feature_cols.extend(['velocity_x_delta', 'velocity_y_delta'])\n    \n    available_features = [col for col in feature_cols if col in train_df.columns]\n    print(f'Available features: {len(available_features)}')\n    \n    train_df = train_df.dropna(subset=available_features + ['target_x', 'target_y'])\n    print(f'Training samples: {train_df.shape[0]:,}')\n    \n    X = train_df[available_features].values\n    y_x = train_df['target_x'].values\n    y_y = train_df['target_y'].values\n    \n    split_idx = int(len(train_df) * TRAIN_VAL_SPLIT)\n    X_train, X_val = X[:split_idx], X[split_idx:]\n    y_x_train, y_x_val = y_x[:split_idx], y_x[split_idx:]\n    y_y_train, y_y_val = y_y[:split_idx], y_y[split_idx:]\n    \n    print(f'\\nTrain: {X_train.shape[0]:,}, Validation: {X_val.shape[0]:,}')\n    \n    print('\\nTraining X coordinate ensemble')\n    meta_X_train_x, meta_X_val_x = train_stacking_ensemble(X_train, y_x_train, X_val)\n    \n    meta_model_x = Ridge(alpha=1.0)\n    meta_model_x.fit(meta_X_train_x, y_x_train)\n    \n    pred_x_val = np.clip(meta_model_x.predict(meta_X_val_x), 0, FIELD_X_MAX)\n    stacking_rmse_x = np.sqrt(mean_squared_error(y_x_val, pred_x_val))\n    print(f'Stacking X RMSE: {stacking_rmse_x:.4f}')\n    \n    print('\\nTraining Y coordinate ensemble')\n    meta_X_train_y, meta_X_val_y = train_stacking_ensemble(X_train, y_y_train, X_val)\n    \n    meta_model_y = Ridge(alpha=1.0)\n    meta_model_y.fit(meta_X_train_y, y_y_train)\n    \n    pred_y_val = np.clip(meta_model_y.predict(meta_X_val_y), 0, FIELD_Y_MAX)\n    stacking_rmse_y = np.sqrt(mean_squared_error(y_y_val, pred_y_val))\n    print(f'Stacking Y RMSE: {stacking_rmse_y:.4f}')\n    \n    final_rmse = np.sqrt(0.5 * (stacking_rmse_x**2 + stacking_rmse_y**2))\n    \n    print(f'\\nFinal Results')\n    print(f'X Coordinate RMSE: {stacking_rmse_x:.4f}')\n    print(f'Y Coordinate RMSE: {stacking_rmse_y:.4f}')\n    print(f'Combined RMSE: {final_rmse:.4f}')\n    print(f'Baseline LGBM: 0.7570')\n    print(f'Improvement: {((0.7570 - final_rmse) / 0.7570 * 100):.2f}%')\n    \n    with open('stacking_models.pkl', 'wb') as f:\n        pickle.dump({\n            'meta_model_x': meta_model_x,\n            'meta_model_y': meta_model_y,\n            'features': available_features,\n            'rmse': final_rmse\n        }, f)\n    \n    print('\\nGenerating submission')\n    test_features = create_physics_features(test_input)\n    test_features = create_player_features(test_features)\n    test_features = create_derived_features(test_features)\n    test_features = create_sequence_features(test_features)\n    \n    test_agg = test_features.groupby(['game_id', 'play_id', 'nfl_id']).last().reset_index()\n    if 'frame_id' in test_agg.columns:\n        test_agg = test_agg.drop('frame_id', axis=1)\n    \n    test_merged = test_template.merge(\n        test_agg, on=['game_id', 'play_id', 'nfl_id'], how='left'\n    )\n    test_merged['id'] = (\n        test_merged['game_id'].astype(str) + '_' + \n        test_merged['play_id'].astype(str) + '_' + \n        test_merged['nfl_id'].astype(str) + '_' + \n        test_merged['frame_id'].astype(str)\n    )\n    \n    for col in available_features:\n        if col not in test_merged.columns:\n            test_merged[col] = 0\n    \n    X_test = test_merged[available_features].fillna(0).values\n\n    # THAY ĐỔI 2: Sửa logic tạo dự đoán cho tập test\n    print('\\nRetraining base models for X coordinate on full training data')\n    base_models_x = get_base_models()\n    for name, model in base_models_x.items():\n        model.fit(X_train, y_x_train)\n    \n    meta_X_test_x = np.column_stack([model.predict(X_test) for model in base_models_x.values()])\n    \n    print('\\nRetraining base models for Y coordinate on full training data')\n    base_models_y = get_base_models()\n    for name, model in base_models_y.items():\n        model.fit(X_train, y_y_train)\n        \n    meta_X_test_y = np.column_stack([model.predict(X_test) for model in base_models_y.values()])\n    \n    pred_x_test = np.clip(meta_model_x.predict(meta_X_test_x), 0, FIELD_X_MAX)\n    pred_y_test = np.clip(meta_model_y.predict(meta_X_test_y), 0, FIELD_Y_MAX)\n    \n    submission = pd.DataFrame({\n        'id': test_merged['id'],\n        'x': pred_x_test,\n        'y': pred_y_test\n    })\n    \n    submission.to_csv('submission.csv', index=False)\n    print(f'Submission saved: {submission.shape}')\n    \n    return final_rmse\n\n\nif __name__ == '__main__':\n    final_rmse = main()\n    print(f'\\nFinal Validation RMSE: {final_rmse:.4f}')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"execution_failed":"2025-10-01T05:34:32.134Z"}},"outputs":[],"execution_count":null}]}