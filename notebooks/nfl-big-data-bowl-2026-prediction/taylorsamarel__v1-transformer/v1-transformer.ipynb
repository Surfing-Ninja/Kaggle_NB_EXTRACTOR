{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":114239,"databundleVersionId":13825858,"sourceType":"competition"}],"dockerImageVersionId":31090,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.cuda.amp import autocast, GradScaler\nfrom pathlib import Path\nfrom typing import List, Tuple, Dict, Optional\nfrom tqdm.auto import tqdm\nimport json\nimport time\n\n# ================================================================================\n# CONFIGURATION SEARCH SYSTEM\n# ================================================================================\n\nclass ConfigSearch:\n    \"\"\"System to quickly test multiple configurations\"\"\"\n    \n    CONFIGS_TO_TEST = [\n        # Baseline\n        {\n            'name': 'baseline',\n            'HIDDEN_DIM': 128,\n            'NUM_GNN_LAYERS': 2,\n            'NUM_ATTENTION_HEADS': 4,\n            'DROPOUT': 0.2,\n            'LEARNING_RATE': 1e-4,\n            'FEATURE_FUSION_DIM': 96\n        },\n        # Larger model\n        {\n            'name': 'large_model',\n            'HIDDEN_DIM': 192,\n            'NUM_GNN_LAYERS': 3,\n            'NUM_ATTENTION_HEADS': 8,\n            'DROPOUT': 0.2,\n            'LEARNING_RATE': 1e-4,\n            'FEATURE_FUSION_DIM': 128\n        },\n        # Higher dropout\n        {\n            'name': 'high_dropout',\n            'HIDDEN_DIM': 128,\n            'NUM_GNN_LAYERS': 2,\n            'NUM_ATTENTION_HEADS': 4,\n            'DROPOUT': 0.3,\n            'LEARNING_RATE': 1e-4,\n            'FEATURE_FUSION_DIM': 96\n        },\n        # Deeper GNN\n        {\n            'name': 'deep_gnn',\n            'HIDDEN_DIM': 128,\n            'NUM_GNN_LAYERS': 4,\n            'NUM_ATTENTION_HEADS': 4,\n            'DROPOUT': 0.2,\n            'LEARNING_RATE': 1e-4,\n            'FEATURE_FUSION_DIM': 96\n        },\n    ]\n    \n    SEARCH_EPOCHS = 5\n    SEARCH_DATA_FRACTION = 0.3\n    \n    @staticmethod\n    def get_results_summary():\n        \"\"\"Print summary of all tested configs\"\"\"\n        try:\n            with open('config_search_results.json', 'r') as f:\n                results = json.load(f)\n            \n            print(\"\\n\" + \"=\"*80)\n            print(\"CONFIG SEARCH RESULTS SUMMARY\")\n            print(\"=\"*80)\n            \n            sorted_results = sorted(results, key=lambda x: x['best_val_loss'])\n            \n            print(f\"\\n{'Rank':<6} {'Config':<15} {'Val Loss':<12} {'Train Loss':<12} {'Params':<12} {'Time(s)':<10}\")\n            print(\"-\"*80)\n            \n            for i, result in enumerate(sorted_results, 1):\n                print(f\"{i:<6} {result['config_name']:<15} {result['best_val_loss']:<12.4f} \"\n                      f\"{result['final_train_loss']:<12.4f} {result['num_parameters']:<12,} \"\n                      f\"{result['training_time']:<10.1f}\")\n            \n            print(\"\\n\" + \"=\"*80)\n            print(f\"BEST CONFIG: {sorted_results[0]['config_name']}\")\n            print(f\"Best Validation Loss: {sorted_results[0]['best_val_loss']:.4f}\")\n            print(\"=\"*80 + \"\\n\")\n            \n            return sorted_results[0]\n            \n        except FileNotFoundError:\n            print(\"No search results found yet.\")\n            return None\n\n# ================================================================================\n# DYNAMIC CONFIGURATION\n# ================================================================================\n\nclass Config:\n    PLAYER_EMBED_DIM = 32\n    SPATIAL_EMBED_DIM = 16\n    HIDDEN_DIM = 128\n    NUM_ATTENTION_HEADS = 4\n    NUM_TRANSFORMER_LAYERS = 2\n    NUM_GNN_LAYERS = 2\n    DROPOUT = 0.2\n    \n    ENGINEERED_FEATURES_DIM = 108\n    FEATURE_FUSION_DIM = 96\n    \n    MAX_FUTURE_FRAMES = 94\n    PREDICTION_HORIZON = 25\n    MULTI_HORIZON_TARGETS = [5, 10, 15, 20, 25]\n    \n    BATCH_SIZE = 16\n    LEARNING_RATE = 1e-4\n    EPOCHS = 25\n    PATIENCE = 8\n    GRADIENT_ACCUMULATION_STEPS = 4\n    USE_AMP = True\n    USE_COMPILE = False\n    \n    WINDOW_SIZE = 10\n    ADAPTIVE_FRAME_SAMPLING = True\n    \n    DATA_DIR = Path(\"/kaggle/input/nfl-big-data-bowl-2026-prediction/\")\n    FIELD_X_MIN, FIELD_X_MAX = 0.0, 120.0\n    FIELD_Y_MIN, FIELD_Y_MAX = 0.0, 53.3\n    FIELD_HASH_LEFT = 17.5\n    FIELD_HASH_RIGHT = 35.8\n    \n    SEARCH_MODE = False\n    \n    @classmethod\n    def update_from_dict(cls, config_dict):\n        \"\"\"Update config from dictionary\"\"\"\n        for key, value in config_dict.items():\n            if hasattr(cls, key):\n                setattr(cls, key, value)\n\n# ================================================================================\n# EFFICIENT COMPONENTS\n# ================================================================================\n\nclass EfficientPositionalEncoding(nn.Module):\n    def __init__(self, d_model: int):\n        super().__init__()\n        self.proj = nn.Linear(2, d_model)\n        \n    def forward(self, positions: torch.Tensor) -> torch.Tensor:\n        return self.proj(positions)\n\nclass EfficientPlayerEncoder(nn.Module):\n    def __init__(self, embed_dim: int):\n        super().__init__()\n        self.role_embed = nn.Embedding(5, embed_dim // 4)\n        self.side_embed = nn.Embedding(2, embed_dim // 4)\n        self.continuous_proj = nn.Linear(8, embed_dim // 2)\n        self.output_proj = nn.Linear(embed_dim, embed_dim)\n        \n    def forward(self, player_features: Dict[str, torch.Tensor]) -> torch.Tensor:\n        role_emb = self.role_embed(player_features['role'])\n        side_emb = self.side_embed(player_features['side'])\n        cont_emb = self.continuous_proj(player_features['continuous'])\n        combined = torch.cat([role_emb, side_emb, cont_emb], dim=-1)\n        return self.output_proj(combined)\n\n# ================================================================================\n# FEATURE INJECTION MODULE\n# ================================================================================\n\nclass FeatureInjectionModule(nn.Module):\n    def __init__(self, feature_dim: int, hidden_dim: int, fusion_dim: int):\n        super().__init__()\n        self.feature_dim = feature_dim\n        \n        if feature_dim > 0:\n            self.feature_encoder = nn.Sequential(\n                nn.Linear(feature_dim, fusion_dim),\n                nn.LayerNorm(fusion_dim),\n                nn.ReLU(),\n                nn.Dropout(Config.DROPOUT),\n                nn.Linear(fusion_dim, fusion_dim)\n            )\n            \n            self.fusion = nn.Sequential(\n                nn.Linear(hidden_dim + fusion_dim, hidden_dim),\n                nn.LayerNorm(hidden_dim),\n                nn.ReLU()\n            )\n        else:\n            self.feature_encoder = None\n            self.fusion = nn.Identity()\n    \n    def forward(self, learned_features: torch.Tensor, \n                engineered_features: Optional[torch.Tensor] = None) -> torch.Tensor:\n        if self.feature_dim > 0 and engineered_features is not None:\n            encoded_features = self.feature_encoder(engineered_features)\n            combined = torch.cat([learned_features, encoded_features], dim=-1)\n            return self.fusion(combined)\n        return learned_features\n\n# ================================================================================\n# EFFICIENT GRAPH ATTENTION - FULLY ROBUST FOR AMP\n# ================================================================================\n\nclass EfficientGraphAttention(nn.Module):\n    def __init__(self, in_features: int, out_features: int, num_heads: int = 2):\n        super().__init__()\n        self.num_heads = num_heads\n        self.head_dim = out_features // num_heads\n        \n        self.W = nn.Linear(in_features, out_features)\n        self.att = nn.Linear(out_features, num_heads)\n        \n    def forward(self, x: torch.Tensor, edge_index: torch.Tensor, \n                edge_attr: torch.Tensor = None) -> torch.Tensor:\n        num_nodes = x.shape[0]\n        \n        target_dtype = x.dtype\n        \n        h = self.W(x)\n        \n        src_idx, dst_idx = edge_index[0], edge_index[1]\n        h_src = h[src_idx]\n        h_dst = h[dst_idx]\n        \n        att_logits = self.att(h_src + h_dst)\n        \n        att_max = torch.zeros(num_nodes, self.num_heads, device=x.device, dtype=target_dtype)\n        \n        att_logits = att_logits.to(target_dtype)\n        att_max.index_reduce_(0, dst_idx, att_logits, 'amax', include_self=False)\n        \n        att_exp = torch.exp(att_logits - att_max[dst_idx])\n        \n        att_sum = torch.zeros(num_nodes, self.num_heads, device=x.device, dtype=target_dtype)\n        att_sum.index_add_(0, dst_idx, att_exp)\n        \n        alpha = att_exp / (att_sum[dst_idx] + 1e-8)\n        \n        h_src_weighted = (h_src.unsqueeze(1) * alpha.unsqueeze(-1)).to(target_dtype)\n        \n        out = torch.zeros(num_nodes, self.num_heads, h.shape[1], device=x.device, dtype=target_dtype)\n        out.index_add_(0, dst_idx, h_src_weighted)\n        \n        return out.mean(dim=1)\n\nclass EfficientGNN(nn.Module):\n    def __init__(self, hidden_dim: int, num_layers: int = 2):\n        super().__init__()\n        self.layers = nn.ModuleList([\n            EfficientGraphAttention(hidden_dim, hidden_dim, num_heads=2)\n            for _ in range(num_layers)\n        ])\n        self.norms = nn.ModuleList([nn.LayerNorm(hidden_dim) for _ in range(num_layers)])\n        \n    def forward(self, x, edge_index, edge_attr=None):\n        for layer, norm in zip(self.layers, self.norms):\n            residual = x\n            x_new = layer(x, edge_index, edge_attr)\n            x = norm(residual.to(x_new.dtype) + x_new)\n            x = F.relu(x)\n        return x\n\n# ================================================================================\n# PARALLEL PLAYER ATTENTION POOLING\n# ================================================================================\n\nclass ParallelPlayerAttention(nn.Module):\n    def __init__(self, d_model: int, num_heads: int):\n        super().__init__()\n        self.num_heads = num_heads\n        self.head_dim = d_model // num_heads\n        \n        self.query_proj = nn.Linear(d_model, d_model)\n        self.key_proj = nn.Linear(d_model, d_model)\n        self.value_proj = nn.Linear(d_model, d_model)\n        self.out_proj = nn.Linear(d_model, d_model)\n        \n        self.norm = nn.LayerNorm(d_model)\n        \n    def forward(self, temporal_features: torch.Tensor) -> torch.Tensor:\n        batch_size, seq_len, num_players, hidden_dim = temporal_features.shape\n        \n        x = temporal_features.permute(0, 2, 1, 3).reshape(batch_size * num_players, seq_len, hidden_dim)\n        \n        q = self.query_proj(x).view(batch_size * num_players, seq_len, self.num_heads, self.head_dim)\n        k = self.key_proj(x).view(batch_size * num_players, seq_len, self.num_heads, self.head_dim)\n        v = self.value_proj(x).view(batch_size * num_players, seq_len, self.num_heads, self.head_dim)\n        \n        q = q.transpose(1, 2)\n        k = k.transpose(1, 2)\n        v = v.transpose(1, 2)\n        \n        scores = torch.matmul(q, k.transpose(-2, -1)) / (self.head_dim ** 0.5)\n        attn = F.softmax(scores, dim=-1)\n        \n        out = torch.matmul(attn, v)\n        out = out.transpose(1, 2).contiguous().view(batch_size * num_players, seq_len, hidden_dim)\n        out = self.out_proj(out)\n        \n        out = out[:, -1, :]\n        out = out.view(batch_size, num_players, hidden_dim)\n        \n        return self.norm(out)\n\n# ================================================================================\n# MULTI-HORIZON DECODER\n# ================================================================================\n\nclass MultiHorizonDecoder(nn.Module):\n    def __init__(self, hidden_dim: int, horizons: List[int]):\n        super().__init__()\n        self.horizons = horizons\n        \n        self.shared = nn.Sequential(\n            nn.Linear(hidden_dim, hidden_dim),\n            nn.LayerNorm(hidden_dim),\n            nn.ReLU(),\n            nn.Dropout(Config.DROPOUT)\n        )\n        \n        self.horizon_heads = nn.ModuleList([\n            nn.Sequential(\n                nn.Linear(hidden_dim, hidden_dim // 2),\n                nn.ReLU(),\n                nn.Linear(hidden_dim // 2, horizon * 2)\n            )\n            for horizon in horizons\n        ])\n        \n    def forward(self, player_states: torch.Tensor, target_horizon: int = None):\n        batch_size, num_players, _ = player_states.shape\n        \n        shared_repr = self.shared(player_states)\n        \n        predictions = {}\n        \n        if target_horizon is not None:\n            idx = self.horizons.index(target_horizon)\n            pred = self.horizon_heads[idx](shared_repr)\n            pred = pred.view(batch_size, num_players, target_horizon, 2)\n            predictions[target_horizon] = pred\n        else:\n            for horizon, head in zip(self.horizons, self.horizon_heads):\n                pred = head(shared_repr)\n                pred = pred.view(batch_size, num_players, horizon, 2)\n                predictions[horizon] = pred\n        \n        return predictions\n\n# ================================================================================\n# ENHANCED MAIN MODEL\n# ================================================================================\n\nclass EnhancedSpatioTemporalPredictor(nn.Module):\n    def __init__(self):\n        super().__init__()\n        \n        self.player_encoder = EfficientPlayerEncoder(Config.PLAYER_EMBED_DIM)\n        self.spatial_encoder = EfficientPositionalEncoding(Config.SPATIAL_EMBED_DIM)\n        \n        self.feature_fusion = nn.Sequential(\n            nn.Linear(Config.PLAYER_EMBED_DIM + Config.SPATIAL_EMBED_DIM + 3, Config.HIDDEN_DIM),\n            nn.ReLU()\n        )\n        \n        self.feature_injection = FeatureInjectionModule(\n            Config.ENGINEERED_FEATURES_DIM,\n            Config.HIDDEN_DIM,\n            Config.FEATURE_FUSION_DIM\n        )\n        \n        self.gnn = EfficientGNN(Config.HIDDEN_DIM, num_layers=Config.NUM_GNN_LAYERS)\n        \n        self.parallel_attention = ParallelPlayerAttention(\n            Config.HIDDEN_DIM,\n            Config.NUM_ATTENTION_HEADS\n        )\n        \n        self.decoder = MultiHorizonDecoder(\n            Config.HIDDEN_DIM,\n            Config.MULTI_HORIZON_TARGETS\n        )\n        \n    def build_graph(self, positions, batch_indices, k=8):\n        device = positions.device\n        num_players = positions.shape[0]\n        \n        dist_matrix = torch.cdist(positions, positions)\n        batch_mask = (batch_indices.unsqueeze(1) == batch_indices.unsqueeze(0))\n        dist_matrix = dist_matrix.masked_fill(~batch_mask, float('inf'))\n        \n        k_actual = min(k + 1, num_players)\n        _, indices = torch.topk(dist_matrix, k=k_actual, dim=1, largest=False)\n        indices = indices[:, 1:]\n        \n        k_actual = indices.shape[1]\n        src = torch.arange(num_players, device=device).unsqueeze(1).expand(-1, k_actual)\n        edge_index = torch.stack([src.flatten(), indices.flatten()], dim=0)\n        \n        src_pos = positions[edge_index[0]]\n        dst_pos = positions[edge_index[1]]\n        edge_attr = torch.cat([\n            dst_pos - src_pos,\n            torch.norm(dst_pos - src_pos, dim=1, keepdim=True)\n        ], dim=1)\n        \n        return edge_index, edge_attr\n    \n    def select_frames(self, seq_len: int) -> List[int]:\n        if not Config.ADAPTIVE_FRAME_SAMPLING or seq_len <= 2:\n            return [0, seq_len - 1] if seq_len > 1 else [0]\n        \n        if seq_len <= 4:\n            return list(range(seq_len))\n        \n        return [0, seq_len // 3, 2 * seq_len // 3, seq_len - 1]\n        \n    def forward(self, batch_data, target_horizon=None, engineered_features=None):\n        batch_size, seq_len, num_players, _ = batch_data['positions'].shape\n        device = batch_data['positions'].device\n        \n        player_emb = self.player_encoder(batch_data['player_features'])\n        \n        frames_to_process = self.select_frames(seq_len)\n        \n        temporal_features = []\n        \n        for t in frames_to_process:\n            pos_t = batch_data['positions'][:, t].reshape(-1, 2)\n            vel_t = batch_data['velocities'][:, t].reshape(-1, 2)\n            acc_t = batch_data['accelerations'][:, t].reshape(-1, 1)\n            \n            spatial_emb = self.spatial_encoder(pos_t)\n            motion_features = torch.cat([vel_t, acc_t], dim=-1)\n            combined = torch.cat([player_emb, spatial_emb, motion_features], dim=-1)\n            node_features = self.feature_fusion(combined)\n            \n            if engineered_features is not None:\n                eng_feat_t = engineered_features[:, t].reshape(-1, Config.ENGINEERED_FEATURES_DIM)\n                node_features = self.feature_injection(node_features, eng_feat_t)\n            \n            batch_indices = torch.arange(batch_size, device=device).repeat_interleave(num_players)\n            edge_index, edge_attr = self.build_graph(pos_t, batch_indices)\n            \n            node_features = self.gnn(node_features, edge_index, edge_attr)\n            node_features = node_features.reshape(batch_size, num_players, -1)\n            temporal_features.append(node_features)\n        \n        temporal_features = torch.stack(temporal_features, dim=1)\n        \n        player_states = self.parallel_attention(temporal_features)\n        \n        predictions = self.decoder(player_states, target_horizon)\n        \n        return predictions\n\n# ================================================================================\n# FEATURE ENGINEERING (keeping all original functions)\n# ================================================================================\n\ndef compute_rolling_statistics(positions_history, velocities_history, accelerations_history):\n    features = np.zeros(8)\n    if len(positions_history) < 2:\n        return features\n    \n    positions = np.array(positions_history)\n    velocities = np.array(velocities_history)\n    accelerations = np.array(accelerations_history)\n    \n    vel_magnitudes = np.sqrt(velocities[:, 0]**2 + velocities[:, 1]**2)\n    features[0] = np.mean(vel_magnitudes) / 10.0\n    features[1] = np.std(vel_magnitudes) / 5.0\n    \n    features[2] = np.mean(accelerations) / 5.0\n    features[3] = np.std(accelerations) / 3.0\n    \n    pos_variance = np.var(positions, axis=0)\n    features[4] = np.sqrt(pos_variance[0]) / 5.0\n    features[5] = np.sqrt(pos_variance[1]) / 5.0\n    \n    if len(velocities) > 1:\n        vel_angles = np.arctan2(velocities[:, 1], velocities[:, 0])\n        angle_diffs = np.diff(vel_angles)\n        angle_diffs = np.abs(np.arctan2(np.sin(angle_diffs), np.cos(angle_diffs)))\n        features[6] = np.mean(angle_diffs) / np.pi\n        features[7] = np.std(angle_diffs) / np.pi\n    \n    return features\n\ndef classify_route(player_pos, ball_land_pos, player_vel, player_role, player_side):\n    features = np.zeros(6)\n    if player_side != 0 or player_role not in [0, 1]:\n        return features\n    \n    depth = ball_land_pos[0] - player_pos[0]\n    lateral = ball_land_pos[1] - player_pos[1]\n    \n    features[0] = 1.0 if depth > 20 else 0.0\n    features[1] = 1.0 if 10 <= depth <= 20 else 0.0\n    features[2] = 1.0 if depth < 10 else 0.0\n    \n    field_center = Config.FIELD_Y_MAX / 2\n    if player_pos[1] < field_center and lateral > 0:\n        features[3] = 1.0\n    elif player_pos[1] > field_center and lateral < 0:\n        features[3] = 1.0\n    else:\n        features[4] = 1.0 if abs(lateral) > 3 else 0.0\n    \n    vel_magnitude = np.sqrt(player_vel[0]**2 + player_vel[1]**2)\n    if vel_magnitude > 0:\n        vel_angle = np.arctan2(player_vel[1], player_vel[0])\n        route_angle = np.arctan2(lateral, depth)\n        angle_diff = abs(vel_angle - route_angle)\n        if angle_diff > np.pi:\n            angle_diff = 2 * np.pi - angle_diff\n        features[5] = 1.0 - (angle_diff / np.pi)\n    \n    return features\n\ndef compute_pursuit_angles(player_pos, player_vel, player_side, player_role, \n                          ball_land_pos, targeted_receiver_pos):\n    features = np.zeros(6)\n    if player_side != 1:\n        return features\n    \n    target = targeted_receiver_pos if targeted_receiver_pos is not None else ball_land_pos\n    \n    dx = target[0] - player_pos[0]\n    dy = target[1] - player_pos[1]\n    optimal_angle = np.arctan2(dy, dx)\n    \n    vel_magnitude = np.sqrt(player_vel[0]**2 + player_vel[1]**2)\n    if vel_magnitude > 0.1:\n        current_angle = np.arctan2(player_vel[1], player_vel[0])\n        angle_diff = abs(current_angle - optimal_angle)\n        if angle_diff > np.pi:\n            angle_diff = 2 * np.pi - angle_diff\n        features[0] = angle_diff / np.pi\n        \n        pursuit_efficiency = np.cos(angle_diff)\n        features[1] = max(0, pursuit_efficiency)\n    else:\n        features[0] = 0.5\n        features[1] = 0.0\n    \n    distance_to_target = np.sqrt(dx**2 + dy**2)\n    if distance_to_target > 0.1:\n        closing_velocity = (player_vel[0] * dx + player_vel[1] * dy) / distance_to_target\n        features[2] = np.clip(closing_velocity / 10.0, -1.0, 1.0)\n        \n        if vel_magnitude > 0.1:\n            time_to_intercept = distance_to_target / vel_magnitude\n            features[3] = min(time_to_intercept / 5.0, 1.0)\n        else:\n            features[3] = 1.0\n    \n    features[4] = distance_to_target / 30.0\n    \n    ball_dist = np.sqrt((ball_land_pos[0] - player_pos[0])**2 + \n                       (ball_land_pos[1] - player_pos[1])**2)\n    features[5] = ball_dist / 40.0\n    \n    return features\n\ndef compute_formation_features(all_positions, all_sides, all_roles, ball_land_pos):\n    num_players = len(all_positions)\n    features = np.zeros((num_players, 8))\n    \n    offense_positions = all_positions[all_sides == 0]\n    offense_roles = all_roles[all_sides == 0]\n    \n    if len(offense_positions) == 0:\n        return features\n    \n    field_center = Config.FIELD_Y_MAX / 2\n    left_receivers = np.sum((offense_positions[:, 1] < field_center) & \n                           ((offense_roles == 0) | (offense_roles == 1)))\n    right_receivers = np.sum((offense_positions[:, 1] > field_center) & \n                            ((offense_roles == 0) | (offense_roles == 1)))\n    \n    receiver_positions = offense_positions[(offense_roles == 0) | (offense_roles == 1)]\n    if len(receiver_positions) > 0:\n        depths = receiver_positions[:, 0]\n        deep_receivers = np.sum(depths > np.mean(depths) + 5)\n        shallow_receivers = np.sum(depths < np.mean(depths) - 5)\n    else:\n        deep_receivers = 0\n        shallow_receivers = 0\n    \n    te_present = np.any(offense_roles == 3)\n    \n    passer_positions = offense_positions[offense_roles == 3]\n    if len(passer_positions) > 0:\n        passer_depth = passer_positions[0, 0]\n    else:\n        passer_depth = np.mean(offense_positions[:, 0]) if len(offense_positions) > 0 else 50\n    \n    for p_idx in range(num_players):\n        features[p_idx, 0] = left_receivers / 5.0\n        features[p_idx, 1] = right_receivers / 5.0\n        features[p_idx, 2] = deep_receivers / 3.0\n        features[p_idx, 3] = shallow_receivers / 3.0\n        features[p_idx, 4] = 1.0 if te_present else 0.0\n        features[p_idx, 5] = passer_depth / Config.FIELD_X_MAX\n        \n        if all_sides[p_idx] == 0:\n            features[p_idx, 6] = 1.0 if all_positions[p_idx, 1] < field_center else 0.0\n            features[p_idx, 7] = abs(all_positions[p_idx, 1] - field_center) / (Config.FIELD_Y_MAX / 2)\n    \n    return features\n\ndef compute_coverage_features(all_positions, all_sides, all_roles, ball_land_pos):\n    num_players = len(all_positions)\n    features = np.zeros((num_players, 6))\n    \n    defense_positions = all_positions[all_sides == 1]\n    defense_roles = all_roles[all_sides == 1]\n    \n    if len(defense_positions) == 0:\n        return features\n    \n    offense_positions = all_positions[all_sides == 0]\n    \n    db_positions = defense_positions[defense_roles == 2]\n    if len(db_positions) > 0:\n        avg_db_depth = np.mean(db_positions[:, 0])\n        deep_coverage = np.sum(db_positions[:, 0] > avg_db_depth + 5)\n    else:\n        avg_db_depth = ball_land_pos[0]\n        deep_coverage = 0\n    \n    for p_idx in range(num_players):\n        if all_sides[p_idx] == 1:\n            features[p_idx, 0] = avg_db_depth / Config.FIELD_X_MAX\n            features[p_idx, 1] = deep_coverage / 4.0\n            \n            if len(offense_positions) > 0:\n                distances_to_offense = np.sqrt(np.sum((offense_positions - all_positions[p_idx])**2, axis=1))\n                min_distance = np.min(distances_to_offense)\n                features[p_idx, 2] = 1.0 if min_distance < 3.0 else 0.0\n                features[p_idx, 3] = 1.0 if min_distance > 8.0 else 0.0\n            \n            features[p_idx, 4] = 1.0 if all_positions[p_idx, 0] < avg_db_depth - 3 else 0.0\n            \n            if len(defense_positions) > 1:\n                distances_to_teammates = np.sqrt(np.sum((defense_positions - all_positions[p_idx])**2, axis=1))\n                distances_to_teammates = distances_to_teammates[distances_to_teammates > 0]\n                if len(distances_to_teammates) > 0:\n                    avg_teammate_distance = np.mean(distances_to_teammates)\n                    features[p_idx, 5] = avg_teammate_distance / 15.0\n    \n    return features\n\ndef compute_player_interaction_features(all_positions, all_velocities, all_sides, all_roles, player_idx):\n    features = np.zeros(15)\n    player_pos = all_positions[player_idx]\n    player_vel = all_velocities[player_idx]\n    player_side = all_sides[player_idx]\n    \n    opponents = all_positions[all_sides != player_side]\n    teammates = all_positions[all_sides == player_side]\n    \n    if len(opponents) > 0:\n        opponent_distances = np.linalg.norm(opponents - player_pos, axis=1)\n        nearest_opponent_dist = np.min(opponent_distances)\n        features[0] = nearest_opponent_dist / 10.0\n        \n        features[1] = np.sum(opponent_distances < 3.0) / 5.0\n        features[2] = np.sum(opponent_distances < 5.0) / 7.0\n        features[3] = np.sum(opponent_distances < 10.0) / 11.0\n        \n        nearest_idx = np.argmin(opponent_distances)\n        nearest_opp_vel = all_velocities[np.where(all_sides != player_side)[0][nearest_idx]]\n        direction_to_player = (player_pos - opponents[nearest_idx]) / (opponent_distances[nearest_idx] + 1e-6)\n        closing_velocity = np.dot(nearest_opp_vel, direction_to_player)\n        features[4] = np.clip(closing_velocity / 10.0, -1, 1)\n        \n        pressure_weights = np.exp(-opponent_distances / 5.0)\n        features[5] = np.sum(pressure_weights) / 10.0\n    \n    if len(teammates) > 1:\n        teammate_distances = np.linalg.norm(teammates - player_pos, axis=1)\n        teammate_distances = teammate_distances[teammate_distances > 0.1]\n        if len(teammate_distances) > 0:\n            features[6] = np.min(teammate_distances) / 10.0\n            features[7] = np.mean(teammate_distances) / 15.0\n            \n            features[8] = np.std(teammates[:, 0]) / 10.0\n            features[9] = np.std(teammates[:, 1]) / 8.0\n    \n    if len(opponents) > 0:\n        sorted_dists = np.sort(opponent_distances)\n        features[10] = np.mean(sorted_dists[:min(3, len(sorted_dists))]) / 10.0\n    \n    if len(opponents) > 0:\n        nearest_idx = np.argmin(opponent_distances)\n        nearest_opp_vel = all_velocities[np.where(all_sides != player_side)[0][nearest_idx]]\n        separation_velocity = np.linalg.norm(player_vel - nearest_opp_vel)\n        features[11] = separation_velocity / 10.0\n    \n    if player_side == 0:\n        db_positions = all_positions[(all_sides == 1) & (all_roles == 2)]\n        if len(db_positions) > 0:\n            db_distances = np.linalg.norm(db_positions - player_pos, axis=1)\n            features[12] = np.min(db_distances) / 10.0\n    else:\n        receiver_positions = all_positions[(all_sides == 0) & ((all_roles == 0) | (all_roles == 1))]\n        if len(receiver_positions) > 0:\n            receiver_distances = np.linalg.norm(receiver_positions - player_pos, axis=1)\n            features[13] = np.min(receiver_distances) / 10.0\n    \n    all_distances = np.linalg.norm(all_positions - player_pos, axis=1)\n    features[14] = (np.sum(all_distances < 10.0) - 1) / 15.0\n    \n    return features\n\ndef compute_trajectory_features(positions_history, velocities_history, accelerations_history, \n                                ball_land_pos, time_to_ball):\n    features = np.zeros(12)\n    \n    if len(positions_history) < 2:\n        return features\n    \n    current_pos = positions_history[-1]\n    current_vel = velocities_history[-1]\n    current_acc = accelerations_history[-1]\n    \n    straight_pred = current_pos + current_vel * time_to_ball\n    features[0] = np.linalg.norm(straight_pred - ball_land_pos) / 50.0\n    \n    if len(accelerations_history) > 0:\n        acc_pred = current_pos + current_vel * time_to_ball + 0.5 * current_acc * (time_to_ball ** 2)\n        features[1] = np.linalg.norm(acc_pred - ball_land_pos) / 50.0\n    \n    if time_to_ball > 0:\n        optimal_velocity = (ball_land_pos - current_pos) / time_to_ball\n        features[2] = np.linalg.norm(optimal_velocity) / 15.0\n        \n        velocity_deficit = np.linalg.norm(current_vel - optimal_velocity)\n        features[3] = velocity_deficit / 10.0\n        \n        if np.linalg.norm(current_vel) > 0.1 and np.linalg.norm(optimal_velocity) > 0.1:\n            cos_angle = np.dot(current_vel, optimal_velocity) / (np.linalg.norm(current_vel) * np.linalg.norm(optimal_velocity))\n            features[4] = (1 - cos_angle) / 2\n    \n    if len(positions_history) >= 3:\n        recent_positions = np.array(positions_history[-3:])\n        vec1 = recent_positions[1] - recent_positions[0]\n        vec2 = recent_positions[2] - recent_positions[1]\n        if np.linalg.norm(vec1) > 0.1 and np.linalg.norm(vec2) > 0.1:\n            cos_curve = np.dot(vec1, vec2) / (np.linalg.norm(vec1) * np.linalg.norm(vec2))\n            features[5] = (1 - cos_curve) / 2\n    \n    if len(velocities_history) >= 3:\n        recent_speeds = [np.linalg.norm(v) for v in velocities_history[-3:]]\n        features[6] = (recent_speeds[-1] - recent_speeds[0]) / 10.0\n        features[7] = np.std(recent_speeds) / 3.0\n    \n    if len(positions_history) >= 3:\n        start_pos = positions_history[-3]\n        end_pos = positions_history[-1]\n        mid_expected = (start_pos + end_pos) / 2\n        mid_actual = positions_history[-2]\n        features[8] = np.linalg.norm(mid_actual - mid_expected) / 5.0\n    \n    if time_to_ball > 0:\n        displacement_needed = ball_land_pos - current_pos\n        required_acc = 2 * (displacement_needed - current_vel * time_to_ball) / (time_to_ball ** 2)\n        features[9] = np.linalg.norm(required_acc) / 10.0\n    \n    if len(accelerations_history) >= 2:\n        acc_change = accelerations_history[-1] - accelerations_history[-2]\n        features[10] = np.linalg.norm(acc_change) / 5.0\n    \n    if time_to_ball > 0:\n        target_direction = (ball_land_pos - current_pos) / (np.linalg.norm(ball_land_pos - current_pos) + 1e-6)\n        momentum_toward_target = np.dot(current_vel, target_direction)\n        features[11] = momentum_toward_target / 10.0\n    \n    return features\n\ndef compute_zone_and_route_features(player_pos, ball_land_pos, all_positions, all_sides, \n                                    all_roles, player_idx):\n    features = np.zeros(14)\n    \n    player_side = all_sides[player_idx]\n    player_role = all_roles[player_idx]\n    \n    if player_pos[1] < Config.FIELD_HASH_LEFT:\n        features[0] = 1.0\n    elif player_pos[1] > Config.FIELD_HASH_RIGHT:\n        features[1] = 1.0\n    else:\n        features[2] = 1.0\n    \n    if ball_land_pos[1] < Config.FIELD_HASH_LEFT:\n        features[3] = 1.0\n    elif ball_land_pos[1] > Config.FIELD_HASH_RIGHT:\n        features[4] = 1.0\n    else:\n        features[5] = 1.0\n    \n    features[6] = 1.0 if (features[0] and (features[4] or features[5])) or \\\n                         (features[1] and (features[3] or features[5])) else 0.0\n    \n    features[7] = 1.0 if ball_land_pos[0] > 100 or ball_land_pos[0] < 20 else 0.0\n    \n    depth = ball_land_pos[0] - player_pos[0]\n    features[8] = 1.0 if depth < 5 else 0.0\n    features[9] = 1.0 if 5 <= depth < 15 else 0.0\n    features[10] = 1.0 if depth >= 15 else 0.0\n    \n    features[11] = min(player_pos[1], Config.FIELD_Y_MAX - player_pos[1]) / Config.FIELD_Y_MAX\n    \n    features[12] = min(ball_land_pos[1], Config.FIELD_Y_MAX - ball_land_pos[1]) / Config.FIELD_Y_MAX\n    \n    if player_side == 0:\n        receiver_positions = all_positions[(all_sides == 0) & ((all_roles == 0) | (all_roles == 1))]\n        if len(receiver_positions) > 0:\n            same_zone_receivers = 0\n            for recv_pos in receiver_positions:\n                if abs(recv_pos[1] - player_pos[1]) < 10:\n                    same_zone_receivers += 1\n            features[13] = same_zone_receivers / 5.0\n    \n    return features\n\ndef compute_physics_features(player_pos, player_vel, player_acc, player_weight, ball_land_pos, time_to_ball):\n    features = np.zeros(13)\n    \n    vel_magnitude = np.linalg.norm(player_vel)\n    features[0] = vel_magnitude / 10.0\n    \n    features[1] = vel_magnitude ** 2 / 100.0\n    \n    acc_magnitude = np.linalg.norm(player_acc)\n    features[2] = acc_magnitude / 5.0\n    \n    features[3] = player_weight * player_vel[0] / 2000.0\n    features[4] = player_weight * player_vel[1] / 2000.0\n    \n    features[5] = 0.5 * player_weight * (vel_magnitude ** 2) / 10000.0\n    \n    if time_to_ball > 0:\n        expected_pos = player_pos + player_vel * time_to_ball\n        features[6] = expected_pos[0] / Config.FIELD_X_MAX\n        features[7] = expected_pos[1] / Config.FIELD_Y_MAX\n        \n        error = np.linalg.norm(expected_pos - ball_land_pos)\n        features[8] = error / 50.0\n        \n        distance_to_ball = np.linalg.norm(ball_land_pos - player_pos)\n        features[9] = distance_to_ball / (time_to_ball + 0.1) / 10.0\n    \n    distance_to_ball = np.linalg.norm(ball_land_pos - player_pos)\n    if distance_to_ball > 0.1:\n        direction_to_ball = (ball_land_pos - player_pos) / distance_to_ball\n        velocity_toward_ball = np.dot(player_vel, direction_to_ball)\n        features[10] = velocity_toward_ball / 10.0\n    \n    features[11] = time_to_ball ** 2 / 25.0\n    features[12] = distance_to_ball ** 2 / 2500.0\n    \n    return features\n\ndef compute_comprehensive_features(player_idx, positions_window, velocities_window, \n                                  accelerations_window, player_sides, player_roles,\n                                  ball_land_pos, all_positions_current, all_velocities_current,\n                                  player_weight, time_to_ball):\n    features = np.zeros(108)\n    \n    player_pos = positions_window[-1][player_idx]\n    player_vel = velocities_window[-1][player_idx]\n    player_acc = accelerations_window[-1][player_idx]\n    player_side = player_sides[player_idx]\n    player_role = player_roles[player_idx]\n    \n    positions_history = [pos[player_idx] for pos in positions_window]\n    velocities_history = [vel[player_idx] for vel in velocities_window]\n    accelerations_history = [acc[player_idx] for acc in accelerations_window]\n    \n    rolling_stats = compute_rolling_statistics(positions_history, velocities_history, \n                                               accelerations_history)\n    features[0:8] = rolling_stats\n    \n    route_features = classify_route(player_pos, ball_land_pos, player_vel, \n                                    player_role, player_side)\n    features[8:14] = route_features\n    \n    targeted_receiver_positions = all_positions_current[player_roles == 0]\n    targeted_receiver_pos = targeted_receiver_positions[0] if len(targeted_receiver_positions) > 0 else None\n    \n    pursuit_features = compute_pursuit_angles(player_pos, player_vel, player_side, \n                                             player_role, ball_land_pos, \n                                             targeted_receiver_pos)\n    features[14:20] = pursuit_features\n    \n    formation_features = compute_formation_features(all_positions_current, player_sides, \n                                                   player_roles, ball_land_pos)\n    features[20:28] = formation_features[player_idx]\n    \n    coverage_features = compute_coverage_features(all_positions_current, player_sides, \n                                                  player_roles, ball_land_pos)\n    features[28:34] = coverage_features[player_idx]\n    \n    dx_ball = ball_land_pos[0] - player_pos[0]\n    dy_ball = ball_land_pos[1] - player_pos[1]\n    distance_to_ball = np.sqrt(dx_ball**2 + dy_ball**2)\n    features[34] = distance_to_ball / 50.0\n    \n    angle_to_ball = np.arctan2(dy_ball, dx_ball)\n    features[35] = angle_to_ball / np.pi\n    \n    opponent_side = 1 - player_side\n    opponent_positions = all_positions_current[player_sides == opponent_side]\n    if len(opponent_positions) > 0:\n        distances_to_opponents = np.sqrt(np.sum((opponent_positions - player_pos)**2, axis=1))\n        features[36] = np.min(distances_to_opponents) / 20.0\n    else:\n        features[36] = 1.0\n    \n    all_distances = np.sqrt(np.sum((all_positions_current - player_pos)**2, axis=1))\n    features[37] = (np.sum(all_distances < 5.0) - 1) / 10.0\n    \n    features[38] = min(player_pos[1], Config.FIELD_Y_MAX - player_pos[1]) / Config.FIELD_Y_MAX\n    features[39] = min(player_pos[0], Config.FIELD_X_MAX - player_pos[0]) / Config.FIELD_X_MAX\n    features[40] = 1.0 if player_role == 0 else 0.0\n    features[41] = player_pos[0] / Config.FIELD_X_MAX if player_side == 0 else 1.0 - player_pos[0] / Config.FIELD_X_MAX\n    \n    interaction_features = compute_player_interaction_features(\n        all_positions_current, all_velocities_current, player_sides, player_roles, player_idx\n    )\n    features[42:57] = interaction_features\n    \n    trajectory_features = compute_trajectory_features(\n        positions_history, velocities_history, accelerations_history, ball_land_pos, time_to_ball\n    )\n    features[57:69] = trajectory_features\n    \n    zone_features = compute_zone_and_route_features(\n        player_pos, ball_land_pos, all_positions_current, player_sides, player_roles, player_idx\n    )\n    features[69:83] = zone_features\n    \n    physics_features = compute_physics_features(\n        player_pos, player_vel, player_acc, player_weight, ball_land_pos, time_to_ball\n    )\n    features[83:96] = physics_features\n    \n    features[96] = player_pos[0] / Config.FIELD_X_MAX\n    features[97] = player_pos[1] / Config.FIELD_Y_MAX\n    features[98] = (Config.FIELD_X_MAX - player_pos[0]) / Config.FIELD_X_MAX\n    features[99] = (Config.FIELD_Y_MAX - player_pos[1]) / Config.FIELD_Y_MAX\n    \n    features[100] = dx_ball / Config.FIELD_X_MAX\n    features[101] = dy_ball / Config.FIELD_Y_MAX\n    \n    vel_magnitude = np.linalg.norm(player_vel)\n    if vel_magnitude > 0.1 and distance_to_ball > 0.1:\n        direction_to_ball = np.array([dx_ball, dy_ball]) / distance_to_ball\n        velocity_alignment = np.dot(player_vel / vel_magnitude, direction_to_ball)\n        features[102] = velocity_alignment\n    \n    features[103] = np.log1p(distance_to_ball) / 5.0\n    features[104] = np.sqrt(distance_to_ball) / 10.0\n    \n    if len(opponent_positions) > 0:\n        avg_opponent_distance = np.mean(distances_to_opponents)\n        features[105] = avg_opponent_distance / 20.0\n        \n        close_opponents = np.sum(distances_to_opponents < 5.0)\n        features[106] = close_opponents / 5.0\n    \n    features[107] = 1.0 / (time_to_ball + 1.0)\n    \n    return features\n\n# ================================================================================\n# TRAINING\n# ================================================================================\n\ndef train_model_enhanced(model, train_data, val_data, epochs=30, config_name=\"default\"):\n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    print(f\"\\nTraining {config_name}\")\n    print(f\"Using device: {device}\")\n    \n    model = model.to(device)\n    \n    optimizer = torch.optim.AdamW(model.parameters(), lr=Config.LEARNING_RATE, weight_decay=1e-5)\n    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=3, factor=0.5)\n    \n    scaler = GradScaler('cuda') if Config.USE_AMP and torch.cuda.is_available() else None\n    \n    best_val_loss = float('inf')\n    patience_counter = 0\n    patience = 3 if Config.SEARCH_MODE else Config.PATIENCE\n    \n    start_time = time.time()\n    \n    for epoch in range(epochs):\n        model.train()\n        train_losses = []\n        optimizer.zero_grad()\n        \n        pbar = tqdm(train_data, desc=f\"Epoch {epoch+1}/{epochs}\", leave=False)\n        for batch_idx, batch in enumerate(pbar):\n            batch_dict = {\n                'positions': torch.FloatTensor(batch['positions']).unsqueeze(0).to(device),\n                'velocities': torch.FloatTensor(batch['velocities']).unsqueeze(0).to(device),\n                'accelerations': torch.FloatTensor(batch['accelerations']).unsqueeze(0).to(device),\n                'player_features': {\n                    'role': torch.LongTensor(batch['player_roles']).to(device),\n                    'side': torch.LongTensor(batch['player_sides']).to(device),\n                    'continuous': torch.FloatTensor(batch['player_continuous']).to(device)\n                }\n            }\n            \n            targets = torch.FloatTensor(batch['targets']).unsqueeze(0).to(device)\n            engineered_features = torch.FloatTensor(batch['engineered_features']).unsqueeze(0).to(device)\n            \n            if Config.USE_AMP and scaler is not None:\n                with autocast('cuda'):\n                    predictions = model(batch_dict, engineered_features=engineered_features)\n                    \n                    loss = 0\n                    for horizon, pred in predictions.items():\n                        target_slice = targets[:, :, :horizon, :]\n                        horizon_loss = F.mse_loss(pred, target_slice)\n                        weight = horizon / max(predictions.keys())\n                        loss += weight * horizon_loss\n                    \n                    loss = loss / Config.GRADIENT_ACCUMULATION_STEPS\n                \n                scaler.scale(loss).backward()\n                \n                if (batch_idx + 1) % Config.GRADIENT_ACCUMULATION_STEPS == 0:\n                    scaler.unscale_(optimizer)\n                    torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n                    scaler.step(optimizer)\n                    scaler.update()\n                    optimizer.zero_grad()\n            else:\n                predictions = model(batch_dict, engineered_features=engineered_features)\n                \n                loss = 0\n                for horizon, pred in predictions.items():\n                    target_slice = targets[:, :, :horizon, :]\n                    horizon_loss = F.mse_loss(pred, target_slice)\n                    weight = horizon / max(predictions.keys())\n                    loss += weight * horizon_loss\n                \n                loss = loss / Config.GRADIENT_ACCUMULATION_STEPS\n                loss.backward()\n                \n                if (batch_idx + 1) % Config.GRADIENT_ACCUMULATION_STEPS == 0:\n                    torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n                    optimizer.step()\n                    optimizer.zero_grad()\n            \n            train_losses.append(loss.item() * Config.GRADIENT_ACCUMULATION_STEPS)\n            pbar.set_postfix({'loss': f\"{np.mean(train_losses):.4f}\"})\n        \n        model.eval()\n        val_losses = []\n        \n        with torch.no_grad():\n            for batch in val_data:\n                batch_dict = {\n                    'positions': torch.FloatTensor(batch['positions']).unsqueeze(0).to(device),\n                    'velocities': torch.FloatTensor(batch['velocities']).unsqueeze(0).to(device),\n                    'accelerations': torch.FloatTensor(batch['accelerations']).unsqueeze(0).to(device),\n                    'player_features': {\n                        'role': torch.LongTensor(batch['player_roles']).to(device),\n                        'side': torch.LongTensor(batch['player_sides']).to(device),\n                        'continuous': torch.FloatTensor(batch['player_continuous']).to(device)\n                    }\n                }\n                \n                targets = torch.FloatTensor(batch['targets']).unsqueeze(0).to(device)\n                engineered_features = torch.FloatTensor(batch['engineered_features']).unsqueeze(0).to(device)\n                \n                if Config.USE_AMP and scaler is not None:\n                    with autocast('cuda'):\n                        predictions = model(batch_dict, engineered_features=engineered_features)\n                        loss = 0\n                        for horizon, pred in predictions.items():\n                            target_slice = targets[:, :, :horizon, :]\n                            horizon_loss = F.mse_loss(pred, target_slice)\n                            weight = horizon / max(predictions.keys())\n                            loss += weight * horizon_loss\n                else:\n                    predictions = model(batch_dict, engineered_features=engineered_features)\n                    loss = 0\n                    for horizon, pred in predictions.items():\n                        target_slice = targets[:, :, :horizon, :]\n                        horizon_loss = F.mse_loss(pred, target_slice)\n                        weight = horizon / max(predictions.keys())\n                        loss += weight * horizon_loss\n                \n                val_losses.append(loss.item())\n        \n        mean_train_loss = np.mean(train_losses)\n        mean_val_loss = np.mean(val_losses)\n        \n        print(f\"Epoch {epoch+1}/{epochs}: Train={mean_train_loss:.4f}, Val={mean_val_loss:.4f}\")\n        \n        scheduler.step(mean_val_loss)\n        \n        if mean_val_loss < best_val_loss:\n            best_val_loss = mean_val_loss\n            patience_counter = 0\n            if not Config.SEARCH_MODE:\n                torch.save(model.state_dict(), f'best_{config_name}_model.pt')\n        else:\n            patience_counter += 1\n            if patience_counter >= patience:\n                print(f\"Early stopping at epoch {epoch+1}\")\n                break\n    \n    training_time = time.time() - start_time\n    \n    return model, best_val_loss, mean_train_loss, training_time\n\n# ================================================================================\n# DATA LOADING\n# ================================================================================\n\ndef load_data():\n    print(\"Loading data...\")\n    train_input_files = [Config.DATA_DIR / f\"train/input_2023_w{w:02d}.csv\" for w in range(1, 19)]\n    train_output_files = [Config.DATA_DIR / f\"train/output_2023_w{w:02d}.csv\" for w in range(1, 19)]\n    \n    train_input_files = [f for f in train_input_files if f.exists()]\n    train_output_files = [f for f in train_output_files if f.exists()]\n    \n    train_input = pd.concat([pd.read_csv(f) for f in train_input_files], ignore_index=True)\n    train_output = pd.concat([pd.read_csv(f) for f in train_output_files], ignore_index=True)\n    \n    test_input = pd.read_csv(Config.DATA_DIR / \"test_input.csv\")\n    test_template = pd.read_csv(Config.DATA_DIR / \"test.csv\")\n    \n    return train_input, train_output, test_input, test_template\n\ndef prepare_graph_data(input_df, output_df=None, window_size=8, is_training=True):\n    data_list = []\n    \n    for (game_id, play_id), play_group in tqdm(input_df.groupby(['game_id', 'play_id']), desc=\"Processing\"):\n        players = play_group['nfl_id'].unique()\n        num_players = len(players)\n        \n        if num_players == 0:\n            continue\n        \n        ball_land_x = play_group['ball_land_x'].iloc[0]\n        ball_land_y = play_group['ball_land_y'].iloc[0]\n        \n        if pd.isna(ball_land_x) or pd.isna(ball_land_y):\n            ball_land_x = play_group['x'].mean()\n            ball_land_y = play_group['y'].mean()\n        \n        positions = np.zeros((window_size, num_players, 2))\n        velocities = np.zeros((window_size, num_players, 2))\n        accelerations = np.zeros((window_size, num_players, 1))\n        engineered_features = np.zeros((window_size, num_players, Config.ENGINEERED_FEATURES_DIM))\n        player_roles = np.zeros(num_players, dtype=np.int64)\n        player_sides = np.zeros(num_players, dtype=np.int64)\n        player_continuous = np.zeros((num_players, 8))\n        player_weights = np.zeros(num_players)\n        \n        for p_idx, nfl_id in enumerate(players):\n            player_data = play_group[play_group['nfl_id'] == nfl_id].sort_values('frame_id').tail(window_size)\n            \n            if len(player_data) < window_size:\n                pad_df = pd.DataFrame(np.nan, index=range(window_size - len(player_data)), columns=player_data.columns)\n                player_data = pd.concat([pad_df, player_data], ignore_index=True)\n            \n            positions[:, p_idx, 0] = player_data['x'].bfill().fillna(0).values\n            positions[:, p_idx, 1] = player_data['y'].bfill().fillna(0).values\n            \n            dir_rad = np.deg2rad(player_data['dir'].fillna(0))\n            velocities[:, p_idx, 0] = (player_data['s'] * np.cos(dir_rad)).fillna(0).values\n            velocities[:, p_idx, 1] = (player_data['s'] * np.sin(dir_rad)).fillna(0).values\n            accelerations[:, p_idx, 0] = player_data['a'].fillna(0).values\n            \n            last_frame = player_data.iloc[-1]\n            role_map = {'Targeted Receiver': 0, 'Other Route Runner': 1, 'Defensive Coverage': 2, 'Passer': 3}\n            player_roles[p_idx] = role_map.get(last_frame['player_role'], 4)\n            player_sides[p_idx] = 0 if last_frame['player_side'] == 'Offense' else 1\n            \n            try:\n                h = last_frame['player_height'].split('-')\n                height = float(h[0]) * 12 + float(h[1])\n            except:\n                height = 70\n            \n            weight = last_frame['player_weight'] if pd.notna(last_frame['player_weight']) else 200\n            player_weights[p_idx] = weight\n            \n            player_continuous[p_idx] = [\n                height,\n                weight,\n                last_frame['s'] if pd.notna(last_frame['s']) else 0,\n                last_frame['a'] if pd.notna(last_frame['a']) else 0,\n                last_frame['o'] if pd.notna(last_frame['o']) else 0,\n                last_frame['dir'] if pd.notna(last_frame['dir']) else 0,\n                last_frame['absolute_yardline_number'] if pd.notna(last_frame['absolute_yardline_number']) else 50,\n                0\n            ]\n        \n        num_frames_output = play_group['num_frames_output'].iloc[0] if 'num_frames_output' in play_group.columns else 25\n        time_to_ball = num_frames_output / 10.0\n        \n        for t in range(window_size):\n            positions_window = positions[:t+1]\n            velocities_window = velocities[:t+1]\n            accelerations_window = accelerations[:t+1, :, 0]\n            \n            ball_land_pos = np.array([ball_land_x, ball_land_y])\n            all_positions_current = positions[t]\n            all_velocities_current = velocities[t]\n            \n            for p_idx in range(num_players):\n                engineered_features[t, p_idx] = compute_comprehensive_features(\n                    p_idx, positions_window, velocities_window, accelerations_window,\n                    player_sides, player_roles, ball_land_pos, all_positions_current,\n                    all_velocities_current, player_weights[p_idx], time_to_ball\n                )\n        \n        targets = None\n        if is_training and output_df is not None:\n            play_output = output_df[(output_df['game_id'] == game_id) & (output_df['play_id'] == play_id)]\n            targets = np.zeros((num_players, Config.PREDICTION_HORIZON, 2))\n            \n            for p_idx, nfl_id in enumerate(players):\n                player_output = play_output[play_output['nfl_id'] == nfl_id].sort_values('frame_id')\n                if len(player_output) > 0:\n                    horizon = min(len(player_output), Config.PREDICTION_HORIZON)\n                    targets[p_idx, :horizon, 0] = player_output['x'].values[:horizon] - positions[-1, p_idx, 0]\n                    targets[p_idx, :horizon, 1] = player_output['y'].values[:horizon] - positions[-1, p_idx, 1]\n        \n        data_list.append({\n            'game_id': game_id,\n            'play_id': play_id,\n            'player_ids': players,\n            'positions': positions,\n            'velocities': velocities,\n            'accelerations': accelerations,\n            'engineered_features': engineered_features,\n            'player_roles': player_roles,\n            'player_sides': player_sides,\n            'player_continuous': player_continuous,\n            'targets': targets,\n            'ball_land_x': ball_land_x,\n            'ball_land_y': ball_land_y\n        })\n    \n    return data_list\n\n# ================================================================================\n# FIXED PREDICTION FUNCTION\n# ================================================================================\n\ndef make_predictions(model, test_data, test_template):\n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    model = model.to(device)\n    model.eval()\n    \n    all_predictions = []\n    \n    with torch.no_grad():\n        for batch in tqdm(test_data, desc=\"Inference\"):\n            batch_dict = {\n                'positions': torch.FloatTensor(batch['positions']).unsqueeze(0).to(device),\n                'velocities': torch.FloatTensor(batch['velocities']).unsqueeze(0).to(device),\n                'accelerations': torch.FloatTensor(batch['accelerations']).unsqueeze(0).to(device),\n                'player_features': {\n                    'role': torch.LongTensor(batch['player_roles']).to(device),\n                    'side': torch.LongTensor(batch['player_sides']).to(device),\n                    'continuous': torch.FloatTensor(batch['player_continuous']).to(device)\n                }\n            }\n            \n            engineered_features = torch.FloatTensor(batch['engineered_features']).unsqueeze(0).to(device)\n            \n            if Config.USE_AMP and torch.cuda.is_available():\n                with autocast('cuda'):\n                    predictions = model(batch_dict, target_horizon=Config.PREDICTION_HORIZON, \n                                      engineered_features=engineered_features)\n            else:\n                predictions = model(batch_dict, target_horizon=Config.PREDICTION_HORIZON,\n                                  engineered_features=engineered_features)\n            \n            pred_array = predictions[Config.PREDICTION_HORIZON].cpu().numpy()[0]\n            last_positions = batch['positions'][-1]\n            last_velocities = batch['velocities'][-1]\n            \n            for p_idx, nfl_id in enumerate(batch['player_ids']):\n                player_frames = test_template[\n                    (test_template['game_id'] == batch['game_id']) &\n                    (test_template['play_id'] == batch['play_id']) &\n                    (test_template['nfl_id'] == nfl_id)\n                ].sort_values('frame_id')\n                \n                num_frames_needed = len(player_frames)\n                \n                for idx, (_, row) in enumerate(player_frames.iterrows()):\n                    if idx < Config.PREDICTION_HORIZON:\n                        # Use model predictions\n                        pred_x = last_positions[p_idx, 0] + pred_array[p_idx, idx, 0]\n                        pred_y = last_positions[p_idx, 1] + pred_array[p_idx, idx, 1]\n                    else:\n                        # Extrapolate beyond prediction horizon using constant velocity\n                        frames_beyond = idx - Config.PREDICTION_HORIZON + 1\n                        pred_x = (last_positions[p_idx, 0] + pred_array[p_idx, -1, 0] + \n                                 last_velocities[p_idx, 0] * frames_beyond * 0.1)\n                        pred_y = (last_positions[p_idx, 1] + pred_array[p_idx, -1, 1] + \n                                 last_velocities[p_idx, 1] * frames_beyond * 0.1)\n                    \n                    # Clip to field boundaries\n                    pred_x = float(np.clip(pred_x, Config.FIELD_X_MIN, Config.FIELD_X_MAX))\n                    pred_y = float(np.clip(pred_y, Config.FIELD_Y_MIN, Config.FIELD_Y_MAX))\n                    \n                    all_predictions.append({\n                        'id': f\"{int(batch['game_id'])}_{int(batch['play_id'])}_{int(nfl_id)}_{int(row['frame_id'])}\",\n                        'x': pred_x,\n                        'y': pred_y\n                    })\n    \n    return pd.DataFrame(all_predictions)\n\n# ================================================================================\n# CONFIG SEARCH\n# ================================================================================\n\ndef run_config_search(train_graph_data, val_graph_data):\n    Config.SEARCH_MODE = True\n    \n    from sklearn.model_selection import train_test_split\n    search_train, _ = train_test_split(train_graph_data, \n                                       train_size=ConfigSearch.SEARCH_DATA_FRACTION, \n                                       random_state=42)\n    search_val, _ = train_test_split(val_graph_data, \n                                     train_size=ConfigSearch.SEARCH_DATA_FRACTION, \n                                     random_state=42)\n    \n    results = []\n    \n    print(\"\\n\" + \"=\"*80)\n    print(\"STARTING CONFIGURATION SEARCH\")\n    print(f\"Testing {len(ConfigSearch.CONFIGS_TO_TEST)} configurations\")\n    print(f\"Using {len(search_train)} training samples, {len(search_val)} validation samples\")\n    print(f\"Training for {ConfigSearch.SEARCH_EPOCHS} epochs each\")\n    print(\"=\"*80 + \"\\n\")\n    \n    for i, config_dict in enumerate(ConfigSearch.CONFIGS_TO_TEST, 1):\n        print(f\"\\n{'='*80}\")\n        print(f\"CONFIG {i}/{len(ConfigSearch.CONFIGS_TO_TEST)}: {config_dict['name']}\")\n        print(f\"{'='*80}\")\n        \n        Config.update_from_dict(config_dict)\n        \n        model = EnhancedSpatioTemporalPredictor()\n        num_params = sum(p.numel() for p in model.parameters())\n        print(f\"Parameters: {num_params:,}\")\n        \n        trained_model, best_val_loss, final_train_loss, training_time = train_model_enhanced(\n            model, search_train, search_val, \n            epochs=ConfigSearch.SEARCH_EPOCHS,\n            config_name=config_dict['name']\n        )\n        \n        result = {\n            'config_name': config_dict['name'],\n            'config': config_dict,\n            'best_val_loss': best_val_loss,\n            'final_train_loss': final_train_loss,\n            'num_parameters': num_params,\n            'training_time': training_time\n        }\n        results.append(result)\n        \n        print(f\"\\nResults: Val={best_val_loss:.4f}, Train={final_train_loss:.4f}, Time={training_time:.1f}s\")\n        \n        del model\n        del trained_model\n        if torch.cuda.is_available():\n            torch.cuda.empty_cache()\n    \n    with open('config_search_results.json', 'w') as f:\n        json.dump(results, f, indent=2)\n    \n    best_config = ConfigSearch.get_results_summary()\n    \n    return best_config\n\n# ================================================================================\n# MAIN\n# ================================================================================\n\nif __name__ == \"__main__\":\n    train_input, train_output, test_input, test_template = load_data()\n    \n    train_graph_data = prepare_graph_data(train_input, train_output, Config.WINDOW_SIZE, True)\n    test_graph_data = prepare_graph_data(test_input, window_size=Config.WINDOW_SIZE, is_training=False)\n    \n    from sklearn.model_selection import train_test_split\n    train_data, val_data = train_test_split(train_graph_data, test_size=0.2, random_state=42)\n    \n    print(f\"Total samples: {len(train_graph_data)}\")\n    print(f\"Training samples: {len(train_data)}\")\n    print(f\"Validation samples: {len(val_data)}\")\n    \n    best_config = run_config_search(train_data, val_data)\n    \n    print(\"\\n\" + \"=\"*80)\n    print(\"TRAINING FINAL MODEL WITH BEST CONFIGURATION\")\n    print(\"=\"*80)\n    \n    Config.SEARCH_MODE = False\n    Config.update_from_dict(best_config['config'])\n    \n    final_model = EnhancedSpatioTemporalPredictor()\n    print(f\"Model parameters: {sum(p.numel() for p in final_model.parameters()):,}\")\n    \n    trained_model, _, _, _ = train_model_enhanced(\n        final_model, train_data, val_data, \n        epochs=Config.EPOCHS,\n        config_name=\"final\"\n    )\n    \n    submission = make_predictions(trained_model, test_graph_data, test_template)\n    \n    # Verify submission matches test_template\n    expected_rows = len(test_template)\n    actual_rows = len(submission)\n    print(f\"\\nExpected rows: {expected_rows}\")\n    print(f\"Actual rows: {actual_rows}\")\n    print(f\"Match: {expected_rows == actual_rows}\")\n    \n    submission.to_csv('submission.csv', index=False)\n    print(f\"Submission saved: {len(submission)} predictions\")\n    \n    print(\"\\n\" + \"=\"*80)\n    print(\"COMPLETE!\")\n    print(\"=\"*80)","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}