{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":114239,"databundleVersionId":13825858,"sourceType":"competition"},{"sourceId":265898126,"sourceType":"kernelVersion"},{"sourceId":266015077,"sourceType":"kernelVersion"}],"dockerImageVersionId":31089,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"This code is largely based off and inspired by the following notebooks:\n1. https://www.kaggle.com/code/mathieuduverne/nfl-2026-simple-ensemble\n2. https://www.kaggle.com/code/jakupymeraj/0-64-score-nfl-2026\n\nI followed some of the suggested steps for tuning and incorporated and slightly different ensemble methodology, which was guided by visuals and was able to achieve slight improvements.","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport torch\nimport pickle\nimport joblib\nfrom pathlib import Path\nimport warnings\nfrom datetime import datetime\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.metrics import mean_squared_error\nwarnings.filterwarnings('ignore')\n\n# Set style for better-looking plots\nsns.set_style(\"whitegrid\")\nplt.rcParams['figure.figsize'] = (12, 8)\n\n# ============================================================================\n# CONFIGURATION\n# ============================================================================\n\nclass Config:\n    DATA_DIR = Path(\"/kaggle/input/nfl-big-data-bowl-2026-prediction/\")\n    \n    CATBOOST_MODEL_PATH = \"/kaggle/input/nfl-2026-big-data-bowl/catboost_5fold_models.pkl\"\n    LSTM_MODEL_DIR = \"/kaggle/input/nfl-big-data-bowl-2026-lstm\"\n    \n    # Updated weights based on your suggestion\n    ENSEMBLE_WEIGHTS = {\n        'catboost': 0.6,\n        'lstm': 0.4\n    }\n    \n    # Position-specific weights (can be tuned based on validation)\n    POSITION_WEIGHTS = {\n        'Targeted Receiver': {'catboost': 0.5, 'lstm': 0.5},\n        'Defensive Coverage': {'catboost': 0.65, 'lstm': 0.35},\n        'Passer': {'catboost': 0.7, 'lstm': 0.3},\n        'Other Route Runner': {'catboost': 0.6, 'lstm': 0.4},\n        'default': {'catboost': 0.6, 'lstm': 0.4}\n    }\n    \n    LSTM_N_FOLDS = 5\n    LSTM_INPUT_DIM = 32\n    LSTM_HIDDEN_DIM = 128\n    LSTM_NUM_LAYERS = 2\n    LSTM_DROPOUT = 0.3\n    LSTM_MAX_FRAMES = 94\n    LSTM_WINDOW_SIZE = 8\n    \n    FIELD_X_MIN, FIELD_X_MAX = 0.0, 120.0\n    FIELD_Y_MIN, FIELD_Y_MAX = 0.0, 53.3\n\n# ============================================================================\n# CATBOOST PIPELINE\n# ============================================================================\n\ndef load_catboost_models(model_path):\n    \"\"\"Load CatBoost models from pickle file\"\"\"\n    print(f\"Loading CatBoost models from {model_path}...\")\n    with open(model_path, 'rb') as f:\n        saved = pickle.load(f)\n    return saved['models_x'], saved['models_y'], saved['features']\n\ndef engineer_catboost_features(df):\n    \"\"\"Reproduce feature engineering from CatBoost notebook\"\"\"\n    df = df.copy()\n    \n    df['velocity_x'] = df['s'] * np.cos(np.radians(df['dir']))\n    df['velocity_y'] = df['s'] * np.sin(np.radians(df['dir']))\n    \n    df['dist_to_ball'] = np.sqrt(\n        (df['x'] - df['ball_land_x'])**2 + \n        (df['y'] - df['ball_land_y'])**2\n    )\n    \n    df['angle_to_ball'] = np.arctan2(\n        df['ball_land_y'] - df['y'],\n        df['ball_land_x'] - df['x']\n    )\n    \n    df['velocity_toward_ball'] = (\n        df['velocity_x'] * np.cos(df['angle_to_ball']) + \n        df['velocity_y'] * np.sin(df['angle_to_ball'])\n    )\n    \n    df['time_to_ball'] = df['num_frames_output'] / 10.0\n    df['orientation_diff'] = np.abs(df['o'] - df['dir'])\n    df['orientation_diff'] = np.minimum(df['orientation_diff'], 360 - df['orientation_diff'])\n    \n    df['role_targeted_receiver'] = (df['player_role'] == 'Targeted Receiver').astype(int)\n    df['role_defensive_coverage'] = (df['player_role'] == 'Defensive Coverage').astype(int)\n    df['role_passer'] = (df['player_role'] == 'Passer').astype(int)\n    df['side_offense'] = (df['player_side'] == 'Offense').astype(int)\n    \n    height_parts = df['player_height'].str.split('-', expand=True)\n    df['height_inches'] = height_parts[0].astype(float) * 12 + height_parts[1].astype(float)\n    df['bmi'] = (df['player_weight'] / (df['height_inches']**2)) * 703\n    \n    df['acceleration_x'] = df['a'] * np.cos(np.radians(df['dir']))\n    df['acceleration_y'] = df['a'] * np.sin(np.radians(df['dir']))\n    df['distance_to_target_x'] = df['ball_land_x'] - df['x']\n    df['distance_to_target_y'] = df['ball_land_y'] - df['y']\n    df['speed_squared'] = df['s'] ** 2\n    df['accel_magnitude'] = np.sqrt(df['acceleration_x']**2 + df['acceleration_y']**2)\n    df['velocity_alignment'] = np.cos(df['angle_to_ball'] - np.radians(df['dir']))\n    \n    df['expected_x_at_ball'] = df['x'] + df['velocity_x'] * df['time_to_ball']\n    df['expected_y_at_ball'] = df['y'] + df['velocity_y'] * df['time_to_ball']\n    df['error_from_ball_x'] = df['expected_x_at_ball'] - df['ball_land_x']\n    df['error_from_ball_y'] = df['expected_y_at_ball'] - df['ball_land_y']\n    df['error_from_ball'] = np.sqrt(df['error_from_ball_x']**2 + df['error_from_ball_y']**2)\n    \n    df['momentum_x'] = df['player_weight'] * df['velocity_x']\n    df['momentum_y'] = df['player_weight'] * df['velocity_y']\n    df['kinetic_energy'] = 0.5 * df['player_weight'] * df['speed_squared']\n    \n    df['angle_diff'] = np.abs(df['o'] - np.degrees(df['angle_to_ball']))\n    df['angle_diff'] = np.minimum(df['angle_diff'], 360 - df['angle_diff'])\n    \n    df['time_squared'] = df['time_to_ball'] ** 2\n    df['dist_squared'] = df['dist_to_ball'] ** 2\n    df['weighted_dist_by_time'] = df['dist_to_ball'] / (df['time_to_ball'] + 0.1)\n    \n    return df\n\ndef add_sequence_features_catboost(df):\n    \"\"\"Add temporal features for CatBoost\"\"\"\n    df = df.sort_values(['game_id', 'play_id', 'nfl_id', 'frame_id'])\n    group_cols = ['game_id', 'play_id', 'nfl_id']\n    \n    for lag in [1, 2, 3, 4, 5]:\n        for col in ['x', 'y', 'velocity_x', 'velocity_y', 's', 'a']:\n            if col in df.columns:\n                df[f'{col}_lag{lag}'] = df.groupby(group_cols)[col].shift(lag)\n    \n    for window in [3, 5]:\n        for col in ['x', 'y', 'velocity_x', 'velocity_y', 's']:\n            if col in df.columns:\n                df[f'{col}_rolling_mean_{window}'] = df.groupby(group_cols)[col].rolling(window, min_periods=1).mean().reset_index(level=[0,1,2], drop=True)\n                df[f'{col}_rolling_std_{window}'] = df.groupby(group_cols)[col].rolling(window, min_periods=1).std().reset_index(level=[0,1,2], drop=True)\n    \n    for col in ['velocity_x', 'velocity_y']:\n        if col in df.columns:\n            df[f'{col}_delta'] = df.groupby(group_cols)[col].diff()\n    \n    return df\n\ndef predict_catboost(models_x, models_y, features, test_input, test_template):\n    \"\"\"Generate CatBoost predictions\"\"\"\n    print(\"Generating CatBoost predictions...\")\n    \n    test_features = engineer_catboost_features(test_input)\n    test_features = add_sequence_features_catboost(test_features)\n    \n    test_agg = test_features.groupby(['game_id', 'play_id', 'nfl_id']).last().reset_index()\n    if 'frame_id' in test_agg.columns:\n        test_agg = test_agg.drop('frame_id', axis=1)\n    \n    test_merged = test_template.merge(\n        test_agg,\n        on=['game_id', 'play_id', 'nfl_id'],\n        how='left'\n    )\n    \n    for col in features:\n        if col not in test_merged.columns:\n            test_merged[col] = 0\n    \n    X_test = test_merged[features].fillna(0).values\n    \n    pred_x = np.mean([model.predict(X_test) for model in models_x], axis=0)\n    pred_y = np.mean([model.predict(X_test) for model in models_y], axis=0)\n    \n    predictions = pd.DataFrame({\n        'id': (test_merged['game_id'].astype(str) + '_' + \n              test_merged['play_id'].astype(str) + '_' + \n              test_merged['nfl_id'].astype(str) + '_' + \n              test_merged['frame_id'].astype(str)),\n        'x': pred_x,\n        'y': pred_y\n    })\n    \n    return predictions\n\n# ============================================================================\n# LSTM PIPELINE\n# ============================================================================\n\nclass ImprovedLSTMRegressor(torch.nn.Module):\n    \"\"\"LSTM architecture identical to training notebook\"\"\"\n    def __init__(self, input_dim, hidden_dim=128, num_layers=2, dropout=0.3, max_frames_output=94):\n        super().__init__()\n        self.max_frames_output = max_frames_output\n        \n        self.lstm = torch.nn.LSTM(\n            input_size=input_dim,\n            hidden_size=hidden_dim,\n            num_layers=num_layers,\n            batch_first=True,\n            dropout=dropout if num_layers > 1 else 0\n        )\n        \n        self.fc = torch.nn.Sequential(\n            torch.nn.Linear(hidden_dim, 128),\n            torch.nn.ReLU(),\n            torch.nn.Dropout(0.2),\n            torch.nn.Linear(128, 64),\n            torch.nn.ReLU(),\n            torch.nn.Dropout(0.2),\n            torch.nn.Linear(64, 2 * max_frames_output)\n        )\n    \n    def forward(self, x, output_lengths=None):\n        lstm_out, _ = self.lstm(x)\n        last_out = lstm_out[:, -1, :]\n        all_outputs = self.fc(last_out)\n        batch_size = all_outputs.shape[0]\n        outputs = all_outputs.view(batch_size, self.max_frames_output, 2)\n        return outputs\n\ndef load_lstm_models(models_dir, n_folds):\n    \"\"\"Load LSTM models and scalers from fold_X/ directories\"\"\"\n    print(f\"Loading LSTM models from {models_dir}...\")\n    \n    models = []\n    scalers = []\n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    \n    for fold in range(n_folds):\n        model_path = Path(models_dir) / f'fold_{fold+1}/lstm_model_fold.pt'\n        scaler_path = Path(models_dir) / f'fold_{fold+1}/lstm_feature_scaler_fold.joblib'\n        \n        ckpt = torch.load(model_path, map_location=device)\n        \n        if isinstance(ckpt, dict) and 'state_dict' in ckpt:\n            state_dict = ckpt['state_dict']\n            cfg = ckpt.get('config', {})\n            input_dim = cfg.get('input_dim', Config.LSTM_INPUT_DIM)\n            hidden_dim = cfg.get('hidden_dim', Config.LSTM_HIDDEN_DIM)\n            num_layers = cfg.get('num_layers', Config.LSTM_NUM_LAYERS)\n            dropout = cfg.get('dropout', Config.LSTM_DROPOUT)\n            max_frames = cfg.get('max_frames_output', Config.LSTM_MAX_FRAMES)\n        else:\n            state_dict = ckpt\n            input_dim = Config.LSTM_INPUT_DIM\n            hidden_dim = Config.LSTM_HIDDEN_DIM\n            num_layers = Config.LSTM_NUM_LAYERS\n            dropout = Config.LSTM_DROPOUT\n            max_frames = Config.LSTM_MAX_FRAMES\n        \n        model = ImprovedLSTMRegressor(\n            input_dim=input_dim,\n            hidden_dim=hidden_dim,\n            num_layers=num_layers,\n            dropout=dropout,\n            max_frames_output=max_frames\n        )\n        model.load_state_dict(state_dict)\n        model.to(device)\n        model.eval()\n        models.append(model)\n        \n        scaler = joblib.load(scaler_path)\n        scalers.append(scaler)\n        \n        print(f\"Loaded fold {fold+1}\")\n    \n    return models, scalers\n\ndef height_to_feet(height_str):\n    try:\n        ft, inches = map(int, height_str.split('-'))\n        return ft + inches/12\n    except:\n        return None\n\ndef prepare_lstm_sequences(input_df, test_template, window_size):\n    \"\"\"Prepare LSTM sequences for inference\"\"\"\n    print(\"Preparing LSTM sequences...\")\n    \n    input_df = input_df.copy()\n    input_df['player_height_feet'] = input_df['player_height'].map(height_to_feet)\n    \n    dir_rad = np.deg2rad(input_df['dir'].fillna(0))\n    delta_t = 0.1\n    input_df['velocity_x'] = (input_df['s'] + 0.5 * input_df['a'] * delta_t) * np.sin(dir_rad)\n    input_df['velocity_y'] = (input_df['s'] + 0.5 * input_df['a'] * delta_t) * np.cos(dir_rad)\n    \n    input_df['is_offense'] = (input_df['player_side'] == 'Offense').astype(int)\n    input_df['is_defense'] = (input_df['player_side'] == 'Defense').astype(int)\n    input_df['is_receiver'] = (input_df['player_role'] == 'Receiver').astype(int)\n    input_df['is_coverage'] = (input_df['player_role'] == 'Defensive Coverage').astype(int)\n    input_df['is_passer'] = (input_df['player_role'] == 'Passer').astype(int)\n    \n    mass_kg = input_df['player_weight'].fillna(200.0) / 2.20462\n    input_df['momentum_x'] = input_df['velocity_x'] * mass_kg\n    input_df['momentum_y'] = input_df['velocity_y'] * mass_kg\n    \n    current_date = datetime.now()\n    input_df['age'] = input_df['player_birth_date'].apply(\n        lambda x: (current_date - datetime.strptime(x, '%Y-%m-%d')).days // 365 if pd.notnull(x) else None\n    )\n    \n    input_df['kinetic_energy'] = 0.5 * mass_kg * (input_df['s'] ** 2)\n    input_df['force'] = mass_kg * input_df['a']\n    \n    input_df['rolling_mean_velocity_x'] = input_df.groupby(['game_id', 'play_id', 'nfl_id'])['velocity_x'].transform(\n        lambda x: x.rolling(window=window_size, min_periods=1).mean()\n    )\n    input_df['rolling_std_acceleration'] = input_df.groupby(['game_id', 'play_id', 'nfl_id'])['a'].transform(\n        lambda x: x.rolling(window=window_size, min_periods=1).std()\n    )\n    \n    if all(col in input_df.columns for col in ['ball_land_x', 'ball_land_y']):\n        ball_dx = input_df['ball_land_x'] - input_df['x']\n        ball_dy = input_df['ball_land_y'] - input_df['y']\n        input_df['distance_to_ball'] = np.sqrt(ball_dx**2 + ball_dy**2)\n        input_df['angle_to_ball'] = np.arctan2(ball_dy, ball_dx)\n        input_df['ball_direction_x'] = ball_dx / (input_df['distance_to_ball'] + 1e-6)\n        input_df['ball_direction_y'] = ball_dy / (input_df['distance_to_ball'] + 1e-6)\n        input_df['closing_speed'] = (input_df['velocity_x'] * input_df['ball_direction_x'] +\n                                     input_df['velocity_y'] * input_df['ball_direction_y'])\n        input_df['estimated_time_to_ball'] = input_df['distance_to_ball'] / 20.0\n        input_df['projected_time_to_ball'] = input_df['distance_to_ball'] / (np.abs(input_df['closing_speed']) + 0.1)\n    \n    input_df = input_df.sort_values(['game_id', 'play_id', 'nfl_id', 'frame_id'])\n    input_df.set_index(['game_id', 'play_id', 'nfl_id'], inplace=True)\n    input_df['is_right'] = (input_df['play_direction'] == 'right').astype(int)\n    input_df['is_left'] = (input_df['play_direction'] == 'left').astype(int)\n    \n    feature_cols = [\n        'x','y','s','a','o','dir',\n        'absolute_yardline_number',\n        'player_height_feet','player_weight',\n        'is_right','is_left',\n        'velocity_x','velocity_y',\n        'momentum_x','momentum_y',\n        'is_offense','is_defense','is_receiver','is_coverage','is_passer',\n        'age',\n        'kinetic_energy','force',\n        'rolling_mean_velocity_x','rolling_std_acceleration'\n    ]\n    if 'distance_to_ball' in input_df.columns:\n        feature_cols += [\n            'distance_to_ball','angle_to_ball','ball_direction_x','ball_direction_y',\n            'closing_speed','estimated_time_to_ball','projected_time_to_ball'\n        ]\n    \n    grouped_input = input_df.groupby(level=['game_id', 'play_id', 'nfl_id'])\n    target_groups = test_template[['game_id', 'play_id', 'nfl_id']].drop_duplicates()\n    \n    sequences, sequence_ids = [], []\n    \n    for _, row in target_groups.iterrows():\n        key = (row['game_id'], row['play_id'], row['nfl_id'])\n        try:\n            group_df = grouped_input.get_group(key)\n        except KeyError:\n            continue\n        \n        input_window = group_df.tail(window_size)\n        \n        if len(input_window) < window_size:\n            pad_length = window_size - len(input_window)\n            pad_df = pd.DataFrame(np.nan, index=range(pad_length), columns=input_window.columns)\n            input_window = pd.concat([pad_df, input_window], ignore_index=True).reset_index(drop=True)\n        \n        seq = input_window[feature_cols].values\n        \n        if np.isnan(seq.astype(np.float32)).any():\n            seq = np.nan_to_num(seq, nan=0.0)\n        \n        sequences.append(seq)\n        \n        last_frame_id = input_window['frame_id'].iloc[-1]\n        sequence_ids.append({\n            'game_id': key[0],\n            'play_id': key[1],\n            'nfl_id': key[2],\n            'frame_id': last_frame_id\n        })\n    \n    return sequences, sequence_ids\n\ndef predict_lstm(models, scalers, test_input, test_template):\n    \"\"\"Generate LSTM predictions\"\"\"\n    print(\"Generating LSTM predictions...\")\n    \n    sequences, seq_ids = prepare_lstm_sequences(\n        test_input, \n        test_template, \n        Config.LSTM_WINDOW_SIZE\n    )\n    \n    X_test_unscaled = np.array(sequences, dtype=object)\n    test_meta = pd.DataFrame(seq_ids)\n    \n    x_last = np.array([seq[-1, 0] for seq in X_test_unscaled], dtype=np.float32)\n    y_last = np.array([seq[-1, 1] for seq in X_test_unscaled], dtype=np.float32)\n    test_meta['x_last'] = x_last\n    test_meta['y_last'] = y_last\n    \n    per_model_abs = []\n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    \n    for i, (model, scaler) in enumerate(zip(models, scalers)):\n        scaled = np.array([scaler.transform(s) for s in X_test_unscaled], dtype=object)\n        stacked = np.stack(scaled.astype(np.float32))\n        \n        test_dataset = torch.utils.data.TensorDataset(torch.from_numpy(stacked))\n        loader = torch.utils.data.DataLoader(test_dataset, batch_size=1024, shuffle=False)\n        \n        dx_list, dy_list = [], []\n        with torch.no_grad():\n            for (batch,) in loader:\n                batch = batch.to(device)\n                out = model(batch)\n                dx_list.append(out[:, :, 0].cpu().numpy())\n                dy_list.append(out[:, :, 1].cpu().numpy())\n        \n        dx_cum = np.vstack(dx_list)\n        dy_cum = np.vstack(dy_list)\n        \n        abs_all_x = x_last[:, None] + dx_cum\n        abs_all_y = y_last[:, None] + dy_cum\n        \n        per_model_abs.append((abs_all_x, abs_all_y))\n    \n    M = len(per_model_abs)\n    N = len(test_meta)\n    max_h = per_model_abs[0][0].shape[1]\n    \n    pad_x = np.full((M, N, max_h), np.nan, dtype=np.float32)\n    pad_y = np.full((M, N, max_h), np.nan, dtype=np.float32)\n    \n    for m, (ax, ay) in enumerate(per_model_abs):\n        h = ax.shape[1]\n        pad_x[m, :, :h] = ax\n        pad_y[m, :, :h] = ay\n    \n    ens_x = np.nanmean(pad_x, axis=0)\n    ens_y = np.nanmean(pad_y, axis=0)\n    \n    out_rows = []\n    for i, seq_info in test_meta.iterrows():\n        game_id = int(seq_info['game_id'])\n        play_id = int(seq_info['play_id'])\n        nfl_id = int(seq_info['nfl_id'])\n        \n        frame_ids = test_template[\n            (test_template['game_id'] == game_id) &\n            (test_template['play_id'] == play_id) &\n            (test_template['nfl_id'] == nfl_id)\n        ]['frame_id'].sort_values().tolist()\n        \n        for t, frame_id in enumerate(frame_ids):\n            if t < ens_x.shape[1]:\n                px = ens_x[i, t]\n                py = ens_y[i, t]\n            else:\n                px = ens_x[i, -1]\n                py = ens_y[i, -1]\n            \n            out_rows.append({\n                'id': f\"{game_id}_{play_id}_{nfl_id}_{frame_id}\",\n                'x': px,\n                'y': py\n            })\n    \n    predictions = pd.DataFrame(out_rows)\n    return predictions\n\n# ============================================================================\n# ADVANCED ENSEMBLE METHODS\n# ============================================================================\n\ndef create_position_adaptive_ensemble(catboost_pred, lstm_pred, test_input, weights_config):\n    \"\"\"\n    Create ensemble with position-specific weights\n    Different player roles may benefit from different model weightings\n    \"\"\"\n    print(\"Creating position-adaptive ensemble...\")\n    \n    # Extract player roles from test_input\n    player_info = test_input[['game_id', 'play_id', 'nfl_id', 'player_role']].drop_duplicates()\n    \n    # Merge predictions with player info\n    catboost_with_role = catboost_pred.copy()\n    lstm_with_role = lstm_pred.copy()\n    \n    # Extract game_id, play_id, nfl_id from id column\n    catboost_with_role[['game_id', 'play_id', 'nfl_id', 'frame_id']] = catboost_with_role['id'].str.split('_', expand=True).astype(int)\n    lstm_with_role[['game_id', 'play_id', 'nfl_id', 'frame_id']] = lstm_with_role['id'].str.split('_', expand=True).astype(int)\n    \n    # Merge with player info\n    catboost_with_role = catboost_with_role.merge(player_info, on=['game_id', 'play_id', 'nfl_id'], how='left')\n    lstm_with_role = lstm_with_role.merge(player_info, on=['game_id', 'play_id', 'nfl_id'], how='left')\n    \n    # Apply position-specific weights\n    ensemble = []\n    for idx, row in catboost_with_role.iterrows():\n        role = row['player_role']\n        weights = weights_config.get(role, weights_config['default'])\n        \n        w_cat = weights['catboost']\n        w_lstm = weights['lstm']\n        total_weight = w_cat + w_lstm\n        \n        lstm_row = lstm_with_role.iloc[idx]\n        \n        ens_x = (row['x'] * w_cat + lstm_row['x'] * w_lstm) / total_weight\n        ens_y = (row['y'] * w_cat + lstm_row['y'] * w_lstm) / total_weight\n        \n        ensemble.append({\n            'id': row['id'],\n            'x': np.clip(ens_x, Config.FIELD_X_MIN, Config.FIELD_X_MAX),\n            'y': np.clip(ens_y, Config.FIELD_Y_MIN, Config.FIELD_Y_MAX),\n            'player_role': role\n        })\n    \n    return pd.DataFrame(ensemble)\n\ndef create_confidence_weighted_ensemble(catboost_pred, lstm_pred, weights):\n    \"\"\"\n    Weighted ensemble with uncertainty consideration\n    Clips to field boundaries\n    \"\"\"\n    catboost_pred = catboost_pred.sort_values('id').reset_index(drop=True)\n    lstm_pred = lstm_pred.sort_values('id').reset_index(drop=True)\n    \n    w_cat = weights['catboost']\n    w_lstm = weights['lstm']\n    total_weight = w_cat + w_lstm\n    \n    # Calculate prediction variance as a proxy for uncertainty\n    x_variance = np.abs(catboost_pred['x'] - lstm_pred['x'])\n    y_variance = np.abs(catboost_pred['y'] - lstm_pred['y'])\n    \n    # Adaptive weighting: when models disagree, rely more on the stronger model\n    adaptive_w_cat = w_cat + 0.1 * (x_variance + y_variance) / (x_variance + y_variance + 1)\n    adaptive_w_lstm = 1 - adaptive_w_cat\n    \n    ensemble = pd.DataFrame({\n        'id': catboost_pred['id'],\n        'x': (catboost_pred['x'] * adaptive_w_cat + lstm_pred['x'] * adaptive_w_lstm),\n        'y': (catboost_pred['y'] * adaptive_w_cat + lstm_pred['y'] * adaptive_w_lstm),\n        'uncertainty': x_variance + y_variance\n    })\n    \n    ensemble['x'] = np.clip(ensemble['x'], Config.FIELD_X_MIN, Config.FIELD_X_MAX)\n    ensemble['y'] = np.clip(ensemble['y'], Config.FIELD_Y_MIN, Config.FIELD_Y_MAX)\n    \n    return ensemble\n\n# ============================================================================\n# VISUALIZATION FUNCTIONS\n# ============================================================================\n\ndef plot_prediction_distributions(catboost_pred, lstm_pred, ensemble_pred):\n    \"\"\"Visualize prediction distributions across models\"\"\"\n    fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n    fig.suptitle('Model Prediction Distributions', fontsize=16, fontweight='bold')\n    \n    # X coordinate distributions\n    axes[0, 0].hist(catboost_pred['x'], bins=50, alpha=0.7, color='blue', edgecolor='black')\n    axes[0, 0].set_title('CatBoost X Predictions')\n    axes[0, 0].set_xlabel('X Coordinate')\n    axes[0, 0].set_ylabel('Frequency')\n    axes[0, 0].axvline(catboost_pred['x'].mean(), color='red', linestyle='--', label=f'Mean: {catboost_pred[\"x\"].mean():.2f}')\n    axes[0, 0].legend()\n    \n    axes[0, 1].hist(lstm_pred['x'], bins=50, alpha=0.7, color='green', edgecolor='black')\n    axes[0, 1].set_title('LSTM X Predictions')\n    axes[0, 1].set_xlabel('X Coordinate')\n    axes[0, 1].set_ylabel('Frequency')\n    axes[0, 1].axvline(lstm_pred['x'].mean(), color='red', linestyle='--', label=f'Mean: {lstm_pred[\"x\"].mean():.2f}')\n    axes[0, 1].legend()\n    \n    axes[0, 2].hist(ensemble_pred['x'], bins=50, alpha=0.7, color='purple', edgecolor='black')\n    axes[0, 2].set_title('Ensemble X Predictions')\n    axes[0, 2].set_xlabel('X Coordinate')\n    axes[0, 2].set_ylabel('Frequency')\n    axes[0, 2].axvline(ensemble_pred['x'].mean(), color='red', linestyle='--', label=f'Mean: {ensemble_pred[\"x\"].mean():.2f}')\n    axes[0, 2].legend()\n    \n    # Y coordinate distributions\n    axes[1, 0].hist(catboost_pred['y'], bins=50, alpha=0.7, color='blue', edgecolor='black')\n    axes[1, 0].set_title('CatBoost Y Predictions')\n    axes[1, 0].set_xlabel('Y Coordinate')\n    axes[1, 0].set_ylabel('Frequency')\n    axes[1, 0].axvline(catboost_pred['y'].mean(), color='red', linestyle='--', label=f'Mean: {catboost_pred[\"y\"].mean():.2f}')\n    axes[1, 0].legend()\n    \n    axes[1, 1].hist(lstm_pred['y'], bins=50, alpha=0.7, color='green', edgecolor='black')\n    axes[1, 1].set_title('LSTM Y Predictions')\n    axes[1, 1].set_xlabel('Y Coordinate')\n    axes[1, 1].set_ylabel('Frequency')\n    axes[1, 1].axvline(lstm_pred['y'].mean(), color='red', linestyle='--', label=f'Mean: {lstm_pred[\"y\"].mean():.2f}')\n    axes[1, 1].legend()\n    \n    axes[1, 2].hist(ensemble_pred['y'], bins=50, alpha=0.7, color='purple', edgecolor='black')\n    axes[1, 2].set_title('Ensemble Y Predictions')\n    axes[1, 2].set_xlabel('Y Coordinate')\n    axes[1, 2].set_ylabel('Frequency')\n    axes[1, 2].axvline(ensemble_pred['y'].mean(), color='red', linestyle='--', label=f'Mean: {ensemble_pred[\"y\"].mean():.2f}')\n    axes[1, 2].legend()\n    \n    plt.tight_layout()\n    plt.savefig('prediction_distributions.png', dpi=300, bbox_inches='tight')\n    print(\"Saved: prediction_distributions.png\")\n    plt.close()\n\ndef plot_model_differences(catboost_pred, lstm_pred):\n    \"\"\"Visualize differences between model predictions\"\"\"\n    fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n    fig.suptitle('Model Prediction Differences', fontsize=16, fontweight='bold')\n    \n    # Calculate differences\n    x_diff = catboost_pred['x'].values - lstm_pred['x'].values\n    y_diff = catboost_pred['y'].values - lstm_pred['y'].values\n    euclidean_diff = np.sqrt(x_diff**2 + y_diff**2)\n    \n    # X difference\n    axes[0].hist(x_diff, bins=50, alpha=0.7, color='orange', edgecolor='black')\n    axes[0].set_title(f'X Coordinate Difference\\n(CatBoost - LSTM)')\n    axes[0].set_xlabel('Difference (yards)')\n    axes[0].set_ylabel('Frequency')\n    axes[0].axvline(0, color='red', linestyle='--', linewidth=2)\n    axes[0].text(0.02, 0.98, f'Mean: {x_diff.mean():.3f}\\nStd: {x_diff.std():.3f}', \n                 transform=axes[0].transAxes, verticalalignment='top',\n                 bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n    \n    # Y difference\n    axes[1].hist(y_diff, bins=50, alpha=0.7, color='cyan', edgecolor='black')\n    axes[1].set_title(f'Y Coordinate Difference\\n(CatBoost - LSTM)')\n    axes[1].set_xlabel('Difference (yards)')\n    axes[1].set_ylabel('Frequency')\n    axes[1].axvline(0, color='red', linestyle='--', linewidth=2)\n    axes[1].text(0.02, 0.98, f'Mean: {y_diff.mean():.3f}\\nStd: {y_diff.std():.3f}', \n                 transform=axes[1].transAxes, verticalalignment='top',\n                 bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n    \n    # Euclidean distance\n    axes[2].hist(euclidean_diff, bins=50, alpha=0.7, color='magenta', edgecolor='black')\n    axes[2].set_title('Euclidean Distance\\nBetween Predictions')\n    axes[2].set_xlabel('Distance (yards)')\n    axes[2].set_ylabel('Frequency')\n    axes[2].text(0.02, 0.98, f'Mean: {euclidean_diff.mean():.3f}\\nStd: {euclidean_diff.std():.3f}', \n                 transform=axes[2].transAxes, verticalalignment='top',\n                 bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n    \n    plt.tight_layout()\n    plt.savefig('model_differences.png', dpi=300, bbox_inches='tight')\n    print(\"Saved: model_differences.png\")\n    plt.close()\n\ndef plot_field_heatmap(predictions, title=\"Prediction Heatmap\"):\n    \"\"\"Create heatmap of predictions on NFL field\"\"\"\n    fig, ax = plt.subplots(figsize=(14, 8))\n    \n    # Create 2D histogram\n    heatmap, xedges, yedges = np.histogram2d(\n        predictions['x'], predictions['y'],\n        bins=[60, 27],\n        range=[[0, 120], [0, 53.3]]\n    )\n    \n    # Plot heatmap\n    im = ax.imshow(heatmap.T, origin='lower', aspect='auto', \n                   extent=[0, 120, 0, 53.3], cmap='YlOrRd', interpolation='bilinear')\n    \n    # Add field markings\n    for x in range(0, 121, 10):\n        ax.axvline(x, color='white', alpha=0.3, linestyle='--', linewidth=0.5)\n    ax.axhline(26.65, color='white', alpha=0.5, linestyle='-', linewidth=1)\n    \n    # Labels and title\n    ax.set_xlabel('Field Length (yards)', fontsize=12)\n    ax.set_ylabel('Field Width (yards)', fontsize=12)\n    ax.set_title(title, fontsize=14, fontweight='bold')\n    \n    # Colorbar\n    cbar = plt.colorbar(im, ax=ax)\n    cbar.set_label('Prediction Density', rotation=270, labelpad=20)\n    \n    plt.tight_layout()\n    filename = title.lower().replace(' ', '_') + '.png'\n    plt.savefig(filename, dpi=300, bbox_inches='tight')\n    print(f\"Saved: {filename}\")\n    plt.close()\n\ndef plot_ensemble_weights_impact(catboost_pred, lstm_pred):\n    \"\"\"Visualize how different ensemble weights affect predictions\"\"\"\n    fig, axes = plt.subplots(2, 2, figsize=(14, 12))\n    fig.suptitle('Ensemble Weight Sensitivity Analysis', fontsize=16, fontweight='bold')\n    \n    weights_to_test = np.arange(0, 1.1, 0.1)\n    \n    # Calculate RMSE for different weights (using model variance as proxy)\n    rmse_x = []\n    rmse_y = []\n    total_rmse = []\n    \n    for w_cat in weights_to_test:\n        w_lstm = 1 - w_cat\n        ens_x = catboost_pred['x'] * w_cat + lstm_pred['x'] * w_lstm\n        ens_y = catboost_pred['y'] * w_cat + lstm_pred['y'] * w_lstm\n        \n        # Use variance as proxy for error\n        var_x = np.var(ens_x)\n        var_y = np.var(ens_y)\n        rmse_x.append(np.sqrt(var_x))\n        rmse_y.append(np.sqrt(var_y))\n        total_rmse.append(np.sqrt(var_x + var_y))\n    \n    # Plot X coordinate impact\n    axes[0, 0].plot(weights_to_test, rmse_x, 'b-o', linewidth=2, markersize=6)\n    axes[0, 0].axvline(0.6, color='red', linestyle='--', label='Selected Weight (0.6)')\n    axes[0, 0].set_xlabel('CatBoost Weight', fontsize=11)\n    axes[0, 0].set_ylabel('X Coordinate Std Dev', fontsize=11)\n    axes[0, 0].set_title('X Coordinate Sensitivity')\n    axes[0, 0].grid(True, alpha=0.3)\n    axes[0, 0].legend()\n    \n    # Plot Y coordinate impact\n    axes[0, 1].plot(weights_to_test, rmse_y, 'g-o', linewidth=2, markersize=6)\n    axes[0, 1].axvline(0.6, color='red', linestyle='--', label='Selected Weight (0.6)')\n    axes[0, 1].set_xlabel('CatBoost Weight', fontsize=11)\n    axes[0, 1].set_ylabel('Y Coordinate Std Dev', fontsize=11)\n    axes[0, 1].set_title('Y Coordinate Sensitivity')\n    axes[0, 1].grid(True, alpha=0.3)\n    axes[0, 1].legend()\n    \n    # Plot total impact\n    axes[1, 0].plot(weights_to_test, total_rmse, 'purple', linewidth=2, marker='o', markersize=6)\n    axes[1, 0].axvline(0.6, color='red', linestyle='--', label='Selected Weight (0.6)')\n    axes[1, 0].set_xlabel('CatBoost Weight', fontsize=11)\n    axes[1, 0].set_ylabel('Combined Std Dev', fontsize=11)\n    axes[1, 0].set_title('Overall Sensitivity')\n    axes[1, 0].grid(True, alpha=0.3)\n    axes[1, 0].legend()\n    \n    # Show weight comparison table\n    axes[1, 1].axis('off')\n    table_data = [\n        ['Weight', 'X Std', 'Y Std', 'Total'],\n        ['0.5/0.5', f'{rmse_x[5]:.3f}', f'{rmse_y[5]:.3f}', f'{total_rmse[5]:.3f}'],\n        ['0.6/0.4', f'{rmse_x[6]:.3f}', f'{rmse_y[6]:.3f}', f'{total_rmse[6]:.3f}'],\n        ['0.7/0.3', f'{rmse_x[7]:.3f}', f'{rmse_y[7]:.3f}', f'{total_rmse[7]:.3f}']\n    ]\n    table = axes[1, 1].table(cellText=table_data, cellLoc='center', loc='center',\n                             colWidths=[0.2, 0.2, 0.2, 0.2])\n    table.auto_set_font_size(False)\n    table.set_fontsize(10)\n    table.scale(1, 2)\n    \n    for i in range(len(table_data[0])):\n        table[(0, i)].set_facecolor('#4CAF50')\n        table[(0, i)].set_text_props(weight='bold', color='white')\n    \n    plt.tight_layout()\n    plt.savefig('ensemble_weights_analysis.png', dpi=300, bbox_inches='tight')\n    print(\"Saved: ensemble_weights_analysis.png\")\n    plt.close()\n\ndef create_summary_report(catboost_pred, lstm_pred, ensemble_pred):\n    \"\"\"Create a comprehensive summary report\"\"\"\n    fig = plt.figure(figsize=(16, 10))\n    gs = fig.add_gridspec(3, 3, hspace=0.3, wspace=0.3)\n    \n    fig.suptitle('NFL Big Data Bowl 2026 - Ensemble Model Summary Report', \n                 fontsize=18, fontweight='bold', y=0.98)\n    \n    # Statistics summary\n    ax_stats = fig.add_subplot(gs[0, :])\n    ax_stats.axis('off')\n    \n    stats_text = f\"\"\"\n    MODEL STATISTICS SUMMARY\n    \n    CatBoost:  X: [{catboost_pred['x'].min():.2f}, {catboost_pred['x'].max():.2f}] μ={catboost_pred['x'].mean():.2f} σ={catboost_pred['x'].std():.2f}\n                    Y: [{catboost_pred['y'].min():.2f}, {catboost_pred['y'].max():.2f}] μ={catboost_pred['y'].mean():.2f} σ={catboost_pred['y'].std():.2f}\n    \n    LSTM:           X: [{lstm_pred['x'].min():.2f}, {lstm_pred['x'].max():.2f}] μ={lstm_pred['x'].mean():.2f} σ={lstm_pred['x'].std():.2f}\n                    Y: [{lstm_pred['y'].min():.2f}, {lstm_pred['y'].max():.2f}] μ={lstm_pred['y'].mean():.2f} σ={lstm_pred['y'].std():.2f}\n    \n    Ensemble:    X: [{ensemble_pred['x'].min():.2f}, {ensemble_pred['x'].max():.2f}] μ={ensemble_pred['x'].mean():.2f} σ={ensemble_pred['x'].std():.2f}\n                    Y: [{ensemble_pred['y'].min():.2f}, {ensemble_pred['y'].max():.2f}] μ={ensemble_pred['y'].mean():.2f} σ={ensemble_pred['y'].std():.2f}\n    \n    Total Predictions: {len(ensemble_pred):,} | Weights: CatBoost={Config.ENSEMBLE_WEIGHTS['catboost']}, LSTM={Config.ENSEMBLE_WEIGHTS['lstm']}\n    \"\"\"\n    ax_stats.text(0.1, 0.5, stats_text, fontsize=11, family='monospace',\n                  verticalalignment='center',\n                  bbox=dict(boxstyle='round', facecolor='lightblue', alpha=0.5))\n    \n    # Scatter plots\n    ax1 = fig.add_subplot(gs[1, 0])\n    sample_size = min(1000, len(catboost_pred))\n    sample_indices = np.random.choice(len(catboost_pred), sample_size, replace=False)\n    ax1.scatter(catboost_pred.iloc[sample_indices]['x'], \n                catboost_pred.iloc[sample_indices]['y'], \n                alpha=0.4, s=10, c='blue', label='CatBoost')\n    ax1.set_xlabel('X Coordinate')\n    ax1.set_ylabel('Y Coordinate')\n    ax1.set_title('CatBoost Predictions\\n(sample)')\n    ax1.set_xlim(0, 120)\n    ax1.set_ylim(0, 53.3)\n    ax1.grid(True, alpha=0.3)\n    \n    ax2 = fig.add_subplot(gs[1, 1])\n    ax2.scatter(lstm_pred.iloc[sample_indices]['x'], \n                lstm_pred.iloc[sample_indices]['y'], \n                alpha=0.4, s=10, c='green', label='LSTM')\n    ax2.set_xlabel('X Coordinate')\n    ax2.set_ylabel('Y Coordinate')\n    ax2.set_title('LSTM Predictions\\n(sample)')\n    ax2.set_xlim(0, 120)\n    ax2.set_ylim(0, 53.3)\n    ax2.grid(True, alpha=0.3)\n    \n    ax3 = fig.add_subplot(gs[1, 2])\n    ax3.scatter(ensemble_pred.iloc[sample_indices]['x'], \n                ensemble_pred.iloc[sample_indices]['y'], \n                alpha=0.4, s=10, c='purple', label='Ensemble')\n    ax3.set_xlabel('X Coordinate')\n    ax3.set_ylabel('Y Coordinate')\n    ax3.set_title('Ensemble Predictions\\n(sample)')\n    ax3.set_xlim(0, 120)\n    ax3.set_ylim(0, 53.3)\n    ax3.grid(True, alpha=0.3)\n    \n    # Model agreement analysis\n    ax4 = fig.add_subplot(gs[2, :])\n    x_diff = np.abs(catboost_pred['x'].values - lstm_pred['x'].values)\n    y_diff = np.abs(catboost_pred['y'].values - lstm_pred['y'].values)\n    total_diff = np.sqrt(x_diff**2 + y_diff**2)\n    \n    ax4.hist(total_diff, bins=50, alpha=0.7, color='coral', edgecolor='black')\n    ax4.axvline(total_diff.mean(), color='red', linestyle='--', linewidth=2, \n                label=f'Mean Disagreement: {total_diff.mean():.2f} yards')\n    ax4.axvline(np.median(total_diff), color='blue', linestyle='--', linewidth=2, \n                label=f'Median Disagreement: {np.median(total_diff):.2f} yards')\n    ax4.set_xlabel('Euclidean Distance Between Models (yards)', fontsize=11)\n    ax4.set_ylabel('Frequency', fontsize=11)\n    ax4.set_title('Model Agreement Analysis', fontsize=13, fontweight='bold')\n    ax4.legend(fontsize=10)\n    ax4.grid(True, alpha=0.3)\n    \n    plt.savefig('comprehensive_summary.png', dpi=300, bbox_inches='tight')\n    print(\"Saved: comprehensive_summary.png\")\n    plt.close()\n\n# ============================================================================\n# MAIN EXECUTION\n# ============================================================================\n\ndef main():\n    print(\"=\" * 70)\n    print(\"NFL BIG DATA BOWL 2026 - ADVANCED ENSEMBLE WITH VISUALIZATIONS\")\n    print(\"=\" * 70)\n    \n    # Load data\n    test_input = pd.read_csv(Config.DATA_DIR / \"test_input.csv\")\n    test_template = pd.read_csv(Config.DATA_DIR / \"test.csv\")\n    print(f\"\\nData loaded: {test_input.shape[0]} input rows, {test_template.shape[0]} predictions needed\")\n    \n    # Load models\n    print(\"\\n\" + \"=\"*70)\n    models_x_cat, models_y_cat, features_cat = load_catboost_models(Config.CATBOOST_MODEL_PATH)\n    print(f\"✓ CatBoost: {len(models_x_cat)} X models, {len(models_y_cat)} Y models, {len(features_cat)} features\")\n    \n    models_lstm, scalers_lstm = load_lstm_models(Config.LSTM_MODEL_DIR, Config.LSTM_N_FOLDS)\n    print(f\"✓ LSTM: {len(models_lstm)} models loaded\")\n    \n    # Generate predictions\n    print(\"\\n\" + \"=\"*70)\n    catboost_pred = predict_catboost(models_x_cat, models_y_cat, features_cat, test_input, test_template)\n    print(f\"✓ CatBoost: {catboost_pred.shape[0]} predictions\")\n    print(f\"  X: [{catboost_pred['x'].min():.2f}, {catboost_pred['x'].max():.2f}]\")\n    print(f\"  Y: [{catboost_pred['y'].min():.2f}, {catboost_pred['y'].max():.2f}]\")\n    \n    lstm_pred = predict_lstm(models_lstm, scalers_lstm, test_input, test_template)\n    print(f\"✓ LSTM: {lstm_pred.shape[0]} predictions\")\n    print(f\"  X: [{lstm_pred['x'].min():.2f}, {lstm_pred['x'].max():.2f}]\")\n    print(f\"  Y: [{lstm_pred['y'].min():.2f}, {lstm_pred['y'].max():.2f}]\")\n    \n    # Create ensemble (choose method)\n    print(\"\\n\" + \"=\"*70)\n    print(\"Creating ensemble with 60/40 weighting (CatBoost/LSTM)...\")\n    \n    # Method 1: Position-adaptive ensemble\n    ensemble_pred = create_position_adaptive_ensemble(\n        catboost_pred, lstm_pred, test_input, Config.POSITION_WEIGHTS\n    )\n    \n    # Method 2: Confidence-weighted (alternative - comment out if not using)\n    # ensemble_pred = create_confidence_weighted_ensemble(\n    #     catboost_pred, lstm_pred, Config.ENSEMBLE_WEIGHTS\n    # )\n    \n    print(f\"✓ Ensemble: {ensemble_pred.shape[0]} predictions\")\n    print(f\"  X: [{ensemble_pred['x'].min():.2f}, {ensemble_pred['x'].max():.2f}]\")\n    print(f\"  Y: [{ensemble_pred['y'].min():.2f}, {ensemble_pred['y'].max():.2f}]\")\n    \n    # Generate visualizations\n    print(\"\\n\" + \"=\"*70)\n    print(\"Generating visualizations...\")\n    \n    plot_prediction_distributions(catboost_pred, lstm_pred, ensemble_pred)\n    plot_model_differences(catboost_pred, lstm_pred)\n    plot_field_heatmap(catboost_pred, \"CatBoost Prediction Heatmap\")\n    plot_field_heatmap(lstm_pred, \"LSTM Prediction Heatmap\")\n    plot_field_heatmap(ensemble_pred, \"Ensemble Prediction Heatmap\")\n    plot_ensemble_weights_impact(catboost_pred, lstm_pred)\n    create_summary_report(catboost_pred, lstm_pred, ensemble_pred)\n    \n    print(\"✓ All visualizations generated\")\n    \n    # Save submission\n    print(\"\\n\" + \"=\"*70)\n    submission = ensemble_pred[['id', 'x', 'y']].copy()\n    submission.to_csv('submission.csv', index=False)\n    print(f\"✓ Submission saved: {len(submission)} predictions\")\n    print(f\"✓ No NaN values: {submission.isnull().sum().sum() == 0}\")\n    print(\"=\" * 70)\n    \n    # Print summary statistics\n    print(\"\\nFINAL SUMMARY:\")\n    print(f\"  Total predictions: {len(submission):,}\")\n    print(f\"  X range: [{submission['x'].min():.2f}, {submission['x'].max():.2f}]\")\n    print(f\"  Y range: [{submission['y'].min():.2f}, {submission['y'].max():.2f}]\")\n    print(f\"  Ensemble method: Position-adaptive with 60/40 base weights\")\n    print(\"=\" * 70)\n\nif __name__ == \"__main__\":\n    main()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}