{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":114239,"databundleVersionId":14210809,"sourceType":"competition"},{"sourceId":13527658,"sourceType":"datasetVersion","datasetId":8589472},{"sourceId":13529204,"sourceType":"datasetVersion","datasetId":8590590}],"dockerImageVersionId":31153,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!ls -R /kaggle/input/","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# \"\"\"\n# NFL Big Data Bowl 2026 - Kaggle Inference (Feedforward Version)\n# Predict future player positions using FeedforwardTimeModel.\n# \"\"\"\n\n# import os\n# import warnings\n# from pathlib import Path\n# import numpy as np\n# import pandas as pd\n# import polars as pl\n# import torch\n# import torch.nn as nn\n# import joblib\n\n# warnings.filterwarnings(\"ignore\")\n\n# # ============================================================================\n# # CONFIG\n# # ============================================================================\n# class Config:\n#     DATA_DIR = Path(\"/kaggle/input/nfl-big-data-bowl-2026-prediction/\")\n#     SEED = 42\n#     N_FOLDS = 5\n#     WINDOW_SIZE = 8\n#     HIDDEN_DIM = 128\n#     MAX_FUTURE_HORIZON = 94\n#     FIELD_X_MIN, FIELD_X_MAX = 0.0, 120.0\n#     FIELD_Y_MIN, FIELD_Y_MAX = 0.0, 53.3\n#     DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# # Update this to your model folder (or use auto-detect below)\n# import glob\n# candidates = sorted(glob.glob(\"/kaggle/input/*/model_x_fold1.pth\"))\n# if candidates:\n#     MODEL_ROOT = Path(candidates[0]).parent\n#     print(f\"✅ Auto-detected model folder: {MODEL_ROOT}\")\n# else:\n#     MODEL_ROOT = Path(\"/kaggle/input/epoch200/model_save/epoch200\")\n#     print(f\"⚠️ Default MODEL_ROOT = {MODEL_ROOT}\")\n\n# def set_seed(seed=42):\n#     import random\n#     random.seed(seed)\n#     np.random.seed(seed)\n#     torch.manual_seed(seed)\n#     torch.cuda.manual_seed_all(seed)\n# set_seed(Config.SEED)\n\n# # ============================================================================\n# # MODEL\n# # ============================================================================\n# class FeedforwardTimeModel(nn.Module):\n#     def __init__(self, in_dim):\n#         super().__init__()\n#         self.net = nn.Sequential(\n#             nn.Linear(in_dim, 128),\n#             nn.ReLU(),\n#             nn.Linear(128, 128),\n#             nn.ReLU(),\n#             nn.Linear(128, 2)  # predict x,y displacements\n#         )\n#     def forward(self, x):\n#         return self.net(x)\n\n# # ============================================================================\n# # FEATURE ENGINEERING (reuses same logic, last frame only)\n# # ============================================================================\n# def _height_to_feet_array(series: pd.Series) -> np.ndarray:\n#     arr = np.asarray(series)\n#     out = np.full(arr.shape, 6.0, dtype=np.float32)\n#     for i, v in enumerate(arr):\n#         try:\n#             if isinstance(v, str) and \"-\" in v:\n#                 ft, inch = v.split(\"-\", 1)\n#                 ft = int(ft.strip()) if ft.strip().isdigit() else 6\n#                 inch = int(inch.strip()) if inch.strip().isdigit() else 0\n#                 out[i] = ft + inch / 12.0\n#             elif isinstance(v, (int, float)) and not np.isnan(v):\n#                 out[i] = float(v)\n#         except Exception:\n#             continue\n#     return out\n\n# def prepare_last_frame_features(df: pd.DataFrame, feature_cols=None):\n#     df = df.copy()\n#     for c in [\"player_height\", \"player_side\", \"player_role\", \"player_weight\", \"dir\"]:\n#         if c not in df.columns:\n#             df[c] = np.nan\n\n#     df[\"player_height_feet\"] = _height_to_feet_array(df[\"player_height\"])\n#     dir_rad = np.deg2rad(df[\"dir\"].fillna(0.0).to_numpy(dtype=np.float32))\n#     s = df[\"s\"].fillna(0.0).to_numpy(dtype=np.float32)\n#     a = df[\"a\"].fillna(0.0).to_numpy(dtype=np.float32)\n#     df[\"velocity_x\"] = s * np.sin(dir_rad)\n#     df[\"velocity_y\"] = s * np.cos(dir_rad)\n#     df[\"acceleration_x\"] = a * np.sin(dir_rad)\n#     df[\"acceleration_y\"] = a * np.cos(dir_rad)\n#     ps = df[\"player_side\"].astype(str).fillna(\"\")\n#     pr = df[\"player_role\"].astype(str).fillna(\"\")\n#     df[\"is_offense\"] = (ps == \"Offense\").astype(np.int8)\n#     df[\"is_defense\"] = (ps == \"Defense\").astype(np.int8)\n#     df[\"is_receiver\"] = (pr == \"Targeted Receiver\").astype(np.int8)\n#     df[\"is_coverage\"] = (pr == \"Defensive Coverage\").astype(np.int8)\n#     df[\"is_passer\"] = (pr == \"Passer\").astype(np.int8)\n#     df[\"momentum_x\"] = df[\"velocity_x\"] * (df[\"player_weight\"].fillna(200.0)/2.20462)\n#     df[\"momentum_y\"] = df[\"velocity_y\"] * (df[\"player_weight\"].fillna(200.0)/2.20462)\n#     df[\"kinetic_energy\"] = 0.5 * (df[\"player_weight\"].fillna(200.0)/2.20462) * (df[\"s\"].fillna(0.0)**2)\n\n#     # Choose last frame per (game_id, play_id, nfl_id)\n#     gcols = [\"game_id\",\"play_id\",\"nfl_id\"]\n#     last_df = df.sort_values([\"game_id\",\"play_id\",\"nfl_id\",\"frame_id\"]).groupby(gcols).tail(1)\n    \n#     if feature_cols is None:\n#         feature_cols = [\n#             \"x\",\"y\",\"s\",\"a\",\"o\",\"dir\",\"player_height_feet\",\"player_weight\",\n#             \"velocity_x\",\"velocity_y\",\"acceleration_x\",\"acceleration_y\",\n#             \"momentum_x\",\"momentum_y\",\"kinetic_energy\",\n#             \"is_offense\",\"is_defense\",\"is_receiver\",\"is_coverage\",\"is_passer\"\n#         ]\n#         feature_cols = [c for c in feature_cols if c in last_df.columns]\n\n#     X = last_df[feature_cols].fillna(0.0).to_numpy(dtype=np.float32)\n#     meta = last_df[gcols + [\"frame_id\"]]\n#     return X, meta, feature_cols\n\n# # ============================================================================\n# # PREDICT FUNCTION (for Kaggle)\n# # ============================================================================\n# def predict(test: pl.DataFrame, test_input: pl.DataFrame) -> pl.DataFrame:\n#     test_pd = test.to_pandas()\n#     test_input_pd = test_input.to_pandas()\n\n#     # Prepare features\n#     X, meta, feature_cols = prepare_last_frame_features(test_input_pd)\n#     input_dim = X.shape[1]\n\n#     # Load model/scaler folds\n#     model_x_paths = [MODEL_ROOT / f\"model_x_fold{i+1}.pth\" for i in range(Config.N_FOLDS)]\n#     model_y_paths = [MODEL_ROOT / f\"model_y_fold{i+1}.pth\" for i in range(Config.N_FOLDS)]\n#     scaler_paths  = [MODEL_ROOT / f\"scaler_fold{i+1}.pkl\" for i in range(Config.N_FOLDS)]\n\n#     for p in model_x_paths + model_y_paths + scaler_paths:\n#         if not p.exists():\n#             raise FileNotFoundError(f\"Missing model/scaler file: {p}\")\n\n#     models, scalers = [], []\n#     for i in range(Config.N_FOLDS):\n#         scaler = joblib.load(scaler_paths[i])\n#         scalers.append(scaler)\n#         model = FeedforwardTimeModel(in_dim=input_dim).to(Config.DEVICE)\n#         state = torch.load(model_x_paths[i], map_location=\"cpu\")\n#         if isinstance(state, dict) and \"state_dict\" in state:\n#             state = state[\"state_dict\"]\n#         model.load_state_dict(state, strict=False)\n#         model.eval()\n#         models.append(model)\n\n#     # Scale inputs\n#     X_scaled = np.stack([scalers[0].transform(X)]).squeeze(0)\n#     X_tensor = torch.tensor(X_scaled, dtype=torch.float32).to(Config.DEVICE)\n\n#     # Predict ensemble\n#     preds = []\n#     with torch.no_grad():\n#         for model in models:\n#             preds.append(model(X_tensor).cpu().numpy())\n#     preds = np.mean(preds, axis=0)  # [N,2]\n\n#     pred_x, pred_y = preds[:,0], preds[:,1]\n#     pred_x = np.clip(pred_x, Config.FIELD_X_MIN, Config.FIELD_X_MAX)\n#     pred_y = np.clip(pred_y, Config.FIELD_Y_MIN, Config.FIELD_Y_MAX)\n\n#     result = pl.DataFrame({\"x\": pred_x, \"y\": pred_y})\n#     return result\n\n# # ============================================================================\n# # Kaggle Inference Server\n# # ============================================================================\n# try:\n#     from kaggle_evaluation.nfl_inference_server import NFLInferenceServer\n# except ImportError:\n#     raise ImportError(\"Please run this in Kaggle's NFL inference environment\")\n\n# inference_server = NFLInferenceServer(predict)\n# if os.getenv(\"KAGGLE_IS_COMPETITION_RERUN\"):\n#     inference_server.serve()\n# else:\n#     inference_server.run_local_gateway((str(Config.DATA_DIR),))\n# print(\"Completed\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# \"\"\"\n# NFL Big Data Bowl 2026 - Kaggle Inference (patched robust version)\n# Self-contained predict() for Kaggle evaluation server.\n# \"\"\"\n\n# import os\n# import warnings\n# from pathlib import Path\n# import numpy as np\n# import pandas as pd\n# import polars as pl\n# import torch\n# import torch.nn as nn\n# import joblib\n\n# warnings.filterwarnings(\"ignore\")\n\n# # ============================================================================\n# # CONFIG (self-contained)\n# # ============================================================================\n# class Config:\n#     DATA_DIR = Path(\"/kaggle/input/nfl-big-data-bowl-2026-prediction/\")\n#     SEED = 42\n#     N_FOLDS = 5\n#     BATCH_SIZE = 512\n#     WINDOW_SIZE = 8\n#     HIDDEN_DIM = 128\n#     MAX_FUTURE_HORIZON = 94\n#     FIELD_X_MIN, FIELD_X_MAX = 0.0, 120.0\n#     FIELD_Y_MIN, FIELD_Y_MAX = 0.0, 53.3\n#     DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# # Change this to match your uploaded model folder in /kaggle/input/\n# #MODEL_ROOT = Path(\"/kaggle/input/nfl-epoch200/model_save/epoch200\")\n# MODEL_ROOT = Path(\"/kaggle/input/epoch200/model_save/epoch200\")\n\n\n# def set_seed(seed=42):\n#     import random\n#     random.seed(seed)\n#     np.random.seed(seed)\n#     torch.manual_seed(seed)\n#     torch.cuda.manual_seed_all(seed)\n#     os.environ[\"PYTHONHASHSEED\"] = str(seed)\n\n# set_seed(Config.SEED)\n\n# # ============================================================================\n# # FEATURE ENGINEERING (robust to type errors)\n# # ============================================================================\n# def _height_to_feet_array(series: pd.Series) -> np.ndarray:\n#     \"\"\"\n#     Robust converter for strings like '6-2' -> 6.1667 feet.\n#     Handles NaN, numbers, and non-string gracefully.\n#     \"\"\"\n#     arr = np.asarray(series)\n#     out = np.full(arr.shape, 6.0, dtype=np.float32)\n#     for i, v in enumerate(arr):\n#         try:\n#             if isinstance(v, str) and \"-\" in v:\n#                 ft, inch = v.split(\"-\", 1)\n#                 ft = int(ft.strip()) if ft.strip().isdigit() else 6\n#                 inch = int(inch.strip()) if inch.strip().isdigit() else 0\n#                 out[i] = ft + inch / 12.0\n#             elif isinstance(v, (int, float)) and not np.isnan(v):\n#                 out[i] = float(v)\n#         except Exception:\n#             continue\n#     return out\n\n# def prepare_sequences_fixed(input_df: pd.DataFrame,\n#                             output_df: pd.DataFrame | None = None,\n#                             test_template: pd.DataFrame | None = None,\n#                             is_training: bool = True,\n#                             window_size: int = 8,\n#                             feature_cols_forced: list[str] | None = None):\n#     df = input_df.copy()\n\n#     # Ensure required identifier columns exist\n#     for c in [\"game_id\",\"play_id\",\"nfl_id\",\"frame_id\"]:\n#         if c not in df.columns:\n#             raise KeyError(f\"Missing required column in test_input: {c}\")\n\n#     # Add missing numeric columns\n#     needed = [\n#         \"x\",\"y\",\"s\",\"a\",\"o\",\"dir\",\n#         \"player_height\",\"player_weight\",\"player_side\",\"player_role\",\n#         \"ball_land_x\",\"ball_land_y\",\n#     ]\n#     for c in needed:\n#         if c not in df.columns:\n#             df[c] = np.nan\n\n#     # Height\n#     df[\"player_height_feet\"] = _height_to_feet_array(df[\"player_height\"])\n\n#     # Direction\n#     dir_rad = np.deg2rad(df[\"dir\"].fillna(0.0).to_numpy(dtype=np.float32))\n#     delta_t = 0.1\n#     s = df[\"s\"].fillna(0.0).to_numpy(dtype=np.float32)\n#     a = df[\"a\"].fillna(0.0).to_numpy(dtype=np.float32)\n#     df[\"velocity_x\"] = (s + 0.5 * a * delta_t) * np.sin(dir_rad)\n#     df[\"velocity_y\"] = (s + 0.5 * a * delta_t) * np.cos(dir_rad)\n#     df[\"acceleration_x\"] = a * np.sin(dir_rad)\n#     df[\"acceleration_y\"] = a * np.cos(dir_rad)\n\n#     # Roles (robust string casting)\n#     ps = df[\"player_side\"].astype(str).fillna(\"\")\n#     pr = df[\"player_role\"].astype(str).fillna(\"\")\n#     df[\"is_offense\"]  = (ps == \"Offense\").astype(np.int8)\n#     df[\"is_defense\"]  = (ps == \"Defense\").astype(np.int8)\n#     df[\"is_receiver\"] = (pr == \"Targeted Receiver\").astype(np.int8)\n#     df[\"is_coverage\"] = (pr == \"Defensive Coverage\").astype(np.int8)\n#     df[\"is_passer\"]   = (pr == \"Passer\").astype(np.int8)\n\n#     # Physics\n#     mass_kg = df[\"player_weight\"].fillna(200.0).to_numpy(dtype=np.float32) / 2.20462\n#     df[\"momentum_x\"] = df[\"velocity_x\"] * mass_kg\n#     df[\"momentum_y\"] = df[\"velocity_y\"] * mass_kg\n#     df[\"kinetic_energy\"] = 0.5 * mass_kg * (df[\"s\"].fillna(0.0).to_numpy(dtype=np.float32) ** 2)\n\n#     # Ball features\n#     if \"ball_land_x\" in df.columns and \"ball_land_y\" in df.columns:\n#         ball_dx = df[\"ball_land_x\"].to_numpy(dtype=np.float32) - df[\"x\"].to_numpy(dtype=np.float32)\n#         ball_dy = df[\"ball_land_y\"].to_numpy(dtype=np.float32) - df[\"y\"].to_numpy(dtype=np.float32)\n#         dist = np.sqrt(ball_dx**2 + ball_dy**2)\n#         df[\"distance_to_ball\"] = dist\n#         df[\"angle_to_ball\"] = np.arctan2(ball_dy, ball_dx)\n#         df[\"ball_direction_x\"] = ball_dx / (dist + 1e-6)\n#         df[\"ball_direction_y\"] = ball_dy / (dist + 1e-6)\n#         df[\"closing_speed\"] = (\n#             df[\"velocity_x\"].to_numpy(dtype=np.float32) * df[\"ball_direction_x\"].to_numpy(dtype=np.float32) +\n#             df[\"velocity_y\"].to_numpy(dtype=np.float32) * df[\"ball_direction_y\"].to_numpy(dtype=np.float32)\n#         )\n#     else:\n#         df[\"distance_to_ball\"] = np.nan\n#         df[\"angle_to_ball\"] = np.nan\n#         df[\"ball_direction_x\"] = np.nan\n#         df[\"ball_direction_y\"] = np.nan\n#         df[\"closing_speed\"] = np.nan\n\n#     # Sort\n#     df = df.sort_values([\"game_id\",\"play_id\",\"nfl_id\",\"frame_id\"]).reset_index(drop=True)\n#     gcols = [\"game_id\",\"play_id\",\"nfl_id\"]\n\n#     # Lag & EMA features\n#     for lag in (1,2,3):\n#         df[f\"x_lag{lag}\"] = df.groupby(gcols)[\"x\"].shift(lag)\n#         df[f\"y_lag{lag}\"] = df.groupby(gcols)[\"y\"].shift(lag)\n#         df[f\"velocity_x_lag{lag}\"] = df.groupby(gcols)[\"velocity_x\"].shift(lag)\n#         df[f\"velocity_y_lag{lag}\"] = df.groupby(gcols)[\"velocity_y\"].shift(lag)\n\n#     df[\"velocity_x_ema\"] = df.groupby(gcols)[\"velocity_x\"].transform(lambda x: x.ewm(alpha=0.3, adjust=False).mean())\n#     df[\"velocity_y_ema\"] = df.groupby(gcols)[\"velocity_y\"].transform(lambda x: x.ewm(alpha=0.3, adjust=False).mean())\n#     df[\"speed_ema\"]      = df.groupby(gcols)[\"s\"].transform(lambda x: x.ewm(alpha=0.3, adjust=False).mean())\n#     df[\"velocity_x_roll\"] = df.groupby(gcols)[\"velocity_x\"].transform(lambda x: x.rolling(window_size, min_periods=1).mean())\n#     df[\"velocity_y_roll\"] = df.groupby(gcols)[\"velocity_y\"].transform(lambda x: x.rolling(window_size, min_periods=1).mean())\n\n#     default_feature_cols = [\n#         \"x\",\"y\",\"s\",\"a\",\"o\",\"dir\",\"frame_id\",\n#         \"ball_land_x\",\"ball_land_y\",\n#         \"player_height_feet\",\"player_weight\",\n#         \"velocity_x\",\"velocity_y\",\"acceleration_x\",\"acceleration_y\",\n#         \"momentum_x\",\"momentum_y\",\"kinetic_energy\",\n#         \"is_offense\",\"is_defense\",\"is_receiver\",\"is_coverage\",\"is_passer\",\n#         \"distance_to_ball\",\"angle_to_ball\",\"ball_direction_x\",\"ball_direction_y\",\"closing_speed\",\n#         \"x_lag1\",\"y_lag1\",\"velocity_x_lag1\",\"velocity_y_lag1\",\n#         \"x_lag2\",\"y_lag2\",\"velocity_x_lag2\",\"velocity_y_lag2\",\n#         \"x_lag3\",\"y_lag3\",\"velocity_x_lag3\",\"velocity_y_lag3\",\n#         \"velocity_x_ema\",\"velocity_y_ema\",\"speed_ema\",\n#         \"velocity_x_roll\",\"velocity_y_roll\",\n#     ]\n\n#     if feature_cols_forced is not None:\n#         feature_cols = [c for c in feature_cols_forced if c in df.columns]\n#     else:\n#         feature_cols = [c for c in default_feature_cols if c in df.columns]\n\n#     df.set_index(gcols, inplace=True)\n#     grouped = df.groupby(level=gcols)\n\n#     assert not is_training\n#     assert test_template is not None\n#     target_groups = test_template[gcols].drop_duplicates()\n#     sequences, sequence_ids, last_xy = [], [], []\n#     for _, row in target_groups.iterrows():\n#         key = (row[\"game_id\"], row[\"play_id\"], row[\"nfl_id\"])\n#         try:\n#             gdf = grouped.get_group(key)\n#         except KeyError:\n#             continue\n#         win = gdf.tail(window_size)\n#         if len(win) < window_size:\n#             pad_len = window_size - len(win)\n#             pad_df = pd.DataFrame(np.nan, index=range(pad_len), columns=gdf.columns)\n#             win = pd.concat([pad_df, win.reset_index(drop=True)], ignore_index=True)\n#         win = win.fillna(gdf.mean(numeric_only=True)).fillna(0.0)\n#         seq = win[feature_cols].to_numpy(dtype=np.float32)\n#         sequences.append(seq)\n#         last_xy.append((float(win.iloc[-1][\"x\"]), float(win.iloc[-1][\"y\"])))\n#         sequence_ids.append({\"game_id\": key[0], \"play_id\": key[1], \"nfl_id\": key[2],\n#                              \"frame_id\": int(win.iloc[-1][\"frame_id\"])})\n#     return sequences, sequence_ids, last_xy, feature_cols\n\n# # ============================================================================\n# # MODEL\n# # ============================================================================\n# class ImprovedSeqModel(nn.Module):\n#     def __init__(self, input_dim, horizon):\n#         super().__init__()\n#         self.horizon = horizon\n#         self.gru = nn.GRU(input_dim, 128, num_layers=2, batch_first=True, dropout=0.1)\n#         self.pool_ln = nn.LayerNorm(128)\n#         self.pool_attn = nn.MultiheadAttention(128, num_heads=4, batch_first=True)\n#         self.pool_query = nn.Parameter(torch.randn(1, 1, 128))\n#         self.head = nn.Sequential(\n#             nn.Linear(128, 128),\n#             nn.GELU(),\n#             nn.Dropout(0.2),\n#             nn.Linear(128, horizon),\n#         )\n\n#     def forward(self, x):\n#         h, _ = self.gru(x)\n#         B = h.size(0)\n#         q = self.pool_query.expand(B, 1, -1)\n#         h_norm = self.pool_ln(h)\n#         ctx, _ = self.pool_attn(q, h_norm, h_norm)\n#         ctx = ctx.squeeze(1)\n#         out = self.head(ctx)\n#         out = torch.cumsum(out, dim=1)\n#         return out\n\n# def _remap_state_dict_keys(sd: dict) -> dict:\n#     new_sd = {}\n#     for k, v in sd.items():\n#         nk = k.replace(\"pool_queries\", \"pool_query\") if \"pool_queries\" in k else k\n#         new_sd[nk] = v\n#     return new_sd\n\n# # ============================================================================\n# # INFERENCE: predict()\n# # ============================================================================\n# def predict(test: pl.DataFrame, test_input: pl.DataFrame) -> pl.DataFrame:\n#     test_pd = test.to_pandas()\n#     test_input_pd = test_input.to_pandas()\n#     feature_cols_forced = None \n#     MODEL_ROOT = Path(\"/kaggle/input/epoch200/model_save/epoch200\")\n#     feat_path = MODEL_ROOT / \"feature_cols.pkl\"\n#     if feat_path.exists():\n#         try:\n#             feature_cols_forced = joblib.load(feat_path)\n#         except Exception:\n#             feature_cols_forced = None\n\n#     seqs, seq_ids, last_xy, feature_cols = prepare_sequences_fixed(\n#         test_input_pd, test_template=test_pd, is_training=False,\n#         window_size=Config.WINDOW_SIZE, feature_cols_forced=feature_cols_forced\n#     )\n#     if len(seqs) == 0:\n#         return pl.DataFrame({\"x\": np.zeros(len(test_pd)), \"y\": np.zeros(len(test_pd))})\n\n#     input_dim = seqs[0].shape[1]\n#     model_x_paths = [MODEL_ROOT / f\"model_x_fold{i+1}.pth\" for i in range(Config.N_FOLDS)]\n#     model_y_paths = [MODEL_ROOT / f\"model_y_fold{i+1}.pth\" for i in range(Config.N_FOLDS)]\n#     scaler_paths  = [MODEL_ROOT / f\"scaler_fold{i+1}.pkl\"   for i in range(Config.N_FOLDS)]\n\n#     for p in model_x_paths + model_y_paths + scaler_paths:\n#         if not p.exists():\n#             raise FileNotFoundError(f\"Missing model/scaler file: {p}\")\n\n#     models_x, models_y, scalers = [], [], []\n#     for i in range(Config.N_FOLDS):\n#         sc = joblib.load(scaler_paths[i])\n#         scalers.append(sc)\n#         mx = ImprovedSeqModel(input_dim, Config.MAX_FUTURE_HORIZON).to(Config.DEVICE)\n#         my = ImprovedSeqModel(input_dim, Config.MAX_FUTURE_HORIZON).to(Config.DEVICE)\n#         sd_x = torch.load(model_x_paths[i], map_location=\"cpu\")\n#         sd_y = torch.load(model_y_paths[i], map_location=\"cpu\")\n#         if isinstance(sd_x, dict) and \"state_dict\" in sd_x: sd_x = sd_x[\"state_dict\"]\n#         if isinstance(sd_y, dict) and \"state_dict\" in sd_y: sd_y = sd_y[\"state_dict\"]\n#         mx.load_state_dict(_remap_state_dict_keys(sd_x), strict=False)\n#         my.load_state_dict(_remap_state_dict_keys(sd_y), strict=False)\n#         mx.eval(); my.eval()\n#         models_x.append(mx); models_y.append(my)\n\n#     X_scaled = np.stack([scalers[0].transform(s) for s in seqs]).astype(np.float32)\n#     X_tensor = torch.from_numpy(X_scaled).to(Config.DEVICE)\n#     with torch.no_grad():\n#         all_dx, all_dy = [], []\n#         for mx, my in zip(models_x, models_y):\n#             dx = mx(X_tensor).cpu().numpy()\n#             dy = my(X_tensor).cpu().numpy()\n#             all_dx.append(dx); all_dy.append(dy)\n#         ens_dx, ens_dy = np.mean(all_dx, axis=0), np.mean(all_dy, axis=0)\n\n#     keycols = [\"game_id\",\"play_id\",\"nfl_id\"]\n#     test_sorted = test_pd.reset_index(drop=True)\n#     group_frames = (\n#         test_sorted.groupby(keycols)[\"frame_id\"]\n#         .apply(lambda s: np.sort(s.to_numpy(dtype=np.int32)))\n#         .to_dict()\n#     )\n#     preds, H = {}, ens_dx.shape[1]\n#     for i, sid in enumerate(seq_ids):\n#         key = (sid[\"game_id\"], sid[\"play_id\"], sid[\"nfl_id\"])\n#         frames = group_frames.get(key)\n#         if frames is None: continue\n#         x0, y0 = last_xy[i]\n#         px = np.clip(x0 + ens_dx[i], Config.FIELD_X_MIN, Config.FIELD_X_MAX)\n#         py = np.clip(y0 + ens_dy[i], Config.FIELD_Y_MIN, Config.FIELD_Y_MAX)\n#         d = {int(fid): (float(px[min(t,H-1)]), float(py[min(t,H-1)])) for t, fid in enumerate(frames)}\n#         preds[key] = d\n#     out_x, out_y = np.empty(len(test_sorted), np.float32), np.empty(len(test_sorted), np.float32)\n#     for idx, row in test_sorted.iterrows():\n#         key = (row[\"game_id\"], row[\"play_id\"], row[\"nfl_id\"])\n#         fid = int(row[\"frame_id\"])\n#         if key in preds and fid in preds[key]:\n#             x, y = preds[key][fid]\n#         else:\n#             x = float(row.get(\"x\", 0.0) or 0.0)\n#             y = float(row.get(\"y\", 0.0) or 0.0)\n#         out_x[idx], out_y[idx] = x, y\n#     return pl.DataFrame({\"x\": out_x, \"y\": out_y})\n\n# # ============================================================================\n# # Kaggle Inference Server\n# # ============================================================================\n# try:\n#     from kaggle_evaluation.nfl_inference_server import NFLInferenceServer\n# except ImportError:\n#     raise ImportError(\"Please run in Kaggle's NFL inference environment\")\n\n# inference_server = NFLInferenceServer(predict)\n# if os.getenv(\"KAGGLE_IS_COMPETITION_RERUN\"):\n#     inference_server.serve()\n# else:\n#     inference_server.run_local_gateway((str(Config.DATA_DIR),))\n# print(\"Completed\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\"\"\"\nNFL Big Data Bowl 2026 - Kaggle Inference (improved robust version)\nSelf-contained predict() for Kaggle evaluation server.\n\"\"\"\n\nimport os\nimport warnings\nfrom pathlib import Path\nimport numpy as np\nimport pandas as pd\nimport polars as pl\nimport torch\nimport torch.nn as nn\nimport joblib\n\nwarnings.filterwarnings(\"ignore\")\n\n# ============================================================================\n# CONFIG\n# ============================================================================\nclass Config:\n    DATA_DIR = Path(\"/kaggle/input/nfl-big-data-bowl-2026-prediction/\")\n    SEED = 42\n    N_FOLDS = 5\n    BATCH_SIZE = 512\n    WINDOW_SIZE = 8\n    HIDDEN_DIM = 128\n    MAX_FUTURE_HORIZON = 94\n    FIELD_X_MIN, FIELD_X_MAX = 0.0, 120.0\n    FIELD_Y_MIN, FIELD_Y_MAX = 0.0, 53.3\n    DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\nMODEL_ROOT = Path(\"/kaggle/input/epoch200/model_save/epoch200\")\n\n# Deterministic setup\ndef set_seed(seed=42):\n    import random\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n\nset_seed(Config.SEED)\n\n# ============================================================================\n# FEATURE ENGINEERING\n# ============================================================================\ndef _height_to_feet_array(series: pd.Series) -> np.ndarray:\n    arr = np.asarray(series)\n    out = np.full(arr.shape, 6.0, dtype=np.float32)\n    for i, v in enumerate(arr):\n        try:\n            if isinstance(v, str) and \"-\" in v:\n                ft, inch = v.split(\"-\", 1)\n                ft = int(ft.strip()) if ft.strip().isdigit() else 6\n                inch = int(inch.strip()) if inch.strip().isdigit() else 0\n                out[i] = ft + inch / 12.0\n            elif isinstance(v, (int, float)) and not np.isnan(v):\n                out[i] = float(v)\n        except Exception:\n            continue\n    return out\n\ndef prepare_sequences_fixed(input_df: pd.DataFrame,\n                            output_df: pd.DataFrame | None = None,\n                            test_template: pd.DataFrame | None = None,\n                            is_training: bool = True,\n                            window_size: int = 8,\n                            feature_cols_forced: list[str] | None = None):\n    df = input_df.copy()\n    for c in [\"game_id\",\"play_id\",\"nfl_id\",\"frame_id\"]:\n        if c not in df.columns:\n            raise KeyError(f\"Missing required column: {c}\")\n\n    needed = [\n        \"x\",\"y\",\"s\",\"a\",\"o\",\"dir\",\n        \"player_height\",\"player_weight\",\"player_side\",\"player_role\",\n        \"ball_land_x\",\"ball_land_y\",\n    ]\n    for c in needed:\n        if c not in df.columns:\n            df[c] = np.nan\n\n    df[\"player_height_feet\"] = _height_to_feet_array(df[\"player_height\"])\n\n    dir_rad = np.deg2rad(df[\"dir\"].fillna(0.0).to_numpy(dtype=np.float32))\n    delta_t = 0.1\n    s = df[\"s\"].fillna(0.0).to_numpy(dtype=np.float32)\n    a = df[\"a\"].fillna(0.0).to_numpy(dtype=np.float32)\n    df[\"velocity_x\"] = (s + 0.5 * a * delta_t) * np.sin(dir_rad)\n    df[\"velocity_y\"] = (s + 0.5 * a * delta_t) * np.cos(dir_rad)\n    df[\"acceleration_x\"] = a * np.sin(dir_rad)\n    df[\"acceleration_y\"] = a * np.cos(dir_rad)\n\n    ps = df[\"player_side\"].astype(str).fillna(\"\")\n    pr = df[\"player_role\"].astype(str).fillna(\"\")\n    df[\"is_offense\"]  = (ps == \"Offense\").astype(np.int8)\n    df[\"is_defense\"]  = (ps == \"Defense\").astype(np.int8)\n    df[\"is_receiver\"] = (pr == \"Targeted Receiver\").astype(np.int8)\n    df[\"is_coverage\"] = (pr == \"Defensive Coverage\").astype(np.int8)\n    df[\"is_passer\"]   = (pr == \"Passer\").astype(np.int8)\n\n    mass_kg = df[\"player_weight\"].fillna(200.0).to_numpy(dtype=np.float32) / 2.20462\n    df[\"momentum_x\"] = df[\"velocity_x\"] * mass_kg\n    df[\"momentum_y\"] = df[\"velocity_y\"] * mass_kg\n    df[\"kinetic_energy\"] = 0.5 * mass_kg * (df[\"s\"].fillna(0.0).to_numpy(dtype=np.float32) ** 2)\n\n    ball_dx = df[\"ball_land_x\"].to_numpy(dtype=np.float32) - df[\"x\"].to_numpy(dtype=np.float32)\n    ball_dy = df[\"ball_land_y\"].to_numpy(dtype=np.float32) - df[\"y\"].to_numpy(dtype=np.float32)\n    dist = np.sqrt(ball_dx**2 + ball_dy**2)\n    df[\"distance_to_ball\"] = dist\n    df[\"angle_to_ball\"] = np.arctan2(ball_dy, ball_dx)\n    df[\"ball_direction_x\"] = ball_dx / (dist + 1e-6)\n    df[\"ball_direction_y\"] = ball_dy / (dist + 1e-6)\n    df[\"closing_speed\"] = (\n        df[\"velocity_x\"] * df[\"ball_direction_x\"] +\n        df[\"velocity_y\"] * df[\"ball_direction_y\"]\n    )\n\n    df = df.sort_values([\"game_id\",\"play_id\",\"nfl_id\",\"frame_id\"]).reset_index(drop=True)\n    gcols = [\"game_id\",\"play_id\",\"nfl_id\"]\n\n    for lag in (1,2,3):\n        df[f\"x_lag{lag}\"] = df.groupby(gcols)[\"x\"].shift(lag)\n        df[f\"y_lag{lag}\"] = df.groupby(gcols)[\"y\"].shift(lag)\n        df[f\"velocity_x_lag{lag}\"] = df.groupby(gcols)[\"velocity_x\"].shift(lag)\n        df[f\"velocity_y_lag{lag}\"] = df.groupby(gcols)[\"velocity_y\"].shift(lag)\n\n    df[\"velocity_x_ema\"] = df.groupby(gcols)[\"velocity_x\"].transform(lambda x: x.ewm(alpha=0.3, adjust=False).mean())\n    df[\"velocity_y_ema\"] = df.groupby(gcols)[\"velocity_y\"].transform(lambda x: x.ewm(alpha=0.3, adjust=False).mean())\n    df[\"speed_ema\"]      = df.groupby(gcols)[\"s\"].transform(lambda x: x.ewm(alpha=0.3, adjust=False).mean())\n    df[\"velocity_x_roll\"] = df.groupby(gcols)[\"velocity_x\"].transform(lambda x: x.rolling(window_size, min_periods=1).mean())\n    df[\"velocity_y_roll\"] = df.groupby(gcols)[\"velocity_y\"].transform(lambda x: x.rolling(window_size, min_periods=1).mean())\n\n    default_feature_cols = [\n        \"x\",\"y\",\"s\",\"a\",\"o\",\"dir\",\"frame_id\",\n        \"ball_land_x\",\"ball_land_y\",\n        \"player_height_feet\",\"player_weight\",\n        \"velocity_x\",\"velocity_y\",\"acceleration_x\",\"acceleration_y\",\n        \"momentum_x\",\"momentum_y\",\"kinetic_energy\",\n        \"is_offense\",\"is_defense\",\"is_receiver\",\"is_coverage\",\"is_passer\",\n        \"distance_to_ball\",\"angle_to_ball\",\"ball_direction_x\",\"ball_direction_y\",\"closing_speed\",\n        \"x_lag1\",\"y_lag1\",\"velocity_x_lag1\",\"velocity_y_lag1\",\n        \"x_lag2\",\"y_lag2\",\"velocity_x_lag2\",\"velocity_y_lag2\",\n        \"x_lag3\",\"y_lag3\",\"velocity_x_lag3\",\"velocity_y_lag3\",\n        \"velocity_x_ema\",\"velocity_y_ema\",\"speed_ema\",\n        \"velocity_x_roll\",\"velocity_y_roll\",\n    ]\n\n    if feature_cols_forced is not None:\n        missing = [c for c in feature_cols_forced if c not in df.columns]\n        if missing:\n            feature_cols_forced = None\n\n    feature_cols = feature_cols_forced or [c for c in default_feature_cols if c in df.columns]\n\n    df.set_index(gcols, inplace=True)\n    grouped = df.groupby(level=gcols)\n\n    assert not is_training\n    assert test_template is not None\n    target_groups = test_template[gcols].drop_duplicates()\n    sequences, sequence_ids, last_xy = [], [], []\n    for _, row in target_groups.iterrows():\n        key = (row[\"game_id\"], row[\"play_id\"], row[\"nfl_id\"])\n        try:\n            gdf = grouped.get_group(key)\n        except KeyError:\n            continue\n        win = gdf.tail(window_size)\n        if len(win) < window_size:\n            pad_len = window_size - len(win)\n            pad_df = pd.DataFrame(np.nan, index=range(pad_len), columns=gdf.columns)\n            win = pd.concat([pad_df, win.reset_index(drop=True)], ignore_index=True)\n        win = win.ffill().bfill().fillna(gdf.mean(numeric_only=True)).fillna(0.0)\n        seq = win[feature_cols].to_numpy(dtype=np.float32)\n        sequences.append(seq)\n        last_xy.append((float(win.iloc[-1][\"x\"]), float(win.iloc[-1][\"y\"])))\n        sequence_ids.append({\"game_id\": key[0], \"play_id\": key[1], \"nfl_id\": key[2],\n                             \"frame_id\": int(win.iloc[-1][\"frame_id\"])})\n    return sequences, sequence_ids, last_xy, feature_cols\n\n# ============================================================================\n# MODEL\n# ============================================================================\nclass ImprovedSeqModel(nn.Module):\n    def __init__(self, input_dim, horizon):\n        super().__init__()\n        self.horizon = horizon\n        self.gru = nn.GRU(input_dim, 128, num_layers=2, batch_first=True, dropout=0.1)\n        self.pool_ln = nn.LayerNorm(128)\n        self.pool_attn = nn.MultiheadAttention(128, num_heads=4, batch_first=True)\n        self.pool_query = nn.Parameter(torch.randn(1, 1, 128))\n        self.head = nn.Sequential(\n            nn.Linear(128, 128),\n            nn.GELU(),\n            nn.Dropout(0.2),\n            nn.Linear(128, horizon),\n        )\n\n    def forward(self, x):\n        h, _ = self.gru(x)\n        B = h.size(0)\n        q = self.pool_query.expand(B, 1, -1)\n        h_norm = self.pool_ln(h)\n        ctx, _ = self.pool_attn(q, h_norm, h_norm)\n        ctx = ctx.squeeze(1)\n        out = self.head(ctx)\n        out = torch.cumsum(out, dim=1)\n        return out\n\ndef _remap_state_dict_keys(sd: dict) -> dict:\n    new_sd = {}\n    for k, v in sd.items():\n        nk = k.replace(\"pool_queries\", \"pool_query\") if \"pool_queries\" in k else k\n        new_sd[nk] = v\n    return new_sd\n\n# ============================================================================\n# INFERENCE\n# ============================================================================\ndef _batched_forward(model, xt, batch_size):\n    outs = []\n    for b in range(0, xt.size(0), batch_size):\n        xb = xt[b:b+batch_size]\n        with torch.no_grad():\n            outs.append(model(xb).cpu().numpy())\n    return np.concatenate(outs, axis=0)\n\ndef predict(test: pl.DataFrame, test_input: pl.DataFrame) -> pl.DataFrame:\n    test_pd = test.to_pandas()\n    test_input_pd = test_input.to_pandas()\n    feature_cols_forced = None\n\n    feat_path = MODEL_ROOT / \"feature_cols.pkl\"\n    if feat_path.exists():\n        try:\n            feature_cols_forced = joblib.load(feat_path)\n        except Exception:\n            feature_cols_forced = None\n\n    seqs, seq_ids, last_xy, feature_cols = prepare_sequences_fixed(\n        test_input_pd, test_template=test_pd, is_training=False,\n        window_size=Config.WINDOW_SIZE, feature_cols_forced=feature_cols_forced\n    )\n    if len(seqs) == 0:\n        return pl.DataFrame({\"x\": np.zeros(len(test_pd)), \"y\": np.zeros(len(test_pd))})\n\n    input_dim = seqs[0].shape[1]\n    model_x_paths = [MODEL_ROOT / f\"model_x_fold{i+1}.pth\" for i in range(Config.N_FOLDS)]\n    model_y_paths = [MODEL_ROOT / f\"model_y_fold{i+1}.pth\" for i in range(Config.N_FOLDS)]\n    scaler_paths  = [MODEL_ROOT / f\"scaler_fold{i+1}.pkl\"   for i in range(Config.N_FOLDS)]\n\n    for p in model_x_paths + model_y_paths + scaler_paths:\n        if not p.exists():\n            raise FileNotFoundError(f\"Missing model/scaler file: {p}\")\n\n    models_x, models_y, scalers = [], [], []\n    for i in range(Config.N_FOLDS):\n        sc = joblib.load(scaler_paths[i])\n        scalers.append(sc)\n        mx = ImprovedSeqModel(input_dim, Config.MAX_FUTURE_HORIZON).to(Config.DEVICE)\n        my = ImprovedSeqModel(input_dim, Config.MAX_FUTURE_HORIZON).to(Config.DEVICE)\n        sd_x = torch.load(model_x_paths[i], map_location=\"cpu\")\n        sd_y = torch.load(model_y_paths[i], map_location=\"cpu\")\n        if isinstance(sd_x, dict) and \"state_dict\" in sd_x: sd_x = sd_x[\"state_dict\"]\n        if isinstance(sd_y, dict) and \"state_dict\" in sd_y: sd_y = sd_y[\"state_dict\"]\n        mx.load_state_dict(_remap_state_dict_keys(sd_x), strict=False)\n        my.load_state_dict(_remap_state_dict_keys(sd_y), strict=False)\n        mx.eval(); my.eval()\n        models_x.append(mx); models_y.append(my)\n\n    # --- Per-fold scaling & batching ---\n    with torch.no_grad():\n        all_dx, all_dy = [], []\n        for i, (mx, my, sc) in enumerate(zip(models_x, models_y, scalers)):\n            X_scaled_i = np.stack([sc.transform(s) for s in seqs]).astype(np.float32)\n            X_tensor_i = torch.from_numpy(X_scaled_i).to(Config.DEVICE)\n            dx_i = _batched_forward(mx, X_tensor_i, Config.BATCH_SIZE)\n            dy_i = _batched_forward(my, X_tensor_i, Config.BATCH_SIZE)\n            all_dx.append(dx_i)\n            all_dy.append(dy_i)\n        ens_dx = np.mean(all_dx, axis=0)\n        ens_dy = np.mean(all_dy, axis=0)\n\n    keycols = [\"game_id\",\"play_id\",\"nfl_id\"]\n    test_sorted = test_pd.reset_index(drop=True)\n    group_frames = (\n        test_sorted.groupby(keycols)[\"frame_id\"]\n        .apply(lambda s: np.sort(s.to_numpy(dtype=np.int32)))\n        .to_dict()\n    )\n    preds, H = {}, ens_dx.shape[1]\n    for i, sid in enumerate(seq_ids):\n        key = (sid[\"game_id\"], sid[\"play_id\"], sid[\"nfl_id\"])\n        frames = group_frames.get(key)\n        if frames is None: continue\n        x0, y0 = last_xy[i]\n        px = np.clip(x0 + ens_dx[i], Config.FIELD_X_MIN, Config.FIELD_X_MAX)\n        py = np.clip(y0 + ens_dy[i], Config.FIELD_Y_MIN, Config.FIELD_Y_MAX)\n        d = {int(fid): (float(px[min(t,H-1)]), float(py[min(t,H-1)])) for t, fid in enumerate(frames)}\n        preds[key] = d\n\n    out_x, out_y = np.empty(len(test_sorted), np.float32), np.empty(len(test_sorted), np.float32)\n    for idx, row in test_sorted.iterrows():\n        key = (row[\"game_id\"], row[\"play_id\"], row[\"nfl_id\"])\n        fid = int(row[\"frame_id\"])\n        if key in preds and fid in preds[key]:\n            x, y = preds[key][fid]\n        else:\n            x = float(row.get(\"x\", 0.0) or 0.0)\n            y = float(row.get(\"y\", 0.0) or 0.0)\n        out_x[idx], out_y[idx] = x, y\n\n    return pl.DataFrame({\"x\": out_x, \"y\": out_y})\n\n# ============================================================================\n# Kaggle Inference Server\n# ============================================================================\ntry:\n    from kaggle_evaluation.nfl_inference_server import NFLInferenceServer\nexcept ImportError:\n    raise ImportError(\"Please run in Kaggle's NFL inference environment\")\n\ninference_server = NFLInferenceServer(predict)\nif os.getenv(\"KAGGLE_IS_COMPETITION_RERUN\"):\n    inference_server.serve()\nelse:\n    inference_server.run_local_gateway((str(Config.DATA_DIR),))\nprint(\"✅ Inference completed successfully.\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}