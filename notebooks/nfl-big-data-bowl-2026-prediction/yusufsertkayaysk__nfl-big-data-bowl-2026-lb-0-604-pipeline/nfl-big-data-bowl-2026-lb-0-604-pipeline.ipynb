{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":114239,"databundleVersionId":14210809,"isSourceIdPinned":false,"sourceType":"competition"},{"sourceId":269995491,"sourceType":"kernelVersion"}],"dockerImageVersionId":31153,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"#  NFL Big Data Bowl 2026 - LB 0.604 Pipeline\n## **Advanced Player Trajectory Prediction with Hybrid Sequence Models**\n## This notebook implements the complete inference pipeline from my LB 0.604 solution, featuring:\n### - 114 comprehensive features with player interactions\n### - 5-fold ensemble of hybrid GRU+Transformer models\n### - Real-time sequence processing for competition inference\n#\n---","metadata":{}},{"cell_type":"markdown","source":"# IMPORT & CONFIG","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport numpy as np\nimport pandas as pd\nfrom pathlib import Path\nimport joblib\nimport os\nimport polars as pl\nfrom sklearn.preprocessing import StandardScaler\nimport kaggle_evaluation.nfl_inference_server\n\nclass Config:\n    \"\"\"Configuration class for model and data parameters\"\"\"\n    # Paths\n    DATA_DIR = Path(\"/kaggle/input/nfl-big-data-bowl-2026-prediction/\")\n    MODEL_DIR = Path(\"/kaggle/input/nfl-big-data-bowl-2026-lb-0-604/\")\n    \n    # Model parameters\n    SEED = 42\n    WINDOW_SIZE = 12\n    HIDDEN_DIM = 192\n    MAX_FUTURE_HORIZON = 94\n    BATCH_SIZE = 512\n    \n    # Feature engineering\n    USE_PLAYERS_INTERACTIONS = True\n    FIELD_X_MIN, FIELD_X_MAX = 0.0, 120.0\n    FIELD_Y_MIN, FIELD_Y_MAX = 0.0, 53.3\n    \n    # Hardware\n    DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    \n    # Feature groups (for organization)\n    BASIC_FEATURES = ['x', 'y', 's', 'a', 'o', 'dir']\n    PHYSICS_FEATURES = ['velocity_x', 'velocity_y', 'acceleration_x', 'acceleration_y']\n    ROLE_FEATURES = ['is_offense', 'is_defense', 'is_receiver', 'is_coverage', 'is_passer']\n    TEMPORAL_FEATURES = ['x_lag1', 'y_lag1', 'velocity_x_lag1', 'velocity_y_lag1']\n\n# Set random seeds for reproducibility\ndef set_seed(seed: int = Config.SEED):\n    \"\"\"Set random seeds for reproducibility\"\"\"\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    if torch.cuda.is_available():\n        torch.cuda.manual_seed(seed)\n        torch.cuda.manual_seed_all(seed)\n\nset_seed()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-26T11:02:26.617084Z","iopub.execute_input":"2025-10-26T11:02:26.617464Z","iopub.status.idle":"2025-10-26T11:02:26.630481Z","shell.execute_reply.started":"2025-10-26T11:02:26.617438Z","shell.execute_reply":"2025-10-26T11:02:26.629247Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# MODEL ARCHITECTURE - Same as training\n","metadata":{}},{"cell_type":"code","source":"class HybridSeqModel(nn.Module):\n    \"\"\"\n    Hybrid GRU + Conv1D + Transformer model for player trajectory prediction\n    This matches exactly the architecture used in training\n    \"\"\"\n    def __init__(self, input_dim, horizon):\n        super().__init__()\n        self.horizon = horizon\n        self.gru = nn.GRU(input_dim, 192, num_layers=3, batch_first=True, dropout=0.2, bidirectional=False)\n        self.conv1d = nn.Sequential(\n            nn.Conv1d(192, 128, kernel_size=3, padding=1),\n            nn.GELU(),\n            nn.Dropout(0.1),\n            nn.Conv1d(128, 128, kernel_size=5, padding=2),\n            nn.GELU(),\n        )\n        self.pool_ln = nn.LayerNorm(192)\n        self.pool_attn = nn.MultiheadAttention(192, num_heads=8, batch_first=True, dropout=0.1)\n        self.pool_query = nn.Parameter(torch.randn(1, 1, 192))\n        self.head_shared = nn.Sequential(\n            nn.Linear(192 + 128, 256),\n            nn.GELU(),\n            nn.Dropout(0.3),\n            nn.Linear(256, 128),\n            nn.GELU(),\n            nn.Dropout(0.2),\n        )\n        self.head_x = nn.Linear(128, horizon)\n        self.head_y = nn.Linear(128, horizon)\n    \n    def forward(self, x):\n        h, _ = self.gru(x)\n        h_conv = self.conv1d(h.transpose(1, 2)).transpose(1, 2)\n        h_conv_pool = h_conv.mean(dim=1)\n        B = h.size(0)\n        q = self.pool_query.expand(B, -1, -1)\n        h_norm = self.pool_ln(h)\n        ctx, _ = self.pool_attn(q, h_norm, h_norm)\n        ctx = ctx.squeeze(1)\n        combined = torch.cat([ctx, h_conv_pool], dim=1)\n        shared = self.head_shared(combined)\n        out_x = torch.cumsum(self.head_x(shared), dim=1)\n        out_y = torch.cumsum(self.head_y(shared), dim=1)\n        return out_x, out_y","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-26T11:02:26.632534Z","iopub.execute_input":"2025-10-26T11:02:26.632921Z","iopub.status.idle":"2025-10-26T11:02:26.659292Z","shell.execute_reply.started":"2025-10-26T11:02:26.632896Z","shell.execute_reply":"2025-10-26T11:02:26.657923Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# FEATURE ENGINEERING PIPELINE","metadata":{}},{"cell_type":"code","source":"class CompleteFeatureEngineer:\n    def __init__(self):\n        pass\n    \n    @staticmethod\n    def height_to_feet(height_str):\n        try:\n            ft, inches = map(int, str(height_str).split('-'))\n            return ft + inches/12\n        except:\n            return 6.0\n    \n    def add_advanced_features(self, df):\n        \"\"\"Enhanced feature engineering from training\"\"\"\n        df = df.copy()\n        df = df.sort_values(['game_id', 'play_id', 'nfl_id', 'frame_id'])\n        gcols = ['game_id', 'play_id', 'nfl_id']\n        \n        # Distance Rate Features\n        if 'distance_to_ball' in df.columns:\n            df['distance_to_ball_change'] = df.groupby(gcols)['distance_to_ball'].diff().fillna(0)\n            df['distance_to_ball_accel'] = df.groupby(gcols)['distance_to_ball_change'].diff().fillna(0)\n            df['time_to_intercept'] = (df['distance_to_ball'] / \n                                        (np.abs(df['distance_to_ball_change']) + 0.1)).clip(0, 10).fillna(0)\n        \n        # Target Alignment Features\n        if 'ball_direction_x' in df.columns:\n            df['velocity_alignment'] = (\n                df['velocity_x'] * df['ball_direction_x'] +\n                df['velocity_y'] * df['ball_direction_y']\n            ).fillna(0)\n            df['velocity_perpendicular'] = (\n                df['velocity_x'] * (-df['ball_direction_y']) +\n                df['velocity_y'] * df['ball_direction_x']\n            ).fillna(0)\n            if 'acceleration_x' in df.columns:\n                df['accel_alignment'] = (\n                    df['acceleration_x'] * df['ball_direction_x'] +\n                    df['acceleration_y'] * df['ball_direction_y']\n                ).fillna(0)\n        \n        # Multi-Window Rolling\n        for window in [3, 5, 10]:\n            for col in ['velocity_x', 'velocity_y', 's', 'a']:\n                if col in df.columns:\n                    df[f'{col}_roll{window}'] = df.groupby(gcols)[col].transform(\n                        lambda x: x.rolling(window, min_periods=1).mean()\n                    ).fillna(0)\n                    df[f'{col}_std{window}'] = df.groupby(gcols)[col].transform(\n                        lambda x: x.rolling(window, min_periods=1).std()\n                    ).fillna(0)\n        \n        # Extended Lag Features\n        for lag in [4, 5]:\n            for col in ['x', 'y', 'velocity_x', 'velocity_y']:\n                if col in df.columns:\n                    df[f'{col}_lag{lag}'] = df.groupby(gcols)[col].shift(lag).fillna(0)\n        \n        # Velocity Change Features\n        if 'velocity_x' in df.columns:\n            df['velocity_x_change'] = df.groupby(gcols)['velocity_x'].diff().fillna(0)\n            df['velocity_y_change'] = df.groupby(gcols)['velocity_y'].diff().fillna(0)\n            df['speed_change'] = df.groupby(gcols)['s'].diff().fillna(0)\n            df['direction_change'] = df.groupby(gcols)['dir'].diff().fillna(0)\n            df['direction_change'] = df['direction_change'].apply(\n                lambda x: x if abs(x) < 180 else x - 360 * np.sign(x) if not pd.isna(x) else 0\n            )\n        \n        # Field Position Features\n        df['dist_from_left'] = df['y']\n        df['dist_from_right'] = 53.3 - df['y']\n        df['dist_from_sideline'] = np.minimum(df['dist_from_left'], df['dist_from_right'])\n        df['dist_from_endzone'] = np.minimum(df['x'], 120 - df['x'])\n        \n        # Role-Specific Features\n        if 'is_receiver' in df.columns and 'velocity_alignment' in df.columns:\n            df['receiver_optimality'] = df['is_receiver'] * df['velocity_alignment']\n            df['receiver_deviation'] = df['is_receiver'] * np.abs(df.get('velocity_perpendicular', 0))\n        if 'is_coverage' in df.columns and 'closing_speed' in df.columns:\n            df['defender_closing_speed'] = df['is_coverage'] * df['closing_speed']\n        \n        # Time Features\n        df['frames_elapsed'] = df.groupby(gcols).cumcount()\n        df['normalized_time'] = df.groupby(gcols)['frames_elapsed'].transform(\n            lambda x: x / (x.max() + 1)\n        ).fillna(0)\n        \n        return df\n\n    def compute_player_interactions_fast(self, df):\n        \"\"\"Fast version of player interactions for inference\"\"\"\n        print(\"Computing player interactions...\")\n        \n        agg_rows = []\n        for (g, p, f), grp in df.groupby(['game_id', 'play_id', 'frame_id']):\n            n = len(grp)\n            if n < 2:\n                continue\n                \n            x = grp['x'].to_numpy(dtype=np.float32)\n            y = grp['y'].to_numpy(dtype=np.float32)\n            vx = grp['velocity_x'].to_numpy(dtype=np.float32)\n            vy = grp['velocity_y'].to_numpy(dtype=np.float32)\n            is_off = grp['is_offense'].to_numpy().astype(bool)\n            nfl_ids = grp['nfl_id'].to_numpy()\n            \n            # Pairwise geometry\n            dx = x[None, :] - x[:, None]\n            dy = y[None, :] - y[:, None]\n            dist = np.sqrt(dx * dx + dy * dy)\n            angle_mat = np.arctan2(-dy, -dx)\n            dvx = vx[:, None] - vx[None, :]\n            dvy = vy[:, None] - vy[None, :]\n            rel_speed = np.sqrt(dvx * dvx + dvy * dvy)\n            \n            # Masks\n            opp_mask = (is_off[:, None] != is_off[None, :])\n            np.fill_diagonal(opp_mask, False)\n            \n            mask_off = np.broadcast_to(is_off[None, :], (n, n)).copy()\n            mask_def = np.broadcast_to(~is_off[None, :], (n, n)).copy()\n            np.fill_diagonal(mask_off, False)\n            np.fill_diagonal(mask_def, False)\n            \n            # Nearest opponent\n            dist_opp = np.where(opp_mask, dist, np.nan)\n            nearest_dist = np.nanmin(dist_opp, axis=1)\n            nearest_idx = np.nanargmin(dist_opp, axis=1)\n            all_nan = ~np.isfinite(nearest_dist)\n            nearest_idx_safe = nearest_idx.copy()\n            nearest_idx_safe[all_nan] = 0\n            nearest_angle = np.take_along_axis(angle_mat, nearest_idx_safe[:, None], axis=1).squeeze(1)\n            nearest_rel = np.take_along_axis(rel_speed, nearest_idx_safe[:, None], axis=1).squeeze(1)\n            nearest_angle[all_nan] = np.nan\n            nearest_rel[all_nan] = np.nan\n            \n            # Group-wise aggregations\n            d_off = np.where(mask_off, dist, np.nan)\n            d_def = np.where(mask_def, dist, np.nan)\n            d_mean_o = np.nanmean(d_off, axis=1); d_min_o = np.nanmin(d_off, axis=1); d_max_o = np.nanmax(d_off, axis=1)\n            d_mean_d = np.nanmean(d_def, axis=1); d_min_d = np.nanmin(d_def, axis=1); d_max_d = np.nanmax(d_def, axis=1)\n            \n            v_off = np.where(mask_off, rel_speed, np.nan)\n            v_def = np.where(mask_def, rel_speed, np.nan)\n            v_mean_o = np.nanmean(v_off, axis=1); v_min_o = np.nanmin(v_off, axis=1); v_max_o = np.nanmax(v_off, axis=1)\n            v_mean_d = np.nanmean(v_def, axis=1); v_min_d = np.nanmin(v_def, axis=1); v_max_d = np.nanmax(v_def, axis=1)\n            \n            sinA = np.sin(angle_mat); cosA = np.cos(angle_mat)\n            cnt_off = mask_off.sum(axis=1).astype(np.float32)\n            cnt_def = mask_def.sum(axis=1).astype(np.float32)\n            denom_off = np.where(cnt_off > 0, cnt_off, np.nan)\n            denom_def = np.where(cnt_def > 0, cnt_def, np.nan)\n            \n            sin_sum_off = (sinA * mask_off).sum(axis=1)\n            cos_sum_off = (cosA * mask_off).sum(axis=1)\n            sin_sum_def = (sinA * mask_def).sum(axis=1)\n            cos_sum_def = (cosA * mask_def).sum(axis=1)\n            \n            a_mean_o = np.arctan2(sin_sum_off / denom_off, cos_sum_off / denom_off)\n            a_mean_d = np.arctan2(sin_sum_def / denom_def, cos_sum_def / denom_def)\n            \n            a_off = np.where(mask_off, angle_mat, np.nan)\n            a_def = np.where(mask_def, angle_mat, np.nan)\n            a_min_o = np.nanmin(a_off, axis=1); a_max_o = np.nanmax(a_off, axis=1)\n            a_min_d = np.nanmin(a_def, axis=1); a_max_d = np.nanmax(a_def, axis=1)\n            \n            for idx, nid in enumerate(nfl_ids):\n                agg_rows.append({\n                    'game_id': g, 'play_id': p, 'frame_id': f, 'nfl_id': int(nid),\n                    'distance_to_player_mean_offense': d_mean_o[idx],\n                    'distance_to_player_min_offense': d_min_o[idx],\n                    'distance_to_player_max_offense': d_max_o[idx],\n                    'relative_velocity_magnitude_mean_offense': v_mean_o[idx],\n                    'relative_velocity_magnitude_min_offense': v_min_o[idx],\n                    'relative_velocity_magnitude_max_offense': v_max_o[idx],\n                    'angle_to_player_mean_offense': a_mean_o[idx],\n                    'angle_to_player_min_offense': a_min_o[idx],\n                    'angle_to_player_max_offense': a_max_o[idx],\n                    'distance_to_player_mean_defense': d_mean_d[idx],\n                    'distance_to_player_min_defense': d_min_d[idx],\n                    'distance_to_player_max_defense': d_max_d[idx],\n                    'relative_velocity_magnitude_mean_defense': v_mean_d[idx],\n                    'relative_velocity_magnitude_min_defense': v_min_d[idx],\n                    'relative_velocity_magnitude_max_defense': v_max_d[idx],\n                    'angle_to_player_mean_defense': a_mean_d[idx],\n                    'angle_to_player_min_defense': a_min_d[idx],\n                    'angle_to_player_max_defense': a_max_d[idx],\n                    'nearest_opponent_dist': float(nearest_dist[idx]) if np.isfinite(nearest_dist[idx]) else 0.0,\n                    'nearest_opponent_angle': float(nearest_angle[idx]) if np.isfinite(nearest_angle[idx]) else 0.0,\n                    'nearest_opponent_rel_speed': float(nearest_rel[idx]) if np.isfinite(nearest_rel[idx]) else 0.0,\n                })\n        \n        return pd.DataFrame(agg_rows) if agg_rows else pd.DataFrame()\n\n    def prepare_sequences_complete(self, input_df, test_template=None, is_training=False, window_size=12):\n        \"\"\"Complete sequence preparation matching training pipeline\"\"\"\n        print(\"Preparing sequences with complete 114-feature engineering...\")\n        \n        input_df = input_df.copy()\n        \n        # Step 1: Basic features\n        print(\"Step 1/4: Adding basic features...\")\n        input_df['player_height_feet'] = input_df['player_height'].apply(self.height_to_feet)\n        \n        dir_rad = np.deg2rad(input_df['dir'].fillna(0))\n        delta_t = 0.1\n        input_df['velocity_x'] = (input_df['s'] + 0.5 * input_df['a'] * delta_t) * np.sin(dir_rad)\n        input_df['velocity_y'] = (input_df['s'] + 0.5 * input_df['a'] * delta_t) * np.cos(dir_rad)\n        input_df['acceleration_x'] = input_df['a'] * np.sin(dir_rad)\n        input_df['acceleration_y'] = input_df['a'] * np.cos(dir_rad)\n        input_df['o_sin'] = np.sin(np.deg2rad(input_df['o'].fillna(0)))\n        input_df['o_cos'] = np.cos(np.deg2rad(input_df['o'].fillna(0)))\n        input_df['dir_sin'] = np.sin(np.deg2rad(input_df['dir'].fillna(0)))\n        input_df['dir_cos'] = np.cos(np.deg2rad(input_df['dir'].fillna(0)))\n        \n        # Roles\n        input_df['is_offense'] = (input_df['player_side'] == 'Offense').astype(int)\n        input_df['is_defense'] = (input_df['player_side'] == 'Defense').astype(int)\n        input_df['is_receiver'] = (input_df['player_role'] == 'Targeted Receiver').astype(int)\n        input_df['is_coverage'] = (input_df['player_role'] == 'Defensive Coverage').astype(int)\n        input_df['is_passer'] = (input_df['player_role'] == 'Passer').astype(int)\n        \n        # Physics\n        mass_kg = input_df['player_weight'].fillna(200.0) / 2.20462\n        input_df['momentum_x'] = input_df['velocity_x'] * mass_kg\n        input_df['momentum_y'] = input_df['velocity_y'] * mass_kg\n        input_df['kinetic_energy'] = 0.5 * mass_kg * (input_df['s'] ** 2)\n        \n        # Ball features\n        if 'ball_land_x' in input_df.columns:\n            ball_dx = input_df['ball_land_x'] - input_df['x']\n            ball_dy = input_df['ball_land_y'] - input_df['y']\n            input_df['distance_to_ball'] = np.sqrt(ball_dx**2 + ball_dy**2)\n            input_df['angle_to_ball'] = np.arctan2(ball_dy, ball_dx)\n            input_df['ball_direction_x'] = ball_dx / (input_df['distance_to_ball'] + 1e-6)\n            input_df['ball_direction_y'] = ball_dy / (input_df['distance_to_ball'] + 1e-6)\n            input_df['closing_speed'] = (\n                input_df['velocity_x'] * input_df['ball_direction_x'] +\n                input_df['velocity_y'] * input_df['ball_direction_y']\n            )\n        \n        # Sort for temporal\n        input_df = input_df.sort_values(['game_id', 'play_id', 'nfl_id', 'frame_id'])\n        gcols = ['game_id', 'play_id', 'nfl_id']\n        \n        # Lag features\n        for lag in [1, 2, 3]:\n            input_df[f'x_lag{lag}'] = input_df.groupby(gcols)['x'].shift(lag).fillna(0)\n            input_df[f'y_lag{lag}'] = input_df.groupby(gcols)['y'].shift(lag).fillna(0)\n            input_df[f'velocity_x_lag{lag}'] = input_df.groupby(gcols)['velocity_x'].shift(lag).fillna(0)\n            input_df[f'velocity_y_lag{lag}'] = input_df.groupby(gcols)['velocity_y'].shift(lag).fillna(0)\n        \n        # EMA features\n        input_df['velocity_x_ema'] = input_df.groupby(gcols)['velocity_x'].transform(\n            lambda x: x.ewm(alpha=0.3, adjust=False).mean()\n        ).fillna(0)\n        input_df['velocity_y_ema'] = input_df.groupby(gcols)['velocity_y'].transform(\n            lambda x: x.ewm(alpha=0.3, adjust=False).mean()\n        ).fillna(0)\n        input_df['speed_ema'] = input_df.groupby(gcols)['s'].transform(\n            lambda x: x.ewm(alpha=0.3, adjust=False).mean()\n        ).fillna(0)\n        \n        # Step 2: Advanced features\n        print(\"Step 2/4: Adding advanced features...\")\n        input_df = self.add_advanced_features(input_df)\n        \n        # Step 3: Player interactions\n        print(\"Step 3/4: Adding player interaction features...\")\n        if Config.USE_PLAYERS_INTERACTIONS:\n            interaction_agg = self.compute_player_interactions_fast(input_df)\n            if not interaction_agg.empty:\n                input_df = input_df.merge(\n                    interaction_agg,\n                    on=['game_id', 'play_id', 'frame_id', 'nfl_id'],\n                    how='left'\n                )\n        \n        # Step 4: Create sequences\n        print(\"Step 4/4: Creating sequences...\")\n        \n        # Complete feature list (114 features)\n        feature_cols = [\n            'x', 'y', 's', 'a', 'ball_land_x', 'ball_land_y',\n            'o_sin', 'o_cos', 'dir_sin', 'dir_cos',\n            'player_height_feet', 'player_weight',\n            'velocity_x', 'velocity_y', 'acceleration_x', 'acceleration_y',\n            'momentum_x', 'momentum_y', 'kinetic_energy',\n            'is_offense', 'is_defense', 'is_receiver', 'is_coverage', 'is_passer',\n            'distance_to_ball', 'angle_to_ball', 'ball_direction_x', 'ball_direction_y', 'closing_speed',\n            'x_lag1', 'y_lag1', 'velocity_x_lag1', 'velocity_y_lag1',\n            'x_lag2', 'y_lag2', 'velocity_x_lag2', 'velocity_y_lag2',\n            'x_lag3', 'y_lag3', 'velocity_x_lag3', 'velocity_y_lag3',\n            'velocity_x_ema', 'velocity_y_ema', 'speed_ema',\n            'distance_to_ball_change', 'distance_to_ball_accel', 'time_to_intercept',\n            'velocity_alignment', 'velocity_perpendicular', 'accel_alignment',\n            'velocity_x_roll3', 'velocity_x_std3', 'velocity_y_roll3', 'velocity_y_std3',\n            's_roll3', 's_std3', 'a_roll3', 'a_std3',\n            'velocity_x_roll5', 'velocity_x_std5', 'velocity_y_roll5', 'velocity_y_std5',\n            's_roll5', 's_std5', 'a_roll5', 'a_std5',\n            'velocity_x_roll10', 'velocity_x_std10', 'velocity_y_roll10', 'velocity_y_std10',\n            's_roll10', 's_std10', 'a_roll10', 'a_std10',\n            'x_lag4', 'y_lag4', 'velocity_x_lag4', 'velocity_y_lag4',\n            'x_lag5', 'y_lag5', 'velocity_x_lag5', 'velocity_y_lag5',\n            'velocity_x_change', 'velocity_y_change', 'speed_change', 'direction_change',\n            'dist_from_sideline', 'dist_from_endzone',\n            'receiver_optimality', 'receiver_deviation', 'defender_closing_speed',\n            'frames_elapsed', 'normalized_time',\n            'distance_to_player_mean_offense', 'distance_to_player_min_offense', 'distance_to_player_max_offense',\n            'relative_velocity_magnitude_mean_offense', 'relative_velocity_magnitude_min_offense', 'relative_velocity_magnitude_max_offense',\n            'angle_to_player_mean_offense', 'angle_to_player_min_offense', 'angle_to_player_max_offense',\n            'distance_to_player_mean_defense', 'distance_to_player_min_defense', 'distance_to_player_max_defense',\n            'relative_velocity_magnitude_mean_defense', 'relative_velocity_magnitude_min_defense', 'relative_velocity_magnitude_max_defense',\n            'angle_to_player_mean_defense', 'angle_to_player_min_defense', 'angle_to_player_max_defense',\n            'nearest_opponent_dist', 'nearest_opponent_angle', 'nearest_opponent_rel_speed',\n        ]\n        \n        # Filter to available columns and fill missing with zeros\n        available_features = []\n        for feature in feature_cols:\n            if feature in input_df.columns:\n                available_features.append(feature)\n            else:\n                input_df[feature] = 0.0\n                available_features.append(feature)\n        \n        print(f\"Using {len(available_features)} features\")\n        \n        # Create sequences\n        input_df.set_index(['game_id', 'play_id', 'nfl_id'], inplace=True)\n        grouped = input_df.groupby(level=['game_id', 'play_id', 'nfl_id'])\n        \n        target_groups = test_template[['game_id', 'play_id', 'nfl_id']].drop_duplicates()\n        \n        sequences, sequence_ids = [], []\n        \n        for _, row in target_groups.iterrows():\n            key = (row['game_id'], row['play_id'], row['nfl_id'])\n            \n            try:\n                group_df = grouped.get_group(key)\n            except KeyError:\n                continue\n            \n            input_window = group_df.tail(window_size)\n            \n            if len(input_window) < window_size:\n                pad_len = window_size - len(input_window)\n                first = input_window.iloc[0:1].copy()\n                pad_df = pd.concat([first] * pad_len, ignore_index=True)\n                input_window = pd.concat([pad_df, input_window], ignore_index=True)\n            \n            input_window = input_window.ffill().bfill().fillna(0.0)\n            \n            seq = input_window[available_features].values\n            seq = np.nan_to_num(seq, nan=0.0)\n            \n            sequences.append(seq)\n            sequence_ids.append({\n                'game_id': key[0],\n                'play_id': key[1],\n                'nfl_id': key[2],\n                'frame_id': input_window.iloc[-1]['frame_id']\n            })\n        \n        print(f\"Created {len(sequences)} sequences\")\n        return sequences, sequence_ids, available_features","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-26T11:02:26.719284Z","iopub.execute_input":"2025-10-26T11:02:26.72006Z","iopub.status.idle":"2025-10-26T11:02:26.776845Z","shell.execute_reply.started":"2025-10-26T11:02:26.720031Z","shell.execute_reply":"2025-10-26T11:02:26.775228Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# MAIN PREDICTION PIPELINE","metadata":{}},{"cell_type":"code","source":"class MainPredictor:\n    def __init__(self):\n        self.models = []\n        self.scalers = []\n        self.config = Config()\n        self.feature_engineer = CompleteFeatureEngineer()\n        self.loaded = False\n    \n    def load_pretrained_models(self):\n        \"\"\"Load your LB 0.604 models\"\"\"\n        if self.loaded:\n            return\n            \n        print(\"üöÄ Loading LB 0.604 pretrained models...\")\n        \n        for fold in range(1, 6):\n            model_path = self.config.MODEL_DIR / f\"fold_{fold}\" / \"model.pt\"\n            scaler_path = self.config.MODEL_DIR / f\"fold_{fold}\" / \"scaler.joblib\"\n            \n            if model_path.exists() and scaler_path.exists():\n                try:\n                    # Load model\n                    checkpoint = torch.load(model_path, map_location='cpu')\n                    model = HybridSeqModel(\n                        input_dim=114,  # Your models expect 114 features\n                        horizon=checkpoint['config']['horizon']\n                    )\n                    model.load_state_dict(checkpoint['state_dict'])\n                    model.to(self.config.DEVICE)\n                    model.eval()\n                    self.models.append(model)\n                    \n                    # Load scaler\n                    scaler = joblib.load(scaler_path)\n                    self.scalers.append(scaler)\n                    \n                    print(f\"‚úÖ Loaded fold {fold}\")\n                    \n                except Exception as e:\n                    print(f\"‚ùå Error loading fold {fold}: {e}\")\n        \n        if not self.models:\n            raise ValueError(\"‚ùå No LB 0.604 models found!\")\n            \n        self.loaded = True\n        print(f\"üéØ Successfully loaded {len(self.models)} LB 0.604 models\")\n    \n    def predict(self, test: pl.DataFrame, test_input: pl.DataFrame) -> pl.DataFrame:\n        \"\"\"Complete prediction using LB 0.604 pipeline\"\"\"\n        if not self.loaded:\n            self.load_pretrained_models()\n        \n        print(f\"üìä Processing {len(test)} predictions with LB 0.604 pipeline...\")\n        \n        # Convert to pandas for feature engineering\n        test_input_pd = test_input.to_pandas()\n        test_template_pd = test.to_pandas()\n        \n        # Prepare sequences with complete feature engineering\n        sequences, sequence_ids, feature_cols = self.feature_engineer.prepare_sequences_complete(\n            test_input_pd, test_template_pd, is_training=False, window_size=self.config.WINDOW_SIZE\n        )\n        \n        if not sequences:\n            print(\"‚ùå No sequences prepared - using fallback\")\n            return pl.DataFrame({'x': [60.0] * len(test), 'y': [26.65] * len(test)})\n        \n        print(f\"üéØ Generated {len(sequences)} sequences with {len(feature_cols)} features\")\n        \n        # Convert to tensor\n        X_test = np.stack([seq.astype(np.float32) for seq in sequences])\n        \n        # Ensemble predictions\n        all_dx, all_dy = [], []\n        \n        for i, (model, scaler) in enumerate(zip(self.models, self.scalers)):\n            print(f\"üîÆ Running LB 0.604 fold {i+1}...\")\n            \n            # Scale features\n            X_scaled = scaler.transform(X_test.reshape(-1, X_test.shape[-1])).reshape(X_test.shape)\n            X_tensor = torch.from_numpy(X_scaled).to(self.config.DEVICE)\n            \n            # Predict\n            with torch.no_grad():\n                dx, dy = model(X_tensor)\n                all_dx.append(dx.cpu().numpy())\n                all_dy.append(dy.cpu().numpy())\n        \n        # Ensemble average\n        ens_dx = np.mean(np.stack(all_dx), axis=0)\n        ens_dy = np.mean(np.stack(all_dy), axis=0)\n        \n        # Create predictions\n        predictions = []\n        sequence_df = pd.DataFrame(sequence_ids)\n        \n        for i, seq_info in sequence_df.iterrows():\n            game_id = seq_info['game_id']\n            play_id = seq_info['play_id'] \n            nfl_id = seq_info['nfl_id']\n            \n            # Get target frames\n            target_rows = test.filter(\n                (pl.col('game_id') == game_id) & \n                (pl.col('play_id') == play_id) & \n                (pl.col('nfl_id') == nfl_id)\n            )\n            \n            if len(target_rows) == 0:\n                continue\n            \n            # Get last position\n            last_frame = test_input.filter(\n                (pl.col('game_id') == game_id) & \n                (pl.col('play_id') == play_id) & \n                (pl.col('nfl_id') == nfl_id)\n            ).sort('frame_id').tail(1)\n            \n            if len(last_frame) == 0:\n                continue\n                \n            last_x = last_frame['x'][0]\n            last_y = last_frame['y'][0]\n            \n            # Create predictions for each future frame\n            target_frames = target_rows.sort('frame_id')\n            \n            for t in range(len(target_frames)):\n                pred_idx = min(t, ens_dx.shape[1] - 1)\n                \n                pred_x = float(last_x + ens_dx[i, pred_idx])\n                pred_y = float(last_y + ens_dy[i, pred_idx])\n                \n                # Clip to field boundaries\n                pred_x = max(self.config.FIELD_X_MIN, min(self.config.FIELD_X_MAX, pred_x))\n                pred_y = max(self.config.FIELD_Y_MIN, min(self.config.FIELD_Y_MAX, pred_y))\n                \n                predictions.append({\n                    'x': pred_x,\n                    'y': pred_y\n                })\n        \n        print(f\"‚úÖ Generated {len(predictions)} predictions using LB 0.604 pipeline\")\n        \n        # Ensure correct count\n        if len(predictions) != len(test):\n            print(f\"‚ö†Ô∏è  Count mismatch: {len(predictions)} vs {len(test)}\")\n            while len(predictions) < len(test):\n                predictions.append({'x': 60.0, 'y': 26.65})\n            predictions = predictions[:len(test)]\n        \n        return pl.DataFrame(predictions)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-26T11:02:26.77885Z","iopub.execute_input":"2025-10-26T11:02:26.779145Z","iopub.status.idle":"2025-10-26T11:02:26.806246Z","shell.execute_reply.started":"2025-10-26T11:02:26.779125Z","shell.execute_reply":"2025-10-26T11:02:26.804571Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# SERVER STARTUP\n## COMPETITION INTERFACE","metadata":{}},{"cell_type":"code","source":"lb_predictor = MainPredictor()\n\ndef predict(test: pl.DataFrame, test_input: pl.DataFrame) -> pl.DataFrame:\n    \"\"\"Competition prediction function using LB 0.604 pipeline\"\"\"\n    return lb_predictor.predict(test, test_input)\n\n# SERVER SETUP\nprint(\"üöÄ Setting up NFL Big Data Bowl 2026 Inference Server...\")\nprint(f\"üìÅ Model directory: {Config.MODEL_DIR}\")\nprint(f\"üéØ Target: LB 0.604 Performance\")\nprint(f\"üîß Features: 114 complete features with player interactions\")\nprint(f\"üèà Model: 5-fold ensemble with full feature engineering\")\n\ninference_server = kaggle_evaluation.nfl_inference_server.NFLInferenceServer(predict)\n\nif os.getenv('KAGGLE_IS_COMPETITION_RERUN'):\n    print(\"üèà Starting competition inference server with LB 0.604 pipeline...\")\n    inference_server.serve()\nelse:\n    print(\"üî¨ Running local test gateway with LB 0.604 pipeline...\")\n    inference_server.run_local_gateway(('/kaggle/input/nfl-big-data-bowl-2026-prediction/',))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-26T11:02:26.807509Z","iopub.execute_input":"2025-10-26T11:02:26.80785Z"}},"outputs":[],"execution_count":null}]}