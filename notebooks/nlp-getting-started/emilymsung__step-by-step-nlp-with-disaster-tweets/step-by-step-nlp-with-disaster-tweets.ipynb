{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Step-by-step NLP with Disaster Tweets","metadata":{}},{"cell_type":"markdown","source":"üëãüèª Welcome to my notebook!<br>\n<br>\nWe're going to use the Twitter dataset from Kaggle's Getting Started Competition, [Natural Language Processing with Disaster Tweets](https://www.kaggle.com/c/nlp-getting-started). We'll go through a step-by-step process to make predictions whether a given Tweet is about a real disaster or not. Please upvote if you find it helpful.\n\nLet's get started!\n","metadata":{}},{"cell_type":"markdown","source":"***","metadata":{}},{"cell_type":"markdown","source":"## Table of Contents\n\n#### 1. [Exploratory Data Analysis](#explore)\n#### 2. [Text Preprocessing - Part I](#preprocess1)\n#### 3. [Feature Engineering](#engineer)\n#### 4. [Text Preprocessing - Part II](#preprocess2)\n#### 5. [Model Building](#build)\n#### 6. [Model Evaluation](#evaluate)\n#### 7. [Final Model Selection](#select)","metadata":{}},{"cell_type":"markdown","source":"***","metadata":{}},{"cell_type":"markdown","source":"## <a id=\"explore\">‚úîÔ∏è Exploratory Data Analysis</a>","metadata":{}},{"cell_type":"markdown","source":"* Data source: [Natural Language Processing with Disaster Tweets](https://www.kaggle.com/competitions/nlp-getting-started/data)\n* License: [CC0: Public Domain](https://creativecommons.org/publicdomain/zero/1.0/)\n\n* Credibility: Medium-high \n    * **Reliable & Original: Yes** - The data was created by the company figure-eight and originally shared on their website (source: 'Acknowledgements' section on this [Kaggle page](https://www.kaggle.com/competitions/nlp-getting-started/overview)). It has been used for one of Kaggle's 'Getting Started' competitions. \n    * **Comprehensive: Yes** - The dataset includes 10,876 Tweets that were hand classified. Although there are lots of missing data in the 'keyword' and 'location' columns, the 'text' column we will focus on in this notebook has no missing or duplicated values. \n    * **Current: No** - The data was collected in 2015.\n    * **Cited: Yes** - The data has been cited and used for many data science projects in many platforms including Kaggle.  \n\n* Files in the dataset:\n\n|File Name||# of Rows||# of Columns|\n|:-:||:-:||:-:|\n|sample_submission||3263||2|\n|train||7613||5|\n|test||3263||4|","metadata":{}},{"cell_type":"markdown","source":"Let's import the libraries and files and start exploring our data. First, we will check the data format, shape, missing data and for duplicates.","metadata":{}},{"cell_type":"code","source":"# import the libraries\nimport pandas as pd\n%matplotlib inline\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\nimport re, string\nimport nltk\nimport spacy","metadata":{"execution":{"iopub.status.busy":"2022-11-30T19:05:15.143778Z","iopub.execute_input":"2022-11-30T19:05:15.144289Z","iopub.status.idle":"2022-11-30T19:05:20.562625Z","shell.execute_reply.started":"2022-11-30T19:05:15.144187Z","shell.execute_reply":"2022-11-30T19:05:20.560909Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# set how many characters to show on the dataframe\npd.set_option('display.max_colwidth', 150)\n\n# import the files as pandas dataframe\nsample_df = pd.read_csv('/kaggle/input/nlp-getting-started/sample_submission.csv')\ntrain_df = pd.read_csv('/kaggle/input/nlp-getting-started/train.csv')\ntest_df = pd.read_csv('/kaggle/input/nlp-getting-started/test.csv')","metadata":{"execution":{"iopub.status.busy":"2022-11-30T19:05:25.597604Z","iopub.execute_input":"2022-11-30T19:05:25.598523Z","iopub.status.idle":"2022-11-30T19:05:25.665646Z","shell.execute_reply.started":"2022-11-30T19:05:25.598462Z","shell.execute_reply":"2022-11-30T19:05:25.664185Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# check the dataframes one by one, starting from sample_df\nsample_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-11-30T19:05:31.372802Z","iopub.execute_input":"2022-11-30T19:05:31.373318Z","iopub.status.idle":"2022-11-30T19:05:31.394525Z","shell.execute_reply.started":"2022-11-30T19:05:31.373274Z","shell.execute_reply":"2022-11-30T19:05:31.393178Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# check the shape\nsample_df.shape","metadata":{"execution":{"iopub.status.busy":"2022-11-30T19:05:34.252782Z","iopub.execute_input":"2022-11-30T19:05:34.253301Z","iopub.status.idle":"2022-11-30T19:05:34.26187Z","shell.execute_reply.started":"2022-11-30T19:05:34.253257Z","shell.execute_reply":"2022-11-30T19:05:34.26056Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# check the missing data\nsample_df.isnull().sum()","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2022-11-30T19:05:35.94456Z","iopub.execute_input":"2022-11-30T19:05:35.945016Z","iopub.status.idle":"2022-11-30T19:05:35.955138Z","shell.execute_reply.started":"2022-11-30T19:05:35.944979Z","shell.execute_reply":"2022-11-30T19:05:35.954Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# check train_df\ntrain_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-11-30T19:05:38.198333Z","iopub.execute_input":"2022-11-30T19:05:38.198784Z","iopub.status.idle":"2022-11-30T19:05:38.213729Z","shell.execute_reply.started":"2022-11-30T19:05:38.198748Z","shell.execute_reply":"2022-11-30T19:05:38.211959Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# check the shape\ntrain_df.shape","metadata":{"execution":{"iopub.status.busy":"2022-11-30T19:05:39.91766Z","iopub.execute_input":"2022-11-30T19:05:39.918109Z","iopub.status.idle":"2022-11-30T19:05:39.927631Z","shell.execute_reply.started":"2022-11-30T19:05:39.918068Z","shell.execute_reply":"2022-11-30T19:05:39.926011Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# check the missing data\ntrain_df.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2022-11-30T19:05:41.98073Z","iopub.execute_input":"2022-11-30T19:05:41.981148Z","iopub.status.idle":"2022-11-30T19:05:41.992607Z","shell.execute_reply.started":"2022-11-30T19:05:41.981115Z","shell.execute_reply":"2022-11-30T19:05:41.991613Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# check the duplicated data\ntrain_df.duplicated().sum()","metadata":{"execution":{"iopub.status.busy":"2022-11-30T19:05:43.743477Z","iopub.execute_input":"2022-11-30T19:05:43.744591Z","iopub.status.idle":"2022-11-30T19:05:43.760807Z","shell.execute_reply.started":"2022-11-30T19:05:43.74454Z","shell.execute_reply":"2022-11-30T19:05:43.759612Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# check test_df\ntest_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-11-30T19:05:45.614808Z","iopub.execute_input":"2022-11-30T19:05:45.615234Z","iopub.status.idle":"2022-11-30T19:05:45.62983Z","shell.execute_reply.started":"2022-11-30T19:05:45.6152Z","shell.execute_reply":"2022-11-30T19:05:45.62802Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# check the shape\ntest_df.shape","metadata":{"execution":{"iopub.status.busy":"2022-11-30T19:05:47.645272Z","iopub.execute_input":"2022-11-30T19:05:47.647174Z","iopub.status.idle":"2022-11-30T19:05:47.657317Z","shell.execute_reply.started":"2022-11-30T19:05:47.64705Z","shell.execute_reply":"2022-11-30T19:05:47.655526Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# check the missing data\ntest_df.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2022-11-30T19:05:49.405559Z","iopub.execute_input":"2022-11-30T19:05:49.405992Z","iopub.status.idle":"2022-11-30T19:05:49.419714Z","shell.execute_reply.started":"2022-11-30T19:05:49.405958Z","shell.execute_reply":"2022-11-30T19:05:49.418339Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# check the duplicated data\ntest_df.duplicated().sum()","metadata":{"execution":{"iopub.status.busy":"2022-11-30T19:05:51.187253Z","iopub.execute_input":"2022-11-30T19:05:51.188507Z","iopub.status.idle":"2022-11-30T19:05:51.203252Z","shell.execute_reply.started":"2022-11-30T19:05:51.188449Z","shell.execute_reply":"2022-11-30T19:05:51.202107Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"|File Name||# of missing values (column)||# duplicated values (column)|\n|:-:||:-:||:-:|\n|sample_submission||0||0|\n|train||61 (keyword), 2533 (location)||0|\n|test||26 (keyword), 1105 (location)||0|\n\n- Missing values were found only in 'keyword' and 'location' columns of the train and test datasets. No duplicated values were found.","metadata":{}},{"cell_type":"markdown","source":"<div class=\"alert alert-block alert-info\">\n    <b>Tips:</b> I included the individual steps above for reference. Another thing you can do is use for example something like <a href='https://github.com/ydataai/pandas-profiling'>Pandas Profiling</a>, a Python package for quick EDA! <br>df.profile_report() provides a detailed report including an overview, variables, correlations, missing values and sample of your dataset.<br> ","metadata":{}},{"cell_type":"markdown","source":"### Is the Dataset Balanced or Imbalanced?\n\nWhy is it important to check if your data is balanced or imbalanced? Why can imbalanced data be problematic? How should we deal with it? This short explanation on [the Google Developer page](https://developers.google.com/machine-learning/data-prep/construct/sampling-splitting/imbalanced-data) is a great place to start. ","metadata":{}},{"cell_type":"code","source":"# set the figure size\nplt.figure(figsize=(9, 5))\n\n# set the style\nplt.style.use('seaborn-darkgrid')\n\n# set the colors\ncolors = ['lightskyblue', 'lightcoral']\n\n# generate a pie plot\nplt.pie(train_df['target'].value_counts(), explode=(0, 0.05), labels=[\"Non-disaster\", \"Disaster\"], \n        autopct=\"%0.2f%%\", textprops={'fontsize': 14}, shadow=True, startangle=90, colors=colors)\n\n# add a title\nplt.title('Proportion of Labeled Tweets', size=16, y=0.93)\n\n# show the plot\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-11-30T19:05:56.555869Z","iopub.execute_input":"2022-11-30T19:05:56.556298Z","iopub.status.idle":"2022-11-30T19:05:56.731414Z","shell.execute_reply.started":"2022-11-30T19:05:56.556264Z","shell.execute_reply":"2022-11-30T19:05:56.728829Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- **Our dataset is well balanced**, and accuracy would not be a poor metric for evaluating our classification models.","metadata":{}},{"cell_type":"markdown","source":"### Word Clouds Using Unprocessed Text\n\nLet's visualize the unprocessed text as a word cloud. The size of text shows the frequency that the word appears in the dataset.","metadata":{}},{"cell_type":"code","source":"# set the random state\nrandom_state = 4041\n\n# import the wordcloud library\nfrom wordcloud import WordCloud\n\n# concat all the text for each labels\nnon_disaster_text = [''.join(t) for t in train_df[train_df['target']==0]['text']]\nnon_disaster_strings = ' '.join(map(str, non_disaster_text))\ndisaster_text = [''.join(t) for t in train_df[train_df['target']==1]['text']]\ndisaster_strings = ' '.join(map(str, disaster_text))\n\n# generate word clouds\nnon_disaster_cloud = WordCloud(width=800, height=400, max_words=500, background_color='white', random_state=random_state).generate(non_disaster_strings)\ndisaster_cloud = WordCloud(width=800, height=400, max_words=500, random_state=random_state).generate(disaster_strings)","metadata":{"execution":{"iopub.status.busy":"2022-11-30T19:06:01.826693Z","iopub.execute_input":"2022-11-30T19:06:01.827129Z","iopub.status.idle":"2022-11-30T19:06:05.577908Z","shell.execute_reply.started":"2022-11-30T19:06:01.827095Z","shell.execute_reply":"2022-11-30T19:06:05.576558Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# create subplots for the generated clouds\nfig, axes = plt.subplots(1, 2, figsize = (20,20))\naxes[0].imshow(non_disaster_cloud, interpolation='bilinear')\naxes[1].imshow(disaster_cloud, interpolation='bilinear')\n\n# turn the axis off\n[ax.axis('off') for ax in axes]\n\n# add titles\naxes[0].set_title('Non-disaster Tweets', fontsize=16)\naxes[1].set_title('Disaster Tweets', fontsize=16)\n\n# show the figure\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-11-30T19:06:07.679942Z","iopub.execute_input":"2022-11-30T19:06:07.680368Z","iopub.status.idle":"2022-11-30T19:06:08.448805Z","shell.execute_reply.started":"2022-11-30T19:06:07.680335Z","shell.execute_reply":"2022-11-30T19:06:08.447663Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We can recognize some disaster-related words (e.g., 'fire', 'flood', and 'storm'), but the difference between disaster and non-disaster Tweets is not easy to tell. Words like \"t\"and \"co\" (reflecting shortened links on Twitter) dominate the clouds, but don't provide much helpful meaning. **Let's compare these with word clouds of preprocessed data later on.** ","metadata":{}},{"cell_type":"markdown","source":"***","metadata":{}},{"cell_type":"markdown","source":"## <a id=\"preprocess1\">üßæ Text Preprocessing - Part I</a>\n\nLet's start preprocessing our text by removing the parts below: \n- URLs\n- HTML tags\n- character references\n- non-printable characters\n- numeric values\n\nWe'll come back to the preprocessing step after creating some new features.","metadata":{}},{"cell_type":"markdown","source":"### Remove URLs","metadata":{}},{"cell_type":"code","source":"# define a function that removes URLs from the text\ndef remove_url(text):\n    text = re.sub(r'((?:https?|ftp|file)://[-\\w\\d+=&@#/%?~|!:;\\.,]*)', '', text)\n    return text\n\n# remove URLs from the text and show the modified text in a new column\ntrain_df['text_cleaned'] = train_df['text'].apply(remove_url)\ntest_df['text_cleaned'] = test_df['text'].apply(remove_url)","metadata":{"execution":{"iopub.status.busy":"2022-11-30T19:06:51.289928Z","iopub.execute_input":"2022-11-30T19:06:51.290371Z","iopub.status.idle":"2022-11-30T19:06:51.333773Z","shell.execute_reply.started":"2022-11-30T19:06:51.290338Z","shell.execute_reply":"2022-11-30T19:06:51.332329Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Remove HTML tags","metadata":{}},{"cell_type":"code","source":"# define a function that removes HTML tags\ndef remove_HTML(text):\n    text = re.sub(r'<.*?>', '', text)\n    return text\n\n# remove HTML tags\ntrain_df['text_cleaned'] = train_df['text_cleaned'].apply(remove_HTML)\ntest_df['text_cleaned'] = test_df['text_cleaned'].apply(remove_HTML)","metadata":{"execution":{"iopub.status.busy":"2022-11-30T19:06:55.188995Z","iopub.execute_input":"2022-11-30T19:06:55.189723Z","iopub.status.idle":"2022-11-30T19:06:55.216165Z","shell.execute_reply.started":"2022-11-30T19:06:55.189687Z","shell.execute_reply":"2022-11-30T19:06:55.214758Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Remove Character References","metadata":{}},{"cell_type":"code","source":"# define a function to remove character references (e.g., &lt;, &amp;, &nbsp;)\ndef remove_references(text):\n    text = re.sub(r'&[a-zA-Z]+;?', '', text)\n    return text\n\n# remove character references\ntrain_df['text_cleaned'] = train_df['text_cleaned'].apply(remove_references)\ntest_df['text_cleaned'] = test_df['text_cleaned'].apply(remove_references)","metadata":{"execution":{"iopub.status.busy":"2022-11-30T19:07:00.212885Z","iopub.execute_input":"2022-11-30T19:07:00.213665Z","iopub.status.idle":"2022-11-30T19:07:00.243155Z","shell.execute_reply.started":"2022-11-30T19:07:00.213618Z","shell.execute_reply":"2022-11-30T19:07:00.241026Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Remove Non-printable Characters","metadata":{}},{"cell_type":"code","source":"# check which characters are printable (ASCII)\nstring.printable","metadata":{"execution":{"iopub.status.busy":"2022-11-30T19:07:05.978592Z","iopub.execute_input":"2022-11-30T19:07:05.979022Z","iopub.status.idle":"2022-11-30T19:07:05.986928Z","shell.execute_reply.started":"2022-11-30T19:07:05.978989Z","shell.execute_reply":"2022-11-30T19:07:05.985586Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# define a function that removes non-printable characters\ndef remove_non_printable(text):\n    text = ''.join([word for word in text if word in string.printable])\n    return text\n\n# remove non-printable characters\ntrain_df['text_cleaned'] = train_df['text_cleaned'].apply(remove_non_printable)\ntest_df['text_cleaned'] = test_df['text_cleaned'].apply(remove_non_printable)","metadata":{"execution":{"iopub.status.busy":"2022-11-30T19:07:09.358424Z","iopub.execute_input":"2022-11-30T19:07:09.358844Z","iopub.status.idle":"2022-11-30T19:07:09.50879Z","shell.execute_reply.started":"2022-11-30T19:07:09.358811Z","shell.execute_reply":"2022-11-30T19:07:09.507604Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Remove Numeric Values\nRemove numeric values, including mixtures of alphabetical characters and numeric values such as 'M194', '5km'.","metadata":{}},{"cell_type":"code","source":"# define a function that removes numeric values and mixtures\ndef remove_num(text):\n    text = re.sub(r'\\w*\\d+\\w*', '', text)\n    return text\n\n# remove numeric values and mixtures\ntrain_df['text_cleaned'] = train_df['text_cleaned'].apply(remove_num)\ntest_df['text_cleaned'] = test_df['text_cleaned'].apply(remove_num)","metadata":{"execution":{"iopub.status.busy":"2022-11-30T19:07:17.48901Z","iopub.execute_input":"2022-11-30T19:07:17.48949Z","iopub.status.idle":"2022-11-30T19:07:17.637921Z","shell.execute_reply.started":"2022-11-30T19:07:17.489442Z","shell.execute_reply":"2022-11-30T19:07:17.6361Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# check the results\ntrain_df.tail()","metadata":{"execution":{"iopub.status.busy":"2022-11-30T19:07:19.946048Z","iopub.execute_input":"2022-11-30T19:07:19.946519Z","iopub.status.idle":"2022-11-30T19:07:19.960951Z","shell.execute_reply.started":"2022-11-30T19:07:19.946483Z","shell.execute_reply":"2022-11-30T19:07:19.959481Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# check the results\ntest_df.tail()","metadata":{"execution":{"iopub.status.busy":"2022-11-30T19:07:22.752308Z","iopub.execute_input":"2022-11-30T19:07:22.752855Z","iopub.status.idle":"2022-11-30T19:07:22.772119Z","shell.execute_reply.started":"2022-11-30T19:07:22.752812Z","shell.execute_reply":"2022-11-30T19:07:22.770058Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"In Text Preprocessing - Part II, we'll lemmatize and lowercase our text, and remove repeated characters in elongated words, as well as mentions, stopwords, and punctuation.","metadata":{}},{"cell_type":"markdown","source":"***","metadata":{}},{"cell_type":"markdown","source":"## <a id=\"engineer\">üìê Feature Engineering</a>","metadata":{}},{"cell_type":"markdown","source":"Below are 10 features we're going to create:\n\n- Number of **sentences**\n- Number of **words**\n- Number of **characters**\n- Number of **hashtags**\n- Number of **mentions**\n- Number of **all caps words**\n- Average **length of words**\n- Number of **proper nouns (PROPN)**\n- Number of **non-proper nouns (NOUN)**\n- Percentage of characters that are **punctuation**\n","metadata":{}},{"cell_type":"markdown","source":"### Number of Sentences","metadata":{}},{"cell_type":"code","source":"# create a new feature for the number of sentences in each Tweet\ntrain_df['sent_count'] = train_df['text'].apply(nltk.tokenize.sent_tokenize).apply(len)\ntest_df['sent_count'] = test_df['text'].apply(nltk.tokenize.sent_tokenize).apply(len)","metadata":{"execution":{"iopub.status.busy":"2022-11-30T19:07:45.20311Z","iopub.execute_input":"2022-11-30T19:07:45.203558Z","iopub.status.idle":"2022-11-30T19:07:45.772116Z","shell.execute_reply.started":"2022-11-30T19:07:45.20352Z","shell.execute_reply":"2022-11-30T19:07:45.770338Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Number of Words","metadata":{}},{"cell_type":"code","source":"# create a new feature for the number of words\ntrain_df['word_count'] = train_df['text'].apply(nltk.tokenize.word_tokenize).apply(len)\ntest_df['word_count'] = test_df['text'].apply(nltk.tokenize.word_tokenize).apply(len)","metadata":{"execution":{"iopub.status.busy":"2022-11-30T19:07:48.213874Z","iopub.execute_input":"2022-11-30T19:07:48.2145Z","iopub.status.idle":"2022-11-30T19:07:50.789951Z","shell.execute_reply.started":"2022-11-30T19:07:48.214459Z","shell.execute_reply":"2022-11-30T19:07:50.788622Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Number of Characters","metadata":{}},{"cell_type":"code","source":"# create a new feature for the number of characters excluding white spaces\ntrain_df['char_count'] = train_df['text'].apply(lambda x: len(x) - x.count(\" \"))\ntest_df['char_count'] = test_df['text'].apply(lambda x: len(x) - x.count(\" \"))","metadata":{"execution":{"iopub.status.busy":"2022-11-30T19:07:54.213234Z","iopub.execute_input":"2022-11-30T19:07:54.21368Z","iopub.status.idle":"2022-11-30T19:07:54.236943Z","shell.execute_reply.started":"2022-11-30T19:07:54.213645Z","shell.execute_reply":"2022-11-30T19:07:54.235534Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Number of Hashtags","metadata":{}},{"cell_type":"code","source":"# define a function that returns the number of hashtags in a string\ndef hash_count(string):\n    words = string.split()\n    hashtags = [w for w in words if w.startswith('#')]\n    return len(hashtags)\n\n# create a new feature for the number of hashtags\ntrain_df['hash_count'] = train_df['text'].apply(hash_count)\ntest_df['hash_count'] = test_df['text'].apply(hash_count)","metadata":{"execution":{"iopub.status.busy":"2022-11-30T19:07:59.161314Z","iopub.execute_input":"2022-11-30T19:07:59.161775Z","iopub.status.idle":"2022-11-30T19:07:59.221574Z","shell.execute_reply.started":"2022-11-30T19:07:59.161739Z","shell.execute_reply":"2022-11-30T19:07:59.21889Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Number of Mentions","metadata":{}},{"cell_type":"code","source":"# define a function that returns the number of mentions in a string\ndef ment_count(string):\n    words = string.split()\n    mentions = [w for w in words if w.startswith('@')]\n    return len(mentions)\n\n# create a new feature for the number of mentions\ntrain_df['ment_count'] = train_df['text'].apply(ment_count)\ntest_df['ment_count'] = test_df['text'].apply(ment_count)","metadata":{"execution":{"iopub.status.busy":"2022-11-30T19:08:02.731872Z","iopub.execute_input":"2022-11-30T19:08:02.732652Z","iopub.status.idle":"2022-11-30T19:08:02.789515Z","shell.execute_reply.started":"2022-11-30T19:08:02.732614Z","shell.execute_reply":"2022-11-30T19:08:02.787949Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Number of All Caps Words","metadata":{}},{"cell_type":"code","source":"# define a function that returns the number of words in all CAPS\ndef all_caps_count(string):\n    words = string.split()\n    pattern = re.compile(r'\\b[A-Z]+[A-Z]+\\b')\n    capsWords = [w for w in words if w in re.findall(pattern, string)]\n    return len(capsWords)\n\n# create a new feature for the number of words in all CAPS\ntrain_df['all_caps_count'] = train_df['text'].apply(all_caps_count)\ntest_df['all_caps_count'] = test_df['text'].apply(all_caps_count)","metadata":{"execution":{"iopub.status.busy":"2022-11-30T19:08:05.641833Z","iopub.execute_input":"2022-11-30T19:08:05.64257Z","iopub.status.idle":"2022-11-30T19:08:06.472994Z","shell.execute_reply.started":"2022-11-30T19:08:05.642531Z","shell.execute_reply":"2022-11-30T19:08:06.471479Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Average Length of words","metadata":{}},{"cell_type":"code","source":"# define a function that returns the average length of words\ndef avg_word_len(string):\n    words = string.split()\n    total_len = sum([len(words[i]) for i in range(len(words))])\n    avg_len = round(total_len / len(words), 2)\n    return avg_len\n\n# create a new feature for the average length of words\ntrain_df['avg_word_len'] = train_df['text'].apply(avg_word_len)\ntest_df['avg_word_len'] = test_df['text'].apply(avg_word_len)","metadata":{"execution":{"iopub.status.busy":"2022-11-30T19:08:09.370163Z","iopub.execute_input":"2022-11-30T19:08:09.370945Z","iopub.status.idle":"2022-11-30T19:08:09.439739Z","shell.execute_reply.started":"2022-11-30T19:08:09.370904Z","shell.execute_reply":"2022-11-30T19:08:09.438396Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Number of Proper Nouns (PROPN)\nIt is known that fake news tends to use more proper nouns than real news ([this article](https://arxiv.org/pdf/1703.09398.pdf) is a great resource to learn about how NLP helps us detect the fake news). Would the number of proper nouns in Tweets tell us anything about whether a given Tweet is an actual disaster-related Tweet or not? Let's try it out.","metadata":{}},{"cell_type":"code","source":"# define a function using nltk that returns the number of proper nouns in the text\ndef propn_count_nltk(text):    \n    tokens = nltk.word_tokenize(text)\n    tagged = [token for token in nltk.pos_tag(tokens)]\n    propn_count = len([token for (token, tag) in tagged if tag == 'NNP' or tag == 'NNPS'])\n    return propn_count\n\n# create a new feature for the number of proper nouns\ntrain_df['propn_count_nltk'] = train_df['text'].apply(propn_count_nltk)\ntest_df['propn_count_nltk'] = test_df['text'].apply(propn_count_nltk)","metadata":{"execution":{"iopub.status.busy":"2022-11-30T19:08:13.572948Z","iopub.execute_input":"2022-11-30T19:08:13.573406Z","iopub.status.idle":"2022-11-30T19:08:31.599432Z","shell.execute_reply.started":"2022-11-30T19:08:13.573357Z","shell.execute_reply":"2022-11-30T19:08:31.598007Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# check the results\ntrain_df[['id', 'text', 'text_cleaned', 'propn_count_nltk']].head()","metadata":{"execution":{"iopub.status.busy":"2022-11-30T19:08:38.41733Z","iopub.execute_input":"2022-11-30T19:08:38.417855Z","iopub.status.idle":"2022-11-30T19:08:38.438841Z","shell.execute_reply.started":"2022-11-30T19:08:38.417812Z","shell.execute_reply":"2022-11-30T19:08:38.437187Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Looking at the results, we can easily tell **nltk** did not do a good job detecting proper nouns here. The first text, \"Our Deeds are the Reason of this #earthquake May ALLAH Forgive us all\" doesn't seem to have 4 proper nouns. Let's check which tokens were tagged as proper nouns.","metadata":{}},{"cell_type":"code","source":"# test how nltk worked with the first text\nstring = \"Our Deeds are the Reason of this #earthquake May ALLAH Forgive us all\"\nprint([(token, tag) for (token, tag) in nltk.pos_tag(nltk.word_tokenize(string)) if tag == 'NNP'])","metadata":{"execution":{"iopub.status.busy":"2022-11-30T19:08:42.050486Z","iopub.execute_input":"2022-11-30T19:08:42.050958Z","iopub.status.idle":"2022-11-30T19:08:42.059916Z","shell.execute_reply.started":"2022-11-30T19:08:42.050921Z","shell.execute_reply":"2022-11-30T19:08:42.058561Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Non-proper nouns that begin with an uppercase letter were tagged as proper-nouns! Would have it been correctly tagged if the string was converted to lowercase first?","metadata":{}},{"cell_type":"code","source":"# test how nltk works with the first text after lowercasing it\nstring = \"Our Deeds are the Reason of this #earthquake May ALLAH Forgive us all\"\nprint([(token, tag) for (token, tag) in nltk.pos_tag(nltk.word_tokenize(string.lower())) if tag == 'NNP'])","metadata":{"execution":{"iopub.status.busy":"2022-11-30T19:08:46.95018Z","iopub.execute_input":"2022-11-30T19:08:46.950619Z","iopub.status.idle":"2022-11-30T19:08:46.958612Z","shell.execute_reply.started":"2022-11-30T19:08:46.950585Z","shell.execute_reply":"2022-11-30T19:08:46.957674Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"No, now with the lowercased text, nltk does not tag \"allah\" as a proper noun. Let's try with **spaCy** this time.","metadata":{}},{"cell_type":"code","source":"# load the model\nnlp = spacy.load('en_core_web_sm')\n\n# check the same string with spaCy\nstring = \"Our Deeds are the Reason of this #earthquake May ALLAH Forgive us all\"\nprint([(token.text, token.pos_) for token in nlp(string) if token.pos_=='PROPN'])","metadata":{"execution":{"iopub.status.busy":"2022-11-30T19:08:51.461864Z","iopub.execute_input":"2022-11-30T19:08:51.46257Z","iopub.status.idle":"2022-11-30T19:08:52.338349Z","shell.execute_reply.started":"2022-11-30T19:08:51.462518Z","shell.execute_reply":"2022-11-30T19:08:52.336561Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"SpaCy correctly picked up the proper noun from the string. Let's create the feature of the number of proper nouns in the text with spaCy and remove the one we previously created with nltk.","metadata":{}},{"cell_type":"code","source":"# define a function that returns number of proper nouns with spaCy\ndef propn_count(text, model=nlp):\n    doc = model(text)\n    pos = [token.pos_ for token in doc]\n    return pos.count('PROPN')\n\n# create a new feature for numbers of proper nouns\ntrain_df['propn_count'] = train_df['text'].apply(propn_count)\ntest_df['propn_count'] = test_df['text'].apply(propn_count)","metadata":{"execution":{"iopub.status.busy":"2022-11-30T19:08:58.915994Z","iopub.execute_input":"2022-11-30T19:08:58.9166Z","iopub.status.idle":"2022-11-30T19:10:49.478977Z","shell.execute_reply.started":"2022-11-30T19:08:58.916548Z","shell.execute_reply":"2022-11-30T19:10:49.477462Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# remove 'propn_count_nltk' columns\ntrain_df = train_df.drop(['propn_count_nltk'], axis=1)\ntest_df = test_df.drop(['propn_count_nltk'], axis=1)","metadata":{"execution":{"iopub.status.busy":"2022-11-30T19:10:53.936776Z","iopub.execute_input":"2022-11-30T19:10:53.937211Z","iopub.status.idle":"2022-11-30T19:10:53.950551Z","shell.execute_reply.started":"2022-11-30T19:10:53.937175Z","shell.execute_reply":"2022-11-30T19:10:53.949058Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# check the results\ntrain_df[['id', 'text', 'text_cleaned', 'propn_count']].head()","metadata":{"execution":{"iopub.status.busy":"2022-11-30T19:10:56.616831Z","iopub.execute_input":"2022-11-30T19:10:56.61756Z","iopub.status.idle":"2022-11-30T19:10:56.634001Z","shell.execute_reply.started":"2022-11-30T19:10:56.617521Z","shell.execute_reply":"2022-11-30T19:10:56.632421Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"SpaCy is not perfect, either - \"La Ronge\" in the second text (id:4) is one proper noun not two, but it is clear that spaCy still performs better than nltk on this specific task. Let's use spaCy for the next feature as well. ","metadata":{}},{"cell_type":"markdown","source":"### Number of Non-proper Nouns (NOUN)","metadata":{}},{"cell_type":"code","source":"# define a function that returns number of non-proper nouns\ndef noun_count(text, model=nlp):\n    doc = model(text)\n    pos = [token.pos_ for token in doc]\n    return pos.count('NOUN')\n\n# create a new feature for numbers of non-proper nouns\ntrain_df['noun_count'] = train_df['text'].apply(noun_count)\ntest_df['noun_count'] = test_df['text'].apply(noun_count)","metadata":{"execution":{"iopub.status.busy":"2022-11-30T19:11:00.727075Z","iopub.execute_input":"2022-11-30T19:11:00.72808Z","iopub.status.idle":"2022-11-30T19:12:42.929491Z","shell.execute_reply.started":"2022-11-30T19:11:00.72802Z","shell.execute_reply":"2022-11-30T19:12:42.927958Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Percentage of Characters that are Punctuation","metadata":{}},{"cell_type":"code","source":"import string\n\n# define a function that returns the percentage of punctuation\ndef punc_per(text):\n    total_count = len(text) - text.count(\" \")\n    punc_count = sum([1 for c in text if c in string.punctuation])\n    if punc_count != 0 and total_count != 0:\n        return round(punc_count / total_count * 100, 2)\n    else:\n        return 0\n\n# create a new feature for the percentage of punctuation in text\ntrain_df['punc_per'] = train_df['text'].apply(punc_per)\ntest_df['punc_per'] = test_df['text'].apply(punc_per)","metadata":{"execution":{"iopub.status.busy":"2022-11-30T19:12:48.958996Z","iopub.execute_input":"2022-11-30T19:12:48.959445Z","iopub.status.idle":"2022-11-30T19:12:49.109427Z","shell.execute_reply.started":"2022-11-30T19:12:48.959408Z","shell.execute_reply":"2022-11-30T19:12:49.107496Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# check the results\ntrain_df.tail()","metadata":{"execution":{"iopub.status.busy":"2022-11-30T19:12:52.456682Z","iopub.execute_input":"2022-11-30T19:12:52.457102Z","iopub.status.idle":"2022-11-30T19:12:52.480125Z","shell.execute_reply.started":"2022-11-30T19:12:52.457068Z","shell.execute_reply":"2022-11-30T19:12:52.4782Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# check the results\ntest_df.tail()","metadata":{"execution":{"iopub.status.busy":"2022-11-30T19:12:56.500756Z","iopub.execute_input":"2022-11-30T19:12:56.501199Z","iopub.status.idle":"2022-11-30T19:12:56.52276Z","shell.execute_reply.started":"2022-11-30T19:12:56.501164Z","shell.execute_reply":"2022-11-30T19:12:56.521428Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"***","metadata":{}},{"cell_type":"markdown","source":"## <a id=\"preprocess2\">üßæ Text Preprocessing - Part II</a>\nLet's resume our text preprocessing and **lemmatize** the text and make it **lowercase**. We'll also **remove repeated characters in elongated words, as well as mentions, stopwords, and punctuation**. We'll keep hashtags as they may provide valuable insights in this particular project. ","metadata":{}},{"cell_type":"markdown","source":"### Lemmatization","metadata":{}},{"cell_type":"code","source":"# lemmatize the text\ntrain_df['text_cleaned'] = train_df['text_cleaned'].apply(lambda x:' '.join([t.lemma_ for t in nlp(x)]))\ntest_df['text_cleaned'] = test_df['text_cleaned'].apply(lambda x:' '.join([t.lemma_ for t in nlp(x)]))","metadata":{"execution":{"iopub.status.busy":"2022-11-30T19:13:01.892835Z","iopub.execute_input":"2022-11-30T19:13:01.893325Z","iopub.status.idle":"2022-11-30T19:14:43.417364Z","shell.execute_reply.started":"2022-11-30T19:13:01.893285Z","shell.execute_reply":"2022-11-30T19:14:43.415856Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Convert the Text to Lowercase","metadata":{}},{"cell_type":"code","source":"# lowercase the text\ntrain_df['text_cleaned'] = [t.lower() for t in train_df['text_cleaned']]\ntest_df['text_cleaned'] = [t.lower() for t in test_df['text_cleaned']]","metadata":{"execution":{"iopub.status.busy":"2022-11-30T19:14:48.211588Z","iopub.execute_input":"2022-11-30T19:14:48.212137Z","iopub.status.idle":"2022-11-30T19:14:48.228921Z","shell.execute_reply.started":"2022-11-30T19:14:48.212099Z","shell.execute_reply":"2022-11-30T19:14:48.227691Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Remove Repeated Charcters in Elongated Words","metadata":{}},{"cell_type":"code","source":"# define a function that removes repeated characters in elongated words\ndef remove_repeated(text):\n    elongated = re.compile(r'(\\S*?)([a-z])\\2{2,}')\n    text = elongated.sub(r'\\1\\2', text)\n    return text\n\n# remove repeated characters in elongated words\ntrain_df['text_cleaned'] = train_df['text_cleaned'].apply(remove_repeated)\ntest_df['text_cleaned'] = test_df['text_cleaned'].apply(remove_repeated)","metadata":{"execution":{"iopub.status.busy":"2022-11-30T19:14:51.506721Z","iopub.execute_input":"2022-11-30T19:14:51.508307Z","iopub.status.idle":"2022-11-30T19:14:51.844027Z","shell.execute_reply.started":"2022-11-30T19:14:51.508251Z","shell.execute_reply":"2022-11-30T19:14:51.841982Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Remove Mentions","metadata":{}},{"cell_type":"code","source":"# define a function that removes mentions\ndef remove_mention(text):\n    text = re.sub(r'@\\w+', '', text)\n    return text\n\n# remove mentions\ntrain_df['text_cleaned'] = train_df['text_cleaned'].apply(remove_mention)\ntest_df['text_cleaned'] = test_df['text_cleaned'].apply(remove_mention)","metadata":{"execution":{"iopub.status.busy":"2022-11-30T19:14:55.557138Z","iopub.execute_input":"2022-11-30T19:14:55.557711Z","iopub.status.idle":"2022-11-30T19:14:55.588648Z","shell.execute_reply.started":"2022-11-30T19:14:55.557665Z","shell.execute_reply":"2022-11-30T19:14:55.587499Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Remove Stopwords","metadata":{}},{"cell_type":"code","source":"# define a function that removes stopwords\ndef remove_stopwords(text):\n    stopwords = nlp.Defaults.stop_words\n    text_nostop = ' '.join([token for token in text.split() if token not in stopwords])\n    return text_nostop\n\n# remove stopwords\ntrain_df['text_cleaned'] = train_df['text_cleaned'].apply(remove_stopwords)\ntest_df['text_cleaned'] = test_df['text_cleaned'].apply(remove_stopwords)","metadata":{"execution":{"iopub.status.busy":"2022-11-30T19:15:01.516932Z","iopub.execute_input":"2022-11-30T19:15:01.517455Z","iopub.status.idle":"2022-11-30T19:15:01.573868Z","shell.execute_reply.started":"2022-11-30T19:15:01.517408Z","shell.execute_reply":"2022-11-30T19:15:01.572583Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Remove Punctuation","metadata":{}},{"cell_type":"code","source":"# define a function to remove punctuation\ndef remove_punct(text):\n    punct = string.punctuation\n    text_nospunct = ' '.join([token for token in text.split() if token not in punct])\n    return text_nospunct\n\n# remove punctuation\ntrain_df['text_cleaned'] = train_df['text_cleaned'].apply(remove_punct)\ntest_df['text_cleaned'] = test_df['text_cleaned'].apply(remove_punct)","metadata":{"execution":{"iopub.status.busy":"2022-11-30T19:15:08.439532Z","iopub.execute_input":"2022-11-30T19:15:08.43994Z","iopub.status.idle":"2022-11-30T19:15:08.479439Z","shell.execute_reply.started":"2022-11-30T19:15:08.439907Z","shell.execute_reply":"2022-11-30T19:15:08.477912Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# check the results\ntrain_df[['id', 'text', 'text_cleaned']].head()","metadata":{"execution":{"iopub.status.busy":"2022-11-30T19:15:14.074371Z","iopub.execute_input":"2022-11-30T19:15:14.074846Z","iopub.status.idle":"2022-11-30T19:15:14.09411Z","shell.execute_reply.started":"2022-11-30T19:15:14.074805Z","shell.execute_reply":"2022-11-30T19:15:14.092649Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# check the results\ntest_df[['id', 'text', 'text_cleaned']].head()","metadata":{"execution":{"iopub.status.busy":"2022-11-30T19:15:18.32994Z","iopub.execute_input":"2022-11-30T19:15:18.330367Z","iopub.status.idle":"2022-11-30T19:15:18.346973Z","shell.execute_reply.started":"2022-11-30T19:15:18.33033Z","shell.execute_reply":"2022-11-30T19:15:18.345723Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Raw vs. Preprocessed Text with Word Clouds","metadata":{}},{"cell_type":"markdown","source":"Let's generate word clouds of preprocessed text.","metadata":{}},{"cell_type":"code","source":"# concat all the preprocessed text for both labels\nnon_disaster_processed = [''.join(t) for t in train_df[train_df['target']==0]['text_cleaned']]\nnon_disaster_processed_s = ' '.join(map(str, non_disaster_processed))\ndisaster_processed = [''.join(t) for t in train_df[train_df['target']==1]['text_cleaned']]\ndisaster_processed_s = ' '.join(map(str, disaster_processed))\n\n# generate word clouds of the preprocessed text\nnon_disaster_processed_wc = WordCloud(width=800, height=400, max_words=500, background_color='white', random_state=random_state).generate(non_disaster_processed_s)\ndisaster_processed_wc = WordCloud(width=800, height=400, max_words=500, random_state=random_state).generate(disaster_processed_s)","metadata":{"execution":{"iopub.status.busy":"2022-11-30T19:15:26.580883Z","iopub.execute_input":"2022-11-30T19:15:26.581336Z","iopub.status.idle":"2022-11-30T19:15:30.242055Z","shell.execute_reply.started":"2022-11-30T19:15:26.581297Z","shell.execute_reply":"2022-11-30T19:15:30.240751Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# create subplots for the generated clouds\nfig, axes = plt.subplots(2, 2, figsize = (20,10))\naxes[0,0].imshow(non_disaster_cloud, interpolation='bilinear')\naxes[0,1].imshow(disaster_cloud, interpolation='bilinear')\naxes[1,0].imshow(non_disaster_processed_wc, interpolation='bilinear')\naxes[1,1].imshow(disaster_processed_wc, interpolation='bilinear')\n\n# turn the axis off\n[ax.axis('off') for ax in axes.ravel()]\n\n# add titles\naxes[0,0].set_title('Non-disaster Tweets (raw)', fontsize=16)\naxes[0,1].set_title('Disaster Tweets (raw)', fontsize=16)\naxes[1,0].set_title('Non-disaster Tweets (preprocessed)', fontsize=16)\naxes[1,1].set_title('Disaster Tweets (preprocessed)', fontsize=16)\n\n# show the figure\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-11-30T19:15:32.886668Z","iopub.execute_input":"2022-11-30T19:15:32.887079Z","iopub.status.idle":"2022-11-30T19:15:34.318865Z","shell.execute_reply.started":"2022-11-30T19:15:32.887045Z","shell.execute_reply":"2022-11-30T19:15:34.317159Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now it's easier to see the frequently used words that actually are meaningful. It also seems like **more disaster-related words are showing on the word cloud of real disaster Tweets**.","metadata":{}},{"cell_type":"markdown","source":"### üìä Visualizing Differences\nLet's visualize some of the features we've created and see if there are easy-to-tell differences between disaster and non-disaster Tweets in our training dataset.","metadata":{}},{"cell_type":"code","source":"# store the features and their names in variables\nfeatures = ['sent_count', 'word_count', 'char_count', 'hash_count', 'ment_count', 'all_caps_count', \n            'avg_word_len', 'propn_count', 'noun_count', 'punc_per']\n\n# create the figure\nfig = plt.figure(figsize=(20, 20))\n\n# adjust the height of the padding between subplots to avoid overlapping\nplt.subplots_adjust(hspace=0.3)\n\n# add a centered suptitle to the figure\nplt.suptitle(\"Difference in Features, Disaster vs. Non-disaster\", fontsize=20, y=0.91)\n\n# generate the histograms in a for loop\nfor i, feature in enumerate(features):\n    \n    # add a new subplot iteratively\n    ax = plt.subplot(4, 3, i+1)\n    ax = train_df[train_df['target']==0][feature].hist(alpha=0.5, label='Non-disaster', bins=40, color='royalblue', density=True)\n    ax = train_df[train_df['target']==1][feature].hist(alpha=0.5, label='Disaster', bins=40, color='lightcoral', density=True)\n    \n    # set x_label, y_label, and legend\n    ax.set_xlabel(features[i], fontsize=14)\n    ax.set_ylabel('Probability Density', fontsize=14)\n    ax.legend(loc='upper right', fontsize=14)\n    \n\n# shot the figure\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-11-30T19:16:17.291246Z","iopub.execute_input":"2022-11-30T19:16:17.291734Z","iopub.status.idle":"2022-11-30T19:16:20.420158Z","shell.execute_reply.started":"2022-11-30T19:16:17.291697Z","shell.execute_reply":"2022-11-30T19:16:20.418844Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- We'll use the four features, **word_count, char_count, avg_word_len, and punc_per**, for our models as they show bigger differences in distributions than other features we've created.\n- Note: The y-axis in the plots above is probability density, not # of Tweets due to the different size of disaster/non-disaster Tweets. ","metadata":{}},{"cell_type":"markdown","source":"Now let's move on and start building our models!","metadata":{}},{"cell_type":"markdown","source":"***","metadata":{}},{"cell_type":"markdown","source":"## <a id=\"build\">üî® Model Building</a>","metadata":{}},{"cell_type":"markdown","source":"### Vectorizing Text & Selecting Input/Output","metadata":{}},{"cell_type":"code","source":"# import TfidfVectorizer\nfrom sklearn.feature_extraction.text import TfidfVectorizer\n\n# instantiate the vectorizer\ntfidf = TfidfVectorizer()\n\n# fit and transform\nX_tfidf = tfidf.fit_transform(train_df['text_cleaned'])","metadata":{"execution":{"iopub.status.busy":"2022-11-30T19:16:42.170205Z","iopub.execute_input":"2022-11-30T19:16:42.170689Z","iopub.status.idle":"2022-11-30T19:16:42.297423Z","shell.execute_reply.started":"2022-11-30T19:16:42.170651Z","shell.execute_reply":"2022-11-30T19:16:42.296091Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# create a dataframe from the sparse matrix\nX_tfidf_df = pd.DataFrame(X_tfidf.toarray())\n\n# check the dataframe\nX_tfidf_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-11-30T19:16:46.939121Z","iopub.execute_input":"2022-11-30T19:16:46.939734Z","iopub.status.idle":"2022-11-30T19:16:47.28952Z","shell.execute_reply.started":"2022-11-30T19:16:46.939681Z","shell.execute_reply":"2022-11-30T19:16:47.288111Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# get the feature names from our stored vectorizer and assign them to X_tfidf_df\n# to avoid getting 'FutureWarning: Feature names only support names that are strings.'\nX_tfidf_df.columns = tfidf.get_feature_names_out()\n\n# check the column names\nX_tfidf_df.columns","metadata":{"execution":{"iopub.status.busy":"2022-11-30T19:16:50.921727Z","iopub.execute_input":"2022-11-30T19:16:50.922148Z","iopub.status.idle":"2022-11-30T19:16:50.947458Z","shell.execute_reply.started":"2022-11-30T19:16:50.922113Z","shell.execute_reply":"2022-11-30T19:16:50.945978Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# create the new dataframe, X_features\nX_features = pd.concat([train_df[['word_count', 'char_count', 'avg_word_len', 'punc_per']],\n                        X_tfidf_df], axis=1)\n\n# check the shape\nX_features.shape","metadata":{"execution":{"iopub.status.busy":"2022-11-30T19:16:54.763947Z","iopub.execute_input":"2022-11-30T19:16:54.764457Z","iopub.status.idle":"2022-11-30T19:16:56.567247Z","shell.execute_reply.started":"2022-11-30T19:16:54.764419Z","shell.execute_reply":"2022-11-30T19:16:56.565785Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# check the dataframe\nX_features.head()","metadata":{"execution":{"iopub.status.busy":"2022-11-30T19:17:00.381167Z","iopub.execute_input":"2022-11-30T19:17:00.381687Z","iopub.status.idle":"2022-11-30T19:17:00.419504Z","shell.execute_reply.started":"2022-11-30T19:17:00.381646Z","shell.execute_reply":"2022-11-30T19:17:00.418076Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Splitting Into Train and Validation Data\nWe're going to split our preprocessed training dataset into training subset and validation subset. The former will be used to train our models, while as the latter is heldout for validation.","metadata":{}},{"cell_type":"code","source":"# import the library\nfrom sklearn.model_selection import train_test_split\n\n# select the input/output\nX = X_features\ny = train_df['target']\n\n# split the data\n# the names, X_val and y_val, are used instead of X_test and y_test to avoid confusion with our actual test data\n# which we will be using to make the predictions with the selected model at the end of this notebook\nX_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=random_state)","metadata":{"execution":{"iopub.status.busy":"2022-11-30T19:17:09.522111Z","iopub.execute_input":"2022-11-30T19:17:09.522577Z","iopub.status.idle":"2022-11-30T19:17:10.907581Z","shell.execute_reply.started":"2022-11-30T19:17:09.522527Z","shell.execute_reply":"2022-11-30T19:17:10.906182Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Building Models","metadata":{}},{"cell_type":"code","source":"# import the libraries\nfrom sklearn.metrics import accuracy_score, precision_score, f1_score, recall_score\nfrom sklearn.metrics import classification_report\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.svm import SVC\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier","metadata":{"execution":{"iopub.status.busy":"2022-11-30T19:17:16.120788Z","iopub.execute_input":"2022-11-30T19:17:16.121219Z","iopub.status.idle":"2022-11-30T19:17:16.281827Z","shell.execute_reply.started":"2022-11-30T19:17:16.121186Z","shell.execute_reply":"2022-11-30T19:17:16.280618Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# create a dictionary containing the names and code of algorithms\nclfs = {'mnb': MultinomialNB(), \n        'svc': SVC(random_state=random_state), \n        'lr': LogisticRegression(max_iter=10000, random_state=random_state), \n        'dtc': DecisionTreeClassifier(random_state=random_state),\n        'knc': KNeighborsClassifier(n_jobs=-1), \n        'rfc': RandomForestClassifier(random_state=random_state, n_jobs=-1), \n        'gbc': GradientBoostingClassifier(random_state=random_state)}","metadata":{"execution":{"iopub.status.busy":"2022-11-30T19:17:25.200551Z","iopub.execute_input":"2022-11-30T19:17:25.201108Z","iopub.status.idle":"2022-11-30T19:17:25.209963Z","shell.execute_reply.started":"2022-11-30T19:17:25.201052Z","shell.execute_reply":"2022-11-30T19:17:25.208174Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# create a function that builds and runs multiple classification models\ndef classify(clf, X_train, X_val, y_train, y_val):\n    y_pred = clf.fit(X_train, y_train).predict(X_val)\n    precision = precision_score(y_val, y_pred)\n    fscore = f1_score(y_val, y_pred)\n    train_accuracy = clf.score(X_train, y_train)\n    test_accuracy = accuracy_score(y_val, y_pred)\n    return precision, fscore, train_accuracy, test_accuracy","metadata":{"execution":{"iopub.status.busy":"2022-11-30T19:17:29.026891Z","iopub.execute_input":"2022-11-30T19:17:29.027368Z","iopub.status.idle":"2022-11-30T19:17:29.036808Z","shell.execute_reply.started":"2022-11-30T19:17:29.027308Z","shell.execute_reply":"2022-11-30T19:17:29.034456Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# create lists to store scores to build a dataframe later on\nprecision_series = []\nfscore_series = []\ntrain_accuracy_series = []\ntest_accuracy_series = []\n\n# run the models with classify() function we created above (this takes some time)\nfor name, clf in clfs.items():\n    i_precision, i_fscore, i_train_accuracy, i_test_accuracy = classify(clf, X_train, X_val, y_train, y_val)\n    \n    # append the scores to the lists\n    precision_series.append(i_precision)\n    fscore_series.append(i_fscore)\n    train_accuracy_series.append(i_train_accuracy)\n    test_accuracy_series.append(i_test_accuracy)\n    \n    # fit and predict\n    y_pred = clf.fit(X_train, y_train).predict(X_val)\n    \n    # print out the scores and classification reports\n    print('[{}]\\nPrecision: {} | F1-score: {} | Train Accuracy: {} | Test Accuracy: {}\\n'.format(name,\n                                                                                                 round(i_precision, 2),\n                                                                                                 round(i_fscore, 2),\n                                                                                                 round(i_train_accuracy, 2),\n                                                                                                 round(i_test_accuracy, 2)))\n    print(classification_report(y_val, y_pred))","metadata":{"execution":{"iopub.status.busy":"2022-11-30T19:17:34.384351Z","iopub.execute_input":"2022-11-30T19:17:34.384831Z","iopub.status.idle":"2022-11-30T19:56:14.741272Z","shell.execute_reply.started":"2022-11-30T19:17:34.384793Z","shell.execute_reply":"2022-11-30T19:56:14.739721Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Feature Importances (optional)\nWe can use RandomForestClassifier's .feature_importances_ attribute to check **which features our model found important**.","metadata":{}},{"cell_type":"code","source":"# fit the model\nrfc_model = clfs.get('rfc').fit(X_train, y_train)\n\n# check the feature_importances\nsorted(zip(rfc_model.feature_importances_, X_train.columns), reverse=True)[0:10]","metadata":{"execution":{"iopub.status.busy":"2022-11-30T19:57:40.300164Z","iopub.execute_input":"2022-11-30T19:57:40.300641Z","iopub.status.idle":"2022-11-30T19:57:51.917861Z","shell.execute_reply.started":"2022-11-30T19:57:40.300602Z","shell.execute_reply":"2022-11-30T19:57:51.916171Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**All four features we've created are listed in top 10 most important features by RandomForestClassifier.** Now let's visualize our model performances.","metadata":{}},{"cell_type":"markdown","source":"### üìä Visualizing Model Performance","metadata":{}},{"cell_type":"code","source":"# create a dataframe with the scores\nscores_df = pd.DataFrame({'Algorithm': clfs.keys(),\n                          'Precision': precision_series,\n                          'F1 Score': fscore_series,\n                          'Train Accuracy': train_accuracy_series,\n                          'Test Accuracy': test_accuracy_series}).round(2).sort_values('Test Accuracy', ascending=False)\n# check the dataframe\nscores_df","metadata":{"execution":{"iopub.status.busy":"2022-11-30T19:58:19.211222Z","iopub.execute_input":"2022-11-30T19:58:19.211663Z","iopub.status.idle":"2022-11-30T19:58:19.236722Z","shell.execute_reply.started":"2022-11-30T19:58:19.211628Z","shell.execute_reply":"2022-11-30T19:58:19.23529Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# create a list of metrics\nmetrics = ['Precision', 'F1 Score', 'Train Accuracy', 'Test Accuracy']\n\n# create the figure\nfig = plt.figure(figsize=(12, 8))\n\n# adjust the height of the padding between subplots to avoid overlapping\n#plt.subplots_adjust(hspace=0.3)\n\n# set the color palette\ncolors = {'lr':'lightcoral',\n          'mnb':'lightskyblue',\n          'rfc':'orange',\n          'gbc':'gold',\n          'dtc':'limegreen',\n          'svc':'royalblue',\n          'knc':'dimgray'}\n\n# add a centered suptitle to the figure\nplt.suptitle('Comparison in Model Performance', fontsize=14, y=0.92)\n\n# generate the histograms in a for loop\nfor i, metric in enumerate(metrics):\n    \n    # add a new subplot iteratively\n    ax = plt.subplot(2, 2, i+1)\n    ax = sns.barplot(x='Algorithm', y=metric, data=scores_df.sort_values(metric, ascending=False), palette=colors)\n    \n    # set x_label, y_label\n    ax.set_xlabel('Algorithm', fontsize=12)\n    ax.set_ylabel(metric, fontsize=12)\n    \n# show the plots\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-11-30T19:58:22.857117Z","iopub.execute_input":"2022-11-30T19:58:22.857588Z","iopub.status.idle":"2022-11-30T19:58:23.514366Z","shell.execute_reply.started":"2022-11-30T19:58:22.85755Z","shell.execute_reply":"2022-11-30T19:58:23.513124Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"***","metadata":{}},{"cell_type":"markdown","source":"## <a id=\"evaluate\">üîé Model Evaluation</a>\nLet's perform cross validation and grid search using **RandomizedSearchCV on our top 3 models**.<br>  \n*On a side note, I had ran the equivalent code with GridSearchCV on my local notebook and got similar results but a lot longer processing time.*","metadata":{}},{"cell_type":"code","source":"# import the libraries\nfrom sklearn.model_selection import RandomizedSearchCV\nfrom time import time","metadata":{"execution":{"iopub.status.busy":"2022-11-30T19:58:36.31555Z","iopub.execute_input":"2022-11-30T19:58:36.31598Z","iopub.status.idle":"2022-11-30T19:58:36.323693Z","shell.execute_reply.started":"2022-11-30T19:58:36.315946Z","shell.execute_reply":"2022-11-30T19:58:36.321808Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Logistic Regression (lr)","metadata":{}},{"cell_type":"code","source":"# instantiate the model\nlr = LogisticRegression(max_iter=10000, random_state=random_state)\n\n# set the parameters\nparam_lr = {'C': [0.01, 0.1, 1, 10, 100]}","metadata":{"execution":{"iopub.status.busy":"2022-11-30T19:58:40.403582Z","iopub.execute_input":"2022-11-30T19:58:40.405615Z","iopub.status.idle":"2022-11-30T19:58:40.411837Z","shell.execute_reply.started":"2022-11-30T19:58:40.405567Z","shell.execute_reply":"2022-11-30T19:58:40.410187Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# construct RandomizedSearchCV object\nrs_lr = RandomizedSearchCV(lr, param_lr, scoring='accuracy', cv=5, n_iter=5, n_jobs=-1, random_state=random_state)\n\n# check the time\nstart = time()\n\n# fit the model\nrs_lr_fit = rs_lr.fit(X_train, y_train)\n\n# check the time\nend = time()\n\n# store the results in a dataframe\nrs_rl_df = pd.DataFrame(rs_lr_fit.cv_results_).sort_values('mean_test_score', ascending=False)\n\n# show the top 5 models\nrs_rl_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-11-30T19:58:49.553018Z","iopub.execute_input":"2022-11-30T19:58:49.553464Z","iopub.status.idle":"2022-11-30T20:21:30.813331Z","shell.execute_reply.started":"2022-11-30T19:58:49.553428Z","shell.execute_reply":"2022-11-30T20:21:30.811786Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# print out the algorithm, fitting time, best parameters, and best score\nprint('Logistic Regression:\\nProcessing Time: {} secs | Best Parameters: {} | Best Score: {}'.format(round(end-start, 2),\n                                                                                                     rs_lr_fit.best_params_, \n                                                                                                     round(rs_lr_fit.best_score_, 2)))","metadata":{"execution":{"iopub.status.busy":"2022-11-30T20:22:28.023896Z","iopub.execute_input":"2022-11-30T20:22:28.024409Z","iopub.status.idle":"2022-11-30T20:22:28.03296Z","shell.execute_reply.started":"2022-11-30T20:22:28.024354Z","shell.execute_reply":"2022-11-30T20:22:28.031998Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Multinomial Naive Bayes (mnb)","metadata":{}},{"cell_type":"code","source":"# instantiate the model\nmnb = MultinomialNB()\n\n# set the parameters\nparam_mnb = {'alpha': [0.0001, 0.001, 0.1, 1, 10, 100,1000]}","metadata":{"execution":{"iopub.status.busy":"2022-11-30T20:22:45.312754Z","iopub.execute_input":"2022-11-30T20:22:45.313201Z","iopub.status.idle":"2022-11-30T20:22:45.320028Z","shell.execute_reply.started":"2022-11-30T20:22:45.313163Z","shell.execute_reply":"2022-11-30T20:22:45.31859Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# construct RandomizedSearchCV object\nrs_mnb = RandomizedSearchCV(mnb, param_mnb, scoring='accuracy', cv=5, n_iter=7, n_jobs=-1, random_state=random_state)\n\n# check the time\nstart = time()\n\n# fit the model\nrs_mnb_fit = rs_mnb.fit(X_train, y_train)\n\n# check the time\nend = time()\n\n# store the results in a dataframe\nrs_mnb_df = pd.DataFrame(rs_mnb_fit.cv_results_).sort_values('mean_test_score', ascending=False)\n\n# show the top 5 models\nrs_mnb_df.head()","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2022-11-30T20:22:47.744703Z","iopub.execute_input":"2022-11-30T20:22:47.74512Z","iopub.status.idle":"2022-11-30T20:23:03.825374Z","shell.execute_reply.started":"2022-11-30T20:22:47.745088Z","shell.execute_reply":"2022-11-30T20:23:03.823605Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# print out the algorithm, fitting time, best parameters, and best score\nprint('Multinomial Naive Bayes:\\nProcessing Time: {} secs | Best Parameters: {} | Best Score: {}'.format(round(end-start, 2),\n                                                                                                         rs_mnb_fit.best_params_,\n                                                                                                         round(rs_mnb_fit.best_score_, 2)))","metadata":{"execution":{"iopub.status.busy":"2022-11-30T20:23:29.258897Z","iopub.execute_input":"2022-11-30T20:23:29.259332Z","iopub.status.idle":"2022-11-30T20:23:29.267268Z","shell.execute_reply.started":"2022-11-30T20:23:29.259294Z","shell.execute_reply":"2022-11-30T20:23:29.26566Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Random Forest Classifier (rfc)","metadata":{}},{"cell_type":"code","source":"# instantiate the model\nrfc = RandomForestClassifier(random_state=random_state)\n\n# set the parameters\nparam_rfc = {'n_estimators': [100, 200, 300, 500],\n             'max_depth': [4, 6, 8, None]}","metadata":{"execution":{"iopub.status.busy":"2022-11-30T20:23:51.992965Z","iopub.execute_input":"2022-11-30T20:23:51.993463Z","iopub.status.idle":"2022-11-30T20:23:52.00003Z","shell.execute_reply.started":"2022-11-30T20:23:51.993424Z","shell.execute_reply":"2022-11-30T20:23:51.999058Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# construct RandomizedSearchCV object\nrs_rfc = RandomizedSearchCV(rfc, param_rfc, cv=5, n_iter=16, n_jobs=-1, random_state=random_state)\n\n# check the time\nstart = time()\n\n# fit the model\nrs_rfc_fit = rs_rfc.fit(X_train, y_train)\n\n# check the time\nend = time()\n\n# store the results in a dataframe\nrs_rfc_df = pd.DataFrame(rs_rfc_fit.cv_results_).sort_values('mean_test_score', ascending=False)\n\n# show the top 5 models in a dataframe\nrs_rfc_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-11-30T20:23:54.770833Z","iopub.execute_input":"2022-11-30T20:23:54.771299Z","iopub.status.idle":"2022-11-30T20:34:07.129093Z","shell.execute_reply.started":"2022-11-30T20:23:54.771265Z","shell.execute_reply":"2022-11-30T20:34:07.127247Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# print out the algorithm, fitting time, best parameters, and best score\nprint('Random Forest Classifier:\\nProcessing Time: {} secs | Best Parameters: {} | Best Score: {}'.format(round(end-start, 2),\n                                                                                                          rs_rfc_fit.best_params_, \n                                                                                                          round(rs_rfc_fit.best_score_, 2)))","metadata":{"execution":{"iopub.status.busy":"2022-11-30T20:35:02.754873Z","iopub.execute_input":"2022-11-30T20:35:02.755357Z","iopub.status.idle":"2022-11-30T20:35:02.764158Z","shell.execute_reply.started":"2022-11-30T20:35:02.755315Z","shell.execute_reply":"2022-11-30T20:35:02.762772Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Testing the Final Models","metadata":{}},{"cell_type":"markdown","source":"RandomizedSearchCV found that Logistic Regression and Multinomial Naive Bayes perform the best with the default hyperparameter settings. Let's test our models with **the default settings for lr and mnb, but the updated setting for rfc**.","metadata":{}},{"cell_type":"code","source":"# create a dictionary of the final models\nfinal_models = {'lr': LogisticRegression(max_iter=10000, random_state=random_state),\n                'mnb': MultinomialNB(),\n                'rfc': RandomForestClassifier(n_estimators=100, random_state=random_state, n_jobs=-1)} ","metadata":{"execution":{"iopub.status.busy":"2022-11-30T20:35:50.154048Z","iopub.execute_input":"2022-11-30T20:35:50.154597Z","iopub.status.idle":"2022-11-30T20:35:50.163559Z","shell.execute_reply.started":"2022-11-30T20:35:50.154553Z","shell.execute_reply":"2022-11-30T20:35:50.161976Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# run the models with classify() function we created above\nfor name, clf in final_models.items():\n    i_precision, i_fscore, i_train_accuracy, i_test_accuracy = classify(clf, X_train, X_val, y_train, y_val)\n    \n    # check the time\n    start = time()\n    \n    # fit and predict\n    y_pred = clf.fit(X_train, y_train).predict(X_val)\n    \n    # check the time\n    end = time()\n    \n    # print out the scores and classification reports\n    print('[{}]\\nProcessing Time: {} secs | Test Accuracy: {} | Precision: {} | F1-score: {}\\n'.format(name, \n                                                                                                  round(end-start, 2),\n                                                                                                  round(i_test_accuracy, 2),\n                                                                                                  round(i_precision, 2), \n                                                                                                  round(i_fscore, 2)))","metadata":{"execution":{"iopub.status.busy":"2022-11-30T20:36:00.260735Z","iopub.execute_input":"2022-11-30T20:36:00.261328Z","iopub.status.idle":"2022-11-30T20:37:54.698295Z","shell.execute_reply.started":"2022-11-30T20:36:00.261279Z","shell.execute_reply":"2022-11-30T20:37:54.69683Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"***","metadata":{}},{"cell_type":"markdown","source":"## <a id=\"select\">‚öñÔ∏è Final Model Selection</a>","metadata":{}},{"cell_type":"markdown","source":"Of our top three models:\n\n- The Logistic Regression model and Multinomial Naive Bayes model are close in terms of accuracy, with lr slightly higher, but mnb is faster and gives slightly higher precision.\n- In terms of F-1 score, the Logistic Regression model is the highest. \n- The Random Forest Classifier model does not perform as well as the other two above.\n\nEven though it takes longer, **let's deploy the lr model** with the actual test data!","metadata":{}},{"cell_type":"code","source":"# fit the cleaned text to the vectorizer\ntfidf_vect_fit = tfidf.fit(train_df['text_cleaned'])\n\n# create the vectorized columns\ntfidf_train = tfidf_vect_fit.transform(train_df['text_cleaned'])\ntfidf_test = tfidf_vect_fit.transform(test_df['text_cleaned'])","metadata":{"execution":{"iopub.status.busy":"2022-11-30T20:40:33.820442Z","iopub.execute_input":"2022-11-30T20:40:33.822044Z","iopub.status.idle":"2022-11-30T20:40:34.084524Z","shell.execute_reply.started":"2022-11-30T20:40:33.821982Z","shell.execute_reply":"2022-11-30T20:40:34.082964Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# create dataframes from the sparse matrices\ntfidf_train_df = pd.DataFrame(tfidf_train.toarray())\ntfidf_test_df = pd.DataFrame(tfidf_test.toarray())\n\n# get the feature names from our stored vectorizers and assign them to tfidf_train_df and tfidf_test_df\n# to avoid getting 'FutureWarning: Feature names only support names that are strings.'\ntfidf_train_df.columns = tfidf.get_feature_names_out()\ntfidf_test_df.columns = tfidf.get_feature_names_out()","metadata":{"execution":{"iopub.status.busy":"2022-11-30T20:40:37.219429Z","iopub.execute_input":"2022-11-30T20:40:37.219938Z","iopub.status.idle":"2022-11-30T20:40:37.926492Z","shell.execute_reply.started":"2022-11-30T20:40:37.219898Z","shell.execute_reply":"2022-11-30T20:40:37.92534Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# concatenate back the vectorized data and the 4 features we've created\nX_train_vect = pd.concat([train_df[['word_count', 'char_count', 'avg_word_len','punc_per']].reset_index(drop=True),\n                          tfidf_train_df], axis=1)\nX_test_vect = pd.concat([test_df[['word_count', 'char_count', 'avg_word_len', 'punc_per']].reset_index(drop=True),\n                         tfidf_test_df], axis=1)\n\n# store the labels\ny_train = train_df['target']\n\n# check the shape\nprint(X_train_vect.shape, X_test_vect.shape)","metadata":{"execution":{"iopub.status.busy":"2022-11-30T20:42:51.850829Z","iopub.execute_input":"2022-11-30T20:42:51.851323Z","iopub.status.idle":"2022-11-30T20:42:54.156629Z","shell.execute_reply.started":"2022-11-30T20:42:51.851281Z","shell.execute_reply":"2022-11-30T20:42:54.154823Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# fit the model and check the processing time\nstart = time()\nfinal_model = final_models['lr']\nfinal_model_fit = final_model.fit(X_train_vect, y_train)\nend = time()\nfit_time = end - start\n\n# make predictions and check the processing time\nstart = time()\nfinal_pred = final_model.predict(X_test_vect)\nend = time()\npred_time = end - start\n\nprint('Fit time: {} secs | Predict time: {} secs'.format(round(fit_time, 2), round(pred_time, 2)))","metadata":{"execution":{"iopub.status.busy":"2022-11-30T20:43:00.050712Z","iopub.execute_input":"2022-11-30T20:43:00.051163Z","iopub.status.idle":"2022-11-30T20:44:23.545533Z","shell.execute_reply.started":"2022-11-30T20:43:00.051129Z","shell.execute_reply":"2022-11-30T20:44:23.544088Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Submission","metadata":{}},{"cell_type":"code","source":"# create a dataframe for submission\nsubmission = test_df[['id']].reset_index(drop=True)\nsubmission['target'] = final_pred.astype('int64')","metadata":{"execution":{"iopub.status.busy":"2022-11-30T20:44:35.162277Z","iopub.execute_input":"2022-11-30T20:44:35.162769Z","iopub.status.idle":"2022-11-30T20:44:35.173354Z","shell.execute_reply.started":"2022-11-30T20:44:35.16273Z","shell.execute_reply":"2022-11-30T20:44:35.171594Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# check the dataframe\nsubmission","metadata":{"execution":{"iopub.status.busy":"2022-11-30T20:44:39.062471Z","iopub.execute_input":"2022-11-30T20:44:39.062907Z","iopub.status.idle":"2022-11-30T20:44:39.080668Z","shell.execute_reply.started":"2022-11-30T20:44:39.062874Z","shell.execute_reply":"2022-11-30T20:44:39.079201Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# export the dataframe as a csv file \nsubmission.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2022-11-30T20:44:42.729246Z","iopub.execute_input":"2022-11-30T20:44:42.730243Z","iopub.status.idle":"2022-11-30T20:44:42.749877Z","shell.execute_reply.started":"2022-11-30T20:44:42.730185Z","shell.execute_reply":"2022-11-30T20:44:42.748752Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Further Exploration\nIn this notebook, we've explored a limited number of algorithms, models, and hyperparameter settings. In practice, it is not uncommon to test over hundreds or even higher number of models. Some other ways that would help us find the best model to solve the given NLP problem include:\n\n- Using different vectorizers (e.g., Word2Vec, N-grams)\n- Including parts of the text we removed (e.g., stopwords)\n- Exploring different hyperparameter settings within each algorithm (e.g., adding 'max_features' parameter and a few possible values of it to the RandomizedSearchCV object)\n- Using different hyperparameter optimization methods (e.g., Bayesian method using Optuna) ","metadata":{}},{"cell_type":"markdown","source":"üìå In the future, I'm planning to compare the traditional machine learning models we've covered in this notebook and LSTM. Stay tuned! **Thank you for reading my notebook and please upvote if you find it helpful!**","metadata":{}}]}