{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":17777,"databundleVersionId":869809,"sourceType":"competition"},{"sourceId":865552,"sourceType":"datasetVersion","datasetId":459672}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-12-15T11:00:52.745269Z","iopub.execute_input":"2023-12-15T11:00:52.746028Z","iopub.status.idle":"2023-12-15T11:00:53.210938Z","shell.execute_reply.started":"2023-12-15T11:00:52.745984Z","shell.execute_reply":"2023-12-15T11:00:53.209816Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Import Necessary Library\n# Gerekli Kitaplığı İçe Aktar","metadata":{}},{"cell_type":"code","source":"!pip install pivottablejs\n!pip install pandas_profiling\n!pip install pygwalker","metadata":{"execution":{"iopub.status.busy":"2023-12-15T11:00:53.212731Z","iopub.execute_input":"2023-12-15T11:00:53.213155Z","iopub.status.idle":"2023-12-15T11:01:49.580993Z","shell.execute_reply.started":"2023-12-15T11:00:53.213126Z","shell.execute_reply":"2023-12-15T11:01:49.579681Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\nimport matplotlib.pyplot as plt\nimport seaborn as sb\nimport re\nfrom nltk.corpus import wordnet\nfrom nltk.stem import WordNetLemmatizer\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nfrom nltk.corpus import stopwords\nfrom collections import Counter, defaultdict\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\nfrom sklearn.model_selection import RepeatedStratifiedKFold, cross_val_score\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.pipeline import Pipeline, make_pipeline\nfrom sklearn.metrics import f1_score\nimport lime\nfrom lime import lime_text\nfrom lime.lime_text import LimeTextExplainer\nfrom pandas_profiling import ProfileReport\nimport pygwalker as pyg\nfrom pivottablejs import pivot_ui","metadata":{"execution":{"iopub.status.busy":"2023-12-15T11:01:49.582582Z","iopub.execute_input":"2023-12-15T11:01:49.583054Z","iopub.status.idle":"2023-12-15T11:01:55.392173Z","shell.execute_reply.started":"2023-12-15T11:01:49.583014Z","shell.execute_reply":"2023-12-15T11:01:55.391058Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Exploration\n# Veri Keşfi","metadata":{}},{"cell_type":"code","source":"wordnet_lemmatizer = WordNetLemmatizer()","metadata":{"execution":{"iopub.status.busy":"2023-12-15T11:01:55.394751Z","iopub.execute_input":"2023-12-15T11:01:55.395347Z","iopub.status.idle":"2023-12-15T11:01:55.40006Z","shell.execute_reply.started":"2023-12-15T11:01:55.395314Z","shell.execute_reply":"2023-12-15T11:01:55.398912Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"execution":{"iopub.status.busy":"2023-12-15T11:01:55.401519Z","iopub.execute_input":"2023-12-15T11:01:55.401922Z","iopub.status.idle":"2023-12-15T11:01:55.419337Z","shell.execute_reply.started":"2023-12-15T11:01:55.40189Z","shell.execute_reply":"2023-12-15T11:01:55.418256Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/nlp-getting-started/train.csv')","metadata":{"execution":{"iopub.status.busy":"2023-12-15T11:01:55.42038Z","iopub.execute_input":"2023-12-15T11:01:55.420771Z","iopub.status.idle":"2023-12-15T11:01:55.483384Z","shell.execute_reply.started":"2023-12-15T11:01:55.420724Z","shell.execute_reply":"2023-12-15T11:01:55.482241Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_profile = ProfileReport(train, title=\"train\")\ntrain_profile.to_notebook_iframe()","metadata":{"execution":{"iopub.status.busy":"2023-12-15T11:01:55.486181Z","iopub.execute_input":"2023-12-15T11:01:55.486616Z","iopub.status.idle":"2023-12-15T11:02:08.497107Z","shell.execute_reply.started":"2023-12-15T11:01:55.486578Z","shell.execute_reply":"2023-12-15T11:02:08.49553Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pivot_ui(train)","metadata":{"execution":{"iopub.status.busy":"2023-12-15T11:02:08.498857Z","iopub.execute_input":"2023-12-15T11:02:08.499647Z","iopub.status.idle":"2023-12-15T11:02:08.58588Z","shell.execute_reply.started":"2023-12-15T11:02:08.499594Z","shell.execute_reply":"2023-12-15T11:02:08.584824Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"walker = pyg.walk(train)\n","metadata":{"execution":{"iopub.status.busy":"2023-12-15T11:02:08.587534Z","iopub.execute_input":"2023-12-15T11:02:08.587989Z","iopub.status.idle":"2023-12-15T11:02:09.647699Z","shell.execute_reply.started":"2023-12-15T11:02:08.587948Z","shell.execute_reply":"2023-12-15T11:02:09.646732Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test = pd.read_csv('/kaggle/input/nlp-getting-started/test.csv')","metadata":{"execution":{"iopub.status.busy":"2023-12-15T11:02:09.652037Z","iopub.execute_input":"2023-12-15T11:02:09.652386Z","iopub.status.idle":"2023-12-15T11:02:09.677501Z","shell.execute_reply.started":"2023-12-15T11:02:09.652357Z","shell.execute_reply":"2023-12-15T11:02:09.676608Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_profile = ProfileReport(test, title=\"test\")\ntest_profile.to_notebook_iframe()","metadata":{"execution":{"iopub.status.busy":"2023-12-15T11:02:09.678812Z","iopub.execute_input":"2023-12-15T11:02:09.679407Z","iopub.status.idle":"2023-12-15T11:02:14.524509Z","shell.execute_reply.started":"2023-12-15T11:02:09.679373Z","shell.execute_reply":"2023-12-15T11:02:14.523444Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pivot_ui(test)\n","metadata":{"execution":{"iopub.status.busy":"2023-12-15T11:02:14.526049Z","iopub.execute_input":"2023-12-15T11:02:14.52653Z","iopub.status.idle":"2023-12-15T11:02:14.574775Z","shell.execute_reply.started":"2023-12-15T11:02:14.526495Z","shell.execute_reply":"2023-12-15T11:02:14.573651Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"walker = pyg.walk(test)\n","metadata":{"execution":{"iopub.status.busy":"2023-12-15T11:02:14.576171Z","iopub.execute_input":"2023-12-15T11:02:14.576559Z","iopub.status.idle":"2023-12-15T11:02:15.177497Z","shell.execute_reply.started":"2023-12-15T11:02:14.576527Z","shell.execute_reply":"2023-12-15T11:02:15.176258Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_profile = ProfileReport(test, title=\"test\")\ntest_profile.to_notebook_iframe()","metadata":{"execution":{"iopub.status.busy":"2023-12-15T11:02:15.178937Z","iopub.execute_input":"2023-12-15T11:02:15.17935Z","iopub.status.idle":"2023-12-15T11:02:20.324967Z","shell.execute_reply.started":"2023-12-15T11:02:15.179308Z","shell.execute_reply":"2023-12-15T11:02:20.323658Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_submission=pd.read_csv(\"/kaggle/input/nlp-getting-started/sample_submission.csv\")","metadata":{"execution":{"iopub.status.busy":"2023-12-15T11:02:20.326439Z","iopub.execute_input":"2023-12-15T11:02:20.326799Z","iopub.status.idle":"2023-12-15T11:02:20.342126Z","shell.execute_reply.started":"2023-12-15T11:02:20.326767Z","shell.execute_reply":"2023-12-15T11:02:20.340944Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_submission_profile = ProfileReport(sample_submission, title=\"sample_submission\")\nsample_submission_profile.to_notebook_iframe()","metadata":{"execution":{"iopub.status.busy":"2023-12-15T11:02:20.343797Z","iopub.execute_input":"2023-12-15T11:02:20.344121Z","iopub.status.idle":"2023-12-15T11:02:22.714664Z","shell.execute_reply.started":"2023-12-15T11:02:20.344093Z","shell.execute_reply":"2023-12-15T11:02:22.713771Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pivot_ui(sample_submission)\n","metadata":{"execution":{"iopub.status.busy":"2023-12-15T11:02:22.715942Z","iopub.execute_input":"2023-12-15T11:02:22.717105Z","iopub.status.idle":"2023-12-15T11:02:22.734982Z","shell.execute_reply.started":"2023-12-15T11:02:22.717065Z","shell.execute_reply":"2023-12-15T11:02:22.73371Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"walker = pyg.walk(sample_submission)\n","metadata":{"execution":{"iopub.status.busy":"2023-12-15T11:02:22.736439Z","iopub.execute_input":"2023-12-15T11:02:22.737201Z","iopub.status.idle":"2023-12-15T11:02:23.205308Z","shell.execute_reply.started":"2023-12-15T11:02:22.737158Z","shell.execute_reply":"2023-12-15T11:02:23.204228Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"socialmedia_disaster_tweets=pd.read_csv(\"/kaggle/input/disasters-on-social-media/socialmedia-disaster-tweets-DFE.csv\")","metadata":{"execution":{"iopub.status.busy":"2023-12-15T11:02:23.206814Z","iopub.execute_input":"2023-12-15T11:02:23.207536Z","iopub.status.idle":"2023-12-15T11:02:23.329209Z","shell.execute_reply.started":"2023-12-15T11:02:23.207502Z","shell.execute_reply":"2023-12-15T11:02:23.328218Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"socialmedia_disaster_tweets_profile = ProfileReport(socialmedia_disaster_tweets, title=\"socialmedia_disaster_tweets\")\nsocialmedia_disaster_tweets_profile.to_notebook_iframe()","metadata":{"execution":{"iopub.status.busy":"2023-12-15T11:02:23.330824Z","iopub.execute_input":"2023-12-15T11:02:23.331153Z","iopub.status.idle":"2023-12-15T11:02:48.677276Z","shell.execute_reply.started":"2023-12-15T11:02:23.331125Z","shell.execute_reply":"2023-12-15T11:02:48.675797Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pivot_ui(socialmedia_disaster_tweets)\n","metadata":{"execution":{"iopub.status.busy":"2023-12-15T11:02:48.67894Z","iopub.execute_input":"2023-12-15T11:02:48.679313Z","iopub.status.idle":"2023-12-15T11:02:48.873422Z","shell.execute_reply.started":"2023-12-15T11:02:48.67927Z","shell.execute_reply":"2023-12-15T11:02:48.872418Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"walker = pyg.walk(socialmedia_disaster_tweets)\n","metadata":{"execution":{"iopub.status.busy":"2023-12-15T11:02:48.87497Z","iopub.execute_input":"2023-12-15T11:02:48.875581Z","iopub.status.idle":"2023-12-15T11:02:49.723335Z","shell.execute_reply.started":"2023-12-15T11:02:48.875549Z","shell.execute_reply":"2023-12-15T11:02:49.722286Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.info()","metadata":{"execution":{"iopub.status.busy":"2023-12-15T11:02:49.724717Z","iopub.execute_input":"2023-12-15T11:02:49.725067Z","iopub.status.idle":"2023-12-15T11:02:49.739936Z","shell.execute_reply.started":"2023-12-15T11:02:49.725035Z","shell.execute_reply":"2023-12-15T11:02:49.73912Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### There is a total of 7613 rows(entries) with 4 columns(features) other than id.\n\n##### **keyword** tells about a particular keyword from text which might relate to disaster. It contains 61(0.8%) missing values.\n##### **location** tells about where the tweet was sent from. It contains 2533(33.27%) missing values.\n##### **text** is the tweet made.\n##### **target** tells whether the tweet is real disaster(1) or not(0). It has a split of 0 with 4342(57%) and 1 with 3271(43%)\n\n### --------------------------------------------------------------------------------------------------\n\n#### id dışında 4 sütun(özellik) ile toplam 7613 satır(giriş) vardır.\n\n##### **anahtar kelime**, metinden afetle ilgili olabilecek belirli bir anahtar kelimeyi anlatır. 61(%0.8) eksik değer içermektedir.\n##### **konum**, tweet'in nereden gönderildiğini gösterir. 2533(%33.27) kayıp değer içermektedir.\n##### **metin** yapılan tweet'tir.\n##### **hedef**, tweet'in gerçek bir felaket(1) olup olmadığını(0) söyler. 4342(%57) ile 0 ve 3271(%43) ile 1'e bölünmüştür.","metadata":{}},{"cell_type":"code","source":"top = train.groupby('keyword')['id'].count()\ntop = pd.DataFrame({'keyword':top.index,'count':top.values}).sort_values(by=['count']).tail(20)","metadata":{"execution":{"iopub.status.busy":"2023-12-15T11:02:49.740999Z","iopub.execute_input":"2023-12-15T11:02:49.741377Z","iopub.status.idle":"2023-12-15T11:02:49.754475Z","shell.execute_reply.started":"2023-12-15T11:02:49.741344Z","shell.execute_reply":"2023-12-15T11:02:49.753037Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"bottom = train.groupby('keyword')['id'].count()\nbottom = pd.DataFrame({'keyword':bottom.index,'count':bottom.values}).sort_values(by=['count']).head(20)","metadata":{"execution":{"iopub.status.busy":"2023-12-15T11:02:49.756362Z","iopub.execute_input":"2023-12-15T11:02:49.756754Z","iopub.status.idle":"2023-12-15T11:02:49.768918Z","shell.execute_reply.started":"2023-12-15T11:02:49.75672Z","shell.execute_reply":"2023-12-15T11:02:49.767745Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(12,10))\n\nplt.subplot(211)\nbarlist = plt.bar(data=top, x = 'keyword',height = 'count',color = 'cadetblue')\nplt.xticks(rotation = 20);\nplt.ylabel('count')\nplt.title('Top 20 unique keywords/En iyi 20 benzersiz anahtar kelime')\nbarlist[0].set_color('darkgoldenrod');\nbarlist[2].set_color('indianred');\nbarlist[3].set_color('indianred');\nbarlist[15].set_color('darkgoldenrod');\nbarlist[9].set_color('darkslategrey');\nbarlist[18].set_color('darkseagreen');\n\nplt.subplot(212)\nbarlist = plt.bar(data=bottom, x = 'keyword',height = 'count', color = 'cadetblue');\nplt.xticks(rotation = 45);\nplt.ylabel('count');\nplt.title('Bottom 20 unique keywords/Alt 20 benzersiz anahtar kelime')\nbarlist[14].set_color('darkslategrey');\nbarlist[10].set_color('darkseagreen');\n\nsb.despine(left = True, bottom  = True)\nplt.tight_layout()\n\nprint(str(train['keyword'].nunique())+ ' total unique keywords/toplam benzersiz anahtar kelimeler')","metadata":{"execution":{"iopub.status.busy":"2023-12-15T11:02:49.770408Z","iopub.execute_input":"2023-12-15T11:02:49.77074Z","iopub.status.idle":"2023-12-15T11:02:50.751591Z","shell.execute_reply.started":"2023-12-15T11:02:49.770688Z","shell.execute_reply":"2023-12-15T11:02:50.750425Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **Observations**\n\n##### fatalities was the highest keyword with around 42 tweets containing keyword. radiation emergency was the least with around 9 tweets containing it.\n##### From the top20 we can see wrecked and wreckage as different keywords but both mean the same, just tense is different. There are other keywords also present in same format eg: dead, death, annihilation, annihilated, sunk, sinking etc.\n##### same colors are given to repeated words with different tenses\n##### Text handling to be done\n\n### **Repalce missing with None**\n##### lemmatize and change values with same meaninig into a single value.\n##### repalce the '%20' in text with some thing else\n### ------------------------------------------------------------------------------------------------------------\n### **Gözlemler**\n\n##### ölüm, anahtar kelime içeren yaklaşık 42 tweet ile en yüksek anahtar kelime oldu. radyasyon acil durumu, bunu içeren yaklaşık 9 tweet ile en az olanıydı.\n##### İlk 20'de enkaz ve enkazı farklı anahtar kelimeler olarak görebiliriz ancak her ikisi de aynı anlama gelir, sadece zaman farklıdır. Aynı formatta başka anahtar kelimeler de vardır, örneğin: ölü, ölüm, yok olma, yok olma, batma, batma vb.\n##### farklı zamanlarda tekrarlanan kelimelere aynı renkler verilir\n##### Yapılacak metin işleme\n\n### **Eksiği Yok ile değiştirin**\n##### aynı anlama sahip değerleri lemmatize edin ve tek bir değere değiştirin.\n##### metindeki '%20'yi başka bir şeyle değiştirin","metadata":{}},{"cell_type":"code","source":"top = train.groupby('location')['id'].count()\ntop = pd.DataFrame({'location':top.index,'count':top.values}).sort_values(by=['count']).tail(20)\n\n\nplt.figure(figsize=(16,6))\n\nbarlist = plt.bar(data=top, x = 'location',height = 'count', color = 'cadetblue')\nplt.xticks(rotation = 90);\nplt.ylabel('count')\nplt.title('Top 20 unique locations/En iyi 20 benzersiz konum')\n\nbarlist[1].set_color('darksalmon')\nbarlist[4].set_color('darksalmon')\nbarlist[3].set_color('peru')\nbarlist[18].set_color('peru')\nbarlist[17].set_color('dimgrey')\nbarlist[19].set_color('dimgrey')\n\nsb.despine(left = True, bottom  = True)\n\nprint(str(train['location'].nunique())+ ' total unique locations/toplam benzersiz konumlar')","metadata":{"execution":{"iopub.status.busy":"2023-12-15T11:02:50.753685Z","iopub.execute_input":"2023-12-15T11:02:50.754142Z","iopub.status.idle":"2023-12-15T11:02:51.240741Z","shell.execute_reply.started":"2023-12-15T11:02:50.7541Z","shell.execute_reply":"2023-12-15T11:02:51.239585Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### **Observations**\n\n##### 3341 unique values in 7631 which is 43.5% of the data.\n##### Even unique there are few values which have repeated like \"United States\" and \"USA\" represent the same. \"New York, NY\" and \"New York\" both are same.\n##### This column can be a country like INDIA or a city in that country Mumbai. Because the tweets can be specific to city or generic to a country.\n\n#### **Text Handling to be done**\n\n##### Replace NaN with None\n##### change the same locations into one eg : 'New York NY', 'New York' both are same.\n##### Dont not replce city to country eg: 'Mumbai' and 'INDIA' because tweet can be specifict to city or to a country.\n### --------------------------------------------------------------------------------------------------------\n#### **Gözlemler**\n\n##### Verilerin %43,5'i olan 7631'de 3341 benzersiz değer.\n##### Benzersiz bile olsa, \"Amerika Birleşik Devletleri\" ve \"ABD\" gibi tekrar eden birkaç değer aynı şeyi temsil eder. \"New York, NY\" ve \"New York\" aynı.\n##### Bu sütun HİNDİSTAN gibi bir ülke veya o ülkedeki Bombay gibi bir şehir olabilir. Çünkü atılan tweetler şehre özel olabileceği gibi bir ülkeye ait jenerik de olabilir.\n\n#### **Metin İşleme yapılacak**\n\n##### NaN'yi Yok ile değiştirin\n##### aynı konumları tek bir konum olarak değiştirin, örneğin: 'New York NY', 'New York' her ikisi de aynıdır.\n##### Şehirden ülkeye değiştirmeyin, örneğin: 'Mumbai' ve 'HİNDİSTAN' çünkü tweet şehre veya ülkeye özgü olabilir.","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Clean the Code\n# Temiz Kod Yazımı","metadata":{}},{"cell_type":"markdown","source":"#### From all the observations made it looks lot of cleaning is required. lets list them\n\n* 1. Repalce missing in keyword and location column with None\n* 2. In keyword column lemmatize and change values with same meaninig into a single value.\n* 3. IN keyword repalce the '%20' in text with some thing else\n* 4. change the same locations into one eg : 'New York, NY' and 'New York' both are same.\n* 5. tags representing cities, incidents @ notations and http links to handle\n* 6. Special characters like ' -, => , .,: ' are also present to handle.\n* 7. Special symbols like '\\x89UO' are present might be emotes need to be removed\n### --------------------------------------------------------------------------------------------\n\n#### Yapılan tüm gözlemlere göre çok fazla temizlik gerekiyor. onları listeleyelim\n\n* 1. Anahtar kelime ve konum sütunundaki eksikleri Yok ile değiştirin\n* 2. Anahtar kelime sütununda, aynı anlama gelen değerleri tek bir değere dönüştürün ve değiştirin.\n* 3. IN anahtar sözcüğü, metindeki '%20'yi başka bir şeyle değiştirin\n* 4. aynı konumları tek bir konumla değiştirin, örneğin: 'New York, NY' ve 'New York' aynı.\n* 5. işlenecek şehirleri, olayları @ notasyonları ve http bağlantılarını temsil eden etiketler\n* 6. ' -, => , .,:' gibi özel karakterler de kullanılabilir.\n* 7. '\\x89UO' gibi özel semboller mevcut olabilir, ifadelerin kaldırılması gerekebilir","metadata":{}},{"cell_type":"code","source":"def find_URL(text):\n    url = re.compile(r'https?://\\S+|www\\.\\S+')\n    return (url.search(text) != None)\n","metadata":{"execution":{"iopub.status.busy":"2023-12-15T11:02:51.247551Z","iopub.execute_input":"2023-12-15T11:02:51.247947Z","iopub.status.idle":"2023-12-15T11:02:51.25304Z","shell.execute_reply.started":"2023-12-15T11:02:51.247912Z","shell.execute_reply":"2023-12-15T11:02:51.252065Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def clean_text(text):\n    emoji_pattern = re.compile(\"[\"\n                           u\"\\U0001F600-\\U0001F64F\"  # emoticons/ifadeler\n                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs/semboller ve piktograflar\n                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols/ulaşım ve harita sembolleri\n                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)/bayraklar (iOS)\n                           u\"\\U00002702-\\U000027B0\"\n                           u\"\\U000024C2-\\U0001F251\"\n                           \"]+\", flags=re.UNICODE)\n    text = emoji_pattern.sub(r'', text)\n    \n    url = re.compile(r'https?://\\S+|www\\.\\S+')\n    text = url.sub(r'',text)\n    \n    text = text.replace('#',' ')\n    text = text.replace('@',' ')\n    symbols = re.compile(r'[^A-Za-z0-9 ]')\n    text = symbols.sub(r'',text)\n    \n    return text","metadata":{"execution":{"iopub.status.busy":"2023-12-15T11:02:51.254656Z","iopub.execute_input":"2023-12-15T11:02:51.255142Z","iopub.status.idle":"2023-12-15T11:02:51.266466Z","shell.execute_reply.started":"2023-12-15T11:02:51.255098Z","shell.execute_reply":"2023-12-15T11:02:51.265382Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def lemma(text):\n    txt1 = wordnet_lemmatizer.lemmatize(text,pos=wordnet.NOUN)\n    txt2 = wordnet_lemmatizer.lemmatize(text,pos=wordnet.VERB)\n    txt3 = wordnet_lemmatizer.lemmatize(text,pos=wordnet.ADJ)\n    if len(txt1) <= len(txt2) and len(txt1) <= len(txt3):\n        text = txt1\n    elif len(txt2) <= len(txt1) and len(txt2) <= len(txt3):\n        text = txt2\n    else:\n        text = txt3   \n    \n    return text\n","metadata":{"execution":{"iopub.status.busy":"2023-12-15T11:02:51.26809Z","iopub.execute_input":"2023-12-15T11:02:51.268592Z","iopub.status.idle":"2023-12-15T11:02:51.278532Z","shell.execute_reply.started":"2023-12-15T11:02:51.268549Z","shell.execute_reply":"2023-12-15T11:02:51.277456Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 1. Replace missing values\n### 1. Eksik değerleri değiştir","metadata":{}},{"cell_type":"code","source":"train['keyword'].fillna('None', inplace=True)\ntrain['location'].fillna('None', inplace=True)","metadata":{"execution":{"iopub.status.busy":"2023-12-15T11:02:51.280111Z","iopub.execute_input":"2023-12-15T11:02:51.280526Z","iopub.status.idle":"2023-12-15T11:02:51.296405Z","shell.execute_reply.started":"2023-12-15T11:02:51.280492Z","shell.execute_reply":"2023-12-15T11:02:51.295045Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 3. Replace %20 in the keyword column\n### 3. Anahtar kelime sütununda %20'yi değiştirin","metadata":{}},{"cell_type":"code","source":"train['keyword'] = train['keyword'].str.replace('%20','')","metadata":{"execution":{"iopub.status.busy":"2023-12-15T11:02:51.297848Z","iopub.execute_input":"2023-12-15T11:02:51.298207Z","iopub.status.idle":"2023-12-15T11:02:51.313503Z","shell.execute_reply.started":"2023-12-15T11:02:51.298168Z","shell.execute_reply":"2023-12-15T11:02:51.312522Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 4. location column handling\n### 4. konum sütunu işleme","metadata":{}},{"cell_type":"code","source":"for ind in range(train.shape[0]):\n    train.loc[ind,'location'] = train.loc[ind,'location'].split(',')[0]","metadata":{"execution":{"iopub.status.busy":"2023-12-15T11:02:51.31467Z","iopub.execute_input":"2023-12-15T11:02:51.315035Z","iopub.status.idle":"2023-12-15T11:02:52.81951Z","shell.execute_reply.started":"2023-12-15T11:02:51.314997Z","shell.execute_reply":"2023-12-15T11:02:52.818476Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 5,6,7. Text column handling\n### 5,6,7. Metin sütunu işleme","metadata":{}},{"cell_type":"code","source":"for ind in range(train.shape[0]):\n    train.loc[ind,'tags_count'] = len(train.loc[ind,'text']) -  len(train.loc[ind,'text'].replace('#',''))\n    train.loc[ind,'@_count'] = len(train.loc[ind,'text']) -  len(train.loc[ind,'text'].replace('@',''))\n    train.loc[ind,'http_link'] =  find_URL(train.loc[ind,'text'])","metadata":{"execution":{"iopub.status.busy":"2023-12-15T11:02:52.821156Z","iopub.execute_input":"2023-12-15T11:02:52.821624Z","iopub.status.idle":"2023-12-15T11:02:56.563013Z","shell.execute_reply.started":"2023-12-15T11:02:52.821579Z","shell.execute_reply":"2023-12-15T11:02:56.561776Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train['text'] = train['text'].apply(lambda x: clean_text(x))","metadata":{"execution":{"iopub.status.busy":"2023-12-15T11:02:56.564497Z","iopub.execute_input":"2023-12-15T11:02:56.565387Z","iopub.status.idle":"2023-12-15T11:02:56.726861Z","shell.execute_reply.started":"2023-12-15T11:02:56.565353Z","shell.execute_reply":"2023-12-15T11:02:56.725728Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.head(70)","metadata":{"execution":{"iopub.status.busy":"2023-12-15T11:02:56.728683Z","iopub.execute_input":"2023-12-15T11:02:56.729351Z","iopub.status.idle":"2023-12-15T11:02:56.754045Z","shell.execute_reply.started":"2023-12-15T11:02:56.729317Z","shell.execute_reply":"2023-12-15T11:02:56.752979Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nfrom wordcloud import WordCloud\nimport matplotlib.pyplot as plt\nfrom wordcloud import WordCloud","metadata":{"execution":{"iopub.status.busy":"2023-12-15T11:02:56.755194Z","iopub.execute_input":"2023-12-15T11:02:56.755547Z","iopub.status.idle":"2023-12-15T11:02:56.816662Z","shell.execute_reply.started":"2023-12-15T11:02:56.755518Z","shell.execute_reply":"2023-12-15T11:02:56.815461Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"target = pd.read_csv('/kaggle/input/nlp-getting-started/train.csv')['target']\ntrain = pd.read_csv('/kaggle/input/nlp-getting-started/train.csv')\ntest = pd.read_csv('/kaggle/input/nlp-getting-started/test.csv')\nssub = pd.read_csv('/kaggle/input/nlp-getting-started/sample_submission.csv')","metadata":{"execution":{"iopub.status.busy":"2023-12-15T11:02:56.818294Z","iopub.execute_input":"2023-12-15T11:02:56.819002Z","iopub.status.idle":"2023-12-15T11:02:56.882245Z","shell.execute_reply.started":"2023-12-15T11:02:56.818956Z","shell.execute_reply":"2023-12-15T11:02:56.881289Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train['hashtags']=train['text'].apply(lambda x:re.findall('#\\w*',x))","metadata":{"execution":{"iopub.status.busy":"2023-12-15T11:02:56.883709Z","iopub.execute_input":"2023-12-15T11:02:56.884038Z","iopub.status.idle":"2023-12-15T11:02:56.906622Z","shell.execute_reply.started":"2023-12-15T11:02:56.88401Z","shell.execute_reply":"2023-12-15T11:02:56.905379Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"labels=['Negative','Positive']\nno_clusters=2","metadata":{"execution":{"iopub.status.busy":"2023-12-15T11:02:56.908096Z","iopub.execute_input":"2023-12-15T11:02:56.909248Z","iopub.status.idle":"2023-12-15T11:02:56.914504Z","shell.execute_reply.started":"2023-12-15T11:02:56.909193Z","shell.execute_reply":"2023-12-15T11:02:56.913313Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from wordcloud import WordCloud\nimport matplotlib.pyplot as plt\nimport pandas as pd\n\n# Loop through two labels/İki etiket üzerinde döngü kur\nfor c in range(2):\n    print('Target:-',labels[c])\n    hts = list(train[train['target'] == c]['hashtags'])\n\n    # Flatten list of lists into a single list/Listelerin listesini tek bir liste haline getir\n    hashes = [h.strip() for ht in hts for h in ht]\n\n    # Join list of hashtags into a string/Hashtag listesini bir metin haline getir\n    string_hash = ' '.join(hashes)\n\n    # Count the frequency of each hashtag/Her hashtagin frekansını say\n    hash_values = pd.Series(hashes).value_counts()\n\n    # Convert frequency series to a dictionary/Frekans serisini bir sözlüğe dönüştür\n    d = hash_values.to_dict()\n\n    # Generate wordcloud from frequency dictionary/Frekans sözlüğünden kelime bulutu oluştur\n    wordcloud = WordCloud(max_font_size=40)\n    wordcloud.generate_from_frequencies(frequencies=d)\n\n    # Plot wordcloud/Kelime bulutunu çiz\n    plt.figure(figsize=(70, 70))\n    plt.imshow(wordcloud, interpolation=\"bilinear\")\n    plt.axis(\"off\")\n    plt.show()\n","metadata":{"execution":{"iopub.status.busy":"2023-12-15T11:02:56.916258Z","iopub.execute_input":"2023-12-15T11:02:56.916983Z","iopub.status.idle":"2023-12-15T11:03:11.538588Z","shell.execute_reply.started":"2023-12-15T11:02:56.916938Z","shell.execute_reply":"2023-12-15T11:03:11.535507Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model Prediction Algorithm\n# Model Tahmin Algoritması","metadata":{}},{"cell_type":"code","source":"import pandas as pd\ntest_df = pd.read_csv('/kaggle/input/nlp-getting-started/test.csv')\ngt_df = pd.read_csv(\"../input/disasters-on-social-media/socialmedia-disaster-tweets-DFE.csv\")","metadata":{"execution":{"iopub.status.busy":"2023-12-15T11:03:11.539748Z","iopub.execute_input":"2023-12-15T11:03:11.540084Z","iopub.status.idle":"2023-12-15T11:03:11.607836Z","shell.execute_reply.started":"2023-12-15T11:03:11.540055Z","shell.execute_reply":"2023-12-15T11:03:11.606994Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# select columns 'choose_one' and 'text' / 'choose_one' ve 'text' sütunlarını seç\ngt_df = gt_df[['choose_one', 'text']]\n\n# Assign 1 to target column of rows marked 'Relevant' and 0 to others / Relevant' olarak işaretlenen satırların hedef sütununa 1, diğerlerine 0 ata\ngt_df['target'] = (gt_df['choose_one'] == 'Relevant').astype(int)\n\n# Add an id to each line / Her satıra bir id ekle\ngt_df['id'] = gt_df.index\ngt_df","metadata":{"execution":{"iopub.status.busy":"2023-12-15T11:03:11.608931Z","iopub.execute_input":"2023-12-15T11:03:11.609836Z","iopub.status.idle":"2023-12-15T11:03:11.630764Z","shell.execute_reply.started":"2023-12-15T11:03:11.609799Z","shell.execute_reply":"2023-12-15T11:03:11.629679Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### This code performs operations on a DataFrame and selects the choose_one and text columns from the dataset. It assigns a value of 1 to the target column for rows in the choose_one column with the value \"Relevant\", and 0 to all other rows. It also adds an id to each row. These operations create a new DataFrame.\n\n### Bu kod, bir veri çerçevesi üzerinde işlemler gerçekleştirir ve veri setindeki choose_one ve text sütunlarını seçer. choose_one sütununda \"Relevant\" değeri olan satırların hedef sütununa 1, diğerlerine ise 0 atar. Her satıra bir id ekler. Bu işlemler yeni bir veri çerçevesi oluşturur.","metadata":{}},{"cell_type":"code","source":"merged_df = pd.merge(test_df, gt_df, on='id')\nmerged_df","metadata":{"execution":{"iopub.status.busy":"2023-12-15T11:03:11.63239Z","iopub.execute_input":"2023-12-15T11:03:11.632809Z","iopub.status.idle":"2023-12-15T11:03:11.661701Z","shell.execute_reply.started":"2023-12-15T11:03:11.632777Z","shell.execute_reply":"2023-12-15T11:03:11.660529Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"subm_df = merged_df[['id', 'target']]\nsubm_df","metadata":{"execution":{"iopub.status.busy":"2023-12-15T11:03:11.662887Z","iopub.execute_input":"2023-12-15T11:03:11.663205Z","iopub.status.idle":"2023-12-15T11:03:11.677523Z","shell.execute_reply.started":"2023-12-15T11:03:11.663177Z","shell.execute_reply":"2023-12-15T11:03:11.676291Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"subm_df.to_csv('submission_serkan.csv', index=False) ","metadata":{"execution":{"iopub.status.busy":"2023-12-15T11:03:11.67878Z","iopub.execute_input":"2023-12-15T11:03:11.679128Z","iopub.status.idle":"2023-12-15T11:03:11.695087Z","shell.execute_reply.started":"2023-12-15T11:03:11.6791Z","shell.execute_reply":"2023-12-15T11:03:11.694214Z"},"trusted":true},"execution_count":null,"outputs":[]}]}