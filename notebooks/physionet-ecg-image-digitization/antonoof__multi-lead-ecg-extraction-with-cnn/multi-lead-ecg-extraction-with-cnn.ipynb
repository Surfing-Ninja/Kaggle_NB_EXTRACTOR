{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":97984,"databundleVersionId":14096757,"sourceType":"competition"}],"dockerImageVersionId":31153,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<div style=\"\n    background: linear-gradient(135deg, #0c0c2e 0%, #1a1a4a 50%, #2d1a4a 100%);\n    border: 2px solid #6366f1;\n    border-radius: 15px;\n    padding: 20px;\n    margin: 15px 0;\n    box-shadow: 0 0 25px rgba(99, 102, 241, 0.3),\n                inset 0 0 15px rgba(255, 255, 255, 0.1);\n    color: #e2e8f0;\n    font-family: 'Segoe UI', system-ui, sans-serif;\n    position: relative;\n    overflow: hidden;\n\">\n\n<div style=\"\n    position: absolute;\n    bottom: -30px;\n    left: -30px;\n    width: 80px;\n    height: 80px;\n    background: radial-gradient(circle, rgba(168, 85, 247, 0.3) 0%, transparent 70%);\n    border-radius: 50%;\n\"></div>\n\n<h1 style=\"\n    color: #818cf8;\n    margin-top: 0;\n    text-align: center;\n    font-weight: 600;\n    text-shadow: 0 0 10px rgba(129, 140, 248, 0.5);\n    position: relative;\n    z-index: 1;\n\">\n    Import libraries\n</h1>","metadata":{}},{"cell_type":"code","source":"import os\nimport cv2\nimport torch\nimport numpy as np\nimport pandas as pd\nimport torch.nn as nn\n\nfrom tqdm import tqdm\nfrom scipy import signal\nfrom scipy.signal import medfilt\nfrom torch.utils.data import Dataset, DataLoader","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-01T00:26:55.238571Z","iopub.execute_input":"2025-11-01T00:26:55.239063Z","iopub.status.idle":"2025-11-01T00:27:02.956868Z","shell.execute_reply.started":"2025-11-01T00:26:55.23904Z","shell.execute_reply":"2025-11-01T00:27:02.956235Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<div style=\"\n    background: linear-gradient(135deg, #0c0c2e 0%, #1a1a4a 50%, #2d1a4a 100%);\n    border: 2px solid #6366f1;\n    border-radius: 15px;\n    padding: 20px;\n    margin: 15px 0;\n    box-shadow: 0 0 25px rgba(99, 102, 241, 0.3),\n                inset 0 0 15px rgba(255, 255, 255, 0.1);\n    color: #e2e8f0;\n    font-family: 'Segoe UI', system-ui, sans-serif;\n    position: relative;\n    overflow: hidden;\n\">\n\n<div style=\"\n    position: absolute;\n    bottom: -30px;\n    left: -30px;\n    width: 80px;\n    height: 80px;\n    background: radial-gradient(circle, rgba(168, 85, 247, 0.3) 0%, transparent 70%);\n    border-radius: 50%;\n\"></div>\n\n<h1 style=\"\n    color: #818cf8;\n    margin-top: 0;\n    text-align: center;\n    font-weight: 600;\n    text-shadow: 0 0 10px rgba(129, 140, 248, 0.5);\n    position: relative;\n    z-index: 1;\n\">\n    Config(u can change parameters)\n</h1>","metadata":{}},{"cell_type":"code","source":"class Config:\n    batch_size = 16\n    epochs = 1\n    lr = 1e-3\n    img_size = (512, 512)\n    target_length = 5000\n\nconfig = Config()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-01T00:27:02.95789Z","iopub.execute_input":"2025-11-01T00:27:02.958208Z","iopub.status.idle":"2025-11-01T00:27:02.962705Z","shell.execute_reply.started":"2025-11-01T00:27:02.95819Z","shell.execute_reply":"2025-11-01T00:27:02.961965Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<div style=\"\n    background: linear-gradient(135deg, #0c0c2e 0%, #1a1a4a 50%, #2d1a4a 100%);\n    border: 2px solid #6366f1;\n    border-radius: 15px;\n    padding: 20px;\n    margin: 15px 0;\n    box-shadow: 0 0 25px rgba(99, 102, 241, 0.3),\n                inset 0 0 15px rgba(255, 255, 255, 0.1);\n    color: #e2e8f0;\n    font-family: 'Segoe UI', system-ui, sans-serif;\n    position: relative;\n    overflow: hidden;\n\">\n\n<div style=\"\n    position: absolute;\n    bottom: -30px;\n    left: -30px;\n    width: 80px;\n    height: 80px;\n    background: radial-gradient(circle, rgba(168, 85, 247, 0.3) 0%, transparent 70%);\n    border-radius: 50%;\n\"></div>\n\n<h1 style=\"\n    color: #818cf8;\n    margin-top: 0;\n    text-align: center;\n    font-weight: 600;\n    text-shadow: 0 0 10px rgba(129, 140, 248, 0.5);\n    position: relative;\n    z-index: 1;\n\">\n    ECG image processor: preprocessing + extraction of 12-lead signals\n</h1>","metadata":{}},{"cell_type":"code","source":"class ECGProcessor:\n    \n    def __init__(self):\n        self.lead_regions = {\n            'I': (0.1, 0.15), 'II': (0.1, 0.3), 'III': (0.1, 0.45),\n            'aVR': (0.1, 0.6), 'aVL': (0.1, 0.75), 'aVF': (0.1, 0.9),\n            'V1': (0.55, 0.15), 'V2': (0.55, 0.3), 'V3': (0.55, 0.45),\n            'V4': (0.55, 0.6), 'V5': (0.55, 0.75), 'V6': (0.55, 0.9)\n        }\n    \n    def adaptive_threshold(self, image):\n        if len(image.shape) == 3:\n            gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n        else:\n            gray = image\n            \n        mean_brightness = np.mean(gray)\n        if mean_brightness > 200:\n            return 170\n        elif mean_brightness < 150:\n            return 150\n        else:\n            return 160\n    \n    def preprocess_image(self, image):\n        if len(image.shape) == 3:\n            gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n        else:\n            gray = image\n        \n        threshold = self.adaptive_threshold(gray)\n        _, binary = cv2.threshold(gray, threshold, 255, cv2.THRESH_BINARY)\n        \n        kernel = np.ones((2, 2), np.uint8)\n        cleaned = cv2.morphologyEx(binary, cv2.MORPH_OPEN, kernel)\n        \n        return cleaned\n    \n    def extract_signal_trace(self, binary_image, lead_name):\n        try:\n            h, w = binary_image.shape\n            x_ratio, y_ratio = self.lead_regions[lead_name]\n            \n            roi_width = int(w * 0.35)\n            roi_height = int(h * 0.06)\n            roi_x = int(w * x_ratio - roi_width // 2)\n            roi_y = int(h * y_ratio - roi_height // 2)\n            \n            roi_x = max(0, roi_x)\n            roi_y = max(0, roi_y)\n            roi_width = min(roi_width, w - roi_x)\n            roi_height = min(roi_height, h - roi_y)\n            \n            roi = binary_image[roi_y:roi_y+roi_height, roi_x:roi_x+roi_width]\n            \n            if roi.size == 0:\n                return np.zeros(config.target_length)\n            \n            signal_positions = []\n            for col in range(roi.shape[1]):\n                column = roi[:, col]\n                dark_indices = np.where(column < 128)[0]\n                \n                if len(dark_indices) > 0:\n                    weights = 255 - column[dark_indices]\n                    weighted_pos = np.average(dark_indices, weights=weights)\n                    signal_positions.append(weighted_pos)\n                else:\n                    signal_positions.append(roi_height / 2)\n            \n            signal = np.array(signal_positions)\n            \n            signal = roi_height - signal\n            signal = (signal - np.mean(signal)) / (np.std(signal) + 1e-8)\n            \n            if len(signal) > 1:\n                signal = signal.resample(signal, config.target_length)\n            \n            signal = medfilt(signal, kernel_size=3)\n            \n            return signal.astype(np.float32)\n            \n        except Exception as e:\n            print(f\"Error extracting {lead_name}: {e}\")\n            return np.zeros(config.target_length)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-11-01T00:27:02.963539Z","iopub.execute_input":"2025-11-01T00:27:02.964108Z","iopub.status.idle":"2025-11-01T00:27:02.981007Z","shell.execute_reply.started":"2025-11-01T00:27:02.964082Z","shell.execute_reply":"2025-11-01T00:27:02.980427Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<div style=\"\n    background: linear-gradient(135deg, #0c0c2e 0%, #1a1a4a 50%, #2d1a4a 100%);\n    border: 2px solid #6366f1;\n    border-radius: 15px;\n    padding: 20px;\n    margin: 15px 0;\n    box-shadow: 0 0 25px rgba(99, 102, 241, 0.3),\n                inset 0 0 15px rgba(255, 255, 255, 0.1);\n    color: #e2e8f0;\n    font-family: 'Segoe UI', system-ui, sans-serif;\n    position: relative;\n    overflow: hidden;\n\">\n\n<div style=\"\n    position: absolute;\n    bottom: -30px;\n    left: -30px;\n    width: 80px;\n    height: 80px;\n    background: radial-gradient(circle, rgba(168, 85, 247, 0.3) 0%, transparent 70%);\n    border-radius: 50%;\n\"></div>\n\n<h1 style=\"\n    color: #818cf8;\n    margin-top: 0;\n    text-align: center;\n    font-weight: 600;\n    text-shadow: 0 0 10px rgba(129, 140, 248, 0.5);\n    position: relative;\n    z-index: 1;\n\">\n    Electrocardiography Dataset\n</h1>","metadata":{}},{"cell_type":"code","source":"class ECGDataset(Dataset):\n    \n    def __init__(self, df, image_dir, is_train=True):\n        self.df = df\n        self.image_dir = image_dir\n        self.is_train = is_train\n        self.processor = ECGProcessor()\n        \n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self, idx):\n        row = self.df.iloc[idx]\n        base_id = row['id']\n        \n        if self.is_train:\n            img_folder = os.path.join(self.image_dir, str(base_id))\n            img_files = [f for f in os.listdir(img_folder) if f.endswith('.png')]\n            img_path = os.path.join(img_folder, img_files[0]) if img_files else None\n        else:\n            img_path = os.path.join(self.image_dir, f\"{base_id}.png\")\n        \n        image = cv2.imread(img_path) if img_path else None\n        if image is None:\n            image = np.ones((1240, 1024, 3), dtype=np.uint8) * 255\n        \n        image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        image_resized = cv2.resize(image_rgb, config.img_size)\n        image_tensor = torch.from_numpy(image_resized.transpose(2, 0, 1)).float() / 255.0\n        \n        if self.is_train:\n            try:\n                csv_path = os.path.join(self.image_dir, str(base_id), f\"{base_id}.csv\")\n                signals_df = pd.read_csv(csv_path)\n                target_signal = signals_df['II'].values.astype(np.float32)\n                \n                if len(target_signal) != config.target_length:\n                    target_signal = signal.resample(target_signal, config.target_length)\n                \n                target_signal = (target_signal - np.mean(target_signal)) / (np.std(target_signal) + 1e-8)\n                \n            except:\n                t = np.linspace(0, 10, config.target_length)\n                target_signal = (np.sin(2 * np.pi * 1 * t) + \n                               0.3 * np.sin(2 * np.pi * 2 * t))\n                target_signal = target_signal.astype(np.float32)\n            \n            return image_tensor, torch.FloatTensor(target_signal), base_id\n        else:\n            return image_tensor, base_id","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-01T00:27:02.982443Z","iopub.execute_input":"2025-11-01T00:27:02.982679Z","iopub.status.idle":"2025-11-01T00:27:03.001302Z","shell.execute_reply.started":"2025-11-01T00:27:02.982663Z","shell.execute_reply":"2025-11-01T00:27:03.000708Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<div style=\"\n    background: linear-gradient(135deg, #0c0c2e 0%, #1a1a4a 50%, #2d1a4a 100%);\n    border: 2px solid #6366f1;\n    border-radius: 15px;\n    padding: 20px;\n    margin: 15px 0;\n    box-shadow: 0 0 25px rgba(99, 102, 241, 0.3),\n                inset 0 0 15px rgba(255, 255, 255, 0.1);\n    color: #e2e8f0;\n    font-family: 'Segoe UI', system-ui, sans-serif;\n    position: relative;\n    overflow: hidden;\n\">\n\n<div style=\"\n    position: absolute;\n    bottom: -30px;\n    left: -30px;\n    width: 80px;\n    height: 80px;\n    background: radial-gradient(circle, rgba(168, 85, 247, 0.3) 0%, transparent 70%);\n    border-radius: 50%;\n\"></div>\n\n<h1 style=\"\n    color: #818cf8;\n    margin-top: 0;\n    text-align: center;\n    font-weight: 600;\n    text-shadow: 0 0 10px rgba(129, 140, 248, 0.5);\n    position: relative;\n    z-index: 1;\n\">\n    Model architecture: Image to Signal Regression\n</h1>","metadata":{}},{"cell_type":"code","source":"class ECGNet(nn.Module):\n    def __init__(self):\n        super().__init__()\n        \n        self.features = nn.Sequential(\n            nn.Conv2d(3, 32, 3, padding=1),\n            nn.BatchNorm2d(32),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(2),\n            \n            nn.Conv2d(32, 64, 3, padding=1),\n            nn.BatchNorm2d(64),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(2),\n            \n            nn.Conv2d(64, 128, 3, padding=1),\n            nn.BatchNorm2d(128),\n            nn.ReLU(inplace=True),\n            nn.AdaptiveAvgPool2d((8, 8))\n        )\n        \n        self.regressor = nn.Sequential(\n            nn.Linear(128 * 8 * 8, 512),\n            nn.ReLU(inplace=True),\n            nn.Dropout(0.3),\n            nn.Linear(512, 256),\n            nn.ReLU(inplace=True),\n            nn.Linear(256, config.target_length)\n        )\n        \n    def forward(self, x):\n        x = self.features(x)\n        x = x.view(x.size(0), -1)\n        x = self.regressor(x)\n        return x","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-01T00:27:03.002327Z","iopub.execute_input":"2025-11-01T00:27:03.002634Z","iopub.status.idle":"2025-11-01T00:27:03.023424Z","shell.execute_reply.started":"2025-11-01T00:27:03.002616Z","shell.execute_reply":"2025-11-01T00:27:03.022884Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<div style=\"\n    background: linear-gradient(135deg, #0c0c2e 0%, #1a1a4a 50%, #2d1a4a 100%);\n    border: 2px solid #6366f1;\n    border-radius: 15px;\n    padding: 20px;\n    margin: 15px 0;\n    box-shadow: 0 0 25px rgba(99, 102, 241, 0.3),\n                inset 0 0 15px rgba(255, 255, 255, 0.1);\n    color: #e2e8f0;\n    font-family: 'Segoe UI', system-ui, sans-serif;\n    position: relative;\n    overflow: hidden;\n\">\n\n<div style=\"\n    position: absolute;\n    bottom: -30px;\n    left: -30px;\n    width: 80px;\n    height: 80px;\n    background: radial-gradient(circle, rgba(168, 85, 247, 0.3) 0%, transparent 70%);\n    border-radius: 50%;\n\"></div>\n\n<h1 style=\"\n    color: #818cf8;\n    margin-top: 0;\n    text-align: center;\n    font-weight: 600;\n    text-shadow: 0 0 10px rgba(129, 140, 248, 0.5);\n    position: relative;\n    z-index: 1;\n\">\n    ECG Loss Function\n</h1>","metadata":{}},{"cell_type":"code","source":"class ECGLoss(nn.Module):\n    \n    def __init__(self):\n        super().__init__()\n        \n    def forward(self, pred, target):\n        mse_loss = nn.MSELoss()(pred, target)\n        \n        pred_diff = pred[:, 1:] - pred[:, :-1]\n        target_diff = target[:, 1:] - target[:, :-1]\n        smooth_loss = nn.MSELoss()(pred_diff, target_diff)\n        \n        return mse_loss + 0.1 * smooth_loss","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-01T00:27:03.024144Z","iopub.execute_input":"2025-11-01T00:27:03.02438Z","iopub.status.idle":"2025-11-01T00:27:03.043157Z","shell.execute_reply.started":"2025-11-01T00:27:03.024362Z","shell.execute_reply":"2025-11-01T00:27:03.042573Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<div style=\"\n    background: linear-gradient(135deg, #0c0c2e 0%, #1a1a4a 50%, #2d1a4a 100%);\n    border: 2px solid #6366f1;\n    border-radius: 15px;\n    padding: 20px;\n    margin: 15px 0;\n    box-shadow: 0 0 25px rgba(99, 102, 241, 0.3),\n                inset 0 0 15px rgba(255, 255, 255, 0.1);\n    color: #e2e8f0;\n    font-family: 'Segoe UI', system-ui, sans-serif;\n    position: relative;\n    overflow: hidden;\n\">\n\n<div style=\"\n    position: absolute;\n    bottom: -30px;\n    left: -30px;\n    width: 80px;\n    height: 80px;\n    background: radial-gradient(circle, rgba(168, 85, 247, 0.3) 0%, transparent 70%);\n    border-radius: 50%;\n\"></div>\n\n<h1 style=\"\n    color: #818cf8;\n    margin-top: 0;\n    text-align: center;\n    font-weight: 600;\n    text-shadow: 0 0 10px rgba(129, 140, 248, 0.5);\n    position: relative;\n    z-index: 1;\n\">\n    Model training\n</h1>","metadata":{}},{"cell_type":"code","source":"train_df = pd.read_csv('/kaggle/input/physionet-ecg-image-digitization/train.csv')\ntrain_df = train_df.head(800)\n\ntrain_dataset = ECGDataset(\n    train_df, \n    '/kaggle/input/physionet-ecg-image-digitization/train',\n    is_train=True\n)\n\ntrain_loader = DataLoader(\n    train_dataset, \n    batch_size=config.batch_size, \n    shuffle=True, \n    num_workers=2\n)\n    \ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel = ECGNet().to(device)\n\nif torch.cuda.device_count() > 1:\n    model = nn.DataParallel(model)\n    \ncriterion = ECGLoss()\noptimizer = torch.optim.AdamW(model.parameters(), lr=config.lr, weight_decay=1e-4)\nscheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=config.epochs)\n    \nbest_loss = float('inf')\nfor epoch in range(config.epochs):\n    model.train()\n    running_loss = 0.0\n    \n    pbar = tqdm(train_loader, desc=f'Epoch {epoch+1}/{config.epochs}')\n    for images, targets, _ in pbar:\n        images, targets = images.to(device), targets.to(device)\n            \n        optimizer.zero_grad()\n        outputs = model(images)\n        loss = criterion(outputs, targets)\n        loss.backward()\n            \n        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n        optimizer.step()\n            \n        running_loss += loss.item()\n        pbar.set_postfix({'Loss': f'{loss.item():.4f}'})\n        \n    epoch_loss = running_loss / len(train_loader)\n    scheduler.step()\n    \n    print(f'Epoch {epoch+1}, Loss: {epoch_loss:.4f}, LR: {scheduler.get_last_lr()[0]:.6f}')\n    \n    if epoch_loss < best_loss:\n        best_loss = epoch_loss\n        torch.save(model.state_dict(), 'ecg_model.pth')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-01T00:28:22.566485Z","iopub.execute_input":"2025-11-01T00:28:22.567031Z","iopub.status.idle":"2025-11-01T00:34:21.191426Z","shell.execute_reply.started":"2025-11-01T00:28:22.567008Z","shell.execute_reply":"2025-11-01T00:34:21.190677Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<div style=\"\n    background: linear-gradient(135deg, #0c0c2e 0%, #1a1a4a 50%, #2d1a4a 100%);\n    border: 2px solid #6366f1;\n    border-radius: 15px;\n    padding: 20px;\n    margin: 15px 0;\n    box-shadow: 0 0 25px rgba(99, 102, 241, 0.3),\n                inset 0 0 15px rgba(255, 255, 255, 0.1);\n    color: #e2e8f0;\n    font-family: 'Segoe UI', system-ui, sans-serif;\n    position: relative;\n    overflow: hidden;\n\">\n\n<div style=\"\n    position: absolute;\n    bottom: -30px;\n    left: -30px;\n    width: 80px;\n    height: 80px;\n    background: radial-gradient(circle, rgba(168, 85, 247, 0.3) 0%, transparent 70%);\n    border-radius: 50%;\n\"></div>\n\n<h1 style=\"\n    color: #818cf8;\n    margin-top: 0;\n    text-align: center;\n    font-weight: 600;\n    text-shadow: 0 0 10px rgba(129, 140, 248, 0.5);\n    position: relative;\n    z-index: 1;\n\">\n    Predict, create submission and check results\n</h1>","metadata":{}},{"cell_type":"code","source":"test_df = pd.read_csv('/kaggle/input/physionet-ecg-image-digitization/test.csv')\ntest_dataset = ECGDataset(test_df, '/kaggle/input/physionet-ecg-image-digitization/test', is_train=False)\ntest_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n\ndevice = next(model.parameters()).device\nmodel.eval()\n\nsubmission_data = []\n\nfor batch_idx, (images, base_ids) in enumerate(tqdm(test_loader, desc='Predicting')):\n    if batch_idx >= len(test_df):\n        break\n        \n    test_row = test_df.iloc[batch_idx]\n    base_id = test_row['id']\n    lead = test_row['lead']\n    num_rows = test_row['number_of_rows']\n    \n    images = images.to(device)\n    \n    with torch.no_grad():\n        prediction = model(images).cpu().numpy().flatten()\n    \n    if len(prediction) > num_rows:\n        prediction = prediction[:num_rows]\n    else:\n        prediction = np.pad(prediction, (0, num_rows - len(prediction)), mode='edge')\n        \n    prediction = medfilt(prediction, kernel_size=3)\n        \n    for row_id in range(num_rows):\n        composite_id = f\"{base_id}_{row_id}_{lead}\"\n        submission_data.append({\n            'id': composite_id,\n            'value': float(prediction[row_id])\n        })\n\nsubmission = pd.DataFrame(submission_data)\nsubmission.to_csv('submission.csv', index=False)\nsubmission.head(30)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-01T00:34:21.19318Z","iopub.execute_input":"2025-11-01T00:34:21.193869Z","iopub.status.idle":"2025-11-01T00:34:23.49416Z","shell.execute_reply.started":"2025-11-01T00:34:21.193846Z","shell.execute_reply":"2025-11-01T00:34:23.49349Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}