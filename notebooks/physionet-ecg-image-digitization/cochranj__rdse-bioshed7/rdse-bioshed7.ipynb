{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":97984,"databundleVersionId":14096757,"sourceType":"competition"}],"dockerImageVersionId":31153,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# =======================================================================\n# ECG Image Digitization — FULL CORRECTED CELL (process *all* images)\n# - New: CFG.SCOPE = \"all\" | \"test\" | \"train\"  (default \"all\")\n# - Scans the entire dataset root recursively for any image extensions\n# - Processes TRAIN + TEST + any stray folders when SCOPE=\"all\"\n# - Saves artifacts to /kaggle/working/out\n# - ALWAYS writes /kaggle/working/submission.csv\n# =======================================================================\nimport os, sys, glob, json, math, re, warnings\nfrom dataclasses import dataclass\nfrom typing import Dict, List, Tuple, Optional, Any\n\nimport numpy as np\nimport pandas as pd\nimport cv2\nimport matplotlib\nmatplotlib.use(\"Agg\")\nimport matplotlib.pyplot as plt\n\nfrom scipy.ndimage import gaussian_filter1d, median_filter\nfrom scipy.signal import butter, filtfilt, find_peaks, welch\nfrom scipy.interpolate import PchipInterpolator\n\nwarnings.filterwarnings(\"ignore\")\n\n# --------------------------\n# Config\n# --------------------------\n@dataclass\nclass CFG:\n    ROOT: str = \"/kaggle/input/physionet-ecg-image-digitization\"  # auto-detected if empty/missing\n    OUT_DIR: str = \"/kaggle/working/out\"\n    SUBMISSION_PARQUET: str = \"/kaggle/working/submission.parquet\"\n    SUBMISSION_CSV: str = \"/kaggle/working/submission.csv\"\n\n    # ECG paper / signal\n    SWEEP_MM_PER_S: float = 25.0\n    GAIN_MM_PER_MV: float = 10.0\n    TARGET_FS: int = 500\n\n    # Layout & names\n    LEAD_NAMES_12: List[str] = None\n\n    # Batch behavior\n    OVERWRITE: bool = False           # set True to recompute even if outputs exist\n    SCOPE: str = \"all\"                # \"all\" | \"test\" | \"train\"\n\n    # Strict redo thresholds\n    STRICT_REDO_TRIGGER_POOR_COUNT: int = 8\n    STRICT_REDO_TRIGGER_NO_GOOD: bool = True\n\n    # Seam refinement\n    STRICT_BAND_EXTRA: int = 4\n\n    # Scale search\n    MM_PER_PX_Y_GUESS: float = 0.1\n    SCALES_MM_PER_PX_X_BASE: Tuple[float, ...] = (1/12, 1/11, 1/10, 1/9, 1/8)\n\n    def __post_init__(self):\n        if self.LEAD_NAMES_12 is None:\n            self.LEAD_NAMES_12 = [\"I\",\"II\",\"III\",\"aVR\",\"aVL\",\"aVF\",\"V1\",\"V2\",\"V3\",\"V4\",\"V5\",\"V6\"]\n\nCFG = CFG()\nos.makedirs(CFG.OUT_DIR, exist_ok=True)\n\n# --------------------------\n# ROOT auto-detection & diagnostics\n# --------------------------\ndef auto_detect_root(preferred: str) -> str:\n    \"\"\"If the preferred ROOT doesn't exist or has no data, scan /kaggle/input for a likely dataset.\"\"\"\n    def has_data(root):\n        if not os.path.isdir(root): return False\n        # any images?\n        exts = (\"*.png\",\"*.jpg\",\"*.jpeg\",\"*.tif\",\"*.tiff\",\"*.bmp\")\n        for e in exts:\n            if glob.glob(os.path.join(root, \"**\", e), recursive=True):\n                return True\n        # or a CSV schema\n        if os.path.exists(os.path.join(root, \"test.csv\")): return True\n        if os.path.exists(os.path.join(root, \"sample_submission.csv\")): return True\n        return False\n\n    if has_data(preferred):\n        return preferred\n\n    candidates = []\n    for d in sorted(glob.glob(\"/kaggle/input/*\")):\n        if os.path.isdir(d) and has_data(d):\n            candidates.append(d)\n\n    # Prefer names that match physionet / ecg / digitization\n    def score_path(p):\n        s = 0\n        name = os.path.basename(p).lower()\n        for token in [\"physionet\",\"ecg\",\"digit\",\"image\",\"cardio\"]:\n            if token in name: s += 2\n        if os.path.exists(os.path.join(p, \"test.csv\")): s += 3\n        return -s  # sort ascending => most negative (highest score) first\n\n    if candidates:\n        best = sorted(candidates, key=score_path)[0]\n        print(f\"[auto-detect] Using dataset root: {best}\")\n        return best\n\n    print(\"[auto-detect] No dataset found under /kaggle/input — proceeding without images.\")\n    return preferred  # will produce dummy submission if empty\n\nCFG.ROOT = auto_detect_root(CFG.ROOT)\n\ndef list_ext_counts(root: str) -> Dict[str,int]:\n    counts = {}\n    for ext in (\"png\",\"jpg\",\"jpeg\",\"tif\",\"tiff\",\"bmp\"):\n        n = len(glob.glob(os.path.join(root, \"**\", f\"*.{ext}\"), recursive=True))\n        counts[ext] = n\n    return counts\n\nprint(\"Dataset root:\", CFG.ROOT)\nprint(\"Image counts by extension:\", list_ext_counts(CFG.ROOT))\nprint(\"Processing scope:\", CFG.SCOPE)\n\n# --------------------------\n# Helpers (IO & listing)\n# --------------------------\ndef find_all_images(root: str) -> List[str]:\n    \"\"\"Find ALL images recursively under root regardless of train/test placement.\"\"\"\n    files: List[str] = []\n    for ext in (\"*.png\",\"*.jpg\",\"*.jpeg\",\"*.tif\",\"*.tiff\",\"*.bmp\"):\n        files += glob.glob(os.path.join(root, \"**\", ext), recursive=True)\n    # Deduplicate but keep stable order\n    seen=set(); out=[]\n    for f in sorted(files):\n        if f not in seen:\n            seen.add(f); out.append(f)\n    return out\n\ndef collect_images_from(dirpath: str) -> List[str]:\n    \"\"\"Collect only top-level images from dirpath (no recursion) for explicit train/test dirs.\"\"\"\n    out=[]\n    for ext in (\"*.png\",\"*.jpg\",\"*.jpeg\",\"*.tif\",\"*.tiff\",\"*.bmp\"):\n        out += glob.glob(os.path.join(dirpath, ext))\n    return sorted(list(dict.fromkeys(out)))\n\ndef save_preview_grid(leads: Dict[str, np.ndarray], fs: int, png_path: str):\n    names = list(leads.keys())\n    if len(names) == 1:\n        y = leads[names[0]]\n        t = np.arange(len(y))/fs if len(y)>0 else np.arange(1)\n        plt.figure(figsize=(10,3))\n        plt.plot(t, y, linewidth=0.9)\n        plt.title(f\"{names[0]}  len={len(y)}  fs={fs}Hz\")\n        plt.grid(True, alpha=0.3)\n        if len(t)>0:\n            plt.xlim(0, min(11, t[-1]))\n        plt.savefig(png_path, dpi=160, bbox_inches=\"tight\"); plt.close()\n        return\n    rows, cols = 3, 4\n    fig, axes = plt.subplots(rows, cols, figsize=(12, 6), constrained_layout=True)\n    axes = axes.ravel()\n    for i, nm in enumerate(CFG.LEAD_NAMES_12):\n        ax = axes[i]\n        if nm in leads and len(leads[nm])>0:\n            y = leads[nm]; t = np.arange(len(y))/fs\n            ax.plot(t, y, linewidth=0.8); ax.grid(True, alpha=0.3)\n            ax.set_xlim(0, min(11, t[-1] if len(t)>0 else 11))\n            ax.set_title(nm, fontsize=9)\n        else:\n            ax.axis(\"off\")\n    plt.suptitle(\"Recovered ECG\", fontsize=12)\n    plt.savefig(png_path, dpi=160, bbox_inches=\"tight\"); plt.close()\n\ndef npz_exists(prefix: str) -> bool:\n    return all(os.path.exists(prefix+ext) for ext in (\".npz\",\".json\",\".png\"))\n\n# ==========================================\n# DFEE, RDSE, BioShed core\n# ==========================================\n_PATCH = {\"strict\": False, \"row_idx\": None}\n\ndef _auto_contrast(gray: np.ndarray) -> np.ndarray:\n    p1,p99 = np.percentile(gray, [1,99])\n    return np.clip((gray - p1) * (255.0/max(1.0,(p99-p1))), 0,255).astype(np.uint8)\n\ndef _rotate_bound(img: np.ndarray, angle_deg: float) -> np.ndarray:\n    h, w = img.shape[:2]\n    cX, cY = (w//2, h//2)\n    M = cv2.getRotationMatrix2D((cX, cY), angle_deg, 1.0)\n    cos = abs(M[0,0]); sin = abs(M[0,1])\n    nW = int((h*sin) + (w*cos)); nH = int((h*cos) + (w*sin))\n    M[0,2] += (nW/2) - cX; M[1,2] += (nH/2) - cY\n    return cv2.warpAffine(img, M, (nW, nH), flags=cv2.INTER_LINEAR, borderValue=255)\n\ndef dfee_angle_and_pitch(gray: np.ndarray) -> Tuple[float, float, float]:\n    g = _auto_contrast(gray)\n    edges = cv2.Canny(g, 50, 150)\n    lines = cv2.HoughLines(edges, 1, np.pi/180, threshold=max(150, int(0.0005*g.size)))\n    angle_deg = 0.0\n    if lines is not None:\n        angs=[]\n        for rho,theta in lines[:,0,:]:\n            deg=(theta*180/np.pi)%180\n            if deg<2 or deg>178: angs.append(deg if deg<2 else deg-180)\n            elif 88<deg<92:      angs.append(deg-90)\n        if angs:\n            m = float(np.median(angs))\n            if abs(m) < 5.0: angle_deg = m\n\n    F = np.fft.fft2(g.astype(np.float32))\n    P = np.fft.fftshift(np.abs(F)); P /= (P.max()+1e-6)\n    vx = P[P.shape[0]//2, :]; vy = P[:, P.shape[1]//2]\n\n    def dominant_period(sig, total_len):\n        sg = gaussian_filter1d(sig, 5)\n        mid = len(sg)//2\n        idx = np.argmax(sg[mid+10:]) + (mid+10)\n        k = abs(idx - mid)\n        if k <= 0: return None\n        return total_len/max(1, k)\n\n    px_per_mm_x = dominant_period(vx, gray.shape[1])\n    px_per_mm_y = dominant_period(vy, gray.shape[0])\n    if px_per_mm_x is None or not (4 <= px_per_mm_x <= 20): px_per_mm_x = 10.0\n    if px_per_mm_y is None or not (4 <= px_per_mm_y <= 20): px_per_mm_y = 10.0\n\n    return angle_deg, 1.0/px_per_mm_x, 1.0/px_per_mm_y\n\ndef degrid_color_to_gray(bgr: np.ndarray) -> np.ndarray:\n    if bgr is None or bgr.ndim != 3:\n        return bgr if bgr is not None else None\n    B,G,R = cv2.split(bgr.astype(np.float32))\n    base = np.minimum(np.minimum(R, G), B)\n    red_excess = np.clip(R - 0.5*(G + B), 0, None)\n    alpha = 0.5 + (0.05 if _PATCH[\"strict\"] else 0.0)\n    red_mask = red_excess / (red_excess.max() + 1e-6)\n    suppr = base - alpha * red_mask * (base - base.min())\n    suppr = cv2.GaussianBlur(suppr, (3,3), 0)\n    suppr -= suppr.min(); suppr /= (suppr.max() + 1e-6)\n    return (suppr*255.0).astype(np.uint8)\n\ndef preprocess(gray_or_bgr):\n    g = degrid_color_to_gray(gray_or_bgr) if (gray_or_bgr.ndim==3) else gray_or_bgr\n    g = _auto_contrast(g)\n    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n    g = clahe.apply(g)\n    g = median_filter(g, size=3).astype(np.uint8)\n    return g\n\ndef _seam_dp(cost, lam_smooth=0.0025, lam_curve=0.003):\n    H,W = cost.shape\n    INF = 1e9\n    C = np.full((H,W), INF, dtype=np.float32)\n    P = np.full((H,W), 0, dtype=np.int8)\n    C[:,0] = cost[:,0]\n    for x in range(1,W):\n        ccol = cost[:,x]\n        up = np.r_[C[0:1,x-1]+1e6, C[:-1,x-1]]\n        mi = C[:,x-1]\n        dn = np.r_[C[1:,x-1], C[-1:,x-1]+1e6]\n        stack = np.stack([up,mi,dn], axis=0)\n        idx = np.argmin(stack, axis=0)\n        base = stack[idx, np.arange(H)]\n        curve_pen = lam_curve * (idx!=1).astype(np.float32)\n        C[:,x] = ccol + base + lam_smooth*np.abs(idx-1) + curve_pen\n        P[:,x] = (idx-1).astype(np.int8)\n    y = int(np.argmin(C[:,-1]))\n    path = np.empty(W, dtype=np.float32); path[-1]=y\n    for x in range(W-1,0,-1):\n        dy = int(P[y,x]); y = max(0, min(H-1, y+dy)); path[x-1]=y\n    return gaussian_filter1d(path, sigma=1.0).astype(np.float32)\n\ndef seam_centerline_multi(g):\n    g_norm = g.astype(np.float32)\n    g_norm = (g_norm - g_norm.min())/max(1e-6,(g_norm.max()-g_norm.min()))\n    edges = cv2.Canny((g_norm*255).astype(np.uint8), 40, 120).astype(np.float32)/255.0\n    sobel = cv2.Sobel(g_norm, cv2.CV_32F, 1, 0, ksize=3)\n    grad = np.abs(sobel); grad /= max(1e-6, grad.max())\n    base_cost = 0.5*g_norm + 0.45*(1.0-edges) + 0.05*(1.0-grad)\n    p1 = _seam_dp(base_cost, lam_smooth=0.0015, lam_curve=0.002)\n    p2 = _seam_dp(base_cost, lam_smooth=0.0030, lam_curve=0.003)\n    p3 = _seam_dp(base_cost, lam_smooth=0.0060, lam_curve=0.004)\n    path = np.median(np.vstack([p1,p2,p3]), axis=0).astype(np.float32)\n    return gaussian_filter1d(path, sigma=1.2).astype(np.float32)\n\ndef seam_centerline_simple(g):\n    gb = cv2.GaussianBlur(g.astype(np.float32), (3,3), 0)\n    k = cv2.getStructuringElement(cv2.MORPH_RECT, (9,9))\n    tophat = cv2.morphologyEx(gb.astype(np.uint8), cv2.MORPH_TOPHAT, k).astype(np.float32)\n    g2 = gb - 0.4*tophat\n    y = np.argmin(g2, axis=0).astype(np.float32)\n    return gaussian_filter1d(y, sigma=2.0).astype(np.float32)\n\ndef seam_centerline_ridge(g):\n    k = cv2.getStructuringElement(cv2.MORPH_RECT, (7,7))\n    bh = cv2.morphologyEx(g.astype(np.uint8), cv2.MORPH_BLACKHAT, k).astype(np.float32)\n    medc = np.median(bh, axis=0, keepdims=True).astype(np.float32)\n    hp = cv2.GaussianBlur(bh - medc, (3,3), 0)\n    y = np.argmin(hp, axis=0).astype(np.float32)\n    return gaussian_filter1d(y, sigma=1.5).astype(np.float32)\n\ndef is_flat(y): return np.std(gaussian_filter1d(y, 20)) < 0.35\n\ndef _adaptive_band_px(panel_gray: np.ndarray) -> int:\n    H,W = panel_gray.shape\n    contrast = float(np.std(panel_gray) / (np.mean(panel_gray)+1e-6))\n    e = cv2.Canny(panel_gray, 40, 120)\n    edged = float(np.mean(e>0))\n    base = 20.0\n    if contrast < 0.35: base += 4.0\n    if edged < 0.05:    base += 2.0\n    if contrast > 0.6:  base -= 2.0\n    if edged > 0.15:    base -= 2.0\n    if _PATCH[\"strict\"]: base += CFG.STRICT_BAND_EXTRA\n    return int(np.clip(base, 12, 32))\n\ndef refine_seam_around_path(g, y_path, band_px=18):\n    g_norm = g.astype(np.float32)\n    g_norm = (g_norm - g_norm.min())/max(1e-6,(g_norm.max()-g_norm.min()))\n    H, W = g_norm.shape\n    edges = cv2.Canny((g_norm*255).astype(np.uint8), 40, 120).astype(np.float32)/255.0\n    sobel = cv2.Sobel(g_norm, cv2.CV_32F, 1, 0, ksize=3)\n    grad = np.abs(sobel); grad /= max(1e-6, grad.max())\n    base_cost = 0.5*g_norm + 0.45*(1.0-edges) + 0.05*(1.0-grad)\n    yy = np.arange(H, dtype=np.float32)[:, None]\n    ribbon = np.exp(-0.5*((yy - y_path[None, :])/(band_px))**2)\n    ribbon = (ribbon - ribbon.min())/(ribbon.max()-ribbon.min()+1e-6)\n    cost = base_cost*0.7 + 0.3*(1.0 - ribbon)\n    return _seam_dp(cost, lam_smooth=0.0025, lam_curve=0.003)\n\ndef to_timeseries_from_path(y_path: np.ndarray, H: int,\n                            mm_per_px_x: float, mm_per_px_y: float) -> Tuple[np.ndarray, np.ndarray]:\n    mv_per_px = (1.0 / CFG.GAIN_MM_PER_MV) / mm_per_px_y\n    trace_mV = ((H/2.0 - y_path) * mv_per_px).astype(np.float32)\n    s_per_px = (mm_per_px_x / CFG.SWEEP_MM_PER_S)\n    t = np.arange(len(y_path), dtype=np.float32) * s_per_px\n    return trace_mV, t\n\ndef butter_bandpass(sig, fs, low=0.67, high=35.0, order=4):\n    nyq = 0.5*fs\n    b, a = butter(order, [low/nyq, high/nyq], btype='band')\n    return filtfilt(b, a, sig)\n\ndef hp_detrend(sig, fs, fc=0.5, order=2):\n    nyq = 0.5*fs\n    b,a = butter(order, fc/nyq, btype='highpass')\n    try:    return filtfilt(b,a,sig).astype(np.float32)\n    except: return sig\n\ndef resample_to_fs(y_mV, t, fs):\n    t = np.asarray(t, dtype=np.float32); y = np.asarray(y_mV, dtype=np.float32)\n    if len(t) < 2: return y, 0.0\n    t_target = np.arange(0, max(1e-6, t[-1]), 1.0/fs, dtype=np.float32)\n    if len(t_target) < 5:\n        t_target = np.linspace(0, max(1e-3, t[-1]), num=min(4096, max(32, len(y))), dtype=np.float32)\n    y_res = PchipInterpolator(t, y, extrapolate=False)(t_target).astype(np.float32)\n    if np.isnan(y_res).any():\n        m = np.isnan(y_res)\n        if (~m).any():\n            first = np.argmax(~m); last = len(y_res)-1 - np.argmax((~m)[::-1])\n            y_res[:first] = y_res[first]; y_res[last+1:] = y_res[last]\n            y_res[m] = np.interp(np.flatnonzero(m), np.flatnonzero(~m), y_res[~m])\n        else:\n            y_res = np.zeros_like(y_res)\n    try:\n        y_bp = butter_bandpass(y_res, fs=fs, low=0.67, high=35.0).astype(np.float32)\n    except Exception:\n        y_bp = y_res\n    y_bp = hp_detrend(y_bp, fs, fc=0.5)\n    return y_bp, float(t_target[-1])\n\ndef snr_estimate(x, fs):\n    if len(x) < 16: return 0.0\n    f, Pxx = welch(x, fs=fs, nperseg=min(1024, len(x)))\n    signal = (f>=5) & (f<=15)\n    noise  = (f<0.5) | (f>45)\n    Ps = float(np.mean(Pxx[signal])) if np.any(signal) else 1e-9\n    Pn = float(np.mean(Pxx[~signal & ~noise])) if np.any(~signal & ~noise) else 1e-9\n    return 10.0*np.log10((Ps+1e-12)/(Pn+1e-12))\n\ndef rpeaks_adaptive(x, fs):\n    def _peaks(sig):\n        try: xb = butter_bandpass(sig, fs, 5, 15)\n        except Exception: xb = sig\n        dx = np.diff(xb, prepend=xb[0]); sq = dx*dx\n        win = max(1, int(0.12*fs))\n        env = np.convolve(sq, np.ones(win)/win, mode='same')\n        thr = np.median(env) + 1.8*np.std(env)\n        peaks, _ = find_peaks(env, height=thr, distance=int(0.28*fs))\n        if len(peaks) < 2:\n            thr = np.median(env) + 1.2*np.std(env)\n            peaks, _ = find_peaks(env, height=thr, distance=int(0.25*fs))\n        return peaks\n    pk = _peaks(x)\n    if len(pk) < 2: pk = _peaks(-x)\n    return pk\n\ndef bioshed_metrics(x: np.ndarray, fs: int) -> Dict[str, Any]:\n    pk = rpeaks_adaptive(x, fs)\n    if len(pk) >= 2:\n        rr = np.diff(pk)/fs\n        rr_mean = float(np.mean(rr)); rr_sdnn = float(np.std(rr, ddof=1)) if len(rr)>1 else 0.0; rr_n=int(len(rr))\n    else:\n        rr_mean = rr_sdnn = 0.0; rr_n = 0\n    hf = x - gaussian_filter1d(x, sigma=max(1, int(fs*0.04)))\n    art = float(np.mean(np.abs(hf) > (3*np.std(hf)+1e-6)))\n    snr = snr_estimate(x, fs)\n    quality = \"good\"\n    if snr < 3 or art > 0.08: quality = \"fair\"\n    if snr < 0 or art > 0.15 or rr_n < 2: quality = \"poor\"\n    return dict(snr_db=float(snr), rr_mean=rr_mean, rr_sdnn=rr_sdnn, rr_n=rr_n,\n                artifact_rate=art, quality=quality)\n\ndef auto_layout_panels(gray_img: np.ndarray) -> Tuple[List[Tuple[int,int,int,int]], str]:\n    H, W = gray_img.shape\n    cols = np.round(np.linspace(0, W, 5)).astype(int)\n    rows = np.round(np.linspace(0, H, 4)).astype(int)\n    panels=[]\n    for i in range(3):\n        for j in range(4):\n            x0,x1 = cols[j], cols[j+1]; y0,y1 = rows[i], rows[i+1]\n            panels.append((int(x0), int(y0), int(x1-x0), int(y1-y0)))\n    return panels, \"4x3\"\n\ndef extract_panel_bestof(panel_gray: np.ndarray, panel_name: str,\n                         mm_per_px_x: float, mm_per_px_y: float) -> Dict[str, Any]:\n    H, W = panel_gray.shape\n    seeds = [\n        (\"multi\", seam_centerline_multi(panel_gray)),\n        (\"simple\", seam_centerline_simple(panel_gray)),\n        (\"ridge\", seam_centerline_ridge(panel_gray))\n    ]\n    band = _adaptive_band_px(panel_gray)\n    best=None\n    for nm,y0 in seeds:\n        if is_flat(y0): continue\n        y1 = refine_seam_around_path(panel_gray, y0, band_px=band)\n        y_mV, t = to_timeseries_from_path(0.25*y0 + 0.75*y1, H, mm_per_px_x, mm_per_px_y)\n        y_f, dur = resample_to_fs(y_mV, t, CFG.TARGET_FS)\n        qa = bioshed_metrics(y_f, CFG.TARGET_FS)\n        score = qa[\"snr_db\"] + (8.0 if qa[\"rr_n\"]>=2 else 0.0) + (1.0 if qa[\"quality\"]==\"good\" else 0.0)\n        cand = dict(name=panel_name, y=y_f, fs=CFG.TARGET_FS, duration_s=dur, qa=qa,\n                    picked={\"seam\": f\"{nm}+ref\", \"mm_per_px_x\": float(mm_per_px_x), \"mm_per_px_y\": float(mm_per_px_y)})\n        if (best is None) or (score > best[\"score\"]):\n            best = {\"score\": score, \"res\": cand}\n    if best is None:\n        y_mV, t = to_timeseries_from_path(seeds[1][1], H, mm_per_px_x, mm_per_px_y)\n        y_f, dur = resample_to_fs(y_mV, t, CFG.TARGET_FS)\n        qa = bioshed_metrics(y_f, CFG.TARGET_FS)\n        return dict(name=panel_name, y=y_f, fs=CFG.TARGET_FS, duration_s=dur, qa=qa,\n                    picked={\"seam\": \"simple-raw\", \"mm_per_px_x\": float(mm_per_px_x), \"mm_per_px_y\": float(mm_per_px_y)})\n    return best[\"res\"]\n\ndef process_image_to_leads(img_path: str) -> Optional[Dict[str, Any]]:\n    raw = cv2.imread(img_path, cv2.IMREAD_COLOR)\n    if raw is None:\n        print(\"!! Cannot decode:\", img_path); return None\n    gray0 = cv2.cvtColor(raw, cv2.COLOR_BGR2GRAY)\n    angle_deg, mmx, mmy = dfee_angle_and_pitch(gray0)\n    gray = _rotate_bound(gray0, -angle_deg) if abs(angle_deg)>0.3 else gray0\n    g = preprocess(gray)\n    panels, layout = auto_layout_panels(g)\n    lead_names = CFG.LEAD_NAMES_12 if (layout==\"4x3\" and len(panels)==12) else [\"Lead0\"]\n    results = {}\n    for idx, (x,y,w,h) in enumerate(panels[:len(lead_names)]):\n        _PATCH[\"row_idx\"] = idx//4 if layout==\"4x3\" else None\n        panel = g[y:y+h, x:x+w]\n        name = lead_names[idx]\n        pr = extract_panel_bestof(panel, name, mmx, mmy)\n        results[name] = pr\n    if not results:\n        return None\n    min_len = min(len(results[k][\"y\"]) for k in results)\n    for k in list(results.keys()):\n        results[k][\"y\"] = results[k][\"y\"][:min_len]\n        results[k][\"qa\"] = bioshed_metrics(results[k][\"y\"], CFG.TARGET_FS)\n    return dict(layout=layout, angle_deg=float(angle_deg),\n                mm_per_px_x=float(mmx), mm_per_px_y=float(mmy),\n                fs=CFG.TARGET_FS, leads=results)\n\n# ==========================================\n# Batch digitization (train+test+others) + QC exports\n# ==========================================\n# discover train/test dirs (if present)\ntest_dir = os.path.join(CFG.ROOT, \"test\")\ntrain_dir = os.path.join(CFG.ROOT, \"train\")\n\ntest_pngs = collect_images_from(test_dir) if os.path.isdir(test_dir) else []\ntrain_pngs = collect_images_from(train_dir) if os.path.isdir(train_dir) else []\nall_imgs = find_all_images(CFG.ROOT)\n\nprint(f\"Discovered counts → train(top-level): {len(train_pngs)}, test(top-level): {len(test_pngs)}, all(recursive): {len(all_imgs)}\")\n\n# choose scope\nif CFG.SCOPE.lower() == \"test\":\n    use_imgs = test_pngs if test_pngs else all_imgs\nelif CFG.SCOPE.lower() == \"train\":\n    use_imgs = train_pngs if train_pngs else all_imgs\nelse:  # \"all\"\n    # Use recursive discovery of ALL images under ROOT\n    use_imgs = all_imgs\n\nprint(f\"Selected {len(use_imgs)} images for processing based on scope='{CFG.SCOPE}'\")\nprint(f\"Outputs will be saved to: {CFG.OUT_DIR}\")\n\nnew_cnt=0; skip_cnt=0; fail_cnt=0\nfor p in use_imgs:\n    base = os.path.splitext(os.path.basename(p))[0]\n    out_prefix = os.path.join(CFG.OUT_DIR, base)\n    if (not CFG.OVERWRITE) and npz_exists(out_prefix):\n        skip_cnt += 1\n        continue\n    try:\n        _PATCH[\"strict\"] = False\n        R = process_image_to_leads(p)\n        if R is None or not R.get(\"leads\"):\n            fail_cnt += 1; continue\n        qc = [R[\"leads\"][k][\"qa\"][\"quality\"] for k in R[\"leads\"]]\n        redo = (CFG.STRICT_REDO_TRIGGER_NO_GOOD and (\"good\" not in qc)) or \\\n               (qc.count(\"poor\") >= CFG.STRICT_REDO_TRIGGER_POOR_COUNT)\n        if redo:\n            _PATCH[\"strict\"] = True\n            R = process_image_to_leads(p) or R\n        os.makedirs(CFG.OUT_DIR, exist_ok=True)\n        npz_dict = {k: R[\"leads\"][k][\"y\"] for k in R[\"leads\"]}\n        npz_dict[\"fs\"] = R[\"fs\"]\n        np.savez_compressed(out_prefix + \".npz\", **npz_dict)\n        with open(out_prefix + \".json\", \"w\") as f:\n            json.dump({\n                \"input\": os.path.basename(p),\n                \"layout\": R[\"layout\"],\n                \"fs\": R[\"fs\"],\n                \"calibration\": {\n                    \"angle_deg\": R[\"angle_deg\"],\n                    \"mm_per_px_x\": R[\"mm_per_px_x\"],\n                    \"mm_per_px_y\": R[\"mm_per_px_y\"],\n                    \"speed_mm_s\": CFG.SWEEP_MM_PER_S,\n                    \"gain_mm_mV\": CFG.GAIN_MM_PER_MV\n                },\n                \"qa\": {k: R[\"leads\"][k][\"qa\"] for k in R[\"leads\"]},\n                \"picked\": {k: R[\"leads\"][k][\"picked\"] for k in R[\"leads\"]},\n                \"strict_mode\": bool(_PATCH[\"strict\"])\n            }, f, indent=2)\n        leads_ts = {k: R[\"leads\"][k][\"y\"] for k in R[\"leads\"]}\n        save_preview_grid(leads_ts, R[\"fs\"], out_prefix + \".png\")\n        new_cnt += 1\n        picks = \", \".join([f\"{k}:{R['leads'][k]['picked']['seam']}/{R['leads'][k]['picked']['mm_per_px_x']:.3f}\"\n                           for k in list(R[\"leads\"].keys())[:4]])\n        qccnt = {\"good\":0,\"fair\":0,\"poor\":0}\n        for k in R[\"leads\"]: qccnt[R[\"leads\"][k][\"qa\"][\"quality\"]] += 1\n        print(f\"OK {os.path.basename(p)} layout={R['layout']} leads={len(R['leads'])} qc={qccnt} picks={picks}\")\n    except Exception as e:\n        fail_cnt += 1\n        print(\"!! Failed:\", p, \"→\", repr(e))\n\nprint(\"\\nBatch complete.\",\n      f\"New processed: {new_cnt}, skipped existing: {skip_cnt}, failed: {fail_cnt}\")\nprint(\"Digitized artifacts (.npz, .json, preview .png) are in:\", CFG.OUT_DIR)\n\n# --------------------------\n# QC aggregation CSVs\n# --------------------------\njfiles = sorted(glob.glob(os.path.join(CFG.OUT_DIR, \"*.json\")))\nrows = []\nfor jf in jfiles:\n    try:\n        with open(jf, \"r\") as f:\n            J = json.load(f)\n        qa = J.get(\"qa\", {})\n        for lead, q in qa.items():\n            rows.append({\n                \"image\": J.get(\"input\"),\n                \"lead\": lead,\n                \"snr_db\": q.get(\"snr_db\"),\n                \"rr_mean\": q.get(\"rr_mean\"),\n                \"rr_sdnn\": q.get(\"rr_sdnn\"),\n                \"artifact_rate\": q.get(\"artifact_rate\"),\n                \"quality\": q.get(\"quality\"),\n                \"strict_mode\": J.get(\"strict_mode\", False)\n            })\n    except Exception as e:\n        print(\"Skip QC:\", jf, \"→\", e)\n\nif rows:\n    df_qc = pd.DataFrame(rows)\n    df_qc.to_csv(\"/kaggle/working/qc_all_traces.csv\", index=False)\n    summary = (df_qc[\"quality\"].value_counts(normalize=True)*100).round(1).to_dict()\n    print(\"QC saved: /kaggle/working/qc_all_traces.csv\")\n    print(\"Overall quality %:\", summary)\nelse:\n    print(\"No QC rows produced.\")\n\n# ==========================================\n# Robust submission.csv builder (no exit; always writes)\n# ==========================================\nLEADS_12 = CFG.LEAD_NAMES_12\nDEFAULT_ROWS = {**{l:1250 for l in LEADS_12}, **{\"II\":5000}}\n\ndef _safe_pchip(x_src, y, x_tgt):\n    try:\n        y_tgt = PchipInterpolator(x_src, y, extrapolate=False)(x_tgt).astype(np.float32)\n        if np.isnan(y_tgt).any():\n            m = np.isnan(y_tgt)\n            if (~m).any():\n                y_tgt[m] = np.interp(np.flatnonzero(m), np.flatnonzero(~m), y_tgt[~m]).astype(np.float32)\n            else:\n                y_tgt = np.zeros_like(y_tgt, dtype=np.float32)\n        return y_tgt\n    except Exception:\n        return np.interp(x_tgt, x_src, y).astype(np.float32)\n\ndef _fetch_vec(img_id: str, lead: str, num_rows: int) -> np.ndarray:\n    base = str(img_id)\n    npz_path = os.path.join(CFG.OUT_DIR, base + \".npz\")\n    json_path = os.path.join(CFG.OUT_DIR, base + \".json\")\n    if not os.path.exists(npz_path):\n        alt = os.path.join(CFG.OUT_DIR, os.path.basename(base) + \".npz\")\n        if os.path.exists(alt):\n            npz_path = alt\n            json_path = os.path.join(CFG.OUT_DIR, os.path.basename(base) + \".json\")\n    if not os.path.exists(npz_path):\n        return np.zeros(num_rows, dtype=np.float32)\n    z = np.load(npz_path, allow_pickle=True)\n    leads = {k: z[k] for k in z.files if k != \"fs\"}\n    if lead in leads:\n        y = leads[lead].astype(np.float32)\n    elif \"II\" in leads:\n        y = leads[\"II\"].astype(np.float32)\n    else:\n        chosen = None\n        try:\n            with open(json_path, \"r\") as f:\n                J = json.load(f)\n            best = None\n            for k, q in (J.get(\"qa\") or {}).items():\n                s = q.get(\"snr_db\", -1e9)\n                if (best is None) or (s > best[1]): best = (k, s)\n            if best and best[0] in leads:\n                chosen = best[0]\n        except Exception:\n            pass\n        if chosen is None:\n            chosen = sorted(leads.keys())[0]\n        y = leads[chosen].astype(np.float32)\n    if len(y) == num_rows:\n        return y\n    if len(y) < 2:\n        return np.zeros(num_rows, dtype=np.float32)\n    x_src = np.linspace(0, 1, len(y), dtype=np.float32)\n    x_tgt = np.linspace(0, 1, num_rows, dtype=np.float32)\n    return _safe_pchip(x_src, y, x_tgt)\n\ndef build_from_test_csv(path: str) -> pd.DataFrame:\n    df = pd.read_csv(path)\n    need = {\"id\",\"lead\",\"number_of_rows\"}\n    if not need.issubset(df.columns):\n        raise RuntimeError(f\"{os.path.basename(path)} missing required columns {need}; found {list(df.columns)}\")\n    rows = []\n    for _, r in df.iterrows():\n        img_id = str(r[\"id\"]); lead = str(r[\"lead\"]); nrows = int(r[\"number_of_rows\"])\n        vec = _fetch_vec(img_id, lead, nrows)\n        rows.extend({\"id\": f\"{img_id}_{i}_{lead}\", \"value\": float(v)} for i, v in enumerate(vec))\n    return pd.DataFrame(rows)\n\ndef build_from_sample_submission(path: str) -> pd.DataFrame:\n    df_sample = pd.read_csv(path)\n    if \"id\" not in df_sample.columns:\n        raise RuntimeError(\"sample_submission.csv must contain 'id' column\")\n    parts = df_sample[\"id\"].astype(str).str.rsplit(\"_\", n=2)\n    meta = pd.DataFrame({\"img_id\": parts.str[0], \"index\": parts.str[1].astype(int), \"lead\": parts.str[2]})\n    need_len = meta.groupby([\"img_id\",\"lead\"])[\"index\"].max().astype(int) + 1\n    cache = {}\n    rows = []\n    for rid, (img_id, idx, lead) in zip(df_sample[\"id\"].tolist(), zip(meta[\"img_id\"], meta[\"index\"], meta[\"lead\"])):\n        key = (img_id, lead)\n        if key not in cache:\n            cache[key] = _fetch_vec(img_id, lead, int(need_len.loc[key]))\n        vec = cache[key]\n        v = float(vec[idx]) if 0 <= idx < len(vec) else 0.0\n        rows.append({\"id\": rid, \"value\": v})\n    return pd.DataFrame(rows)\n\ndef build_from_outputs_only() -> pd.DataFrame:\n    npzs = sorted(glob.glob(os.path.join(CFG.OUT_DIR, \"*.npz\")))\n    if not npzs:\n        # Ensure Kaggle UI sees a file; write a tiny valid CSV\n        return pd.DataFrame([{\"id\": \"dummy_0_II\", \"value\": 0.0}])\n    rows = []\n    for path in npzs:\n        base = os.path.splitext(os.path.basename(path))[0]\n        # Emit all 12-leads with default expected lengths (II longer)\n        for lead in CFG.LEAD_NAMES_12:\n            nrows = 5000 if lead==\"II\" else 1250\n            vec = _fetch_vec(base, lead, nrows)\n            rows.extend({\"id\": f\"{base}_{i}_{lead}\", \"value\": float(v)} for i, v in enumerate(vec))\n    return pd.DataFrame(rows)\n\ntest_csv = os.path.join(CFG.ROOT, \"test.csv\")\nsample_csv = os.path.join(CFG.ROOT, \"sample_submission.csv\")\n\nbuilt = None\nif os.path.exists(test_csv):\n    try:\n        print(\"Building submission from test.csv …\")\n        built = build_from_test_csv(test_csv)\n    except Exception as e:\n        print(\"test.csv route failed:\", e)\n\nif (built is None or built.empty) and os.path.exists(sample_csv):\n    try:\n        print(\"Building submission from sample_submission.csv …\")\n        built = build_from_sample_submission(sample_csv)\n    except Exception as e:\n        print(\"sample_submission.csv route failed:\", e)\n\nif built is None or built.empty:\n    print(\"No schema CSV found or both routes failed → synthesizing from outputs in /out.\")\n    built = build_from_outputs_only()\n\nbuilt.to_csv(CFG.SUBMISSION_CSV, index=False)\ntry:\n    built.to_parquet(CFG.SUBMISSION_PARQUET, index=False)\nexcept Exception:\n    pass\n\nprint(f\"\\n✅ submission.csv written to: {CFG.SUBMISSION_CSV}\")\nprint(f\"Rows: {len(built)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-31T15:42:23.992503Z","iopub.execute_input":"2025-10-31T15:42:23.992824Z"}},"outputs":[],"execution_count":null}]}