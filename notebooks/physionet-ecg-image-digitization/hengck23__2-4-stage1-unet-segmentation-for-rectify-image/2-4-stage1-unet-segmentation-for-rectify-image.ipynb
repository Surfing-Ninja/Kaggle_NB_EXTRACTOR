{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceType":"competition","sourceId":97984,"databundleVersionId":14096757},{"sourceType":"datasetVersion","sourceId":13602765,"datasetId":8642264,"databundleVersionId":14334607}],"dockerImageVersionId":31153,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"try:\n    import cc3d\nexcept:\n    !pip install 'connected-components-3d'\n\n\nimport sys\nsys.path.append('/kaggle/input/hengck23-rectification-net-demo')\n\nimport numpy as np\nimport pandas as pd\nimport cv2\nimport cc3d\n\nimport matplotlib.pyplot as plt\nimport matplotlib\nfrom scipy.interpolate import griddata\n\nfrom model import *\n\n\nprint('import ok!')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-11-03T21:04:52.137443Z","iopub.execute_input":"2025-11-03T21:04:52.137746Z","iopub.status.idle":"2025-11-03T21:05:11.148282Z","shell.execute_reply.started":"2025-11-03T21:04:52.137726Z","shell.execute_reply":"2025-11-03T21:05:11.147574Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def encode_with_resnet(e, x):\n\tencode = []\n\t# x 256\n\n\tx = e.conv1(x)\n\tx = e.bn1(x)\n\tx = e.act1(x)\n\t#x = e.maxpool(x)\n\n\tx = e.layer1(x); encode.append(x)  # 128\n\tx = e.layer2(x); encode.append(x)  # 64\n\tx = e.layer3(x); encode.append(x)  # 32\n\tx = e.layer4(x); encode.append(x)  # 16\n\treturn encode\n\n\nclass Net(nn.Module):\n\tdef __init__(self, pretrained=False, cfg=None):\n\t\tsuper(Net, self).__init__()\n\t\tself.output_type = ['infer', 'loss']\n\t\tself.register_buffer('D', torch.tensor(0))\n\t\tself.register_buffer('mean', torch.tensor([0.485, 0.456, 0.406]).reshape(1, 3, 1, 1))\n\t\tself.register_buffer('std', torch.tensor([0.229, 0.224, 0.225]).reshape(1, 3, 1, 1))\n\n\t\t#arch = 'convnext_tiny.fb_in22k'  \n\t\tarch = 'resnet18d.ra4_e3600_r224_in1k'\n\n\t\tencoder_dim = {\n\t\t\t'resnet18d.ra4_e3600_r224_in1k': [64, 128, 256, 512],\n\t\t\t'convnext_tiny_in22k': [96, 192, 384, 768],\n\t\t\t'convnext_tiny.fb_in22k': [96, 192, 384, 768],\n\t\t\t'convnext_small.fb_in22k': [96, 192, 384, 768], #96, 192, 384, 768\n\t\t\t'convnext_base.fb_in22k': [128, 256, 512, 1024], #96, 192, 384, 768\n\t\t\t'resnet50d': [64, 256, 512, 1024, 2048, ],\n\t\t}[arch]\n\t\tdecoder_dim = [256, 128, 64, 32]\n\n\t\t#self.upby2 = UpSampleDeconv(decoder_dim[-1],decoder_dim[-1])\n\n\t\tself.encoder = timm.create_model(\n\t\t\tmodel_name=arch, pretrained=pretrained, in_chans=3, num_classes=0, global_pool=''\n\t\t)\n\n\t\tself.decoder = MyUnetDecoder(\n\t\t\tin_channel=encoder_dim[-1],\n\t\t\tskip_channel=encoder_dim[:-1][::-1]+[0],\n\t\t\tout_channel=decoder_dim,\n\t\t\tscale = [2,2,2,2]\n\t\t)\n\t\t#self.lead      = nn.Conv2d(decoder_dim[-1], NUM_LEAD + 1, kernel_size=1)  #softmax\n\t\t#self.marker    = nn.Conv2d(decoder_dim[-1], NUM_MARKER + 1, kernel_size=1)  #softmax\n\t\tself.gpoint = nn.Conv2d(decoder_dim[-1], 1, kernel_size=1) #yx: sigmoid\n\t\tself.ghline = nn.Conv2d(decoder_dim[-1], 1, kernel_size=1) #yx: sigmoid\n\t\tself.gvline = nn.Conv2d(decoder_dim[-1], 1, kernel_size=1) #yx: sigmoid\n\n\n\t# todo image level grade ???\n\n\tdef forward(self, batch):\n\t\tdevice = self.D.device\n\t\timage = batch['image'].to(device)\n\n\t\tB, _3_, H, W = image.shape\n\n\t\tx = image.float() / 255\n\t\tx = (x - self.mean) / self.std\n\n\t\t# ---------------------------------------\n\n\t\te = self.encoder\n\t\tencode = encode_with_resnet(e, x) \n\t\t#[print(f'encode_{i}', e.shape) for i,e in enumerate(encode)]\n\n\t\tlast, decode = self.decoder(\n\t\t\tfeature=encode[-1], skip=encode[:-1][::-1]+[None]\n\t\t)\n\t\t#last = self.upby2(last) \n\t\t#[print(f'decode_{i}', e.shape) for i,e in enumerate(decode)]\n\t\t#print('last', last.shape)\n\n\n\t\t#lead     = self.lead(last)\n\t\t#marker   = self.marker(last)\n\t\tgpoint = self.gpoint(last)\n\t\tghline = self.ghline(last)\n\t\tgvline = self.gvline(last)\n\n\n\t\toutput = {}\n\t\tif 'loss' in self.output_type:\n\t\t \n\t\t\toutput['gpoint_loss'] = F.binary_cross_entropy_with_logits(\n\t\t\t\tgpoint, (batch['gpoint'].to(device) > 0.5).float())\n\t\t\toutput['ghline_loss'] = F.binary_cross_entropy_with_logits(\n\t\t\t\tghline, (batch['ghline'].to(device) > 0.5).float())\n\t\t\toutput['gvline_loss'] = F.binary_cross_entropy_with_logits(\n\t\t\t\tgvline, (batch['gvline'].to(device) > 0.5).float())\n\t\t\toutput['grid_loss'] = 2*output['gpoint_loss']+output['ghline_loss']+output['gvline_loss']\n\n\t\t# ----\n\t\t\t#output['signal_loss'] = F.mse_loss(signal, batch['signal'].to(device).float()) #snr\n\t\t#todo masked loss ... (invalid point)\n\n\n\t\tif 'infer' in self.output_type:\n\t\t\toutput['gpoint'] = torch.sigmoid(gpoint)\n\t\t\toutput['ghline'] = torch.sigmoid(ghline)\n\t\t\toutput['gvline'] = torch.sigmoid(gvline)\n\n\t\treturn output\n\n\ndef run_check_net():\n\tH, W = 320, 320\n\tbatch_size = 4\n\n\tbatch = {\n\t\t'image': torch.from_numpy(np.random.randint(0, 256, (batch_size, 3, H, W))).byte(),\n\t\t'gpoint': torch.from_numpy(np.random.uniform(0,1, (batch_size, 1, H, W))).float(),\n\t\t'ghline': torch.from_numpy(np.random.uniform(0,1, (batch_size, 1, H, W))).float(),\n\t\t'gvline': torch.from_numpy(np.random.uniform(0,1, (batch_size, 1, H, W))).float(),\n\t}\n\n\tnet = Net(pretrained=True)#.cuda()\n\t# print(net)\n\n\twith torch.no_grad():\n\t\twith torch.amp.autocast('cuda'):\n\t\t\toutput = net(batch)\n\t# ---\n\n\n\tprint('batch')\n\tfor k, v in batch.items():\n\t\tprint(f'{k:>32} : {v.shape} ')\n\n\tprint('output')\n\tfor k, v in output.items():\n\t\tif 'loss' not in k:\n\t\t\tprint(f'{k:>32} : {v.shape} ')\n\tprint('loss')\n\tfor k, v in output.items():\n\t\tif 'loss' in k:\n\t\t\tprint(f'{k:>32} : {v.item()} ')\nrun_check_net()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-03T21:05:11.149056Z","iopub.execute_input":"2025-11-03T21:05:11.149263Z","iopub.status.idle":"2025-11-03T21:05:15.654853Z","shell.execute_reply.started":"2025-11-03T21:05:11.149243Z","shell.execute_reply":"2025-11-03T21:05:15.654028Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"KAGGLE_DIR='/kaggle/input/physionet-ecg-image-digitization'\nDEVICE = 'cuda'\n\nimage_id = '31294838'  \ntype_id  = '0005'  \n\nimage = cv2.imread(f'{KAGGLE_DIR}/train/{image_id}/{image_id}-{type_id}.png', cv2.IMREAD_COLOR_RGB)\nH, W = image.shape[:2]\nprint('image:', H, W)\n\npH = int(H // 32) * 32 + 32\npW = int(W // 32) * 32 + 32\npadded = np.pad(image, [[0, pH - H], [0, pW - W], [0, 0]], mode='constant', constant_values=0)\n\n\ndef run_infer_demo():\n    net = Net(pretrained=False) \n    #f = torch.load(f'/kaggle/input/hengck23-rectification-net-demo/last.checkpoint.pth', map_location=lambda storage, loc: storage)\n    f = torch.load(f'/kaggle/input/hengck23-rectification-net-demo/00002500.checkpoint.pth', map_location=lambda storage, loc: storage)\n\n    state_dict = f['state_dict']\n    print(net.load_state_dict(state_dict, strict=False))  # True\n    net = net.to(DEVICE)\n    net = net.eval()\n    net.output_type = ['infer']\n\n    prob = 0\n    count = 0\n    print('padded', padded.shape)\n    for trial in range(4):\n        print('trial', trial)\n        crop = torch.from_numpy(np.ascontiguousarray(padded.transpose(2, 0, 1))).unsqueeze(0)\n\n        # augment\n        if trial == 1:\n            crop = torch.flip(crop, [2]).contiguous()\n        if trial == 2:\n            crop = torch.flip(crop, [3]).contiguous()\n        if trial == 3:\n            crop = torch.flip(crop, [2, 3]).contiguous()\n\n        batch = {\n            'image': crop,\n        }\n        #with torch.amp.autocast('cuda', dtype=torch.bfloat16):\n        with torch.no_grad():\n            output = net(batch)\n        \n\n        #print('g1', output['gridpoint'].max())\n        p = torch.cat([\n            output['gpoint'],output['ghline'],output['gvline']\n        ],1)\n        if trial == 1:\n            p = torch.flip(p, [2]).contiguous()\n        if trial == 2:\n            p = torch.flip(p, [3]).contiguous()\n        if trial == 3:\n            p = torch.flip(p, [2, 3]).contiguous()\n\n        p = p.float().data.cpu().numpy()[0]\n        prob += p\n        count +=1\n        torch.cuda.empty_cache()\n        \n\n    prob = prob/count\n    prob = prob[..., :H, :W]\n\n    #save\n    np.save(f'prob.npy', prob)\n    cv2.imwrite(f'image.png', cv2.cvtColor(image, cv2.COLOR_RGB2BGR))\n\nrun_infer_demo()\nprint('infer ok!') ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-03T21:05:15.65638Z","iopub.execute_input":"2025-11-03T21:05:15.656641Z","iopub.status.idle":"2025-11-03T21:05:23.993193Z","shell.execute_reply.started":"2025-11-03T21:05:15.656619Z","shell.execute_reply":"2025-11-03T21:05:23.992545Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from post_process import *\n\ndef probability_to_gridpoint(probability, image=None):\n\tis_debug = True\n\tis_ok = True\n\n\tgp, gh, gv = probability[0], probability[1], probability[2]\n\t_3_, H, W = probability.shape\n\n\tcc = cc3d.connected_components(gp > 0.7)\n\tstats = cc3d.statistics(cc)\n\tpcenter = stats['centroids'][1:]\n\tprint('pcenter:', len(pcenter))  # 2492\n\n\t## label horizontal lines\n\thcc = np.zeros((H, W), dtype=np.uint8)\n\tcc = cc3d.connected_components(gh > 0.5)\n\tcc = cc3d.dust(\n        cc, threshold=1000,\n        connectivity=26, in_place=False\n    ) \n\tstats = cc3d.statistics(cc)\n\thcenter = stats['centroids'][1:]\n\tprint('hcenter', len(hcenter))  # 44\n\n\targsort = np.argsort(hcenter[:, 0])\n\tfor j, a in enumerate(argsort):\n\t\ty = hcenter[a, 0]\n\t\thcc[cc == a + 1] = j + 1\n\n\t## label vertical lines\n\tvcc = np.zeros((H, W), dtype=np.uint8)\n\tcc = cc3d.connected_components(gv > 0.5)\n\tcc = cc3d.dust(\n        cc, threshold=1000,\n        connectivity=26, in_place=False\n    ) \n\tstats = cc3d.statistics(cc)\n\tvcenter = stats['centroids'][1:]\n\tprint('vcenter', len(vcenter))  # 57\n\n\targsort = np.argsort(vcenter[:, 1])\n\tfor j, a in enumerate(argsort):\n\t\tx = vcenter[a, 1]\n\t\tvcc[cc == a + 1] = j + 1\n \n\n\t## meshing ...\n\tgridpoint_xy = np.zeros((44, 57, 2), np.float32)\n\n\t##--\n\t## filtering\n\t#   choose top/longest 44 horizontal lines ...\n \n\t# temporary ....\n\tif (len(pcenter) == 2492) & (len(hcenter) == 44) & (len(vcenter) == 57):\n\t\t## gridpoint\n\t\tfor y, x in pcenter:\n\t\t\tuy = ROUND(y)\n\t\t\tux = ROUND(x)\n\t\t\tj = hcc[uy, ux]\n\t\t\ti = vcc[uy, ux]\n\t\t\t# print(f'({x},{y}) --> ({j},{i})')\n\t\t\tgridpoint_xy[j - 1, i - 1] = [x, y]\n\telse:\n\t\tprint('filtering method not impelemnted yet ....!') \n\t\t#return None\n\n\n\treturn {\n\t\t'gridpoint_xy': gridpoint_xy,\n\t\t'vcc': vcc,\n\t\t'hcc': hcc,\n\t}\n\ndef draw_probability_point(probability, image):\n    gp = probability[0]\n    \n    threshed = gp > 0.7\n    cc = cc3d.connected_components(threshed)\n    stats = cc3d.statistics(cc)\n    centroid = stats['centroids'][1:]\n    print('centroid', len(centroid)) #2492\n    \n    overlay1= image//3\n    for y1,x1 in centroid:\n    \ty1 = ROUND(y1)\n    \tx1 = ROUND(x1)\n    \tcv2.circle(overlay1, (x1, y1), 10, color=[0, 255, 0], thickness=-1)\n        \n    return overlay1\n    \n######################################################################\n\nimage = cv2.imread('image.png', cv2.IMREAD_COLOR_RGB)\nprobability = np.load('prob.npy')\n\n#convert from unet probability into recification grid\nout = probability_to_gridpoint(probability, image)\ngridpoint_xy = out['gridpoint_xy']\n\nrectified = rectify_image(\n\timage, \n    gridpoint_xy\n    #interpolate_xy \n)\nplt.imshow(image); plt.show()\nprint('rectified')\nplt.imshow(rectified); plt.show()\nprint('rectified (zoom)')\nplt.imshow(rectified[-800:,:800]); plt.show()\n\n\n\n#option: these are for visualisation only\nprint('unet lines probability')\nmline, mpoint = draw_probability(probability) \nplt.imshow(RESIZE(mline)); plt.show()\n\nmpoint = draw_probability_point(probability, image) \nprint('unet points probability')\nplt.imshow(mpoint); plt.show()\n\n\n\nvcc = out['vcc']\nhcc = out['hcc']\nhcc1 = color_line(hcc, cmap='repeat')\nvcc2 = color_line(vcc, cmap='repeat')\nprint('clustered horizontal lines using connected component analysis cca')\nplt.imshow(RESIZE(hcc1)); plt.show()\nprint('clustered vertical lines using connected component analysis cca')\nplt.imshow(RESIZE(vcc2)); plt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-03T21:05:23.99387Z","iopub.execute_input":"2025-11-03T21:05:23.994076Z","iopub.status.idle":"2025-11-03T21:05:30.768312Z","shell.execute_reply.started":"2025-11-03T21:05:23.994059Z","shell.execute_reply":"2025-11-03T21:05:30.767527Z"}},"outputs":[],"execution_count":null}]}