{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":97984,"databundleVersionId":14096757,"sourceType":"competition"},{"sourceId":13533444,"sourceType":"datasetVersion","datasetId":8585840},{"sourceId":13574721,"sourceType":"datasetVersion","datasetId":8621452}],"dockerImageVersionId":31153,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## 1.Using Unet for pixel label","metadata":{}},{"cell_type":"code","source":"import sys\nsys.path.append('/kaggle/input/kaggle-physionet-hengck-demo-00')\n\nfrom model import *\nfrom dataset import *\nfrom config import *\n\nimport matplotlib\nimport matplotlib.pyplot as plt   \n\nprint('import ok!!!')","metadata":{"_uuid":"9f668f25-5c84-4eb9-b5a9-120441f74fed","_cell_guid":"3022f6ce-842c-48b5-b4a1-2157654584e7","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-11-01T11:13:24.949685Z","iopub.execute_input":"2025-11-01T11:13:24.949965Z","iopub.status.idle":"2025-11-01T11:13:24.955557Z","shell.execute_reply.started":"2025-11-01T11:13:24.949946Z","shell.execute_reply":"2025-11-01T11:13:24.954602Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"net = Net(pretrained=False)\nf = torch.load('/kaggle/input/kaggle-physionet-hengck-demo-00/checkpoint.pth', map_location=lambda storage, loc: storage)\nstate_dict = f['state_dict']\nprint(net.load_state_dict(state_dict, strict=False))  \n\nnet = net.eval()\nnet.output_type = ['infer']\n\n# dummy data ....\nKAGGLE_DIR = '/kaggle/input/physionet-ecg-image-digitization'\nclass ECGDataset(Dataset):\n\tdef __init__(self):\n\t\tself.length = 1000000\n\n\t\timage_id = 31294838\n\t\timage_file = f'{KAGGLE_DIR}/train/{image_id}/{image_id}-0001.png'\n\t\timage = cv2.imread(image_file, cv2.IMREAD_COLOR_RGB)\n\t\tcsv_file = f'{KAGGLE_DIR}/train/{image_id}/{image_id}.csv'\n\t\ttruth_df = pd.read_csv(csv_file)\n\n\t\tcrop = make_demo_crop(image)\n\t\tlead, horizontal, vertical = make_demo_mask(crop, truth_df)\n\t\tprint('crop:', crop.shape)\n\t\tprint('lead:', lead.shape)\n\t\tprint('horizontal:', horizontal.shape)\n\t\tprint('vertical:', vertical.shape)\n\t\tself.crop = crop\n\t\tself.lead = lead\n\t\tself.horizontal = horizontal\n\t\tself.vertical = vertical\n\n\tdef __len__(self):\n\t\treturn self.length\n\n\tdef __getitem__(self, index):\n\t\tout = train_transform(\n\t\t\timage=self.crop.copy(),\n\t\t\tmask=self.lead.copy(),\n\t\t\thorizontal=self.horizontal.copy(),\n\t\t\tvertical=self.vertical.copy(),\n\t\t)\n\t\tr = {}\n\t\tr['image'     ] = torch.from_numpy(np.ascontiguousarray(out['image'].transpose(2,0,1)))  # float32, normalized, CHW\n\t\tr['lead'] = torch.from_numpy(out['mask'])\n\t\tr['horizontal'] = torch.from_numpy(out['horizontal'])\n\t\tr['vertical'  ] = torch.from_numpy(out['vertical'])\n\t\treturn r\n\n# let's try some image ---------------------------------------------\nvalid_dataset = ECGDataset()\n\nnet = net.cuda()\nfor trial in range(3):\n\tprint(f'trial:{trial}')\n\tr = valid_dataset[np.random.choice(len(valid_dataset))]\n\tbatch = {\n\t\t'image':r['image'].unsqueeze(0),\n\t}\n\twith torch.amp.autocast('cuda', dtype=torch.bfloat16):\n\t\twith torch.no_grad():\n\t\t\toutput = net(batch)\n\n\n\tif 1:\n\t\timage = batch['image'].permute(0,2,3,1).contiguous().data.cpu().numpy()\n\t\thorizontal = output['horizontal'].argmax(1).byte().data.cpu().numpy()\n\t\tvertical = output['vertical'].argmax(1).byte().data.cpu().numpy()\n\t\tlead = output['lead'].argmax(1).byte().data.cpu().numpy()\n\n\t\tB = len(image)\n\t\tfor b in range(B):\n\t\t\tm = image[b]\n\t\t\th = horizontal[b]\n\t\t\tv = vertical[b]\n\t\t\tl = lead[b]\n\t\t\th = color_horizontal(h)\n\t\t\tv = color_vertical(v)\n\t\t\tl = color_lead(l)\n\n\t\t\tg = cv2.cvtColor(m, cv2.COLOR_RGB2GRAY)\n\t\t\tg = cv2.cvtColor(g, cv2.COLOR_GRAY2RGB)\n\t\t\toverlay = g.copy()\n\t\t\toverlay[h.sum(-1)!=0] =h[h.sum(-1)!=0]\n\t\t\toverlay[v.sum(-1)!=0] =v[v.sum(-1)!=0]\n\t\t\toverlay[l.sum(-1)!=0] =l[l.sum(-1)!=0]\n\n\t\t\tall = np.vstack([m,l,h,v])\n\n\t\t\tplt.imshow(overlay)\n\t\t\tplt.show()\n\t\t\tplt.imshow(all)\n\t\t\tplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-01T11:13:24.95677Z","iopub.execute_input":"2025-11-01T11:13:24.95699Z","iopub.status.idle":"2025-11-01T11:13:27.318525Z","shell.execute_reply.started":"2025-11-01T11:13:24.956972Z","shell.execute_reply":"2025-11-01T11:13:27.317686Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 2.Unwrap Mask to canonical reference","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport cv2\n\nimport torch\nimport torch.nn.functional as F\n\nimport matplotlib.pyplot as plt\nimport matplotlib\n\n\ndef rectify_image(\n\timage, gridpoint_xy\n):\n\tH, W = 1700, 2200 #reference size\n\tH1,W1 = image.shape[:2]\n\tsparse_map = gridpoint_xy/[[[W1-1,H1-1]]]*2 -1\n\tsparse_map = torch.from_numpy(np.ascontiguousarray(sparse_map.transpose(2, 0, 1))).unsqueeze(0).float()\n\tdense_map  = F.interpolate(sparse_map, size=(H, W), mode='bilinear', align_corners=True)\n\tdistort    = torch.from_numpy(np.ascontiguousarray(image.transpose(2, 0, 1))).unsqueeze(0).float()\n\trectified = F.grid_sample(\n\t\tdistort, dense_map.permute(0, 2, 3, 1), mode='bilinear', padding_mode='border', align_corners=False\n\t)\n\trectified = rectified.data.cpu().numpy()\n\trectified = rectified[0].transpose(1, 2, 0).astype(np.uint8)\n\treturn rectified\n\nkaggle_dir = '/kaggle/input/physionet-ecg-image-digitization'\nprocessed_dir = '/kaggle/input/hengck23-gridpoint-demo'\n\nall=[]\nimage_id ='4211091537'\nfor type_id in ['0005', '0006', '0012']: \n    print('type_id:', type_id)\n\n    image_file = f'{kaggle_dir}/train/{image_id}/{image_id}-{type_id}.png' \n    image = cv2.imread(image_file, cv2.IMREAD_COLOR_RGB)\n    gridpoint_xy = np.load(f'{processed_dir}/{image_id}-{type_id}.gridpoint_xy.npy' ) #detected grid point from unet ,,,\n    \n    rectified = rectify_image(\n    \timage, gridpoint_xy\n    )\n    \n    plt.imshow(image)\n    plt.show()\n    plt.imshow(rectified)\n    plt.show()\n    all.append(rectified[-1000:, 0:1000])\n\nprint('compare all results:')\nplt.imshow(np.hstack(all), aspect='equal')\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-01T11:15:35.375178Z","iopub.execute_input":"2025-11-01T11:15:35.375851Z","iopub.status.idle":"2025-11-01T11:15:42.634603Z","shell.execute_reply.started":"2025-11-01T11:15:35.375827Z","shell.execute_reply":"2025-11-01T11:15:42.633599Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 3.Mask to time series (lead signal)","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport cv2\nimport numpy as np\n\n\nimport matplotlib.pyplot as plt\nimport matplotlib\nimport torch\nimport torch.nn.functional as F\n\nimport sys\nsys.path.append('/kaggle/input/kaggle-physionet-hengck-demo-00')\nfrom kaggle_metric import *\ndef compute_one_snr(predict, truth, max_shift=100):\n\tt = truth\n\tp = predict\n\taligned = align_signals(t, p, max_shift)\n\tp_signal, p_noise = compute_power(t, aligned)\n\tsnr = compute_snr(p_signal, p_noise)\n\tsnr_db = max(float(10 * np.log10(snr)), -PERFECT_SCORE)\n\treturn snr_db\n\n\nKAGGLE_DIR = '/kaggle/input/physionet-ecg-image-digitization'\nGSY = 39.38095238095238 #height of grid 'square'\n\n\n#load dummy data\nimage_id = 31294838\nimage_file = f'{KAGGLE_DIR}/train/{image_id}/{image_id}-0001.png'\nimage = cv2.imread(image_file, cv2.IMREAD_COLOR_RGB)\ncsv_file = f'{KAGGLE_DIR}/train/{image_id}/{image_id}.csv'\ntruth_df = pd.read_csv(csv_file)\n\nH,W, _ = image.shape\n\n\n#example signal ------\nlead = 'I'\ny0 = 708  #zero mV\nx0,x1 = 118, 610  #start to end of signal\n\n\nt    = truth_df[lead].values\nmask = ~np.isnan(t)\nt    = t[mask]\nL = len(t)\nprint('lead:', lead, L)\n\noverlay = image.copy()\npoint=[]  #ground truth of pixel label\nfor i in range(0, L):\n\tpx = int(round(x0 + (i / (L-1)) * (x1 - x0-1)))\n\tpy = int(round(y0 - t[i] * 2 * GSY))\n\tpoint.append([px, py])\n\toverlay[py, px] = [0,255,0]\n\nprobility=np.zeros((H,W),np.float32) #probability from unet\nfor i in range(0, L-1):\n\tx0, y0 = point[i]\n\tx1, y1 = point[i+1]\n\tcv2.line(probility,(x0,y0),(x1,y1), 1,1)#, cv2.LINE_AA)\n\n#make a crop\nmy,mx=np.where(probility>0)\nmy0 = my.min()\nmy1 = my.max()+1\nmx0 = mx.min()\nmx1 = mx.max()+1\nprint('crop:', my0, my1, mx0, mx1)\n\ncrop = probility[my0:my1, mx0:mx1]\nplt.title('probability crop')\nplt.imshow(crop,cmap='gray')\nplt.show()\n\nplt.title('overlay crop')\nplt.imshow(overlay[my0:my1, mx0:mx1],)\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-01T11:13:35.382128Z","iopub.execute_input":"2025-11-01T11:13:35.382444Z","iopub.status.idle":"2025-11-01T11:13:36.152907Z","shell.execute_reply.started":"2025-11-01T11:13:35.382416Z","shell.execute_reply":"2025-11-01T11:13:36.151976Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def mask_to_signal(probility, num_sample, zero_mv,  mV_per_pixel):\n\tH, W = probility.shape\n\tm = torch.from_numpy(probility).float() #(mask > 0).float()\n\tidx = torch.arange(H, device=m.device).view(H, 1).to(m.dtype)  # (H,1)\n\tnum = (m * idx).sum(dim=0)  # sum of indices where mask==1, per column -> (W,)\n\tden = m.sum(dim=0)  # count of ones per column -> (W,)\n\tnon_zero_signal = num / den.clamp_min(1)  # avoid div-by-0 :\n\t## todo: use nan for missing instead ... then interpolate\n\n\tsignal = (zero_mv - non_zero_signal) * mV_per_pixel\n\tresampled = F.interpolate(\n\t\tsignal.view(1, 1, W), size=num_sample, mode=\"linear\", align_corners=False\n\t).view(-1) #todo: align_corners=False ???\n\tresampled = resampled.data.cpu().numpy()\n\treturn resampled\n\n\ntruth = t\nnum_sample = L\nzero_mv = 708-my0  #708 is the bottom of the dc pulse in image\nmV_per_pixel = 1/(2*GSY)\n\nresampled = mask_to_signal(crop, num_sample, zero_mv, mV_per_pixel)\n\nsnr = compute_one_snr(resampled, truth, max_shift=100)\nprint('snr', snr)\n\nplt.plot(resampled, label='resampled')\nplt.plot(t, label='truth')\nplt.legend()\nplt.show()","metadata":{"trusted":true,"execution":{"execution_failed":"2025-11-01T11:25:58.725Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\n#another example signal ------\n#lead = 'I'\n#y0 = 708  #zero mV\n#x0,x1 = 118, 610  #start to end of signal\n\nfor lead,y0,x0,x1 in [\n    ['aVR',708,  610, 1102],\n    ['V1', 708, 1102, 1594],\n    ['V4', 708, 1594, 2087],\n]:\n\n    t    = truth_df[lead].values\n    mask = ~np.isnan(t)\n    t    = t[mask]\n    L = len(t)\n    print('lead:', lead, L)\n    \n    overlay = image.copy()\n    point=[]  #ground truth of pixel label\n    for i in range(0, L):\n    \tpx = int(round(x0 + (i / (L-1)) * (x1 - x0-1)))\n    \tpy = int(round(y0 - t[i] * 2 * GSY))\n    \tpoint.append([px, py])\n    \toverlay[py, px] = [0,255,0]\n    \n    probility=np.zeros((H,W),np.float32) #probability from unet\n    for i in range(0, L-1):\n    \tx0, y0 = point[i]\n    \tx1, y1 = point[i+1]\n    \tcv2.line(probility,(x0,y0),(x1,y1), 1,1)#, cv2.LINE_AA)\n    \n    #make a crop\n    my,mx=np.where(probility>0)\n    my0 = my.min()\n    my1 = my.max()+1\n    mx0 = mx.min()\n    mx1 = mx.max()+1\n    print('crop:', my0, my1, mx0, mx1)\n    \n    crop = probility[my0:my1, mx0:mx1]\n    plt.title('probability crop')\n    plt.imshow(crop,cmap='gray')\n    plt.show()\n    \n    plt.title('overlay crop')\n    plt.imshow(overlay[my0:my1, mx0:mx1],)\n    plt.show()\n    \n    \n    truth = t\n    num_sample = L\n    zero_mv = 708-my0  #708 is the bottom of the dc pulse in image\n    mV_per_pixel = 1/(2*GSY)\n    \n    resampled = mask_to_signal(crop, num_sample, zero_mv, mV_per_pixel)\n    \n    snr = compute_one_snr(resampled, truth, max_shift=100)\n    print('snr', snr)\n    \n    plt.plot(resampled, label='resampled')\n    plt.plot(t, label='truth')\n    plt.legend()\n    plt.show()","metadata":{"trusted":true,"execution":{"execution_failed":"2025-11-01T11:25:58.726Z"}},"outputs":[],"execution_count":null}]}