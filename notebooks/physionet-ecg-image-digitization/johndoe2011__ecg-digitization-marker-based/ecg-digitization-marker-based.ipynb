{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":97984,"databundleVersionId":14096757,"sourceType":"competition"}],"dockerImageVersionId":31154,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport cv2\nimport numpy as np\nimport pandas as pd\nfrom tqdm import tqdm\nfrom collections import defaultdict\nfrom scipy.signal import medfilt\nimport scipy.signal\nimport scipy.optimize\n\n# ============================================================================\n# CONFIGURATION\n# ============================================================================\n\nLEADS = ['I', 'II', 'III', 'aVR', 'aVL', 'aVF', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6']\nMAX_TIME_SHIFT = 0.2\nPERFECT_SCORE = 384\n\n\nOUTLIER_LOW_THRESHOLD = -1.6\nOUTLIER_HIGH_THRESHOLD = 0.85\nMARKER_ARTIFACT_THRESHOLD = 0.2\nMEDIAN_FILTER_SIZE = 5\nIMAGE_BINARIZATION_THRESHOLD = 160\nSCALING_FACTOR = 80\nTAIL_CORRECTION_FACTOR = 2.0\n\nTRAIN_DIR = '/kaggle/input/physionet-ecg-image-digitization/train/'\nTEST_DIR = '/kaggle/input/physionet-ecg-image-digitization/test/'\n\n\ndef compute_power(label, prediction):\n    finite_mask = np.isfinite(prediction)\n    if not np.any(finite_mask):\n        return 0, 1\n    prediction = prediction.copy()\n    prediction[~np.isfinite(prediction)] = 0\n    noise = label - prediction\n    return np.sum(label**2), np.sum(noise**2)\n\ndef compute_snr(signal, noise):\n    if noise == 0: return PERFECT_SCORE\n    elif signal == 0: return 0\n    else: return min((signal / noise), PERFECT_SCORE)\n\ndef align_signals(label, pred, max_shift=float('inf')):\n    label_arr = np.asarray(label, dtype=np.float64)\n    pred_arr = np.asarray(pred, dtype=np.float64)\n    \n    correlation = scipy.signal.correlate(label_arr - np.mean(label_arr), \n                                        pred_arr - np.mean(pred_arr), mode='full')\n    lags = scipy.signal.correlation_lags(len(label_arr), len(pred_arr), mode='full')\n    valid_mask = (lags >= -max_shift) & (lags <= max_shift)\n    \n    best_idx = np.argmax(correlation[valid_mask])\n    time_shift = lags[valid_mask][best_idx]\n    \n    start_pad = max(time_shift, 0)\n    pred_start = max(-time_shift, 0)\n    pred_end = min(len(label_arr) - time_shift, len(pred_arr))\n    end_pad = max(len(label_arr) - len(pred_arr) - time_shift, 0)\n    \n    aligned_pred = np.concatenate((\n        np.full(start_pad, np.nan),\n        pred_arr[pred_start:pred_end],\n        np.full(end_pad, np.nan)\n    ))\n    \n    if np.any(np.isfinite(label_arr) & np.isfinite(aligned_pred)):\n        def objective(v): return np.nansum((label_arr - (aligned_pred - v)) ** 2)\n        result = scipy.optimize.minimize_scalar(objective, method='Brent')\n        aligned_pred -= result.x\n    \n    return aligned_pred\n\n\ndef fit_mean_model(train_df):\n    print(\"\\n Building fallback templates...\")\n    mean_dict = defaultdict(list)\n    \n    for idx, row in tqdm(train_df.iterrows(), total=len(train_df), desc=\"Processing\"):\n        csv_path = f'{TRAIN_DIR}{row.id}/{row.id}.csv'\n        if not os.path.exists(csv_path):\n            continue\n        \n        try:\n            labels = pd.read_csv(csv_path)\n            for lead in labels.columns:\n                values = labels[lead].dropna().values.astype(np.float32)\n                if len(values) < 50:\n                    continue\n                \n                values_norm = (values - values.mean()) / (values.std() + 1e-8)\n                values_resamp = np.interp(\n                    np.linspace(0, 1, 20000),\n                    np.linspace(0, 1, len(values_norm)),\n                    values_norm\n                )\n                mean_dict[lead].append(values_resamp)\n        except:\n            continue\n    \n    for lead in mean_dict.keys():\n        mean_dict[lead] = np.stack(mean_dict[lead])\n    \n    for lead in LEADS:\n        if lead not in mean_dict:\n            t = np.linspace(0, 1, 20000)\n            mean_dict[lead] = np.array([np.sin(2 * np.pi * t)])\n    \n    print(f\"✓ Fallback ready for {len(mean_dict)} leads\")\n    return mean_dict\n\n\nclass MarkerFinder:\n    \"\"\"Marker detection adapted for 1700x2200 format\"\"\"\n    \n    def __init__(self):\n        # Load reference images\n        ref_paths = [\n            f'{TRAIN_DIR}4292118763/4292118763-0001.png',\n            f'{TRAIN_DIR}4289880010/4289880010-0001.png',\n            f'{TRAIN_DIR}4284351157/4284351157-0001.png',\n        ]\n        \n        ref_images = [cv2.imread(p) for p in ref_paths if os.path.exists(p)]\n        if not ref_images:\n            self.templates = None\n            return\n        \n        ima = np.max(ref_images, axis=0)\n        \n   \n        self.scale_factor_1700 = 1700 / 1652\n        self.scale_factor_2200 = 2200 / 2132\n        \n        # Define marker positions (original coordinates)\n        absolute_points = np.zeros((17, 2), dtype=int)\n        for i in range(3):\n            absolute_points[5 * i] = np.array([707 + 284 * i, 118])\n            for j in range(1, 5):\n                absolute_points[5 * i + j] = np.array([707 + 284 * i, 118 + 492 * j])\n        absolute_points[15] = np.array([1535, 118])\n        absolute_points[16] = np.array([1535, 118 + 492 * 4])\n        \n        template_positions = [None] * 17\n        template_points = [None] * 17\n        \n        for i in range(len(absolute_points)):\n            if absolute_points[i][1] < 118 + 492 * 4:\n                if i % 5 == 0:\n                    template_positions[i] = (absolute_points[i][0] - 87, absolute_points[i][1] - 50)\n                else:\n                    template_positions[i] = (absolute_points[i][0] - 37, absolute_points[i][1] - 13)\n                template_points[i] = np.array([\n                    absolute_points[i][0] - template_positions[i][0],\n                    absolute_points[i][1] - template_positions[i][1]\n                ])\n        \n        template_sizes = np.array([(105, 60)] * 17)\n        \n        self.templates = [None] * 17\n        for i in range(len(template_positions)):\n            if template_positions[i] is not None:\n                template = ima[\n                    template_positions[i][0]:template_positions[i][0] + template_sizes[i][0],\n                    template_positions[i][1]:template_positions[i][1] + template_sizes[i][1]\n                ]\n                self.templates[i] = template\n        \n        self.template_positions = template_positions\n        self.template_sizes = template_sizes\n        self.template_points = template_points\n    \n    def find_markers(self, ima):\n        \"\"\"Find markers with scaling support for 1700x2200 images\"\"\"\n        if self.templates is None or self.templates[0] is None:\n            return None\n        \n        h, w = ima.shape[:2]\n        \n        # Calculate scale factors\n        scale_y = h / 1652\n        scale_x = w / 2132\n        \n        markers = [None] * 17\n        \n        for j in range(len(self.templates)):\n            if self.templates[j] is None:\n                continue\n            \n            try:\n                # Scale search region\n                t = int((self.template_positions[j][0] - 100) * scale_y)\n                l = max(int((self.template_positions[j][1] - 100) * scale_x), 0)\n                t_end = int((self.template_positions[j][0] + 100 + self.template_sizes[j][0]) * scale_y)\n                l_end = int((self.template_positions[j][1] + 250 + self.template_sizes[j][1]) * scale_x)\n                \n                search_range = ima[t:t_end, l:l_end]\n                \n                # Resize template to match scale\n                scaled_template = cv2.resize(\n                    self.templates[j],\n                    (int(self.template_sizes[j][1] * scale_x), \n                     int(self.template_sizes[j][0] * scale_y))\n                )\n                \n                res = cv2.matchTemplate(search_range, scaled_template, cv2.TM_CCOEFF)\n                _, max_val, _, max_loc = cv2.minMaxLoc(res)\n                \n                top_left = max_loc\n                markers[j] = np.array((\n                    t + top_left[1] + int(self.template_points[j][0] * scale_y),\n                    l + top_left[0] + int(self.template_points[j][1] * scale_x)\n                ))\n            except:\n                continue\n        \n        # Interpolate missing markers\n        for i in range(3):\n            if markers[5 * i + 3] is not None and markers[5 * i + 2] is not None:\n                markers[5 * i + 4] = markers[5 * i + 3] * 2 - markers[5 * i + 2]\n        \n        if markers[14] is not None and markers[9] is not None:\n            markers[16] = ((markers[14] * (284 + 260) - markers[9] * 260) / 284).astype(int)\n        \n        return markers\n    \n    @staticmethod\n    def lead_info(lead):\n        mapping = {\n            'I': (0, 1), 'II-subset': (5, 6), 'III': (10, 11),\n            'aVR': (1, 2), 'aVL': (6, 7), 'aVF': (11, 12),\n            'V1': (2, 3), 'V2': (7, 8), 'V3': (12, 13),\n            'V4': (3, 4), 'V5': (8, 9), 'V6': (13, 14),\n            'II': (15, 16),\n        }\n        begin, end = mapping[lead]\n        return begin // 5, begin, end\n\n\ndef find_line_by_topdown_sweep(ima):\n    \"\"\"Extract signal boundaries\"\"\"\n    top = np.argmin(ima, axis=0)\n    median_top = int(np.median(top))\n    top[top == 0] = median_top\n    top[top > median_top + 300] = median_top\n    \n    strip_width = 64\n    for strip_left in range(0, ima.shape[1], strip_width):\n        median_top_strip = int(np.median(top[strip_left:strip_left + strip_width]))\n        if median_top_strip > median_top + 300:\n            median_top_strip = median_top\n        \n        strip = ima[median_top_strip + 80:, strip_left:strip_left + strip_width]\n        all_white = strip.all(axis=1)\n        \n        if all_white.size > 0:\n            first_white_row = np.argmax(all_white)\n            if first_white_row > 0 or all_white[0]:\n                first_white_row += median_top_strip + 80\n                mask = top > first_white_row\n                mask[:strip_left] = False\n                mask[strip_left + strip_width:] = False\n                top[mask] = median_top_strip\n    \n    mask = np.tile(np.arange(len(ima)).reshape(-1, 1), reps=(1, ima.shape[1]))\n    mask = mask >= top\n    ima &= mask\n    \n    bottom = np.argmax(ima, axis=0)\n    bottomx = np.maximum(bottom, np.median(top) + 100)\n    mask = np.tile(np.arange(len(ima)).reshape(-1, 1), reps=(1, ima.shape[1]))\n    mask = mask < bottomx\n    ima |= mask\n    ima[:, :-1] |= mask[:, 1:]\n    ima[:, 1:] |= mask[:, :-1]\n    \n    return top, bottom\n\ndef get_lead_from_top_bottom(tops, bottoms, lead, number_of_rows, markers):\n    \"\"\"Extract lead signal from boundaries\"\"\"\n    line, begin, end = MarkerFinder.lead_info(lead)\n    top = tops[line]\n    bottom = bottoms[line]\n    begin, end = markers[begin], markers[end]\n    \n    baseline = np.linspace(begin[0], end[0], end[1] - begin[1])\n    pred0 = (top[begin[1]:end[1]] + bottom[begin[1]:end[1]]) / 2\n    \n    if len(pred0) < len(baseline):\n        baseline = baseline[:len(pred0)]\n    \n    pred = baseline - pred0\n    pred /= SCALING_FACTOR\n    \n    # Remove marker artifacts\n    if lead in ['aVR', 'aVL', 'aVF', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6']:\n        pred[:4] = np.where(pred[:4] > MARKER_ARTIFACT_THRESHOLD, pred[4], pred[:4])\n    if lead in ['I', 'II-subset', 'III', 'aVR', 'aVL', 'aVF', 'V1', 'V2', 'V3']:\n        pred[-5:] = np.where(pred[-5:] > MARKER_ARTIFACT_THRESHOLD, pred[-6], pred[-5:])\n    if lead in ['I', 'II-subset', 'III', 'II']:\n        pred[:2] = pred[2]\n    \n    pred = np.interp(np.linspace(0, 1, number_of_rows),\n                     np.linspace(0, 1, len(pred)), pred)\n    \n    # Adaptive outlier removal\n    outlier_mask = (pred < OUTLIER_LOW_THRESHOLD) | (pred > OUTLIER_HIGH_THRESHOLD)\n    if np.any(outlier_mask):\n        for i in np.where(outlier_mask)[0]:\n            start_idx = max(0, i - 3)\n            end_idx = min(len(pred), i + 4)\n            neighbors = pred[start_idx:end_idx]\n            valid_neighbors = neighbors[\n                (neighbors >= OUTLIER_LOW_THRESHOLD) & \n                (neighbors <= OUTLIER_HIGH_THRESHOLD)\n            ]\n            if len(valid_neighbors) > 0:\n                pred[i] = np.median(valid_neighbors)\n            else:\n                pred[i] = 0\n    \n    pred = medfilt(pred, kernel_size=MEDIAN_FILTER_SIZE)\n    \n    # Tail correction\n    if lead == 'II':\n        n_tail = number_of_rows // 48\n        tail_values = pred[-n_tail:]\n        tail_median = np.median(tail_values)\n        tail_std = np.std(tail_values)\n        threshold = min(OUTLIER_HIGH_THRESHOLD, tail_median + TAIL_CORRECTION_FACTOR * tail_std)\n        pred[-n_tail:] = np.where(np.abs(pred[-n_tail:]) <= threshold, pred[-n_tail:], tail_median)\n    \n    if lead in ['V4', 'V5', 'V6']:\n        n_tail = number_of_rows // 12\n        tail_values = pred[-n_tail:]\n        tail_median = np.median(tail_values)\n        tail_std = np.std(tail_values)\n        threshold = min(OUTLIER_HIGH_THRESHOLD, tail_median + TAIL_CORRECTION_FACTOR * tail_std)\n        pred[-n_tail:] = np.where(np.abs(pred[-n_tail:]) <= threshold, pred[-n_tail:], tail_median)\n    \n    return pred\n\ndef apply_einthoven(preds):\n    \"\"\"Apply Einthoven's law\"\"\"\n    residual = preds['I'] + preds['III'] - preds['II'][:len(preds['III'])]\n    correction = residual / 3\n    preds['I'] -= correction\n    preds['III'] -= correction\n    preds['II'][:len(preds['III'])] += correction\n    \n    residual = preds['aVR'] + preds['aVL'] + preds['aVF']\n    correction = residual / 3\n    preds['aVR'] -= correction\n    preds['aVL'] -= correction\n    preds['aVF'] -= correction\n    \n    residual = (2 * preds['aVR'] - 2 * preds['aVF'] + \n                3 * preds['II'][len(preds['I']):len(preds['I']) + len(preds['aVR'])])\n    correction = residual / 17\n    preds['aVR'] -= 2 * correction\n    preds['aVF'] += 2 * correction\n    preds['II'][len(preds['I']):len(preds['I']) + len(preds['aVR'])] -= 3 * correction\n\ndef convert_scanned_color(ima, markers, n_timesteps):\n    \"\"\"Convert image to signals using marker-based extraction\"\"\"\n    crop_top = int(400 * (ima.shape[0] / 1652))  # Scale crop\n    \n    # Use red channel and binarize\n    ima = ima[crop_top:, :, 2] > IMAGE_BINARIZATION_THRESHOLD\n    \n    # Morphological smoothing\n    iima = ima.astype(np.uint8)\n    ima = (iima[:-2, :-2] + iima[:-2, 1:-1] + iima[:-2, 2:] +\n           iima[1:-1, :-2] + iima[1:-1, 1:-1] + iima[1:-1, 2:] +\n           iima[2:, :-2] + iima[2:, 1:-1] + iima[2:, 2:]) >= 7\n    \n    tops, bottoms = [], []\n    for i in range(4):\n        top, bottom = find_line_by_topdown_sweep(ima)\n        tops.append(top)\n        bottoms.append(bottom)\n    \n    tops = [t + crop_top for t in tops]\n    bottoms = [b + crop_top for b in bottoms]\n    \n    n_timesteps['II-subset'] = n_timesteps['I']\n    preds = {}\n    for lead in LEADS + ['II-subset']:\n        pred = get_lead_from_top_bottom(tops, bottoms, lead, n_timesteps[lead], markers)\n        preds[lead] = pred\n    \n    preds['II'][:len(preds['II-subset'])] = (\n        preds['II'][:len(preds['II-subset'])] + preds['II-subset']\n    ) / 2\n    del preds['II-subset']\n    \n    apply_einthoven(preds)\n    \n    return preds\n\ndef is_color_image(ima):\n    return ima.std(axis=2).mean() != 0\n\n\ndef main():\n\n    train = pd.read_csv('/kaggle/input/physionet-ecg-image-digitization/train.csv')\n    test = pd.read_csv('/kaggle/input/physionet-ecg-image-digitization/test.csv')\n    print(f\"\\n Data: {len(train)} train, {len(test)} test\")\n    \n    mean_dict = fit_mean_model(train)\n    \n \n    mf = MarkerFinder()\n    \n    # Validation\n    print(\"\\n Validating on holdout set...\")\n    val_split = int(len(train) * 0.8)\n    val_df = train.iloc[val_split:]\n    \n    snr_list = []\n    for idx, row in tqdm(val_df.iterrows(), total=len(val_df), desc=\"Validating\"):\n        csv_path = f'{TRAIN_DIR}{row.id}/{row.id}.csv'\n        img_path = f'{TRAIN_DIR}{row.id}/{row.id}-0001.png'\n        \n        if not os.path.exists(csv_path) or not os.path.exists(img_path):\n            continue\n        \n        try:\n            ima = cv2.imread(img_path)\n            if not is_color_image(ima):\n                continue\n            \n            markers = mf.find_markers(ima)\n            if markers is None or sum(1 for m in markers if m is not None) < 10:\n                continue\n            \n            n_timesteps = {lead: row.fs * 10 if lead == 'II' else row.fs * 10 // 4 for lead in LEADS}\n            preds = convert_scanned_color(ima, markers, n_timesteps)\n            \n            labels = pd.read_csv(csv_path)\n            sum_signal = 0\n            sum_noise = 0\n            \n            for lead in labels.columns:\n                label = labels[lead].dropna().values\n                if len(label) == 0:\n                    continue\n                \n                pred = preds[lead][:len(label)]\n                aligned_pred = align_signals(label, pred, int(row.fs * MAX_TIME_SHIFT))\n                p_signal, p_noise = compute_power(label, aligned_pred)\n                sum_signal += p_signal\n                sum_noise += p_noise\n            \n            snr = compute_snr(sum_signal, sum_noise)\n            snr_list.append(snr)\n        except:\n            continue\n    \n    if snr_list:\n        mean_snr = np.mean(snr_list)\n        val_score = max(10 * np.log10(mean_snr), -PERFECT_SCORE)\n        print(f\"\\n✓ Validated on {len(snr_list)} samples\")\n        print(f\"✓ Mean SNR: {mean_snr:.4f}\")\n        print(f\"✓ Validation Score: {val_score:.2f} dB\\n\")\n    else:\n        print(\"\\n No successful validations\\n\")\n    \n    print(\"\\n Processing...\")\n    submission_data = []\n    old_id = None\n    processed = 0\n    fallback = 0\n    \n    for idx, row in tqdm(test.iterrows(), total=len(test), desc=\"Extracting\"):\n        if row.id != old_id:\n            path = f\"{TEST_DIR}{row.id}.png\"\n            ima = cv2.imread(path)\n            \n            if is_color_image(ima):\n                try:\n                    markers = mf.find_markers(ima)\n                    if markers is not None and sum(1 for m in markers if m is not None) >= 10:\n                        n_timesteps = {lead: row.fs * 10 if lead == 'II' else row.fs * 10 // 4 for lead in LEADS}\n                        preds = convert_scanned_color(ima, markers, n_timesteps)\n                        processed += 1\n                    else:\n                        preds = None\n                        fallback += 1\n                except:\n                    preds = None\n                    fallback += 1\n            else:\n                preds = None\n                fallback += 1\n            \n            old_id = row.id\n        \n        if preds is not None:\n            pred = preds[row.lead]\n        else:\n            pred = mean_dict[row.lead].mean(axis=0)\n            pred = np.interp(np.linspace(0, 1, row.number_of_rows),\n                           np.linspace(0, 1, len(pred)), pred)\n        \n        for timestep in range(row.number_of_rows):\n            signal_id = f\"{row.id}_{timestep}_{row.lead}\"\n            submission_data.append({'id': signal_id, 'value': float(pred[timestep])})\n    \n    print(f\"\\n Processed: {processed} | Fallback: {fallback}\")\n    \n    submission = pd.DataFrame(submission_data)\n    submission.to_csv('submission.csv', index=False)\n    print(f\" Saved: {len(submission):,} predictions\")\n    print(f\"   Range: [{submission['value'].min():.4f}, {submission['value'].max():.4f}]\")\n   \n\nif __name__ == \"__main__\":\n    main()","metadata":{"_uuid":"c26e2b57-bcda-448f-bd2d-f4d49c0ed696","_cell_guid":"8300733c-e27c-4df0-a105-c96656792311","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-10-30T20:28:35.851574Z","iopub.execute_input":"2025-10-30T20:28:35.852175Z","iopub.status.idle":"2025-10-30T20:30:58.346883Z","shell.execute_reply.started":"2025-10-30T20:28:35.852149Z","shell.execute_reply":"2025-10-30T20:30:58.34616Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}