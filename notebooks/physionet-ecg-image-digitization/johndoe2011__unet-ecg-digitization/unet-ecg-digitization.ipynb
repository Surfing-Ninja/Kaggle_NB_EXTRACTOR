{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[],"toc_visible":true},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":97984,"databundleVersionId":14096757,"isSourceIdPinned":false,"sourceType":"competition"},{"sourceId":13570322,"sourceType":"datasetVersion","datasetId":8620697}],"dockerImageVersionId":31154,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport cv2\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision.models import efficientnet_b0\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2\nimport os\nfrom tqdm import tqdm\nimport time\nfrom scipy.signal import savgol_filter\nimport math","metadata":{"_uuid":"081e1eaf-6a09-47d1-9974-59b42d8ccfa6","_cell_guid":"dc4f814c-ecec-435a-863c-e384d7ccc691","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-10-31T17:04:03.942307Z","iopub.execute_input":"2025-10-31T17:04:03.942513Z","iopub.status.idle":"2025-10-31T17:04:14.613314Z","shell.execute_reply.started":"2025-10-31T17:04:03.942483Z","shell.execute_reply":"2025-10-31T17:04:14.612605Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"KAGGLE_DIR = \"/kaggle/input/physionet-ecg-image-digitization\"\nEFFICIENTNET_PATH = \"/kaggle/input/efficientnet-b0/efficientnet_b0_rwightman-7f5810bc.pth\"\nTRAIN_CSV = os.path.join(KAGGLE_DIR, \"train.csv\")\nTEST_CSV = os.path.join(KAGGLE_DIR, \"test.csv\")\nSUBMISSION_CSV = os.path.join(KAGGLE_DIR, \"sample_submission.parquet\")\nTRAIN_DIR = os.path.join(KAGGLE_DIR, \"train\")\nTEST_DIR = os.path.join(KAGGLE_DIR, \"test\")\n\ntrain_meta = pd.read_csv(TRAIN_CSV)\ntest_meta = pd.read_csv(TEST_CSV)\nsubmission_template = pd.read_parquet(SUBMISSION_CSV)\n\nprint(f\"Training samples: {len(train_meta)}\")\nprint(f\"Test samples: {len(test_meta)}\")","metadata":{"_uuid":"096695a0-7e12-4636-bd9d-36d63d91d5a8","_cell_guid":"3d9a22ae-e55e-4014-89b8-15e4e030d978","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-10-31T17:04:14.615048Z","iopub.execute_input":"2025-10-31T17:04:14.615432Z","iopub.status.idle":"2025-10-31T17:04:14.821457Z","shell.execute_reply.started":"2025-10-31T17:04:14.615412Z","shell.execute_reply":"2025-10-31T17:04:14.820674Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def compute_snr(original, reconstructed, max_shift=50):\n    \"\"\"Compute Signal-to-Noise Ratio with optimal alignment\"\"\"\n    if len(original) != len(reconstructed):\n        min_len = min(len(original), len(reconstructed))\n        original = original[:min_len]\n        reconstructed = reconstructed[:min_len]\n    \n    if len(original) == 0:\n        return 0\n    \n    best_snr = -np.inf\n    \n    for shift in range(-max_shift, max_shift + 1):\n        if shift >= 0:\n            rec_shifted = reconstructed[shift:]\n            orig_shifted = original[:len(rec_shifted)]\n        else:\n            rec_shifted = reconstructed[:len(reconstructed) + shift]\n            orig_shifted = original[-shift:len(rec_shifted) - shift]\n        \n        if len(rec_shifted) > 100:\n            signal_power = np.mean(orig_shifted ** 2)\n            noise_power = np.mean((rec_shifted - orig_shifted) ** 2)\n            \n            if noise_power > 1e-10 and signal_power > 1e-10:\n                snr = 10 * np.log10(signal_power / noise_power)\n                if snr > best_snr:\n                    best_snr = snr\n    \n    return best_snr if best_snr != -np.inf else 0\n\ndef compute_rmse(original, reconstructed):\n    \"\"\"Compute Root Mean Square Error\"\"\"\n    if len(original) != len(reconstructed):\n        min_len = min(len(original), len(reconstructed))\n        original = original[:min_len]\n        reconstructed = reconstructed[:min_len]\n    \n    if len(original) == 0:\n        return 0\n    \n    valid_mask = ~(np.isnan(original) | np.isnan(reconstructed) | np.isinf(original) | np.isinf(reconstructed))\n    if np.sum(valid_mask) == 0:\n        return 0\n    \n    original_clean = original[valid_mask]\n    reconstructed_clean = reconstructed[valid_mask]\n    \n    return np.sqrt(np.mean((original_clean - reconstructed_clean) ** 2))\n\ndef compute_correlation(original, reconstructed):\n    \"\"\"Compute Pearson correlation coefficient\"\"\"\n    if len(original) != len(reconstructed):\n        min_len = min(len(original), len(reconstructed))\n        original = original[:min_len]\n        reconstructed = reconstructed[:min_len]\n    \n    if len(original) < 2:\n        return 0\n    \n    valid_mask = ~(np.isnan(original) | np.isnan(reconstructed) | np.isinf(original) | np.isinf(reconstructed))\n    if np.sum(valid_mask) < 2:\n        return 0\n    \n    original_clean = original[valid_mask]\n    reconstructed_clean = reconstructed[valid_mask]\n    \n    return np.corrcoef(original_clean, reconstructed_clean)[0, 1]","metadata":{"_uuid":"618fcb10-da0a-4512-8456-03727ab47981","_cell_guid":"120b53a6-7560-411f-a4b3-68fdad726414","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-10-31T17:04:14.82243Z","iopub.execute_input":"2025-10-31T17:04:14.822719Z","iopub.status.idle":"2025-10-31T17:04:14.832229Z","shell.execute_reply.started":"2025-10-31T17:04:14.822691Z","shell.execute_reply":"2025-10-31T17:04:14.831505Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class StableECGDataset(Dataset):\n    def __init__(self, meta_df, data_dir, split='train', transform=None, max_samples=None, img_size=224):\n        self.meta_df = meta_df.copy()\n        self.data_dir = data_dir\n        self.split = split\n        self.transform = transform\n        self.img_size = img_size\n        \n        if max_samples:\n            self.meta_df = self.meta_df.sample(n=min(max_samples, len(self.meta_df))).reset_index(drop=True)\n        \n        self.leads = ['I', 'II', 'III', 'aVR', 'aVL', 'aVF', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6']\n        self.lead_durations = {'II': 10.0, **{lead: 2.5 for lead in self.leads if lead != 'II'}}\n        \n    def __len__(self):\n        return len(self.meta_df)\n    \n    def load_image(self, ecg_id):\n        if self.split == 'test':\n            image_file = f\"{self.data_dir}/{ecg_id}.png\"\n            if os.path.exists(image_file):\n                image = cv2.imread(image_file, cv2.IMREAD_COLOR)\n                if image is not None:\n                    return cv2.resize(image, (self.img_size, self.img_size))\n        else:\n            for idx in range(1, 13):\n                image_file = f\"{self.data_dir}/{ecg_id}/{ecg_id}-{idx:04d}.png\"\n                if os.path.exists(image_file):\n                    image = cv2.imread(image_file, cv2.IMREAD_COLOR)\n                    if image is not None:\n                        return cv2.resize(image, (self.img_size, self.img_size))\n        \n        return np.ones((self.img_size, self.img_size, 3), dtype=np.uint8) * 128\n    \n    def load_ground_truth(self, ecg_id):\n        gt_file = f\"{self.data_dir}/{ecg_id}/{ecg_id}.csv\"\n        if os.path.exists(gt_file):\n            return pd.read_csv(gt_file)\n        return None\n    \n    def __getitem__(self, idx):\n        row = self.meta_df.iloc[idx]\n        ecg_id = row['id']\n        fs = row['fs']\n        \n        image = self.load_image(ecg_id)\n        \n        if self.split == 'test':\n            target_lead = row['lead']\n            \n            if self.transform:\n                transformed = self.transform(image=image)\n                image_tensor = transformed['image']\n            else:\n                image_tensor = torch.from_numpy(image).permute(2, 0, 1).float() / 255.0\n            \n            return {\n                'image': image_tensor,\n                'ecg_id': ecg_id,\n                'fs': fs,\n                'target_lead': target_lead\n            }\n        else:\n            ground_truth = self.load_ground_truth(ecg_id)\n            \n            lead_signals = {}\n            for lead in self.leads:\n                if ground_truth is not None and lead in ground_truth.columns:\n                    duration = self.lead_durations[lead]\n                    expected_length = int(math.floor(fs * duration))\n                    signal = ground_truth[lead].values.astype(np.float32)\n                    \n                    if len(signal) > expected_length:\n                        signal = signal[:expected_length]\n                    elif len(signal) < expected_length:\n                        signal = np.pad(signal, (0, expected_length - len(signal)), mode='constant')\n                    \n                    signal = np.nan_to_num(signal, nan=0.0)\n                    signal = (signal - signal.mean()) / (signal.std() + 1e-8)\n                    lead_signals[lead] = signal\n                else:\n                    lead_signals[lead] = np.zeros(2500, dtype=np.float32)\n            \n            if self.transform:\n                transformed = self.transform(image=image)\n                image_tensor = transformed['image']\n            else:\n                image_tensor = torch.from_numpy(image).permute(2, 0, 1).float() / 255.0\n            \n            return {\n                'image': image_tensor,\n                'signals': lead_signals,\n                'ecg_id': ecg_id,\n                'fs': fs\n            }","metadata":{"_uuid":"52b094f0-07a3-4bb2-a77f-da5c832e5bab","_cell_guid":"dc4b0961-34bb-4ef3-bd7a-9969d9238dbb","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-10-31T17:04:14.832878Z","iopub.execute_input":"2025-10-31T17:04:14.833091Z","iopub.status.idle":"2025-10-31T17:04:14.85288Z","shell.execute_reply.started":"2025-10-31T17:04:14.833067Z","shell.execute_reply":"2025-10-31T17:04:14.852223Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class StableECGModel(nn.Module):\n    def __init__(self, num_leads=12, signal_length=2500):\n        super(StableECGModel, self).__init__()\n        \n        self.backbone = efficientnet_b0()\n        \n        checkpoint = torch.load(EFFICIENTNET_PATH)\n        self.backbone.load_state_dict(checkpoint)\n        \n        self.backbone.features[0][0] = nn.Conv2d(3, 32, kernel_size=3, stride=2, padding=1, bias=False)\n        in_features = self.backbone.classifier[1].in_features\n        self.backbone.classifier = nn.Identity()\n        \n        self.shared_encoder = nn.Sequential(\n            nn.Linear(in_features, 1024),\n            nn.BatchNorm1d(1024),\n            nn.ReLU(inplace=True),\n            nn.Dropout(0.3),\n            nn.Linear(1024, 512),\n            nn.BatchNorm1d(512),\n            nn.ReLU(inplace=True),\n            nn.Dropout(0.2),\n        )\n        \n        self.lead_heads = nn.ModuleDict()\n        for lead in ['I', 'II', 'III', 'aVR', 'aVL', 'aVF', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6']:\n            self.lead_heads[lead] = nn.Linear(512, signal_length)\n        \n        self._initialize_weights()\n    \n    def _initialize_weights(self):\n        for m in self.modules():\n            if isinstance(m, nn.Linear):\n                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n                if m.bias is not None:\n                    nn.init.constant_(m.bias, 0)\n    \n    def forward(self, x):\n        features = self.backbone(x)\n        encoded = self.shared_encoder(features)\n        \n        outputs = {}\n        for lead, head in self.lead_heads.items():\n            outputs[lead] = head(encoded)\n        \n        return outputs","metadata":{"_uuid":"5c29fea2-4be5-4c5b-a721-9d4c2fd25851","_cell_guid":"e1230aa1-47de-46a1-b3f0-5b59da693f8a","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-10-31T17:04:14.853558Z","iopub.execute_input":"2025-10-31T17:04:14.853753Z","iopub.status.idle":"2025-10-31T17:04:14.870482Z","shell.execute_reply.started":"2025-10-31T17:04:14.853737Z","shell.execute_reply":"2025-10-31T17:04:14.869844Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def get_stable_transforms(img_size=224):\n    train_transform = A.Compose([\n        A.Resize(img_size, img_size),\n        A.HorizontalFlip(p=0.3),\n        A.RandomBrightnessContrast(brightness_limit=0.1, contrast_limit=0.1, p=0.3),\n        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n        ToTensorV2()\n    ])\n    \n    test_transform = A.Compose([\n        A.Resize(img_size, img_size),\n        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n        ToTensorV2()\n    ])\n    \n    return train_transform, test_transform","metadata":{"_uuid":"e9b2865f-8d64-43cd-b395-2b42b21ab09a","_cell_guid":"7648a5db-5457-43d9-8bfb-6ebd9c50d208","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-10-31T17:04:14.87124Z","iopub.execute_input":"2025-10-31T17:04:14.871487Z","iopub.status.idle":"2025-10-31T17:04:14.887383Z","shell.execute_reply.started":"2025-10-31T17:04:14.871461Z","shell.execute_reply":"2025-10-31T17:04:14.886702Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class StableECGLoss(nn.Module):\n    def __init__(self):\n        super(StableECGLoss, self).__init__()\n        self.mse_loss = nn.MSELoss()\n        \n    def forward(self, predictions, targets):\n        total_loss = 0\n        lead_count = 0\n        \n        for lead in predictions.keys():\n            if lead in targets:\n                pred_signal = predictions[lead]\n                target_signal = targets[lead]\n                \n                valid_mask = ~torch.isnan(target_signal) & ~torch.isinf(target_signal)\n                if valid_mask.sum() > 0:\n                    pred_clean = pred_signal[valid_mask]\n                    target_clean = target_signal[valid_mask]\n                    \n                    loss = self.mse_loss(pred_clean, target_clean)\n                    total_loss += loss\n                    lead_count += 1\n        \n        return total_loss / max(lead_count, 1)","metadata":{"_uuid":"58db1a99-c284-4335-b17d-22582dbca6df","_cell_guid":"5ee96fcc-39dc-4e9c-81e7-4ef699623370","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-10-31T17:04:14.88967Z","iopub.execute_input":"2025-10-31T17:04:14.890132Z","iopub.status.idle":"2025-10-31T17:04:14.902171Z","shell.execute_reply.started":"2025-10-31T17:04:14.890113Z","shell.execute_reply":"2025-10-31T17:04:14.901635Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(f\"Using device: {device}\")\n\nmodel = StableECGModel(num_leads=12, signal_length=2500).to(device)\n\noptimizer = optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-4)\n\ncriterion = StableECGLoss()\n\nprint(f\"Model parameters: {sum(p.numel() for p in model.parameters()):,}\")","metadata":{"_uuid":"cd560c2e-9974-4556-83b6-fadd815ec95b","_cell_guid":"cc7b186b-8687-44a3-9d58-fb3447e06142","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-10-31T17:04:14.902791Z","iopub.execute_input":"2025-10-31T17:04:14.903064Z","iopub.status.idle":"2025-10-31T17:04:15.943646Z","shell.execute_reply.started":"2025-10-31T17:04:14.903041Z","shell.execute_reply":"2025-10-31T17:04:15.94292Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def stable_collate_fn(batch):\n    batch_dict = {}\n    \n    for key in batch[0].keys():\n        if key == 'signals':\n            signals_dict = {}\n            for lead in batch[0]['signals'].keys():\n                signal_list = []\n                for item in batch:\n                    signal = item['signals'][lead].copy()\n                    signal = np.nan_to_num(signal, nan=0.0)\n                    if len(signal) < 2500:\n                        signal = np.pad(signal, (0, 2500 - len(signal)), mode='constant')\n                    elif len(signal) > 2500:\n                        signal = signal[:2500]\n                    signal_list.append(torch.from_numpy(signal))\n                signals_dict[lead] = torch.stack(signal_list)\n            batch_dict[key] = signals_dict\n        else:\n            values = [item[key] for item in batch]\n            if isinstance(values[0], torch.Tensor):\n                batch_dict[key] = torch.stack(values)\n            else:\n                batch_dict[key] = values\n    \n    return batch_dict","metadata":{"_uuid":"a6c0fd8f-6ad5-4d6b-a2e3-8378987f9495","_cell_guid":"0e5df54a-b813-43f4-bdd6-8def05909fb0","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-10-31T17:04:15.94437Z","iopub.execute_input":"2025-10-31T17:04:15.944579Z","iopub.status.idle":"2025-10-31T17:04:15.950521Z","shell.execute_reply.started":"2025-10-31T17:04:15.944563Z","shell.execute_reply":"2025-10-31T17:04:15.949832Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def train_epoch_stable(model, train_loader, criterion, optimizer, device):\n    model.train()\n    total_loss = 0\n    batch_count = 0\n    \n    pbar = tqdm(train_loader, desc=\"Training\")\n    \n    for batch_idx, batch in enumerate(pbar):\n        images = batch['image'].to(device)\n        signals = batch['signals']\n        \n        optimizer.zero_grad()\n        \n        predictions = model(images)\n        \n        signal_targets = {}\n        for lead in predictions.keys():\n            signal_targets[lead] = signals[lead].to(device)\n        \n        loss = criterion(predictions, signal_targets)\n        \n        if torch.isnan(loss) or torch.isinf(loss):\n            continue\n        \n        loss.backward()\n        \n        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n        \n        optimizer.step()\n        \n        total_loss += loss.item()\n        batch_count += 1\n        \n        if batch_idx % 5 == 0:\n            pbar.set_postfix({\n                'Loss': f\"{loss.item():.4f}\",\n                'AvgLoss': f\"{total_loss/batch_count:.4f}\"\n            })\n    \n    return total_loss / batch_count if batch_count > 0 else float('inf')","metadata":{"_uuid":"a47fc787-6403-48ef-9a08-90890c11c9db","_cell_guid":"afa47375-4493-42f4-8a70-ec7c2174d0f4","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-10-31T17:04:15.951275Z","iopub.execute_input":"2025-10-31T17:04:15.951455Z","iopub.status.idle":"2025-10-31T17:04:15.967712Z","shell.execute_reply.started":"2025-10-31T17:04:15.951429Z","shell.execute_reply":"2025-10-31T17:04:15.967048Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def evaluate_model_stable(model, val_loader, device):\n    \"\"\"Evaluate model performance with multiple metrics\"\"\"\n    model.eval()\n    all_snrs = []\n    all_rmses = []\n    all_correlations = []\n    \n    with torch.no_grad():\n        for batch in val_loader:\n            images = batch['image'].to(device)\n            signals = batch['signals']\n            \n            predictions = model(images)\n            \n            for lead in predictions.keys():\n                if lead in signals:\n                    pred_signal = predictions[lead].cpu().numpy()\n                    true_signal = signals[lead].cpu().numpy()\n                    \n                    for i in range(pred_signal.shape[0]):\n                        pred = pred_signal[i]\n                        true = true_signal[i]\n                        \n                        pred = np.nan_to_num(pred, nan=0.0)\n                        true = np.nan_to_num(true, nan=0.0)\n                        \n                        snr = compute_snr(true, pred)\n                        rmse = compute_rmse(true, pred)\n                        corr = compute_correlation(true, pred)\n                        \n                        if not np.isnan(snr) and not np.isinf(snr):\n                            all_snrs.append(snr)\n                        if not np.isnan(rmse) and not np.isinf(rmse):\n                            all_rmses.append(rmse)\n                        if not np.isnan(corr) and not np.isinf(corr):\n                            all_correlations.append(corr)\n    \n    metrics = {\n        'snr_mean': np.mean(all_snrs) if all_snrs else 0,\n        'snr_std': np.std(all_snrs) if all_snrs else 0,\n        'rmse_mean': np.mean(all_rmses) if all_rmses else 0,\n        'rmse_std': np.std(all_rmses) if all_rmses else 0,\n        'correlation_mean': np.mean(all_correlations) if all_correlations else 0,\n        'correlation_std': np.std(all_correlations) if all_correlations else 0\n    }\n    \n    return metrics","metadata":{"_uuid":"017cb40b-fd2f-4865-a905-8abbfd92e97e","_cell_guid":"39c4ce59-2493-44ac-ac5a-28c6db713296","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-10-31T17:04:15.968459Z","iopub.execute_input":"2025-10-31T17:04:15.968751Z","iopub.status.idle":"2025-10-31T17:04:15.986653Z","shell.execute_reply.started":"2025-10-31T17:04:15.968733Z","shell.execute_reply":"2025-10-31T17:04:15.985864Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_transform, test_transform = get_stable_transforms(img_size=512)\n\ntrain_dataset = StableECGDataset(\n    meta_df=train_meta,\n    data_dir=TRAIN_DIR,\n    split='train',\n    transform=train_transform,\n    max_samples=50,\n    img_size=512\n)\n\ntest_dataset = StableECGDataset(\n    meta_df=test_meta,\n    data_dir=TEST_DIR,\n    split='test',\n    transform=test_transform,\n    img_size=512\n)\n\ntrain_loader = DataLoader(\n    train_dataset, \n    batch_size=12, \n    shuffle=True, \n    num_workers=2,\n    collate_fn=stable_collate_fn,\n    pin_memory=True\n)\n\ntest_loader = DataLoader(\n    test_dataset, \n    batch_size=2, \n    shuffle=False, \n    num_workers=2,\n    pin_memory=True\n)\n\nprint(f\"Training batches: {len(train_loader)}\")\nprint(f\"Test batches: {len(test_loader)}\")","metadata":{"_uuid":"640961fb-9379-4823-ba48-cded5c313edd","_cell_guid":"314f1b07-f0a3-4447-afa2-81952e0b8e52","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-10-31T17:04:15.987375Z","iopub.execute_input":"2025-10-31T17:04:15.987661Z","iopub.status.idle":"2025-10-31T17:04:16.016744Z","shell.execute_reply.started":"2025-10-31T17:04:15.987635Z","shell.execute_reply":"2025-10-31T17:04:16.016144Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"num_epochs = 2500\nbest_loss = float('inf')\nbest_snr = -float('inf')\ntrain_losses = []\nperformance_metrics = []\n\nprint(\"Starting stable training...\")\n\nfor epoch in range(num_epochs):\n    print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n    print(\"=\" * 50)\n    \n    start_time = time.time()\n    \n    avg_loss = train_epoch_stable(model, train_loader, criterion, optimizer, device)\n    \n    epoch_time = time.time() - start_time\n    \n    if not np.isinf(avg_loss):\n        train_losses.append(avg_loss)\n        \n        metrics = evaluate_model_stable(model, train_loader, device)\n        performance_metrics.append(metrics)\n        \n        print(f\"Average Loss: {avg_loss:.4f} | Time: {epoch_time:.2f}s\")\n        print(f\"SNR: {metrics['snr_mean']:.2f} ± {metrics['snr_std']:.2f} dB\")\n        print(f\"RMSE: {metrics['rmse_mean']:.4f} ± {metrics['rmse_std']:.4f}\")\n        print(f\"Correlation: {metrics['correlation_mean']:.4f} ± {metrics['correlation_std']:.4f}\")\n        \n        if metrics['snr_mean'] > best_snr:\n            best_snr = metrics['snr_mean']\n            torch.save({\n                'epoch': epoch,\n                'model_state_dict': model.state_dict(),\n                'optimizer_state_dict': optimizer.state_dict(),\n                'loss': avg_loss,\n                'snr': best_snr,\n                'metrics': metrics\n            }, 'best_stable_model.pth')\n            print(f\"New best model saved with SNR: {best_snr:.2f} dB\")\n        \n        if avg_loss < best_loss:\n            best_loss = avg_loss\n    else:\n        print(f\"Epoch failed - skipping\")","metadata":{"_uuid":"ad9405f8-ab52-4a5f-873f-c722a93b35a5","_cell_guid":"0b81bbcb-e24c-44ac-80c4-93487a658ca6","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-10-31T17:04:16.017484Z","iopub.execute_input":"2025-10-31T17:04:16.017723Z","iopub.status.idle":"2025-10-31T17:04:52.026027Z","shell.execute_reply.started":"2025-10-31T17:04:16.017697Z","shell.execute_reply":"2025-10-31T17:04:52.024979Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def safe_signal_processing(signal, fs, target_lead):\n    signal = np.nan_to_num(signal, nan=0.0, posinf=0.0, neginf=0.0)\n    \n    duration = 10.0 if target_lead == 'II' else 2.5\n    expected_length = int(math.floor(fs * duration))\n    \n    if len(signal) > expected_length:\n        signal = signal[:expected_length]\n    elif len(signal) < expected_length:\n        signal = np.pad(signal, (0, expected_length - len(signal)), mode='edge')\n    \n    if len(signal) > 11:\n        try:\n            window_length = min(11, len(signal)//2*2+1)\n            if window_length > 3:\n                signal = savgol_filter(signal, window_length, 3)\n        except:\n            pass\n    \n    signal = np.clip(signal, -2.0, 2.0)\n    \n    return signal\n\ndef predict_signal_stable(model, image, target_lead, fs, device):\n    model.eval()\n    \n    with torch.no_grad():\n        if isinstance(image, np.ndarray):\n            image_tensor = torch.from_numpy(image).permute(2, 0, 1).unsqueeze(0).float() / 255.0\n        else:\n            image_tensor = image.unsqueeze(0) if image.dim() == 3 else image\n        \n        image_tensor = image_tensor.to(device)\n        \n        predictions = model(image_tensor)\n        \n        signal = predictions[target_lead][0].cpu().numpy()\n        signal = np.nan_to_num(signal, nan=0.0)\n        \n        return safe_signal_processing(signal, fs, target_lead)","metadata":{"_uuid":"b447c5e7-3af7-460d-8122-d638ac53bbb6","_cell_guid":"8ffefb94-6164-4f6b-925b-a6351ab3c987","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-10-31T17:04:52.027629Z","iopub.execute_input":"2025-10-31T17:04:52.028031Z","iopub.status.idle":"2025-10-31T17:04:52.039119Z","shell.execute_reply.started":"2025-10-31T17:04:52.027995Z","shell.execute_reply":"2025-10-31T17:04:52.03841Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def generate_stable_submission(model, test_loader, device):\n    model.eval()\n    all_predictions = []\n    \n    print(\"Generating stable submission...\")\n    \n    with torch.no_grad():\n        for batch in tqdm(test_loader, desc=\"Processing\"):\n            images = batch['image']\n            ecg_ids = batch['ecg_id']\n            fs_values = batch['fs']\n            target_leads = batch['target_lead']\n            \n            for i in range(len(images)):\n                ecg_id = ecg_ids[i]\n                fs = fs_values[i]\n                target_lead = target_leads[i]\n                image = images[i]\n                \n                try:\n                    signal = predict_signal_stable(model, image, target_lead, fs, device)\n                    \n                    for row_id, value in enumerate(signal):\n                        submission_id = f\"{ecg_id}_{row_id}_{target_lead}\"\n                        all_predictions.append({\n                            'id': submission_id,\n                            'value': float(value)\n                        })\n                except Exception as e:\n                    print(f\"Error processing {ecg_id}, {target_lead}: {e}\")\n                    duration = 10.0 if target_lead == 'II' else 2.5\n                    expected_length = int(math.floor(fs * duration))\n                    for row_id in range(expected_length):\n                        submission_id = f\"{ecg_id}_{row_id}_{target_lead}\"\n                        all_predictions.append({\n                            'id': submission_id,\n                            'value': 0.0\n                        })\n    \n    return pd.DataFrame(all_predictions)","metadata":{"_uuid":"a0907f94-7153-4373-a2d0-0466bc3aea9a","_cell_guid":"0f213f23-c448-47d3-8136-2555b36e8cf6","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-10-31T17:04:52.039937Z","iopub.execute_input":"2025-10-31T17:04:52.040205Z","iopub.status.idle":"2025-10-31T17:04:52.069718Z","shell.execute_reply.started":"2025-10-31T17:04:52.04018Z","shell.execute_reply":"2025-10-31T17:04:52.068866Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"Creating stable submission...\")\nsubmission_df = generate_stable_submission(model, test_loader, device)\n\nprint(f\"Generated {len(submission_df)} predictions\")\n\nfinal_metrics = evaluate_model_stable(model, train_loader, device)\nprint(f\"\\nFinal Performance Metrics:\")\nprint(f\"SNR: {final_metrics['snr_mean']:.2f} ± {final_metrics['snr_std']:.2f} dB\")\nprint(f\"RMSE: {final_metrics['rmse_mean']:.4f} ± {final_metrics['rmse_std']:.4f}\")\nprint(f\"Correlation: {final_metrics['correlation_mean']:.4f} ± {final_metrics['correlation_std']:.4f}\")\n\nprint(f\"\\nValue statistics:\")\nprint(f\"Min: {submission_df['value'].min():.6f}\")\nprint(f\"Max: {submission_df['value'].max():.6f}\")\nprint(f\"Mean: {submission_df['value'].mean():.6f}\")\nprint(f\"Std: {submission_df['value'].std():.6f}\")","metadata":{"_uuid":"e63a4966-bac9-4d39-bfb2-27c53fdf478c","_cell_guid":"00feb364-6b89-42f6-ad8e-c2b078b5f7c4","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-10-31T17:04:52.070509Z","iopub.execute_input":"2025-10-31T17:04:52.070765Z","iopub.status.idle":"2025-10-31T17:04:57.259698Z","shell.execute_reply.started":"2025-10-31T17:04:52.070748Z","shell.execute_reply":"2025-10-31T17:04:57.258793Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Save submission as both Parquet and CSV\nsubmission_df.to_parquet('submission.parquet', index=False)\nsubmission_df.to_csv('submission.csv', index=False)\nprint(\"Submission saved as 'submission.parquet' and 'submission.csv'\")\n\n# Show lead distribution\nlead_counts = submission_df['id'].str.split('_', expand=True)[2].value_counts()\nprint(\"\\nLead distribution:\")\nfor lead, count in lead_counts.items():\n    print(f\"  {lead}: {count} samples\")\n\nprint(f\"\\nSubmission completed successfully!\")\nprint(f\"Best SNR achieved: {best_snr:.2f} dB\")\n","metadata":{"_uuid":"b17ca650-10d5-43b1-856d-aae12cf15052","_cell_guid":"f7bfeabb-99f5-4d7d-ad55-01db2ce4f3f3","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-10-31T17:04:57.260726Z","iopub.execute_input":"2025-10-31T17:04:57.260986Z","iopub.status.idle":"2025-10-31T17:04:57.704208Z","shell.execute_reply.started":"2025-10-31T17:04:57.260965Z","shell.execute_reply":"2025-10-31T17:04:57.703525Z"}},"outputs":[],"execution_count":null}]}