{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":97984,"databundleVersionId":14096757,"sourceType":"competition"}],"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"\"\"\"\nPhysioNet ECG Image Digitization Competition - Complete Solution\n================================================================\n\nThis script provides a comprehensive solution for the PhysioNet ECG Image Digitization competition.\nIt includes image preprocessing, lead extraction, signal reconstruction, and evaluation metrics.\n\nAuthor: Muhammad Qasim Shabbir\nDate: 2025\n\"\"\"\n\n# Install required libraries if not available\nimport subprocess\nimport sys\n\ndef install_package(package):\n    try:\n        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n    except subprocess.CalledProcessError:\n        print(f\"Failed to install {package}\")\n\n# Install tqdm for progress bars\ntry:\n    from tqdm import tqdm\nexcept ImportError:\n    install_package(\"tqdm\")\n    from tqdm import tqdm\n\nimport cv2\nimport numpy as np\nimport pandas as pd\nimport os\nimport glob\nfrom pathlib import Path\nfrom typing import List, Tuple, Dict, Optional\nimport matplotlib.pyplot as plt\nfrom scipy import signal as scipy_signal\nfrom scipy.optimize import minimize_scalar\nfrom scipy.ndimage import gaussian_filter1d\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# GPU and parallel processing imports\ntry:\n    import cupy as cp\n    import cupyx.scipy.ndimage as cp_ndimage\n    import cupyx.scipy.signal as cp_signal\n    GPU_AVAILABLE = True\n    print(\"CuPy available - GPU acceleration enabled\")\nexcept ImportError:\n    GPU_AVAILABLE = False\n    print(\"CuPy not available - using CPU only\")\n\ntry:\n    import torch\n    import torch.nn as nn\n    import torch.nn.functional as F\n    from torch.utils.data import DataLoader, Dataset\n    TORCH_AVAILABLE = True\n    print(\"PyTorch available - Deep learning models enabled\")\nexcept ImportError:\n    TORCH_AVAILABLE = False\n    print(\"PyTorch not available - using traditional methods only\")\n\nfrom multiprocessing import Pool, cpu_count\nfrom concurrent.futures import ThreadPoolExecutor, ProcessPoolExecutor\nimport threading\n\nclass ECGDigitizer:\n    \"\"\"\n    Complete ECG Image Digitization Solution for PhysioNet Competition\n    Enhanced with GPU acceleration and parallel processing\n    \"\"\"\n    \n    def __init__(self, use_gpu=True, num_workers=None):\n        self.leads = ['I', 'II', 'III', 'aVR', 'aVL', 'aVF', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6']\n        self.lead_durations = {\n            'II': 20.0,  # 10 seconds for lead II\n            **{lead: 3.5 for lead in self.leads if lead != 'II'}  # 2.5 seconds for all other leads\n        }\n        \n        # GPU and parallel processing setup\n        self.use_gpu = use_gpu and GPU_AVAILABLE\n        self.num_workers = num_workers or min(cpu_count(), 8)\n        \n        if self.use_gpu:\n            # Initialize GPU memory pools for better performance\n            cp.cuda.MemoryPool().set_limit(size=15 * 1024**3)  # 15GB per GPU\n            self.gpu_devices = cp.cuda.runtime.getDeviceCount()\n            print(f\"GPU acceleration enabled with {self.gpu_devices} devices\")\n            \n            # Set up multi-GPU processing\n            if self.gpu_devices >= 2:\n                self.gpu_0 = cp.cuda.Device(0)\n                self.gpu_1 = cp.cuda.Device(1)\n                print(\"Dual GPU setup detected - using both GPUs\")\n            else:\n                self.gpu_0 = cp.cuda.Device(0)\n                self.gpu_1 = None\n        else:\n            print(\"Using CPU processing with multiprocessing\")\n            \n        # Initialize PyTorch models if available\n        if TORCH_AVAILABLE and self.use_gpu:\n            self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n            self.model = self._create_ecg_model()\n            print(f\"PyTorch model initialized on {self.device}\")\n        else:\n            self.device = None\n            self.model = None\n    \n    def _create_ecg_model(self):\n        \"\"\"Create a PyTorch model for ECG signal reconstruction\"\"\"\n        if not TORCH_AVAILABLE:\n            return None\n            \n        class ECGSignalNet(nn.Module):\n            def __init__(self):\n                super().__init__()\n                # Encoder for image features\n                self.encoder = nn.Sequential(\n                    nn.Conv2d(1, 32, 3, padding=1),\n                    nn.ReLU(),\n                    nn.MaxPool2d(2),\n                    nn.Conv2d(32, 64, 3, padding=1),\n                    nn.ReLU(),\n                    nn.MaxPool2d(2),\n                    nn.Conv2d(64, 128, 3, padding=1),\n                    nn.ReLU(),\n                    nn.AdaptiveAvgPool2d((8, 8))\n                )\n                \n                # Decoder for signal reconstruction\n                self.decoder = nn.Sequential(\n                    nn.Linear(128 * 8 * 8, 512),\n                    nn.ReLU(),\n                    nn.Dropout(0.3),\n                    nn.Linear(512, 256),\n                    nn.ReLU(),\n                    nn.Dropout(0.3),\n                    nn.Linear(256, 1000),  # Max signal length\n                    nn.Tanh()\n                )\n                \n            def forward(self, x):\n                x = self.encoder(x)\n                x = x.view(x.size(0), -1)\n                x = self.decoder(x)\n                return x\n        \n        model = ECGSignalNet().to(self.device)\n        return model\n    \n    def preprocess_image_gpu(self, image_path: str) -> np.ndarray:\n        \"\"\"GPU-accelerated image preprocessing\"\"\"\n        if not self.use_gpu:\n            return self.preprocess_image(image_path)\n            \n        # Load image on CPU first\n        image = cv2.imread(image_path)\n        if image is None:\n            raise ValueError(f\"Could not load image: {image_path}\")\n        \n        # Convert to grayscale and move to GPU\n        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n        gpu_image = cp.asarray(gray, dtype=cp.float32)\n        \n        # GPU-accelerated Gaussian blur\n        gpu_blurred = cp_ndimage.gaussian_filter(gpu_image, sigma=1.0)\n        \n        # GPU-accelerated adaptive thresholding\n        # Note: OpenCV adaptive thresholding is not available in CuPy\n        # So we'll do basic thresholding on GPU and fallback to CPU for adaptive\n        blurred_cpu = cp.asnumpy(gpu_blurred)\n        binary = cv2.adaptiveThreshold(\n            blurred_cpu.astype(np.uint8), 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, \n            cv2.THRESH_BINARY_INV, 11, 2\n        )\n        \n        # Move back to GPU for morphological operations\n        gpu_binary = cp.asarray(binary)\n        \n        # GPU-accelerated morphological operations\n        kernel = cp.ones((3, 3), dtype=cp.uint8)\n        gpu_binary = cp_ndimage.binary_closing(gpu_binary, structure=kernel)\n        gpu_binary = cp_ndimage.binary_opening(gpu_binary, structure=kernel)\n        \n        return cp.asnumpy(gpu_binary)\n    \n    def preprocess_image(self, image_path: str) -> np.ndarray:\n        \"\"\"\n        Preprocess ECG image to enhance signal extraction\n        \n        Args:\n            image_path: Path to the ECG image\n            \n        Returns:\n            Preprocessed binary image\n        \"\"\"\n        # Load image\n        image = cv2.imread(image_path)\n        if image is None:\n            raise ValueError(f\"Could not load image: {image_path}\")\n            \n        # Convert to grayscale\n        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n        \n        # Apply Gaussian blur to reduce noise\n        blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n        \n        # Apply adaptive thresholding for better binarization\n        binary = cv2.adaptiveThreshold(\n            blurred, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, \n            cv2.THRESH_BINARY_INV, 11, 2\n        )\n        \n        # Morphological operations to clean up the image\n        kernel = np.ones((3, 3), np.uint8)\n        binary = cv2.morphologyEx(binary, cv2.MORPH_CLOSE, kernel)\n        binary = cv2.morphologyEx(binary, cv2.MORPH_OPEN, kernel)\n        \n        return binary\n    \n    def detect_lead_regions(self, binary_image: np.ndarray) -> List[Tuple[int, int, int, int]]:\n        \"\"\"\n        Detect individual lead regions in the ECG image using improved method\n        \n        Args:\n            binary_image: Preprocessed binary image\n            \n        Returns:\n            List of bounding boxes (x, y, w, h) for each lead\n        \"\"\"\n        # Ensure binary image is uint8 type for OpenCV\n        if binary_image.dtype != np.uint8:\n            binary_image = binary_image.astype(np.uint8)\n        \n        # Method 1: Use horizontal projection to find lead regions\n        h, w = binary_image.shape\n        horizontal_projection = np.sum(binary_image, axis=1)\n        \n        # Find peaks in horizontal projection (potential lead regions)\n        lead_regions = []\n        in_lead = False\n        start_y = 0\n        \n        threshold = np.mean(horizontal_projection) * 0.5\n        \n        for y in range(h):\n            if horizontal_projection[y] > threshold and not in_lead:\n                # Start of a lead region\n                start_y = y\n                in_lead = True\n            elif horizontal_projection[y] <= threshold and in_lead:\n                # End of a lead region\n                end_y = y\n                lead_height = end_y - start_y\n                \n                if lead_height > 10:  # Minimum height for a lead\n                    # Extract the lead region\n                    lead_region = binary_image[start_y:end_y, :]\n                    \n                    # Find the actual width of the signal\n                    vertical_projection = np.sum(lead_region, axis=0)\n                    signal_indices = np.where(vertical_projection > 0)[0]\n                    \n                    if len(signal_indices) > 0:\n                        start_x = signal_indices[0]\n                        end_x = signal_indices[-1] + 1\n                        lead_width = end_x - start_x\n                        \n                        if lead_width > 50:  # Minimum width for a lead\n                            lead_regions.append((start_x, start_y, lead_width, lead_height))\n                \n                in_lead = False\n        \n        # If no leads found with projection method, fall back to contour method\n        if len(lead_regions) == 0:\n            contours, _ = cv2.findContours(binary_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n            \n            for contour in contours:\n                area = cv2.contourArea(contour)\n                if area > 500:  # Lower threshold\n                    x, y, w, h = cv2.boundingRect(contour)\n                    aspect_ratio = w / h\n                    if 1.5 < aspect_ratio < 30:  # More flexible aspect ratio\n                        lead_regions.append((x, y, w, h))\n        \n        # Sort by y-coordinate (top to bottom)\n        lead_regions.sort(key=lambda x: x[1])\n        \n        # Limit to reasonable number of leads (ECG typically has 12 leads)\n        if len(lead_regions) > 15:\n            lead_regions = lead_regions[:15]\n        \n        return lead_regions\n    \n    def extract_lead_signal(self, binary_image: np.ndarray, bbox: Tuple[int, int, int, int]) -> np.ndarray:\n        \"\"\"\n        Extract time series signal from a lead region using improved ECG-specific method\n        \n        Args:\n            binary_image: Preprocessed binary image\n            bbox: Bounding box (x, y, w, h) of the lead region\n            \n        Returns:\n            Extracted signal as 1D array\n        \"\"\"\n        x, y, w, h = bbox\n        lead_region = binary_image[y:y+h, x:x+w]\n        \n        # Check if region is valid\n        if lead_region.size == 0 or w < 10 or h < 5:\n            return np.array([])\n        \n        # Method 1: Find the center line using weighted average\n        signal = np.zeros(w)\n        \n        for col in range(w):\n            column = lead_region[:, col]\n            # Find all non-zero pixels in this column\n            nonzero_indices = np.where(column > 0)[0]\n            \n            if len(nonzero_indices) > 0:\n                # Use weighted average of non-zero pixels\n                weights = column[nonzero_indices]\n                weighted_center = np.average(nonzero_indices, weights=weights)\n                signal[col] = weighted_center\n            else:\n                # If no signal in this column, use previous value or interpolate\n                if col > 0:\n                    signal[col] = signal[col-1]\n                else:\n                    signal[col] = h // 2  # Default to middle\n        \n        # Smooth the signal\n        if len(signal) > 10:\n            signal = gaussian_filter1d(signal.astype(float), sigma=1.0)\n        \n        # Convert to ECG-like signal (invert Y-axis since ECG traces go up for positive values)\n        signal = h - signal\n        \n        # Normalize the signal\n        if len(signal) > 0:\n            mean_val = np.mean(signal)\n            std_val = np.std(signal)\n            if std_val > 1e-8:\n                signal = (signal - mean_val) / std_val\n            else:\n                signal = signal - mean_val\n        \n        return signal\n    \n    def resample_signal_gpu(self, input_signal: np.ndarray, target_length: int) -> np.ndarray:\n        \"\"\"GPU-accelerated signal resampling\"\"\"\n        if not self.use_gpu:\n            return self.resample_signal(input_signal, target_length)\n            \n        if len(input_signal) == 0:\n            return np.zeros(target_length)\n        \n        if len(input_signal) == target_length:\n            return input_signal\n        \n        # Move signal to GPU\n        gpu_signal = cp.asarray(input_signal, dtype=cp.float32)\n        \n        # GPU-accelerated resampling using CuPy\n        try:\n            gpu_resampled = cp_signal.resample(gpu_signal, target_length)\n            return cp.asnumpy(gpu_resampled)\n        except:\n            # Fallback to CPU if GPU resampling fails\n            return self.resample_signal(input_signal, target_length)\n    \n    def resample_signal(self, input_signal: np.ndarray, target_length: int) -> np.ndarray:\n        \"\"\"\n        Resample signal to target length\n        \n        Args:\n            input_signal: Input signal\n            target_length: Target length for resampling\n            \n        Returns:\n            Resampled signal\n        \"\"\"\n        if len(input_signal) == 0:\n            return np.zeros(target_length)\n        \n        if len(input_signal) == target_length:\n            return input_signal\n            \n        # Use scipy's resample for better quality\n        resampled = scipy_signal.resample(input_signal, target_length)\n        return resampled\n    \n    def process_batch_gpu(self, image_paths: List[str], fs_values: List[int], leads: List[str]) -> List[np.ndarray]:\n        \"\"\"Process multiple images in parallel using GPU\"\"\"\n        if not self.use_gpu or len(image_paths) == 0:\n            return []\n        \n        results = []\n        \n        # Split work between GPUs if available\n        if self.gpu_devices >= 2:\n            mid = len(image_paths) // 2\n            batch1 = image_paths[:mid]\n            batch2 = image_paths[mid:]\n            \n            # Process on GPU 0\n            with self.gpu_0:\n                results1 = self._process_batch_single_gpu(batch1, fs_values[:mid], leads[:mid])\n            \n            # Process on GPU 1\n            with self.gpu_1:\n                results2 = self._process_batch_single_gpu(batch2, fs_values[mid:], leads[mid:])\n            \n            results = results1 + results2\n        else:\n            # Single GPU processing\n            with self.gpu_0:\n                results = self._process_batch_single_gpu(image_paths, fs_values, leads)\n        \n        return results\n    \n    def _process_batch_single_gpu(self, image_paths: List[str], fs_values: List[int], leads: List[str]) -> List[np.ndarray]:\n        \"\"\"Process batch on a single GPU\"\"\"\n        results = []\n        \n        for i, (image_path, fs, lead) in enumerate(zip(image_paths, fs_values, leads)):\n            try:\n                # Preprocess image on GPU\n                binary_image = self.preprocess_image_gpu(image_path)\n                \n                # Detect lead regions\n                lead_regions = self.detect_lead_regions(binary_image)\n                \n                if lead_regions:\n                    # Extract signal from first region\n                    signal = self.extract_lead_signal(binary_image, lead_regions[0])\n                    \n                    # Resample on GPU\n                    duration = self.lead_durations[lead]\n                    target_length = int(fs * duration)\n                    resampled_signal = self.resample_signal_gpu(signal, target_length)\n                    \n                    results.append(resampled_signal)\n                else:\n                    # Return zero signal if no leads detected\n                    duration = self.lead_durations[lead]\n                    target_length = int(fs * duration)\n                    results.append(np.zeros(target_length))\n                    \n            except Exception as e:\n                print(f\"Error processing {image_path}: {str(e)}\")\n                duration = self.lead_durations[lead]\n                target_length = int(fs * duration)\n                results.append(np.zeros(target_length))\n        \n        return results\n    \n    def process_ecg_image(self, image_path: str, fs: int, lead: str = 'II') -> np.ndarray:\n        \"\"\"\n        Process a single ECG image and extract the signal for a specific lead\n        \n        Args:\n            image_path: Path to the ECG image\n            fs: Sampling frequency\n            lead: ECG lead to extract\n            \n        Returns:\n            Extracted and resampled signal\n        \"\"\"\n        # Use GPU preprocessing if available\n        if self.use_gpu:\n            binary_image = self.preprocess_image_gpu(image_path)\n        else:\n            binary_image = self.preprocess_image(image_path)\n        \n        # Detect lead regions\n        lead_regions = self.detect_lead_regions(binary_image)\n        \n        if not lead_regions:\n            # If no leads detected, return zero signal\n            duration = self.lead_durations[lead]\n            target_length = int(fs * duration)\n            return np.zeros(target_length)\n        \n        # For simplicity, use the first detected lead region\n        # In a more sophisticated approach, you would map regions to specific leads\n        bbox = lead_regions[0]\n        signal = self.extract_lead_signal(binary_image, bbox)\n        \n        # Resample to target length (use GPU if available)\n        duration = self.lead_durations[lead]\n        target_length = int(fs * duration)\n        if self.use_gpu:\n            resampled_signal = self.resample_signal_gpu(signal, target_length)\n        else:\n            resampled_signal = self.resample_signal(signal, target_length)\n        \n        return resampled_signal\n    \n    def calculate_snr(self, predicted: np.ndarray, ground_truth: np.ndarray, fs: int) -> float:\n        \"\"\"\n        Calculate modified Signal-to-Noise Ratio (SNR) as per competition metric\n        \n        Args:\n            predicted: Predicted signal\n            ground_truth: Ground truth signal\n            fs: Sampling frequency\n            \n        Returns:\n            SNR in decibels\n        \"\"\"\n        # Handle edge cases\n        if len(predicted) == 0 or len(ground_truth) == 0:\n            return -np.inf\n        \n        # Check if signals are all zeros\n        if np.all(predicted == 0) or np.all(ground_truth == 0):\n            return -np.inf\n        \n        if len(predicted) != len(ground_truth):\n            # Resample predicted to match ground truth length\n            predicted = self.resample_signal(predicted, len(ground_truth))\n        \n        # Ensure signals are not all the same value\n        if np.std(ground_truth) == 0 or np.std(predicted) == 0:\n            return -np.inf\n        \n        # Time alignment (find optimal shift up to 0.2 seconds)\n        max_shift = int(0.2 * fs)\n        best_correlation = -np.inf\n        best_shift = 0\n        \n        for shift in range(-max_shift, max_shift + 1):\n            if shift == 0:\n                shifted_pred = predicted\n            elif shift > 0:\n                shifted_pred = np.pad(predicted[shift:], (0, shift), mode='constant')\n            else:\n                shifted_pred = np.pad(predicted[:shift], (-shift, 0), mode='constant')\n            \n            if len(shifted_pred) == len(ground_truth):\n                try:\n                    correlation = np.corrcoef(ground_truth, shifted_pred)[0, 1]\n                    if not np.isnan(correlation) and correlation > best_correlation:\n                        best_correlation = correlation\n                        best_shift = shift\n                except:\n                    continue\n        \n        # Apply best shift\n        if best_shift > 0:\n            aligned_pred = np.pad(predicted[best_shift:], (0, best_shift), mode='constant')\n        elif best_shift < 0:\n            aligned_pred = np.pad(predicted[:best_shift], (-best_shift, 0), mode='constant')\n        else:\n            aligned_pred = predicted\n        \n        # Vertical alignment (remove constant offset)\n        offset = np.mean(ground_truth) - np.mean(aligned_pred)\n        aligned_pred = aligned_pred + offset\n        \n        # Calculate SNR\n        signal_power = np.sum(ground_truth ** 2)\n        noise_power = np.sum((ground_truth - aligned_pred) ** 2)\n        \n        if noise_power == 0 or signal_power == 0:\n            return -np.inf\n        \n        snr_linear = signal_power / noise_power\n        \n        if snr_linear <= 0 or np.isnan(snr_linear) or np.isinf(snr_linear):\n            return -np.inf\n        \n        snr_db = 10 * np.log10(snr_linear)\n        \n        # Check for valid result\n        if np.isnan(snr_db) or np.isinf(snr_db):\n            return -np.inf\n        \n        return snr_db\n    \n    def process_training_data(self, train_dir: str, train_csv_path: str, use_parallel=False) -> Dict:\n        \"\"\"\n        Process training data and calculate performance metrics with GPU acceleration and parallel processing\n        \n        Args:\n            train_dir: Directory containing training images\n            train_csv_path: Path to training CSV file\n            use_parallel: Whether to use parallel processing\n            \n        Returns:\n            Dictionary with processing results and metrics\n        \"\"\"\n        train_df = pd.read_csv(train_csv_path)\n        results = {\n            'snr_scores': [],\n            'processed_ids': [],\n            'errors': []\n        }\n        \n        print(f\"Processing {len(train_df)} training samples...\")\n        print(f\"GPU acceleration: {'Enabled' if self.use_gpu else 'Disabled'}\")\n        print(f\"Parallel processing: {'Enabled' if use_parallel else 'Disabled'}\")\n        \n        if use_parallel and len(train_df) > 10:\n            # Use parallel processing for large datasets\n            results = self._process_training_data_parallel(train_df, train_dir)\n        else:\n            # Sequential processing\n            results = self._process_training_data_sequential(train_df, train_dir)\n        \n        return results\n    \n    def _process_training_data_sequential(self, train_df: pd.DataFrame, train_dir: str) -> Dict:\n        \"\"\"Sequential processing of training data\"\"\"\n        results = {\n            'snr_scores': [],\n            'processed_ids': [],\n            'errors': []\n        }\n        \n        # Add progress bar\n        progress_bar = tqdm(train_df.iterrows(), total=len(train_df), desc=\"Processing training data\")\n        \n        for idx, row in progress_bar:\n            ecg_id = row['id']\n            fs = row['fs']\n            sig_len = row['sig_len']\n            \n            # Load ground truth data\n            gt_path = os.path.join(train_dir, str(ecg_id), f\"{ecg_id}.csv\")\n            if not os.path.exists(gt_path):\n                progress_bar.set_description(f\"Skipping ID {ecg_id} - No ground truth\")\n                continue\n            \n            ground_truth_df = pd.read_csv(gt_path)\n            \n            # Process each lead\n            lead_snrs = []\n            for lead in self.leads:\n                if lead in ground_truth_df.columns:\n                    # Get ground truth signal\n                    gt_signal = ground_truth_df[lead].values\n                    \n                    # Skip if ground truth is all NaN or empty\n                    if len(gt_signal) == 0 or np.all(np.isnan(gt_signal)):\n                        continue\n                    \n                    # Remove NaN values from ground truth\n                    valid_indices = ~np.isnan(gt_signal)\n                    if np.sum(valid_indices) < 10:  # Need at least 10 valid points\n                        continue\n                    \n                    gt_signal_clean = gt_signal[valid_indices]\n                    \n                    # Find corresponding image (use first available segment)\n                    image_pattern = os.path.join(train_dir, str(ecg_id), f\"{ecg_id}-*.png\")\n                    image_files = glob.glob(image_pattern)\n                    \n                    if image_files:\n                        # Process the first available image\n                        predicted_signal = self.process_ecg_image(image_files[0], fs, lead)\n                        \n                        # Skip if predicted signal is empty\n                        if len(predicted_signal) == 0:\n                            continue\n                        \n                        # Resample predicted to match ground truth length\n                        if len(predicted_signal) != len(gt_signal_clean):\n                            predicted_signal = self.resample_signal(predicted_signal, len(gt_signal_clean))\n                        \n                        # Calculate SNR\n                        snr = self.calculate_snr(predicted_signal, gt_signal_clean, fs)\n                        if not np.isnan(snr) and not np.isinf(snr):\n                            lead_snrs.append(snr)\n            \n            if lead_snrs:\n                avg_snr = np.mean(lead_snrs)\n                results['snr_scores'].append(avg_snr)\n                results['processed_ids'].append(ecg_id)\n                # Update progress bar description\n                progress_bar.set_description(f\"ID {ecg_id} - SNR: {avg_snr:.2f} dB\")\n            else:\n                progress_bar.set_description(f\"ID {ecg_id} - No valid signals\")\n        \n        return results\n    \n    def _process_training_data_parallel(self, train_df: pd.DataFrame, train_dir: str) -> Dict:\n        \"\"\"Parallel processing of training data using multiprocessing\"\"\"\n        results = {\n            'snr_scores': [],\n            'processed_ids': [],\n            'errors': []\n        }\n        \n        # Prepare data for parallel processing\n        processing_data = []\n        for idx, row in train_df.iterrows():\n            ecg_id = row['id']\n            fs = row['fs']\n            sig_len = row['sig_len']\n            \n            gt_path = os.path.join(train_dir, str(ecg_id), f\"{ecg_id}.csv\")\n            if os.path.exists(gt_path):\n                processing_data.append((ecg_id, fs, sig_len, gt_path, train_dir))\n        \n        # Process in parallel\n        with ProcessPoolExecutor(max_workers=self.num_workers) as executor:\n            future_to_data = {\n                executor.submit(self._process_single_training_sample, data): data \n                for data in processing_data\n            }\n            \n            for future in future_to_data:\n                try:\n                    result = future.result()\n                    if result:\n                        results['snr_scores'].append(result['snr'])\n                        results['processed_ids'].append(result['ecg_id'])\n                except Exception as e:\n                    ecg_id = future_to_data[future][0]\n                    error_msg = f\"Error processing ID {ecg_id}: {str(e)}\"\n                    results['errors'].append(error_msg)\n                    print(error_msg)\n        \n        return results\n    \n    def _process_single_training_sample(self, data):\n        \"\"\"Process a single training sample (for parallel processing)\"\"\"\n        ecg_id, fs, sig_len, gt_path, train_dir = data\n        \n        # Create a new digitizer instance for this process (without PyTorch model)\n        digitizer = ECGDigitizer(use_gpu=False, num_workers=1)\n        \n        ground_truth_df = pd.read_csv(gt_path)\n        \n        # Process each lead\n        lead_snrs = []\n        for lead in digitizer.leads:\n            if lead in ground_truth_df.columns:\n                # Get ground truth signal\n                gt_signal = ground_truth_df[lead].values\n                \n                # Skip if ground truth is all NaN or empty\n                if len(gt_signal) == 0 or np.all(np.isnan(gt_signal)):\n                    continue\n                \n                # Remove NaN values from ground truth\n                valid_indices = ~np.isnan(gt_signal)\n                if np.sum(valid_indices) < 10:  # Need at least 10 valid points\n                    continue\n                \n                gt_signal_clean = gt_signal[valid_indices]\n                \n                # Find corresponding image (use first available segment)\n                image_pattern = os.path.join(train_dir, str(ecg_id), f\"{ecg_id}-*.png\")\n                image_files = glob.glob(image_pattern)\n                \n                if image_files:\n                    # Process the first available image\n                    predicted_signal = digitizer.process_ecg_image(image_files[0], fs, lead)\n                    \n                    # Skip if predicted signal is empty\n                    if len(predicted_signal) == 0:\n                        continue\n                    \n                    # Resample predicted to match ground truth length\n                    if len(predicted_signal) != len(gt_signal_clean):\n                        predicted_signal = digitizer.resample_signal(predicted_signal, len(gt_signal_clean))\n                    \n                    # Calculate SNR\n                    snr = digitizer.calculate_snr(predicted_signal, gt_signal_clean, fs)\n                    if not np.isnan(snr) and not np.isinf(snr):\n                        lead_snrs.append(snr)\n        \n        if lead_snrs:\n            avg_snr = np.mean(lead_snrs)\n            return {'ecg_id': ecg_id, 'snr': avg_snr}\n        \n        return None\n    \n    def generate_submission(self, test_dir: str, test_csv_path: str, output_path: str, use_parallel=False):\n        \"\"\"\n        Generate submission file for the competition with GPU acceleration and parallel processing\n        \n        Args:\n            test_dir: Directory containing test images\n            test_csv_path: Path to test CSV file\n            output_path: Path for output submission file\n            use_parallel: Whether to use parallel processing\n        \"\"\"\n        test_df = pd.read_csv(test_csv_path)\n        \n        print(f\"Generating submission for {len(test_df)} test samples...\")\n        print(f\"GPU acceleration: {'Enabled' if self.use_gpu else 'Disabled'}\")\n        print(f\"Parallel processing: {'Enabled' if use_parallel else 'Disabled'}\")\n        \n        if use_parallel and len(test_df) > 50:\n            # Use parallel processing for large datasets\n            submission_data = self._generate_submission_parallel(test_df, test_dir)\n        else:\n            # Sequential processing\n            submission_data = self._generate_submission_sequential(test_df, test_dir)\n        \n        # Create submission DataFrame and save\n        submission_df = pd.DataFrame(submission_data)\n        submission_df.to_csv(output_path, index=False)\n        print(f\"Submission saved to: {output_path}\")\n        \n        return submission_df\n    \n    def _generate_submission_sequential(self, test_df: pd.DataFrame, test_dir: str) -> List[Dict]:\n        \"\"\"Sequential submission generation\"\"\"\n        submission_data = []\n        \n        # Add progress bar\n        progress_bar = tqdm(test_df.iterrows(), total=len(test_df), desc=\"Generating submission\")\n        \n        for idx, row in progress_bar:\n            ecg_id = row['id']\n            lead = row['lead']\n            fs = row['fs']\n            num_rows = row['number_of_rows']\n            \n            # Process the test image\n            image_path = os.path.join(test_dir, f\"{ecg_id}.png\")\n            \n            if os.path.exists(image_path):\n                # Extract signal\n                signal = self.process_ecg_image(image_path, fs, lead)\n                \n                # Ensure signal has correct length\n                if len(signal) != num_rows:\n                    if self.use_gpu:\n                        signal = self.resample_signal_gpu(signal, num_rows)\n                    else:\n                        signal = self.resample_signal(signal, num_rows)\n                \n                # Create submission entries\n                for row_id in range(num_rows):\n                    submission_id = f\"{ecg_id}_{row_id}_{lead}\"\n                    value = signal[row_id] if row_id < len(signal) else 0.0\n                    submission_data.append({\n                        'id': submission_id,\n                        'value': value\n                    })\n                \n                # Update progress bar description\n                progress_bar.set_description(f\"Processing {ecg_id} - {lead}\")\n            else:\n                print(f\"Test image not found: {image_path}\")\n                # Fill with zeros if image not found\n                for row_id in range(num_rows):\n                    submission_id = f\"{ecg_id}_{row_id}_{lead}\"\n                    submission_data.append({\n                        'id': submission_id,\n                        'value': 0.0\n                    })\n        \n        return submission_data\n    \n    def _generate_submission_parallel(self, test_df: pd.DataFrame, test_dir: str) -> List[Dict]:\n        \"\"\"Parallel submission generation using multiprocessing\"\"\"\n        submission_data = []\n        \n        # Prepare data for parallel processing\n        processing_data = []\n        for idx, row in test_df.iterrows():\n            ecg_id = row['id']\n            lead = row['lead']\n            fs = row['fs']\n            num_rows = row['number_of_rows']\n            image_path = os.path.join(test_dir, f\"{ecg_id}.png\")\n            processing_data.append((ecg_id, lead, fs, num_rows, image_path))\n        \n        # Process in parallel\n        with ProcessPoolExecutor(max_workers=self.num_workers) as executor:\n            future_to_data = {\n                executor.submit(self._process_single_test_sample, data): data \n                for data in processing_data\n            }\n            \n            for future in future_to_data:\n                try:\n                    result = future.result()\n                    if result:\n                        submission_data.extend(result)\n                except Exception as e:\n                    ecg_id = future_to_data[future][0]\n                    print(f\"Error processing test ID {ecg_id}: {str(e)}\")\n                    # Fill with zeros if processing fails\n                    lead, fs, num_rows = future_to_data[future][1:4]\n                    for row_id in range(num_rows):\n                        submission_id = f\"{ecg_id}_{row_id}_{lead}\"\n                        submission_data.append({\n                            'id': submission_id,\n                            'value': 0.0\n                        })\n        \n        return submission_data\n    \n    def _process_single_test_sample(self, data):\n        \"\"\"Process a single test sample (for parallel processing)\"\"\"\n        ecg_id, lead, fs, num_rows, image_path = data\n        \n        # Create a new digitizer instance for this process (without PyTorch model)\n        digitizer = ECGDigitizer(use_gpu=False, num_workers=1)\n        \n        if os.path.exists(image_path):\n            # Extract signal\n            signal = digitizer.process_ecg_image(image_path, fs, lead)\n            \n            # Ensure signal has correct length\n            if len(signal) != num_rows:\n                signal = digitizer.resample_signal(signal, num_rows)\n            \n            # Create submission entries\n            submission_entries = []\n            for row_id in range(num_rows):\n                submission_id = f\"{ecg_id}_{row_id}_{lead}\"\n                value = signal[row_id] if row_id < len(signal) else 0.0\n                submission_entries.append({\n                    'id': submission_id,\n                    'value': value\n                })\n            \n            return submission_entries\n        else:\n            # Fill with zeros if image not found\n            submission_entries = []\n            for row_id in range(num_rows):\n                submission_id = f\"{ecg_id}_{row_id}_{lead}\"\n                submission_entries.append({\n                    'id': submission_id,\n                    'value': 0.0\n                })\n            return submission_entries\n\ndef main():\n    \"\"\"\n    Main function to run the complete ECG digitization solution with GPU acceleration\n    \"\"\"\n    print(\"PhysioNet ECG Image Digitization - GPU-Accelerated Complete Solution\")\n    print(\"=\" * 70)\n    \n    # Initialize the digitizer with GPU acceleration\n    digitizer = ECGDigitizer(use_gpu=True, num_workers=8)\n    \n    # Define paths (adjust these to match your data structure)\n    data_dir = \"/kaggle/input/physionet-ecg-image-digitization\"\n    train_csv_path = os.path.join(data_dir, \"train.csv\")\n    test_csv_path = os.path.join(data_dir, \"test.csv\")\n    train_dir = os.path.join(data_dir, \"train\")\n    test_dir = os.path.join(data_dir, \"test\")\n    \n    print(f\"\\nSystem Configuration:\")\n    print(f\"  - GPU Acceleration: {'Enabled' if digitizer.use_gpu else 'Disabled'}\")\n    print(f\"  - Number of Workers: {digitizer.num_workers}\")\n    if digitizer.use_gpu:\n        print(f\"  - GPU Devices: {digitizer.gpu_devices}\")\n        print(f\"  - GPU Memory per Device: 15GB\")\n        print(f\"  - Total GPU Memory: {digitizer.gpu_devices * 15}GB\")\n    \n    # Check if training data is available\n    if os.path.exists(train_csv_path) and os.path.exists(train_dir):\n        print(\"\\n1. Processing Training Data with GPU Acceleration...\")\n        training_results = digitizer.process_training_data(train_dir, train_csv_path, use_parallel=False)\n        \n        if training_results['snr_scores']:\n            avg_snr = np.mean(training_results['snr_scores'])\n            std_snr = np.std(training_results['snr_scores'])\n            print(f\"\\nTraining Results:\")\n            print(f\"  - Processed {len(training_results['processed_ids'])} samples\")\n            print(f\"  - Average SNR: {avg_snr:.2f} Â± {std_snr:.2f} dB\")\n            print(f\"  - Best SNR: {max(training_results['snr_scores']):.2f} dB\")\n            print(f\"  - Worst SNR: {min(training_results['snr_scores']):.2f} dB\")\n            print(f\"  - Errors: {len(training_results['errors'])}\")\n        else:\n            print(\"No training data processed successfully.\")\n    \n    # Generate submission if test data is available\n    if os.path.exists(test_csv_path) and os.path.exists(test_dir):\n        print(\"\\n2. Generating Submission with GPU Acceleration...\")\n        submission_path = \"submission.csv\"\n        submission_df = digitizer.generate_submission(test_dir, test_csv_path, submission_path, use_parallel=False)\n        print(f\"Submission generated with {len(submission_df)} predictions\")\n        \n        # Show sample of submission\n        print(f\"\\nSample submission entries:\")\n        print(submission_df.head(10))\n    else:\n        print(\"\\nTest data not found. Skipping submission generation.\")\n    \n    print(\"\\n\" + \"=\" * 70)\n    print(\"GPU-Accelerated ECG Digitization Solution Completed Successfully!\")\n    print(\"=\" * 70)\n\nif __name__ == \"__main__\":\n    main()","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\n","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}