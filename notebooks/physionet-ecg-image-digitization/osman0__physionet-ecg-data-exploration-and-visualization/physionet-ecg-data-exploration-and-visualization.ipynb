{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":97984,"databundleVersionId":14096757,"sourceType":"competition"}],"dockerImageVersionId":31153,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## 1. Load and Explore Metadata Files (train.csv, test.csv, sample_submission.parquet)\nFirst, we load the metadata files using pandas and inspect their contents. The training and test CSV files contain metadata for each ECG record, and the sample submission file shows the required output format for the competition. We will examine the number of records and the columns provided in each:","metadata":{}},{"cell_type":"code","source":"import pandas as pd\n\n# Load metadata files\ntrain_df = pd.read_csv(\"/kaggle/input/physionet-ecg-image-digitization/train.csv\")\ntest_df = pd.read_csv(\"/kaggle/input/physionet-ecg-image-digitization/test.csv\")\nsubmission_df = pd.read_parquet(\"/kaggle/input/physionet-ecg-image-digitization/sample_submission.parquet\")\n\n# Print basic information\nprint(f\"Training records: {len(train_df)}\")\nprint(f\"Test records: {len(test_df)}\")\nprint(\"Train columns:\", train_df.columns.tolist())\nprint(\"Test columns:\", test_df.columns.tolist())\nprint(\"Sample submission columns:\", submission_df.columns.tolist())\n\n# Peek at the first few rows of each\nprint(\"\\nTrain.csv sample:\")\nprint(train_df.head(3))  # first 3 rows of train metadata\nprint(\"\\nTest.csv sample:\")\nprint(test_df.head(3))\nprint(\"\\nSample_submission.parquet sample:\")\nprint(submission_df.head(5))","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-10-24T11:48:22.082141Z","iopub.execute_input":"2025-10-24T11:48:22.082481Z","iopub.status.idle":"2025-10-24T11:48:22.341585Z","shell.execute_reply.started":"2025-10-24T11:48:22.082445Z","shell.execute_reply":"2025-10-24T11:48:22.34078Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 2. Load and Visualize Sample ECG Time-Series (12-Lead Signals)\n\nNow, let’s load a few example ECG time-series from the training set and plot their 12-lead signals. Each training ECG has a corresponding CSV file (train/<id>/<id>.csv) containing the raw waveform data. This CSV has 12 columns, one for each ECG lead (typically labeled I, II, III, aVR, aVL, aVF, V1, V2, V3, V4, V5, V6 – the standard 12 leads ). We will:\n\t•\tSelect a few sample record IDs from train_df.\n\t•\tFor each example ID, read its CSV file into a DataFrame.\n\t•\tPrint the sampling frequency and signal length from the metadata (to know the time span of the recording).\n\t•\tPlot all 12 lead signals using matplotlib, arranging subplots for clarity.","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\n# Select a few example ECG IDs from the training set (e.g., first 2 records)\nexample_ids = train_df['id'].iloc[:2].tolist()\n\nfor ecg_id in example_ids:\n    # Load the raw time-series data for this ECG ID\n    filepath = f\"/kaggle/input/physionet-ecg-image-digitization/train/{ecg_id}/{ecg_id}.csv\"\n    ecg_signal = pd.read_csv(filepath)\n    \n    # Get sampling frequency (fs) and signal length from metadata\n    fs = train_df.loc[train_df['id'] == ecg_id, 'fs'].iloc[0]\n    sig_len = train_df.loc[train_df['id'] == ecg_id, 'sig_len'].iloc[0]\n    duration = sig_len / fs if fs else 0\n    print(f\"\\nECG ID: {ecg_id} -> Sampling frequency = {fs} Hz, Signal length = {sig_len} samples (~{duration:.1f} sec)\")\n    print(\"Lead columns:\", list(ecg_signal.columns))\n    \n    # Plot the 12-lead ECG signals\n    fig, axes = plt.subplots(nrows=6, ncols=2, figsize=(12, 8))\n    axes = axes.ravel()  # flatten the 6x2 grid to a 1D array for easy iteration\n    for i, lead in enumerate(ecg_signal.columns):\n        axes[i].plot(ecg_signal[lead], color='black')\n        axes[i].set_title(lead)\n        axes[i].set_xlabel(\"Sample index\")\n        axes[i].set_ylabel(\"Amplitude\")\n        # Optional: add grid or adjust y-axis for clarity\n        axes[i].grid(True, which='both', linestyle='--', linewidth=0.5)\n    plt.tight_layout()\n    plt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-24T11:49:31.85374Z","iopub.execute_input":"2025-10-24T11:49:31.854071Z","iopub.status.idle":"2025-10-24T11:49:35.428693Z","shell.execute_reply.started":"2025-10-24T11:49:31.854048Z","shell.execute_reply":"2025-10-24T11:49:35.42768Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## **3. Load and Visualize Sample ECG Images**\n\nIn addition to numeric signals, the dataset provides **ECG images** for each record. These are scans or renderings of the ECG paper printouts. Each training record’s folder contains one or more PNG images of the ECG (multiple images if the ECG spans more than one page) , and each test record has at least one ECG image (since our task is to digitize these images). We can use Matplotlib to load and display these images to understand how the ECGs look in image form.\n\n*Example of a 12-lead ECG image from the dataset (synthetic data). The 12 leads (I, II, III, aVR, aVL, aVF, V1–V6) are arranged on a standard grid. Time runs along the horizontal axis and voltage along the vertical axis; each small grid box typically represents 40 ms (horizontal) and 0.1 mV (vertical). The printout includes metadata (patient details, recording info) at the top, which in this example is synthetically generated or anonymized. This image illustrates the kind of input (paper ECG format) that needs to be converted back to digital signals.*\n\nIn code, let’s read and display one training ECG image and one test ECG image:","metadata":{}},{"cell_type":"code","source":"# Choose an example train ID and test ID to visualize images\ntrain_example_id = example_ids[0]            # use one of the earlier example IDs\ntest_example_id = test_df['id'].iloc[0]      # first test ID (for example)\n\n# Load and display the first page of the train ECG image\ntrain_img_path = f\"/kaggle/input/physionet-ecg-image-digitization/train/{train_example_id}/{train_example_id}-0001.png\"\ntrain_img = plt.imread(train_img_path)\nplt.figure(figsize=(6, 4))\nplt.imshow(train_img, cmap='gray')\nplt.title(f\"Train ECG Image - ID: {train_example_id} (page 1)\")\nplt.axis('off')  # hide axis ticks\nplt.show()\n\n# Load and display the test ECG image\ntest_img_path = f\"/kaggle/input/physionet-ecg-image-digitization/test/{test_example_id}.png\"\ntest_img = plt.imread(test_img_path)\nplt.figure(figsize=(6, 4))\nplt.imshow(test_img, cmap='gray')\nplt.title(f\"Test ECG Image - ID: {test_example_id}\")\nplt.axis('off')\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-24T11:50:33.497546Z","iopub.execute_input":"2025-10-24T11:50:33.497889Z","iopub.status.idle":"2025-10-24T11:50:35.317092Z","shell.execute_reply.started":"2025-10-24T11:50:33.497862Z","shell.execute_reply":"2025-10-24T11:50:35.316234Z"}},"outputs":[],"execution_count":null}]}