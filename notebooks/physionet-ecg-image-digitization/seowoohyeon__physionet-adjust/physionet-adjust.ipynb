{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":97984,"databundleVersionId":14096757,"sourceType":"competition"}],"dockerImageVersionId":31153,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# =========================================\n# Full pipeline (3/11) — Change-Limit BASE + 3 Creative Mix\n#  - BASE: Change-Limit(국소 MAD로 SG 평활과의 차이를 클램프)\n#  - + Energy Subpixel(강도×기울기)\n#  - + Crest(QRS) mask 보호(스무딩/보정/II 평균)\n#  - + Two-pass Narrow Corridor 재탐색\n#  - Non-color/test: mean fallback\n# =========================================\nimport os, cv2, numpy as np, pandas as pd, matplotlib.pyplot as plt\nfrom glob import glob\nfrom collections import defaultdict\nfrom tqdm import tqdm\nfrom typing import Tuple\n\nimport scipy.optimize, scipy.signal\n\n# -------------------------\n# 하이퍼파라미터 (필요시 여기만 조정)\n# -------------------------\nCROP_TOP = 400          # 헤더 컷\nPX_PER_MV = 80          # 80 px = 1 mV (type 3/11)\nLEADS = ['I','II','III','aVR','aVL','aVF','V1','V2','V3','V4','V5','V6']\nMAX_TIME_SHIFT = 0.2\nPERFECT_SCORE = 384\n\n# Subpixel energy\nSUBPIX_UPSCALE      = 1          # 1 or 2 (2면 더 미세하되 느려짐)\nENERGY_W_INT        = 0.6        # 강도 가중\nENERGY_W_GRAD       = 0.4        # 기울기 가중\nENERGY_SOFTARG_TAU  = 1.0        # soft-argmax 온도\n\n# Two-pass 협대역\nNARROW_BASE_HALF    = 26         # 1차 창 반높이(px)\nNARROW_MIN_HALF     = 10         # 2차 최소 반높이\nNARROW_MAX_HALF     = 24         # 2차 최대 반높이\nNARROW_K_SLOPE      = 120.0      # 기울기→높이 맵핑 상수(클수록 더 좁힘 약함)\n\n# Crest mask\nCREST_WIN_FRAC      = 0.004      # 파생량 계산(1차 미디안/SG) 윈도 비율\nCREST_PCT_DY        = 92.0       # |dy| 상위 퍼센타일\nCREST_PCT_D2        = 92.0       # |d2| 상위 퍼센타일\nCREST_DILATE_FRAC   = 0.008      # 마스크 팽창 폭 비율(전체 길이×)\nCREST_MIN_LEN       = 7          # 너무 짧은 마스크 제거\n\n# Change-Limit (BASE)\nCH_WIN_FRAC         = 0.015      # SG·MAD 창 비율\nCH_POLY             = 2\nCH_K_OUT            = 3.5        # crest 바깥 MAD 계수\nCH_K_IN             = 6.0        # crest 내부 MAD 계수(보호↑)\n\n# II 평균/Einthoven 보정 제약\nII_W_OUT            = 0.6        # crest 바깥 가중(II = 0.6, subset = 0.4)\nII_W_IN             = 0.85       # crest 내부는 II 가중↑(첨점 보존)\nEINTH_MAX_K_OUT     = 1.0        # 바깥 보정량 스케일\nEINTH_MAX_K_IN      = 0.3        # 내부(마스크) 보정량 스케일(보정 약화)\n\n# 안전 클리핑\nCLIP_MV             = 1.25       # 물리적 과대치 방지; 하드 0으로 날리지 않고 clip\n\n# -------------------------\n# Metric helpers\n# -------------------------\nclass ParticipantVisibleError(Exception): pass\n\ndef compute_power(label: np.ndarray, prediction: np.ndarray) -> Tuple[float, float]:\n    if label.ndim != 1 or prediction.ndim != 1:\n        raise ParticipantVisibleError('Inputs must be 1-dimensional arrays.')\n    if not np.any(np.isfinite(prediction)):\n        raise ParticipantVisibleError(\"prediction has no finite values.\")\n    prediction = prediction.copy()\n    prediction[~np.isfinite(prediction)] = 0\n    noise = label - prediction\n    return float(np.sum(label**2)), float(np.sum(noise**2))\n\ndef compute_snr(signal: float, noise: float) -> float:\n    if noise == 0: return PERFECT_SCORE\n    if signal == 0: return 0.0\n    return min((signal / noise), PERFECT_SCORE)\n\ndef align_signals(label: np.ndarray, pred: np.ndarray, max_shift: float = float('inf')) -> np.ndarray:\n    if np.any(~np.isfinite(label)): raise ParticipantVisibleError('values in label should all be finite')\n    if np.sum(np.isfinite(pred)) == 0: raise ParticipantVisibleError('prediction can not all be infinite')\n    la = np.asarray(label, dtype=np.float64)\n    pr = np.asarray(pred,  dtype=np.float64)\n    corr = scipy.signal.correlate(la - np.mean(la), pr - np.mean(pr), mode='full')\n    lags = scipy.signal.correlation_lags(la.size, pr.size, mode='full')\n    valid = (lags >= -max_shift) & (lags <= max_shift)\n    max_corr = np.nanmax(corr[valid])\n    best_i = min(np.flatnonzero(corr == max_corr), key=lambda i: abs(lags[i]))\n    shift = lags[best_i]\n    start_pad = max(shift, 0)\n    pred_start = max(-shift, 0); pred_end = min(la.size - shift, pr.size)\n    end_pad = max(la.size - pr.size - shift, 0)\n    aligned = np.concatenate([np.full(start_pad, np.nan), pr[pred_start:pred_end], np.full(end_pad, np.nan)])\n    def obj(v): return np.nansum((la - (aligned - v))**2)\n    if np.any(np.isfinite(la) & np.isfinite(aligned)):\n        res = scipy.optimize.minimize_scalar(obj, method='Brent')\n        aligned -= res.x\n    return aligned\n\n# -------------------------\n# Mean model (fallback)\n# -------------------------\ndef fit_mean_model(train_df, verbose=False):\n    mean_dict = defaultdict(list)\n    for _, row in tqdm(train_df.iterrows(), total=len(train_df)):\n        labels = pd.read_csv(f'/kaggle/input/physionet-ecg-image-digitization/train/{row.id}/{row.id}.csv')\n        for lead in labels.columns:\n            v = labels[lead].dropna().values\n            rs = np.interp(np.linspace(0, len(v)-1, 20000), np.arange(len(v)), v)\n            mean_dict[lead].append(rs)\n    for k in mean_dict.keys():\n        mean_dict[k] = np.stack(mean_dict[k])\n        if verbose:\n            m = mean_dict[k].mean(axis=0)\n            plt.figure(figsize=(12,2)); plt.title(f\"Mean {k}\"); plt.plot(m); plt.axhline(0,color='gray'); plt.show()\n    return mean_dict\n\ndef validate_mean_model(val_df, mean_dict):\n    snr_list = []\n    for _, row in tqdm(val_df.iterrows(), total=len(val_df)):\n        labels = pd.read_csv(f'/kaggle/input/physionet-ecg-image-digitization/train/{row.id}/{row.id}.csv')\n        sum_signal = 0.0; sum_noise = 0.0\n        for lead in labels.columns:\n            y = labels[lead].dropna().values\n            p = mean_dict[lead].mean(axis=0)\n            p = np.interp(np.linspace(0,1,len(y)), np.linspace(0,1,len(p)), p)\n            aligned = align_signals(y, p, int(row.fs * MAX_TIME_SHIFT))\n            ps, pn = compute_power(y, aligned)\n            sum_signal += ps; sum_noise += pn\n        snr_list.append(compute_snr(sum_signal, sum_noise))\n    snr = float(np.mean(snr_list))\n    val_score = max(float(10*np.log10(snr)), -PERFECT_SCORE)\n    print(f\"# Validation SNR for mean prediction: {snr:.2f} {val_score=:.2f}\")\n\n# -------------------------\n# Marker finder (스캔 전용)\n# -------------------------\nclass MarkerFinder:\n    def __init__(self, show_templates=False):\n        ima = np.max([\n            cv2.imread('/kaggle/input/physionet-ecg-image-digitization/train/4292118763/4292118763-0001.png'),\n            cv2.imread('/kaggle/input/physionet-ecg-image-digitization/train/4289880010/4289880010-0001.png'),\n            cv2.imread('/kaggle/input/physionet-ecg-image-digitization/train/4284351157/4284351157-0001.png'),\n        ], axis=0)\n        absolute_points = np.zeros((17, 2), dtype=int)\n        for i in range(3):\n            absolute_points[5*i] = np.array([707 + 284*i, 118])\n            for j in range(1,5):\n                absolute_points[5*i + j] = np.array([707 + 284*i, 118 + 492*j])\n        absolute_points[15] = np.array([1535, 118])\n        absolute_points[16] = np.array([1535, 118 + 492*4])\n        template_positions = [None]*17\n        for i in range(len(absolute_points)):\n            if absolute_points[i][1] < 118 + 492*4:\n                template_positions[i] = (absolute_points[i][0] - (87 if i%5==0 else 37),\n                                         absolute_points[i][1] - (50 if i%5==0 else 13))\n        template_sizes = np.array([(105, 60)]*17)\n        template_points = [\n            (np.array([absolute_points[i][0]-template_positions[i][0],\n                       absolute_points[i][1]-template_positions[i][1]])\n             if template_positions[i] is not None else None)\n            for i in range(17)\n        ]\n        templates = [None]*17\n        for i in range(17):\n            if template_points[i] is not None:\n                t,l = template_positions[i]; h,w = template_sizes[i]\n                templates[i] = ima[t:t+h, l:l+w]\n        self._template_positions = template_positions\n        self._template_sizes = template_sizes\n        self._template_points = template_points\n        self._templates = templates\n\n    def find_markers(self, ima, warn=False, plot=False, title=''):\n        if ima.shape[0] != 1652: raise ValueError(\"scanned only (3,4,11,12)\")\n        markers = [None]*17\n        for j in range(len(self._templates)):\n            if self._template_points[j] is None: continue\n            t0 = self._template_positions[j][0]-100\n            l0 = max(self._template_positions[j][1]-100, 0)\n            h  = self._template_sizes[j][0]; w  = self._template_sizes[j][1]\n            sr = ima[t0:self._template_positions[j][0]+100+h,\n                     l0:self._template_positions[j][1]+250+w]\n            if sr.size == 0: continue\n            res = cv2.matchTemplate(sr, self._templates[j], cv2.TM_CCOEFF)\n            _, _, _, max_loc = cv2.minMaxLoc(res)\n            top_left = max_loc\n            m = np.array((t0 + top_left[1] + self._template_points[j][0],\n                          l0 + top_left[0] + self._template_points[j][1]))\n            markers[j] = m\n        for i in range(3):\n            if (markers[5*i+3] is not None) and (markers[5*i+2] is not None):\n                markers[5*i+4] = markers[5*i+3]*2 - markers[5*i+2]\n        if (markers[14] is not None) and (markers[9] is not None):\n            markers[16] = ((markers[14]*(284+260) - markers[9]*260) / 284).astype(int)\n        if plot:\n            vis = ima.copy()\n            for m in markers:\n                if m is not None:\n                    cv2.rectangle(vis, (m[1]-40, m[0]-40), (m[1]+40, m[0]+40), (255,0,0), 2)\n            plt.imshow(vis); plt.title(title); plt.show()\n        return markers\n\n    @staticmethod\n    def lead_info(lead):\n        begin, end = {\n            'I': (0, 1), 'II-subset': (5, 6), 'III': (10, 11),\n            'aVR': (1, 2), 'aVL': (6, 7), 'aVF': (11, 12),\n            'V1': (2, 3), 'V2': (7, 8), 'V3': (12, 13),\n            'V4': (3, 4), 'V5': (8, 9), 'V6': (13, 14), 'II': (15, 16),\n        }[lead]\n        return begin // 5, begin, end\n\nmf = MarkerFinder(show_templates=False)\n\n# -------------------------\n# 라인(밴드) 탐색 — top-down sweep\n# -------------------------\ndef find_line_by_topdown_sweep(ima_bool):\n    top = np.argmin(ima_bool, axis=0)\n    H,W = ima_bool.shape\n    mask = np.arange(H).reshape(-1,1) >= top.reshape(1,-1)\n    ima_bool &= mask\n    bottom = np.argmax(ima_bool, axis=0)\n    bottomx = np.maximum(bottom, np.median(top) + 100).astype(int)\n    mask2 = (np.arange(H).reshape(-1,1) < bottomx.reshape(1,-1))\n    ima_bool |= mask2\n    ima_bool[:, :-1] |= mask2[:, 1:]\n    ima_bool[:, 1:]  |= mask2[:, :-1]\n    return top, bottom\n\n# -------------------------\n# (Creative #1) Energy-based subpixel centerline\n# -------------------------\ndef _softargmax_idx(vals, tau=1.0):\n    v = (vals - np.max(vals)) / max(tau, 1e-6)\n    p = np.exp(v); p /= (p.sum() + 1e-8)\n    ys = np.arange(len(vals), dtype=np.float32)\n    return float((p * ys).sum())\n\ndef _quad_peak_idx(vals, idx):\n    if idx <= 0 or idx >= len(vals)-1: return float(idx)\n    fm, f0, fp = float(vals[idx-1]), float(vals[idx]), float(vals[idx+1])\n    denom = (fm - 2*f0 + fp)\n    if abs(denom) < 1e-6: return float(idx)\n    delta = 0.5 * (fm - fp) / denom\n    return float(idx + np.clip(delta, -0.5, 0.5))\n\ndef _norm01(x):\n    x = x.astype(np.float32)\n    if x.size == 0: return x\n    mn, mx = float(x.min()), float(x.max())\n    if mx - mn < 1e-6: return np.zeros_like(x, dtype=np.float32)\n    return (x - mn) / (mx - mn)\n\ndef _centerline_energy(grayR, gradY, yt, yb, x):\n    colI = grayR[yt:yb+1, x].astype(np.float32)     # 잉크 = R반전\n    colG = gradY[yt:yb+1, x].astype(np.float32)     # 수직기울기\n    if colI.size == 0: return None\n    e = ENERGY_W_INT*_norm01(colI) + ENERGY_W_GRAD*_norm01(np.abs(colG))\n    return e\n\ndef _energy_peak_y(e, method=\"soft\"):\n    if e is None or len(e)==0: return 0.0\n    j = int(np.argmax(e))\n    if method == \"soft\":  return _softargmax_idx(e, tau=ENERGY_SOFTARG_TAU)\n    else:                 return _quad_peak_idx(e, j)\n\ndef _choose_centerline_energy(ima_crop_bgr, top, bottom, x0, x1,\n                              upscale=1, method=\"soft\", narrow_map=None):\n    \"\"\"\n    열 x는 [x0, x1) 범위. narrow_map은 길이 (x1-x0).\n    narrow_map에 접근할 때 절대 x가 아니라 '상대 인덱스'로 접근해야 한다.\n    \"\"\"\n    grayR = 255 - ima_crop_bgr[:,:,2]\n    gradY = cv2.Sobel(grayR, cv2.CV_32F, 0, 1, ksize=3)\n\n    if upscale > 1:\n        H,W = grayR.shape\n        grayR = cv2.resize(grayR, (W*upscale, H*upscale), interpolation=cv2.INTER_CUBIC)\n        gradY = cv2.resize(gradY, (W*upscale, H*upscale), interpolation=cv2.INTER_CUBIC) * upscale\n\n        top_u = (top * upscale).astype(np.int32)\n        bot_u = (bottom * upscale).astype(np.int32)\n        x0_u, x1_u = x0*upscale, x1*upscale\n\n        ys_u = np.zeros(max(1, x1_u - x0_u), np.float32)\n        H2, W2 = grayR.shape\n\n        for i, xu in enumerate(range(x0_u, min(x1_u, W2))):\n            # 절대→상대 인덱스 (열 오프셋)\n            if narrow_map is None:\n                half_u = NARROW_BASE_HALF * upscale\n            else:\n                rel = (xu - x0_u) // upscale                            # 0..(x1-x0-1)\n                rel = int(np.clip(rel, 0, len(narrow_map)-1))\n                half   = int(np.clip(narrow_map[rel], NARROW_MIN_HALF, NARROW_MAX_HALF))\n                half_u = half * upscale\n\n            xg = xu // upscale\n            # 밴드 중심\n            yc_u = int(0.5 * (top_u[xg] + bot_u[xg]))\n            yt = int(np.clip(yc_u - half_u, 0, H2-1))\n            yb = int(np.clip(yc_u + half_u, 0, H2-1))\n\n            e = _centerline_energy(grayR, gradY, yt, yb, xu)\n            ys_u[i] = yt + _energy_peak_y(e, method=method)\n\n        ys = cv2.resize(ys_u.reshape(1,-1), (max(1, x1-x0), 1), interpolation=cv2.INTER_AREA).ravel()\n        return ys\n\n    else:\n        H,W = grayR.shape\n        ys = np.zeros(max(1, x1 - x0), np.float32)\n\n        for i, x in enumerate(range(x0, min(x1, W))):\n            # 절대→상대 인덱스 (열 오프셋 i 사용)\n            if narrow_map is None:\n                half = NARROW_BASE_HALF\n            else:\n                rel = int(np.clip(i, 0, len(narrow_map)-1))             # 0..(x1-x0-1)\n                half = int(np.clip(narrow_map[rel], NARROW_MIN_HALF, NARROW_MAX_HALF))\n\n            yc = int(0.5 * (top[x] + bottom[x]))\n            yt = int(np.clip(yc - half, 0, H-1))\n            yb = int(np.clip(yc + half, 0, H-1))\n\n            e = _centerline_energy(grayR, gradY, yt, yb, x)\n            ys[i] = yt + _energy_peak_y(e, method=method)\n\n        if len(ys) >= 3:\n            ys = cv2.blur(ys.reshape(1,-1), (1,3)).ravel()\n        return ys\n\n\n# -------------------------\n# (Creative #2) Crest mask (QRS 보호)\n# -------------------------\ndef _sg(y, win):\n    win = max(5, win + (win%2==0))\n    if len(y) < win: return y.copy()\n    return scipy.signal.savgol_filter(y, win, 2, mode='interp').astype(np.float32)\n\ndef build_crest_mask(y):\n    n = len(y)\n    if n < 9: return np.zeros(n, dtype=bool)\n    w = max(5, int(n*CREST_WIN_FRAC)); w += (w%2==0)\n    y_s = _sg(y, w)\n    dy  = np.diff(y_s, prepend=y_s[:1])\n    d2  = np.diff(dy, prepend=dy[:1])\n\n    thr1 = np.percentile(np.abs(dy), CREST_PCT_DY)\n    thr2 = np.percentile(np.abs(d2), CREST_PCT_D2)\n    mask = (np.abs(dy) >= thr1) | (np.abs(d2) >= thr2)\n\n    # dilation\n    dil = max(3, int(n*CREST_DILATE_FRAC))\n    out = np.zeros_like(mask)\n    for i, v in enumerate(mask):\n        if not v: continue\n        s = max(0, i-dil); e = min(n, i+dil+1)\n        out[s:e] = True\n\n    # 짧은 조각 제거\n    clean = out.copy()\n    cnt = 0; s = None\n    for i, v in enumerate(out.tolist()+[False]):\n        if v and s is None: s = i\n        if not v and s is not None:\n            if (i - s) < CREST_MIN_LEN:\n                clean[s:i] = False\n            s = None\n    return clean\n\n# -------------------------\n# (BASE + Creative #3) Change-Limit + crest-aware\n# -------------------------\ndef change_limit_filter(y, crest_mask):\n    n = len(y)\n    if n < 9: return y.astype(np.float32)\n    w = max(7, int(n*CH_WIN_FRAC)); w += (w%2==0)\n    ys = _sg(y, w)\n    # rolling MAD\n    half = w//2\n    mad = np.zeros(n, np.float32)\n    for i in range(n):\n        s = max(0, i-half); e = min(n, i+half+1)\n        seg = y[s:e] - ys[s:e]\n        med = np.median(seg)\n        mad[i] = 1.4826*np.median(np.abs(seg - med)) + 1e-6\n    k = np.where(crest_mask, CH_K_IN, CH_K_OUT)\n    allowed = k * mad\n    y_lim = ys + np.clip(y - ys, -allowed, allowed)\n    return np.clip(y_lim, -CLIP_MV, CLIP_MV).astype(np.float32)\n\n# -------------------------\n# 3/11 중심선→전위 변환 (Two-pass + Energy subpixel)\n# -------------------------\ndef get_lead_from_energy_two_pass(ima_crop_bgr, tops, bottoms, lead, number_of_rows, markers):\n    line, b_idx, e_idx = mf.lead_info(lead)\n    top, bottom = tops[line], bottoms[line]\n    begin, end = markers[b_idx], markers[e_idx]\n    W = len(top)\n    if (begin is None) or (end is None):\n        x0, x1 = 0, W\n        base = np.linspace(top[x0], bottom[x1-1], max(1, x1-x0))  # 대략적(실제는 밴드 중간)\n    else:\n        x0 = int(np.clip(begin[1], 0, W-1))\n        x1 = int(np.clip(end[1],   0, W))\n        if x1 <= x0: x1 = min(W, x0+1)\n        base = np.linspace(begin[0]-CROP_TOP, end[0]-CROP_TOP, max(1, x1-x0))\n\n    # 1-pass: 기본 NARROW_BASE_HALF로 에너지 중심선\n    ys1 = _choose_centerline_energy(ima_crop_bgr, top, bottom, x0, x1,\n                                    upscale=SUBPIX_UPSCALE, method=\"soft\", narrow_map=None)\n\n    # 열별 기울기 → 협대역 지도\n    if len(ys1) >= 3:\n        slope = np.abs(np.diff(ys1, prepend=ys1[:1]))\n        slope_n = _norm01(slope)\n        hmap = NARROW_MAX_HALF - (slope_n * (NARROW_MAX_HALF - NARROW_MIN_HALF) * (ys1.size / NARROW_K_SLOPE))\n        hmap = np.clip(hmap, NARROW_MIN_HALF, NARROW_MAX_HALF)\n    else:\n        hmap = np.full_like(ys1, NARROW_BASE_HALF, dtype=np.float32)\n   \n    # 2-pass: 협대역으로 재탐색\n    ys2 = _choose_centerline_energy(ima_crop_bgr, top, bottom, x0, x1,\n                                    upscale=SUBPIX_UPSCALE, method=\"soft\", narrow_map=hmap)\n\n    base = base[:len(ys2)]\n    pred = (base - ys2) / PX_PER_MV\n\n    # 마커 가림 완화(경계 튐 방지)\n    if lead in ['aVR','aVL','aVF','V1','V2','V3','V4','V5','V6'] and len(pred) >= 5:\n        pred[:4][pred[:4] > 0.2] = pred[4]\n    if lead in ['I','II-subset','III','aVR','aVL','aVF','V1','V2','V3'] and len(pred) >= 6:\n        pred[-5:][pred[-5:] > 0.2] = pred[-6]\n    if lead in ['I','II-subset','III','II']:\n        if len(pred) >= 2 and 0.9 < pred[0] < 1.1 and pred[1] < 0.5:\n            pred[0] = pred[1]\n\n    pred = np.interp(np.linspace(0,1,number_of_rows), np.linspace(0,1,len(pred)), pred)\n    return np.clip(pred, -CLIP_MV, CLIP_MV).astype(np.float32)\n\n# -------------------------\n# Einthoven 보정(crest-aware) + II 평균(crest-aware)\n# -------------------------\ndef crest_aware_einthoven_and_II(preds):\n    # per-lead crest mask\n    masks = {ld: build_crest_mask(preds[ld]) for ld in LEADS}\n\n    # II vs II-subset은 호출부에서 가중 평균/보호 적용하므로 여기선 스킵\n\n    # I + III ≈ II (crest 내부 보정량 축소)\n    L = min(len(preds['I']), len(preds['III']), len(preds['II']))\n    if L > 0:\n        res = preds['I'][:L] + preds['III'][:L] - preds['II'][:L]\n        # 보정량 스케일\n        m = (masks['I'][:L] | masks['III'][:L] | masks['II'][:L])\n        scale = np.where(m, EINTH_MAX_K_IN, EINTH_MAX_K_OUT).astype(np.float32)\n        corr = (res/3) * scale\n        preds['I'][:L]   -= corr\n        preds['III'][:L] -= corr\n        preds['II'][:L]  += corr\n\n    # aVR + aVL + aVF ≈ 0\n    L2 = min(len(preds['aVR']), len(preds['aVL']), len(preds['aVF']))\n    if L2 > 0:\n        res2 = preds['aVR'][:L2] + preds['aVL'][:L2] + preds['aVF'][:L2]\n        m2 = (masks['aVR'][:L2] | masks['aVL'][:L2] | masks['aVF'][:L2])\n        scale2 = np.where(m2, EINTH_MAX_K_IN, EINTH_MAX_K_OUT).astype(np.float32)\n        corr2 = (res2/3) * scale2\n        preds['aVR'][:L2] -= corr2\n        preds['aVL'][:L2] -= corr2\n        preds['aVF'][:L2] -= corr2\n\ndef crest_aware_merge_II(ii, ii_subset):\n    n = min(len(ii), len(ii_subset))\n    if n == 0: return ii\n    mask = build_crest_mask(ii[:n]) | build_crest_mask(ii_subset[:n])\n    out = ii.copy()\n    # crest 내부: II 가중↑ + 피크 보호(더 큰 절댓값 유지)\n    mix_in  = II_W_IN*ii[:n] + (1.0-II_W_IN)*ii_subset[:n]\n    choose  = np.where(np.abs(ii[:n])>=np.abs(ii_subset[:n]), ii[:n], ii_subset[:n])\n    out[:n] = np.where(mask, choose, II_W_OUT*ii[:n] + (1.0-II_W_OUT)*ii_subset[:n])\n    # 경계 부드럽게\n    k = max(3, int(0.004*n)); k += (k%2==0)\n    out[:n] = _sg(out[:n], k)\n    return np.clip(out, -CLIP_MV, CLIP_MV).astype(np.float32)\n\n# -------------------------\n# 변환(3/11 컬러)\n# -------------------------\ndef convert_scanned_color(ima, markers, n_timesteps, verbose=False):\n    crop_top = CROP_TOP\n    # R 채널 기준 이진화(밴드 찾기용)\n    bw0 = (ima[crop_top:, :, 2] > 160).astype(np.uint8)\n    bw  = (bw0[:-2, :-2] + bw0[:-2, 1:-1] + bw0[:-2, 2:]\n         + bw0[1:-1, :-2] + bw0[1:-1, 1:-1] + bw0[1:-1, 2:]\n         + bw0[2:, :-2] + bw0[2:, 1:-1] + bw0[2:, 2:]) >= 7\n    if verbose:\n        plt.figure(figsize=(6,3)); plt.imshow(bw, cmap='gray'); plt.title('BW majority (R>160)'); plt.show()\n    # 밴드(4줄) 찾기\n    tops, bottoms = [], []; work = bw.copy()\n    for _ in range(4):\n        top, bottom = find_line_by_topdown_sweep(work)\n        tops.append(top); bottoms.append(bottom)\n\n    # 리드별 예측\n    n_ts = dict(n_timesteps); n_ts['II-subset'] = n_ts['I']\n    preds = {}\n    ima_crop = ima[crop_top:, :, :]\n    for lead in (LEADS + ['II-subset']):\n        y0 = get_lead_from_energy_two_pass(ima_crop, tops, bottoms, lead, n_ts[lead], markers)\n        # BASE: Change-Limit + crest-aware\n        crest = build_crest_mask(y0)\n        y1 = change_limit_filter(y0, crest)\n        preds[lead] = y1\n\n    # II + II-subset crest-aware 병합\n    L = min(len(preds['II']), len(preds['II-subset']))\n    if L > 0:\n        ii_merged = crest_aware_merge_II(preds['II'][:L], preds['II-subset'][:L])\n        preds['II'][:L] = ii_merged\n    if 'II-subset' in preds: del preds['II-subset']\n\n    # Einthoven crest-aware\n    crest_aware_einthoven_and_II(preds)\n\n    # 최종 clip\n    for ld in LEADS:\n        preds[ld] = np.clip(preds[ld], -CLIP_MV, CLIP_MV).astype(np.float32)\n    return preds\n\n# -------------------------\n# 간단 컬러 감지\n# -------------------------\ndef is_color_image(ima):\n    return ima.std(axis=2).mean() != 0\n\n# -------------------------\n# 검증 루틴(3/11만)\n# -------------------------\ndef validate_algorithm(train_df, image_types, convert_fn):\n    snr_list = []; index_list = []; is_first = True\n    for idx, row in train_df.iterrows():\n        labels = pd.read_csv(f'/kaggle/input/physionet-ecg-image-digitization/train/{row.id}/{row.id}.csv')\n        for path in sorted(glob(f'/kaggle/input/physionet-ecg-image-digitization/train/{row.id}/{row.id}-*.png')):\n            t = int(path[-8:-4])\n            if t not in image_types: continue\n            ima = cv2.imread(path)\n            markers = mf.find_markers(ima, plot=is_first, title='markers' if is_first else '')\n            n_ts = {ld: (~labels[ld].isna()).sum() for ld in LEADS}\n            preds = convert_fn(ima, markers, n_ts, verbose=is_first)\n\n            if is_first:\n                _, axs = plt.subplots(6,2, figsize=(12,18))\n            sum_signal = 0; sum_noise = 0\n            for i, ld in enumerate(LEADS):\n                y = labels[ld].dropna().values; p = preds[ld]\n                aligned = align_signals(y, p, int(row.fs*MAX_TIME_SHIFT))\n                ps, pn = compute_power(y, aligned); sum_signal += ps; sum_noise += pn\n                if is_first:\n                    ax = axs.T.ravel()[i]; ax.set_title(ld)\n                    ax.plot(y, label='y_true'); ax.plot(p, label='y_pred'); ax.legend()\n            if is_first: plt.tight_layout(); plt.suptitle('y_true vs y_pred', y=1.01); plt.show()\n\n            snr = compute_snr(sum_signal, sum_noise)\n            print(f\"idx={idx:4d} id={row.id:10d} type={t:2d} SNR: {snr:5.2f}\")\n            snr_list.append(snr); index_list.append([idx, t])\n            is_first = False\n\n    snr = float(np.mean(snr_list)) if snr_list else 0.0\n    val_score = max(float(10*np.log10(snr)) if snr>0 else -PERFECT_SCORE, -PERFECT_SCORE)\n    print(f\"# Average SNR: {snr:.2f} {val_score=:.2f}\")\n    pd.DataFrame(index_list, columns=['idx','type']).assign(snr=snr_list).to_csv('~snr.csv', index=False)\n\n# -------------------------\n# Main\n# -------------------------\nif __name__ == \"__main__\":\n    train = pd.read_csv('/kaggle/input/physionet-ecg-image-digitization/train.csv')\n    test  = pd.read_csv('/kaggle/input/physionet-ecg-image-digitization/test.csv')\n\n    # mean fallback 준비\n    split = 780\n    mean_dict = fit_mean_model(train.iloc[:split], verbose=False)\n    validate_mean_model(train.iloc[split:], mean_dict)\n    mean_dict = fit_mean_model(train, verbose=False)\n\n    # 검증: 컬러(3,11)만\n    print(\"\\n[Validate] Color scans (3,11) — BASE: Change-Limit + Energy + Crest + Narrow\")\n    validate_algorithm(train.iloc[100:110], image_types=[3,11], convert_fn=convert_scanned_color)\n\n    # 테스트 변환/제출(컬러만 변환, 아니면 mean)\n    submission = []; old_id=None; preds_cache=None\n    for _, row in test.iterrows():\n        if row.id != old_id:\n            path = f\"/kaggle/input/physionet-ecg-image-digitization/test/{row.id}.png\"\n            ima  = cv2.imread(path); preds_cache=None\n            if ima is not None and ima.shape[0]==1652 and is_color_image(ima):\n                try:\n                    ms  = mf.find_markers(ima, plot=False)\n                    n_ts = {ld: (row.fs*10 if ld=='II' else row.fs*10//4) for ld in LEADS}\n                    preds_cache = convert_scanned_color(ima, ms, n_ts, verbose=False)\n                    reason = \"converted_color_energyCL\"\n                except Exception as e:\n                    print(f\"[WARN] convert failed {row.id}: {e} -> mean fallback\"); preds_cache=None\n            else:\n                reason = \"mean_fallback\"\n            print(f\"[TEST] id={row.id} route={reason}\")\n            old_id = row.id\n\n        need = row.fs*10 if row.lead=='II' else row.fs*10//4\n        if preds_cache is not None:\n            pred = preds_cache[row.lead]\n        else:\n            pred = mean_dict[row.lead].mean(axis=0)\n            pred = np.interp(np.linspace(0,1,need), np.linspace(0,1,len(pred)), pred)\n        assert len(pred)==need\n        for t in range(need):\n            submission.append({\"id\": f\"{row.id}_{t}_{row.lead}\", \"value\": float(pred[t])})\n\n    sub = pd.DataFrame(submission)\n    sub.to_csv('submission.csv', index=False)\n    print(\"Length:\", len(sub))\n    print(sub.head())","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-10-31T19:56:31.796795Z","iopub.execute_input":"2025-10-31T19:56:31.797022Z"}},"outputs":[],"execution_count":null}]}