{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.13"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":91722,"databundleVersionId":14262372,"sourceType":"competition"},{"sourceId":13059803,"sourceType":"datasetVersion","datasetId":8264672}],"dockerImageVersionId":31154,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"papermill":{"default_parameters":{},"duration":71.602368,"end_time":"2025-11-01T13:01:47.606988","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2025-11-01T13:00:36.00462","version":"2.6.0"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Import warnings and suppress unnecessary outputs\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Import core libraries\nimport pandas as pd\nimport numpy as np\nimport optuna\n\n# Import modeling and evaluation tools\nfrom sklearn.model_selection import StratifiedKFold, train_test_split\nfrom sklearn.metrics import roc_auc_score\nfrom xgboost import XGBClassifier\n\n# Import plotting libraries\nimport plotly.graph_objects as go\nfrom plotly.subplots import make_subplots","metadata":{"_uuid":"705dd87e-4c98-49c8-b09f-28c31a84f272","_cell_guid":"993c385b-9db9-40ce-9919-3ed0e8e4ef75","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Define the data loading function\ndef load_data():\n    # Read train, test, and original datasets\n    train = pd.read_csv('/kaggle/input/playground-series-s5e11/train.csv')\n    test = pd.read_csv('/kaggle/input/playground-series-s5e11/test.csv')\n    orig = pd.read_csv('/kaggle/input/loan-prediction-dataset-2025/loan_dataset_20000.csv')\n\n    # Define target variable\n    target = 'loan_paid_back'\n\n    # Return datasets and target name\n    return train, test, orig, target","metadata":{"_uuid":"a778ccf3-114f-4e61-9056-3aa0f5495563","_cell_guid":"ac50037d-d30d-46d1-a038-478f0c8242d4","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Define preprocessing and feature engineering\ndef preprocess_data(train, test, orig, target):\n    # Define numerical columns for outlier treatment\n    numerical_cols = ['annual_income', 'debt_to_income_ratio', 'credit_score',\n                      'loan_amount', 'interest_rate']\n\n    # Apply IQR-based clipping for outlier removal\n    for col in numerical_cols:\n        Q1 = train[col].quantile(0.25)\n        Q3 = train[col].quantile(0.75)\n        IQR = Q3 - Q1\n        lower = Q1 - 1.5 * IQR\n        upper = Q3 + 1.5 * IQR\n        train[col] = train[col].clip(lower, upper)\n        test[col] = test[col].clip(lower, upper)\n\n    # Extract grade from grade_subgrade\n    train['grade'] = train['grade_subgrade'].str[0]\n    test['grade'] = test['grade_subgrade'].str[0]\n\n    # Create financial ratio features\n    train['loan_to_income'] = train['loan_amount'] / (train['annual_income'] + 1)\n    test['loan_to_income'] = test['loan_amount'] / (test['annual_income'] + 1)\n\n    train['total_debt'] = train['debt_to_income_ratio'] * train['annual_income']\n    test['total_debt'] = test['debt_to_income_ratio'] * test['annual_income']\n\n    # Create composite risk score feature\n    train['risk_score'] = (train['debt_to_income_ratio'] * 40 +\n                           (1 - train['credit_score'] / 850) * 30 +\n                           train['interest_rate'] * 2)\n\n    test['risk_score'] = (test['debt_to_income_ratio'] * 40 +\n                          (1 - test['credit_score'] / 850) * 30 +\n                          test['interest_rate'] * 2)\n\n    # Apply target encoding using original dataset means\n    base_cols = [col for col in train.columns if col not in ['id', target, 'grade']]\n    \n    for col in base_cols:\n        if col in orig.columns:\n            mean_map = orig.groupby(col)[target].mean()\n            train[f\"orig_mean_{col}\"] = train[col].map(mean_map)\n            test[f\"orig_mean_{col}\"] = test[col].map(mean_map)\n\n    # Define categorical and feature columns\n    categorical_cols = ['gender', 'marital_status', 'education_level',\n                        'employment_status', 'loan_purpose',\n                        'grade_subgrade', 'grade']\n\n    feature_cols = [col for col in train.columns if col not in ['id', target] + categorical_cols]\n\n    # Split into final feature matrices\n    X = train[feature_cols].copy()\n    y = train[target].copy()\n    X_test = test[feature_cols].copy()\n\n    # Return processed data\n    return X, y, X_test","metadata":{"_uuid":"25530c65-124b-4ce9-8887-3c5d02c054ab","_cell_guid":"152523e8-d5a2-4d6f-97fd-fa3d13f008b7","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Define Optuna objective function for XGBoost\ndef objective(trial, X, y):\n    # Suggest hyperparameters\n    params = {\n        'objective': 'binary:logistic',\n        'eval_metric': 'auc',\n        'max_depth': trial.suggest_int('max_depth', 2, 6),\n        'learning_rate': trial.suggest_float('learning_rate', 0.0025, 0.1, log=True),\n        'n_estimators': trial.suggest_int('n_estimators', 1000, 10000),\n        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 1.0),\n        'subsample': trial.suggest_float('subsample', 0.6, 1.0),\n        'min_child_weight': trial.suggest_int('min_child_weight', 1, 10),\n        'gamma': trial.suggest_float('gamma', 0.0, 0.3),\n        'reg_alpha': trial.suggest_float('reg_alpha', 0.0, 0.5),\n        'reg_lambda': trial.suggest_float('reg_lambda', 0.5, 2.0),\n        'random_state': 42,\n        'n_jobs': -1,\n        'device': 'cuda',\n        'tree_method': 'hist'\n    }\n\n    # Split data for validation\n    X_train, X_val, y_train, y_val = train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)\n\n    # Train model\n    model = XGBClassifier(**params)\n    model.fit(X_train, y_train, eval_set=[(X_val, y_val)],\n              early_stopping_rounds=100, verbose=0)\n\n    # Predict and calculate AUC\n    preds = model.predict_proba(X_val)[:, 1]\n    auc = roc_auc_score(y_val, preds)\n    return auc","metadata":{"_uuid":"7710e81d-ad4a-462b-9dc2-2507fceba96a","_cell_guid":"06ef444e-95e3-416f-9c2d-94ab7c040370","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Define function to run Optuna optimization\ndef optimize_hyperparameters(X, y, n_trials=30):\n    # Initialize Optuna study\n    study = optuna.create_study(direction='maximize')\n    study.optimize(lambda trial: objective(trial, X, y), n_trials=n_trials)\n\n    # Print best parameters and score\n    print(\"=\" * 80)\n    print(\"ðŸŽ¯ Optuna Hyperparameter Optimization Complete\")\n    print(f\"Best AUC Score: {study.best_value:.6f}\")\n    print(\"Best Parameters:\")\n    for key, val in study.best_params.items():\n        print(f\"{key}: {val}\")\n    print(\"=\" * 80)\n\n    # Return best parameters\n    return study.best_params","metadata":{"_uuid":"88a3e003-3c88-43a2-9878-b7918d26a04c","_cell_guid":"09b53f57-fded-4654-b85b-b32b97ab6773","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Define XGBoost model training with optimized parameters\ndef train_xgboost(X, y, X_test, best_params):\n    # Initialize cross-validation\n    N_SPLITS = 7\n    skf = StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=42)\n\n    # Add fixed parameters to Optuna params\n    params = best_params.copy()\n    params.update({\n        'objective': 'binary:logistic',\n        'eval_metric': 'auc',\n        'random_state': 42,\n        'n_jobs': -1,\n        'device': 'cuda',\n        'tree_method': 'hist'\n    })\n\n    # Initialize arrays\n    oof = np.zeros(len(X))\n    test_pred = np.zeros(len(X_test))\n    scores = []\n\n    # Train using stratified k-fold\n    for fold, (train_idx, val_idx) in enumerate(skf.split(X, y), 1):\n        X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n        y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n\n        model = XGBClassifier(**params)\n        model.fit(X_train, y_train, eval_set=[(X_val, y_val)],\n                  early_stopping_rounds=100, verbose=0)\n\n        oof[val_idx] = model.predict_proba(X_val)[:, 1]\n        test_pred += model.predict_proba(X_test)[:, 1] / N_SPLITS\n        scores.append(roc_auc_score(y_val, oof[val_idx]))\n\n    # Compute metrics\n    cv_auc = roc_auc_score(y, oof)\n    mean_auc = np.mean(scores)\n    std_auc = np.std(scores)\n\n    # Return predictions and performance\n    return oof, test_pred, cv_auc, mean_auc, std_auc","metadata":{"_uuid":"be23ea74-d1ac-4a2d-ab42-3629d857e76d","_cell_guid":"2b8781cc-4e39-4f55-ae5b-b69f08b8b8c4","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Define model evaluation and visualization\ndef evaluate_model(oof, y):\n    # Generate predictions\n    from sklearn.metrics import confusion_matrix, roc_curve, accuracy_score\n\n    y_pred = (oof > 0.5).astype(int)\n    cm = confusion_matrix(y, y_pred)\n\n    # Compute ROC curve\n    fpr, tpr, _ = roc_curve(y, oof)\n    auc_score = roc_auc_score(y, oof)\n    acc_score = accuracy_score(y, y_pred)\n\n    # Create subplots\n    fig = make_subplots(rows=1, cols=2, subplot_titles=('Confusion Matrix', 'ROC Curve'),\n                        specs=[[{'type': 'heatmap'}, {'type': 'scatter'}]])\n\n    # Add confusion matrix\n    fig.add_trace(go.Heatmap(z=cm, x=['Pred Default', 'Pred Paid'],\n                             y=['Act Default', 'Act Paid'], showscale=False),\n                  row=1, col=1)\n\n    # Add ROC curve\n    fig.add_trace(go.Scatter(x=fpr, y=tpr, mode='lines',\n                             name=f'XGBoost (AUC={auc_score:.4f})', line=dict(width=3)),\n                  row=1, col=2)\n\n    # Add diagonal\n    fig.add_trace(go.Scatter(x=[0, 1], y=[0, 1], mode='lines',\n                             name='Random', line=dict(width=2, dash='dash')),\n                  row=1, col=2)\n\n    # Update layout\n    fig.update_layout(title=f'XGBoost | AUC: {auc_score:.6f} | Accuracy: {acc_score:.4f}',\n                      height=500)\n    fig.show()","metadata":{"_uuid":"dd90ed9f-08eb-4312-84ea-4be71aaa4db5","_cell_guid":"8457e1d6-296e-427c-8ed6-135cba4255cd","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Define the submission generator\ndef save_submission(test, target, test_pred):\n    # Create submission dataframe\n    submission = pd.DataFrame({'id': test['id'], target: test_pred})\n\n    # Save file\n    submission.to_csv('submission.csv', index=False)\n\n    # Print summary\n    print(\"=\" * 80)\n    print(\"ðŸ“ˆ XGBoost Model Summary\")\n    print(f\"File Saved: submission.csv ({len(submission)} rows)\")\n    print(\"=\" * 80)","metadata":{"_uuid":"b0e4b9ff-9eb1-46a0-bcf3-bdf6f6c422be","_cell_guid":"26a7b9c3-9a24-4b86-923d-a2a9d1f7e532","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Define the main function\ndef main():\n    # Load datasets\n    train, test, orig, target = load_data()\n\n    # Preprocess data\n    X, y, X_test = preprocess_data(train, test, orig, target)\n\n    # Optimize with Optuna\n    best_params = optimize_hyperparameters(X, y, n_trials=768)\n\n    # Train model\n    oof, test_pred, cv_auc, mean_auc, std_auc = train_xgboost(X, y, X_test, best_params)\n\n    # Evaluate model\n    evaluate_model(oof, y)\n\n    # Display results\n    print(\"=\" * 80)\n    print(\"âœ… Cross-Validation Results\")\n    print(f\"OOF AUC: {cv_auc:.6f}\")\n    print(f\"Mean Fold AUC: {mean_auc:.6f} Â± {std_auc:.6f}\")\n    print(\"=\" * 80)\n\n    # Save submission\n    save_submission(test, target, test_pred)","metadata":{"_uuid":"4948971b-3d90-4e2c-99ff-69acacf4fd5d","_cell_guid":"0444c301-33e9-4e17-b9ff-3782340b6b10","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Execute script\nif __name__ == \"__main__\":\n    main()","metadata":{"_uuid":"ad8152e9-dc13-49f2-ada4-7c1a24d104ec","_cell_guid":"599c6987-1da8-4cfd-a79d-9d6814ccc8c0","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null}]}