{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":91722,"databundleVersionId":14262372,"isSourceIdPinned":false,"sourceType":"competition"},{"sourceId":13059803,"sourceType":"datasetVersion","datasetId":8264672}],"dockerImageVersionId":31154,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-02T15:05:36.155492Z","iopub.execute_input":"2025-11-02T15:05:36.156231Z","iopub.status.idle":"2025-11-02T15:05:36.418196Z","shell.execute_reply.started":"2025-11-02T15:05:36.156197Z","shell.execute_reply":"2025-11-02T15:05:36.417538Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_df = pd.read_csv('/kaggle/input/playground-series-s5e11/train.csv')\ntest_df = pd.read_csv('/kaggle/input/playground-series-s5e11/test.csv')\norig = pd.read_csv('/kaggle/input/loan-prediction-dataset-2025/loan_dataset_20000.csv')\n\nprint('Train Shape:', train_df.shape)\nprint('Test Shape:', test_df.shape)\n\ntrain = train_df.copy()\ntest = test_df.copy()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-02T15:05:36.419594Z","iopub.execute_input":"2025-11-02T15:05:36.419889Z","iopub.status.idle":"2025-11-02T15:05:38.0929Z","shell.execute_reply.started":"2025-11-02T15:05:36.419872Z","shell.execute_reply":"2025-11-02T15:05:38.092196Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Define target and categorical columns\nTARGET = 'loan_paid_back'  # boolean\nCATEGORICAL_COLS = ['gender', 'marital_status', 'education_level', 'employment_status', 'loan_purpose', 'grade_subgrade']\nBASE = [col for col in train_df.columns if col not in ['id', TARGET]]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-02T15:05:38.093651Z","iopub.execute_input":"2025-11-02T15:05:38.09391Z","iopub.status.idle":"2025-11-02T15:05:38.098049Z","shell.execute_reply.started":"2025-11-02T15:05:38.093892Z","shell.execute_reply":"2025-11-02T15:05:38.097384Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Create ORIG Features\nORIG = []\n\nfor col in BASE:\n    # MEAN\n    mean_map = orig.groupby(col)[TARGET].mean()\n    new_mean_col_name = f\"orig_mean_{col}\"\n    mean_map.name = new_mean_col_name\n    \n    train = train.merge(mean_map, on=col, how='left')\n    test = test.merge(mean_map, on=col, how='left')\n    ORIG.append(new_mean_col_name)\n\n    # COUNT\n    new_count_col_name = f\"orig_count_{col}\"\n    count_map = orig.groupby(col).size().reset_index(name=new_count_col_name)\n    \n    train = train.merge(count_map, on=col, how='left')\n    test = test.merge(count_map, on=col, how='left')\n    ORIG.append(new_count_col_name)\n\nprint(f'‚úÖ {len(ORIG)} ORIG Features created!')\n\n# Create FEATURES list\nFEATURES = BASE + ORIG\nprint(f'‚úÖ Total {len(FEATURES)} features (BASE: {len(BASE)} + ORIG: {len(ORIG)})')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-02T15:05:38.098859Z","iopub.execute_input":"2025-11-02T15:05:38.099103Z","iopub.status.idle":"2025-11-02T15:05:42.255075Z","shell.execute_reply.started":"2025-11-02T15:05:38.099082Z","shell.execute_reply":"2025-11-02T15:05:42.254318Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Add numerical_cols to the FEATURES list and remove duplicates\nnumerical_cols = ['annual_income', 'debt_to_income_ratio', 'credit_score', \n                  'loan_amount', 'interest_rate']\n\n# Limit outliers\nfor col in numerical_cols:\n    Q1 = train[col].quantile(0.25)\n    Q3 = train[col].quantile(0.75)\n    IQR = Q3 - Q1\n    lower_bound = Q1 - 1.5 * IQR\n    upper_bound = Q3 + 1.5 * IQR\n    train[col] = train[col].clip(lower=lower_bound, upper=upper_bound)\n    test[col] = test[col].clip(lower=lower_bound, upper=upper_bound)\n\n# Add numerical_cols to the FEATURES list\nFEATURES = list(set(FEATURES + numerical_cols))  # Use set to remove duplicates\nprint(f'‚úÖ FEATURES list updated: {len(FEATURES)} features')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-02T15:05:42.25695Z","iopub.execute_input":"2025-11-02T15:05:42.257231Z","iopub.status.idle":"2025-11-02T15:05:42.453996Z","shell.execute_reply.started":"2025-11-02T15:05:42.257214Z","shell.execute_reply":"2025-11-02T15:05:42.453358Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Display the list of all features\nprint(\"List of all features:\")\nfor i, feature in enumerate(FEATURES, 1):\n    print(f\"{i}. {feature}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-02T15:05:42.454741Z","iopub.execute_input":"2025-11-02T15:05:42.454922Z","iopub.status.idle":"2025-11-02T15:05:42.459691Z","shell.execute_reply.started":"2025-11-02T15:05:42.454906Z","shell.execute_reply":"2025-11-02T15:05:42.458906Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Preprocessing function (for reuse)\ndef preprocess_features(df, features, cat_cols, numeric_cols):\n    \"\"\"Prepare categorical and numeric columns\"\"\"\n    df_processed = df[features].copy()\n    for col in cat_cols:\n        if col in df_processed.columns:\n            df_processed[col] = df_processed[col].fillna('NA').astype('category')\n    for col in numeric_cols:\n        if col in df_processed.columns:\n            df_processed[col] = df_processed[col].fillna(0)\n    return df_processed\n\nprint('‚úÖ Preprocessing function defined')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-02T15:05:42.460536Z","iopub.execute_input":"2025-11-02T15:05:42.460823Z","iopub.status.idle":"2025-11-02T15:05:42.473326Z","shell.execute_reply.started":"2025-11-02T15:05:42.460807Z","shell.execute_reply":"2025-11-02T15:05:42.472707Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ====== Split train data ======\nfrom sklearn.model_selection import train_test_split\n\nX = train.drop(columns=[TARGET])\ny = train[TARGET]\n\nX_train, X_valid, y_train, y_valid = train_test_split(\n    X, y, test_size=0.2, random_state=42, stratify=y\n    )\nprint('‚úÖ Train-test split completed')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-02T15:05:42.47417Z","iopub.execute_input":"2025-11-02T15:05:42.474417Z","iopub.status.idle":"2025-11-02T15:05:43.519734Z","shell.execute_reply.started":"2025-11-02T15:05:42.474395Z","shell.execute_reply":"2025-11-02T15:05:43.518904Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Prepare data for optimization\nnumeric_cols_opt = [col for col in FEATURES if col not in CATEGORICAL_COLS]\nX_train_split_opt = preprocess_features(X_train, FEATURES, CATEGORICAL_COLS, numeric_cols_opt)\nX_val_split_opt = preprocess_features(X_valid, FEATURES, CATEGORICAL_COLS, numeric_cols_opt)\nX_test_opt = preprocess_features(test, FEATURES, CATEGORICAL_COLS, numeric_cols_opt)\n\nprint('‚úÖ Data prepared for optimization')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-02T15:05:43.520569Z","iopub.execute_input":"2025-11-02T15:05:43.520968Z","iopub.status.idle":"2025-11-02T15:05:44.598505Z","shell.execute_reply.started":"2025-11-02T15:05:43.520936Z","shell.execute_reply":"2025-11-02T15:05:44.597778Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 2Ô∏è‚É£ HYPERPARAMETER TUNING (Optuna)\nimport optuna\nfrom optuna.samplers import TPESampler\nfrom xgboost import XGBClassifier\nfrom sklearn.metrics import roc_auc_score\n\nprint('='*70)\nprint('2Ô∏è‚É£  HYPERPARAMETER TUNING (Optuna)')\nprint('='*70)\n\ndef objective(trial):\n    \"\"\"Optuna objective function\"\"\"\n    params = {\n        'n_estimators': 10000,\n        'max_depth': trial.suggest_int('max_depth', 4, 6),\n        'learning_rate': trial.suggest_float('learning_rate', 0.0095, 0.0105, log=True),\n        'tree_method': 'hist',\n        'device': 'cuda',\n        'eval_metric': 'auc',\n        'objective': 'binary:logistic',\n        'random_state': 42,\n        'min_child_weight': trial.suggest_int('min_child_weight', 1, 20),\n        'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n        'gamma': trial.suggest_float('gamma', 0, 0.7),\n        'reg_alpha': trial.suggest_float('reg_alpha', 0, 1.2),\n        'reg_lambda': trial.suggest_float('reg_lambda', 0, 1),\n        'enable_categorical': True,\n        'early_stopping_rounds': 50,\n    }\n\n    model_trial = XGBClassifier(**params)\n    model_trial.fit(\n        X_train_split_opt, y_train,\n        eval_set=[(X_val_split_opt, y_valid)],\n        verbose=False\n    )\n    \n    y_pred = model_trial.predict_proba(X_val_split_opt)[:, 1]\n    auc = roc_auc_score(y_valid, y_pred)\n    \n    return auc\n\n# Optuna study\nprint('\\nüîç Optuna optimization starting...')\n\nstudy = optuna.create_study(\n    direction='maximize', \n    study_name='xgboost_optimization',\n    sampler=TPESampler(seed=42)\n)\n\nstudy.optimize(objective, n_trials=5, timeout=3600, show_progress_bar=True)\n\nprint(f'\\n‚úÖ Optimization completed!')\nprint(f'   Best trial: {study.best_trial.number}')\nprint(f'   Best AUC: {study.best_value:.4f}')\nprint(f'\\nüìä Best parameters:')\nfor key, value in study.best_params.items():\n    print(f'   {key}: {value}')\n\n# Final model with best parameters\nbest_params = study.best_params.copy()\nbest_params.update({\n    'n_estimators': 10000,\n    'tree_method': 'hist',\n    'device': 'cuda',\n    'eval_metric': 'auc',\n    'objective': 'binary:logistic',\n    'random_state': 42,\n    'enable_categorical': True,\n    'early_stopping_rounds': 50,\n})\n\nprint('\\nüöÄ Training final model with best parameters...')\nfinal_model = XGBClassifier(**best_params)\nfinal_model.fit(\n    X_train_split_opt, y_train,\n    eval_set=[(X_train_split_opt, y_train), (X_val_split_opt, y_valid)],\n    verbose=1000\n)\n\n# Predict on test set with tuned model\npred_tuned = final_model.predict_proba(X_test_opt)[:, 1]\n\nsubmission_tuned = pd.DataFrame({\n    \"id\": test[\"id\"],\n    TARGET: pred_tuned\n})\n\nsubmission_tuned.to_csv(\"submission_xgboost_tuned.csv\", index=False)\nprint(f'\\nüìÅ Tuned submission saved: submission_xgboost_tuned.csv')\n\n# Validation AUC\ny_val_pred_tuned = final_model.predict_proba(X_val_split_opt)[:, 1]\nval_auc_tuned = roc_auc_score(y_valid, y_val_pred_tuned)\nprint(f'   Validation AUC: {val_auc_tuned:.4f}')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-02T15:05:44.599271Z","iopub.execute_input":"2025-11-02T15:05:44.599492Z","iopub.status.idle":"2025-11-02T15:09:35.934159Z","shell.execute_reply.started":"2025-11-02T15:05:44.599467Z","shell.execute_reply":"2025-11-02T15:09:35.933343Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 3Ô∏è‚É£ FEATURE SELECTION (Remove low-importance features)\nimport matplotlib.pyplot as plt\n\nprint('='*70)\nprint('3Ô∏è‚É£  FEATURE SELECTION')\nprint('='*70)\n\n# Calculate feature importance from the best model (use tuned or early stopping model)\n# Here, we use the final_model (tuned)\nfeature_importance_sel = pd.DataFrame({\n    'feature': X_train_split_opt.columns,\n    'importance': final_model.feature_importances_\n}).sort_values('importance', ascending=False)\n\nprint('\\nüìä Feature Importance Statistics:')\nprint(feature_importance_sel['importance'].describe())\n\n# Identify low-importance features\n# Threshold: features below the median or with very low importance\nthreshold = feature_importance_sel['importance'].quantile(0.25)  # Bottom 25%\nlow_importance_features = feature_importance_sel[feature_importance_sel['importance'] < threshold]['feature'].tolist()\n\nprint(f'\\nüóëÔ∏è  {len(low_importance_features)} low-importance features found (importance < {threshold:.2f})')\nprint(f'   Total number of features: {len(FEATURES)}')\nprint(f'   Remaining features: {len(FEATURES) - len(low_importance_features)}')\n\n# Display the 10 least important features\nprint(f'\\n   10 least important features:')\nfor i, row in feature_importance_sel.tail(10).iterrows():\n    print(f'     {row[\"feature\"]}: {row[\"importance\"]:.2f}')\n\n# Create new feature set\nFEATURES_SELECTED = [f for f in FEATURES if f not in low_importance_features]\nnumeric_cols_selected = [c for c in FEATURES_SELECTED if c not in CATEGORICAL_COLS]\n\nprint(f'\\n‚úÖ New feature set prepared: {len(FEATURES_SELECTED)} features')\n\n# Retrain the model\nX_train_selected = preprocess_features(train, FEATURES_SELECTED, CATEGORICAL_COLS, numeric_cols_selected)\nX_test_selected = preprocess_features(test, FEATURES_SELECTED, CATEGORICAL_COLS, numeric_cols_selected)\n\nX_train_split_selected = preprocess_features(X_train, FEATURES_SELECTED, CATEGORICAL_COLS, numeric_cols_selected)\nX_val_split_selected = preprocess_features(X_valid, FEATURES_SELECTED, CATEGORICAL_COLS, numeric_cols_selected)\n\nprint('\\nüöÄ Training model with selected features...')\n# Override early_stopping_rounds to 200 for longer training\nparams_selected = best_params.copy()\nparams_selected['early_stopping_rounds'] = 200\nparams_selected['n_estimators'] = 10000\n\nmodel_selected = XGBClassifier(**params_selected)\n\n\nmodel_selected.fit(\n    X_train_split_selected, y_train,\n    eval_set=[(X_train_split_selected, y_train), (X_val_split_selected, y_valid)],\n    verbose=100\n)\n\nprint(f'\\n‚úÖ Feature selection model training completed!')\n\n# Predict\npred_selected = model_selected.predict_proba(X_test_selected)[:, 1]\n\nsubmission_selected = pd.DataFrame({\n    \"id\": test[\"id\"],\n    TARGET: pred_selected\n})\n\nsubmission_selected.to_csv(\"submission_xgboost_selected.csv\", index=False)\nprint(f'üìÅ Submission saved: submission_xgboost_selected.csv')\n\n# Validation AUC\ny_val_pred_selected = model_selected.predict_proba(X_val_split_selected)[:, 1]\nval_auc_selected = roc_auc_score(y_valid, y_val_pred_selected)\nprint(f'   Validation AUC: {val_auc_selected:.4f}')\n\n# Feature reduction comparison\nprint(f'\\nüìâ Feature reduction results:')\nprint(f'   Before: {len(FEATURES)} features ‚Üí After: {len(FEATURES_SELECTED)} features')\nprint(f'   Reduction: {len(low_importance_features)} features ({100*len(low_importance_features)/len(FEATURES):.1f}%)')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-02T15:12:04.96285Z","iopub.execute_input":"2025-11-02T15:12:04.963312Z","iopub.status.idle":"2025-11-02T15:13:08.826011Z","shell.execute_reply.started":"2025-11-02T15:12:04.963289Z","shell.execute_reply":"2025-11-02T15:13:08.825109Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 4Ô∏è‚É£ CROSS-VALIDATION for Robust Predictions\nfrom sklearn.model_selection import StratifiedKFold\nimport numpy as np\nfrom xgboost import XGBClassifier\nfrom sklearn.metrics import roc_auc_score\n\nprint('='*70)\nprint('4Ô∏è‚É£  K-FOLD CROSS-VALIDATION (5-Fold)')\nprint('='*70)\n\n# Use best_params if available, otherwise use baseline parameters\ntry:\n    params_to_use = best_params.copy()\n    print('‚úÖ Using Optuna best_params')\nexcept NameError:\n    print('‚ö†Ô∏è  best_params not found, using baseline parameters')\n    params_to_use = {\n        'n_estimators': 10000,\n        'max_depth': 6,\n        'learning_rate': 0.01,\n        'tree_method': 'hist',\n        'device': 'cuda',\n        'eval_metric': 'auc',\n        'objective': 'binary:logistic',\n        'random_state': 42,\n        'min_child_weight': 89,\n        'subsample': 1.0,\n        'colsample_bytree': 1.0,\n        'gamma': 0.11,\n        'reg_alpha': 1.8,\n        'reg_lambda': 5.2,\n        'enable_categorical': True,\n        'early_stopping_rounds': 100,\n    }\n\nn_folds = 5\nkf = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=42)\n\n# Array for out-of-fold predictions\noof_predictions = np.zeros(len(train))\ntest_predictions = np.zeros(len(test))\n\nfold_scores = []\n\n# Select feature set: use FEATURES_SELECTED if available, otherwise use FEATURES\ntry:\n    features_to_use = FEATURES_SELECTED\n    numeric_cols_to_use = numeric_cols_selected\n    print(f'‚úÖ Using FEATURES_SELECTED: {len(features_to_use)} features')\nexcept NameError:\n    features_to_use = FEATURES\n    numeric_cols_to_use = [col for col in FEATURES if col not in CATEGORICAL_COLS]\n    print(f'‚ö†Ô∏è  FEATURES_SELECTED not found, using all FEATURES: {len(features_to_use)} features')\n\n# Prepare CV data\nX_train_cv = preprocess_features(train, features_to_use, CATEGORICAL_COLS, numeric_cols_to_use)\ny_train_cv = train[TARGET].astype(int)\nX_test_cv = preprocess_features(test, features_to_use, CATEGORICAL_COLS, numeric_cols_to_use)\n\nprint(f'‚úÖ CV data prepared: {X_train_cv.shape}')\n\nfor fold, (train_idx, val_idx) in enumerate(kf.split(X_train_cv, y_train_cv), 1):\n    print(f'\\n{\"=\"*50}')\n    print(f'üìÇ Fold {fold}/{n_folds}')\n    print(f'{\"=\"*50}')\n    \n    X_fold_train = X_train_cv.iloc[train_idx]\n    y_fold_train = y_train_cv.iloc[train_idx]\n    X_fold_val = X_train_cv.iloc[val_idx]\n    y_fold_val = y_train_cv.iloc[val_idx]\n    \n    print(f'   Train: {X_fold_train.shape}, Val: {X_fold_val.shape}')\n    \n    # Create model\n    fold_model = XGBClassifier(**params_to_use)\n    \n    print(f'   üöÄ Training model...')\n    fold_model.fit(\n        X_fold_train, y_fold_train,\n        eval_set=[(X_fold_val, y_fold_val)],\n        verbose=1000\n    )\n    \n    # Validation predictions\n    oof_predictions[val_idx] = fold_model.predict_proba(X_fold_val)[:, 1]\n    \n    # Test predictions (average across folds)\n    test_predictions += fold_model.predict_proba(X_test_cv)[:, 1] / n_folds\n    \n    fold_auc = roc_auc_score(y_fold_val, oof_predictions[val_idx])\n    fold_scores.append(fold_auc)\n    print(f'   ‚úÖ Fold {fold} AUC: {fold_auc:.4f}')\n\n# Overall CV score\ncv_auc = roc_auc_score(y_train_cv, oof_predictions)\ncv_std = np.std(fold_scores)\n\nprint(f'\\n{\"=\"*70}')\nprint(f'üìä CROSS-VALIDATION RESULTS')\nprint(f'{\"=\"*70}')\nprint(f'   Overall CV AUC: {cv_auc:.4f}')\nprint(f'   Std Dev: {cv_std:.4f}')\nprint(f'   Min Fold AUC: {min(fold_scores):.4f}')\nprint(f'   Max Fold AUC: {max(fold_scores):.4f}')\nprint(f'\\n   Fold AUC Details:')\nfor i, score in enumerate(fold_scores, 1):\n    print(f'     Fold {i}: {score:.4f}')\n\n# CV submission\nsubmission_cv = pd.DataFrame({\n    \"id\": test[\"id\"],\n    TARGET: test_predictions\n})\n\nsubmission_cv.to_csv(\"submission_xgboost_cv.csv\", index=False)\nprint(f'\\nüìÅ CV submission saved: submission_xgboost_cv.csv')\nprint(f'   This is the most robust prediction! (5-fold average)')\n\n# Visualize Fold AUCs\nimport matplotlib.pyplot as plt\n\nplt.figure(figsize=(10, 6))\nplt.bar(range(1, n_folds+1), fold_scores, color='steelblue', alpha=0.7, edgecolor='black')\nplt.axhline(y=cv_auc, color='red', linestyle='--', linewidth=2, label=f'Mean AUC: {cv_auc:.4f}')\nplt.xlabel('Fold', fontsize=12)\nplt.ylabel('AUC Score', fontsize=12)\nplt.title('Cross-Validation: Fold-wise AUC Scores', fontsize=14, fontweight='bold')\nplt.legend(fontsize=11)\nplt.grid(axis='y', alpha=0.3)\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-02T15:13:27.021136Z","iopub.execute_input":"2025-11-02T15:13:27.021875Z","iopub.status.idle":"2025-11-02T15:16:47.721928Z","shell.execute_reply.started":"2025-11-02T15:13:27.021852Z","shell.execute_reply":"2025-11-02T15:16:47.720769Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.linear_model import Ridge\nfrom sklearn.model_selection import cross_val_score\n\n# Load the CSV files\nxgboost_csv = pd.read_csv('submission_xgboost_cv.csv')\nxgboost_tuned = pd.read_csv('submission_xgboost_tuned.csv')\nxgboost_selected = pd.read_csv('submission_xgboost_selected.csv')\n\n# Assuming the CSVs have predictions columns\n# Extract prediction columns (adjust column names as needed)\npredictions = pd.DataFrame({\n    'xgb_cv': xgboost_csv.iloc[:, -1],  # Last column assumed to be predictions\n    'xgb_tuned': xgboost_tuned.iloc[:, -1],\n    'xgb_selected': xgboost_selected.iloc[:, -1]\n})\n\n# Create H-blend using Ridge regression\n# If you have true labels, replace y_true with actual target variable\n# For demonstration, using simple averaging if no labels available\nweights = [0.32, 0.38, 0.30]  # Equal weights for 3 models\n\n# Simple weighted blend\nh_blend = (predictions['xgb_cv'] * weights[0] + \n           predictions['xgb_tuned'] * weights[1] + \n           predictions['xgb_selected'] * weights[2])\n\n# Create final submission with h-blend\nsubmission_hblend = pd.DataFrame({\n    'id': xgboost_csv['id'],\n    'loan_paid_back': h_blend\n})\n\n# Save to CSV file\nsubmission_hblend.to_csv('submission.csv', index=False)\n\nprint(\"Ensemble Solution file created successfully!\")\nprint(f\"Blend shape: {h_blend.shape}\")\nprint(f\"\\nModel weights:\")\nprint(f\"  XGBoost CV: {weights[0]:.3f}\")\nprint(f\"  XGBoost Tuned: {weights[1]:.3f}\")\nprint(f\"  XGBoost Selected: {weights[2]:.3f}\")\nprint(f\"\\nFirst 5 predictions:\")\nprint(submission_hblend.head())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-02T15:16:47.723234Z","iopub.execute_input":"2025-11-02T15:16:47.723569Z","iopub.status.idle":"2025-11-02T15:16:48.593834Z","shell.execute_reply.started":"2025-11-02T15:16:47.723549Z","shell.execute_reply":"2025-11-02T15:16:48.592952Z"}},"outputs":[],"execution_count":null}]}