{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":91722,"databundleVersionId":14262372,"sourceType":"competition"}],"dockerImageVersionId":31154,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Needed Library","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nimport warnings\n#import pytabkit\nfrom sklearn.model_selection import train_test_split\n\nimport lightgbm as lgb\nfrom sklearn.metrics import *\n\nfrom sklearn.pipeline import Pipeline\nfrom lightgbm import LGBMClassifier, early_stopping, log_evaluation,early_stopping\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import StratifiedKFold\nfrom lightgbm import early_stopping, log_evaluation\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.preprocessing import OneHotEncoder\n\n\nwarnings.filterwarnings('ignore')\nprint('Done')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-11-10T10:15:58.947945Z","iopub.execute_input":"2025-11-10T10:15:58.948571Z","iopub.status.idle":"2025-11-10T10:16:06.852738Z","shell.execute_reply.started":"2025-11-10T10:15:58.948531Z","shell.execute_reply":"2025-11-10T10:16:06.852067Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Read Data Files","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/playground-series-s5e11/train.csv\")\ndf_test = pd.read_csv(\"/kaggle/input/playground-series-s5e11/test.csv\")\ntarget = 'loan_paid_back'\nprint(df.shape)\nprint(df.columns.tolist())\n\ndf.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-10T10:16:06.853859Z","iopub.execute_input":"2025-11-10T10:16:06.854369Z","iopub.status.idle":"2025-11-10T10:16:09.019113Z","shell.execute_reply.started":"2025-11-10T10:16:06.854348Z","shell.execute_reply":"2025-11-10T10:16:09.018107Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# train_pipeline.py\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import roc_auc_score\nimport optuna\n\n#   FEATURE ENGINEERING\ndef feature_engineer(df):\n    df = df.copy()\n\n    # --- grade & subgrade\n    def extract_grade_subgrade(s):\n        if pd.isna(s): return (np.nan, np.nan)\n        s = str(s).strip()\n        if len(s)==0: return (np.nan, np.nan)\n        return (s[0], s[1:])\n\n    g = df['grade_subgrade'].fillna(\"\").astype(str).apply(extract_grade_subgrade)\n    df['grade'] = g.apply(lambda x: x[0]).replace(\"\", np.nan)\n    df['subgrade'] = pd.to_numeric(g.apply(lambda x: x[1]), errors='coerce')\n\n    # --- numeric\n    num_cols = ['annual_income','loan_amount','debt_to_income_ratio','interest_rate','credit_score']\n    for c in num_cols:\n        if c in df.columns:\n            df[c] = pd.to_numeric(df[c], errors='coerce')\n\n    # --- interactions\n    df['loan_to_income'] = df['loan_amount'] / df['annual_income'].replace(0, np.nan)\n    df['income_to_loan'] = df['annual_income'] / df['loan_amount'].replace(0, np.nan)\n    df['log_annual_income'] = np.log1p(df['annual_income'].clip(lower=0))\n    df['log_loan_amount'] = np.log1p(df['loan_amount'].clip(lower=0))\n    df['interest_x_loan'] = df['interest_rate'] * df['loan_amount']\n    df['interest_x_credit'] = df['interest_rate'] * df['credit_score']\n    df['dti_x_interest'] = df['debt_to_income_ratio'] * df['interest_rate']\n\n    # --- credit bucket\n    if 'credit_score' in df.columns:\n        df['credit_score_bucket'] = pd.cut(\n            df['credit_score'],\n            bins=[0,580,670,740,800,900],\n            labels=['poor','fair','good','very_good','excellent']\n        ).astype(object)\n\n    # --- freq encoding\n    cat_cols = ['loan_purpose','employment_status','education_level','marital_status','gender']\n    for c in cat_cols:\n        if c in df.columns:\n            freq = df[c].fillna('NA').value_counts(normalize=True)\n            df[f'{c}_freq'] = df[c].fillna('NA').map(freq).astype(float)\n\n    df['missing_count'] = df.isna().sum(axis=1)\n\n    # --- grade one-hot\n    df['grade'] = df['grade'].astype(object)\n    grade_dummies = pd.get_dummies(df['grade'], prefix='grade', dummy_na=True)\n    df = pd.concat([df, grade_dummies], axis=1)\n\n    return df\n\n#   LOAD DATA\ntrain_path = \"/kaggle/input/playground-series-s5e11/train.csv\"\ntest_path  = \"/kaggle/input/playground-series-s5e11/test.csv\"\n\ntrain = pd.read_csv(train_path)\ntest  = pd.read_csv(test_path)\n\ntarget = 'loan_paid_back'\n\ntrain_fe = feature_engineer(train)\ntest_fe  = feature_engineer(test)\n\nFEATURES = [c for c in train_fe.columns if c not in ['id', target, 'grade_subgrade']]\n\ntrain_X = train_fe[FEATURES].copy()\ntrain_y = train_fe[target].copy()\ntest_X  = test_fe[FEATURES].copy()\n\n#   Basic Fill\nfor c in train_X.columns:\n    if train_X[c].dtype.kind in 'biufc': # numeric\n        med = train_X[c].median()\n        train_X[c] = train_X[c].fillna(med)\n        test_X[c]  = test_X[c].fillna(med)\n    else:\n        train_X[c] = train_X[c].fillna('NA')\n        test_X[c]  = test_X[c].fillna('NA')\n\n# Convert object to category code\nfor c in train_X.columns:\n    if train_X[c].dtype == 'object':\n        train_X[c] = train_X[c].astype('category').cat.codes\n        test_X[c]  = test_X[c].astype('category').cat.codes\n\n#   OPTUNA OBJECTIVE\ndef objective(trial):\n\n    param = {\n        'objective': 'binary',\n        'metric': 'auc',\n        'boosting_type': 'gbdt',\n        'verbosity': -1,\n        'seed': 42,\n        'n_jobs': -1,\n        'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.1),\n        'num_leaves': trial.suggest_int('num_leaves', 30, 300),\n        'max_depth': trial.suggest_int('max_depth', 4, 12),\n        'min_child_samples': trial.suggest_int('min_child_samples', 10, 200),\n        'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n        'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.5, 1.0),\n        'reg_alpha': trial.suggest_loguniform('reg_alpha', 1e-3, 10.0),\n        'reg_lambda': trial.suggest_loguniform('reg_lambda', 1e-3, 10.0),\n    }\n\n    folds = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n    aucs = []\n\n    for tr_idx, val_idx in folds.split(train_X, train_y):\n        X_tr, X_val = train_X.iloc[tr_idx], train_X.iloc[val_idx]\n        y_tr, y_val = train_y.iloc[tr_idx], train_y.iloc[val_idx]\n\n        dtrain = lgb.Dataset(X_tr, label=y_tr)\n        dval   = lgb.Dataset(X_val, label=y_val, reference=dtrain)\n\n        bst = lgb.train(\n            param,\n            dtrain,\n            valid_sets=[dval],\n            num_boost_round=5000,\n            callbacks=[\n                lgb.early_stopping(100),\n                lgb.log_evaluation(period=0)\n            ]\n        )\n\n        pred = bst.predict(X_val, num_iteration=bst.best_iteration)\n        aucs.append(roc_auc_score(y_val, pred))\n\n    return np.mean(aucs)\n\n\n#   RUN OPTUNA\nstudy = optuna.create_study(direction='maximize')\nstudy.optimize(objective, n_trials=40, show_progress_bar=True)\n\nprint(\"Best AUC:\", study.best_value)\nprint(\"Best params:\", study.best_params)\n\n#   TRAIN FINAL MODEL\nbest_params = {\n    **study.best_params,\n    'objective':'binary',\n    'metric':'auc',\n    'boosting_type':'gbdt',\n    'verbosity':-1,\n    'seed':42,\n    'n_jobs':-1\n}\n\ndtrain = lgb.Dataset(train_X, label=train_y)\n\nfinal_model = lgb.train(\n    best_params,\n    dtrain,\n    num_boost_round=5000,\n    valid_sets=[dtrain],\n    callbacks=[\n        lgb.early_stopping(100),\n        lgb.log_evaluation(period=0)\n    ]\n)\n\nprint(\"âœ… Done Training\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-10T10:19:19.303946Z","iopub.execute_input":"2025-11-10T10:19:19.304681Z","iopub.status.idle":"2025-11-10T13:26:57.510049Z","shell.execute_reply.started":"2025-11-10T10:19:19.304655Z","shell.execute_reply":"2025-11-10T13:26:57.509386Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Submission","metadata":{}}]}