{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":91722,"databundleVersionId":14262372,"sourceType":"competition"}],"dockerImageVersionId":31153,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# ============================================\n# 0. load library\n# ============================================\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, classification_report\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.pipeline import Pipeline\n\n# ============================================\n# 1. load data\n# ============================================\n\n# load train data\ndf = pd.read_csv(\"/kaggle/input/playground-series-s5e11/train.csv\")\n\n# load test data\ntest = pd.read_csv(\"/kaggle/input/playground-series-s5e11/test.csv\")\n\n# Identify feature\ntarget = df.columns.tolist()[-1]\ncols = df.drop(columns=[target,\"id\"]).columns.tolist()\n\n# Categorical features\ncat = [c for c in cols if df[c].dtype in [\"object\",\"category\"]]\n\n# Numerical features\nnum = [c for c in cols if df[c].dtype not in [\"object\",\"category\",\"bool\"]]\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2025-11-09T02:42:04.572031Z","iopub.execute_input":"2025-11-09T02:42:04.57228Z","iopub.status.idle":"2025-11-09T02:42:10.092784Z","shell.execute_reply.started":"2025-11-09T02:42:04.57226Z","shell.execute_reply":"2025-11-09T02:42:10.091802Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-09T02:42:10.093735Z","iopub.execute_input":"2025-11-09T02:42:10.094069Z","iopub.status.idle":"2025-11-09T02:42:10.125138Z","shell.execute_reply.started":"2025-11-09T02:42:10.094039Z","shell.execute_reply":"2025-11-09T02:42:10.124133Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-09T02:42:10.127324Z","iopub.execute_input":"2025-11-09T02:42:10.12797Z","iopub.status.idle":"2025-11-09T02:42:10.146894Z","shell.execute_reply.started":"2025-11-09T02:42:10.127937Z","shell.execute_reply":"2025-11-09T02:42:10.146048Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ============================================\n# 1. EDA\n# ============================================\n\nfrom ydata_profiling import ProfileReport\nreport = ProfileReport(df,title='LoanPayback')\nreport.to_notebook_iframe()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-09T02:42:10.147866Z","iopub.execute_input":"2025-11-09T02:42:10.148154Z","iopub.status.idle":"2025-11-09T02:42:51.868493Z","shell.execute_reply.started":"2025-11-09T02:42:10.148128Z","shell.execute_reply":"2025-11-09T02:42:51.867129Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#employment_status\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nsns.countplot(x='employment_status', hue='loan_paid_back', data=df)\nplt.legend(['defaulted', 'paidback'])\nplt.show()\n\ndisplay(pd.crosstab(df['employment_status'], df['loan_paid_back']))\ndisplay(pd.crosstab(df['employment_status'], df['loan_paid_back'], normalize='index'))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-09T02:42:51.869487Z","iopub.execute_input":"2025-11-09T02:42:51.870225Z","iopub.status.idle":"2025-11-09T02:42:52.650806Z","shell.execute_reply.started":"2025-11-09T02:42:51.870185Z","shell.execute_reply":"2025-11-09T02:42:52.649907Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#grade_subgrade\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nsns.countplot(x='grade_subgrade', hue='loan_paid_back', data=df)\nplt.legend(['defaulted', 'paidback'])\nplt.show()\n\ndisplay(pd.crosstab(df['grade_subgrade'], df['loan_paid_back']))\ndisplay(pd.crosstab(df['grade_subgrade'], df['loan_paid_back'], normalize='index'))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-09T02:42:52.651743Z","iopub.execute_input":"2025-11-09T02:42:52.65207Z","iopub.status.idle":"2025-11-09T02:42:53.571464Z","shell.execute_reply.started":"2025-11-09T02:42:52.652038Z","shell.execute_reply":"2025-11-09T02:42:53.570602Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ============================================\n# 2. Outlier Treatment & feature engineering\n# ============================================","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-09T02:42:53.572487Z","iopub.execute_input":"2025-11-09T02:42:53.572851Z","iopub.status.idle":"2025-11-09T02:42:53.576708Z","shell.execute_reply.started":"2025-11-09T02:42:53.572826Z","shell.execute_reply":"2025-11-09T02:42:53.575885Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def create_frequency_features(df, df_test):\n    \"\"\"\n    Add frequency and binning features efficiently.\n\n    - For each categorical column, create <col>_freq = how often each value appears in train data.\n    - For numeric columns, split values into 5, 10, 15 quantile bins.\n    \"\"\"\n    # Pre-allocate DataFrames for new features to avoid fragmentation\n    freq_features_train = pd.DataFrame(index=df.index)\n    freq_features_test = pd.DataFrame(index=df_test.index)\n    bin_features_train = pd.DataFrame(index=df.index)\n    bin_features_test = pd.DataFrame(index=df_test.index)\n\n    for col in cols:\n        # --- Frequency encoding ---\n        freq = df[col].value_counts()\n        df[f\"{col}_freq\"] = df[col].map(freq)\n        freq_features_test[f\"{col}_freq\"] = df_test[col].map(freq).fillna(freq.mean())\n\n        # --- Quantile binning for numeric columns ---\n        if col in num:\n            for q in [5, 10, 15]:\n                try:\n                    train_bins, bins = pd.qcut(df[col], q=q, labels=False, retbins=True, duplicates=\"drop\")\n                    bin_features_train[f\"{col}_bin{q}\"] = train_bins\n                    bin_features_test[f\"{col}_bin{q}\"] = pd.cut(df_test[col], bins=bins, labels=False, include_lowest=True)\n                except Exception:\n                    bin_features_train[f\"{col}_bin{q}\"] = 0\n                    bin_features_test[f\"{col}_bin{q}\"] = 0\n\n    # Concatenate all new features at once\n    df = pd.concat([df, freq_features_train, bin_features_train], axis=1)\n    df_test = pd.concat([df_test, freq_features_test, bin_features_test], axis=1)\n\n    return df, df_test","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-09T02:42:53.577729Z","iopub.execute_input":"2025-11-09T02:42:53.578068Z","iopub.status.idle":"2025-11-09T02:42:53.603277Z","shell.execute_reply.started":"2025-11-09T02:42:53.578046Z","shell.execute_reply":"2025-11-09T02:42:53.602086Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.model_selection import KFold\ndef target_encoding(train, predict, n_splits=5):\n    \"\"\"\n    Add K-Fold target mean encoded features to train and predict datasets.\n    \n    Parameters:\n    - train: training DataFrame\n    - predict: prediction/test DataFrame\n    - target: name of the target column\n    - n_splits: number of folds for K-Fold encoding\n    \n    Returns:\n    - train and predict DataFrames with new mean encoded features\n    \"\"\"\n    kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n\n    mean_features_train = pd.DataFrame(index=train.index)\n    mean_features_test = pd.DataFrame(index=predict.index)\n\n    for col in cols:\n        # --- K-Fold Target Mean Encoding ---\n        mean_encoded = np.zeros(len(train))\n        for tr_idx, val_idx in kf.split(train):\n            tr_fold = train.iloc[tr_idx]\n            val_fold = train.iloc[val_idx]\n            mean_map = tr_fold.groupby(col)[target].mean()\n            mean_encoded[val_idx] = val_fold[col].map(mean_map)\n\n        mean_features_train[f'mean_{col}'] = mean_encoded\n\n        # --- Apply global mean mapping to prediction/test data ---\n        global_mean = train.groupby(col)[target].mean()\n        mean_features_test[f'mean_{col}'] = predict[col].map(global_mean)\n\n    # --- Concatenate new features at once to avoid fragmentation ---\n    train = pd.concat([train, mean_features_train], axis=1)\n    predict = pd.concat([predict, mean_features_test], axis=1)\n\n    # Defragment\n    train = train.copy()\n    predict = predict.copy()\n    return train, predict","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-09T02:42:53.60698Z","iopub.execute_input":"2025-11-09T02:42:53.607257Z","iopub.status.idle":"2025-11-09T02:42:53.620815Z","shell.execute_reply.started":"2025-11-09T02:42:53.607235Z","shell.execute_reply":"2025-11-09T02:42:53.619811Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Specific feature engineering\ndf['subgrade'] = df['grade_subgrade'].str[1:].astype(int)\ntest['subgrade'] = test['grade_subgrade'].str[1:].astype(int)\n\ndf['grade'] = df['grade_subgrade'].str[0]\ntest['grade'] = test['grade_subgrade'].str[0]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-09T02:42:53.621869Z","iopub.execute_input":"2025-11-09T02:42:53.622217Z","iopub.status.idle":"2025-11-09T02:42:54.06053Z","shell.execute_reply.started":"2025-11-09T02:42:53.622194Z","shell.execute_reply":"2025-11-09T02:42:54.059625Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Creating new features based on the frequency of numerical features\ndf2, test2 = target_encoding(df, test, 10)\ndf2, test2 = create_frequency_features(df2, test2)\n\n# Preparing categorical features\ndf2[cat], test2[cat] = df[cat].astype(\"category\"), test[cat].astype(\"category\")\n\nprint(df2.columns.tolist())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-09T02:42:54.06138Z","iopub.execute_input":"2025-11-09T02:42:54.061691Z","iopub.status.idle":"2025-11-09T02:43:08.907803Z","shell.execute_reply.started":"2025-11-09T02:42:54.061666Z","shell.execute_reply":"2025-11-09T02:43:08.906811Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Dropping unnecessary columns\nremove = [\"interest_rate\",\n          \"education_level\",\"loan_purpose\", \"grade_subgrade\", \"marital_status\", \"gender\", \"employment_status\", \"grade\",\n          \"debt_to_income_ratio_bin5\", \"credit_score_bin5\", \"loan_amount_bin5\",\n          \"credit_score_freq\", \"employment_status_freq\"]\ndf2, test2 = df2.drop(columns = remove), test2.drop(columns = remove)\n\n# Dropping ID and duplicates\ndf2.drop(columns=\"id\", inplace=True)\ndf2.drop_duplicates(inplace=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-09T02:43:08.908557Z","iopub.execute_input":"2025-11-09T02:43:08.908814Z","iopub.status.idle":"2025-11-09T02:43:09.538067Z","shell.execute_reply.started":"2025-11-09T02:43:08.908783Z","shell.execute_reply":"2025-11-09T02:43:09.537296Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"## LightGBM\nimport lightgbm as lgb\n\n#Cross Verification(K-fold)\nfrom sklearn.model_selection import train_test_split\nfrom lightgbm import LGBMClassifier, early_stopping, log_evaluation\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import roc_auc_score\n\nX = df2.drop(columns=[target])\ny = df2[target]\nlgb_train = lgb.Dataset(X, label=y)\n\nlgb_params = {\n    'objective': 'binary', 'metric': 'auc', 'boosting_type': 'gbdt',\n    'max_depth': 6, 'num_leaves': 50, 'learning_rate': 0.03,\n    'colsample_bytree': 0.8, 'subsample': 0.8,\n    'subsample_freq': 1, 'min_child_samples': 20, 'reg_alpha': 0.05,\n    'reg_lambda': 0.1, 'random_state': 42,\n    'n_jobs': -1, \n    'verbose': -1,\n}\n\ncv_results = lgb.cv(\n    params=lgb_params,\n    train_set=lgb_train,\n    num_boost_round=20000,\n    nfold=7,\n    stratified=True,\n    callbacks=[early_stopping(stopping_rounds=50), log_evaluation(period = 100)],\n    seed=42\n)\n\ncv_df = pd.DataFrame(cv_results)\nprint(cv_df.tail())\n\nbest_round = len(cv_results['valid auc-mean'])\nbest_auc = cv_results['valid auc-mean'][-1]\nprint(f\"Best round: {best_round}, Best CV AUC: {best_auc:.7f}\")\n\n#1feature Accuracy: 0.8044\n#2feature Accuracy: 0.8119\n#3feature Accuracy: 0.8120\n#LGBM with 5feature: train score : 0.9055616349402951 test score : 0.9046122593280546\n#Cross Verification: Overall CV AUC: 0.919931\n#outliertreatment+annual_income -> Overall   CV AUC: 0.920096   pub=0.92047\n#LGBM parameter tune: Best round: 1472, Best CV AUC: 0.9224443  pub=0.92274\n#feature engineering(from simple-lightgbm-only-competition-data-s5e11): Best round: 697, Best CV AUC: 0.9259890  pub=0.92600\n#delete Outlier Treatment from above                                  : Best round: 704, Best CV AUC: 0.9266021  pub=0.xxxxx","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-09T02:43:09.538934Z","iopub.execute_input":"2025-11-09T02:43:09.539146Z","iopub.status.idle":"2025-11-09T02:47:37.471064Z","shell.execute_reply.started":"2025-11-09T02:43:09.539129Z","shell.execute_reply":"2025-11-09T02:47:37.469848Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# putting the n_estimator at the average early stopping point to avoid overfitting\nlgb_params[\"n_estimators\"] = best_round + 100\nprint(best_round)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-09T02:47:37.472041Z","iopub.execute_input":"2025-11-09T02:47:37.472913Z","iopub.status.idle":"2025-11-09T02:47:37.478104Z","shell.execute_reply.started":"2025-11-09T02:47:37.472889Z","shell.execute_reply":"2025-11-09T02:47:37.477215Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Train LGBM model\nmodel = LGBMClassifier(\n    **lgb_params,\n)\nmodel.fit(X, y)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-09T02:47:37.479096Z","iopub.execute_input":"2025-11-09T02:47:37.479441Z","iopub.status.idle":"2025-11-09T02:48:18.451419Z","shell.execute_reply.started":"2025-11-09T02:47:37.479422Z","shell.execute_reply":"2025-11-09T02:48:18.450202Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"y_sub_proba = model.predict_proba(test2.drop(columns = \"id\"))[:, 1]\n\n# make submission.csv\nsubmission = pd.DataFrame({\n    \"id\": test[\"id\"],\n    \"loan_paid_back\": y_sub_proba\n})\n\nsubmission.to_csv(\"submission.csv\", index=False)\nsubmission.head()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-09T02:48:18.452449Z","iopub.execute_input":"2025-11-09T02:48:18.453008Z","iopub.status.idle":"2025-11-09T02:48:28.650977Z","shell.execute_reply.started":"2025-11-09T02:48:18.452985Z","shell.execute_reply":"2025-11-09T02:48:28.650043Z"}},"outputs":[],"execution_count":null}]}