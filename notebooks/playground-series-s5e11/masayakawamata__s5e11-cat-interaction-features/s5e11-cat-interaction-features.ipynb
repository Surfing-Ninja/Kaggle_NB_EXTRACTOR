{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":91722,"databundleVersionId":14262372,"sourceType":"competition"},{"sourceId":13059803,"sourceType":"datasetVersion","datasetId":8264672}],"dockerImageVersionId":31153,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Introduction: Interaction Features & Target Encoding with CatBoost\n\nIn my previous [Notebook](https://www.kaggle.com/code/masayakawamata/s5e11-te-xgb-interaction-features/notebook), I implemented a feature engineering (FE) strategy that involved:\n1.  Manually creating interaction terms.\n2.  Applying Target Encoding (TE) to these new, high-cardinality features to make them useful for the model.\n\nThe purpose of *this* notebook is to demonstrate how to implement that same core methodology using **CatBoost** and to explore the unique advantages this framework offers for such a task.\n\nReference: [CatBoost: gradient boosting with categorical features support](https://arxiv.org/pdf/1706.09516)\n\n### Built-in Categorical Feature Handling\n\nCatBoost has powerful, integrated functionalities for handling categorical data, which we aim to leverage.\n\n* **Ordered Target Encoding:** The primary feature we are interested in is CatBoost's internal TE mechanism. By simply passing our categorical column names (including our manually created interactions) to the `cat_features` parameter, the model automatically applies its own robust, ordered version of Target Encoding. \n\n* **Internal Feature Interactions:** CatBoost also has a built-in mechanism to test interactions between categorical columns. In this notebook, we are passing our *manually-created interaction features* as categorical features. This implies that CatBoost may also consider second-order relationships *between these already-combined interaction terms*, potentially capturing even more complex patterns.\n\n### A Key Advantage: Multi-GPU Support\n\nBeyond its handling of categorical data, CatBoost offers a significant advantage in the Kaggle environment: **native multi-GPU support**.\n\nIn our Kaggle Notebooks, we have access to a dual T4 GPU setup. However, models like XGBoost and LightGBM typically only utilize one of these GPUs.\n\nCatBoost, on the other hand, will automatically detect and utilize **both** available T4 GPUs for training. This can dramatically speed up computation and experimentation, which feels like a great bonus for iterating quickly.","metadata":{}},{"cell_type":"code","source":"import warnings\nwarnings.simplefilter('ignore')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-11-05T00:16:22.531969Z","iopub.execute_input":"2025-11-05T00:16:22.532502Z","iopub.status.idle":"2025-11-05T00:16:22.688753Z","shell.execute_reply.started":"2025-11-05T00:16:22.532483Z","shell.execute_reply":"2025-11-05T00:16:22.688111Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd, numpy as np\n\ntrain = pd.read_csv('/kaggle/input/playground-series-s5e11/train.csv')\ntest = pd.read_csv('/kaggle/input/playground-series-s5e11/test.csv')\norig = pd.read_csv('/kaggle/input/loan-prediction-dataset-2025/loan_dataset_20000.csv')\nprint('Train Shape:', train.shape)\nprint('Test Shape:', test.shape)\nprint('Orig Shape:', orig.shape)\n\ntrain.head(3)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-05T00:16:22.689512Z","iopub.execute_input":"2025-11-05T00:16:22.689993Z","iopub.status.idle":"2025-11-05T00:16:24.596706Z","shell.execute_reply.started":"2025-11-05T00:16:22.689975Z","shell.execute_reply":"2025-11-05T00:16:24.596091Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"TARGET = 'loan_paid_back'\nCATS = ['gender', 'marital_status', 'education_level', 'employment_status', 'loan_purpose', 'grade_subgrade']\nBASE = [col for col in train.columns if col not in ['id', TARGET]]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-05T00:16:24.59744Z","iopub.execute_input":"2025-11-05T00:16:24.59769Z","iopub.status.idle":"2025-11-05T00:16:24.601827Z","shell.execute_reply.started":"2025-11-05T00:16:24.597663Z","shell.execute_reply":"2025-11-05T00:16:24.601076Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from itertools import combinations\n\nINTER = []\n\nfor col1, col2 in combinations(BASE, 2):\n    new_col_name = f'{col1}_{col2}'\n    INTER.append(new_col_name)\n    for df in [train, test, orig]:\n        df[new_col_name] = df[col1].astype(str) + '_' + df[col2].astype(str)\n        \nprint(f'{len(INTER)} Features.')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-05T00:16:24.603534Z","iopub.execute_input":"2025-11-05T00:16:24.603797Z","iopub.status.idle":"2025-11-05T00:16:55.510157Z","shell.execute_reply.started":"2025-11-05T00:16:24.603781Z","shell.execute_reply":"2025-11-05T00:16:55.50938Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"ORIG = []\n\nfor col in BASE:\n    # MEAN\n    mean_map = orig.groupby(col)[TARGET].mean()\n    new_mean_col_name = f\"orig_mean_{col}\"\n    mean_map.name = new_mean_col_name\n    \n    train = train.merge(mean_map, on=col, how='left')\n    test = test.merge(mean_map, on=col, how='left')\n    ORIG.append(new_mean_col_name)\n\n    # COUNT\n    new_count_col_name = f\"orig_count_{col}\"\n    count_map = orig.groupby(col).size().reset_index(name=new_count_col_name)\n    \n    train = train.merge(count_map, on=col, how='left')\n    test = test.merge(count_map, on=col, how='left')\n    ORIG.append(new_count_col_name)\n\nprint(len(ORIG), 'Orig Features Created!!')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-05T00:16:55.511026Z","iopub.execute_input":"2025-11-05T00:16:55.511296Z","iopub.status.idle":"2025-11-05T00:17:22.182315Z","shell.execute_reply.started":"2025-11-05T00:16:55.511269Z","shell.execute_reply":"2025-11-05T00:17:22.181555Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"FEATURES = BASE + ORIG + INTER\nprint(len(FEATURES), 'Features.')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-05T00:17:22.183058Z","iopub.execute_input":"2025-11-05T00:17:22.183308Z","iopub.status.idle":"2025-11-05T00:17:22.187552Z","shell.execute_reply.started":"2025-11-05T00:17:22.18329Z","shell.execute_reply":"2025-11-05T00:17:22.186818Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X = train[FEATURES]\ny = train[TARGET]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-05T00:17:22.188297Z","iopub.execute_input":"2025-11-05T00:17:22.188512Z","iopub.status.idle":"2025-11-05T00:17:22.70899Z","shell.execute_reply.started":"2025-11-05T00:17:22.188495Z","shell.execute_reply":"2025-11-05T00:17:22.708424Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.model_selection import StratifiedKFold, KFold\n\nN_SPLITS = 5\nskf = StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=42)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-05T00:17:22.709742Z","iopub.execute_input":"2025-11-05T00:17:22.70999Z","iopub.status.idle":"2025-11-05T00:17:23.252777Z","shell.execute_reply.started":"2025-11-05T00:17:22.709964Z","shell.execute_reply":"2025-11-05T00:17:23.251919Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from catboost import CatBoostClassifier\nfrom sklearn.metrics import roc_auc_score","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-05T00:17:23.253649Z","iopub.execute_input":"2025-11-05T00:17:23.253927Z","iopub.status.idle":"2025-11-05T00:17:23.816723Z","shell.execute_reply.started":"2025-11-05T00:17:23.253911Z","shell.execute_reply":"2025-11-05T00:17:23.816142Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"cat_params = {\n    'loss_function': 'Logloss',\n    'bootstrap_type': 'Bernoulli',\n    'eval_metric': 'AUC',     \n    'iterations': 100000,      \n    'learning_rate': 0.01,\n    'max_depth': 5,\n    'subsample': 0.8,\n    'early_stopping_rounds': 100,\n    'random_seed': 42,        \n    'thread_count': -1,       \n    'verbose': 1000,           \n    'task_type': 'GPU'\n}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-05T00:17:23.817432Z","iopub.execute_input":"2025-11-05T00:17:23.817714Z","iopub.status.idle":"2025-11-05T00:17:23.822278Z","shell.execute_reply.started":"2025-11-05T00:17:23.817698Z","shell.execute_reply":"2025-11-05T00:17:23.821376Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"all_categorical_features = INTER + CATS \n\noof_preds = np.zeros(len(X))\ntest_preds = np.zeros(len(test))\n\nfor fold, (train_idx, val_idx) in enumerate(skf.split(X, y), 1):\n    print(f'--- Fold {fold}/{N_SPLITS} ---')\n    \n    X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n    y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n    X_test = test[FEATURES].copy()\n\n    model = CatBoostClassifier(**cat_params)\n    model.fit(X_train, y_train,\n              eval_set=(X_val, y_val),      \n              cat_features=all_categorical_features \n             )\n\n    val_preds = model.predict_proba(X_val)[:, 1]\n    oof_preds[val_idx] = val_preds\n    \n    fold_score = roc_auc_score(y_val, val_preds)\n    print(f'Fold {fold} AUC: {fold_score:.4f}')\n    \n    test_preds += model.predict_proba(X_test)[:, 1] / N_SPLITS\n\noverall_auc = roc_auc_score(y, oof_preds)\nprint(f'====================')\nprint(f'Overall OOF AUC: {overall_auc:.4f}')\nprint(f'====================')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-05T00:17:23.823161Z","iopub.execute_input":"2025-11-05T00:17:23.823418Z","execution_failed":"2025-11-05T00:21:11.697Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import seaborn as sns\nimport matplotlib.pyplot as plt\n\nfeature_importances = model.feature_importances_\n\nimportance_df = pd.DataFrame({\n    'feature': X_train.columns, \n    'importance': feature_importances\n})\n\nimportance_df = importance_df.sort_values('importance', ascending=False)\n\nplt.style.use('fivethirtyeight')\nplt.figure(figsize=(12, 20))\nsns.barplot(x='importance', \n            y='feature', \n            data=importance_df.head(50)) \nplt.title('Feature Importance (Fold5 model)')\nplt.xlabel('Importance Score')\nplt.ylabel('Features')\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true,"execution":{"execution_failed":"2025-11-05T00:21:11.697Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pd.DataFrame({'id': train.id, TARGET: oof_preds}).to_csv(f'oof_cat_cv_{overall_auc}.csv', index=False)\npd.DataFrame({'id': test.id, TARGET: test_preds}).to_csv(f'test_cat_cv_{overall_auc}.csv', index=False)","metadata":{"trusted":true,"execution":{"execution_failed":"2025-11-05T00:21:11.697Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}