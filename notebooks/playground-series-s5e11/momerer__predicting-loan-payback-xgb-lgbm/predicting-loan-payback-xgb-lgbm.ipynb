{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":91722,"databundleVersionId":14262372,"sourceType":"competition"},{"sourceId":13059803,"sourceType":"datasetVersion","datasetId":8264672}],"dockerImageVersionId":31154,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-11-01T09:29:36.034268Z","iopub.execute_input":"2025-11-01T09:29:36.034726Z","iopub.status.idle":"2025-11-01T09:29:36.290851Z","shell.execute_reply.started":"2025-11-01T09:29:36.034704Z","shell.execute_reply":"2025-11-01T09:29:36.29022Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Veri setlerinin yollarını belirleyelim\ntrain_path = '/kaggle/input/playground-series-s5e11/train.csv'\ntest_path = '/kaggle/input/playground-series-s5e11/test.csv'\nsubmission_path = '/kaggle/input/playground-series-s5e11/sample_submission.csv'\n\n# Veri setlerini yükleyelim\ntry:\n    train_df = pd.read_csv(train_path)\n    test_df = pd.read_csv(test_path)\n    sample_submission_df = pd.read_csv(submission_path)\n    \n    print(f\"Train verisi yüklendi. Shape: {train_df.shape}\")\n    print(f\"Test verisi yüklendi. Shape: {test_df.shape}\")\n    print(f\"Örnek submission dosyası yüklendi. Shape: {sample_submission_df.shape}\")\n\nexcept FileNotFoundError as e:\n    print(f\"HATA: Dosya bulunamadı. Lütfen yolları kontrol edin.\")\n    print(e)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-01T09:32:03.662616Z","iopub.execute_input":"2025-11-01T09:32:03.663042Z","iopub.status.idle":"2025-11-01T09:32:06.496918Z","shell.execute_reply.started":"2025-11-01T09:32:03.663018Z","shell.execute_reply":"2025-11-01T09:32:06.496075Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Veri çerçevelerinin ilk 5 satırını (head) gösterelim\nprint(\"--- Train Verisi İlk 5 Satır (head) ---\")\nprint(train_df.head())\nprint(\"\\n\" + \"=\"*50 + \"\\n\")\n\nprint(\"--- Test Verisi İlk 5 Satır (head) ---\")\nprint(test_df.head())\nprint(\"\\n\" + \"=\"*50 + \"\\n\")\n\n# Veri çerçevelerinin yapısını (info) inceleyelim (Veri tipleri ve eksik veriler)\nprint(\"--- Train Verisi Bilgisi (info) ---\")\n# .info() çıktısı doğrudan konsola yazdırılır, print() içine almaya gerek yok.\ntrain_df.info()\nprint(\"\\n\" + \"=\"*50 + \"\\n\")\n\nprint(\"--- Test Verisi Bilgisi (info) ---\")\ntest_df.info()\nprint(\"\\n\" + \"=\"*50 + \"\\n\")\n\n# Train ve Test setlerindeki sütunları karşılaştırarak hedef değişkeni bulalım\ntrain_cols = set(train_df.columns)\ntest_cols = set(test_df.columns)\n\n# Test setinde olmayan sütunları bulalım\ntarget_col = list(train_cols - test_cols)\n\nif len(target_col) == 1:\n    target_variable_name = target_col[0]\n    print(f\"Tespit edilen Hedef Değişken (Target Variable): '{target_variable_name}'\")\n    \n    # Hedef değişkenin dağılımını kontrol edelim\n    print(f\"\\n--- Hedef Değişken Dağılımı (%) ---\")\n    print(train_df[target_variable_name].value_counts(normalize=True) * 100)\n    \n    # Dağılımı görselleştirelim\n    plt.figure(figsize=(7, 5))\n    sns.countplot(x=target_variable_name, data=train_df, palette='pastel')\n    plt.title(f'Hedef Değişken Dağılımı ({target_variable_name})', fontsize=14)\n    plt.ylabel('Sayı (Count)')\n    plt.xlabel('Sınıf')\n    \n    # Eksen etiketlerini daha okunaklı hale getirelim (eğer gerekirse)\n    plt.xticks(rotation=0) \n    \n    # Grafiği kaydet\n    plt.tight_layout() # Düzeni optimize et\n    plt.savefig('target_distribution.png')\n    \n    print(\"\\nHedef değişken dağılım grafiği 'target_distribution.png' olarak kaydedildi.\")\n    \nelif len(target_col) == 0:\n    print(\"HATA: Train ve Test setleri aynı sütunlara sahip. Hedef değişken bulunamadı.\")\nelse:\n    print(f\"HATA: Birden fazla potansiyel hedef değişken bulundu: {target_col}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-01T09:32:45.85759Z","iopub.execute_input":"2025-11-01T09:32:45.857893Z","iopub.status.idle":"2025-11-01T09:32:46.456773Z","shell.execute_reply.started":"2025-11-01T09:32:45.857871Z","shell.execute_reply":"2025-11-01T09:32:46.456179Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Hedef değişkeni ve ID sütununu ayıralım\ntarget_col = 'loan_paid_back'\nid_col = 'id'\n\n# Sütun türlerini ayıralım (ID ve Target hariç)\nfeatures = train_df.columns.difference([target_col, id_col])\n\nnumerical_features = train_df[features].select_dtypes(include=np.number).columns.tolist()\ncategorical_features = train_df[features].select_dtypes(include='object').columns.tolist()\n\nprint(f\"Sayısal Özellikler (Numerical): {numerical_features}\")\nprint(f\"Kategorik Özellikler (Categorical): {categorical_features}\")\nprint(\"\\n\" + \"=\"*50 + \"\\n\")\n\n# --- 1. Sayısal Özelliklerin İstatistikleri ---\nprint(\"--- Sayısal Özellikler İstatistikleri (Train) ---\")\n# .T (transpose) ile daha okunaklı hale getirelim\nprint(train_df[numerical_features].describe().T)\nprint(\"\\n\" + \"=\"*50 + \"\\n\")\n\n# --- 2. Sayısal Özelliklerin Dağılımları (Histogramlar) ---\nprint(\"--- Sayısal Özelliklerin Dağılımları (Histogramlar) ---\")\nplt.figure(figsize=(18, 12))\nplt.suptitle('Sayısal Özelliklerin Dağılımı (Train)', fontsize=16)\nfor i, col in enumerate(numerical_features):\n    plt.subplot(2, 3, i + 1) # 2 satır, 3 sütunlu bir grid\n    sns.histplot(train_df[col], kde=True, bins=50, color='blue', alpha=0.6, label='Train')\n    sns.histplot(test_df[col], kde=True, bins=50, color='orange', alpha=0.6, label='Test')\n    plt.title(f'{col} Dağılımı')\n    plt.legend()\nplt.tight_layout(rect=[0, 0.03, 1, 0.95]) # Ana başlık için yer ayır\nplt.savefig('numerical_distributions.png')\nprint(\"Sayısal özellik dağılım grafikleri 'numerical_distributions.png' olarak kaydedildi.\")\nprint(\"Grafikler, train (mavi) ve test (turuncu) setlerinin dağılımlarını karşılaştırır.\")\nprint(\"\\n\" + \"=\"*50 + \"\\n\")\n\n# --- 3. Kategorik Özelliklerin Analizi (Benzersiz Değerler) ---\nprint(\"--- Kategorik Özellikler Analizi (Benzersiz Değerler) ---\")\n\n# Benzersiz değer sayılarını bir DataFrame'de gösterelim\nnunique_df = pd.DataFrame({\n    'Özellik': categorical_features,\n    'Benzersiz Değer Sayısı (Train)': [train_df[col].nunique() for col in categorical_features],\n    'Benzersiz Değer Sayısı (Test)': [test_df[col].nunique() for col in categorical_features]\n})\nprint(nunique_df.to_markdown(index=False)) # .to_markdown() ile daha güzel bir tablo çıktısı\nprint(\"\\n\" + \"-\"*30 + \"\\n\")\n\n# Benzersiz değerlerin kendilerini inceleyelim\nprint(\"--- Kategorik Özelliklerin İçeriği ---\")\nfor col in categorical_features:\n     print(f\"\\n--- '{col}' Benzersiz Değerleri (Train) ---\")\n     # Değerleri sıralayarak yazdıralım\n     print(np.sort(train_df[col].unique()))\n     \n     # Test setinde train'de olmayan bir değer var mı kontrol edelim\n     train_values = set(train_df[col].unique())\n     test_values = set(test_df[col].unique())\n     if not test_values.issubset(train_values):\n         print(f\"!!! DİKKAT: '{col}' test setinde, train'de olmayan şu değerleri içeriyor: {test_values - train_values}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-01T09:33:47.866035Z","iopub.execute_input":"2025-11-01T09:33:47.866672Z","iopub.status.idle":"2025-11-01T09:34:07.840073Z","shell.execute_reply.started":"2025-11-01T09:33:47.866648Z","shell.execute_reply":"2025-11-01T09:34:07.839341Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.preprocessing import OrdinalEncoder\n\n# Orijinal veri çerçevelerini korumak için kopyalarını oluşturalım\n# Bu aynı zamanda 'SettingWithCopyWarning' uyarısını almamızı engeller\ntrain_encoded = train_df.copy()\ntest_encoded = test_df.copy()\n\nprint(\"--- Ordinal Encoding Başlatıldı ---\")\n\n# 1. education_level için manuel haritalama (mapping)\n# 'Other' kategorisini en düşük seviye olarak (0) tanımlayalım\neducation_map = {\n    'Other': 0,\n    'High School': 1,\n    \"Bachelor's\": 2,\n    \"Master's\": 3,\n    'PhD': 4\n}\n\ntrain_encoded['education_level_encoded'] = train_encoded['education_level'].map(education_map)\ntest_encoded['education_level_encoded'] = test_encoded['education_level'].map(education_map)\n\nprint(\"--- 'education_level' Kodlama Sonucu (İlk 5 Satır) ---\")\nprint(train_encoded[['education_level', 'education_level_encoded']].head())\nprint(\"\\n\" + \"-\"*30 + \"\\n\")\n\n\n# 2. grade_subgrade için OrdinalEncoder\n# Kategorilerin sırasını (A1...F5) train setinden alıp,\n# hem train hem de test setine uygulayacağız.\ngrade_categories = np.sort(train_df['grade_subgrade'].unique())\n\n# Encoder'ı kategorileri belirterek başlatalım\nordinal_encoder = OrdinalEncoder(\n    categories=[grade_categories], \n    dtype=int  # Çıktı tipi integer olsun\n)\n\n# SADECE train verisine fit et\nordinal_encoder.fit(train_encoded[['grade_subgrade']])\n\n# Hem train hem test verisini transform et\ntrain_encoded['grade_subgrade_encoded'] = ordinal_encoder.transform(train_encoded[['grade_subgrade']])\ntest_encoded['grade_subgrade_encoded'] = ordinal_encoder.transform(test_encoded[['grade_subgrade']])\n\nprint(\"--- 'grade_subgrade' Kodlama Sonucu (Örnek Satırlar) ---\")\n# Farklı 'grade'leri görebilmek için .head(15) yerine .sample(10) alalım\nprint(train_encoded[['grade_subgrade', 'grade_subgrade_encoded']].sample(10, random_state=42))\nprint(\"\\n\" + \"-\"*30 + \"\\n\")\n\n# --- Özellik listelerimizi güncelleyelim ---\n# Artık sayısal olan yeni özellikleri 'numerical_features' listesine ekleyelim\n# ve eskilerini 'categorical_features' listesinden çıkaralım.\n\n# 'numerical_features' ve 'categorical_features' listelerinin \n# bir önceki hücrede tanımlandığını varsayıyoruz.\ntry:\n    numerical_features.extend(['education_level_encoded', 'grade_subgrade_encoded'])\n    categorical_features.remove('education_level')\n    categorical_features.remove('grade_subgrade')\n    \n    print(f\"Güncel Sayısal Özellikler: {numerical_features}\")\n    print(f\"Kalan Kategorik Özellikler (OHE için): {categorical_features}\")\n\nexcept NameError:\n    print(\"HATA: 'numerical_features' veya 'categorical_features' listeleri bulunamadı.\")\n    print(\"Lütfen bir önceki hücrenin (Hücre 3) tam olarak çalıştığından emin olun.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-01T09:35:39.758447Z","iopub.execute_input":"2025-11-01T09:35:39.758723Z","iopub.status.idle":"2025-11-01T09:35:40.149467Z","shell.execute_reply.started":"2025-11-01T09:35:39.758702Z","shell.execute_reply":"2025-11-01T09:35:40.148609Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Bir önceki hücrede tanımlanan 'categorical_features' listesini kullanalım\n# OHE yapılacak sütunlar: ['employment_status', 'gender', 'loan_purpose', 'marital_status']\n\nprint(f\"One-Hot Encoding uygulanacak {len(categorical_features)} özellik: {categorical_features}\")\n\n# Orijinal 'train_encoded' ve 'test_encoded' veri çerçevelerini koruyalım\ntrain_final = train_encoded.copy()\ntest_final = test_encoded.copy()\n\n# OHE'nin hem train hem de testte tutarlı olmasını sağlamak için birleştirelim\n# Hedef değişkeni geçici olarak ayır\ntarget = train_final[target_col]\ntrain_final = train_final.drop(columns=[target_col])\n\n# Birleştirme öncesi setleri tanımak için bir işaretçi ekleyelim\ntrain_final['dataset_marker'] = 'train'\ntest_final['dataset_marker'] = 'test'\n\n# İki seti birleştir\ncombined_df = pd.concat([train_final, test_final], ignore_index=True)\n\nprint(f\"Birleştirilmiş veri boyutu: {combined_df.shape}\")\n\n# One-Hot Encoding uygula\n# drop_first=False kullanıyoruz, çünkü ağaç bazlı modeller (LightGBM, XGBoost)\n# için bu genellikle daha iyi çalışır ve yorumlanabilirliği artırır.\ncombined_df_encoded = pd.get_dummies(combined_df, columns=categorical_features, drop_first=False)\n\nprint(f\"OHE sonrası birleştirilmiş veri boyutu: {combined_df_encoded.shape}\")\n\n# Veri setlerini tekrar ayıralım\ntrain_final = combined_df_encoded[combined_df_encoded['dataset_marker'] == 'train'].copy()\ntest_final = combined_df_encoded[combined_df_encoded['dataset_marker'] == 'test'].copy()\n\n# İşaretçi sütununu kaldıralım\ntrain_final = train_final.drop(columns=['dataset_marker'])\ntest_final = test_final.drop(columns=['dataset_marker'])\n\n# Hedef değişkeni train setine geri ekleyelim\ntrain_final[target_col] = target\n\n# Orijinal (object tipi) kategorik sütunları da temizleyelim\n# 'categorical_features' listesindeki orijinal sütun adları\noriginal_cat_cols_to_drop = [col for col in categorical_features if col in train_final.columns]\nif original_cat_cols_to_drop:\n    train_final = train_final.drop(columns=original_cat_cols_to_drop)\n    test_final = test_final.drop(columns=original_cat_cols_to_drop)\n\nprint(\"\\n\" + \"=\"*50 + \"\\n\")\nprint(\"--- One-Hot Encoding Tamamlandı ---\")\nprint(f\"Yeni Train Verisi Boyutu: {train_final.shape}\")\nprint(f\"Yeni Test Verisi Boyutu: {test_final.shape}\")\n\nprint(\"\\n--- Yeni Sütunlardan Bazı Örnekler (Train) ---\")\n# Yeni oluşturulan OHE sütunlarından bazılarını gösterelim\nohe_cols = [col for col in train_final.columns if any(cat_col in col for cat_col in categorical_features)]\nprint(train_final[ohe_cols].head())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-01T09:36:20.494311Z","iopub.execute_input":"2025-11-01T09:36:20.494584Z","iopub.status.idle":"2025-11-01T09:36:21.364829Z","shell.execute_reply.started":"2025-11-01T09:36:20.494564Z","shell.execute_reply":"2025-11-01T09:36:21.364039Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# %load_ext cudf.pandas\n\nimport warnings\nwarnings.simplefilter('ignore')\n\nimport pandas as pd\nimport numpy as np\nfrom itertools import combinations\nfrom sklearn.model_selection import StratifiedKFold, KFold\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.base import BaseEstimator, TransformerMixin\nfrom xgboost import XGBClassifier\nimport lightgbm as lgb\nimport gc\n\n# --- 1. Veri Yükleme ---\nprint(\"--- Veri Yükleniyor ---\")\ntrain = pd.read_csv('/kaggle/input/playground-series-s5e11/train.csv')\ntest = pd.read_csv('/kaggle/input/playground-series-s5e11/test.csv')\norig = pd.read_csv('/kaggle/input/loan-prediction-dataset-2025/loan_dataset_20000.csv')\norig = orig.drop_duplicates()\nprint(f'Train Shape: {train.shape}, Test Shape: {test.shape}, Orig Shape (temizlenmiş): {orig.shape}')\n\nTARGET = 'loan_paid_back'\nCATS = ['gender', 'marital_status', 'education_level', 'employment_status', 'loan_purpose', 'grade_subgrade']\nBASE = [col for col in train.columns if col not in ['id', TARGET]]\n\n# --- 2. Etkileşim Özellikleri (INTER) ---\nprint(\"\\n--- Etkileşim Özellikleri Oluşturuluyor (INTER) ---\")\nINTER = []\nfor col1, col2 in combinations(BASE, 2):\n    new_col_name = f'{col1}_{col2}'\n    INTER.append(new_col_name)\n    for df in [train, test, orig]:\n        if col1 in df.columns and col2 in df.columns:\n            df[new_col_name] = df[col1].astype(str) + '_' + df[col2].astype(str)\nprint(f'{len(INTER)} INTER Features created.')\n\n# --- 3. Harici Veri Özellikleri (ORIG) - (mean, count, std, median) ---\nprint(\"\\n--- Harici Veri Özellikleri Oluşturuluyor (ORIG) ---\")\nORIG = []\nfor col in BASE:\n    if col not in orig.columns:\n        print(f\"Uyarı: '{col}' sütunu 'orig' veri setinde bulunamadı. Atlanıyor.\")\n        continue\n    \n    agg_funcs = ['mean', 'count', 'std', 'median']\n    aggs = orig.groupby(col)[TARGET].agg(agg_funcs).reset_index()\n    aggs.columns = [col] + [f'orig_{func}_{col}' for func in agg_funcs]\n    aggs[f'orig_std_{col}'] = aggs[f'orig_std_{col}'].fillna(0)\n    \n    train = train.merge(aggs, on=col, how='left')\n    test = test.merge(aggs, on=col, how='left')\n    ORIG.extend([f'orig_{func}_{col}' for func in agg_funcs])\n\nprint(f'{len(ORIG)} ORIG Features created.') # 44 olmalı\n\n# --- 4. Özellik Listesi ve Veri Hazırlığı ---\nFEATURES = BASE + ORIG + INTER\nFEATURES = [col for col in FEATURES if col in test.columns]\nCATS = [col for col in CATS if col in FEATURES] \nprint(f'\\nToplam {len(FEATURES)} özellik ile eğitime başlanacak.')\n\nX = train[FEATURES]\ny = train[TARGET]\n\nN_SPLITS = 5\nskf = StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=42)\n\n# --- 5. Target Encoder Sınıfı (Değişiklik yok) ---\nclass TargetEncoder(BaseEstimator, TransformerMixin):\n    def __init__(self, cols_to_encode, aggs=['mean'], cv=5, smooth='auto', drop_original=False):\n        self.cols_to_encode = cols_to_encode\n        self.aggs = aggs\n        self.cv = cv\n        self.smooth = smooth\n        self.drop_original = drop_original\n        self.mappings_ = {}\n        self.global_stats_ = {}\n\n    def fit(self, X, y):\n        temp_df = X.copy()\n        temp_df['target'] = y\n        for agg_func in self.aggs:\n            self.global_stats_[agg_func] = y.agg(agg_func)\n        for col in self.cols_to_encode:\n            self.mappings_[col] = {}\n            for agg_func in self.aggs:\n                mapping = temp_df.groupby(col)['target'].agg(agg_func)\n                self.mappings_[col][agg_func] = mapping\n        return self\n\n    def transform(self, X):\n        X_transformed = X.copy()\n        for col in self.cols_to_encode:\n            for agg_func in self.aggs:\n                new_col_name = f'TE_{col}_{agg_func}'\n                map_series = self.mappings_[col][agg_func]\n                X_transformed[new_col_name] = X[col].map(map_series)\n                X_transformed[new_col_name].fillna(self.global_stats_[agg_func], inplace=True)\n        if self.drop_original:\n            X_transformed.drop(columns=self.cols_to_encode, inplace=True)\n        return X_transformed\n\n    def fit_transform(self, X, y):\n        self.fit(X, y)\n        encoded_features = pd.DataFrame(index=X.index)\n        kf = KFold(n_splits=self.cv, shuffle=True, random_state=42)\n        for train_idx, val_idx in kf.split(X, y):\n            X_train, y_train = X.iloc[train_idx], y.iloc[train_idx]\n            X_val = X.iloc[val_idx]\n            temp_df_train = X_train.copy()\n            temp_df_train['target'] = y_train\n            for col in self.cols_to_encode:\n                for agg_func in self.aggs:\n                    new_col_name = f'TE_{col}_{agg_func}'\n                    fold_global_stat = y_train.agg(agg_func)\n                    mapping = temp_df_train.groupby(col)['target'].agg(agg_func)\n                    if agg_func == 'mean':\n                        counts = temp_df_train.groupby(col)['target'].count()\n                        m = self.smooth\n                        if self.smooth == 'auto':\n                            variance_between = mapping.var()\n                            avg_variance_within = temp_df_train.groupby(col)['target'].var().mean()\n                            if variance_between > 0 and avg_variance_within > 0:\n                                m = avg_variance_within / variance_between\n                            else:\n                                m = 0\n                        smoothed_mapping = (counts * mapping + m * fold_global_stat) / (counts + m)\n                        encoded_values = X_val[col].map(smoothed_mapping)\n                    else:\n                        encoded_values = X_val[col].map(mapping)\n                    encoded_features.loc[X_val.index, new_col_name] = encoded_values.fillna(fold_global_stat)\n        X_transformed = X.copy()\n        for col in encoded_features.columns:\n            X_transformed[col] = encoded_features[col]\n        if self.drop_original:\n            X_transformed.drop(columns=self.cols_to_encode, inplace=True)\n        return X_transformed\n\n# --- 6. Model 1: XGBoost Eğitimi (GPU) (Çalışıyor) ---\nprint(\"\\n--- MODEL 1: XGBoost EĞİTİMİ (GPU) BAŞLIYOR ---\")\nxgb_params = {\n    'objective': 'binary:logistic',\n    'eval_metric': 'auc',\n    'max_depth': 5,\n    'colsample_bytree': 0.5,\n    'subsample': 0.8,\n    'n_estimators': 10000,\n    'learning_rate': 0.01,\n    'early_stopping_rounds': 100,\n    'random_state': 42,\n    'enable_categorical': True,\n    'tree_method': 'hist',\n    'device': 'cuda',\n    'predictor': 'gpu_predictor', \n}\n\noof_preds_xgb = np.zeros(len(X))\ntest_preds_xgb = np.zeros(len(test))\n\n# XGB için OOF skorunu önceki çalışmadan biliyoruz, \n# ama blend için tahminleri (test_preds_xgb) yeniden oluşturmamız lazım.\n# Bu yüzden bu döngü tekrar çalışmalı.\nfor fold, (train_idx, val_idx) in enumerate(skf.split(X, y), 1):\n    print(f'--- XGB Fold {fold}/{N_SPLITS} ---')\n    X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n    y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n    X_test = test[FEATURES].copy()\n    \n    INTER_to_encode = [col for col in INTER if col in X_train.columns]\n    TE = TargetEncoder(cols_to_encode=INTER_to_encode, cv=5, smooth='auto', aggs=['mean'], drop_original=True)\n    X_train = TE.fit_transform(X_train, y_train)\n    X_val = TE.transform(X_val)\n    X_test = TE.transform(X_test)\n    \n    CATS_in_train = [col for col in CATS if col in X_train.columns]\n    X_train[CATS_in_train] = X_train[CATS_in_train].astype('category')\n    X_val[CATS_in_train] = X_val[CATS_in_train].astype('category')\n    X_test[CATS_in_train] = X_test[CATS_in_train].astype('category')\n\n    model_xgb = XGBClassifier(**xgb_params)\n    model_xgb.fit(X_train, y_train, eval_set=[(X_val, y_val)], verbose=1000)\n    val_preds = model_xgb.predict_proba(X_val)[:, 1]\n    oof_preds_xgb[val_idx] = val_preds\n    fold_score = roc_auc_score(y_val, val_preds)\n    print(f'XGB Fold {fold} AUC: {fold_score:.6f}')\n    test_preds_xgb += model_xgb.predict_proba(X_test)[:, 1] / N_SPLITS\n    del X_train, X_val, y_train, y_val, X_test, TE\n    gc.collect()\n\noverall_auc_xgb = roc_auc_score(y, oof_preds_xgb)\nprint(f'====================\\nOverall XGB OOF AUC: {overall_auc_xgb:.6f}\\n====================')\n\n# --- 7. Model 2: LightGBM Eğitimi (CPU - DÜZELTİLDİ) ---\nprint(\"\\n--- MODEL 2: LightGBM EĞİTİMİ (CPU) BAŞLIYOR (Yavaş olacak) ---\")\nlgb_params = {\n    'objective': 'binary',\n    'metric': 'auc',\n    'boosting_type': 'gbdt',\n    'n_estimators': 10000,\n    'learning_rate': 0.01,\n    'num_leaves': 31,\n    'max_depth': -1,\n    'seed': 42,\n    'verbose': -1,\n    'colsample_bytree': 0.5,\n    'subsample': 0.8,\n    'reg_alpha': 0.1,\n    'reg_lambda': 0.1,\n    \n    # --- GPU PARAMETRELERİ (KALDIRILDI) ---\n    # 'device': 'gpu',\n    # 'device_type': 'opencl',\n    \n    # --- CPU PARAMETRESİ (EKLENDİ) ---\n    'n_jobs': -1, \n    # --- BİTTİ ---\n}\n\noof_preds_lgbm = np.zeros(len(X))\ntest_preds_lgbm = np.zeros(len(test))\n\nfor fold, (train_idx, val_idx) in enumerate(skf.split(X, y), 1):\n    print(f'--- LGBM Fold {fold}/{N_SPLITS} ---')\n    \n    X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n    y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n    X_test = test[FEATURES].copy()\n\n    INTER_to_encode = [col for col in INTER if col in X_train.columns]\n    TE = TargetEncoder(cols_to_encode=INTER_to_encode, cv=5, smooth='auto', aggs=['mean'], drop_original=True)\n    X_train = TE.fit_transform(X_train, y_train)\n    X_val = TE.transform(X_val)\n    X_test = TE.transform(X_test)\n    \n    CATS_in_train = [col for col in CATS if col in X_train.columns]\n    X_train[CATS_in_train] = X_train[CATS_in_train].astype('category')\n    X_val[CATS_in_train] = X_val[CATS_in_train].astype('category')\n    X_test[CATS_in_train] = X_test[CATS_in_train].astype('category')\n\n    model_lgbm = lgb.LGBMClassifier(**lgb_params)\n    \n    model_lgbm.fit(X_train, y_train,\n                   eval_set=[(X_val, y_val)],\n                   eval_metric='auc',\n                   callbacks=[lgb.early_stopping(100, verbose=1000)],\n                   categorical_feature=CATS_in_train) \n\n    val_preds = model_lgbm.predict_proba(X_val)[:, 1]\n    oof_preds_lgbm[val_idx] = val_preds\n    fold_score = roc_auc_score(y_val, val_preds)\n    print(f'LGBM Fold {fold} AUC: {fold_score:.6f}')\n    test_preds_lgbm += model_lgbm.predict_proba(X_test)[:, 1] / N_SPLITS\n    del X_train, X_val, y_train, y_val, X_test, TE\n    gc.collect()\n\noverall_auc_lgbm = roc_auc_score(y, oof_preds_lgbm)\nprint(f'====================\\nOverall LGBM OOF AUC: {overall_auc_lgbm:.6f}\\n====================')\n\n# --- 8. Blending (Karışım) ve Final Skor ---\nprint(\"\\n--- MODELLER KARIŞTIRILIYOR (BLENDING) ---\")\n\noof_blend = (oof_preds_xgb * 0.5) + (oof_preds_lgbm * 0.5)\noverall_auc_blend = roc_auc_score(y, oof_blend)\n\nprint(f'====================')\nprint(f'XGB OOF AUC (GPU):    {overall_auc_xgb:.6f}')\nprint(f'LGBM OOF AUC (CPU):   {overall_auc_lgbm:.6f}')\nprint(f'BLEND OOF AUC:        {overall_auc_blend:.6f}') \nprint(f'====================')\n\n# --- 9. Submission Dosyası Oluşturma ---\ntest_blend = (test_preds_xgb * 0.5) + (test_preds_lgbm * 0.5)\n\nsub_df = pd.DataFrame({'id': test['id'], TARGET: test_blend})\nsub_filename = f'blend_xgb_lgbm_cpu_cv_{overall_auc_blend:.6f}.csv'\nsub_df.to_csv(sub_filename, index=False)\n\nprint(f\"Submission dosyası kaydedildi: {sub_filename}\")\nprint(sub_df.head())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-01T10:53:47.875192Z","iopub.execute_input":"2025-11-01T10:53:47.875786Z","iopub.status.idle":"2025-11-01T11:33:28.924262Z","shell.execute_reply.started":"2025-11-01T10:53:47.875761Z","shell.execute_reply":"2025-11-01T11:33:28.923389Z"}},"outputs":[],"execution_count":null}]}