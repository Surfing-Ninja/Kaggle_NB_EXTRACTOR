{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.13"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":91722,"databundleVersionId":14262372,"sourceType":"competition"},{"sourceId":13631075,"sourceType":"datasetVersion","datasetId":8652235}],"dockerImageVersionId":31153,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false},"papermill":{"default_parameters":{},"duration":71.602368,"end_time":"2025-11-01T13:01:47.606988","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2025-11-01T13:00:36.00462","version":"2.6.0"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### PS-s4e11 - [Predicting Loan Payback](https://www.kaggle.com/competitions/playground-series-s5e11/code?competitionId=91722&sortBy=scoreDescending&excludeNonAccessedDatasources=true)\n\nPlayground Series - Season 5, Episode 11\n\nTwo master files submitted (subgroup 5) [differ significantly](#first_glance) from each other and from the group average. Very interesting! How will this build behave? To do this, we'll: **1)** h-blend all the build participants; **2)** \"merge-friendly-intersect\" the two master files into one to get an estimate; **3)** try to artificially, in a single step, \"bring\" each master file as close to the group as possible—and return to point **1)**.\n\nOh, I almost forgot, here is my [correspondence](https://www.kaggle.com/code/canozensoy/ps-s5e11-xgboost-stability-model/comments) with the respected Turkish master [Can Özensoy](https://www.kaggle.com/canozensoy) on this matter.\n\npublic solutions\n\n| | | &nbsp; | | &nbsp; | &nbsp; | &nbsp; |\n|:-|:-| :-: | :-: | :-: | :-: | :-: |\n| 1. | [0.92546](https://) |&nbsp;v.2&nbsp;| [Simple LightGBM Baseline for Loan Payback](https://www.kaggle.com/code/sidakou/simple-lightgbm-baseline-for-loan-payback) | contributor | [安尾 晃貴](https://www.kaggle.com/sidakou) | Japan |\n| 2. | [0.92574](https://) |&nbsp;v.1&nbsp;| [Simple HGBoost Baseline for Loan Payback](https://www.kaggle.com/code/sidakou/simple-histgradientboost-baseline-for-loan-payback) | contributor | [安尾 晃貴](https://www.kaggle.com/sidakou) | Japan |\n| 3. | [0.92576](https://) |&nbsp;v.6&nbsp;| [Simple XGBoost Baseline for Loan Payback](https://www.kaggle.com/code/sidakou/simple-xgboost-baseline-for-loan-payback) | contributor | [安尾 晃貴](https://www.kaggle.com/sidakou) | Japan |\n| 4. | [0.92615](https://) |&nbsp;v.11&nbsp;| [Simple CatBoost Baseline for Loan Payback](https://www.kaggle.com/code/sidakou/simple-catboost-baseline-for-loan-payback) | contributor | [安尾 晃貴](https://www.kaggle.com/sidakou) | Japan |\n| 5.<br> &nbsp; <br>6. | [0.92620](https://)<br>[?](https://)<br>[0.92668](https://) |&nbsp;v.1&nbsp;<br>&nbsp;<br>&nbsp;v.1&nbsp;| [Loan Payback . Ensemble](https://www.kaggle.com/code/mikhailnaumov/loan-payback-ensemble/output)<br>&nbsp;**+**&nbsp;<br>[PS-S5E11: XGBoost Stability Model](https://www.kaggle.com/code/canozensoy/ps-s5e11-xgboost-stability-model/notebook) | master<br>&nbsp;<br>master | [Mikhail Naumov](https://www.kaggle.com/mikhailnaumov)<br> &nbsp; <br>[Can Özensoy](https://www.kaggle.com/canozensoy) | World<br> &nbsp; <br>Türkiye |\n| 7. | [0.92677](https://www.kaggle.com/code/adilshamim8/predicting-loan-payback-101?scriptVersionId=273568426) |&nbsp;v.3&nbsp;| [Predicting Loan Payback 101](https://www.kaggle.com/code/adilshamim8/predicting-loan-payback-101) | expert | [Adil Shamim](https://www.kaggle.com/adilshamim8) | World |\n| 8. | [0.92728](https://www.kaggle.com/code/nina2025/ps-s5e9-simple-blend?scriptVersionId=273591739) |&nbsp;v.11&nbsp;| [PS-s5e9 . simple blend](https://www.kaggle.com/code/nina2025/ps-s5e9-simple-blend) | master | [F.A.Nina](https://www.kaggle.com/code/nina2025) | Georgia |\n| 9.<br> &nbsp; <br>10. | [?](https://)<br>[??](https://)<br>[?](https://) |&nbsp;v.1&nbsp;<br>&nbsp;<br>&nbsp;v.1&nbsp;| [arti_1](https://)<br>&nbsp;**+**&nbsp;<br>[arti_2](https://) | <br>&nbsp;<br> | []()<br> &nbsp; <br>[]() | World<br> &nbsp; <br>World |\n| 11. | [no_data](https://www.kaggle.com/code/nina2025/ps-s5e9-simple-blend) |&nbsp;v.1&nbsp;| [JGroupe = [ 1, 2, 3, 4, 7 ]](https://www.kaggle.com/code/nina2025/ps-s5e9-simple-blend) | master | Straight blend | World |\n| 12. | [no_data](https://www.kaggle.com/code/nina2025/ps-s5e9-simple-blend) |&nbsp;v.1&nbsp;| [Masters = [ 5, 6 ]](https://www.kaggle.com/code/nina2025/ps-s5e9-simple-blend) | master | Straight blend | World |\n| 13. | [0.92730](https://www.kaggle.com/code/nina2025/ps-s5e11-experiment?scriptVersionId=273789165) |&nbsp;v.5&nbsp;| [PS-s5e9 . experiment](https://www.kaggle.com/code/nina2025/ps-s5e9-simple-blend) | master | [F.A.Nina](https://www.kaggle.com/code/nina2025/ps-s5e11-experiment) | Georgia |\n|||||||\n|||| main weights | asc/desc | correct weights |\n|  | [0.92680](https://www.kaggle.com/code/nina2025/ps-s5e11-experiment?scriptVersionId=273510786) | [v.1](#first_glance) | ( 1,2,3,4,5,6 ) . [ 0.15+0.17+0.17+0.17+0.17+0.17 ] |40%&nbsp;**x**&nbsp;60%|[-0.01,-0,02,-0.03,-0.04,+0.05,+0.05]|\n|  | [0.92715](https://www.kaggle.com/code/nina2025/ps-s5e11-experiment?scriptVersionId=273770961) | [v.2](#Version.2) | ( 8,9,10,11 ) . [ 0.25 + 0.25 + 0.25 + 0.25 ] |35%&nbsp;**x**&nbsp;65%|[ +0.11,-0,01,-0.03,-0.07 ]|\n|  | [0.92725](https://www.kaggle.com/code/nina2025/ps-s5e11-experiment?scriptVersionId=273776149) | [v.3](#Version.3) | ( 8,9,10,11 ) . [ 0.55 + 0.15 + 0.15 + 0.15 ] |35%&nbsp;**x**&nbsp;65%|[ +0.11,-0,01,-0.03,-0.07 ]|\n|  | [0.92727](https://www.kaggle.com/code/nina2025/ps-s5e11-experiment?scriptVersionId=273780179) | [v.4](#Version.4) | ( 8,9,10,11 ) . [ 0.70 + 0.10 + 0.10 + 0.10 ] |35%&nbsp;**x**&nbsp;65%|[ +0.11,-0,01,-0.03,-0.07 ]|\n|  | [0.92728](https://www.kaggle.com/code/nina2025/ps-s5e11-experiment?scriptVersionId=273785001) | [v.5](#Version.5) | ( 8,9,10,11 ) . [ 0.85 + 0.05 + 0.05 + 0.05 ] |35%&nbsp;**x**&nbsp;65%|[ +0.11,-0,01,-0.03,-0.07 ]|\n|||||||\n|  | [0.92730](https://www.kaggle.com/code/nina2025/ps-s5e11-experiment?scriptVersionId=273789165) | [v.6](#Version.6) | ( 8,9,10,11 ) . [ 0.79 + 0.07 + 0.07 + 0.07 ] |35%&nbsp;**x**&nbsp;65%|[ -0.07,-0,03,-0.01,+0.11 ]|\n|  | [?](https://www.kaggle.com/code/nina2025/ps-s5e11-experiment) | [v.7](#Version.7) | ( 11,12,13 ) . [ 0.015 + 0.030 + 0.955 ] |35.5%&nbsp;**x**&nbsp;64.5%|[ +0.03,-0,01,-0.02 ]|","metadata":{}},{"cell_type":"code","source":"import os,copy,ast\nimport numpy as np\nimport pandas as pd\n\nfrom bokeh.plotting import figure, gridplot \nfrom bokeh.io import output_file, show, output_notebook\noutput_notebook()\n\ndef color_scheme(dk,color):\n    colors    = ['red','green','blue']\n    clr_alls  = ['silver','crimson',\"forestgreen\"]\n    clr_alls2 = ['red',\"green\",'blue',\"silver\",'gold']\n    clr_alls3 = ['darkmagenta',\"forestgreen\",'mediumblue']\n    clr_alls4 = ['crimson',\"darkgreen\",'mediumblue','brown']\n    clr_alls4m= ['red',\"forestgreen\",'mediumblue',\"darkmagenta\"]\n    clr_alls4j= ['red',\"green\",'blue',\"sienna\"]\n    clr_alls4i= ['crimson',\"green\",'mediumblue',\"chocolate\"]\n    clr_alls5 = ['red',\"forestgreen\",'mediumblue',\"darkmagenta\",'crimson']\n    clr_gold  = ['gainsboro',\"silver\",'darkgray','gray','gold']\n    clr_Red4  = [\"firebrick\",\"orangered\",\"crimson\",'red']\n    clr_Red52 = ['silver','darkgray','gray','crimson',\"crimson\"]\n    clr_Red53 = ['silver','darkgray','gray','dimgray',\"crimson\"]\n    clr_Red54 = ['forestgreen','limegreen','lime',\"crimson\"]\n    clr_Red55 = [\"silver\",'darkgray','gray',\"crimson\"]\n    clr_Red6  = [\"crimson\",'red','orangered','tomato','green','mediumblue']\n    clr_Red5  = [\"crimson\",'red','orangered','tomato','darkmagenta']\n    clr_Red3  = ['olivedrab','gold',\"lemonchiffon\"]\n    clr_Red31 = [\"crimson\",'red','gold']\n    clr_Red13 = ['gold',\"crimson\",'red']\n    clr_Green = [\"darkgreen\",\"limegreen\",\"green\",'lime',\"forestgreen\"]\n    clr_Green2= ['olivedrab',\"darkgreen\",\"forestgreen\"]\n    clr_Green3= [\"darkmagenta\",'olivedrab',\"darkgreen\"]\n    clr_Green4= [\"darkgreen\",\"forestgreen\",\"limegreen\",\"lime\"]\n    clr_Green5= [\"crimson\",\"darkgreen\",\"forestgreen\",\"limegreen\",\"lime\"]\n    clr_Blue  = ['midnightblue',\"royalblue\",\"mediumblue\",\"blue\",\"steelblue\",'cyan']\n    clr_Blue4 = ['midnightblue',\"royalblue\",\"mediumblue\",\"deepskyblue\"]\n    clr_Blue5 = [\"firebrick\",'navy',\"mediumblue\",\"royalblue\",\"deepskyblue\"]\n    clr_Brown = [\"maroon\",\"sienna\",\"chocolate\",\"sandybrown\",'brown']\n    clr_Brown3= [\"maroon\",\"sienna\",\"sandybrown\"]\n    clr_Brown4= [\"maroon\",\"sienna\",\"chocolate\",\"sandybrown\"]\n    clr_Brown5= [\"maroon\",\"sienna\",\"chocolate\",\"sandybrown\",'gold']\n    clr_Two   = ['crimson','mediumblue']\n    clr_Two2  = ['crimson','darkgreen']\n    clr_tes3  = ['limegreen',\"magenta\",'red']\n    clr_tes3b = ['darkmagenta',\"magenta\",'red']\n    clr_tes5  = ['mediumblue','crimson','crimson','crimson','mediumblue']\n    clr_tes6  = ['limegreen'] + clr_Brown\n    clr_tes7  = clr_Brown4 + [\"mediumblue\"]+[\"crimson\"]+['blue']\n    clr_tes8  = clr_Red4 + clr_Blue4\n    clr_tes9  = clr_Red4 + ['darkmagenta'] + clr_Blue4\n    clr_tes10 = clr_Brown + clr_Green\n    clr_tes11 = clr_Brown + ['red','darkmagenta'] + clr_Green\n    l = len(dk['subm'])\n    if color == 'Two2'  : colors = clr_Two2   [0:l]\n    if color == 'Two'   : colors = clr_Two    [0:l]\n    if color == 'alls'  : colors = clr_alls   [0:l]\n    if color == 'alls2' : colors = clr_alls2  [0:l]\n    if color == 'alls3' : colors = clr_alls3  [0:l]\n    if color == 'alls4' : colors = clr_alls4  [0:l]\n    if color == 'alls4m': colors = clr_alls4m [0:l]\n    if color == 'alls4i': colors = clr_alls4i [0:l]\n    if color == 'alls4j': colors = clr_alls4j [0:l]\n    if color == 'alls5' : colors = clr_alls5  [0:l]\n    if color == 'red'   : colors = clr_Red    [0:l]\n    if color == 'red3'  : colors = clr_Red3   [0:l]\n    if color == 'red4'  : colors = clr_Red4   [0:l]\n    if color == 'red5'  : colors = clr_Red5   [0:l]\n    if color == 'red52' : colors = clr_Red52  [0:l]\n    if color == 'red53' : colors = clr_Red53  [0:l]\n    if color == 'red54' : colors = clr_Red54  [0:l]\n    if color == 'red55' : colors = clr_Red55  [0:l]\n    if color == 'red6'  : colors = clr_Red6   [0:l]\n    if color == 'gold'  : colors = clr_gold   [0:l]\n    if color == 'red31' : colors = clr_Red31  [0:l]\n    if color == 'red13' : colors = clr_Red13  [0:l]\n    if color == 'green' : colors = clr_Green  [0:l]\n    if color == 'green2': colors = clr_Green2 [0:l]\n    if color == 'green3': colors = clr_Green3 [0:l]\n    if color == 'green4': colors = clr_Green4 [0:l]\n    if color == 'green5': colors = clr_Green5 [0:l]\n    if color == 'blue'  : colors = clr_Blue   [0:l]\n    if color == 'blue4' : colors = clr_Blue4  [0:l]\n    if color == 'blue5' : colors = clr_Blue5  [0:l]\n    if color == 'brown' : colors = clr_Brown  [0:l]\n    if color == 'brown3': colors = clr_Brown3 [0:l]\n    if color == 'brown4': colors = clr_Brown4 [0:l]\n    if color == 'brown5': colors = clr_Brown5 [0:l]\n    if color == 'tes3'  : colors = clr_tes3   [0:l]\n    if color == 'tes3b' : colors = clr_tes3b  [0:l]\n    if color == 'tes5'  : colors = clr_tes5   [0:l]\n    if color == 'tes6'  : colors = clr_tes6   [0:l]\n    if color == 'tes7'  : colors = clr_tes7   [0:l]\n    if color == 'tes8'  : colors = clr_tes8   [0:l]\n    if color == 'tes9'  : colors = clr_tes9   [0:l]\n    if color == 'tes10' : colors = clr_tes10  [0:l]\n    if color == 'tes11' : colors = clr_tes11  [0:l]\n    return colors\n\n\ndef bokeh_show(\n        params,\n        df_cross,\n        colors, \n        show_figures1, \n        show_figures2, wps_fig2,\n        color_cross):\n    \n    def dossier(js,subms,cols):\n        def quant(i,js,subms,cols):\n            return {\"c\" : i, \"q\" : sum([1 for subm in cols[i] if subm == subms[js]])}\n        return {\n            'name' : subms[js],\n            'q_in' : [quant(i,js,subms,cols) for i in range(len(subms))]\n        }\n    alls = pd.read_csv(f'tida_desc.csv')\n    matrix = [ast.literal_eval(str(row.alls)) for row in alls.itertuples()]\n    subms = sorted(matrix[0])\n    cols = [[data[i] for data in matrix] for i in range(len(subms))]\n    df_subms = pd.DataFrame({f'col_{i}': [x[i] for x in matrix] for i in range(len(subms))})\n    dossiers = [dossier(js,subms,cols) for js in range(len(subms))]\n    subm_names = [one_dossier['name'] for one_dossier in dossiers]\n    figures1,qss,i = [],[],0\n    height = 85 if len(colors)==2\\\n        else 134 if len(colors)==3 else (154 if len(colors)==4 else 174)\n    for one_dossier in dossiers: \n        i_col = 'alls. ' + str(one_dossier['q_in'][i]['c'])\n        qs = [one['q'] for one in one_dossier['q_in']]\n        x_names = [name.replace(\"Group\",\"\").replace(\"subm_\",\"\") for name in subm_names]\n        width = 157  if len(colors) == 5\\\n            else (121 if len(colors) == 8\\\n            else (131 if len(colors) == 9\\\n            else (141 if len(colors) == 10\\\n            else (171 if len(colors) == 11 else 133))))\n        f = figure(x_range=x_names,width=width, height=height, title=i_col)\n        f.vbar(x=x_names, width=0.585, top=qs, color=colors)\n        figures1.append(f)\n        qss.append(qs)\n        i+=1\n    grid = gridplot([figures1])\n    output_file('tida_alls.html')\n    if show_figures1 == True: show(grid)\n    sub_wts = params['subwts']\n    main_wts = [subm['weight'] for subm in params['subm']]\n    mms,acc_mass = [],[]\n    for j in range(len(dossiers)):\n        one_dossier = dossiers[j]\n        qs = [one['q'] for one in one_dossier['q_in']]\n        mm = [qs[h] * (main_wts[j] + sub_wts[h]) for h in range(len(sub_wts))]\n        mass = sum(mm)\n        mms.append(mm)\n        acc_mass.append(round(mass))                        #subm_names[::-1]\n    y_names = [name + \" - \" + str(mass) for name,mass in zip(subm_names,acc_mass)]\n    f1 = figure(y_range=y_names, width=313, height=height, title='relations of general masses')\n    f1.hbar(y=y_names, height=0.585, right=acc_mass, left=0, color=colors)\n    output_file('tida_alls2.html')\n    alls = [f'alls.{i}' for i in range(len(dossiers))]\n    subm = [f'sub{i}'   for i in range(len(dossiers))] \n    mmsT  = np.asarray(mms).T\n    data = {'cols' : alls}\n    for i in range(len(dossiers)): data[f'sub{i}'] = mmsT[i,:]\n    f2 = figure(y_range=alls, height=height, width=274, title=\" ( relations of columns masses )\")\n    f2.hbar_stack(subm, y='cols', height=0.585, color=colors, source=data)\n    qssT  = np.asarray(qss).T\n    data = {'cols' : alls}\n    for i in range(len(dossiers)): data[f'sub{i}'] = qssT[i,:]\n    f3 = figure(y_range=alls, height=height, width=215, title=\"ratios in columns\")\n    f3.hbar_stack(subm, y='cols', height=0.585, color=colors, source=data)\n    grid = gridplot([[f3,f2,f1]])\n    show(grid)\n    if show_figures2 == True:\n        def read(params,i):\n            FiN = params[\"path\"] + params[\"subm\"][i][\"name\"] + \".csv\"\n            target_name_back = {'target':params[\"target\"],'pred':params[\"target\"]}\n            return pd.read_csv(FiN).rename(columns=target_name_back)\n        dfs = [read(params,i) for i in range(len(params[\"subm\"]))] + [df_cross]\n        f   = figure(width=800, height=274)\n        f.title.text = 'Click on legend entries to mute the corresponding lines'\n        b,e        = 21000,21121\n        line_x     = [dfs[i][b:e]['id']            for i in range(len(dfs))]\n        line_y     = [dfs[i][b:e]['loan_paid_back'] for i in range(len(dfs))]\n        color      = colors + [color_cross]\n        alpha      = [0.8 for i in range(len(dfs)-1)] + [0.95]\n        lws        = [1.0 for i in range(len(dfs)-1)] + [1.00]\n        legend = subm_names + ['cross']\n        for i in range(len(legend)):\n            f.line(line_x[i], line_y[i], line_width=lws[i], color=color[i], alpha=alpha[i],\n                   muted_color='white',legend_label=legend[i])\n        f.legend.location = \"top_left\"\n        f.legend.click_policy=\"mute\"\n        show(f)\n\n\ndef h_blend(params,color,cross='silver',\n            figures1=False,figures2=False,wf2=555,\n            details=False):\n\n    color_cross = cross\n\n    dk = copy.deepcopy(params)\n\n    show_details,show_figures1,show_figures2 = details,figures1,figures2\n\n    file_short_names = [subm['name'] for subm in params['subm']]\n    type_sort    = params['type_sort'][0]\n    dk['asc']    = params['type_sort'][1]\n    dk['desc']   = params['type_sort'][2]\n    dk['id']     = params['id_target'][0]\n    dk['target'] = params['id_target'][1]\n# ------------------------------------------------------------------------\n    def read(dk,i):\n        tnm = dk[\"subm\"][i][\"name\"]\n        FiN = dk[\"path\"] + tnm + \".csv\"\n        return pd.read_csv(FiN).rename(columns={\n            'target':tnm, 'pred':tnm, dk[\"target\"]:tnm})\n        \n    def merge(dfs_subm):\n        df_subms = pd.merge(dfs_subm[0],  dfs_subm[1], on=[dk['id']])\n        for i in range(2, len(dk[\"subm\"])): \n            df_subms = pd.merge(df_subms, dfs_subm[i], on=[dk['id']])\n        return df_subms\n        \n    def da(dk,sorting_direction,show_details):\n        \n        df_subms = merge([read(dk,i) for i in range(len(dk[\"subm\"]))])\n        cols = [col for col in df_subms.columns if col != dk['id']]\n        short_name_cols = [c for c in cols]\n        \n        def alls1(x, sd=sorting_direction,cs=cols):\n            reverse = True if sd=='desc' else False\n            tes = {c: x[c] for c in cs}.items()\n            subms_sorted = [t[0] for t in sorted(tes,key=lambda k:k[1],reverse=reverse)]\n            return subms_sorted\n\n        import random\n\n        def alls2(x, sd=sorting_direction,cs=cols):\n            reverse = True if sd=='desc' else False\n            tes = {c: x[c] for c in cs}.items()\n            subms_random = [t[0] for t in tes]\n            random.shuffle(subms_random)\n            return subms_random\n\n        alls = alls1 if type_sort == 'asc/desc' else alls2\n            \n        def summa(x,cs,wts,ic_alls): \n            return sum([x[cs[j]] * (wts[0][j] + wts[1][ic_alls[j]]) for j in range(len(cs))])\n            \n        wts = [[[e['weight'] for e in dk[\"subm\"]], [w for w in dk[\"subwts\" ]]]]\n          \n        def correct(x, cs=cols, wts=wts):\n            i = [x['alls'].index(c) for c in short_name_cols]\n            return summa(x,cs,wts[0],i)\n\n        if len(wts) == 1:\n            correct_sub_weights = [wt for wt in dk[\"subwts\"]]\n            weights = [subm['weight'] for subm in dk[\"subm\"]]\n            def correct(x, cs=cols, w=weights, cw=correct_sub_weights):\n                ic = [x['alls'].index(c) for c in short_name_cols]\n                cS = [x[cols[j]] * (w[j] + cw[ic[j]]) for j in range(len(cols))]\n                return sum(cS)\n                   \n        def amxm(x, cs=cols):\n            list_values = x[cs].to_list()\n            mxm = abs(max(list_values)-min(list_values))\n            return mxm\n\n        if len(wts) > 1:\n            df_subms['mx-m']   = df_subms.apply(lambda x: amxm   (x), axis=1)\n        df_subms['alls']       = df_subms.apply(lambda x: alls   (x), axis=1)\n        df_subms[dk[\"target\"]] = df_subms.apply(lambda x: correct(x), axis=1)\n        schema_rename = { old_nc:new_shnc for old_nc, new_shnc in zip(cols, short_name_cols) }\n        df_subms = df_subms.rename(columns=schema_rename)\n        df_subms = df_subms.rename(columns={dk[\"target\"]:\"ensemble\"})\n        df_subms.insert(loc=1, column=' _ ', value=['   '] * len(df_subms))\n        df_subms[' _ '] = df_subms[' _ '].astype(str)\n        pd.set_option('display.max_rows',100)\n        pd.set_option('display.float_format', '{:.5f}'.format)\n        vcols = [dk['id']]+[' _ '] + short_name_cols + [' _ ']+['alls']+[' _ ']+['ensemble']\n        if len(wts) > 1: vcols.append([' _ '] + ['mx-m'])\n        df_subms = df_subms[vcols]\n        if show_details and sorting_direction=='desc': display(df_subms.head(5))\n        pd.set_option('display.float_format', '{:.5f}'.format)\n        df_subms = df_subms.rename(columns={\"ensemble\":dk[\"target\"]})\n        df_subms.to_csv(f'tida_{sorting_direction}.csv', index=False)\n        return df_subms[[dk['id'],dk['target']]]\n   \n    def ensemble_da(dk,        show_details): \n        dfD    = da(dk,'desc', show_details)\n        dfA    = da(dk,'asc',  show_details)\n        dfA[dk['target']] = dk['desc']*dfD[dk['target']] + dfA[dk['target']]*dk['asc']\n        return dfA\n\n    da = ensemble_da(dk,show_details)\n    colors = color_scheme(dk, color)\n    bokeh_show(dk, da, colors, show_figures1, show_figures2, wf2, color_cross)\n    return  da\n\n\ndef matrix_vs(path,fs_names):\n    def load(path,fs_names):\n        dfs = [pd.read_csv(path + name_subm +'.csv') for name_subm in fs_names]\n        for i in range(len(dfs)):\n            dfs[i] = dfs[i].rename(columns={\"loan_paid_back\": f'{fs_names[i]}'})\n        dfsm = pd.merge(dfs[0], dfs[1], on=\"id\")\n        for i in range(2,len(dfs)):\n            dfsm = pd.merge(dfsm,dfs[i],on='id')\n        return dfsm   \n    def make_list_vs(fs_names):\n        list = []\n        for i in range(0,len(fs_names)-1):\n            for j in range(i+1,len(fs_names)):\n                list.append(fs_names[i] + \"_vs_\" + fs_names[j])\n        return list\n    def get_mvs(dfs, list_vs):\n        def get_abs_distance(x,t1,t2):\n            return abs(x[t1]-x[t2])\n        for vs in list_vs:\n            t = vs.split('_vs_')\n            dfs[vs] = dfs.apply(lambda x: get_abs_distance(x,t[0],t[1]), axis=1)\n        return dfs   \n    def distance_vs(name, st_names, list_vs, dfs):\n        distances = []\n        for st in st_names:\n            vs_between = name + \"_vs_\" + st\n            if vs_between not in list_vs:\n                distances.append(0)\n            else: distances.append(round(dfs[vs_between].sum()))\n        return distances\n    dfs = load(path,fs_names)\n    list_vs = make_list_vs(fs_names)\n    mvs = get_mvs(dfs, list_vs)\n    m1 = pd.DataFrame({'subm':fs_names})\n    m2 = pd.DataFrame({ name :distance_vs(name, fs_names, list_vs, mvs) for name in fs_names})\n    matrix = pd.concat([m1,m2],axis=1)\n    return matrix\n\n\ndef display_distances(params):\n    files = [subm['name'] for subm in params['subm']]\n    distances = matrix_vs ( params['path'], files )            \n    display(distances)","metadata":{"trusted":true,"_kg_hide-input":true,"execution":{"iopub.status.busy":"2025-11-05T16:38:14.416932Z","iopub.execute_input":"2025-11-05T16:38:14.417659Z","iopub.status.idle":"2025-11-05T16:38:15.416609Z","shell.execute_reply.started":"2025-11-05T16:38:14.417633Z","shell.execute_reply":"2025-11-05T16:38:15.415833Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## first_glance","metadata":{}},{"cell_type":"code","source":"path = f'/kaggle/input/4-november-2025-ps-s5e11/submission '\n\nparams = {\n      'path'     : path,            \n      'id_target': ['id',\"loan_paid_back\"],          \n      'type_sort': ['asc/desc',0.40,0.60 ],\n      'subwts'   : [-0.01,-0.02,-0.03,-0.04, +0.05,+0.05 ],\n      'subm'     : [\n         { 'name': f'0.92546','weight':+0.15 },\n         { 'name': f'0.92574','weight':+0.17 },\n         { 'name': f'0.92576','weight':+0.17 },\n         { 'name': f'0.92615','weight':+0.17 },\n         { 'name': f'0.92620','weight':+0.17 },\n         { 'name': f'0.92668','weight':+0.17 },]\n}\n\ndf_cross = h_blend(params, color='red6', figures1=True, figures2=True, details=True)\n\ndisplay_distances(params)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-04T18:58:47.630101Z","iopub.execute_input":"2025-11-04T18:58:47.630402Z","iopub.status.idle":"2025-11-04T18:59:59.459642Z","shell.execute_reply.started":"2025-11-04T18:58:47.630382Z","shell.execute_reply":"2025-11-04T18:59:59.458768Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Well, friends, let's move on.\n\n#### We've added a new element—the result of good expert work, with a LB of 0.92677.\n\nLet's see how it performs in the overall group—we won't be sending it to the main system for evaluation yet, but we'll look at the \"vs\" matrix and, of course, the Bokeh visual 'slice'.\nThis should be enough to understand—submit this new 'csv' file to the same '**action**' that the two master files will undergo—that is, files 5 and 6 (LB.5=0.92620, LB.6=0.92668). \n\nThe '**action**' will be as follows: each of the files candidates for artificial antialiasing will be brought as close to the group as possible in a single operation, meaning each prediction line in the 'csv' file of the submission will be multiplied by a single constant.\n\n#### We'll try to find this constant using a simple enumeration. \n\nThis function will be written in C# and attached here as an archive cell. We're doing this because we already have half of this function; we worked on it a little earlier but didn't have time to launch it. So, we'll have time to do it here, especially since we have 10 launches per day in this competition.\n\n#### After this procedure, we'll run h-blend \n\non these arti files for our existing group—four Japanese files plus one newcomer. We'll first evaluate this newcomer—that is, whether it will be relegated to the main Japanese group or subject to artificial smoothing.\n\n#### And tomorrow, November 7, 2025, we'll enable the voting subsystem. \n\nWe hope to see and understand the essence, or rather the result, of this experiment within 10 launches.\n\nTo business..","metadata":{}},{"cell_type":"markdown","source":"#### Let's assign the color darkmagenta to file 0.92677 \n\nand run it along with the red group from the Japanese contributor. We'll remove the two master files from there for now, so we can see better where to place the new file 0.92677.","metadata":{}},{"cell_type":"code","source":"path = f'/kaggle/input/4-november-2025-ps-s5e11/submission '\n\nparams = {\n      'path'     : path,            \n      'id_target': ['id',\"loan_paid_back\"],          \n      'type_sort': ['asc/desc',0.40,0.60 ],\n      'subwts'   : [ +0.07,+0.04, -0.01,-0.03,-0.07 ],\n      'subm'     : [\n         { 'name': f'0.92546','weight':+0.20 },\n         { 'name': f'0.92574','weight':+0.20 },\n         { 'name': f'0.92576','weight':+0.20 },\n         { 'name': f'0.92615','weight':+0.20 },\n         # { 'name': f'0.92620','weight':+0.17 },\n         # { 'name': f'0.92668','weight':+0.17 },\n         { 'name': f'0.92677','weight':+0.20 },]\n}\n\ndf_cross = h_blend(params, color='red5', figures1=True, figures2=True, details=True)\n\ndisplay_distances(params)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-05T12:19:12.159269Z","iopub.execute_input":"2025-11-05T12:19:12.159582Z","iopub.status.idle":"2025-11-05T12:20:03.902283Z","shell.execute_reply.started":"2025-11-05T12:19:12.159559Z","shell.execute_reply":"2025-11-05T12:20:03.901048Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### Yeah, it's obvious to the naked eye. \n#### More precisely, interactive Bokeh shows that this magenta file \n#### is more similar to the Japanese group—based on this similarity, \n\n### it'll be assigned to that group.\n\n## We'll zoom in on two master files to this J-Group: \n\n#### four Japanese files + one magenta file.","metadata":{}},{"cell_type":"markdown","source":"#### Let's start the smoothing process with a simple 50 x 50 straight blend","metadata":{}},{"cell_type":"code","source":"df_master1 = pd.read_csv('/kaggle/input/4-november-2025-ps-s5e11/submission 0.92620.csv')\ndf_master2 = pd.read_csv('/kaggle/input/4-november-2025-ps-s5e11/submission 0.92668.csv')\n\ndf_masters = pd.read_csv('/kaggle/input/playground-series-s5e11/sample_submission.csv')\n\ndf_masters['loan_paid_back'] =\\\n    df_master1['loan_paid_back'] *0.50 + \\\n    df_master2['loan_paid_back'] *0.50\n\n# df_masters.to_csv('submission masters.csv',index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-05T12:40:37.894527Z","iopub.execute_input":"2025-11-05T12:40:37.894991Z","iopub.status.idle":"2025-11-05T12:40:38.591892Z","shell.execute_reply.started":"2025-11-05T12:40:37.894962Z","shell.execute_reply":"2025-11-05T12:40:38.591059Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### We run the 'vs' matrix for all group members\n\nand then smoothly move on to the smoothing procedure","metadata":{}},{"cell_type":"code","source":"path = '/kaggle/input/4-november-2025-ps-s5e11/submission '\n\nfiles = [\n    '0.92546','0.92574','0.92576','0.92615','0.92677',\n    'masters','0.92620','0.92668',\n]\n\nprint('before smoothing')\n\ndistances = matrix_vs ( path, files )\ndistances","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-05T12:54:38.854107Z","iopub.execute_input":"2025-11-05T12:54:38.854443Z","iopub.status.idle":"2025-11-05T12:55:28.486356Z","shell.execute_reply.started":"2025-11-05T12:54:38.854419Z","shell.execute_reply":"2025-11-05T12:55:28.485646Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"The J-Groupe's center of mass will be simple for now—namely, a straight blend for the five members of this group, in equal proportions.\nThat's not entirely true, but it'll do for now. If the experiment is successful, we'll try to optimize 'the whole thing.'","metadata":{}},{"cell_type":"code","source":"df_JpnRed1 = pd.read_csv('/kaggle/input/4-november-2025-ps-s5e11/submission 0.92546.csv')\ndf_JpnRed2 = pd.read_csv('/kaggle/input/4-november-2025-ps-s5e11/submission 0.92574.csv')\ndf_JpnRed3 = pd.read_csv('/kaggle/input/4-november-2025-ps-s5e11/submission 0.92576.csv')\ndf_JpnRed4 = pd.read_csv('/kaggle/input/4-november-2025-ps-s5e11/submission 0.92615.csv')\ndf_magenta = pd.read_csv('/kaggle/input/4-november-2025-ps-s5e11/submission 0.92677.csv')\n\ndf_JGroupe = pd.read_csv('/kaggle/input/playground-series-s5e11/sample_submission.csv')\n\ndf_JGroupe['loan_paid_back'] =\\\n    df_JpnRed1['loan_paid_back'] *0.20 + \\\n    df_JpnRed2['loan_paid_back'] *0.20 + \\\n    df_JpnRed3['loan_paid_back'] *0.20 + \\\n    df_JpnRed4['loan_paid_back'] *0.20 + \\\n    df_magenta['loan_paid_back'] *0.20\n\n# df_JGroupe.to_csv('submission JGroupe.csv',index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-05T14:00:05.339803Z","iopub.execute_input":"2025-11-05T14:00:05.341047Z","iopub.status.idle":"2025-11-05T14:00:06.265248Z","shell.execute_reply.started":"2025-11-05T14:00:05.341014Z","shell.execute_reply":"2025-11-05T14:00:06.264258Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"path = '/kaggle/input/4-november-2025-ps-s5e11/submission '\n\nfiles = [\n    'JGroupe','0.92546','0.92574','0.92576','0.92615','0.92677',\n    'masters','0.92620','0.92668'\n]\n\nprint('before smoothing')\n\ndistances = matrix_vs ( path, files )\ndistances","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-05T14:05:02.973428Z","iopub.execute_input":"2025-11-05T14:05:02.974144Z","iopub.status.idle":"2025-11-05T14:06:07.713411Z","shell.execute_reply.started":"2025-11-05T14:05:02.974109Z","shell.execute_reply":"2025-11-05T14:06:07.712668Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## The moment of smoothing, or rather their approach to JGroupe","metadata":{}},{"cell_type":"code","source":"df_master1 = pd.read_csv('/kaggle/input/4-november-2025-ps-s5e11/submission 0.92620.csv')\ndf_master2 = pd.read_csv('/kaggle/input/4-november-2025-ps-s5e11/submission 0.92668.csv')\n\ndf_master1['loan_paid_back'] *= 1.009523\ndf_master2['loan_paid_back'] *= 1.072271\n\n# df_master1.to_csv('submission arti_1.csv',index=False)\n# df_master2.to_csv('submission arti_2.csv',index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-05T16:39:03.31238Z","iopub.execute_input":"2025-11-05T16:39:03.312797Z","iopub.status.idle":"2025-11-05T16:39:04.724084Z","shell.execute_reply.started":"2025-11-05T16:39:03.312777Z","shell.execute_reply":"2025-11-05T16:39:04.723155Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"path = '/kaggle/input/4-november-2025-ps-s5e11/submission '\n\nfiles = [\n    'JGroupe','0.92546','0.92574','0.92576','0.92615','0.92677',\n    'masters','0.92620','0.92668',\n               'arti_1', 'arti_2',\n    '0.92728' \n]\n\nprint('after smoothing')\n\ndistances = matrix_vs ( path, files )\ndistances","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-05T16:43:37.661574Z","iopub.execute_input":"2025-11-05T16:43:37.662238Z","iopub.status.idle":"2025-11-05T16:45:43.397533Z","shell.execute_reply.started":"2025-11-05T16:43:37.662209Z","shell.execute_reply":"2025-11-05T16:45:43.396545Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Version.2","metadata":{}},{"cell_type":"code","source":"path = f'/kaggle/input/4-november-2025-ps-s5e11/submission '\n\nparams = {\n      'path'     : path,            \n      'id_target': ['id',\"loan_paid_back\"],          \n      'type_sort': ['asc/desc',0.35,0.65 ],\n      'subwts'   : [ +0.11,-0.01,-0.03,-0.07 ],\n      'subm'     : [\n         { 'name': f'0.92728','weight':+0.25 },\n         { 'name': f'arti_1', 'weight':+0.25 },\n         { 'name': f'arti_2', 'weight':+0.25 },\n         { 'name': f'JGroupe','weight':+0.25 },]\n}\n\ndf_cross = h_blend(params, color='brown4', figures1=True, figures2=True, details=True)\n\ndisplay_distances(params)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-05T17:49:16.017503Z","iopub.execute_input":"2025-11-05T17:49:16.021403Z","iopub.status.idle":"2025-11-05T17:49:59.173048Z","shell.execute_reply.started":"2025-11-05T17:49:16.021323Z","shell.execute_reply":"2025-11-05T17:49:59.172013Z"},"_kg_hide-input":true,"_kg_hide-output":true,"jupyter":{"source_hidden":true,"outputs_hidden":true},"collapsed":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Version.3","metadata":{}},{"cell_type":"code","source":"path = f'/kaggle/input/4-november-2025-ps-s5e11/submission '\n\nparams = {\n      'path'     : path,            \n      'id_target': ['id',\"loan_paid_back\"],          \n      'type_sort': ['asc/desc',0.35,0.65 ],\n      'subwts'   : [ +0.11,-0.01,-0.03,-0.07 ],\n      'subm'     : [\n         { 'name': f'0.92728','weight':+0.55 },\n         { 'name': f'arti_1', 'weight':+0.15 },\n         { 'name': f'arti_2', 'weight':+0.15 },\n         { 'name': f'JGroupe','weight':+0.15 },]\n}\n\ndf_cross = h_blend(params, color='brown4', figures1=True, figures2=True, details=True)\n\ndisplay_distances(params)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-05T18:01:06.225602Z","iopub.execute_input":"2025-11-05T18:01:06.226556Z","iopub.status.idle":"2025-11-05T18:01:48.221462Z","shell.execute_reply.started":"2025-11-05T18:01:06.226523Z","shell.execute_reply":"2025-11-05T18:01:48.220488Z"},"_kg_hide-input":true,"_kg_hide-output":true,"jupyter":{"source_hidden":true,"outputs_hidden":true},"collapsed":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Version 4","metadata":{}},{"cell_type":"code","source":"path = f'/kaggle/input/4-november-2025-ps-s5e11/submission '\n\nparams = {\n      'path'     : path,            \n      'id_target': ['id',\"loan_paid_back\"],          \n      'type_sort': ['asc/desc',0.35,0.65 ],\n      'subwts'   : [ +0.11,-0.01,-0.03,-0.07 ],\n      'subm'     : [\n         { 'name': f'0.92728','weight':+0.70 },\n         { 'name': f'arti_1', 'weight':+0.10 },\n         { 'name': f'arti_2', 'weight':+0.10 },\n         { 'name': f'JGroupe','weight':+0.10 },]\n}\n\ndf_cross = h_blend(params, color='brown4', figures1=True, figures2=True, details=True)\n\ndisplay_distances(params)","metadata":{"trusted":true,"_kg_hide-input":true,"_kg_hide-output":true,"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Version.5","metadata":{}},{"cell_type":"code","source":"path = f'/kaggle/input/4-november-2025-ps-s5e11/submission '\n\nparams = {\n      'path'     : path,            \n      'id_target': ['id',\"loan_paid_back\"],          \n      'type_sort': ['asc/desc',0.35,0.65 ],\n      'subwts'   : [ +0.11,-0.01,-0.03,-0.07 ],\n      'subm'     : [\n         { 'name': f'0.92728','weight':+0.85 },\n         { 'name': f'arti_1', 'weight':+0.05 },\n         { 'name': f'arti_2', 'weight':+0.05 },\n         { 'name': f'JGroupe','weight':+0.05 },]\n}\n\ndf_cross = h_blend(params, color='brown4', figures1=True, figures2=True, details=True)\n\ndisplay_distances(params)","metadata":{"trusted":true,"_kg_hide-input":true,"_kg_hide-output":true,"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Version.6","metadata":{}},{"cell_type":"code","source":"path = f'/kaggle/input/4-november-2025-ps-s5e11/submission '\n\nparams = {\n      'path'     : path,            \n      'id_target': ['id',\"loan_paid_back\"],          \n      'type_sort': ['asc/desc',0.35,0.65 ],\n      'subwts'   : [ -0.07,-0.03,-0.01,+0.11 ],\n      'subm'     : [\n         { 'name': f'0.92728','weight':+0.79 },\n         { 'name': f'arti_1', 'weight':+0.07 },\n         { 'name': f'arti_2', 'weight':+0.07 },\n         { 'name': f'JGroupe','weight':+0.07 },]\n}\n\ndf_cross = h_blend(params, color='brown4', figures1=True, figures2=True, details=True)\n\ndisplay_distances(params)","metadata":{"trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Version.7","metadata":{}},{"cell_type":"code","source":"path = f'/kaggle/input/4-november-2025-ps-s5e11/submission '\n\nparams = {\n      'path'     : path,            \n      'id_target': ['id',\"loan_paid_back\"],          \n      'type_sort': ['asc/desc',0.355,0.645 ],\n      'subwts'   : [ +0.03,-0.01,-0.02 ],\n      'subm'     : [\n         { 'name': f'0.92730','weight':+0.955 },\n         { 'name': f'JGroupe','weight':+0.015 },\n         { 'name': f'masters','weight':+0.030 },\n      ]\n}\n\ndf_cross = h_blend(params, color='alls', figures1=True, figures2=True, details=True)\n\ndisplay_distances(params)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Submit","metadata":{"papermill":{"duration":0.005641,"end_time":"2025-11-01T13:01:46.330978","exception":false,"start_time":"2025-11-01T13:01:46.325337","status":"completed"},"tags":[]}},{"cell_type":"code","source":"df_cross . to_csv('submission.csv',index=False)\ndf_cross","metadata":{"execution":{"iopub.status.busy":"2025-11-04T18:58:35.246671Z","iopub.execute_input":"2025-11-04T18:58:35.247581Z","iopub.status.idle":"2025-11-04T18:58:35.817391Z","shell.execute_reply.started":"2025-11-04T18:58:35.24755Z","shell.execute_reply":"2025-11-04T18:58:35.81664Z"},"papermill":{"duration":0.5445,"end_time":"2025-11-01T13:01:46.881223","exception":false,"start_time":"2025-11-01T13:01:46.336723","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null}]}