{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.13"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":91722,"databundleVersionId":14262372,"sourceType":"competition"},{"sourceId":13582034,"sourceType":"datasetVersion","datasetId":8623353},{"sourceId":13617019,"sourceType":"datasetVersion","datasetId":8635402},{"sourceId":13631075,"sourceType":"datasetVersion","datasetId":8652235},{"sourceId":13652933,"sourceType":"datasetVersion","datasetId":8679193},{"sourceId":13661896,"sourceType":"datasetVersion","datasetId":8679843}],"dockerImageVersionId":31192,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false},"papermill":{"default_parameters":{},"duration":709.34758,"end_time":"2025-11-06T07:13:22.892667","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2025-11-06T07:01:33.545087","version":"2.6.0"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### PS-s4e11 - [Predicting Loan Payback](https://www.kaggle.com/competitions/playground-series-s5e11/code?competitionId=91722&sortBy=scoreDescending&excludeNonAccessedDatasources=true)\n\nPlayground Series - Season 5, Episode 11\n\n| | | &nbsp; | | &nbsp; | &nbsp; | &nbsp; |\n|:-|:-| :-: | :-: | :-: | :-: | :-: |\n| 1. | [0.92_684](https://www.kaggle.com/code/yeoyunsianggeremie/ps5e11-agentic-ai-solution-single-xgb?scriptVersionId=273334165) |&nbsp;v.8&nbsp;| [PS5E11 . Agentic AI Solution](https://www.kaggle.com/code/yeoyunsianggeremie/ps5e11-agentic-ai-solution) | grandmaster | [bogoconic1](https://www.kaggle.com/yeoyunsianggeremie) | Singapore |\n| 2. | [0.92_683](https://www.kaggle.com/code/sagarnagpure1310/s5e11-xgb-lgbm-fe-te-ensemble-92-68?scriptVersionId=273333134) |&nbsp;v.2&nbsp;| [S5E11 . XGB + LGBM . FE, TE & Ensemble . 92.68](https://www.kaggle.com/code/sagarnagpure1310/s5e11-xgb-lgbm-fe-te-ensemble-92-68) | contributor | [Sagar Nagpure](https://www.kaggle.com/sagarnagpure1310) | India |\n| 3. | [0.92_672](https://www.kaggle.com/code/shreyashpatil217/loan-prediction-credit-risk-assessment?scriptVersionId=273425848) |&nbsp;v.1&nbsp;| [ðŸ’° Loan Prediction & Credit Risk Assessment](https://www.kaggle.com/code/shreyashpatil217/loan-prediction-credit-risk-assessment) | expert |[Shreyash Patil](https://www.kaggle.com/shreyashpatil217) | India |\n| 4. | [0.92_664](https://www.kaggle.com/code/jockeroika/loan-payback?scriptVersionId=274058844) |&nbsp;v.1&nbsp;| [Loan Payback](https://www.kaggle.com/code/jockeroika/loan-payback) | grandmaster |[Omar Essa](https://www.kaggle.com/jockeroika) | Egypt |\n| 5. | [0.92_677](https://www.kaggle.com/code/adilshamim8/predicting-loan-payback-101?scriptVersionId=273568426) |&nbsp;v.3&nbsp;| [Predicting Loan Payback 101](https://www.kaggle.com/code/adilshamim8/predicting-loan-payback-101) | expert | [Adil Shamim](https://www.kaggle.com/adilshamim8) | World |\n| 6. | [0.92_655](https://www.kaggle.com/code/karltonkxb/s5e11-loan-xgb-lgbm-cuml-92-64/log?scriptVersionId=273327882) |&nbsp;v.7&nbsp;| [S5E11-Loan-XGB LGBM-CuML-92.64](https://www.kaggle.com/code/karltonkxb/s5e11-loan-xgb-lgbm-cuml-92-64) | expert | [Samidullo](https://www.kaggle.com/karltonkxb) | Poland |\n| 7. | [0.92_657](https://www.kaggle.com/code/yousefelshahat2/simple-lightgbm-only-competition-data-s5e11?scriptVersionId=273815639) |&nbsp;v.6&nbsp;| [Simple LightGBM . Only Competition Data](https://www.kaggle.com/code/yousefelshahat2/simple-lightgbm-only-competition-data-s5e11) | expert | [yousef Elshahat](https://www.kaggle.com/yousefelshahat2) | World |\n| 8. | [0.92_643](https://www.kaggle.com/code/sidakou/optimized-weighted-ensemble-of-xgb-lgb-cat-hgb?scriptVersionId=273000295) |&nbsp;v.1&nbsp;| [Opt. Weighted Ensemble of XGB, LGB, CAT & HGB](https://www.kaggle.com/code/sidakou/optimized-weighted-ensemble-of-xgb-lgb-cat-hgb) | contributor | [å®‰å°¾ æ™ƒè²´](https://www.kaggle.com/sidakou) | Japan |\n| 9. | [0.92_712](https://www.kaggle.com/code/masayakawamata/s5e11-single-xgb-add-features?scriptVersionId=274389899) |&nbsp;v.3&nbsp;| [S5E11 . Single XGB - Add Features](https://www.kaggle.com/code/masayakawamata/s5e11-single-xgb-add-features) | expert | [Masaya Kawamata](https://www.kaggle.com/masayakawamata) | Japan |\n| 10. | [0.92_603](https://www.kaggle.com/code/masayakawamata/s5e11-cat-interaction-features?scriptVersionId=273552378) |&nbsp;v.1&nbsp;| [S5E11 . Cat - Interaction Features](https://www.kaggle.com/code/masayakawamata/s5e11-cat-interaction-features) | expert | [Masaya Kawamata](https://www.kaggle.com/masayakawamata) | Japan |\n| 11. | [0.92_601](https://www.kaggle.com/code/pradiptadatta/org-pss5e11-flaml-roc-auc?scriptVersionId=272623191) |&nbsp;v.1&nbsp;| [Org+PSS5E11 : FLAML : roc_auc](https://www.kaggle.com/code/pradiptadatta/org-pss5e11-flaml-roc-auc) | expert | [Pradipta Datta](https://www.kaggle.com/pradiptadatta) | India |\n| 12. | [0.92_353](https://www.kaggle.com/code/yeoyunsianggeremie/ps5e11-pytorch-nn-baseline-ft-transformer?scriptVersionId=274007166) |&nbsp;v.4&nbsp;| [PS5E11 . PyTorch NN Baseline [FT-Transformer]](https://www.kaggle.com/code/yeoyunsianggeremie/ps5e11-pytorch-nn-baseline-ft-transformer) | grandmaster | [bogoconic1](https://www.kaggle.com/yeoyunsianggeremie) | Singapore |\n| [ 13](https://www.kaggle.com/code/nina2025/ps-s5e11-straight-blend/notebook?scriptVersionId=274386273). |[&nbsp;](https://)<br>[0.92_698](https://www.kaggle.com/code/nina2025/ps-s5e11-straight-blend?scriptVersionId=274386273)<br>[&nbsp;](https://)|&nbsp;v.1&nbsp;<br>&nbsp;v.1&nbsp;<br>&nbsp;v.1&nbsp;| [Loan Payback . Ensemble](https://www.kaggle.com/code/mikhailnaumov/loan-payback-ensemble/output)<br>&nbsp;[PlaygroundS5E11 - Autogluon](https://www.kaggle.com/code/dalloliogm/playgrounds5e11-autogluon/notebook)&nbsp;<br>[PS-S5E11: XGBoost Stability Model](https://www.kaggle.com/code/canozensoy/ps-s5e11-xgboost-stability-model/notebook) | master<br>expert<br>master | [Mikhail Naumov](https://www.kaggle.com/mikhailnaumov)<br>[Giovanni Marco Dall'Olio](https://www.kaggle.com/dalloliogm)<br>[Can Ã–zensoy](https://www.kaggle.com/canozensoy) | World <br> England <br> TÃ¼rkiye |\n| 14. | [0.92_732](https://www.kaggle.com/code/nina2025/ps-s5e11-straight-blend?scriptVersionId=274390431) |&nbsp;v.3&nbsp;| [[ 1, 2, 3, 11 ](https://www.kaggle.com/code/nina2025/ps-s5e11-straight-blend)] | master | [community](https://www.kaggle.com/) | International |\n| 15. | [0.92_694](https://www.kaggle.com/code/nina2025/ps-s5e11-straight-blend/notebook?scriptVersionId=274399423) |&nbsp;v.4&nbsp;| [[ 4, 5, 6, 7 ](https://www.kaggle.com/code/nina2025/ps-s5e11-straight-blend)] | master | [community](https://www.kaggle.com/) | International |\n| 16. | [0.92_661](https://www.kaggle.com/code/nina2025/ps-s5e11-straight-blend/notebook?scriptVersionId=274403386) |&nbsp;v.5&nbsp;| [[ 8, 9, 10, 12 ](https://www.kaggle.com/code/nina2025/ps-s5e11-straight-blend)] | master | [community](https://www.kaggle.com/) | International |\n| 17. | [0.92_711](https://www.kaggle.com/code/sagarnagpure1310/s5e11-enhanced-xgb-cat-lb-0-92715/notebook?scriptVersionId=274485714) |&nbsp;v.14&nbsp;| [ S5E11 . Enhanced XGB + CAT ](https://www.kaggle.com/code/sagarnagpure1310/s5e11-enhanced-xgb-cat-lb-0-92715)] | contributor | [Sagar Nagpure](https://www.kaggle.com/sagarnagpure1310) | India |\n| 18. | [0.92_715](https://www.kaggle.com/code/sagarnagpure1310/s5e11-enhanced-xgb-cat-lb-0-92715?scriptVersionId=274471354) |&nbsp;v.12&nbsp;| [ S5E11 . Enhanced XGB + CAT ](https://www.kaggle.com/code/sagarnagpure1310/s5e11-enhanced-xgb-cat-lb-0-92715/notebook)] | contributor | [Sagar Nagpure](https://www.kaggle.com/sagarnagpure1310) | India |\n|||||||\n|||| main weights % | asc/desc % | correct weights % |\n|  | [0.92_732](https://www.kaggle.com/code/nina2025/ps-s5e11-h-blend?scriptVersionId=274434793) | v.1 | [ 13, 14, 15, 16 ] . wts .[ 9+79+9+3 ] | 30&nbsp;**x**&nbsp;70 | + 0.11, -0.01,-0.03,-0.07 |\n|  | [0.92_730](https://www.kaggle.com/code/nina2025/ps-s5e11-h-blend?scriptVersionId=274437981) | v.1 | [ 13, 14, 15, 16 ] . wts .[ 15+60+15+10 ] | 35&nbsp;**x**&nbsp;65 | + 0.11, -0.01,-0.03,-0.07 |\n|  | [0.92_739](https://www.kaggle.com/code/nina2025/ps-s5e11-h-blend?scriptVersionId=274442884) | v.3 | [ 13, 14, 15, 9 ] . wts .[ 7+79+7+7 ] | 30&nbsp;**x**&nbsp;70 | + 0.11, -0.01,-0.03,-0.07 |\n|||||||\n|  | [0.92_728](https://www.kaggle.com/code/nina2025/ps-s5e11-h-blend?scriptVersionId=274639117) | v.4 |[[ 1, 2, 3, 11 ](https://www.kaggle.com/code/nina2025/ps-s5e11-h-blend/log?scriptVersionId=274442884)] + [[ 4, 5, 6, 7 ](https://www.kaggle.com/code/nina2025/ps-s5e11-h-blend/log?scriptVersionId=274442884)] + [[ 8, 9, 10 ](https://www.kaggle.com/code/nina2025/ps-s5e11-h-blend/log?scriptVersionId=274442884)] + [[ 13 ](https://www.kaggle.com/code/nina2025/ps-s5e11-straight-blend)] |[30&nbsp;**x**&nbsp;70](#h-blend.Groups)| [cwts4](https://www.kaggle.com/code/nina2025/ps-s5e11-h-blend/log?scriptVersionId=274442884) |\n|  | [0.92_734](https://www.kaggle.com/code/nina2025/ps-s5e11-h-blend?scriptVersionId=274645753) | v.5 |[[ 1, 2, 3, 11 ](https://www.kaggle.com/code/nina2025/ps-s5e11-h-blend?scriptVersionId=27464575)] + [[ 4, 5, 6, 7 ](https://www.kaggle.com/code/nina2025/ps-s5e11-h-blend?scriptVersionId=27464575)] + [[ 8, 9, 10 ](https://www.kaggle.com/code/nina2025/ps-s5e11-h-blend?scriptVersionId=27464575)] + [[ 13 ](https://www.kaggle.com/code/nina2025/ps-s5e11-straight-blend)] |[30&nbsp;**x**&nbsp;70](https://www.kaggle.com/code/nina2025/ps-s5e11-h-blend?scriptVersionId=27464575)| [cwts5](https://www.kaggle.com/code/nina2025/ps-s5e11-h-blend?scriptVersionId=27464575) |\n|  | [0.92_733](https://www.kaggle.com/code/nina2025/ps-s5e11-h-blend?scriptVersionId=274647564/) | v.6 |[[ 1, 2, 3, 11 ](https://www.kaggle.com/code/nina2025/ps-s5e11-h-blend?scriptVersionId=274647564)] + [[ 4, 5, 6, 7 ](https://www.kaggle.com/code/nina2025/ps-s5e11-h-blend?scriptVersionId=274647564)] + [[ 8, 9, 10 ](https://www.kaggle.com/code/nina2025/ps-s5e11-h-blend?scriptVersionId=274647564)] + [[ 13 ](https://www.kaggle.com/code/nina2025/ps-s5e11-straight-blend)] |[30&nbsp;**x**&nbsp;70](https://www.kaggle.com/code/nina2025/ps-s5e11-h-blend?scriptVersionId=274647564)| [cwts6](https://www.kaggle.com/code/nina2025/ps-s5e11-h-blend?scriptVersionId=274647564) |\n|  | [?](https://) | v.7 |[[ 1, 2, 3, 11 ](#version_7)] + [[ 4, 5, 6, 7 ](#version_7)] + [[ 9, 17, 18 ](#version_7)] + [[ 13 ](https://www.kaggle.com/code/nina2025/ps-s5e11-straight-blend)] |[30&nbsp;**x**&nbsp;70](#version_7)| [cwts6](#version_7) |","metadata":{"papermill":{"duration":0.007306,"end_time":"2025-11-06T07:01:39.114502","exception":false,"start_time":"2025-11-06T07:01:39.107196","status":"completed"},"tags":[]}},{"cell_type":"code","source":"import os,ast\nimport numpy as np\nimport pandas as pd\n\nimport shutil,copy\n\nfrom bokeh.plotting import figure, gridplot \nfrom bokeh.io import output_file, show, output_notebook\noutput_notebook()\n\ndef color_scheme(dk,color):\n    colors    = ['red','green','blue']\n    clr_alls  = ['green','gold',\"blue\",'crimson']\n    clr_alls2 = ['red',\"green\",'blue',\"silver\",'gold']\n    clr_alls3 = ['darkmagenta',\"forestgreen\",'mediumblue']\n    clr_alls4 = ['crimson','darkgreen',\"forestgreen\",\"limegreen\"]\n    clr_alls4r= ['darkgreen',\"forestgreen\",'crimson',\"limegreen\"]\n    clr_alls4m= ['red',\"forestgreen\",'mediumblue',\"darkmagenta\"]\n    clr_alls4j= ['red',\"green\",'blue',\"sienna\"]\n    clr_alls4i= ['crimson',\"green\",'mediumblue',\"chocolate\"]\n    clr_alls5 = ['red',\"forestgreen\",'mediumblue',\"darkmagenta\",'crimson']\n    clr_alls15= ['blue','mediumblue','navy','crimson']\n    clr_gold  = ['gainsboro',\"silver\",'darkgray','gray','gold']\n    clr_Red4  = [\"firebrick\",\"orangered\",\"crimson\",'red']\n    clr_Red52 = ['silver','darkgray','gray','crimson',\"crimson\"]\n    clr_Red53 = ['silver','darkgray','gray','dimgray',\"crimson\"]\n    clr_Red54 = ['forestgreen','limegreen','lime',\"crimson\"]\n    clr_Red55 = [\"silver\",'darkgray','gray',\"crimson\"]\n    clr_Red6  = [\"crimson\",'red','orangered','tomato','green','mediumblue']\n    clr_Red5  = [\"crimson\",'red','orangered','tomato','darkmagenta']\n    clr_Red3  = ['red','tomato',\"crimson\"]\n    clr_Red31 = [\"crimson\",'red','gold']\n    clr_Red13 = ['gold',\"crimson\",'red']\n    clr_Green = [\"limegreen\",\"forestgreen\",\"mediumseagreen\",\"green\",\"darkgreen\"]\n    clr_Green2= ['olivedrab',\"darkgreen\",\"forestgreen\"]\n    clr_Green3= [\"darkmagenta\",'olivedrab',\"darkgreen\"]\n    clr_Green4= [\"darkgreen\",\"forestgreen\",\"limegreen\",\"lime\"]\n    clr_Green5= [\"crimson\",\"darkgreen\",\"forestgreen\",\"limegreen\",\"lime\"]\n    clr_Blue  = ['midnightblue',\"royalblue\",\"mediumblue\",\"blue\",\"steelblue\",'cyan']\n    clr_Blue4 = ['midnightblue',\"royalblue\",\"mediumblue\",\"deepskyblue\"]\n    clr_Blue5 = [\"firebrick\",'navy',\"mediumblue\",\"royalblue\",\"deepskyblue\"]\n    clr_Brown = [\"maroon\",'firebrick',\"chocolate\",\"sienna\",\"sandybrown\"]\n    clr_Brown3= [\"maroon\",\"sienna\",\"sandybrown\"]\n    clr_Brown4= [\"maroon\",\"sienna\",\"chocolate\",\"sandybrown\"]\n    clr_Brown5= [\"maroon\",\"sienna\",\"chocolate\",\"sandybrown\",'gold']\n    clr_Two   = ['crimson','mediumblue']\n    clr_Two2  = ['crimson','darkgreen']\n    clr_tes3  = ['limegreen',\"magenta\",'red']\n    clr_tes3b = ['darkmagenta',\"magenta\",'red']\n    clr_tes5  = ['mediumblue','crimson','crimson','crimson','mediumblue']\n    clr_tes6  = ['limegreen'] + clr_Brown\n    clr_tes7  = clr_Brown4 + [\"mediumblue\"]+[\"crimson\"]+['red']\n    clr_tes8  = clr_Red4 + clr_Blue4\n    clr_tes9  = clr_Red4 + ['darkmagenta'] + clr_Blue4\n    clr_tes10 = clr_Brown + clr_Green\n    clr_tes11 = clr_Brown + clr_Green + ['blue']\n    l = len(dk['subm'])\n    if color == 'Two2'  : colors = clr_Two2   [0:l]\n    if color == 'Two'   : colors = clr_Two    [0:l]\n    if color == 'alls'  : colors = clr_alls   [0:l]\n    if color == 'alls2' : colors = clr_alls2  [0:l]\n    if color == 'alls3' : colors = clr_alls3  [0:l]\n    if color == 'alls4' : colors = clr_alls4  [0:l]\n    if color == 'alls4r': colors = clr_alls4r [0:l]\n    if color == 'alls4m': colors = clr_alls4m [0:l]\n    if color == 'alls4i': colors = clr_alls4i [0:l]\n    if color == 'alls4j': colors = clr_alls4j [0:l]\n    if color == 'alls5' : colors = clr_alls5  [0:l]\n    if color == 'alls15': colors = clr_alls15 [0:l]\n    if color == 'red'   : colors = clr_Red    [0:l]\n    if color == 'red3'  : colors = clr_Red3   [0:l]\n    if color == 'red4'  : colors = clr_Red4   [0:l]\n    if color == 'red5'  : colors = clr_Red5   [0:l]\n    if color == 'red52' : colors = clr_Red52  [0:l]\n    if color == 'red53' : colors = clr_Red53  [0:l]\n    if color == 'red54' : colors = clr_Red54  [0:l]\n    if color == 'red55' : colors = clr_Red55  [0:l]\n    if color == 'red6'  : colors = clr_Red6   [0:l]\n    if color == 'gold'  : colors = clr_gold   [0:l]\n    if color == 'red31' : colors = clr_Red31  [0:l]\n    if color == 'red13' : colors = clr_Red13  [0:l]\n    if color == 'green' : colors = clr_Green  [0:l]\n    if color == 'green2': colors = clr_Green2 [0:l]\n    if color == 'green3': colors = clr_Green3 [0:l]\n    if color == 'green4': colors = clr_Green4 [0:l]\n    if color == 'green5': colors = clr_Green5 [0:l]\n    if color == 'blue'  : colors = clr_Blue   [0:l]\n    if color == 'blue4' : colors = clr_Blue4  [0:l]\n    if color == 'blue5' : colors = clr_Blue5  [0:l]\n    if color == 'brown' : colors = clr_Brown  [0:l]\n    if color == 'brown3': colors = clr_Brown3 [0:l]\n    if color == 'brown4': colors = clr_Brown4 [0:l]\n    if color == 'brown5': colors = clr_Brown5 [0:l]\n    if color == 'tes3'  : colors = clr_tes3   [0:l]\n    if color == 'tes3b' : colors = clr_tes3b  [0:l]\n    if color == 'tes5'  : colors = clr_tes5   [0:l]\n    if color == 'tes6'  : colors = clr_tes6   [0:l]\n    if color == 'tes7'  : colors = clr_tes7   [0:l]\n    if color == 'tes8'  : colors = clr_tes8   [0:l]\n    if color == 'tes9'  : colors = clr_tes9   [0:l]\n    if color == 'tes10' : colors = clr_tes10  [0:l]\n    if color == 'tes11' : colors = clr_tes11  [0:l]\n    return colors\n\n\ndef bokeh_show(\n        params,\n        df_cross,\n        colors, \n        show_figures1, \n        show_figures2, wps_fig2,\n        color_cross):\n    \n    def dossier(js,subms,cols):\n        def quant(i,js,subms,cols):\n            return {\"c\" : i, \"q\" : sum([1 for subm in cols[i] if subm == subms[js]])}\n        return {\n            'name' : subms[js],\n            'q_in' : [quant(i,js,subms,cols) for i in range(len(subms))]\n        }\n    alls = pd.read_csv(f'tida_desc.csv')\n    matrix = [ast.literal_eval(str(row.alls)) for row in alls.itertuples()]\n    subms = sorted(matrix[0])\n    cols = [[data[i] for data in matrix] for i in range(len(subms))]\n    df_subms = pd.DataFrame({f'col_{i}': [x[i] for x in matrix] for i in range(len(subms))})\n    dossiers = [dossier(js,subms,cols) for js in range(len(subms))]\n    subm_names = [one_dossier['name'] for one_dossier in dossiers]\n    figures1,qss,i = [],[],0\n    height = 85 if len(colors)==2\\\n        else 134 if len(colors)==3 else (154 if len(colors)==4 else 174)\n    for one_dossier in dossiers: \n        i_col = 'alls. ' + str(one_dossier['q_in'][i]['c'])\n        qs = [one['q'] for one in one_dossier['q_in']]\n        x_names = [name.replace(\"Group\",\"\").replace(\"subm_\",\"\") for name in subm_names]\n        width = 157  if len(colors) == 5\\\n            else (121 if len(colors) == 8\\\n            else (131 if len(colors) == 9\\\n            else (141 if len(colors) == 10\\\n            else (171 if len(colors) == 11 else 133))))\n        f = figure(x_range=x_names,width=width, height=height, title=i_col)\n        f.vbar(x=x_names, width=0.585, top=qs, color=colors)\n        figures1.append(f)\n        qss.append(qs)\n        i+=1\n    grid = gridplot([figures1])\n    output_file('tida_alls.html')\n    if show_figures1 == True: show(grid)\n    sub_wts = params['subwts']\n    main_wts = [subm['weight'] for subm in params['subm']]\n    mms,acc_mass = [],[]\n    for j in range(len(dossiers)):\n        one_dossier = dossiers[j]\n        qs = [one['q'] for one in one_dossier['q_in']]\n        mm = [qs[h] * (main_wts[j] + sub_wts[h]) for h in range(len(sub_wts))]\n        mass = sum(mm)\n        mms.append(mm)\n        acc_mass.append(round(mass))                        #subm_names[::-1]\n    y_names = [name + \" - \" + str(mass) for name,mass in zip(subm_names,acc_mass)]\n    f1 = figure(y_range=y_names, width=313, height=height, title='relations of general masses')\n    f1.hbar(y=y_names, height=0.585, right=acc_mass, left=0, color=colors)\n    output_file('tida_alls2.html')\n    alls = [f'alls.{i}' for i in range(len(dossiers))]\n    subm = [f'sub{i}'   for i in range(len(dossiers))] \n    mmsT  = np.asarray(mms).T\n    data = {'cols' : alls}\n    for i in range(len(dossiers)): data[f'sub{i}'] = mmsT[i,:]\n    f2 = figure(y_range=alls, height=height, width=274, title=\" ( relations of columns masses )\")\n    f2.hbar_stack(subm, y='cols', height=0.585, color=colors, source=data)\n    qssT  = np.asarray(qss).T\n    data = {'cols' : alls}\n    for i in range(len(dossiers)): data[f'sub{i}'] = qssT[i,:]\n    f3 = figure(y_range=alls, height=height, width=215, title=\"ratios in columns\")\n    f3.hbar_stack(subm, y='cols', height=0.585, color=colors, source=data)\n    grid = gridplot([[f3,f2,f1]])\n    show(grid)\n    if show_figures2 == True:\n        def read(params,i):\n            FiN = params[\"path\"] + params[\"subm\"][i][\"name\"] + \".csv\"\n            target_name_back = {'target':params[\"target\"],'pred':params[\"target\"]}\n            return pd.read_csv(FiN).rename(columns=target_name_back)\n        dfs = [read(params,i) for i in range(len(params[\"subm\"]))] + [df_cross]\n        f   = figure(width=800, height=254)\n        f.title.text = 'Click on legend entries to mute the corresponding lines'\n        b,e        = 21000,21121\n        line_x     = [dfs[i][b:e]['id']            for i in range(len(dfs))]\n        line_y     = [dfs[i][b:e]['loan_paid_back'] for i in range(len(dfs))]\n        color      = colors + [color_cross]\n        alpha      = [0.8 for i in range(len(dfs)-1)] + [0.95]\n        lws        = [1.0 for i in range(len(dfs)-1)] + [1.00]\n        legend = subm_names + ['cross']\n        for i in range(len(legend)):\n            f.line(line_x[i], line_y[i], line_width=lws[i], color=color[i], alpha=alpha[i],\n                   muted_color='white',legend_label=legend[i])\n        f.legend.location = \"top_left\"\n        f.legend.click_policy=\"mute\"\n        show(f)\n\n\ndef h_blend(params,color,cross='silver',\n            figures1=False,figures2=False,wf2=555,\n            details=False):\n\n    color_cross = cross\n\n    dk = copy.deepcopy(params)\n\n    show_details,show_figures1,show_figures2 = details,figures1,figures2\n\n    file_short_names = [subm['name'] for subm in params['subm']]\n    type_sort    = params['type_sort'][0]\n    dk['asc']    = params['type_sort'][1]\n    dk['desc']   = params['type_sort'][2]\n    dk['id']     = params['id_target'][0]\n    dk['target'] = params['id_target'][1]\n# ------------------------------------------------------------------------\n    def read(dk,i):\n        tnm = dk[\"subm\"][i][\"name\"]\n        FiN = dk[\"path\"] + tnm + \".csv\"\n        return pd.read_csv(FiN).rename(columns={\n            'target':tnm, 'pred':tnm, dk[\"target\"]:tnm})\n        \n    def merge(dfs_subm):\n        df_subms = pd.merge(dfs_subm[0],  dfs_subm[1], on=[dk['id']])\n        for i in range(2, len(dk[\"subm\"])): \n            df_subms = pd.merge(df_subms, dfs_subm[i], on=[dk['id']])\n        return df_subms\n        \n    def da(dk,sorting_direction,show_details):\n        \n        df_subms = merge([read(dk,i) for i in range(len(dk[\"subm\"]))])\n        cols = [col for col in df_subms.columns if col != dk['id']]\n        short_name_cols = [c for c in cols]\n        \n        def alls1(x, sd=sorting_direction,cs=cols):\n            reverse = True if sd=='desc' else False\n            tes = {c: x[c] for c in cs}.items()\n            subms_sorted = [t[0] for t in sorted(tes,key=lambda k:k[1],reverse=reverse)]\n            return subms_sorted\n\n        import random\n\n        def alls2(x, sd=sorting_direction,cs=cols):\n            reverse = True if sd=='desc' else False\n            tes = {c: x[c] for c in cs}.items()\n            subms_random = [t[0] for t in tes]\n            random.shuffle(subms_random)\n            return subms_random\n\n        alls = alls1 if type_sort == 'asc/desc' else alls2\n            \n        def summa(x,cs,wts,ic_alls): \n            return sum([x[cs[j]] * (wts[0][j] + wts[1][ic_alls[j]]) for j in range(len(cs))])\n            \n        wts = [[[e['weight'] for e in dk[\"subm\"]], [w for w in dk[\"subwts\" ]]]]\n          \n        def correct(x, cs=cols, wts=wts):\n            i = [x['alls'].index(c) for c in short_name_cols]\n            return summa(x,cs,wts[0],i)\n\n        if len(wts) == 1:\n            correct_sub_weights = [wt for wt in dk[\"subwts\"]]\n            weights = [subm['weight'] for subm in dk[\"subm\"]]\n            def correct(x, cs=cols, w=weights, cw=correct_sub_weights):\n                ic = [x['alls'].index(c) for c in short_name_cols]\n                cS = [x[cols[j]] * (w[j] + cw[ic[j]]) for j in range(len(cols))]\n                return sum(cS)\n                   \n        def amxm(x, cs=cols):\n            list_values = x[cs].to_list()\n            mxm = abs(max(list_values)-min(list_values))\n            return mxm\n\n        if len(wts) > 1:\n            df_subms['mx-m']   = df_subms.apply(lambda x: amxm   (x), axis=1)\n        df_subms['alls']       = df_subms.apply(lambda x: alls   (x), axis=1)\n        df_subms[dk[\"target\"]] = df_subms.apply(lambda x: correct(x), axis=1)\n        schema_rename = { old_nc:new_shnc for old_nc, new_shnc in zip(cols, short_name_cols) }\n        df_subms = df_subms.rename(columns=schema_rename)\n        df_subms = df_subms.rename(columns={dk[\"target\"]:\"ensemble\"})\n        df_subms.insert(loc=1, column=' _ ', value=['   '] * len(df_subms))\n        df_subms[' _ '] = df_subms[' _ '].astype(str)\n        pd.set_option('display.max_rows',100)\n        pd.set_option('display.float_format', '{:.5f}'.format)\n        vcols = [dk['id']]+[' _ '] + short_name_cols + [' _ ']+['alls']+[' _ ']+['ensemble']\n        if len(wts) > 1: vcols.append([' _ '] + ['mx-m'])\n        df_subms = df_subms[vcols]\n        if show_details and sorting_direction=='desc': display(df_subms.head(5))\n        pd.set_option('display.float_format', '{:.5f}'.format)\n        df_subms = df_subms.rename(columns={\"ensemble\":dk[\"target\"]})\n        df_subms.to_csv(f'tida_{sorting_direction}.csv', index=False)\n        return df_subms[[dk['id'],dk['target']]]\n   \n    def ensemble_da(dk,        show_details): \n        dfD    = da(dk,'desc', show_details)\n        dfA    = da(dk,'asc',  show_details)\n        dfA[dk['target']] = dk['desc']*dfD[dk['target']] + dfA[dk['target']]*dk['asc']\n        return dfA\n\n    da = ensemble_da(dk,show_details)\n    colors = color_scheme(dk, color)\n    bokeh_show(dk, da, colors, show_figures1, show_figures2, wf2, color_cross)\n    return  da\n\n\ndef matrix_vs(path,fs_names):\n    def load(path,fs_names):\n        dfs = [pd.read_csv(path + name_subm +'.csv') for name_subm in fs_names]\n        for i in range(len(dfs)):\n            dfs[i] = dfs[i].rename(columns={\"loan_paid_back\": f'{fs_names[i]}'})\n        dfsm = pd.merge(dfs[0], dfs[1], on=\"id\")\n        for i in range(2,len(dfs)):\n            dfsm = pd.merge(dfsm,dfs[i],on='id')\n        return dfsm   \n    def make_list_vs(fs_names):\n        list = []\n        for i in range(0,len(fs_names)-1):\n            for j in range(i+1,len(fs_names)):\n                list.append(fs_names[i] + \"_vs_\" + fs_names[j])\n        return list\n    def get_mvs(dfs, list_vs):\n        def get_abs_distance(x,t1,t2):\n            return abs(x[t1]-x[t2])\n        for vs in list_vs:\n            t = vs.split('_vs_')\n            dfs[vs] = dfs.apply(lambda x: get_abs_distance(x,t[0],t[1]), axis=1)\n        return dfs   \n    def distance_vs(name, st_names, list_vs, dfs):\n        distances = []\n        for st in st_names:\n            vs_between = name + \"_vs_\" + st\n            if vs_between not in list_vs:\n                distances.append(0)\n            else: distances.append(round(dfs[vs_between].sum()))\n        return distances\n    dfs = load(path,fs_names)\n    list_vs = make_list_vs(fs_names)\n    mvs = get_mvs(dfs, list_vs)\n    m1 = pd.DataFrame({'subm':fs_names})\n    m2 = pd.DataFrame({ name :distance_vs(name, fs_names, list_vs, mvs) for name in fs_names})\n    matrix = pd.concat([m1,m2],axis=1)\n    return matrix\n\n\ndef display_distances(params):\n    files = [subm['name'] for subm in params['subm']]\n    distances = matrix_vs ( params['path'], files )            \n    display(distances)\n\n\ndef straight_blend(df_1,df_2,wts=[0.50,0.50],subm='submission.csv'):\n    t = 'loan_paid_back'\n    df_1[t] = df_1[t]*wts[0] + df_2[t]*wts[1]\n    df_1.to_csv(subm, index=False)\n    print(f'{subm} - ready to use')\n\n\n\n# def preparing_5_Groups(dfs):\n#     df_11 = get_preds_from_column(0, df_desc)\n#     df_12 = get_preds_from_column(1, df_desc) \n#     straight_blend(df_11,df_12,subm='Group_1.csv')\n#     df_21 = get_preds_from_column(2, df_desc) \n#     df_22 = get_preds_from_column(3, df_desc) \n#     straight_blend(df_21,df_22,subm='Group_2.csv')\n#     df_31 = get_preds_from_column(4, df_desc)\n#     df_32 = get_preds_from_column(5, df_desc)\n#     straight_blend(df_31,df_32,subm='Group_3.csv')\n#     df_41 = get_preds_from_column(7, df_desc)\n#     df_42 = get_preds_from_column(8, df_desc)\n#     straight_blend(df_41,df_42,subm='Group_4.csv')\n#     df_51 = get_preds_from_column(9, df_desc)\n#     df_52 = get_preds_from_column(10,df_desc)\n#     straight_blend(df_51,df_52,subm='Group_5.csv')\n\n\n# def voting(rem_left=0,rem_right=1, wts_with_Top=[0.50,0.50]):\n\n#     target = 'loan_paid_back'\n\n#     print(f'\\nVoting:\\n')\n\n#     df_Top    = pd.read_csv('/kaggle/input/4-november-2025-ps-s5e11/submission 0.92730.csv')\n#     df_vote   = pd.read_csv('/kaggle/input/playground-series-s5e11/sample_submission.csv') \n#     df_desc   = pd.read_csv('/kaggle/working/tida_desc.csv')\n\n#     print(f'participiants voting -----------------------------------------------------\\n')\n\n#     df_soluts = df_desc[df_desc.columns[2:13]];      display(df_soluts)\n\n#     rem_right = df_soluts.shape[1] - rem_right\n\n#     np_soluts_sorted = np.sort(df_soluts.to_numpy(), axis=1)\n\n#     rezult_matrix_of_vote = np_soluts_sorted[ : , rem_left : rem_right]\n\n#     print(\"'simple voting - sorting and exclusion from the list of 'dissenters'\")\n#     print(\"by trimming the 'presumed dissenters from the majority' from the left and right\\n\")\n\n#     display(pd.DataFrame(rezult_matrix_of_vote))\n\n#     print(f'voted --------------------------------------------------------------------\\n')\n\n#     df_vote[target]  = np.mean(rezult_matrix_of_vote, axis=1)\n\n#     df_vote[target]  =\\\n#         df_Top [target] * wts_with_Top[0] + \\\n#         df_vote[target] * wts_with_Top[1]\n    \n#     print(f'Compare: df_Top = loan_paid_back_x  vs  df_vote = loan_paid_back_y','-'*7,'\\n')\n\n#     df_comparison = pd.merge(df_Top, df_vote, on='id')\n#     df_comparison[\"delta_back's\"] = df_Top[target] - df_vote[target]\n#     display  (df_comparison)\n#     print(sum(df_comparison[\"delta_back's\"]),\n#               df_comparison[\"delta_back's\"][df_comparison[\"delta_back's\"] < 0].sum())\n#     return df_vote\n\n\n# df_vote = voting(rem_left=0,rem_right=4)\n\n\n# df_desc   = pd.read_csv('/kaggle/working/tida_desc.csv')\n\n# print('\\ntida_desc: column names are the short names of the submission files and voting participants') \n# print(\"\\n'alls' column is a sorted list of the short names of the participants according to their preds.\\n\")\n# display(df_desc[2:3])\n      \n# matrix = [ast.literal_eval(str(row.alls)) for row in df_desc.itertuples()]\n\n# print('\\n\\nGeneral represent of the \"parsed\" \"alls\" function column - a sorted list of short names')\n\n# print('\\nAll numbers in this dataframe are not preds but abbreviated names of subm. files')\n# print('\\nthe numbers are the assessment of the main system - this is LB \\n')\n\n# display(pd.DataFrame(matrix).head())\n\n# print('\\n one of the columns is selected and their predictions are taken from their names')\n\n\n# def get_preds_from_column(iCol,df_desc):\n#     def gic(ic=iCol,dd=df_desc):\n#         return dd.apply(lambda x:  x[ast.literal_eval(str(x['alls']))[ic]], axis=1)\n#     df = pd.read_csv('/kaggle/input/playground-series-s5e11/sample_submission.csv')\n#     df['loan_paid_back'] = gic()\n#     return df\n    \n\n# print('\\n For example, column 4 â€” alls.4 â€” can be viewed using the Bokeh visualization')\n# print('\\n this is one of the core components of the h-blend.\\n')\n\n# df_ic_vote = get_preds_from_column(4, df_desc)\n\n# print('\\n The question is raised - could this approach result in some kind of vote?\\n')\n\n# display(df_ic_vote)\n\n# print(\"\\n We have 11 columnsâ€”let's try sending each one to the system's evolution.\")\n# print(\"\\n Maybe we'll get something out of it, or at least see something.\")","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2025-11-09T01:27:12.60167Z","iopub.execute_input":"2025-11-09T01:27:12.602009Z","iopub.status.idle":"2025-11-09T01:27:12.720826Z","shell.execute_reply.started":"2025-11-09T01:27:12.601984Z","shell.execute_reply":"2025-11-09T01:27:12.719879Z"},"papermill":{"duration":3.695998,"end_time":"2025-11-06T07:01:42.816779","exception":false,"start_time":"2025-11-06T07:01:39.120781","status":"completed"},"tags":[],"trusted":true,"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## first_glance","metadata":{"papermill":{"duration":0.007349,"end_time":"2025-11-06T07:01:42.831429","exception":false,"start_time":"2025-11-06T07:01:42.82408","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"### version 1\n\nLB = 0.93_732","metadata":{}},{"cell_type":"code","source":"params = {\n      'path'     : f\"/kaggle/input/9-november-2025-ps-s5e11/submission \",            \n      'id_target': ['id',\"loan_paid_back\"],          \n      'type_sort': ['asc/desc',0.30,0.70 ],\n      'subwts'   : [ +0.11,-0.01,-0.03,-0.07 ],\n      'subm'     : [\n         { 'name': f'0.92661','weight':+0.03 },    # crimson\n         { 'name': f'0.92694','weight':+0.09 },    # darkgreen\n         { 'name': f'0.92698','weight':+0.09 },    # forestgreen\n         { 'name': f'0.92732','weight':+0.79 },]   # limegreen\n}\n\ndf_cross = h_blend(params, color='alls4', figures1=True, figures2=True, details=True)\n\ndisplay_distances(params)","metadata":{"execution":{"iopub.status.busy":"2025-11-08T06:14:12.015411Z","iopub.execute_input":"2025-11-08T06:14:12.015772Z","iopub.status.idle":"2025-11-08T06:14:58.769779Z","shell.execute_reply.started":"2025-11-08T06:14:12.015748Z","shell.execute_reply":"2025-11-08T06:14:58.768913Z"},"papermill":{"duration":78.605735,"end_time":"2025-11-06T07:03:01.444683","exception":false,"start_time":"2025-11-06T07:01:42.838948","status":"completed"},"tags":[],"trusted":true,"_kg_hide-input":true,"_kg_hide-output":true,"jupyter":{"source_hidden":true,"outputs_hidden":true},"collapsed":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### version 2\n\nLB = 0.92_730","metadata":{}},{"cell_type":"code","source":"params = {\n      'path'     : f\"/kaggle/input/9-november-2025-ps-s5e11/submission \",            \n      'id_target': ['id',\"loan_paid_back\"],          \n      'type_sort': ['asc/desc',0.35,0.65 ],\n      'subwts'   : [ +0.11,-0.01,-0.03,-0.07 ],\n      'subm'     : [\n         { 'name': f'0.92661','weight':+0.10 },    # crimson\n         { 'name': f'0.92694','weight':+0.15 },    # darkgreen\n         { 'name': f'0.92698','weight':+0.15 },    # forestgreen\n         { 'name': f'0.92732','weight':+0.60 },]   # limegreen\n}\n\ndf_cross = h_blend(params, color='alls4', figures1=True, figures2=True)\n","metadata":{"trusted":true,"_kg_hide-input":true,"_kg_hide-output":true,"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### version 3\n\nLB = 0.92_739","metadata":{}},{"cell_type":"code","source":"params = {\n      'path'     : f\"/kaggle/input/9-november-2025-ps-s5e11/submission \",            \n      'id_target': ['id',\"loan_paid_back\"],          \n      'type_sort': ['asc/desc',0.30,0.70 ],\n      'subwts'   : [ +0.11,-0.01,-0.03,-0.07 ],\n      'subm'     : [    \n         { 'name': f'0.92694','weight':+0.07 },    # darkgreen\n         { 'name': f'0.92698','weight':+0.07 },    # forestgreen\n         { 'name': f'0.92712','weight':+0.07 },    # crimson\n         { 'name': f'0.92732','weight':+0.79 },]   # limegreen\n}\n\ndf_cross = h_blend(params, color='alls4r', figures1=True, figures2=True, details=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-08T06:58:36.277625Z","iopub.execute_input":"2025-11-08T06:58:36.277949Z","iopub.status.idle":"2025-11-08T06:59:12.537885Z","shell.execute_reply.started":"2025-11-08T06:58:36.277925Z","shell.execute_reply":"2025-11-08T06:59:12.536754Z"},"jupyter":{"source_hidden":true,"outputs_hidden":true},"collapsed":true,"_kg_hide-input":true,"_kg_hide-output":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## version_7","metadata":{}},{"cell_type":"markdown","source":"Copying files from different datasets into a single shared folder. After completing the h-blend (friendly intersection) procedure, deleting the created folder and all its contents","metadata":{}},{"cell_type":"code","source":"new_path = '/kaggle/working/public'\nds_path4 = '/kaggle/input/4-november-2025-ps-s5e11'\nds_path1 = '/kaggle/input/01-november-2025-ps-s5e11'\nds_path3 = '/kaggle/input/03-november-2025-ps-s5e11'\nds_path8 = '/kaggle/input/8-november-2025-ps-s5e11'\nds_path9 = '/kaggle/input/9-november-2025-ps-s5e11'\n\nif os.path.isdir(new_path): shutil.rmtree(new_path); \n    \nos.mkdir(new_path)\n\nshutil.copy(ds_path3 +'/submission 0.92601.csv', new_path +'/0.92601.csv')\nshutil.copy(ds_path8 +'/submission 0.92657.csv', new_path +'/0.92657.csv')\nshutil.copy(ds_path8 +'/submission 0.92664.csv', new_path +'/0.92664.csv')\nshutil.copy(ds_path3 +'/submission 0.92643.csv', new_path +'/0.92643.csv')\nshutil.copy(ds_path3 +'/submission 0.92655.csv', new_path +'/0.92655.csv')\nshutil.copy(ds_path1 +'/submission 0.92603.csv', new_path +'/0.92603.csv')\nshutil.copy(ds_path3 +'/submission 0.92672.csv', new_path +'/0.92672.csv')\nshutil.copy(ds_path4 +'/submission 0.92677.csv', new_path +'/0.92677.csv')\nshutil.copy(ds_path3 +'/submission 0.92683.csv', new_path +'/0.92683.csv')\nshutil.copy(ds_path3 +'/submission 0.92684.csv', new_path +'/0.92684.csv')\nshutil.copy(ds_path9 +'/submission 0.92712.csv', new_path +'/0.92712.csv')\nshutil.copy(ds_path9 +'/submission 0.92711.csv', new_path +'/0.92711.csv')\nshutil.copy(ds_path9 +'/submission 0.92715.csv', new_path +'/0.92715.csv')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-09T01:27:59.984228Z","iopub.execute_input":"2025-11-09T01:27:59.984521Z","iopub.status.idle":"2025-11-09T01:28:00.467818Z","shell.execute_reply.started":"2025-11-09T01:27:59.984502Z","shell.execute_reply":"2025-11-09T01:28:00.466457Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_13 = pd.read_csv('/kaggle/input/9-november-2025-ps-s5e11/submission 0.92698.csv')\n\ndf_13 . to_csv('Group_13.csv',index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-09T01:28:07.705042Z","iopub.execute_input":"2025-11-09T01:28:07.705371Z","iopub.status.idle":"2025-11-09T01:28:08.534085Z","shell.execute_reply.started":"2025-11-09T01:28:07.705345Z","shell.execute_reply":"2025-11-09T01:28:08.532999Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"params = {\n      'path'     : new_path + '/',            \n      'id_target': ['id',\"loan_paid_back\"],          \n      'type_sort': ['asc/desc',0.30,0.70 ],\n      'subwts'   : [ +0.02,+0.02, -0.02,-0.02 ],\n      'subm'     : [    \n         { 'name': f'0.92601','weight':+0.25 },    # [11]  #  crimson\n         { 'name': f'0.92672','weight':+0.25 },    #  [3]  #  darkgreen \n         { 'name': f'0.92683','weight':+0.25 },    #  [2]  #  forestgreen\n         { 'name': f'0.92684','weight':+0.25 },]   #  [1]  #  limegreen\n}\n\ndf_cross = h_blend(params, color='alls4', figures1=True, figures2=True, details=True)\n\ndf_cross . to_csv('Group_14.csv', index=False)\n\ndisplay_distances(params)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-09T01:28:50.285123Z","iopub.execute_input":"2025-11-09T01:28:50.285444Z","iopub.status.idle":"2025-11-09T01:29:35.122582Z","shell.execute_reply.started":"2025-11-09T01:28:50.285418Z","shell.execute_reply":"2025-11-09T01:29:35.121692Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"params = {\n      'path'     : new_path + '/',            \n      'id_target': ['id',\"loan_paid_back\"],          \n      'type_sort': ['asc/desc',0.30,0.70 ],\n      'subwts'   : [ +0.02,-0.02,+0.02,-0.02 ],\n      'subm'     : [    \n         { 'name': f'0.92655','weight':+0.25 },    #  [6]  #  blue \n         { 'name': f'0.92657','weight':+0.25 },    #  [7]  #  mediumblue\n         { 'name': f'0.92664','weight':+0.25 },    #  [4]  #  navy\n         { 'name': f'0.92677','weight':+0.25 },]   #  [5]  #  crimson\n}\n\ndf_cross = h_blend(params, color='alls15', figures1=True, figures2=True, details=True)\n\ndf_cross . to_csv('Group_15.csv', index=False)\n\ndisplay_distances(params)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-09T00:18:43.634073Z","iopub.execute_input":"2025-11-09T00:18:43.634393Z","iopub.status.idle":"2025-11-09T00:19:27.896435Z","shell.execute_reply.started":"2025-11-09T00:18:43.634369Z","shell.execute_reply":"2025-11-09T00:19:27.895388Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"params = {\n      'path'     : new_path + '/',            \n      'id_target': ['id',\"loan_paid_back\"],          \n      'type_sort': ['asc/desc',0.30,0.70 ],\n      'subwts'   : [ +0.03,-0.01,-0.02 ],\n      'subm'     : [    \n         { 'name': f'0.92711','weight':+0.333 },    # [10]  #  red \n         { 'name': f'0.92712','weight':+0.333 },    #  [8]  #  tomato\n         { 'name': f'0.92715','weight':+0.334 },]   #  [9]  #  crimson\n}\n\ndf_cross = h_blend(params, color='red3', figures1=True, figures2=True, details=True)\n\ndf_cross . to_csv('Group_16.csv', index=False)\n\ndisplay_distances(params)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-09T01:31:42.110323Z","iopub.execute_input":"2025-11-09T01:31:42.110607Z","iopub.status.idle":"2025-11-09T01:32:16.203897Z","shell.execute_reply.started":"2025-11-09T01:31:42.110588Z","shell.execute_reply":"2025-11-09T01:32:16.202996Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### h-blend Grops . [ 13, 14, 15, 16 ]\n\nLB = ?","metadata":{}},{"cell_type":"code","source":"params = {\n      'path'     : f\"/kaggle/working/\",            \n      'id_target': ['id',\"loan_paid_back\"],          \n      'type_sort': ['asc/desc',0.30,0.70 ],\n      'subwts'   : [ -0.02, +0.02,+0.02, -0.02 ],\n      'subm'     : [    \n         { 'name': f'Group_13','weight':+0.13 },    #  [13]  #  green\n         { 'name': f'Group_14','weight':+0.37 },    #  [14]  #  gold\n         { 'name': f'Group_15','weight':+0.13 },    #  [15]  #  blue\n         { 'name': f'Group_16','weight':+0.37 },]   #  [16]  #  crimson\n}\n\ndf_cross = h_blend(params, color='alls', figures1=True, figures2=True, details=True)\n\ndf_cross . to_csv('Groups.csv', index=False)\n\ndisplay_distances(params)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-09T00:52:07.424689Z","iopub.execute_input":"2025-11-09T00:52:07.425012Z","iopub.status.idle":"2025-11-09T00:52:52.863442Z","shell.execute_reply.started":"2025-11-09T00:52:07.424987Z","shell.execute_reply":"2025-11-09T00:52:52.862303Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"if os.path.isdir(new_path): shutil.rmtree(new_path); ","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Submit","metadata":{"papermill":{"duration":0.024828,"end_time":"2025-11-06T07:13:21.248608","exception":false,"start_time":"2025-11-06T07:13:21.22378","status":"completed"},"tags":[]}},{"cell_type":"code","source":"df_cross . to_csv('submission.csv',index=False)\ndf_cross","metadata":{"execution":{"iopub.status.busy":"2025-11-08T23:37:24.283021Z","iopub.execute_input":"2025-11-08T23:37:24.283317Z","iopub.status.idle":"2025-11-08T23:37:24.859473Z","shell.execute_reply.started":"2025-11-08T23:37:24.283297Z","shell.execute_reply":"2025-11-08T23:37:24.858442Z"},"papermill":{"duration":0.568934,"end_time":"2025-11-06T07:13:21.842385","exception":false,"start_time":"2025-11-06T07:13:21.273451","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null}]}