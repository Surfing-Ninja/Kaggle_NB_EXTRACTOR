{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.13"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":91722,"databundleVersionId":14262372,"sourceType":"competition"},{"sourceId":13582034,"sourceType":"datasetVersion","datasetId":8623353},{"sourceId":13617019,"sourceType":"datasetVersion","datasetId":8635402},{"sourceId":13631075,"sourceType":"datasetVersion","datasetId":8652235},{"sourceId":13652933,"sourceType":"datasetVersion","datasetId":8679193},{"sourceId":13672512,"sourceType":"datasetVersion","datasetId":8679843}],"dockerImageVersionId":31192,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false},"papermill":{"default_parameters":{},"duration":709.34758,"end_time":"2025-11-06T07:13:22.892667","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2025-11-06T07:01:33.545087","version":"2.6.0"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"prev. Versions\n\n### PS-s4e11 - [Predicting Loan Payback](https://www.kaggle.com/competitions/playground-series-s5e11/code?competitionId=91722&sortBy=scoreDescending&excludeNonAccessedDatasources=true)\n\nPlayground Series - Season 5, Episode 11\n\n\n| | | &nbsp; | | &nbsp; | &nbsp; | &nbsp; |\n|:-|:-| :-: | :-: | :-: | :-: | :-: |\n| 1. | [0.92_684](https://www.kaggle.com/code/yeoyunsianggeremie/ps5e11-agentic-ai-solution-single-xgb?scriptVersionId=273334165) |&nbsp;v.8&nbsp;| [PS5E11 . Agentic AI Solution](https://www.kaggle.com/code/yeoyunsianggeremie/ps5e11-agentic-ai-solution) | grandmaster | [bogoconic1](https://www.kaggle.com/yeoyunsianggeremie) | Singapore |\n| 2. | [0.92_683](https://www.kaggle.com/code/sagarnagpure1310/s5e11-xgb-lgbm-fe-te-ensemble-92-68?scriptVersionId=273333134) |&nbsp;v.2&nbsp;| [S5E11 . XGB + LGBM . FE, TE & Ensemble . 92.68](https://www.kaggle.com/code/sagarnagpure1310/s5e11-xgb-lgbm-fe-te-ensemble-92-68) | contributor | [Sagar Nagpure](https://www.kaggle.com/sagarnagpure1310) | India |\n| 3. | [0.92_672](https://www.kaggle.com/code/shreyashpatil217/loan-prediction-credit-risk-assessment?scriptVersionId=273425848) |&nbsp;v.1&nbsp;| [ðŸ’° Loan Prediction & Credit Risk Assessment](https://www.kaggle.com/code/shreyashpatil217/loan-prediction-credit-risk-assessment) | expert |[Shreyash Patil](https://www.kaggle.com/shreyashpatil217) | India |\n| 4. | [0.92_664](https://www.kaggle.com/code/jockeroika/loan-payback?scriptVersionId=274058844) |&nbsp;v.1&nbsp;| [Loan Payback](https://www.kaggle.com/code/jockeroika/loan-payback) | grandmaster |[Omar Essa](https://www.kaggle.com/jockeroika) | Egypt |\n| 5. | [0.92_677](https://www.kaggle.com/code/adilshamim8/predicting-loan-payback-101?scriptVersionId=273568426) |&nbsp;v.3&nbsp;| [Predicting Loan Payback 101](https://www.kaggle.com/code/adilshamim8/predicting-loan-payback-101) | expert | [Adil Shamim](https://www.kaggle.com/adilshamim8) | World |\n| 6. | [0.92_655](https://www.kaggle.com/code/karltonkxb/s5e11-loan-xgb-lgbm-cuml-92-64/log?scriptVersionId=273327882) |&nbsp;v.7&nbsp;| [S5E11-Loan-XGB LGBM-CuML-92.64](https://www.kaggle.com/code/karltonkxb/s5e11-loan-xgb-lgbm-cuml-92-64) | expert | [Samidullo](https://www.kaggle.com/karltonkxb) | Poland |\n| 7. | [0.92_657](https://www.kaggle.com/code/yousefelshahat2/simple-lightgbm-only-competition-data-s5e11?scriptVersionId=273815639) |&nbsp;v.6&nbsp;| [Simple LightGBM . Only Competition Data](https://www.kaggle.com/code/yousefelshahat2/simple-lightgbm-only-competition-data-s5e11) | expert | [yousef Elshahat](https://www.kaggle.com/yousefelshahat2) | World |\n| 8. | [0.92_643](https://www.kaggle.com/code/sidakou/optimized-weighted-ensemble-of-xgb-lgb-cat-hgb?scriptVersionId=273000295) |&nbsp;v.1&nbsp;| [Opt. Weighted Ensemble of XGB, LGB, CAT & HGB](https://www.kaggle.com/code/sidakou/optimized-weighted-ensemble-of-xgb-lgb-cat-hgb) | contributor | [å®‰å°¾ æ™ƒè²´](https://www.kaggle.com/sidakou) | Japan |\n| 9. | [0.92_712](https://www.kaggle.com/code/masayakawamata/s5e11-single-xgb-add-features?scriptVersionId=274389899) |&nbsp;v.3&nbsp;| [S5E11 . Single XGB - Add Features](https://www.kaggle.com/code/masayakawamata/s5e11-single-xgb-add-features) | expert | [Masaya Kawamata](https://www.kaggle.com/masayakawamata) | Japan |\n| 10. | [0.92_603](https://www.kaggle.com/code/masayakawamata/s5e11-cat-interaction-features?scriptVersionId=273552378) |&nbsp;v.1&nbsp;| [S5E11 . Cat - Interaction Features](https://www.kaggle.com/code/masayakawamata/s5e11-cat-interaction-features) | expert | [Masaya Kawamata](https://www.kaggle.com/masayakawamata) | Japan |\n| 11. | [0.92_601](https://www.kaggle.com/code/pradiptadatta/org-pss5e11-flaml-roc-auc?scriptVersionId=272623191) |&nbsp;v.1&nbsp;| [Org+PSS5E11 : FLAML : roc_auc](https://www.kaggle.com/code/pradiptadatta/org-pss5e11-flaml-roc-auc) | expert | [Pradipta Datta](https://www.kaggle.com/pradiptadatta) | India |\n| 12. | [0.92_353](https://www.kaggle.com/code/yeoyunsianggeremie/ps5e11-pytorch-nn-baseline-ft-transformer?scriptVersionId=274007166) |&nbsp;v.4&nbsp;| [PS5E11 . PyTorch NN Baseline [FT-Transformer]](https://www.kaggle.com/code/yeoyunsianggeremie/ps5e11-pytorch-nn-baseline-ft-transformer) | grandmaster | [bogoconic1](https://www.kaggle.com/yeoyunsianggeremie) | Singapore |\n| [ 13](https://www.kaggle.com/code/nina2025/ps-s5e11-straight-blend/notebook?scriptVersionId=274386273). |[&nbsp;](https://)<br>[0.92_698](https://www.kaggle.com/code/nina2025/ps-s5e11-straight-blend?scriptVersionId=274386273)<br>[&nbsp;](https://)|&nbsp;v.1&nbsp;<br>&nbsp;v.1&nbsp;<br>&nbsp;v.1&nbsp;| [Loan Payback . Ensemble](https://www.kaggle.com/code/mikhailnaumov/loan-payback-ensemble/output)<br>&nbsp;[PlaygroundS5E11 - Autogluon](https://www.kaggle.com/code/dalloliogm/playgrounds5e11-autogluon/notebook)&nbsp;<br>[PS-S5E11: XGBoost Stability Model](https://www.kaggle.com/code/canozensoy/ps-s5e11-xgboost-stability-model/notebook) | master<br>expert<br>master | [Mikhail Naumov](https://www.kaggle.com/mikhailnaumov)<br>[Giovanni Marco Dall'Olio](https://www.kaggle.com/dalloliogm)<br>[Can Ã–zensoy](https://www.kaggle.com/canozensoy) | World <br> England <br> TÃ¼rkiye |\n| 14. | [0.92_732](https://www.kaggle.com/code/nina2025/ps-s5e11-straight-blend?scriptVersionId=274390431) |&nbsp;v.3&nbsp;| [[ 1, 2, 3, 11 ](https://www.kaggle.com/code/nina2025/ps-s5e11-straight-blend)] | master | [community](https://www.kaggle.com/) | International |\n| 15. | [0.92_694](https://www.kaggle.com/code/nina2025/ps-s5e11-straight-blend/notebook?scriptVersionId=274399423) |&nbsp;v.4&nbsp;| [[ 4, 5, 6, 7 ](https://www.kaggle.com/code/nina2025/ps-s5e11-straight-blend)] | master | [community](https://www.kaggle.com/) | International |\n| 16. | [0.92_661](https://www.kaggle.com/code/nina2025/ps-s5e11-straight-blend/notebook?scriptVersionId=274403386) |&nbsp;v.5&nbsp;| [[ 8, 9, 10, 12 ](https://www.kaggle.com/code/nina2025/ps-s5e11-straight-blend)] | master | [community](https://www.kaggle.com/) | International |\n| 17. | [0.92_711](https://www.kaggle.com/code/sagarnagpure1310/s5e11-enhanced-xgb-cat-lb-0-92715/notebook?scriptVersionId=274485714) |&nbsp;v.14&nbsp;| [ S5E11 . Enhanced XGB + CAT ](https://www.kaggle.com/code/sagarnagpure1310/s5e11-enhanced-xgb-cat-lb-0-92715) | contributor | [Sagar Nagpure](https://www.kaggle.com/sagarnagpure1310) | India |\n| 18. | [0.92_715](https://www.kaggle.com/code/sagarnagpure1310/s5e11-enhanced-xgb-cat-lb-0-92715?scriptVersionId=274471354) |&nbsp;v.12&nbsp;| [ S5E11 . Enhanced XGB + CAT ](https://www.kaggle.com/code/sagarnagpure1310/s5e11-enhanced-xgb-cat-lb-0-92715/notebook) | contributor | [Sagar Nagpure](https://www.kaggle.com/sagarnagpure1310) | India |\n| 19. | [0.92_740](https://www.kaggle.com/code/nina2025/ps-s5e11-experiment) |&nbsp;v.8&nbsp;| [ PS-s5e11 . experiment ](https://www.kaggle.com/code/nina2025/ps-s5e11-experiment) | master | [Ninel Bolotta](https://www.kaggle.com/code/nina2025) | Georgia |\n| 20. | [0.92_722](https://www.kaggle.com/code/momerer/s5e11-lgbm-xgb-cat-0-92722/notebook?scriptVersionId=274790579) |&nbsp;v.4&nbsp;| [ S5E11 . LGBM - XGB - CAT ](https://www.kaggle.com/code/momerer/s5e11-lgbm-xgb-cat-0-92722) | contributor | [Muhammed Ã–mer ERKOÃ‡](https://www.kaggle.com/momerer) | TÃ¼rkiye |\n| 21. | [0.92_720](https://www.kaggle.com/code/sagarnagpure1310/s5e11-3-models-pl-ensemble-lb-0-92722?scriptVersionId=274719007) |&nbsp;v.21&nbsp;| [S5E11 . 3 Models + PL Ensemble](https://www.kaggle.com/code/sagarnagpure1310/s5e11-3-models-pl-ensemble-lb-0-92720/notebook) | contributor | [Sagar Nagpure](https://www.kaggle.com/sagarnagpure1310) | India |\n| 22. | [0.92_756](https://www.kaggle.com/code/mikhailnaumov/loan-payback-xgb-lgbm-hgb?scriptVersionId=274901553) |&nbsp;v.2&nbsp;| [Loan Payback . XGB+LGBM+HGB](https://www.kaggle.com/code/mikhailnaumov/loan-payback-xgb-lgbm-hgb) | master | [Mikhail Naumov](https://www.kaggle.com/mikhailnaumov) | World |\n|||||||\n|||| main weights % | asc/desc % | correct weights % |\n|||||||\n|  | [0.92_753](https://) | v.1 | [[1,2,3,11](#h-blend)]+[[4,5,6,7](#h-blend)]+[[9,17,18](#h-blend)]+[ [13](https://www.kaggle.com/code/nina2025/ps-s5e11-straight-blend/notebook?scriptVersionId=274386273) ] &nbsp;**+**&nbsp; [[ 19 ](https://www.kaggle.com/code/nina2025/ps-s5e11-experiment)] |[70](#cross_Groups)%&nbsp;**+**&nbsp;[30](#cross_Groups)%| [cwts](#cross_Groups) |\n|  | [0.92_752](https://www.kaggle.com/code/nina2025/ps-s5e11-cage?scriptVersionId=274778955) | v.2 | [[1,2,3,11](#h-blend)]+[[4,5,6,7](#h-blend)]+[[9,17,18](#h-blend)]+[ [13](https://www.kaggle.com/code/nina2025/ps-s5e11-straight-blend/notebook?scriptVersionId=274386273) ] &nbsp;**+**&nbsp; [[ 19 ](https://www.kaggle.com/code/nina2025/ps-s5e11-experiment)] |[60](#cross_Groups)%&nbsp;**+**&nbsp;[40](#cross_Groups1)%| [cwts](#cross_Groups) |\n|  | [0.92_753](https://www.kaggle.com/code/nina2025/ps-s5e11-cage?scriptVersionId=274781652) | v.3 | [[1,2,3,11](#h-blend)]+[[4,5,6,7](#h-blend)]+[[9,17,18](#h-blend)]+[ [13](https://www.kaggle.com/code/nina2025/ps-s5e11-straight-blend/notebook?scriptVersionId=274386273) ] &nbsp;**+**&nbsp; [[ 19 ](https://www.kaggle.com/code/nina2025/ps-s5e11-experiment)] |[85](#cross_Groups)%&nbsp;**+**&nbsp;[15](#cross_Groups1)%| [cwts](#cross_Groups) |\n|||||||\n|  | [0.92_754](https://www.kaggle.com/code/nina2025/ps-s5e11-cage?scriptVersionId=274792079) | v.5 | [[ 1,2,3,11 ](#h-blend)]+[[ 9,17,18 ](#h-blend)]+[ [ 19 ](https://www.kaggle.com/code/nina2025/ps-s5e11-experiment) ] |[30](#cross_Groups)% + [70](#cross_Groups1)%| [cwts](#cross_Groups) |\n|  | [0.92_754](https://www.kaggle.com/code/nina2025/ps-s5e11-cage?scriptVersionId=274805760) | v.7 | **[** [[ 1,2,3,11 ](#h-blend)]+[[4,5,6,7](#h-blend)]+[[ 9,17,18 ](#h-blend)]+[ [13](https://www.kaggle.com/code/nina2025/ps-s5e11-straight-blend/notebook?scriptVersionId=274386273) ]+[ [ 19 ](https://www.kaggle.com/code/nina2025/ps-s5e11-experiment) ] **]** |[30](#cross_Groups)% + [70](#cross_Groups1)%| [cwts](#cross_Groups) |\n|||||||\n|  | [0.92_755](https://www.kaggle.com/code/nina2025/ps-s5e11-cage?scriptVersionId=274837185) | [v.8](#version.8) | **[** [[ 1,21,3,11 ](#h-blend)]+[[4,5,6,7,20](#h-blend)]+[[ 9,17,18 ](#h-blend)]+[ [13](https://www.kaggle.com/code/nina2025/ps-s5e11-straight-blend/notebook?scriptVersionId=274386273) ]+[ [ 19 ](https://www.kaggle.com/code/nina2025/ps-s5e11-experiment) ] **]** |[30](#cross_Groups)% + [70](#cross_Groups1)%| [cwts](#cross_Groups) |\n|  | [0.92_755](https://www.kaggle.com/code/momerer/s5e11-lgbm-xgb-cat-0-92722) | [v.9](#version.9) | **[** [[ 1,21,3,11 ](#h-blend)]+[[4,5,6,7,20](#h-blend)]+[[ 9,17,18 ](#h-blend)]+[ [13](https://www.kaggle.com/code/nina2025/ps-s5e11-straight-blend/notebook?scriptVersionId=274386273) ]+[ [ 19 ](https://www.kaggle.com/code/nina2025/ps-s5e11-experiment) ] **]** |[30](#cross_Groups)% + [70](#cross_Groups1)%| [cwts](#cross_Groups) |","metadata":{"jupyter":{"source_hidden":true},"_kg_hide-input":true,"_kg_hide-output":true}},{"cell_type":"markdown","source":"### PS-s4e11 - [Predicting Loan Payback](https://www.kaggle.com/competitions/playground-series-s5e11/code?competitionId=91722&sortBy=scoreDescending&excludeNonAccessedDatasources=true)\n\nPlayground Series - Season 5, Episode 11\n\n\n| | | &nbsp; | | &nbsp; | &nbsp; | &nbsp; |\n|:-|:-| :-: | :-: | :-: | :-: | :-: |\n| 1. | [0.92_684](https://www.kaggle.com/code/yeoyunsianggeremie/ps5e11-agentic-ai-solution-single-xgb?scriptVersionId=273334165) |&nbsp;v.8&nbsp;| [PS5E11 . Agentic AI Solution](https://www.kaggle.com/code/yeoyunsianggeremie/ps5e11-agentic-ai-solution) | grandmaster | [bogoconic1](https://www.kaggle.com/yeoyunsianggeremie) | Singapore |\n| 3. | [0.92_672](https://www.kaggle.com/code/shreyashpatil217/loan-prediction-credit-risk-assessment?scriptVersionId=273425848) |&nbsp;v.1&nbsp;| [ðŸ’° Loan Prediction & Credit Risk Assessment](https://www.kaggle.com/code/shreyashpatil217/loan-prediction-credit-risk-assessment) | expert |[Shreyash Patil](https://www.kaggle.com/shreyashpatil217) | India |\n| 5. | [0.92_677](https://www.kaggle.com/code/adilshamim8/predicting-loan-payback-101?scriptVersionId=273568426) |&nbsp;v.3&nbsp;| [Predicting Loan Payback 101](https://www.kaggle.com/code/adilshamim8/predicting-loan-payback-101) | expert | [Adil Shamim](https://www.kaggle.com/adilshamim8) | World |\n| 4. | [0.92_664](https://www.kaggle.com/code/jockeroika/loan-payback?scriptVersionId=274058844) |&nbsp;v.1&nbsp;| [Loan Payback](https://www.kaggle.com/code/jockeroika/loan-payback) | grandmaster |[Omar Essa](https://www.kaggle.com/jockeroika) | Egypt |\n| 7. | [0.92_657](https://www.kaggle.com/code/yousefelshahat2/simple-lightgbm-only-competition-data-s5e11?scriptVersionId=273815639) |&nbsp;v.6&nbsp;| [Simple LightGBM . Only Competition Data](https://www.kaggle.com/code/yousefelshahat2/simple-lightgbm-only-competition-data-s5e11) | expert | [yousef Elshahat](https://www.kaggle.com/yousefelshahat2) | World |\n| 9. | [0.92_712](https://www.kaggle.com/code/masayakawamata/s5e11-single-xgb-add-features?scriptVersionId=274389899) |&nbsp;v.3&nbsp;| [S5E11 . Single XGB - Add Features](https://www.kaggle.com/code/masayakawamata/s5e11-single-xgb-add-features) | expert | [Masaya Kawamata](https://www.kaggle.com/masayakawamata) | Japan |\n| 11. | [0.92_601](https://www.kaggle.com/code/pradiptadatta/org-pss5e11-flaml-roc-auc?scriptVersionId=272623191) |&nbsp;v.1&nbsp;| [Org+PSS5E11 : FLAML : roc_auc](https://www.kaggle.com/code/pradiptadatta/org-pss5e11-flaml-roc-auc) | expert | [Pradipta Datta](https://www.kaggle.com/pradiptadatta) | India |\n| 18. | [0.92_715](https://www.kaggle.com/code/sagarnagpure1310/s5e11-enhanced-xgb-cat-lb-0-92715?scriptVersionId=274471354) |&nbsp;v.12&nbsp;| [ S5E11 . Enhanced XGB + CAT ](https://www.kaggle.com/code/sagarnagpure1310/s5e11-enhanced-xgb-cat-lb-0-92715/notebook) | contributor | [Sagar Nagpure](https://www.kaggle.com/sagarnagpure1310) | India |\n| 19. | [0.92_740](https://www.kaggle.com/code/nina2025/ps-s5e11-experiment) |&nbsp;v.8&nbsp;| [ PS-s5e11 . experiment ](https://www.kaggle.com/code/nina2025/ps-s5e11-experiment) | master | [Ninel Bolotta](https://www.kaggle.com/code/nina2025) | Georgia |\n| 20. | [0.92_722](https://www.kaggle.com/code/momerer/s5e11-lgbm-xgb-cat-0-92722/notebook?scriptVersionId=274790579) |&nbsp;v.4&nbsp;| [ S5E11 . LGBM - XGB - CAT ](https://www.kaggle.com/code/momerer/s5e11-lgbm-xgb-cat-0-92722) | contributor | [Muhammed Ã–mer ERKOÃ‡](https://www.kaggle.com/momerer) | TÃ¼rkiye |\n| 21. | [0.92_720](https://www.kaggle.com/code/sagarnagpure1310/s5e11-3-models-pl-ensemble-lb-0-92722?scriptVersionId=274719007) |&nbsp;v.21&nbsp;| [S5E11 . 3 Models + PL Ensemble](https://www.kaggle.com/code/sagarnagpure1310/s5e11-3-models-pl-ensemble-lb-0-92720/notebook) | contributor | [Sagar Nagpure](https://www.kaggle.com/sagarnagpure1310) | India |\n| 22. | [0.92_756](https://www.kaggle.com/code/mikhailnaumov/loan-payback-xgb-lgbm-hgb?scriptVersionId=274901553) |&nbsp;v.2&nbsp;| [Loan Payback . XGB+LGBM+HGB](https://www.kaggle.com/code/mikhailnaumov/loan-payback-xgb-lgbm-hgb) | master | [Mikhail Naumov](https://www.kaggle.com/mikhailnaumov) | World |\n|||||||\n|||| main weights % | asc/desc % | correct weights % |\n|  | [0.92757](https://www.kaggle.com/code/momerer/s5e11-lgbm-xgb-cat-0-92722) | [v.1](#version.1) | [ [ 1,3,7,21 ](#Group.2)] + [[ 5,4,11,19 ](#Group.3)] + [[ 9,18,20,22 ](#Group.1)]|[30](#cross_Groups)% + [70](#cross_Groups1)%| [cwts1](#cross_Groups) |\n|  | [?](https://www.kaggle.com/code/momerer/s5e11-lgbm-xgb-cat-0-92722) | [v.2](#version.1) | [ [ 1,3,7,21 ](#Group.2)] + [[ 5,4,11,19 ](#Group.3)] + [[ 9,18,20,22 ](#Group.1)]|[30](#cross_Groups)% + [70](#cross_Groups1)%| [cwts2](#cross_Groups) |","metadata":{}},{"cell_type":"code","source":"import os,ast\nimport numpy as np\nimport pandas as pd\n\nimport shutil,copy\n\nfrom bokeh.plotting import figure, gridplot \nfrom bokeh.io import output_file, show, output_notebook\noutput_notebook()\n\n\ndef bokeh_show(\n        params,\n        df_cross,\n        show_figures1, \n        show_figures2, wps_fig2,\n        color_cross):\n\n    colors = [subm['color'] for subm in params['subm']]\n    \n    def dossier(js,subms,cols):\n        def quant(i,js,subms,cols):\n            return {\"c\" : i, \"q\" : sum([1 for subm in cols[i] if subm == subms[js]])}\n        return {\n            'name' : subms[js],\n            'q_in' : [quant(i,js,subms,cols) for i in range(len(subms))]\n        }\n    alls = pd.read_csv(f'tida_desc.csv')\n    matrix = [ast.literal_eval(str(row.alls)) for row in alls.itertuples()]\n    subms = sorted(matrix[0])\n    cols = [[data[i] for data in matrix] for i in range(len(subms))]\n    df_subms = pd.DataFrame({f'col_{i}': [x[i] for x in matrix] for i in range(len(subms))})\n    dossiers = [dossier(js,subms,cols) for js in range(len(subms))]\n    subm_names = [one_dossier['name'] for one_dossier in dossiers]\n    figures1,qss,i = [],[],0\n    height = 85 if len(colors)==2\\\n        else 134 if len(colors)==3 else (154 if len(colors)==4 else 174)\n    for one_dossier in dossiers: \n        i_col = 'alls. ' + str(one_dossier['q_in'][i]['c'])\n        qs = [one['q'] for one in one_dossier['q_in']]\n        x_names = [name.replace(\"Group\",\"\").replace(\"subm_\",\"\") for name in subm_names]\n        width = 157  if len(colors) == 5\\\n            else (121 if len(colors) == 8\\\n            else (131 if len(colors) == 9\\\n            else (141 if len(colors) == 10\\\n            else (171 if len(colors) == 11 else 133))))\n        f = figure(x_range=x_names,width=width, height=height, title=i_col)\n        f.vbar(x=x_names, width=0.585, top=qs, color=colors)\n        figures1.append(f)\n        qss.append(qs)\n        i+=1\n    grid = gridplot([figures1])\n    output_file('tida_alls.html')\n    if show_figures1 == True: show(grid)\n    sub_wts = params['subwts']\n    main_wts = [subm['weight'] for subm in params['subm']]\n    mms,acc_mass = [],[]\n    for j in range(len(dossiers)):\n        one_dossier = dossiers[j]\n        qs = [one['q'] for one in one_dossier['q_in']]\n        mm = [qs[h] * (main_wts[j] + sub_wts[h]) for h in range(len(sub_wts))]\n        mass = sum(mm)\n        mms.append(mm)\n        acc_mass.append(round(mass))                        #subm_names[::-1]\n    y_names = [name + \" - \" + str(mass) for name,mass in zip(subm_names,acc_mass)]\n    f1 = figure(y_range=y_names, width=313, height=height, title='relations of general masses')\n    f1.hbar(y=y_names, height=0.585, right=acc_mass, left=0, color=colors)\n    output_file('tida_alls2.html')\n    alls = [f'alls.{i}' for i in range(len(dossiers))]\n    subm = [f'sub{i}'   for i in range(len(dossiers))] \n    mmsT  = np.asarray(mms).T\n    data = {'cols' : alls}\n    for i in range(len(dossiers)): data[f'sub{i}'] = mmsT[i,:]\n    f2 = figure(y_range=alls, height=height, width=274, title=\" ( relations of columns masses )\")\n    f2.hbar_stack(subm, y='cols', height=0.585, color=colors, source=data)\n    qssT  = np.asarray(qss).T\n    data = {'cols' : alls}\n    for i in range(len(dossiers)): data[f'sub{i}'] = qssT[i,:]\n    f3 = figure(y_range=alls, height=height, width=210, title=\"ratios in columns\")\n    f3.hbar_stack(subm, y='cols', height=0.585, color=colors, source=data)\n    grid = gridplot([[f3,f2,f1]])\n    show(grid)\n    if show_figures2 == True:\n        def read(params,i):\n            FiN = params[\"path\"] + params[\"subm\"][i][\"name\"] + \".csv\"\n            target_name_back = {'target':params[\"target\"],'pred':params[\"target\"]}\n            return pd.read_csv(FiN).rename(columns=target_name_back)\n        dfs = [read(params,i) for i in range(len(params[\"subm\"]))] + [df_cross]\n        f   = figure(width=785, height=254)\n        f.title.text = 'Click on legend entries to mute the corresponding lines'\n        b,e        = 21000,21121\n        line_x     = [dfs[i][b:e]['id']            for i in range(len(dfs))]\n        line_y     = [dfs[i][b:e]['loan_paid_back'] for i in range(len(dfs))]\n        color      = colors + [color_cross]\n        alpha      = [0.8 for i in range(len(dfs)-1)] + [0.95]\n        lws        = [1.0 for i in range(len(dfs)-1)] + [1.00]\n        legend = subm_names + ['cross']\n        for i in range(len(legend)):\n            f.line(line_x[i], line_y[i], line_width=lws[i], color=color[i], alpha=alpha[i],\n                   muted_color='white',legend_label=legend[i])\n        f.legend.location = \"top_left\"\n        f.legend.click_policy=\"mute\"\n        show(f)\n\n\ndef h_blend(params,cross='silver',\n            figures1=False,figures2=False,wf2=555,\n            details=False):\n\n    color_cross = cross\n\n    dk = copy.deepcopy(params)\n\n    show_details,show_figures1,show_figures2 = details,figures1,figures2\n\n    file_short_names = [subm['name'] for subm in params['subm']]\n    type_sort    = params['type_sort'][0]\n    dk['asc']    = params['type_sort'][1]\n    dk['desc']   = params['type_sort'][2]\n    dk['id']     = params['id_target'][0]\n    dk['target'] = params['id_target'][1]\n# ------------------------------------------------------------------------\n    def read(dk,i):\n        tnm = dk[\"subm\"][i][\"name\"]\n        FiN = dk[\"path\"] + tnm + \".csv\"\n        return pd.read_csv(FiN).rename(columns={\n            'target':tnm, 'pred':tnm, dk[\"target\"]:tnm})\n        \n    def merge(dfs_subm):\n        df_subms = pd.merge(dfs_subm[0],  dfs_subm[1], on=[dk['id']])\n        for i in range(2, len(dk[\"subm\"])): \n            df_subms = pd.merge(df_subms, dfs_subm[i], on=[dk['id']])\n        return df_subms\n        \n    def da(dk,sorting_direction,show_details):\n        \n        df_subms = merge([read(dk,i) for i in range(len(dk[\"subm\"]))])\n        cols = [col for col in df_subms.columns if col != dk['id']]\n        short_name_cols = [c for c in cols]\n        \n        def alls1(x, sd=sorting_direction,cs=cols):\n            reverse = True if sd=='desc' else False\n            tes = {c: x[c] for c in cs}.items()\n            subms_sorted = [t[0] for t in sorted(tes,key=lambda k:k[1],reverse=reverse)]\n            return subms_sorted\n\n        import random\n\n        def alls2(x, sd=sorting_direction,cs=cols):\n            reverse = True if sd=='desc' else False\n            tes = {c: x[c] for c in cs}.items()\n            subms_random = [t[0] for t in tes]\n            random.shuffle(subms_random)\n            return subms_random\n\n        alls = alls1 if type_sort == 'asc/desc' else alls2\n            \n        def summa(x,cs,wts,ic_alls): \n            return sum([x[cs[j]] * (wts[0][j] + wts[1][ic_alls[j]]) for j in range(len(cs))])\n            \n        wts = [[[e['weight'] for e in dk[\"subm\"]], [w for w in dk[\"subwts\" ]]]]\n          \n        def correct(x, cs=cols, wts=wts):\n            i = [x['alls'].index(c) for c in short_name_cols]\n            return summa(x,cs,wts[0],i)\n\n        if len(wts) == 1:\n            correct_sub_weights = [wt for wt in dk[\"subwts\"]]\n            weights = [subm['weight'] for subm in dk[\"subm\"]]\n            def correct(x, cs=cols, w=weights, cw=correct_sub_weights):\n                ic = [x['alls'].index(c) for c in short_name_cols]\n                cS = [x[cols[j]] * (w[j] + cw[ic[j]]) for j in range(len(cols))]\n                return sum(cS)\n                   \n        def amxm(x, cs=cols):\n            list_values = x[cs].to_list()\n            mxm = abs(max(list_values)-min(list_values))\n            return mxm\n\n        if len(wts) > 1:\n            df_subms['mx-m']   = df_subms.apply(lambda x: amxm   (x), axis=1)\n        df_subms['alls']       = df_subms.apply(lambda x: alls   (x), axis=1)\n        df_subms[dk[\"target\"]] = df_subms.apply(lambda x: correct(x), axis=1)\n        schema_rename = { old_nc:new_shnc for old_nc, new_shnc in zip(cols, short_name_cols) }\n        df_subms = df_subms.rename(columns=schema_rename)\n        df_subms = df_subms.rename(columns={dk[\"target\"]:\"ensemble\"})\n        df_subms.insert(loc=1, column=' _ ', value=['   '] * len(df_subms))\n        df_subms[' _ '] = df_subms[' _ '].astype(str)\n        pd.set_option('display.max_rows',100)\n        pd.set_option('display.float_format', '{:.5f}'.format)\n        vcols = [dk['id']]+[' _ '] + short_name_cols + [' _ ']+['alls']+[' _ ']+['ensemble']\n        if len(wts) > 1: vcols.append([' _ '] + ['mx-m'])\n        df_subms = df_subms[vcols]\n        if show_details and sorting_direction=='desc': display(df_subms.head(5))\n        pd.set_option('display.float_format', '{:.5f}'.format)\n        df_subms = df_subms.rename(columns={\"ensemble\":dk[\"target\"]})\n        df_subms.to_csv(f'tida_{sorting_direction}.csv', index=False)\n        return df_subms[[dk['id'],dk['target']]]\n   \n    def ensemble_da(dk,        show_details): \n        dfD    = da(dk,'desc', show_details)\n        dfA    = da(dk,'asc',  show_details)\n        dfA[dk['target']] = dk['desc']*dfD[dk['target']] + dfA[dk['target']]*dk['asc']\n        return dfA\n\n    da = ensemble_da(dk,show_details)\n    \n    bokeh_show(dk, da, show_figures1, show_figures2, wf2, color_cross)\n    \n    return  da\n\n\ndef matrix_vs(path,fs_names):\n    def load(path,fs_names):\n        dfs = [pd.read_csv(path + name_subm +'.csv') for name_subm in fs_names]\n        for i in range(len(dfs)):\n            dfs[i] = dfs[i].rename(columns={\"loan_paid_back\": f'{fs_names[i]}'})\n        dfsm = pd.merge(dfs[0], dfs[1], on=\"id\")\n        for i in range(2,len(dfs)):\n            dfsm = pd.merge(dfsm,dfs[i],on='id')\n        return dfsm   \n    def make_list_vs(fs_names):\n        list = []\n        for i in range(0,len(fs_names)-1):\n            for j in range(i+1,len(fs_names)):\n                list.append(fs_names[i] + \"_vs_\" + fs_names[j])\n        return list\n    def get_mvs(dfs, list_vs):\n        def get_abs_distance(x,t1,t2):\n            return abs(x[t1]-x[t2])\n        for vs in list_vs:\n            t = vs.split('_vs_')\n            dfs[vs] = dfs.apply(lambda x: get_abs_distance(x,t[0],t[1]), axis=1)\n        return dfs   \n    def distance_vs(name, st_names, list_vs, dfs):\n        distances = []\n        for st in st_names:\n            vs_between = name + \"_vs_\" + st\n            if vs_between not in list_vs:\n                distances.append(0)\n            else: distances.append(round(dfs[vs_between].sum()))\n        return distances\n    dfs = load(path,fs_names)\n    list_vs = make_list_vs(fs_names)\n    mvs = get_mvs(dfs, list_vs)\n    m1 = pd.DataFrame({'subm':fs_names})\n    m2 = pd.DataFrame({ name :distance_vs(name, fs_names, list_vs, mvs) for name in fs_names})\n    matrix = pd.concat([m1,m2],axis=1)\n    return matrix\n\n\ndef procedure_Cage(FiN_import,n_iter=4,ks1=[1.0054,0.0021],ks2=[1.00037,0.00037]):\n    import seaborn as sns\n    import matplotlib.pyplot as plt\n    import warnings; warnings.filterwarnings('ignore')\n    \n    sub_sample = pd.read_csv('../input/playground-series-s5e11/sample_submission.csv') \n    sub_import = pd.read_csv(FiN_import) \n    per = sub_import['loan_paid_back'].values\n    # ..................................................................................................\n    sns.set()\n    plt.figure(figsize=(5, 2))\n    plt.hist(per, bins=80)\n    plt.gca().set_facecolor('mintcream')\n    plt.suptitle('Before | loan_paid_back', y=0.96, fontsize=12, c='navy')\n    # ..................................................................................................\n    print('- - - - - - - ',FiN_import)\n    min_per  = np.min(per);  print('Min:',  round(min_per, 7))\n    max_per  = np.max(per);  print('Max:',  round(max_per, 7))\n    mean_per = np.mean(per); print('Mean:', round(mean_per,7))\n    print('-------')\n    R = -0.0\n    guide = mean_per - R\n    # ....................................\n    per1 = [f for f in per if f < guide]\n    per2 = [f for f in per if f > guide]\n    print(len(per1),'-',len(per2))\n    print('-------')\n    N = n_iter\n    for _ in range(N):\n        for i in range(len(per)):\n            per_guide = (per[i] + guide) / 2            \n            if per[i] <= guide:\n                per[i] = (per[i] *ks1[0]) - (per_guide *ks1[1])\n            else:\n                per[i] = (per[i] *ks2[0]) - (per_guide *ks2[1])\n    # .......................................................................\n    sns.set()\n    plt.figure(figsize=(5, 2))\n    plt.hist(per, bins=80)\n    plt.gca().set_facecolor('snow')\n    plt.suptitle('After | loan_paid_back', y=0.96, fontsize=11, c='navy')\n    # .......................................................................\n    min_per  = np.min(per);  print('Min:',  round(min_per, 7))\n    max_per  = np.max(per);  print('Max:',  round(max_per, 7))\n    mean_per = np.mean(per); print('Mean:', round(mean_per,7)); \n    # .......................................................................\n    print('- - - - - - - ', 'Cage '+FiN_import, '\\n')\n    # .......................................................................\n    sub_sample['loan_paid_back'] = per\n    return sub_sample \n    # df = direct_blend('Groups.csv','Group_19.csv',wts=[0.85,0.15])\n    # df_Cage = procedure_Cage('Groups.csv',n_iter=4,ks1=[1.002,0.001],ks2=[1.002,0.001])\n    # display ( df_Cage )\n    # .......................................................................\n\n\ndef display_distances(params):\n    files = [subm['name'] for subm in params['subm']]\n    distances = matrix_vs ( params['path'], files )            \n    display(distances)\n\n\ndef redirrect(full_FiN, short_FiN):\n    df = pd.read_csv(full_FiN)\n    df.to_csv(short_FiN, index=False)\n\n\ndef straight_blend(df1,df2,wts=[0.50,0.50],subm=''):\n    t = 'loan_paid_back'\n    df1[t] = df1[t]*wts[0] + df2[t]*wts[1]\n    if subm != \"\":\n        df1.to_csv(subm, index=False)\n        print(f'{subm} - ready to use')\n    return df1\n    \n\ndef direct_blend(subm_file_1, subm_file_2, wts=[0.50,0.50]):\n    df1 = pd.read_csv(subm_file_1)\n    df2 = pd.read_csv(subm_file_2)\n    return straight_blend(df1,df2,wts=wts)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2025-11-10T02:06:42.844516Z","iopub.execute_input":"2025-11-10T02:06:42.844877Z","iopub.status.idle":"2025-11-10T02:06:43.784575Z","shell.execute_reply.started":"2025-11-10T02:06:42.844849Z","shell.execute_reply":"2025-11-10T02:06:43.783672Z"},"papermill":{"duration":3.695998,"end_time":"2025-11-06T07:01:42.816779","exception":false,"start_time":"2025-11-06T07:01:39.120781","status":"completed"},"tags":[],"trusted":true,"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# redirrect\n\nwrk_path = '/kaggle/working/'\nnew_path = '/kaggle/working/public'\nds_path4 = '/kaggle/input/4-november-2025-ps-s5e11'\nds_path8 = '/kaggle/input/8-november-2025-ps-s5e11'\nds_path9 = '/kaggle/input/9-november-2025-ps-s5e11'\nds_path3 = '/kaggle/input/03-november-2025-ps-s5e11'\n\nif os.path.isdir(new_path): shutil.rmtree(new_path); \n    \nos.mkdir(new_path)\n\nshutil.copy(ds_path3 +'/submission 0.92601.csv', new_path +'/0.92601.csv')\nshutil.copy(ds_path8 +'/submission 0.92657.csv', new_path +'/0.92657.csv')\nshutil.copy(ds_path8 +'/submission 0.92664.csv', new_path +'/0.92664.csv')\nshutil.copy(ds_path3 +'/submission 0.92672.csv', new_path +'/0.92672.csv')\nshutil.copy(ds_path4 +'/submission 0.92677.csv', new_path +'/0.92677.csv')\nshutil.copy(ds_path3 +'/submission 0.92683.csv', new_path +'/0.92683.csv')\nshutil.copy(ds_path3 +'/submission 0.92684.csv', new_path +'/0.92684.csv')\nshutil.copy(ds_path9 +'/submission 0.92712.csv', new_path +'/0.92712.csv')\nshutil.copy(ds_path9 +'/submission 0.92715.csv', new_path +'/0.92715.csv')\nshutil.copy(ds_path9 +'/submission 0.92720.csv', new_path +'/0.92720.csv')\nshutil.copy(ds_path9 +'/submission 0.92722.csv', new_path +'/0.92722.csv')\nshutil.copy(ds_path9 +'/submission 0.92740.csv', new_path +'/0.92740.csv')\nshutil.copy(ds_path9 +'/submission 0.92756.csv', new_path +'/0.92756.csv')","metadata":{"trusted":true,"_kg_hide-input":true,"_kg_hide-output":true,"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2025-11-10T02:06:49.02087Z","iopub.execute_input":"2025-11-10T02:06:49.021361Z","iopub.status.idle":"2025-11-10T02:06:50.008558Z","shell.execute_reply.started":"2025-11-10T02:06:49.021332Z","shell.execute_reply":"2025-11-10T02:06:50.007631Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Group.1","metadata":{}},{"cell_type":"code","source":"params = {\n      'path'     : new_path + '/',            \n      'id_target': ['id',\"loan_paid_back\"],          \n      'type_sort': ['asc/desc',0.30,0.70 ],\n      'subwts'   : [ -0.03,+0.03,-0.03,+0.03 ],\n      'subm'     : [    \n         { 'name': f'0.92712','weight':+0.07,'color':\"crimson\" },  #   [9] \n         { 'name': f'0.92715','weight':+0.08,'color':\"gray\" },     #  [18]\n         { 'name': f'0.92722','weight':+0.15,'color':\"darkgray\" }, #  [20] \n         { 'name': f'0.92756','weight':+0.70,'color':\"silver\" },   #  [22]    \n      ]  \n}\n\ndf_cross = h_blend(params, figures1=True, figures2=True, details=True)\ndf_cross . to_csv('Gr1.csv', index=False)\ndisplay_distances(params)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-10T02:06:54.682879Z","iopub.execute_input":"2025-11-10T02:06:54.683223Z","iopub.status.idle":"2025-11-10T02:07:37.482212Z","shell.execute_reply.started":"2025-11-10T02:06:54.68319Z","shell.execute_reply":"2025-11-10T02:07:37.481267Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Group.2","metadata":{}},{"cell_type":"code","source":"params = {\n      'path'     : new_path + '/',            \n      'id_target': ['id',\"loan_paid_back\"],          \n      'type_sort': ['asc/desc',0.30,0.70 ],\n      'subwts'   : [ +0.02,+0.02, -0.02,-0.02 ],\n      'subm'     : [    \n         { 'name': f'0.92657','weight':+0.10,'color':\"crimson\"},\n         { 'name': f'0.92672','weight':+0.10,'color':\"darkgreen\"}, \n         { 'name': f'0.92684','weight':+0.30,'color':\"forestgreen\"},\n         { 'name': f'0.92720','weight':+0.50,'color':\"limegreen\"},]\n}\n\ndf_cross = h_blend(params, figures1=True, figures2=True, details=True)\ndf_cross . to_csv('Gr2.csv', index=False)\ndisplay_distances(params)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-10T02:07:43.933046Z","iopub.execute_input":"2025-11-10T02:07:43.934088Z","iopub.status.idle":"2025-11-10T02:08:25.42742Z","shell.execute_reply.started":"2025-11-10T02:07:43.934054Z","shell.execute_reply":"2025-11-10T02:08:25.426537Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Group.3","metadata":{}},{"cell_type":"code","source":"params = {\n      'path'     : new_path + '/',            \n      'id_target': ['id',\"loan_paid_back\"],          \n      'type_sort': ['asc/desc',0.30,0.70 ],\n      'subwts'   : [ +0.02,+0.01,-0.01,-0.02 ],\n      'subm'     : [    \n         { 'name': f'0.92601','weight':+0.07,'color':\"crimson\"},     # [11]  \n         { 'name': f'0.92664','weight':+0.09,'color':\"navy\"},        #  [4]\n         { 'name': f'0.92677','weight':+0.10,'color':\"mediumblue\"},  #  [5]\n         { 'name': f'0.92740','weight':+0.74,'color':\"royalblue\"},]  # [20]\n}\n\ndf_cross = h_blend(params, figures1=True, figures2=True, details=True)\ndf_cross . to_csv('Gr3.csv', index=False)\ndisplay_distances(params)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-10T02:08:41.233057Z","iopub.execute_input":"2025-11-10T02:08:41.233975Z","iopub.status.idle":"2025-11-10T02:09:23.452807Z","shell.execute_reply.started":"2025-11-10T02:08:41.233943Z","shell.execute_reply":"2025-11-10T02:09:23.451938Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### cross_Groups","metadata":{}},{"cell_type":"code","source":"params = {\n      'path'     : f\"/kaggle/working/\",            \n      'id_target': ['id',\"loan_paid_back\"],          \n      'type_sort': ['asc/desc',0.30,0.70 ],\n      'subwts'   : [ +0.03, -0.01, -0.02 ],\n      'subm'     : [\n         { 'name': f'Gr1','weight':+0.50,'color':'gold'},\n         { 'name': f'Gr2','weight':+0.25,'color':'chocolate'},\n         { 'name': f'Gr3','weight':+0.25,'color':'maroon'},]\n}\n\ndf_cross = h_blend(params, figures1=True, figures2=True, details=True)\n\ndisplay_distances(params)\n\nif os.path.isdir(new_path): shutil.rmtree(new_path); ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-10T02:09:52.165183Z","iopub.execute_input":"2025-11-10T02:09:52.165497Z","iopub.status.idle":"2025-11-10T02:10:23.212917Z","shell.execute_reply.started":"2025-11-10T02:09:52.165474Z","shell.execute_reply":"2025-11-10T02:10:23.212041Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Submit","metadata":{"papermill":{"duration":0.024828,"end_time":"2025-11-06T07:13:21.248608","exception":false,"start_time":"2025-11-06T07:13:21.22378","status":"completed"},"tags":[]}},{"cell_type":"code","source":"df_cross.to_csv('submission.csv',index=False)\ndf_cross","metadata":{"execution":{"iopub.status.busy":"2025-11-09T15:40:25.499997Z","iopub.execute_input":"2025-11-09T15:40:25.500753Z","iopub.status.idle":"2025-11-09T15:40:25.820583Z","shell.execute_reply.started":"2025-11-09T15:40:25.500733Z","shell.execute_reply":"2025-11-09T15:40:25.819791Z"},"papermill":{"duration":0.568934,"end_time":"2025-11-06T07:13:21.842385","exception":false,"start_time":"2025-11-06T07:13:21.273451","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null}]}