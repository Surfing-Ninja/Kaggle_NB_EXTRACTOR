{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.13"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":91722,"databundleVersionId":14262372,"isSourceIdPinned":false,"sourceType":"competition"},{"sourceId":13582034,"sourceType":"datasetVersion","datasetId":8623353},{"sourceId":13617019,"sourceType":"datasetVersion","datasetId":8635402},{"sourceId":13631075,"sourceType":"datasetVersion","datasetId":8652235}],"dockerImageVersionId":31153,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false},"papermill":{"default_parameters":{},"duration":709.34758,"end_time":"2025-11-06T07:13:22.892667","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2025-11-06T07:01:33.545087","version":"2.6.0"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### PS-s4e11 - [Predicting Loan Payback](https://www.kaggle.com/competitions/playground-series-s5e11/code?competitionId=91722&sortBy=scoreDescending&excludeNonAccessedDatasources=true)\n\nPlayground Series - Season 5, Episode 11\n\nWe're done with this notebook. We'll make a 90% copy of it, changing the groups. But we don't think it'll result in anything more meaningful than before. We'll try v-blend, which, by dividing attention, will attempt to identify where one group of participants performs slightly better than others. To do this, we'll try assembling them so that certain group members have a slightly different architecture than the other groups.\n\n| | | &nbsp; | | &nbsp; | &nbsp; | &nbsp; |\n|:-|:-| :-: | :-: | :-: | :-: | :-: |\n| 0. | [0.92_730](https://www.kaggle.com/code/nina2025/ps-s5e11-experiment?scriptVersionId=273789165) |&nbsp;v.5&nbsp;| [PS-s5e9 . experiment](https://www.kaggle.com/code/nina2025/ps-s5e9-simple-blend) | master | [F.A.Nina](https://www.kaggle.com/code/nina2025/ps-s5e11-experiment) | Georgia |\n| 1. | [0.92_684](https://www.kaggle.com/code/yeoyunsianggeremie/ps5e11-agentic-ai-solution-single-xgb?scriptVersionId=273334165) |&nbsp;v.8&nbsp;| [PS5E11 . Agentic AI Solution](https://www.kaggle.com/code/yeoyunsianggeremie/ps5e11-agentic-ai-solution) | grandmaster | [bogoconic1](https://www.kaggle.com/yeoyunsianggeremie) | Singapore |\n| 2. | [0.92_683](https://www.kaggle.com/code/sagarnagpure1310/s5e11-xgb-lgbm-fe-te-ensemble-92-68?scriptVersionId=273333134) |&nbsp;v.2&nbsp;| [S5E11 . XGB + LGBM . FE, TE & Ensemble . 92.68](https://www.kaggle.com/code/yeoyunsianggeremie/ps5e11-agentic-ai-solution) | contributor | [Sagar Nagpure](https://www.kaggle.com/sagarnagpure1310) | India |\n| 3. | [0.92_677](https://www.kaggle.com/code/adilshamim8/predicting-loan-payback-101?scriptVersionId=273568426) |&nbsp;v.3&nbsp;| [Predicting Loan Payback 101](https://www.kaggle.com/code/adilshamim8/predicting-loan-payback-101) | expert | [Adil Shamim](https://www.kaggle.com/adilshamim8) | World |\n| 4. | [0.92_672](https://www.kaggle.com/code/shreyashpatil217/loan-prediction-credit-risk-assessment?scriptVersionId=273425848) |&nbsp;v.1&nbsp;| [ðŸ’° Loan Prediction & Credit Risk Assessment](https://www.kaggle.com/code/shreyashpatil217/loan-prediction-credit-risk-assessment) | expert |[Shreyash Patil](https://www.kaggle.com/shreyashpatil217) | India |\n| 5. | [0.92_668](https://) |&nbsp;v.1&nbsp;| [PS-S5E11: XGBoost Stability Model](https://www.kaggle.com/code/canozensoy/ps-s5e11-xgboost-stability-model/notebook) | master | [Can Ã–zensoy](https://www.kaggle.com/canozensoy) | TÃ¼rkiye |\n| 6. | [0.92_655](https://www.kaggle.com/code/karltonkxb/s5e11-loan-xgb-lgbm-cuml-92-64/log?scriptVersionId=273327882) |&nbsp;v.7&nbsp;| [S5E11-Loan-XGB LGBM-CuML-92.64](https://www.kaggle.com/code/karltonkxb/s5e11-loan-xgb-lgbm-cuml-92-64) | expert | [Samidullo](https://www.kaggle.com/karltonkxb) | Poland |\n| 7. | [0.92_643](https://www.kaggle.com/code/sidakou/optimized-weighted-ensemble-of-xgb-lgb-cat-hgb?scriptVersionId=273000295) |&nbsp;v.1&nbsp;| [Opt. Weighted Ensemble of XGB, LGB, CAT & HGB](https://www.kaggle.com/code/sidakou/optimized-weighted-ensemble-of-xgb-lgb-cat-hgb) | contributor | [å®‰å°¾ æ™ƒè²´](https://www.kaggle.com/sidakou) | Japan |\n| 8. | [0.92_640](https://www.kaggle.com/code/yousefelshahat2/simple-xgboost-s5e11?scriptVersionId=272961176) |&nbsp;v.26&nbsp;| [Simple XGB  Only Competition Data](https://www.kaggle.com/code/yousefelshahat2/simple-xgboost-only-competition-data-s5e11) | expert | [yousef Elshahat](https://www.kaggle.com/yousefelshahat2) | World |\n| 9. | [0.92_620](https://) |&nbsp;v.1&nbsp;| [Loan Payback . Ensemble](https://www.kaggle.com/code/mikhailnaumov/loan-payback-ensemble/output) | master| [Mikhail Naumov](https://www.kaggle.com/mikhailnaumov) | World |\n| 10. | [0.92_601](https://www.kaggle.com/code/pradiptadatta/org-pss5e11-flaml-roc-auc?scriptVersionId=272623191) |&nbsp;v.1&nbsp;| [Org+PSS5E11 : FLAML : roc_auc](https://www.kaggle.com/code/pradiptadatta/org-pss5e11-flaml-roc-auc) | expert | [Pradipta Datta](https://www.kaggle.com/pradiptadatta) | India |\n|||||||\n|||| main weights % | asc/desc % | correct weights % |\n|  | [0.92_723](https://www.kaggle.com/code/nina2025/ps-s5e11-vote?scriptVersionId=273977640) | v.1 | [ 0+10+10+10+10+10+10+10+10+10+10 ](#first_glance) |[30&nbsp;**x**&nbsp;70](#first_glance)|[ +5,+4,+3,+2,+1, 0, -1,-2,-3,-4,-5 ](#first_glance)|\n|  | [0.92_727](https://www.kaggle.com/code/nina2025/ps-s5e11-vote?scriptVersionId=273989625) | v.3 | [ 50+5+5+5+5+5+5+5+5+5+5 ](#first_glance) |[30&nbsp;**x**&nbsp;70](#first_glance)|[ +5,+4,+3,+2,+1, 0, -1,-2,-3,-4,-5 ](#first_glance)|\n|  | [0.92_729](https://www.kaggle.com/code/nina2025/ps-s5e11-vote?scriptVersionId=273995965) | v.5 | [ 70+3+3+3+3+3+3+3+3+3+3 ](#first_glance) |[30&nbsp;**x**&nbsp;70](#first_glance)|[ +5,+4,+3,+2,+1, 0, -1,-2,-3,-4,-5 ](#first_glance)|\n|  | [0.92_730](https://www.kaggle.com/code/nina2025/ps-s5e11-vote?scriptVersionId=274000844) | v.7 | [ 90+1+1+1+1+1+1+1+1+1+1 ](#first_glance) |[30&nbsp;**x**&nbsp;70](#first_glance)|[ +5,+4,+3,+2,+1, 0, -1,-2,-3,-4,-5 ](#first_glance)|\n|  | [0.92_730](https://www.kaggle.com/code/nina2025/ps-s5e11-vote?scriptVersionId=274102646) | v.12 | [ 100+0+0+0+0+0+0+0+0+0+0 ](#first_glance) |[30&nbsp;**x**&nbsp;70](#first_glance)|[ +5,+4,+3,+2,+1, 0, -1,-2,-3,-4,-5 ](#first_glance)|\n|||||||\n||||participants|Top %|dissenters|\n|  | [0.92_727](https://www.kaggle.com/code/nina2025/ps-s5e11-vote?scriptVersionId=273986164) | v.2 | [ all ](#Vote) |[ 50% ](#Vote)|[ -2 ](#Vote) &nbsp; err!|\n|  | [0.92_727](https://www.kaggle.com/code/nina2025/ps-s5e11-vote?scriptVersionId=273993259) | v.4 | [ all ](#Vote) |[ 50% ](#Vote)|[ -3 ](#Vote) &nbsp; err!|\n|  | [0.92_727](https://www.kaggle.com/code/nina2025/ps-s5e11-vote?scriptVersionId=273997986) | v.6 | [ all ](#Vote) |[ 50% ](#Vote)|[ -4 ](#Vote) &nbsp; err!|\n|  | [0.92_730](https://www.kaggle.com/code/nina2025/ps-s5e11-vote?scriptVersionId=274006529) | v.8 | [ all ](#Vote) |[ 95% ](#Vote)|[ -5 ](#Vote)|\n|  | [0.92_727](https://www.kaggle.com/code/nina2025/ps-s5e11-vote?scriptVersionId=274100581) | v.10,11 | [ all ](#Vote) |[ 50% ](#Vote)|[ -4 ](#Vote)|\n||||dynamic participants|100 %|there are no disagreements|\n|  | [0.92_670](https://www.kaggle.com/code/nina2025/ps-s5e11-vote?scriptVersionId=274276700) | v.16 | [ alls . 0 ](#first_glance) |[ yes ](#Submit)|[ absent ](#Submit)|\n|  | [0.92_694](https://www.kaggle.com/code/nina2025/ps-s5e11-vote?scriptVersionId=274280000) | v.17 | [ alls . 1 ](#first_glance) |[ yes ](#Submit)|[ absent ](#Submit)|\n|  | [0.92_707](https://www.kaggle.com/code/nina2025/ps-s5e11-vote?scriptVersionId=274283574) | v.18 | [ alls . 4 ](#first_glance) |[ yes ](#Submit)|[ absent ](#Submit)|\n|  | [0.92_715](https://www.kaggle.com/code/nina2025/ps-s5e11-vote?scriptVersionId=274285960) | v.19 | [ alls . 5 ](#first_glance) |[ yes ](#Submit)|[ absent ](#Submit)|\n|||||||\n|||| main weights % | asc/desc % | correct weights % |\n|  | [0.92719](https://www.kaggle.com/code/nina2025/ps-s5e11-vote?scriptVersionId=274320671) | v.20 |[ [ (0,1) + (2,3) +(4,5) + (7,8) + (9,10) ](#h-blend.Groups) ] . wts = 5 x 20% |[30&nbsp;**x**&nbsp;70](#h-blend.Groups)|[ +0.11, +0.07, -0.03,-0.05,-0.10 ](#h-blend.Groups)|","metadata":{"papermill":{"duration":0.007306,"end_time":"2025-11-06T07:01:39.114502","exception":false,"start_time":"2025-11-06T07:01:39.107196","status":"completed"},"tags":[]}},{"cell_type":"code","source":"import os,ast\nimport numpy as np\nimport pandas as pd\n\nimport shutil,copy\n\nfrom bokeh.plotting import figure, gridplot \nfrom bokeh.io import output_file, show, output_notebook\noutput_notebook()\n\ndef color_scheme(dk,color):\n    colors    = ['red','green','blue']\n    clr_alls  = ['silver','crimson',\"forestgreen\"]\n    clr_alls2 = ['red',\"green\",'blue',\"silver\",'gold']\n    clr_alls3 = ['darkmagenta',\"forestgreen\",'mediumblue']\n    clr_alls4 = ['crimson',\"darkgreen\",'mediumblue','brown']\n    clr_alls4m= ['red',\"forestgreen\",'mediumblue',\"darkmagenta\"]\n    clr_alls4j= ['red',\"green\",'blue',\"sienna\"]\n    clr_alls4i= ['crimson',\"green\",'mediumblue',\"chocolate\"]\n    clr_alls5 = ['red',\"forestgreen\",'mediumblue',\"darkmagenta\",'crimson']\n    clr_gold  = ['gainsboro',\"silver\",'darkgray','gray','gold']\n    clr_Red4  = [\"firebrick\",\"orangered\",\"crimson\",'red']\n    clr_Red52 = ['silver','darkgray','gray','crimson',\"crimson\"]\n    clr_Red53 = ['silver','darkgray','gray','dimgray',\"crimson\"]\n    clr_Red54 = ['forestgreen','limegreen','lime',\"crimson\"]\n    clr_Red55 = [\"silver\",'darkgray','gray',\"crimson\"]\n    clr_Red6  = [\"crimson\",'red','orangered','tomato','green','mediumblue']\n    clr_Red5  = [\"crimson\",'red','orangered','tomato','darkmagenta']\n    clr_Red3  = ['olivedrab','gold',\"lemonchiffon\"]\n    clr_Red31 = [\"crimson\",'red','gold']\n    clr_Red13 = ['gold',\"crimson\",'red']\n    clr_Green = [\"limegreen\",\"forestgreen\",\"mediumseagreen\",\"green\",\"darkgreen\"]\n    clr_Green2= ['olivedrab',\"darkgreen\",\"forestgreen\"]\n    clr_Green3= [\"darkmagenta\",'olivedrab',\"darkgreen\"]\n    clr_Green4= [\"darkgreen\",\"forestgreen\",\"limegreen\",\"lime\"]\n    clr_Green5= [\"crimson\",\"darkgreen\",\"forestgreen\",\"limegreen\",\"lime\"]\n    clr_Blue  = ['midnightblue',\"royalblue\",\"mediumblue\",\"blue\",\"steelblue\",'cyan']\n    clr_Blue4 = ['midnightblue',\"royalblue\",\"mediumblue\",\"deepskyblue\"]\n    clr_Blue5 = [\"firebrick\",'navy',\"mediumblue\",\"royalblue\",\"deepskyblue\"]\n    clr_Brown = [\"maroon\",'firebrick',\"chocolate\",\"sienna\",\"sandybrown\"]\n    clr_Brown3= [\"maroon\",\"sienna\",\"sandybrown\"]\n    clr_Brown4= [\"maroon\",\"sienna\",\"chocolate\",\"sandybrown\"]\n    clr_Brown5= [\"maroon\",\"sienna\",\"chocolate\",\"sandybrown\",'gold']\n    clr_Two   = ['crimson','mediumblue']\n    clr_Two2  = ['crimson','darkgreen']\n    clr_tes3  = ['limegreen',\"magenta\",'red']\n    clr_tes3b = ['darkmagenta',\"magenta\",'red']\n    clr_tes5  = ['mediumblue','crimson','crimson','crimson','mediumblue']\n    clr_tes6  = ['limegreen'] + clr_Brown\n    clr_tes7  = clr_Brown4 + [\"mediumblue\"]+[\"crimson\"]+['red']\n    clr_tes8  = clr_Red4 + clr_Blue4\n    clr_tes9  = clr_Red4 + ['darkmagenta'] + clr_Blue4\n    clr_tes10 = clr_Brown + clr_Green\n    clr_tes11 = clr_Brown + clr_Green + ['blue']\n    l = len(dk['subm'])\n    if color == 'Two2'  : colors = clr_Two2   [0:l]\n    if color == 'Two'   : colors = clr_Two    [0:l]\n    if color == 'alls'  : colors = clr_alls   [0:l]\n    if color == 'alls2' : colors = clr_alls2  [0:l]\n    if color == 'alls3' : colors = clr_alls3  [0:l]\n    if color == 'alls4' : colors = clr_alls4  [0:l]\n    if color == 'alls4m': colors = clr_alls4m [0:l]\n    if color == 'alls4i': colors = clr_alls4i [0:l]\n    if color == 'alls4j': colors = clr_alls4j [0:l]\n    if color == 'alls5' : colors = clr_alls5  [0:l]\n    if color == 'red'   : colors = clr_Red    [0:l]\n    if color == 'red3'  : colors = clr_Red3   [0:l]\n    if color == 'red4'  : colors = clr_Red4   [0:l]\n    if color == 'red5'  : colors = clr_Red5   [0:l]\n    if color == 'red52' : colors = clr_Red52  [0:l]\n    if color == 'red53' : colors = clr_Red53  [0:l]\n    if color == 'red54' : colors = clr_Red54  [0:l]\n    if color == 'red55' : colors = clr_Red55  [0:l]\n    if color == 'red6'  : colors = clr_Red6   [0:l]\n    if color == 'gold'  : colors = clr_gold   [0:l]\n    if color == 'red31' : colors = clr_Red31  [0:l]\n    if color == 'red13' : colors = clr_Red13  [0:l]\n    if color == 'green' : colors = clr_Green  [0:l]\n    if color == 'green2': colors = clr_Green2 [0:l]\n    if color == 'green3': colors = clr_Green3 [0:l]\n    if color == 'green4': colors = clr_Green4 [0:l]\n    if color == 'green5': colors = clr_Green5 [0:l]\n    if color == 'blue'  : colors = clr_Blue   [0:l]\n    if color == 'blue4' : colors = clr_Blue4  [0:l]\n    if color == 'blue5' : colors = clr_Blue5  [0:l]\n    if color == 'brown' : colors = clr_Brown  [0:l]\n    if color == 'brown3': colors = clr_Brown3 [0:l]\n    if color == 'brown4': colors = clr_Brown4 [0:l]\n    if color == 'brown5': colors = clr_Brown5 [0:l]\n    if color == 'tes3'  : colors = clr_tes3   [0:l]\n    if color == 'tes3b' : colors = clr_tes3b  [0:l]\n    if color == 'tes5'  : colors = clr_tes5   [0:l]\n    if color == 'tes6'  : colors = clr_tes6   [0:l]\n    if color == 'tes7'  : colors = clr_tes7   [0:l]\n    if color == 'tes8'  : colors = clr_tes8   [0:l]\n    if color == 'tes9'  : colors = clr_tes9   [0:l]\n    if color == 'tes10' : colors = clr_tes10  [0:l]\n    if color == 'tes11' : colors = clr_tes11  [0:l]\n    return colors\n\n\ndef bokeh_show(\n        params,\n        df_cross,\n        colors, \n        show_figures1, \n        show_figures2, wps_fig2,\n        color_cross):\n    \n    def dossier(js,subms,cols):\n        def quant(i,js,subms,cols):\n            return {\"c\" : i, \"q\" : sum([1 for subm in cols[i] if subm == subms[js]])}\n        return {\n            'name' : subms[js],\n            'q_in' : [quant(i,js,subms,cols) for i in range(len(subms))]\n        }\n    alls = pd.read_csv(f'tida_desc.csv')\n    matrix = [ast.literal_eval(str(row.alls)) for row in alls.itertuples()]\n    subms = sorted(matrix[0])\n    cols = [[data[i] for data in matrix] for i in range(len(subms))]\n    df_subms = pd.DataFrame({f'col_{i}': [x[i] for x in matrix] for i in range(len(subms))})\n    dossiers = [dossier(js,subms,cols) for js in range(len(subms))]\n    subm_names = [one_dossier['name'] for one_dossier in dossiers]\n    figures1,qss,i = [],[],0\n    height = 85 if len(colors)==2\\\n        else 134 if len(colors)==3 else (154 if len(colors)==4 else 174)\n    for one_dossier in dossiers: \n        i_col = 'alls. ' + str(one_dossier['q_in'][i]['c'])\n        qs = [one['q'] for one in one_dossier['q_in']]\n        x_names = [name.replace(\"Group\",\"\").replace(\"subm_\",\"\") for name in subm_names]\n        width = 157  if len(colors) == 5\\\n            else (121 if len(colors) == 8\\\n            else (131 if len(colors) == 9\\\n            else (141 if len(colors) == 10\\\n            else (171 if len(colors) == 11 else 133))))\n        f = figure(x_range=x_names,width=width, height=height, title=i_col)\n        f.vbar(x=x_names, width=0.585, top=qs, color=colors)\n        figures1.append(f)\n        qss.append(qs)\n        i+=1\n    grid = gridplot([figures1])\n    output_file('tida_alls.html')\n    if show_figures1 == True: show(grid)\n    sub_wts = params['subwts']\n    main_wts = [subm['weight'] for subm in params['subm']]\n    mms,acc_mass = [],[]\n    for j in range(len(dossiers)):\n        one_dossier = dossiers[j]\n        qs = [one['q'] for one in one_dossier['q_in']]\n        mm = [qs[h] * (main_wts[j] + sub_wts[h]) for h in range(len(sub_wts))]\n        mass = sum(mm)\n        mms.append(mm)\n        acc_mass.append(round(mass))                        #subm_names[::-1]\n    y_names = [name + \" - \" + str(mass) for name,mass in zip(subm_names,acc_mass)]\n    f1 = figure(y_range=y_names, width=313, height=height, title='relations of general masses')\n    f1.hbar(y=y_names, height=0.585, right=acc_mass, left=0, color=colors)\n    output_file('tida_alls2.html')\n    alls = [f'alls.{i}' for i in range(len(dossiers))]\n    subm = [f'sub{i}'   for i in range(len(dossiers))] \n    mmsT  = np.asarray(mms).T\n    data = {'cols' : alls}\n    for i in range(len(dossiers)): data[f'sub{i}'] = mmsT[i,:]\n    f2 = figure(y_range=alls, height=height, width=274, title=\" ( relations of columns masses )\")\n    f2.hbar_stack(subm, y='cols', height=0.585, color=colors, source=data)\n    qssT  = np.asarray(qss).T\n    data = {'cols' : alls}\n    for i in range(len(dossiers)): data[f'sub{i}'] = qssT[i,:]\n    f3 = figure(y_range=alls, height=height, width=215, title=\"ratios in columns\")\n    f3.hbar_stack(subm, y='cols', height=0.585, color=colors, source=data)\n    grid = gridplot([[f3,f2,f1]])\n    show(grid)\n    if show_figures2 == True:\n        def read(params,i):\n            FiN = params[\"path\"] + params[\"subm\"][i][\"name\"] + \".csv\"\n            target_name_back = {'target':params[\"target\"],'pred':params[\"target\"]}\n            return pd.read_csv(FiN).rename(columns=target_name_back)\n        dfs = [read(params,i) for i in range(len(params[\"subm\"]))] + [df_cross]\n        f   = figure(width=800, height=354)\n        f.title.text = 'Click on legend entries to mute the corresponding lines'\n        b,e        = 21000,21121\n        line_x     = [dfs[i][b:e]['id']            for i in range(len(dfs))]\n        line_y     = [dfs[i][b:e]['loan_paid_back'] for i in range(len(dfs))]\n        color      = colors + [color_cross]\n        alpha      = [0.8 for i in range(len(dfs)-1)] + [0.95]\n        lws        = [1.0 for i in range(len(dfs)-1)] + [1.00]\n        legend = subm_names + ['cross']\n        for i in range(len(legend)):\n            f.line(line_x[i], line_y[i], line_width=lws[i], color=color[i], alpha=alpha[i],\n                   muted_color='white',legend_label=legend[i])\n        f.legend.location = \"top_left\"\n        f.legend.click_policy=\"mute\"\n        show(f)\n\n\ndef h_blend(params,color,cross='silver',\n            figures1=False,figures2=False,wf2=555,\n            details=False):\n\n    color_cross = cross\n\n    dk = copy.deepcopy(params)\n\n    show_details,show_figures1,show_figures2 = details,figures1,figures2\n\n    file_short_names = [subm['name'] for subm in params['subm']]\n    type_sort    = params['type_sort'][0]\n    dk['asc']    = params['type_sort'][1]\n    dk['desc']   = params['type_sort'][2]\n    dk['id']     = params['id_target'][0]\n    dk['target'] = params['id_target'][1]\n# ------------------------------------------------------------------------\n    def read(dk,i):\n        tnm = dk[\"subm\"][i][\"name\"]\n        FiN = dk[\"path\"] + tnm + \".csv\"\n        return pd.read_csv(FiN).rename(columns={\n            'target':tnm, 'pred':tnm, dk[\"target\"]:tnm})\n        \n    def merge(dfs_subm):\n        df_subms = pd.merge(dfs_subm[0],  dfs_subm[1], on=[dk['id']])\n        for i in range(2, len(dk[\"subm\"])): \n            df_subms = pd.merge(df_subms, dfs_subm[i], on=[dk['id']])\n        return df_subms\n        \n    def da(dk,sorting_direction,show_details):\n        \n        df_subms = merge([read(dk,i) for i in range(len(dk[\"subm\"]))])\n        cols = [col for col in df_subms.columns if col != dk['id']]\n        short_name_cols = [c for c in cols]\n        \n        def alls1(x, sd=sorting_direction,cs=cols):\n            reverse = True if sd=='desc' else False\n            tes = {c: x[c] for c in cs}.items()\n            subms_sorted = [t[0] for t in sorted(tes,key=lambda k:k[1],reverse=reverse)]\n            return subms_sorted\n\n        import random\n\n        def alls2(x, sd=sorting_direction,cs=cols):\n            reverse = True if sd=='desc' else False\n            tes = {c: x[c] for c in cs}.items()\n            subms_random = [t[0] for t in tes]\n            random.shuffle(subms_random)\n            return subms_random\n\n        alls = alls1 if type_sort == 'asc/desc' else alls2\n            \n        def summa(x,cs,wts,ic_alls): \n            return sum([x[cs[j]] * (wts[0][j] + wts[1][ic_alls[j]]) for j in range(len(cs))])\n            \n        wts = [[[e['weight'] for e in dk[\"subm\"]], [w for w in dk[\"subwts\" ]]]]\n          \n        def correct(x, cs=cols, wts=wts):\n            i = [x['alls'].index(c) for c in short_name_cols]\n            return summa(x,cs,wts[0],i)\n\n        if len(wts) == 1:\n            correct_sub_weights = [wt for wt in dk[\"subwts\"]]\n            weights = [subm['weight'] for subm in dk[\"subm\"]]\n            def correct(x, cs=cols, w=weights, cw=correct_sub_weights):\n                ic = [x['alls'].index(c) for c in short_name_cols]\n                cS = [x[cols[j]] * (w[j] + cw[ic[j]]) for j in range(len(cols))]\n                return sum(cS)\n                   \n        def amxm(x, cs=cols):\n            list_values = x[cs].to_list()\n            mxm = abs(max(list_values)-min(list_values))\n            return mxm\n\n        if len(wts) > 1:\n            df_subms['mx-m']   = df_subms.apply(lambda x: amxm   (x), axis=1)\n        df_subms['alls']       = df_subms.apply(lambda x: alls   (x), axis=1)\n        df_subms[dk[\"target\"]] = df_subms.apply(lambda x: correct(x), axis=1)\n        schema_rename = { old_nc:new_shnc for old_nc, new_shnc in zip(cols, short_name_cols) }\n        df_subms = df_subms.rename(columns=schema_rename)\n        df_subms = df_subms.rename(columns={dk[\"target\"]:\"ensemble\"})\n        df_subms.insert(loc=1, column=' _ ', value=['   '] * len(df_subms))\n        df_subms[' _ '] = df_subms[' _ '].astype(str)\n        pd.set_option('display.max_rows',100)\n        pd.set_option('display.float_format', '{:.5f}'.format)\n        vcols = [dk['id']]+[' _ '] + short_name_cols + [' _ ']+['alls']+[' _ ']+['ensemble']\n        if len(wts) > 1: vcols.append([' _ '] + ['mx-m'])\n        df_subms = df_subms[vcols]\n        if show_details and sorting_direction=='desc': display(df_subms.head(5))\n        pd.set_option('display.float_format', '{:.5f}'.format)\n        df_subms = df_subms.rename(columns={\"ensemble\":dk[\"target\"]})\n        df_subms.to_csv(f'tida_{sorting_direction}.csv', index=False)\n        return df_subms[[dk['id'],dk['target']]]\n   \n    def ensemble_da(dk,        show_details): \n        dfD    = da(dk,'desc', show_details)\n        dfA    = da(dk,'asc',  show_details)\n        dfA[dk['target']] = dk['desc']*dfD[dk['target']] + dfA[dk['target']]*dk['asc']\n        return dfA\n\n    da = ensemble_da(dk,show_details)\n    colors = color_scheme(dk, color)\n    bokeh_show(dk, da, colors, show_figures1, show_figures2, wf2, color_cross)\n    return  da\n\n\ndef matrix_vs(path,fs_names):\n    def load(path,fs_names):\n        dfs = [pd.read_csv(path + name_subm +'.csv') for name_subm in fs_names]\n        for i in range(len(dfs)):\n            dfs[i] = dfs[i].rename(columns={\"loan_paid_back\": f'{fs_names[i]}'})\n        dfsm = pd.merge(dfs[0], dfs[1], on=\"id\")\n        for i in range(2,len(dfs)):\n            dfsm = pd.merge(dfsm,dfs[i],on='id')\n        return dfsm   \n    def make_list_vs(fs_names):\n        list = []\n        for i in range(0,len(fs_names)-1):\n            for j in range(i+1,len(fs_names)):\n                list.append(fs_names[i] + \"_vs_\" + fs_names[j])\n        return list\n    def get_mvs(dfs, list_vs):\n        def get_abs_distance(x,t1,t2):\n            return abs(x[t1]-x[t2])\n        for vs in list_vs:\n            t = vs.split('_vs_')\n            dfs[vs] = dfs.apply(lambda x: get_abs_distance(x,t[0],t[1]), axis=1)\n        return dfs   \n    def distance_vs(name, st_names, list_vs, dfs):\n        distances = []\n        for st in st_names:\n            vs_between = name + \"_vs_\" + st\n            if vs_between not in list_vs:\n                distances.append(0)\n            else: distances.append(round(dfs[vs_between].sum()))\n        return distances\n    dfs = load(path,fs_names)\n    list_vs = make_list_vs(fs_names)\n    mvs = get_mvs(dfs, list_vs)\n    m1 = pd.DataFrame({'subm':fs_names})\n    m2 = pd.DataFrame({ name :distance_vs(name, fs_names, list_vs, mvs) for name in fs_names})\n    matrix = pd.concat([m1,m2],axis=1)\n    return matrix\n\n\ndef display_distances(params):\n    files = [subm['name'] for subm in params['subm']]\n    distances = matrix_vs ( params['path'], files )            \n    display(distances)\n\n\ndef straight_blend(df_1,df_2,wts=[0.50,0.50],subm='submission.csv'):\n    t = 'loan_paid_back'\n    df_1[t] = df_1[t]*wts[0] + df_2[t]*wts[1]\n    df_1.to_csv(subm, index=False)\n    print(f'{subm} - ready to use')","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2025-11-07T16:55:16.794109Z","iopub.execute_input":"2025-11-07T16:55:16.794393Z","iopub.status.idle":"2025-11-07T16:55:16.863226Z","shell.execute_reply.started":"2025-11-07T16:55:16.794374Z","shell.execute_reply":"2025-11-07T16:55:16.862321Z"},"papermill":{"duration":3.695998,"end_time":"2025-11-06T07:01:42.816779","exception":false,"start_time":"2025-11-06T07:01:39.120781","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%%time\n\nnew_path  = '/kaggle/working/public'\nds_path4 = '/kaggle/input/4-november-2025-ps-s5e11'\nds_path3 = '/kaggle/input/03-november-2025-ps-s5e11'\n\nif os.path.isdir(new_path): shutil.rmtree(new_path); \n    \nos.mkdir(new_path)\n\nshutil.copy(ds_path3 +'/submission 0.92601.csv', new_path +'/0.92601.csv')\nshutil.copy(ds_path3 +'/submission 0.92620.csv', new_path +'/0.92620.csv')\nshutil.copy(ds_path3 +'/submission 0.92640.csv', new_path +'/0.92640.csv')\nshutil.copy(ds_path3 +'/submission 0.92643.csv', new_path +'/0.92643.csv')\nshutil.copy(ds_path3 +'/submission 0.92655.csv', new_path +'/0.92655.csv')\nshutil.copy(ds_path4 +'/submission 0.92668.csv', new_path +'/0.92668.csv')\nshutil.copy(ds_path3 +'/submission 0.92672.csv', new_path +'/0.92672.csv')\nshutil.copy(ds_path4 +'/submission 0.92677.csv', new_path +'/0.92677.csv')\nshutil.copy(ds_path3 +'/submission 0.92683.csv', new_path +'/0.92683.csv')\nshutil.copy(ds_path3 +'/submission 0.92684.csv', new_path +'/0.92684.csv')\nshutil.copy(ds_path4 +'/submission 0.92730.csv', new_path +'/0.92730.csv')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-07T16:48:00.665185Z","iopub.execute_input":"2025-11-07T16:48:00.666112Z","iopub.status.idle":"2025-11-07T16:48:01.515485Z","shell.execute_reply.started":"2025-11-07T16:48:00.666079Z","shell.execute_reply":"2025-11-07T16:48:01.514707Z"},"_kg_hide-input":true,"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## first_glance","metadata":{"papermill":{"duration":0.007349,"end_time":"2025-11-06T07:01:42.831429","exception":false,"start_time":"2025-11-06T07:01:42.82408","status":"completed"},"tags":[]}},{"cell_type":"code","source":"params = {\n      'path'     : new_path + \"/\",            \n      'id_target': ['id',\"loan_paid_back\"],          \n      'type_sort': ['asc/desc',0.30,0.70 ],\n      'subwts'   : [e/100 for e in [5,4,3,2,1, 0, -1,-2,-3,-4,-5]],\n      'subm'     : [\n         { 'name': f'0.92601','weight':+0.00 },\n         { 'name': f'0.92620','weight':+0.00 },\n         { 'name': f'0.92640','weight':+0.00 },\n         { 'name': f'0.92643','weight':+0.00 },\n         { 'name': f'0.92655','weight':+0.00 },\n         { 'name': f'0.92668','weight':+0.00 },\n         { 'name': f'0.92672','weight':+0.00 },\n         { 'name': f'0.92677','weight':+0.00 },\n         { 'name': f'0.92683','weight':+0.00 },\n         { 'name': f'0.92684','weight':+0.00 },\n         { 'name': f'0.92730','weight':+1.00 },]\n}\n\ndf_cross = h_blend(params, color='tes11', figures1=True, figures2=True) #, details=True)\n\n# display_distances(params)","metadata":{"execution":{"iopub.status.busy":"2025-11-07T16:48:11.042564Z","iopub.execute_input":"2025-11-07T16:48:11.042901Z","iopub.status.idle":"2025-11-07T16:49:24.001754Z","shell.execute_reply.started":"2025-11-07T16:48:11.042875Z","shell.execute_reply":"2025-11-07T16:49:24.00051Z"},"papermill":{"duration":78.605735,"end_time":"2025-11-06T07:03:01.444683","exception":false,"start_time":"2025-11-06T07:01:42.838948","status":"completed"},"tags":[],"trusted":true,"_kg_hide-input":true,"_kg_hide-output":false,"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"if os.path.isdir(new_path): shutil.rmtree(new_path)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-07T16:50:08.418559Z","iopub.execute_input":"2025-11-07T16:50:08.418957Z","iopub.status.idle":"2025-11-07T16:50:08.436033Z","shell.execute_reply.started":"2025-11-07T16:50:08.41893Z","shell.execute_reply":"2025-11-07T16:50:08.435035Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Vote","metadata":{}},{"cell_type":"code","source":"def voting(rem_left=0,rem_right=1, wts_with_Top=[0.50,0.50]):\n\n    target = 'loan_paid_back'\n\n    print(f'\\nVoting:\\n')\n\n    df_Top    = pd.read_csv('/kaggle/input/4-november-2025-ps-s5e11/submission 0.92730.csv')\n    df_vote   = pd.read_csv('/kaggle/input/playground-series-s5e11/sample_submission.csv') \n    df_desc   = pd.read_csv('/kaggle/working/tida_desc.csv')\n\n    print(f'participiants voting -----------------------------------------------------\\n')\n\n    df_soluts = df_desc[df_desc.columns[2:13]];      display(df_soluts)\n\n    rem_right = df_soluts.shape[1] - rem_right\n\n    np_soluts_sorted = np.sort(df_soluts.to_numpy(), axis=1)\n\n    rezult_matrix_of_vote = np_soluts_sorted[ : , rem_left : rem_right]\n\n    print(\"'simple voting - sorting and exclusion from the list of 'dissenters'\")\n    print(\"by trimming the 'presumed dissenters from the majority' from the left and right\\n\")\n\n    display(pd.DataFrame(rezult_matrix_of_vote))\n\n    print(f'voted --------------------------------------------------------------------\\n')\n\n    df_vote[target]  = np.mean(rezult_matrix_of_vote, axis=1)\n\n    df_vote[target]  =\\\n        df_Top [target] * wts_with_Top[0] + \\\n        df_vote[target] * wts_with_Top[1]\n    \n    print(f'Compare: df_Top = loan_paid_back_x  vs  df_vote = loan_paid_back_y','-'*7,'\\n')\n\n    df_comparison = pd.merge(df_Top, df_vote, on='id')\n    df_comparison[\"delta_back's\"] = df_Top[target] - df_vote[target]\n    display  (df_comparison)\n    print(sum(df_comparison[\"delta_back's\"]),\n              df_comparison[\"delta_back's\"][df_comparison[\"delta_back's\"] < 0].sum())\n    return df_vote\n\n\ndf_vote = voting(rem_left=0,rem_right=4)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-07T16:50:12.629535Z","iopub.execute_input":"2025-11-07T16:50:12.629857Z","iopub.status.idle":"2025-11-07T16:50:14.155003Z","shell.execute_reply.started":"2025-11-07T16:50:12.629826Z","shell.execute_reply":"2025-11-07T16:50:14.153967Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_desc   = pd.read_csv('/kaggle/working/tida_desc.csv')\n\nprint('\\ntida_desc: column names are the short names of the submission files and voting participants') \nprint(\"\\n'alls' column is a sorted list of the short names of the participants according to their preds.\\n\")\ndisplay(df_desc[2:3])\n      \nmatrix = [ast.literal_eval(str(row.alls)) for row in df_desc.itertuples()]\n\nprint('\\n\\nGeneral represent of the \"parsed\" \"alls\" function column - a sorted list of short names')\n\nprint('\\nAll numbers in this dataframe are not preds but abbreviated names of subm. files')\nprint('\\nthe numbers are the assessment of the main system - this is LB \\n')\n\ndisplay(pd.DataFrame(matrix).head())\n\nprint('\\n one of the columns is selected and their predictions are taken from their names')\n\n\ndef get_preds_from_column(iCol,df_desc):\n    def gic(ic=iCol,dd=df_desc):\n        return dd.apply(lambda x:  x[ast.literal_eval(str(x['alls']))[ic]], axis=1)\n    df = pd.read_csv('/kaggle/input/playground-series-s5e11/sample_submission.csv')\n    df['loan_paid_back'] = gic()\n    return df\n    \n\nprint('\\n For example, column 4 â€” alls.4 â€” can be viewed using the Bokeh visualization')\nprint('\\n this is one of the core components of the h-blend.\\n')\n\ndf_ic_vote = get_preds_from_column(4, df_desc)\n\nprint('\\n The question is raised - could this approach result in some kind of vote?\\n')\n\ndisplay(df_ic_vote)\n\nprint(\"\\n We have 11 columnsâ€”let's try sending each one to the system's evolution.\")\nprint(\"\\n Maybe we'll get something out of it, or at least see something.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-07T16:50:33.042701Z","iopub.execute_input":"2025-11-07T16:50:33.043293Z","iopub.status.idle":"2025-11-07T16:50:51.046083Z","shell.execute_reply.started":"2025-11-07T16:50:33.043265Z","shell.execute_reply":"2025-11-07T16:50:51.045026Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"display(get_preds_from_column(3, df_desc)) # For example, the 3-rd column","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-07T16:51:55.730211Z","iopub.execute_input":"2025-11-07T16:51:55.731036Z","iopub.status.idle":"2025-11-07T16:52:04.759045Z","shell.execute_reply.started":"2025-11-07T16:51:55.731005Z","shell.execute_reply":"2025-11-07T16:52:04.75808Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Submit","metadata":{"papermill":{"duration":0.024828,"end_time":"2025-11-06T07:13:21.248608","exception":false,"start_time":"2025-11-06T07:13:21.22378","status":"completed"},"tags":[]}},{"cell_type":"code","source":"df = df_vote   # lb = 0.92_727\ndf = df_cross  # lb = 0.92_730 - it still remains our top\n\n# --------------------------------------------------------\n\n# The beginning of another moment of local experimentation\n\n'''\nIt's a bit much, of course, but we have 10 launches a day.\n\nWe'll send all the columns, but they're still predictions of public works.\n\nThat's what our top list is based on. Well, let's get to it, let's see...\n'''\npass","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-07T16:53:31.739181Z","iopub.execute_input":"2025-11-07T16:53:31.739454Z","iopub.status.idle":"2025-11-07T16:53:31.743925Z","shell.execute_reply.started":"2025-11-07T16:53:31.739436Z","shell.execute_reply":"2025-11-07T16:53:31.742858Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#df = get_preds_from_column(0, df_desc) # LB = 0.92670 - v.16\n#df = get_preds_from_column(1, df_desc) # LB = 0.92694 - v.17\n#df = get_preds_from_column(4, df_desc) # LB = 0.92707 - v.18\n#df = get_preds_from_column(5, df_desc) # LB = 0.92715 - v.19","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## h-blend.Groups\n\n5 groups = [ (0,1) + (2,3) + (4,5) + (7,8) + (9,10) ] . weights. [20% + 20% + 20% + 20% + 20% ]","metadata":{}},{"cell_type":"code","source":"%%time\n\n# Preparing Groups\n\ndf_11 = get_preds_from_column(0, df_desc) # LB = 0.92670 - v.16\ndf_12 = get_preds_from_column(1, df_desc) # LB = 0.92694 - v.17\n\nstraight_blend(df_11,df_12,wts=[0.40,0.60],subm='Group_1.csv')\n#----------------------------------------------------------------\n\ndf_21 = get_preds_from_column(2, df_desc) # LB = no_data\ndf_22 = get_preds_from_column(3, df_desc) # LB = no_data\n\nstraight_blend(df_21,df_22,wts=[0.50,0.50],subm='Group_2.csv')\n#----------------------------------------------------------------\n\ndf_31 = get_preds_from_column(4, df_desc) # LB = 0.92707 - v.18\ndf_32 = get_preds_from_column(5, df_desc) # LB = 0.92715 - v.19\n\nstraight_blend(df_31,df_32,wts=[0.45,0.55],subm='Group_3.csv')\n#----------------------------------------------------------------\n\ndf_41 = get_preds_from_column(7, df_desc) # LB = no_data\ndf_42 = get_preds_from_column(8, df_desc) # LB = no_data\n\nstraight_blend(df_41,df_42,wts=[0.45,0.55],subm='Group_4.csv')\n#----------------------------------------------------------------\ndf_51 = get_preds_from_column(9, df_desc) # LB = no_data\ndf_52 = get_preds_from_column(10,df_desc) # LB = no_data\n\nstraight_blend(df_51,df_52,wts=[0.40,0.60],subm='Group_5.csv')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-07T16:55:27.64563Z","iopub.execute_input":"2025-11-07T16:55:27.645979Z","iopub.status.idle":"2025-11-07T16:57:00.176537Z","shell.execute_reply.started":"2025-11-07T16:55:27.645956Z","shell.execute_reply":"2025-11-07T16:57:00.17571Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"params = {\n      'path'     : \"/kaggle/working/\",            \n      'id_target': ['id',\"loan_paid_back\"],          \n      'type_sort': ['asc/desc',0.30,0.70 ],\n      'subwts'   : [-0.07,-0.04, 0.29, -0.05,-0.13],\n      'subm'     : [\n         { 'name': f'Group_1','weight':+0.20 },\n         { 'name': f'Group_2','weight':+0.20 },\n         { 'name': f'Group_3','weight':+0.20 },\n         { 'name': f'Group_4','weight':+0.20 },\n         { 'name': f'Group_5','weight':+0.20 },]\n}\n\ndf = h_blend(params, color='alls5', figures1=True, figures2=True, details=True)\n\ndisplay_distances(params)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-07T17:10:03.491426Z","iopub.execute_input":"2025-11-07T17:10:03.492017Z","iopub.status.idle":"2025-11-07T17:10:59.535683Z","shell.execute_reply.started":"2025-11-07T17:10:03.491989Z","shell.execute_reply":"2025-11-07T17:10:59.53471Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df . to_csv('submission.csv',index=False)\ndf","metadata":{"execution":{"iopub.status.busy":"2025-11-06T13:27:44.071765Z","iopub.execute_input":"2025-11-06T13:27:44.07267Z","iopub.status.idle":"2025-11-06T13:27:44.603656Z","shell.execute_reply.started":"2025-11-06T13:27:44.072639Z","shell.execute_reply":"2025-11-06T13:27:44.602762Z"},"papermill":{"duration":0.568934,"end_time":"2025-11-06T07:13:21.842385","exception":false,"start_time":"2025-11-06T07:13:21.273451","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Appendix-archive\n\nThree things naturally suggest themselves: 1) Increasing the number of participants; 2) vertical blend; 3) GAN - !??\n\nThe Bokeh histograms show that the h-blend itself loses its \"agility\" in the last experimental operationâ€”at 99%, it already resembles a regular straight blend.\nWe'll still run this operation, which (we're 99% sure) will also yield no improvement in accuracy. And it seems like we've achieved nothing but wasted timeâ€”we don't think this is entirely true, because we won't be returning to these points!\n\nIf we don't abandon this topic, then first of all, we need to change some of the participants themselvesâ€”specifically, try replacing them. We already did this in our other notebook, Experimental, where we smoothed and merged two master-classes of a file-submit into one, ensuring their inclusion in the main group. Their dispersion relative to the other members is noticeably different. We may be wrong, but the system requires further consideration. And here, first of all, I'd like to honestly note that blendsâ€”both simple and complexâ€”are unlikely to yield more than they already have. ARCHITECTURE + FEATURE ENGINEERING WILL PREVAIL, and predominate more than they have in the past two competitions, for example.\n\nP.S. We'll try to change both the groups and the group members ourselves, but we're more inclined to move to v-blends.","metadata":{"_kg_hide-input":true,"jupyter":{"source_hidden":true}}}]}