{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":91722,"databundleVersionId":14262372,"sourceType":"competition"},{"sourceId":13582034,"sourceType":"datasetVersion","datasetId":8623353},{"sourceId":13617019,"sourceType":"datasetVersion","datasetId":8635402},{"sourceId":13631075,"sourceType":"datasetVersion","datasetId":8652235},{"sourceId":13652933,"sourceType":"datasetVersion","datasetId":8679193},{"sourceId":13661896,"sourceType":"datasetVersion","datasetId":8679843}],"dockerImageVersionId":31153,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport ast\nimport numpy as np\nimport pandas as pd\nimport shutil\nimport copy\nimport random\nfrom typing import List, Dict, Tuple, Any\nfrom dataclasses import dataclass\nfrom functools import reduce\n\nfrom bokeh.plotting import figure, gridplot \nfrom bokeh.io import output_file, show, output_notebook\noutput_notebook()\n\n\ndef get_visualization_colors(config_dict, theme_name):\n    \"\"\"\n    Generate color palette for visualizations based on selected theme.\n    Returns a list of colors trimmed to match the number of submissions.\n    \"\"\"\n    palette_map = {\n        'Two': ['crimson', 'mediumblue'],\n        'Two2': ['crimson', 'darkgreen'],\n        'alls': ['silver', 'crimson', 'forestgreen'],\n        'alls2': ['red', 'green', 'blue', 'silver', 'gold'],\n        'alls3': ['darkmagenta', 'forestgreen', 'mediumblue'],\n        'alls4': ['crimson', 'darkgreen', 'forestgreen', 'limegreen'],\n        'alls4r': ['darkgreen', 'forestgreen', 'crimson', 'limegreen'],\n        'alls4m': ['red', 'forestgreen', 'mediumblue', 'darkmagenta'],\n        'alls4i': ['crimson', 'green', 'mediumblue', 'chocolate'],\n        'alls4j': ['red', 'green', 'blue', 'sienna'],\n        'alls5': ['red', 'forestgreen', 'mediumblue', 'darkmagenta', 'crimson'],\n        'gold': ['gainsboro', 'silver', 'darkgray', 'gray', 'gold'],\n        'red3': ['olivedrab', 'gold', 'lemonchiffon'],\n        'red4': ['firebrick', 'orangered', 'crimson', 'red'],\n        'red5': ['crimson', 'red', 'orangered', 'tomato', 'darkmagenta'],\n        'red6': ['crimson', 'red', 'orangered', 'tomato', 'green', 'mediumblue'],\n        'red13': ['gold', 'crimson', 'red'],\n        'red31': ['crimson', 'red', 'gold'],\n        'red52': ['silver', 'darkgray', 'gray', 'crimson', 'crimson'],\n        'red53': ['silver', 'darkgray', 'gray', 'dimgray', 'crimson'],\n        'red54': ['forestgreen', 'limegreen', 'lime', 'crimson'],\n        'red55': ['silver', 'darkgray', 'gray', 'crimson'],\n        'green': ['limegreen', 'forestgreen', 'mediumseagreen', 'green', 'darkgreen'],\n        'green2': ['olivedrab', 'darkgreen', 'forestgreen'],\n        'green3': ['darkmagenta', 'olivedrab', 'darkgreen'],\n        'green4': ['darkgreen', 'forestgreen', 'limegreen', 'lime'],\n        'green5': ['crimson', 'darkgreen', 'forestgreen', 'limegreen', 'lime'],\n        'blue': ['midnightblue', 'royalblue', 'mediumblue', 'blue', 'steelblue', 'cyan'],\n        'blue4': ['midnightblue', 'royalblue', 'mediumblue', 'deepskyblue'],\n        'blue5': ['firebrick', 'navy', 'mediumblue', 'royalblue', 'deepskyblue'],\n        'brown': ['maroon', 'firebrick', 'chocolate', 'sienna', 'sandybrown'],\n        'brown3': ['maroon', 'sienna', 'sandybrown'],\n        'brown4': ['maroon', 'sienna', 'chocolate', 'sandybrown'],\n        'brown5': ['maroon', 'sienna', 'chocolate', 'sandybrown', 'gold'],\n    }\n    \n    # Combine palettes for custom themes\n    palette_map['tes3'] = ['limegreen', 'magenta', 'red']\n    palette_map['tes3b'] = ['darkmagenta', 'magenta', 'red']\n    palette_map['tes5'] = ['mediumblue', 'crimson', 'crimson', 'crimson', 'mediumblue']\n    palette_map['tes6'] = ['limegreen'] + palette_map['brown']\n    palette_map['tes7'] = palette_map['brown4'] + ['mediumblue'] + ['crimson'] + ['red']\n    palette_map['tes8'] = palette_map['red4'] + palette_map['blue4']\n    palette_map['tes9'] = palette_map['red4'] + ['darkmagenta'] + palette_map['blue4']\n    palette_map['tes10'] = palette_map['brown'] + palette_map['green']\n    palette_map['tes11'] = palette_map['brown'] + palette_map['green'] + ['blue']\n    num_submissions = len(config_dict['subm'])\n    selected_colors = palette_map.get(theme_name, ['red', 'green', 'blue'])\n    \n    return selected_colors[0:num_submissions]\n\n\ndef create_interactive_plots(config, ensemble_result, color_list, \n                             display_plot1, display_plot2, width_param, highlight_color):\n    \"\"\"\n    Generate interactive Bokeh visualizations for model ensemble analysis.\n    Creates bar charts showing submission rankings and relationships.\n    \"\"\"\n    \n    def build_submission_profile(index, submission_list, column_data):\n        \"\"\"Build frequency distribution for a submission across sorted columns.\"\"\"\n        def compute_frequency(col_idx, row_idx, submissions, cols):\n            occurrences = sum(1 for item in cols[col_idx] if item == submissions[row_idx])\n            return {\"column_id\": col_idx, \"frequency\": occurrences}\n        \n        return {\n            'submission_name': submission_list[index],\n            'frequencies': [compute_frequency(i, index, submission_list, column_data) \n                          for i in range(len(submission_list))]\n        }\n    \n    # Load and parse the ranking data\n    ranking_data = pd.read_csv('tida_desc.csv')\n    ranking_matrix = [ast.literal_eval(str(row.alls)) for row in ranking_data.itertuples()]\n    submission_names = sorted(ranking_matrix[0])\n    \n    # Transpose matrix to get column-wise data\n    columns_transposed = [[data[i] for data in ranking_matrix] for i in range(len(submission_names))]\n    \n    # Build DataFrame for analysis\n    df_submissions = pd.DataFrame({\n        f'col_{i}': [x[i] for x in ranking_matrix] \n        for i in range(len(submission_names))\n    })\n    \n    # Generate profiles for each submission\n    submission_profiles = [build_submission_profile(j, submission_names, columns_transposed) \n                          for j in range(len(submission_names))]\n    \n    display_names = [profile['submission_name'] for profile in submission_profiles]\n    \n    # Create individual bar charts for each submission\n    plot_list = []\n    frequency_arrays = []\n    \n    # Calculate plot dimensions based on number of colors\n    if len(color_list) == 2:\n        plot_height = 85\n    elif len(color_list) == 3:\n        plot_height = 134\n    elif len(color_list) == 4:\n        plot_height = 154\n    else:\n        plot_height = 174\n    \n    for idx, profile in enumerate(submission_profiles):\n        chart_title = f'alls. {profile[\"frequencies\"][idx][\"column_id\"]}'\n        freq_values = [item['frequency'] for item in profile['frequencies']]\n        \n        # Clean up display names\n        x_labels = [name.replace(\"Group\", \"\").replace(\"subm_\", \"\") for name in display_names]\n        \n        # Determine width based on number of submissions\n        if len(color_list) == 5:\n            plot_width = 157\n        elif len(color_list) == 8:\n            plot_width = 121\n        elif len(color_list) == 9:\n            plot_width = 131\n        elif len(color_list) == 10:\n            plot_width = 141\n        elif len(color_list) == 11:\n            plot_width = 171\n        else:\n            plot_width = 133\n        \n        # Create bar chart\n        chart = figure(x_range=x_labels, width=plot_width, height=plot_height, title=chart_title)\n        chart.vbar(x=x_labels, width=0.585, top=freq_values, color=color_list)\n        \n        plot_list.append(chart)\n        frequency_arrays.append(freq_values)\n    \n    # Display first grid of plots\n    grid_layout = gridplot([plot_list])\n    output_file('tida_alls.html')\n    if display_plot1:\n        show(grid_layout)\n    \n    # Calculate weighted masses for submissions\n    adjustment_weights = config['subwts']\n    primary_weights = [sub['weight'] for sub in config['subm']]\n    \n    weighted_masses = []\n    total_masses = []\n    \n    for j in range(len(submission_profiles)):\n        profile = submission_profiles[j]\n        frequencies = [item['frequency'] for item in profile['frequencies']]\n        \n        # Apply dual weighting system\n        mass_components = [\n            frequencies[h] * (primary_weights[j] + adjustment_weights[h]) \n            for h in range(len(adjustment_weights))\n        ]\n        total_mass = sum(mass_components)\n        \n        weighted_masses.append(mass_components)\n        total_masses.append(round(total_mass))\n    \n    # Create horizontal bar chart for total masses\n    y_labels_with_mass = [f\"{name} - {mass}\" \n                         for name, mass in zip(display_names, total_masses)]\n    \n    chart1 = figure(y_range=y_labels_with_mass, width=313, height=plot_height, \n                   title='relations of general masses')\n    chart1.hbar(y=y_labels_with_mass, height=0.585, right=total_masses, left=0, color=color_list)\n    output_file('tida_alls2.html')\n    \n    # Create stacked horizontal bar charts\n    column_labels = [f'alls.{i}' for i in range(len(submission_profiles))]\n    submission_keys = [f'sub{i}' for i in range(len(submission_profiles))]\n    \n    # Prepare data for mass distribution chart\n    masses_transposed = np.asarray(weighted_masses).T\n    mass_data = {'cols': column_labels}\n    for i in range(len(submission_profiles)):\n        mass_data[f'sub{i}'] = masses_transposed[i, :]\n    \n    chart2 = figure(y_range=column_labels, height=plot_height, width=274, \n                   title=\" ( relations of columns masses )\")\n    chart2.hbar_stack(submission_keys, y='cols', height=0.585, \n                     color=color_list, source=mass_data)\n    \n    # Prepare data for frequency ratio chart\n    frequencies_transposed = np.asarray(frequency_arrays).T\n    freq_data = {'cols': column_labels}\n    for i in range(len(submission_profiles)):\n        freq_data[f'sub{i}'] = frequencies_transposed[i, :]\n    \n    chart3 = figure(y_range=column_labels, height=plot_height, width=215, \n                   title=\"ratios in columns\")\n    chart3.hbar_stack(submission_keys, y='cols', height=0.585, \n                     color=color_list, source=freq_data)\n    \n    # Display combined charts\n    combined_grid = gridplot([[chart3, chart2, chart1]])\n    show(combined_grid)\n    \n    # Create time series comparison plot if requested\n    if display_plot2:\n        def load_submission_file(params, index):\n            filename = params[\"path\"] + params[\"subm\"][index][\"name\"] + \".csv\"\n            column_mapping = {'target': params[\"target\"], 'pred': params[\"target\"]}\n            return pd.read_csv(filename).rename(columns=column_mapping)\n        \n        # Load all submission files plus ensemble result\n        dataframes = [load_submission_file(config, i) \n                     for i in range(len(config[\"subm\"]))] + [ensemble_result]\n        \n        # Create line plot\n        line_chart = figure(width=800, height=254)\n        line_chart.title.text = 'Click on legend entries to mute the corresponding lines'\n        \n        # Select sample range for visualization\n        start_idx, end_idx = 21000, 21121\n        \n        # Extract x and y data for each submission\n        x_data = [df[start_idx:end_idx]['id'] for df in dataframes]\n        y_data = [df[start_idx:end_idx]['loan_paid_back'] for df in dataframes]\n        \n        # Configure visual properties\n        line_colors = color_list + [highlight_color]\n        alpha_values = [0.8] * (len(dataframes) - 1) + [0.95]\n        line_widths = [1.0] * (len(dataframes) - 1) + [1.00]\n        legend_labels = display_names + ['cross']\n        \n        # Add lines to chart\n        for i in range(len(legend_labels)):\n            line_chart.line(x_data[i], y_data[i], line_width=line_widths[i], \n                          color=line_colors[i], alpha=alpha_values[i],\n                          muted_color='white', legend_label=legend_labels[i])\n        \n        line_chart.legend.location = \"top_left\"\n        line_chart.legend.click_policy = \"mute\"\n        show(line_chart)\n\n\ndef weighted_ensemble_blend(config, color_theme, cross_color='silver',\n                            show_plot1=False, show_plot2=False, width_fig2=555,\n                            show_details=False):\n    \"\"\"\n    Main ensemble function that combines multiple predictions using weighted blending.\n    Supports both ascending and descending sort strategies with configurable weights.\n    \"\"\"\n    \n    # Initialize configuration\n    working_config = copy.deepcopy(config)\n    \n    # Parse configuration parameters\n    sort_strategy = config['type_sort'][0]\n    working_config['asc'] = config['type_sort'][1]\n    working_config['desc'] = config['type_sort'][2]\n    working_config['id'] = config['id_target'][0]\n    working_config['target'] = config['id_target'][1]\n    \n    # Helper function to load individual submission files\n    def load_submission(cfg, index):\n        submission_name = cfg[\"subm\"][index][\"name\"]\n        file_path = cfg[\"path\"] + submission_name + \".csv\"\n        \n        # Rename columns to use submission name as identifier\n        column_rename = {\n            'target': submission_name,\n            'pred': submission_name,\n            cfg[\"target\"]: submission_name\n        }\n        return pd.read_csv(file_path).rename(columns=column_rename)\n    \n    # Merge all submissions on ID column\n    def merge_submissions(submission_dfs):\n        merged_df = pd.merge(submission_dfs[0], submission_dfs[1], \n                            on=[working_config['id']])\n        \n        for i in range(2, len(working_config[\"subm\"])):\n            merged_df = pd.merge(merged_df, submission_dfs[i], \n                                on=[working_config['id']])\n        return merged_df\n    \n    # Core blending algorithm with directional sorting\n    def apply_directional_blend(cfg, sort_direction, show_info):\n        \"\"\"\n        Apply weighted blending with specified sort direction.\n        Sorts predictions and applies position-based weights.\n        \"\"\"\n        \n        # Load and merge all submissions\n        merged_data = merge_submissions([load_submission(cfg, i) \n                                        for i in range(len(cfg[\"subm\"]))])\n        \n        # Get prediction columns (exclude ID)\n        pred_columns = [col for col in merged_data.columns if col != cfg['id']]\n        short_names = [c for c in pred_columns]\n        \n        # Define sorting function\n        def sort_predictions_desc_asc(row, direction=sort_direction, cols=pred_columns):\n            \"\"\"Sort predictions for each row by value.\"\"\"\n            use_reverse = True if direction == 'desc' else False\n            value_dict = {c: row[c] for c in cols}\n            sorted_names = [item[0] for item in sorted(value_dict.items(), \n                                                       key=lambda k: k[1], \n                                                       reverse=use_reverse)]\n            return sorted_names\n        \n        def randomize_predictions(row, direction=sort_direction, cols=pred_columns):\n            \"\"\"Alternative strategy: randomize prediction order.\"\"\"\n            value_dict = {c: row[c] for c in cols}\n            name_list = [item[0] for item in value_dict.items()]\n            random.shuffle(name_list)\n            return name_list\n        \n        # Select sorting strategy\n        if sort_strategy == 'asc/desc':\n            sort_function = sort_predictions_desc_asc\n        else:\n            sort_function = randomize_predictions\n        \n        # Extract weights from configuration\n        primary_weights = [entry['weight'] for entry in cfg[\"subm\"]]\n        position_weights = [w for w in cfg[\"subwts\"]]\n        \n        # Calculate weighted sum based on position in sorted order\n        def calculate_weighted_prediction(row, cols=pred_columns, \n                                         w_primary=primary_weights, \n                                         w_position=position_weights):\n            \"\"\"\n            Compute final prediction using dual weighting:\n            - Primary weight: based on submission quality\n            - Position weight: based on rank in sorted order\n            \"\"\"\n            position_indices = [row['alls'].index(c) for c in short_names]\n            weighted_values = [\n                row[pred_columns[j]] * (w_primary[j] + w_position[position_indices[j]]) \n                for j in range(len(pred_columns))\n            ]\n            return sum(weighted_values)\n        \n        # Calculate prediction spread (max - min)\n        def calculate_spread(row, cols=pred_columns):\n            \"\"\"Measure disagreement between predictions.\"\"\"\n            values = row[cols].to_list()\n            return abs(max(values) - min(values))\n        \n        # Apply transformations\n        merged_data['alls'] = merged_data.apply(lambda x: sort_function(x), axis=1)\n        merged_data[cfg[\"target\"]] = merged_data.apply(\n            lambda x: calculate_weighted_prediction(x), axis=1)\n        \n        # Rename columns for clarity\n        merged_data = merged_data.rename(columns={cfg[\"target\"]: \"ensemble\"})\n        \n        # Add separator columns for display\n        merged_data.insert(loc=1, column=' _ ', value=['   '] * len(merged_data))\n        merged_data[' _ '] = merged_data[' _ '].astype(str)\n        \n        # Configure pandas display options\n        pd.set_option('display.max_rows', 100)\n        pd.set_option('display.float_format', '{:.5f}'.format)\n        \n        # Select columns for display\n        display_cols = ([cfg['id']] + [' _ '] + short_names + \n                       [' _ '] + ['alls'] + [' _ '] + ['ensemble'])\n        merged_data = merged_data[display_cols]\n        \n        # Show sample if requested\n        if show_info and sort_direction == 'desc':\n            display(merged_data.head(5))\n        \n        # Save intermediate results\n        merged_data = merged_data.rename(columns={\"ensemble\": cfg[\"target\"]})\n        merged_data.to_csv(f'tida_{sort_direction}.csv', index=False)\n        \n        return merged_data[[cfg['id'], cfg['target']]]\n    \n    # Combine ascending and descending strategies\n    def create_bidirectional_ensemble(cfg, show_info):\n        \"\"\"\n        Create ensemble by combining desc and asc sorted predictions.\n        Weights the two strategies according to configuration.\n        \"\"\"\n        result_desc = apply_directional_blend(cfg, 'desc', show_info)\n        result_asc = apply_directional_blend(cfg, 'asc', show_info)\n        \n        # Blend the two strategies\n        result_asc[cfg['target']] = (cfg['desc'] * result_desc[cfg['target']] + \n                                     result_asc[cfg['target']] * cfg['asc'])\n        return result_asc\n    \n    # Execute ensemble creation\n    final_ensemble = create_bidirectional_ensemble(working_config, show_details)\n    \n    # Generate visualizations\n    color_palette = get_visualization_colors(working_config, color_theme)\n    create_interactive_plots(working_config, final_ensemble, color_palette, \n                           show_plot1, show_plot2, width_fig2, cross_color)\n    \n    return final_ensemble\n\n\ndef compute_pairwise_distances(file_path, submission_names):\n    \"\"\"\n    Calculate pairwise prediction distances between all submissions.\n    Returns a matrix showing divergence between each pair of predictions.\n    \"\"\"\n    \n    def load_all_submissions(path, names):\n        \"\"\"Load all submission files and merge them.\"\"\"\n        dataframes = [pd.read_csv(path + name + '.csv') for name in names]\n        \n        # Rename target column to submission name\n        for i in range(len(dataframes)):\n            dataframes[i] = dataframes[i].rename(\n                columns={\"loan_paid_back\": f'{names[i]}'})\n        \n        # Merge all dataframes on ID\n        merged = pd.merge(dataframes[0], dataframes[1], on=\"id\")\n        for i in range(2, len(dataframes)):\n            merged = pd.merge(merged, dataframes[i], on='id')\n        \n        return merged\n    \n    def generate_comparison_pairs(names):\n        \"\"\"Create list of all pairwise comparisons.\"\"\"\n        pairs = []\n        for i in range(len(names) - 1):\n            for j in range(i + 1, len(names)):\n                pairs.append(f\"{names[i]}_vs_{names[j]}\")\n        return pairs\n    \n    def calculate_all_distances(df, pair_list):\n        \"\"\"Compute absolute distance for each pair of predictions.\"\"\"\n        def get_absolute_diff(row, name1, name2):\n            return abs(row[name1] - row[name2])\n        \n        for pair in pair_list:\n            names = pair.split('_vs_')\n            df[pair] = df.apply(\n                lambda x: get_absolute_diff(x, names[0], names[1]), axis=1)\n        \n        return df\n    \n    def extract_distances_for_submission(target_name, all_names, pairs, df):\n        \"\"\"Get total distance from target to all other submissions.\"\"\"\n        distance_list = []\n        \n        for name in all_names:\n            pair_key = f\"{target_name}_vs_{name}\"\n            \n            if pair_key not in pairs:\n                distance_list.append(0)\n            else:\n                distance_list.append(round(df[pair_key].sum()))\n        \n        return distance_list\n    \n    # Execute distance calculations\n    merged_df = load_all_submissions(file_path, submission_names)\n    comparison_pairs = generate_comparison_pairs(submission_names)\n    distance_df = calculate_all_distances(merged_df, comparison_pairs)\n    \n    # Build distance matrix\n    names_column = pd.DataFrame({'subm': submission_names})\n    distance_columns = pd.DataFrame({\n        name: extract_distances_for_submission(name, submission_names, \n                                               comparison_pairs, distance_df)\n        for name in submission_names\n    })\n    \n    distance_matrix = pd.concat([names_column, distance_columns], axis=1)\n    return distance_matrix\n\n\ndef show_submission_distances(config):\n    \"\"\"Display pairwise distance matrix for all submissions in config.\"\"\"\n    submission_list = [sub['name'] for sub in config['subm']]\n    dist_matrix = compute_pairwise_distances(config['path'], submission_list)\n    display(dist_matrix)\n\n\ndef simple_weighted_blend(dataframe_1, dataframe_2, weights=[0.50, 0.50], \n                          output_file='submission.csv'):\n    \"\"\"\n    Perform simple weighted average of two prediction dataframes.\n    Useful for quick blending of two models.\n    \"\"\"\n    target_col = 'loan_paid_back'\n    dataframe_1[target_col] = (dataframe_1[target_col] * weights[0] + \n                               dataframe_2[target_col] * weights[1])\n    dataframe_1.to_csv(output_file, index=False)\n    print(f'{output_file} - ready to use')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-09T10:13:49.143938Z","iopub.execute_input":"2025-11-09T10:13:49.144266Z","iopub.status.idle":"2025-11-09T10:13:51.652329Z","shell.execute_reply.started":"2025-11-09T10:13:49.144242Z","shell.execute_reply":"2025-11-09T10:13:51.651239Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Third configuration - different model selection\n# Using model 0.92712 instead of 0.92661 with reversed color scheme\nensemble_config_v3 = {\n    'path': f\"/kaggle/input/9-november-2025-ps-s5e11/submission \",            \n    'id_target': ['id', \"loan_paid_back\"],          \n    'type_sort': ['asc/desc', 0.33, 0.66],  # Back to 30/70 split\n    'subwts': [+0.11, -0.01, -0.03, -0.07],  # Position weights unchanged\n    'subm': [    \n        {'name': f'0.92694', 'weight': +0.07},    # Model 2 - darkgreen in viz\n        {'name': f'0.92698', 'weight': +0.07},    # Model 3 - forestgreen in viz\n        {'name': f'0.92712', 'weight': +0.07},    # Different model - crimson in viz\n        {'name': f'0.92732', 'weight': +0.79},    # Model 4 - limegreen (dominant)\n    ]\n}\n\nfinal_predictions_v3 = weighted_ensemble_blend(\n    ensemble_config_v3, \n    color_theme='alls4r',\n    show_plot1=True, \n    show_plot2=True, \n    show_details=True\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-09T10:14:16.738603Z","iopub.execute_input":"2025-11-09T10:14:16.738908Z","iopub.status.idle":"2025-11-09T10:14:48.397239Z","shell.execute_reply.started":"2025-11-09T10:14:16.738886Z","shell.execute_reply":"2025-11-09T10:14:48.396304Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"final_predictions_v3.to_csv('submission.csv', index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-09T10:14:50.379404Z","iopub.execute_input":"2025-11-09T10:14:50.380051Z","iopub.status.idle":"2025-11-09T10:14:50.946563Z","shell.execute_reply.started":"2025-11-09T10:14:50.380013Z","shell.execute_reply":"2025-11-09T10:14:50.94566Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}