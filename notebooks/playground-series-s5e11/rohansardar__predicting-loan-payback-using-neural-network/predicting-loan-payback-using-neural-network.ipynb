{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":91722,"databundleVersionId":14262372,"sourceType":"competition"}],"dockerImageVersionId":31153,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# <p style=\"background-image: url(https://thumb.ac-illust.com/ef/efba71f003602d81b40951d0040bbab0_t.jpeg);font-family:consolas;font-size:120%;color:#ffffff;text-align:center;border-radius:20px 20px; padding:5px;\"> About </p>","metadata":{}},{"cell_type":"markdown","source":"This notebook is created for participation in the “Predicting Loan Payback” Playground Prediction Competition on Kaggle. The objective is to build a **PyTorch** model that predicts whether a client will subscribe to a bank term deposit, based on their personal and financial attributes.","metadata":{}},{"cell_type":"markdown","source":"# <p style=\"background-image: url(https://thumb.ac-illust.com/ef/efba71f003602d81b40951d0040bbab0_t.jpeg);font-family:consolas;font-size:120%;color:#ffffff;text-align:center;border-radius:20px 20px; padding:5px\"> Imports </p>","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport math\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import roc_auc_score\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import TensorDataset\nfrom torch.utils.data import DataLoader\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-08T12:12:04.558746Z","iopub.execute_input":"2025-11-08T12:12:04.559093Z","iopub.status.idle":"2025-11-08T12:12:09.351527Z","shell.execute_reply.started":"2025-11-08T12:12:04.559068Z","shell.execute_reply":"2025-11-08T12:12:09.35094Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# <p style=\"background-image: url(https://thumb.ac-illust.com/ef/efba71f003602d81b40951d0040bbab0_t.jpeg);font-family:consolas;font-size:120%;color:#ffffff;text-align:center;border-radius:20px 20px; padding:5px\"> Reading Data </p>","metadata":{}},{"cell_type":"code","source":"train = pd.read_csv(\"/kaggle/input/playground-series-s5e11/train.csv\", index_col=\"id\")\ntest = pd.read_csv(\"/kaggle/input/playground-series-s5e11/test.csv\", index_col=\"id\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-08T12:12:09.352652Z","iopub.execute_input":"2025-11-08T12:12:09.35304Z","iopub.status.idle":"2025-11-08T12:12:10.945337Z","shell.execute_reply.started":"2025-11-08T12:12:09.353021Z","shell.execute_reply":"2025-11-08T12:12:10.944522Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-08T12:12:10.945981Z","iopub.execute_input":"2025-11-08T12:12:10.946208Z","iopub.status.idle":"2025-11-08T12:12:10.967523Z","shell.execute_reply.started":"2025-11-08T12:12:10.946191Z","shell.execute_reply":"2025-11-08T12:12:10.966835Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Checking for `null` values in the dataset.","metadata":{}},{"cell_type":"code","source":"train.isna().sum()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-08T12:12:10.968396Z","iopub.execute_input":"2025-11-08T12:12:10.968589Z","iopub.status.idle":"2025-11-08T12:12:11.12929Z","shell.execute_reply.started":"2025-11-08T12:12:10.968575Z","shell.execute_reply":"2025-11-08T12:12:11.128481Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test.isna().sum()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-08T12:12:11.131301Z","iopub.execute_input":"2025-11-08T12:12:11.131516Z","iopub.status.idle":"2025-11-08T12:12:11.205085Z","shell.execute_reply.started":"2025-11-08T12:12:11.1315Z","shell.execute_reply":"2025-11-08T12:12:11.204522Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Selecting the `categorical_cols` and the `numerical_cols` from the dataset.","metadata":{}},{"cell_type":"code","source":"categorical_cols = test.select_dtypes(include=['object']).columns\nnumerical_cols = test.select_dtypes(include=['int64', 'float64']).columns\n\nprint(f\"The categorical value columns are: {categorical_cols.values}\")\nprint(f\"The numerical value columns are: {numerical_cols.values}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-08T12:12:11.205672Z","iopub.execute_input":"2025-11-08T12:12:11.205897Z","iopub.status.idle":"2025-11-08T12:12:11.220603Z","shell.execute_reply.started":"2025-11-08T12:12:11.205877Z","shell.execute_reply":"2025-11-08T12:12:11.219898Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# <p style=\"background-image: url(https://thumb.ac-illust.com/ef/efba71f003602d81b40951d0040bbab0_t.jpeg);font-family:consolas;font-size:120%;color:#ffffff;text-align:center;border-radius:20px 20px; padding:5px\"> Visualizations </p>","metadata":{}},{"cell_type":"markdown","source":"The following plot shows the count of **loan_paid_back**.","metadata":{"execution":{"iopub.status.busy":"2025-11-01T04:01:59.65494Z","iopub.status.idle":"2025-11-01T04:01:59.655223Z","shell.execute_reply.started":"2025-11-01T04:01:59.655103Z","shell.execute_reply":"2025-11-01T04:01:59.655116Z"}}},{"cell_type":"code","source":"y_counts = train['loan_paid_back'].value_counts()\nplt.figure(figsize=(4, 4))\n\ncmap = plt.get_cmap('flare')\ncolors = cmap(np.linspace(0, 1, len(y_counts)))\n\nplt.pie(\n    y_counts.values,\n    labels=y_counts.index,\n    autopct='%1.1f%%',\n    colors=colors,\n    startangle=90,\n    counterclock=False,\n    textprops={'color': 'white'}\n)\nplt.title('Distribution of loan_paid_back')\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-08T12:12:11.221381Z","iopub.execute_input":"2025-11-08T12:12:11.221611Z","iopub.status.idle":"2025-11-08T12:12:11.388183Z","shell.execute_reply.started":"2025-11-08T12:12:11.221587Z","shell.execute_reply":"2025-11-08T12:12:11.387425Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Visualize the distribution of each categorical feature in relation to the target variable `loan_paid_back` using count plots.","metadata":{}},{"cell_type":"code","source":"n_plots = len(categorical_cols)\ncols_per_row = math.ceil(n_plots / 2)\n\nplt.figure(figsize=(5 * cols_per_row, 10))\n\nfor i, col in enumerate(categorical_cols, 1):\n    plt.subplot(3, cols_per_row, i)\n    sns.countplot(x=col, hue='loan_paid_back', data=train, palette='mako')\n    plt.title(f\"{col} vs loan_paid_back count\")\n    plt.xticks(rotation=90)\n\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-08T12:12:11.388849Z","iopub.execute_input":"2025-11-08T12:12:11.389045Z","iopub.status.idle":"2025-11-08T12:12:14.549407Z","shell.execute_reply.started":"2025-11-08T12:12:11.389028Z","shell.execute_reply":"2025-11-08T12:12:14.548621Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Visualize the distribution of each numerical feature in relation to the target variable `y` using histogram plots.","metadata":{}},{"cell_type":"code","source":"n_plots = len(numerical_cols)\ncols_per_row = math.ceil(n_plots / 2)\n\nplt.figure(figsize=(5 * cols_per_row, 10))\n\nfor i, col in enumerate(numerical_cols, 1):\n    plt.subplot(3, cols_per_row, i)\n    sns.histplot(x=col, hue='loan_paid_back', data=train, fill=True, palette='mako', bins=30)\n    plt.title(f\"{col} vs loan_paid_back count\")\n\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-08T12:12:14.550225Z","iopub.execute_input":"2025-11-08T12:12:14.550461Z","iopub.status.idle":"2025-11-08T12:12:16.916481Z","shell.execute_reply.started":"2025-11-08T12:12:14.550444Z","shell.execute_reply":"2025-11-08T12:12:16.91574Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# <p style=\"background-image: url(https://thumb.ac-illust.com/ef/efba71f003602d81b40951d0040bbab0_t.jpeg);font-family:consolas;font-size:120%;color:#ffffff;text-align:center;border-radius:20px 20px; padding:5px\"> Data Preprocessing </p>","metadata":{}},{"cell_type":"markdown","source":"`LabelEncoder` is used to encode the categorical values.","metadata":{}},{"cell_type":"code","source":"encoder = LabelEncoder()\nfor i in categorical_cols:\n    train[i] = encoder.fit_transform(train[i])\n    test[i] = encoder.transform(test[i])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-08T12:12:16.917339Z","iopub.execute_input":"2025-11-08T12:12:16.917986Z","iopub.status.idle":"2025-11-08T12:12:17.637126Z","shell.execute_reply.started":"2025-11-08T12:12:16.917961Z","shell.execute_reply":"2025-11-08T12:12:17.63653Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"`MinMaxScaler` is used to scale the values before feeding into the neural network.","metadata":{}},{"cell_type":"code","source":"scaler = MinMaxScaler()\ntrain[numerical_cols] = scaler.fit_transform(train[numerical_cols])\ntest[numerical_cols] = scaler.transform(test[numerical_cols])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-08T12:12:17.637882Z","iopub.execute_input":"2025-11-08T12:12:17.638174Z","iopub.status.idle":"2025-11-08T12:12:17.716986Z","shell.execute_reply.started":"2025-11-08T12:12:17.638113Z","shell.execute_reply":"2025-11-08T12:12:17.716192Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"The dataset is partitioned into feature matrix **X** and target vector **y** to prepare it for model training.","metadata":{}},{"cell_type":"code","source":"X = train.drop('loan_paid_back', axis=1)\ny = train['loan_paid_back']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-08T12:12:17.717895Z","iopub.execute_input":"2025-11-08T12:12:17.718167Z","iopub.status.idle":"2025-11-08T12:12:17.749882Z","shell.execute_reply.started":"2025-11-08T12:12:17.718123Z","shell.execute_reply":"2025-11-08T12:12:17.749085Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Using `train_test_split` to split the **X** and **y** for training the model.","metadata":{}},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=21, stratify=y)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-08T12:12:17.750694Z","iopub.execute_input":"2025-11-08T12:12:17.750943Z","iopub.status.idle":"2025-11-08T12:12:18.035998Z","shell.execute_reply.started":"2025-11-08T12:12:17.75092Z","shell.execute_reply":"2025-11-08T12:12:18.035277Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"`CUDA` is set up for faster training.","metadata":{}},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(f'Using device: {device}')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-08T12:12:18.038741Z","iopub.execute_input":"2025-11-08T12:12:18.038972Z","iopub.status.idle":"2025-11-08T12:12:18.098585Z","shell.execute_reply.started":"2025-11-08T12:12:18.038954Z","shell.execute_reply":"2025-11-08T12:12:18.09794Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Converting from `pandas.core.frame.DataFrame` to `torch.Tensor`.","metadata":{}},{"cell_type":"code","source":"X_train_tensor = torch.tensor(X_train.values.astype(np.float32)).to(device)\ny_train_tensor = torch.tensor(y_train.values.astype(np.float32)).unsqueeze(1).to(device)\n\nX_val_tensor = torch.tensor(X_test.values.astype(np.float32)).to(device)\ny_val_tensor = torch.tensor(y_test.values.astype(np.float32)).unsqueeze(1).to(device)\n\nX_test_tensor = torch.tensor(test.values.astype(np.float32)).to(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-08T12:12:18.099436Z","iopub.execute_input":"2025-11-08T12:12:18.100131Z","iopub.status.idle":"2025-11-08T12:12:18.355794Z","shell.execute_reply.started":"2025-11-08T12:12:18.100105Z","shell.execute_reply":"2025-11-08T12:12:18.355107Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Setting up the `DataLoaders` from the tensors.","metadata":{}},{"cell_type":"code","source":"train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\nval_dataset = TensorDataset(X_val_tensor, y_val_tensor)\n\ntrain_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-08T12:12:18.356645Z","iopub.execute_input":"2025-11-08T12:12:18.356935Z","iopub.status.idle":"2025-11-08T12:12:18.361815Z","shell.execute_reply.started":"2025-11-08T12:12:18.356908Z","shell.execute_reply":"2025-11-08T12:12:18.36102Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# <p style=\"background-image: url(https://thumb.ac-illust.com/ef/efba71f003602d81b40951d0040bbab0_t.jpeg);font-family:consolas;font-size:120%;color:#ffffff;text-align:center;border-radius:20px 20px; padding:5px\"> Model Training </p>","metadata":{}},{"cell_type":"markdown","source":"The architecture is designed to balance expressive power with regularization, ensuring strong generalization on tabular data.\n\n#### Layer Breakdown\n- **Input Layer**: Accepts `input_dim` features.\n- **Hidden Layer 1**: \n  - `Linear(input_dim → 256)`\n  - `BatchNorm1d(256)`\n  - `LeakyReLU`\n  - `Dropout(0.3)`\n- **Hidden Layer 2**:\n  - `Linear(256 → 128)`\n  - `BatchNorm1d(128)`\n  - `ELU`\n  - `Dropout(0.3)`\n- **Hidden Layer 3**:\n  - `Linear(64 → 32)`\n  - `BatchNorm1d(32)`\n  - `ReLU`\n  - `Dropout(0.2)`\n- **Hidden Layer 4**:\n  - `Linear(64 → 32)`\n  - `BatchNorm1d(32)`\n  - `ReLU`\n- **Output Layer**:\n  - `Linear(32 → 1)` → Outputs raw logits for binary classification\n\n#### Design Rationale\n- **Batch Normalization** stabilizes training and accelerates convergence.\n- **LeakyReLU** mitigates dying neuron issues in early layers.\n- **Dropout** adds regularization to prevent overfitting.\n- **Final ReLU** introduces non-linearity before the output layer.\n\nThis architecture is optimized for tabular datasets and integrates well with `BCEWithLogitsLoss`, which expects raw logits as input.","metadata":{}},{"cell_type":"code","source":"class BinaryClassifier(nn.Module):\n    def __init__(self, input_dim):\n        super(BinaryClassifier, self).__init__()\n        self.net = nn.Sequential(\n            nn.Linear(input_dim, 256),\n            nn.BatchNorm1d(256),\n            nn.LeakyReLU(),\n            nn.Dropout(0.3),\n            nn.Linear(256, 128),\n            nn.BatchNorm1d(128),\n            nn.ELU(),\n            nn.Dropout(0.3),\n            nn.Linear(128, 64),\n            nn.BatchNorm1d(64),\n            nn.ReLU(),\n            nn.Dropout(0.2),\n            nn.Linear(64, 32),\n            nn.ReLU(),\n            nn.Linear(32, 1)\n        )\n        \n    def forward(self, x):\n        return self.net(x)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-08T12:12:18.362712Z","iopub.execute_input":"2025-11-08T12:12:18.362944Z","iopub.status.idle":"2025-11-08T12:12:18.377935Z","shell.execute_reply.started":"2025-11-08T12:12:18.362928Z","shell.execute_reply":"2025-11-08T12:12:18.377326Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"The model is trained with a weighted loss function to handle class imbalance, and a learning rate scheduler is used to adaptively reduce the learning rate based on validation performance.\n\n**Key Components:**\n- `BinaryClassifier`: A 4-layer feedforward neural network with BatchNorm, LeakyReLU, and Dropout.\n- `BCEWithLogitsLoss`: Weighted using `pos_weight` to address class imbalance.\n- `Adam Optimizer`: Initialized with a learning rate of `0.005`.\n- `ReduceLROnPlateau`: Monitors ROC AUC and reduces LR by half if no improvement for 5 epochs.\n\nThis setup ensures robust training while preventing overfitting and stagnation in learning.","metadata":{}},{"cell_type":"code","source":"model = BinaryClassifier(input_dim=X_train.shape[1]).to(device)\nnum_neg = (y_train == 0).sum()\nnum_pos = (y_train == 1).sum()\npos_weight_value = num_neg / num_pos\npos_weight = torch.tensor([pos_weight_value]).to(device)\ncriterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\noptimizer = torch.optim.Adam(model.parameters(), lr=0.005)\nscheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n    optimizer, mode='max', factor=0.5, patience=5, verbose=True\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-08T12:12:18.378735Z","iopub.execute_input":"2025-11-08T12:12:18.379009Z","iopub.status.idle":"2025-11-08T12:12:20.912516Z","shell.execute_reply.started":"2025-11-08T12:12:18.378987Z","shell.execute_reply":"2025-11-08T12:12:20.911946Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Train the `BinaryClassifier` using a standard supervised learning loop with performance tracking and early stopping. The model is evaluated every epoch on both training and validation sets, with metrics logged for analysis.\n\n#### Epoch-wise Training\n- **Loss Function**: `BCEWithLogitsLoss` with `pos_weight` to handle class imbalance.\n- **Optimizer**: Adam with initial LR = 0.005.\n- **Scheduler**: `ReduceLROnPlateau` monitors ROC AUC and reduces LR if no improvement for 5 epochs.\n\n#### Metrics Tracked\n- `Train/Val Loss`\n- `Train/Val Accuracy`\n- `Validation ROC AUC`\n\n#### Early Stopping\n- Monitors best ROC AUC.\n- Stops training if no improvement for **20 consecutive epochs**.\n\n#### Highlights\n- Predictions are thresholded at 0.5 after applying `sigmoid`.\n- ROC AUC is computed using raw probabilities for better discrimination.\n- Model weights are saved when ROC AUC improves.\n\nThis setup ensures efficient training while guarding against overfitting and learning stagnation.","metadata":{}},{"cell_type":"code","source":"best_auc = 0.0\npatience = 20\ncounter = 0\nnum_epochs = 200\ntrain_losses = []\nval_losses = []\ntrain_accuracies = []\nval_accuracies = []\nroc_aucs = []\n\nfor epoch in range(num_epochs):\n    model.train()\n    running_loss = 0.0\n    correct = 0\n    total = 0\n    for batch_X, batch_y in train_loader:\n        batch_X = batch_X.to(device)\n        batch_y = batch_y.to(device)\n        optimizer.zero_grad()\n        logits = model(batch_X)\n        loss = criterion(logits, batch_y)\n        loss.backward()\n        optimizer.step()\n        running_loss += loss.item() * batch_X.size(0)\n        preds = (torch.sigmoid(logits) > 0.5).float()\n        correct += (preds == batch_y).sum().item()\n        total += batch_y.size(0)\n    epoch_train_loss = running_loss / total\n    epoch_train_accuracy = correct / total\n    train_losses.append(epoch_train_loss)\n    train_accuracies.append(epoch_train_accuracy)\n\n    model.eval()\n    val_running_loss = 0.0\n    val_correct = 0\n    val_total = 0\n    all_preds = []\n    all_labels = []\n    with torch.no_grad():\n        for batch_X, batch_y in val_loader:\n            batch_X = batch_X.to(device)\n            batch_y = batch_y.to(device)\n            logits = model(batch_X)\n            loss = criterion(logits, batch_y)\n            val_running_loss += loss.item() * batch_X.size(0)\n            probs = torch.sigmoid(logits)\n            preds = (probs > 0.5).float()\n            all_preds.extend(probs.squeeze().cpu().numpy())\n            all_labels.extend(batch_y.squeeze().cpu().numpy())\n\n            val_correct += (preds == batch_y).sum().item()\n            val_total += batch_y.size(0)\n\n    epoch_val_loss = val_running_loss / val_total\n    epoch_val_accuracy = val_correct / val_total\n    val_losses.append(epoch_val_loss)\n    val_accuracies.append(epoch_val_accuracy)\n    \n    roc_auc = roc_auc_score(all_labels, all_preds)\n    roc_aucs.append(roc_auc)\n    scheduler.step(roc_auc)\n    if ((epoch+1)%5 == 0):\n        print(f\"Epoch {epoch+1}: Train_Loss={epoch_train_loss:.4f}, Val_Loss={epoch_val_loss:.4f}, \"\n          f\"Train_Acc={epoch_train_accuracy:.4f}, Val_Acc={epoch_val_accuracy:.4f}, ROC_AUC={roc_auc:.4f}\")\n        for param_group in optimizer.param_groups:\n            print(f\"Current LR: {param_group['lr']}\")\n\n    if roc_auc > best_auc:\n        best_auc = roc_auc\n        best_model_state = model.state_dict()\n        counter = 0\n    else:\n        counter += 1\n        if counter >= patience:\n            print(\"Early stopping.\")\n            break","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-08T12:12:20.913226Z","iopub.execute_input":"2025-11-08T12:12:20.913558Z","execution_failed":"2025-11-08T12:12:37.863Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### Training Metrics Visualization\n\nTo monitor model performance across epochs, we plot the following metrics:\n\n#### What We Track\n- **Loss**: Measures prediction error for both training and validation sets.\n- **Accuracy**: Percentage of correct predictions.\n- **ROC AUC**: Evaluates classification quality, especially for imbalanced data.\n\n#### Visualization Details\n- Color palette: `Paired` from Matplotlib for clear contrast.\n- Layout: 3 side-by-side subplots for easy comparison.\n- Epochs: X-axis spans from 1 to the final training epoch.\n\n#### Insights\n- **Loss Trends**: Helps detect overfitting or underfitting.\n- **Accuracy Curves**: Useful for gauging generalization.\n- **ROC AUC Curve**: Key metric for binary classification robustness.\n\nThis visual summary provides a quick diagnostic of training dynamics and helps guide model tuning decisions.\n","metadata":{}},{"cell_type":"code","source":"epochs = range(1, len(train_losses) + 1)\n\nplt.figure(figsize=(15, 4))\ncmap = plt.get_cmap('Paired')\n\nplt.subplot(1, 3, 1)\nplt.plot(epochs, train_losses, label='Train Loss', color=cmap(0))\nplt.plot(epochs, val_losses, label='Val Loss', color=cmap(1))\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.title('Loss per Epoch')\nplt.legend()\n\nplt.subplot(1, 3, 2)\nplt.plot(epochs, train_accuracies, label='Train Acc', color=cmap(2))\nplt.plot(epochs, val_accuracies, label='Val Acc', color=cmap(3))\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.title('Accuracy per Epoch')\nplt.legend()\n\nplt.subplot(1, 3, 3)\nplt.plot(epochs, roc_aucs, label='Val ROC AUC', color=cmap(4))\nplt.xlabel('Epoch')\nplt.ylabel('ROC AUC')\nplt.title('ROC AUC per Epoch')\nplt.legend()\n\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true,"execution":{"execution_failed":"2025-11-08T12:12:37.864Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# <p style=\"background-image: url(https://thumb.ac-illust.com/ef/efba71f003602d81b40951d0040bbab0_t.jpeg);font-family:consolas;font-size:120%;color:#ffffff;text-align:center;border-radius:20px 20px; padding:5px\"> Inference </p>","metadata":{}},{"cell_type":"markdown","source":"Loading the *best* model state.","metadata":{}},{"cell_type":"code","source":"model.load_state_dict(best_model_state)","metadata":{"trusted":true,"execution":{"execution_failed":"2025-11-08T12:12:37.864Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### Validation ROC AUC\n\n- Switched to `eval` mode and disabled gradients.\n- Predicted probabilities using `sigmoid`.\n- Calculated ROC AUC: **{roc_auc_score:.4f}**\n\nThis score reflects how well the model separates the two classes.","metadata":{}},{"cell_type":"code","source":"model.eval()\nwith torch.no_grad():\n    test_logits = model(X_val_tensor)\n    test_probs = torch.sigmoid(test_logits).squeeze().cpu().numpy()\nprint(f\"ROC AUC Score: {roc_auc_score(y_test, test_probs):.4f}\")","metadata":{"trusted":true,"execution":{"execution_failed":"2025-11-08T12:12:37.864Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model.eval()\nwith torch.no_grad():\n    test_logits = model(X_test_tensor)\n    test_probs = torch.sigmoid(test_logits).squeeze().cpu().numpy()","metadata":{"trusted":true,"execution":{"execution_failed":"2025-11-08T12:12:37.864Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# <p style=\"background-image: url(https://thumb.ac-illust.com/ef/efba71f003602d81b40951d0040bbab0_t.jpeg);font-family:consolas;font-size:120%;color:#ffffff;text-align:center;border-radius:20px 20px; padding:5px\"> Submission </p>","metadata":{}},{"cell_type":"code","source":"sub = pd.read_csv('/kaggle/input/playground-series-s5e11/sample_submission.csv')\nsubmission = pd.DataFrame({\n    \"id\": sub['id'],\n    \"loan_paid_back\": test_probs \n})\n\nsubmission.to_csv(\"submission.csv\", index=False)","metadata":{"trusted":true,"execution":{"execution_failed":"2025-11-08T12:12:37.864Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}