{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.13"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":91722,"databundleVersionId":14262372,"sourceType":"competition"},{"sourceId":13680169,"sourceType":"datasetVersion","datasetId":8698939}],"dockerImageVersionId":31192,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"papermill":{"default_parameters":{},"duration":52.796911,"end_time":"2025-11-10T14:28:45.994317","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2025-11-10T14:27:53.197406","version":"2.6.0"}},"nbformat_minor":4,"nbformat":4,"cells":[{"id":"7d945ce2","cell_type":"code","source":"import os,ast\nimport numpy as np\nimport pandas as pd\n\nimport shutil,copy\n\nfrom bokeh.plotting import figure, gridplot \nfrom bokeh.io import output_file, show, output_notebook\noutput_notebook()\n\n\ndef bokeh_show(\n        params,\n        df_cross,\n        show_figures1, \n        show_figures2, wps_fig2,\n        color_cross):\n\n    colors = [subm['color'] for subm in params['subm']]\n    \n    def dossier(js,subms,cols):\n        def quant(i,js,subms,cols):\n            return {\"c\" : i, \"q\" : sum([1 for subm in cols[i] if subm == subms[js]])}\n        return {\n            'name' : subms[js],\n            'q_in' : [quant(i,js,subms,cols) for i in range(len(subms))]\n        }\n    alls = pd.read_csv(f'tida_desc.csv')\n    matrix = [ast.literal_eval(str(row.alls)) for row in alls.itertuples()]\n    subms = sorted(matrix[0])\n    cols = [[data[i] for data in matrix] for i in range(len(subms))]\n    df_subms = pd.DataFrame({f'col_{i}': [x[i] for x in matrix] for i in range(len(subms))})\n    dossiers = [dossier(js,subms,cols) for js in range(len(subms))]\n    subm_names = [one_dossier['name'] for one_dossier in dossiers]\n    figures1,qss,i = [],[],0\n    height = 85 if len(colors)==2\\\n        else 134 if len(colors)==3 else (154 if len(colors)==4 else 174)\n    for one_dossier in dossiers: \n        i_col = 'alls. ' + str(one_dossier['q_in'][i]['c'])\n        qs = [one['q'] for one in one_dossier['q_in']]\n        x_names = [name.replace(\"Group\",\"\").replace(\"subm_\",\"\") for name in subm_names]\n        width = 157  if len(colors) == 5\\\n            else (121 if len(colors) == 8\\\n            else (131 if len(colors) == 9\\\n            else (141 if len(colors) == 10\\\n            else (171 if len(colors) == 11 else 133))))\n        f = figure(x_range=x_names,width=width, height=height, title=i_col)\n        f.vbar(x=x_names, width=0.585, top=qs, color=colors)\n        figures1.append(f)\n        qss.append(qs)\n        i+=1\n    grid = gridplot([figures1])\n    output_file('tida_alls.html')\n    if show_figures1 == True: show(grid)\n    sub_wts = params['subwts']\n    main_wts = [subm['weight'] for subm in params['subm']]\n    mms,acc_mass = [],[]\n    for j in range(len(dossiers)):\n        one_dossier = dossiers[j]\n        qs = [one['q'] for one in one_dossier['q_in']]\n        mm = [qs[h] * (main_wts[j] + sub_wts[h]) for h in range(len(sub_wts))]\n        mass = sum(mm)\n        mms.append(mm)\n        acc_mass.append(round(mass))                        #subm_names[::-1]\n    y_names = [name + \" - \" + str(mass) for name,mass in zip(subm_names,acc_mass)]\n    f1 = figure(y_range=y_names, width=313, height=height, title='relations of general masses')\n    f1.hbar(y=y_names, height=0.585, right=acc_mass, left=0, color=colors)\n    output_file('tida_alls2.html')\n    alls = [f'alls.{i}' for i in range(len(dossiers))]\n    subm = [f'sub{i}'   for i in range(len(dossiers))] \n    mmsT  = np.asarray(mms).T\n    data = {'cols' : alls}\n    for i in range(len(dossiers)): data[f'sub{i}'] = mmsT[i,:]\n    f2 = figure(y_range=alls, height=height, width=274, title=\" ( relations of columns masses )\")\n    f2.hbar_stack(subm, y='cols', height=0.585, color=colors, source=data)\n    qssT  = np.asarray(qss).T\n    data = {'cols' : alls}\n    for i in range(len(dossiers)): data[f'sub{i}'] = qssT[i,:]\n    f3 = figure(y_range=alls, height=height, width=210, title=\"ratios in columns\")\n    f3.hbar_stack(subm, y='cols', height=0.585, color=colors, source=data)\n    grid = gridplot([[f3,f2,f1]])\n    show(grid)\n    if show_figures2 == True:\n        def read(params,i):\n            FiN = params[\"path\"] + params[\"subm\"][i][\"name\"] + \".csv\"\n            target_name_back = {'target':params[\"target\"],'pred':params[\"target\"]}\n            return pd.read_csv(FiN).rename(columns=target_name_back)\n        dfs = [read(params,i) for i in range(len(params[\"subm\"]))] + [df_cross]\n        f   = figure(width=785, height=254)\n        f.title.text = 'Click on legend entries to mute the corresponding lines'\n        b,e        = 21000,21121\n        line_x     = [dfs[i][b:e]['id']            for i in range(len(dfs))]\n        line_y     = [dfs[i][b:e]['loan_paid_back'] for i in range(len(dfs))]\n        color      = colors + [color_cross]\n        alpha      = [0.8 for i in range(len(dfs)-1)] + [0.95]\n        lws        = [1.0 for i in range(len(dfs)-1)] + [1.00]\n        legend = subm_names + ['cross']\n        for i in range(len(legend)):\n            f.line(line_x[i], line_y[i], line_width=lws[i], color=color[i], alpha=alpha[i],\n                   muted_color='white',legend_label=legend[i])\n        f.legend.location = \"top_left\"\n        f.legend.click_policy=\"mute\"\n        show(f)\n\n\ndef h_blend(params,cross='silver',\n            figures1=False,figures2=False,wf2=555,\n            details=False):\n\n    color_cross = cross\n\n    dk = copy.deepcopy(params)\n\n    show_details,show_figures1,show_figures2 = details,figures1,figures2\n\n    file_short_names = [subm['name'] for subm in params['subm']]\n    type_sort    = params['type_sort'][0]\n    dk['asc']    = params['type_sort'][1]\n    dk['desc']   = params['type_sort'][2]\n    dk['id']     = params['id_target'][0]\n    dk['target'] = params['id_target'][1]\n# ------------------------------------------------------------------------\n    def read(dk,i):\n        tnm = dk[\"subm\"][i][\"name\"]\n        FiN = dk[\"path\"] + tnm + \".csv\"\n        return pd.read_csv(FiN).rename(columns={\n            'target':tnm, 'pred':tnm, dk[\"target\"]:tnm})\n        \n    def merge(dfs_subm):\n        df_subms = pd.merge(dfs_subm[0],  dfs_subm[1], on=[dk['id']])\n        for i in range(2, len(dk[\"subm\"])): \n            df_subms = pd.merge(df_subms, dfs_subm[i], on=[dk['id']])\n        return df_subms\n        \n    def da(dk,sorting_direction,show_details):\n        \n        df_subms = merge([read(dk,i) for i in range(len(dk[\"subm\"]))])\n        cols = [col for col in df_subms.columns if col != dk['id']]\n        short_name_cols = [c for c in cols]\n        \n        def alls1(x, sd=sorting_direction,cs=cols):\n            reverse = True if sd=='desc' else False\n            tes = {c: x[c] for c in cs}.items()\n            subms_sorted = [t[0] for t in sorted(tes,key=lambda k:k[1],reverse=reverse)]\n            return subms_sorted\n\n        import random\n\n        def alls2(x, sd=sorting_direction,cs=cols):\n            reverse = True if sd=='desc' else False\n            tes = {c: x[c] for c in cs}.items()\n            subms_random = [t[0] for t in tes]\n            random.shuffle(subms_random)\n            return subms_random\n\n        alls = alls1 if type_sort == 'asc/desc' else alls2\n            \n        def summa(x,cs,wts,ic_alls): \n            return sum([x[cs[j]] * (wts[0][j] + wts[1][ic_alls[j]]) for j in range(len(cs))])\n            \n        wts = [[[e['weight'] for e in dk[\"subm\"]], [w for w in dk[\"subwts\" ]]]]\n          \n        def correct(x, cs=cols, wts=wts):\n            i = [x['alls'].index(c) for c in short_name_cols]\n            return summa(x,cs,wts[0],i)\n\n        if len(wts) == 1:\n            correct_sub_weights = [wt for wt in dk[\"subwts\"]]\n            weights = [subm['weight'] for subm in dk[\"subm\"]]\n            def correct(x, cs=cols, w=weights, cw=correct_sub_weights):\n                ic = [x['alls'].index(c) for c in short_name_cols]\n                cS = [x[cols[j]] * (w[j] + cw[ic[j]]) for j in range(len(cols))]\n                return sum(cS)\n                   \n        def amxm(x, cs=cols):\n            list_values = x[cs].to_list()\n            mxm = abs(max(list_values)-min(list_values))\n            return mxm\n\n        if len(wts) > 1:\n            df_subms['mx-m']   = df_subms.apply(lambda x: amxm   (x), axis=1)\n        df_subms['alls']       = df_subms.apply(lambda x: alls   (x), axis=1)\n        df_subms[dk[\"target\"]] = df_subms.apply(lambda x: correct(x), axis=1)\n        schema_rename = { old_nc:new_shnc for old_nc, new_shnc in zip(cols, short_name_cols) }\n        df_subms = df_subms.rename(columns=schema_rename)\n        df_subms = df_subms.rename(columns={dk[\"target\"]:\"ensemble\"})\n        df_subms.insert(loc=1, column=' _ ', value=['   '] * len(df_subms))\n        df_subms[' _ '] = df_subms[' _ '].astype(str)\n        pd.set_option('display.max_rows',100)\n        pd.set_option('display.float_format', '{:.5f}'.format)\n        vcols = [dk['id']]+[' _ '] + short_name_cols + [' _ ']+['alls']+[' _ ']+['ensemble']\n        if len(wts) > 1: vcols.append([' _ '] + ['mx-m'])\n        df_subms = df_subms[vcols]\n        if show_details and sorting_direction=='desc': display(df_subms.head(5))\n        pd.set_option('display.float_format', '{:.5f}'.format)\n        df_subms = df_subms.rename(columns={\"ensemble\":dk[\"target\"]})\n        df_subms.to_csv(f'tida_{sorting_direction}.csv', index=False)\n        return df_subms[[dk['id'],dk['target']]]\n   \n    def ensemble_da(dk,        show_details): \n        dfD    = da(dk,'desc', show_details)\n        dfA    = da(dk,'asc',  show_details)\n        dfA[dk['target']] = dk['desc']*dfD[dk['target']] + dfA[dk['target']]*dk['asc']\n        return dfA\n\n    da = ensemble_da(dk,show_details)\n    \n    bokeh_show(dk, da, show_figures1, show_figures2, wf2, color_cross)\n    \n    return  da\n\n\ndef matrix_vs(path,fs_names):\n    def load(path,fs_names):\n        dfs = [pd.read_csv(path + name_subm +'.csv') for name_subm in fs_names]\n        for i in range(len(dfs)):\n            dfs[i] = dfs[i].rename(columns={\"loan_paid_back\": f'{fs_names[i]}'})\n        dfsm = pd.merge(dfs[0], dfs[1], on=\"id\")\n        for i in range(2,len(dfs)):\n            dfsm = pd.merge(dfsm,dfs[i],on='id')\n        return dfsm   \n    def make_list_vs(fs_names):\n        list = []\n        for i in range(0,len(fs_names)-1):\n            for j in range(i+1,len(fs_names)):\n                list.append(fs_names[i] + \"_vs_\" + fs_names[j])\n        return list\n    def get_mvs(dfs, list_vs):\n        def get_abs_distance(x,t1,t2):\n            return abs(x[t1]-x[t2])\n        for vs in list_vs:\n            t = vs.split('_vs_')\n            dfs[vs] = dfs.apply(lambda x: get_abs_distance(x,t[0],t[1]), axis=1)\n        return dfs   \n    def distance_vs(name, st_names, list_vs, dfs):\n        distances = []\n        for st in st_names:\n            vs_between = name + \"_vs_\" + st\n            if vs_between not in list_vs:\n                distances.append(0)\n            else: distances.append(round(dfs[vs_between].sum()))\n        return distances\n    dfs = load(path,fs_names)\n    list_vs = make_list_vs(fs_names)\n    mvs = get_mvs(dfs, list_vs)\n    m1 = pd.DataFrame({'subm':fs_names})\n    m2 = pd.DataFrame({ name :distance_vs(name, fs_names, list_vs, mvs) for name in fs_names})\n    matrix = pd.concat([m1,m2],axis=1)\n    return matrix\n\n\ndef procedure_Cage(FiN_import,n_iter=4,ks1=[1.0054,0.0021],ks2=[1.00037,0.00037]):\n    import seaborn as sns\n    import matplotlib.pyplot as plt\n    import warnings; warnings.filterwarnings('ignore')\n    \n    sub_sample = pd.read_csv('../input/playground-series-s5e11/sample_submission.csv') \n    sub_import = pd.read_csv(FiN_import) \n    per = sub_import['loan_paid_back'].values\n    # ..................................................................................................\n    sns.set()\n    plt.figure(figsize=(5, 2))\n    plt.hist(per, bins=80)\n    plt.gca().set_facecolor('mintcream')\n    plt.suptitle('Before | loan_paid_back', y=0.96, fontsize=12, c='navy')\n    # ..................................................................................................\n    print('- - - - - - - ',FiN_import)\n    min_per  = np.min(per);  print('Min:',  round(min_per, 7))\n    max_per  = np.max(per);  print('Max:',  round(max_per, 7))\n    mean_per = np.mean(per); print('Mean:', round(mean_per,7))\n    print('-------')\n    R = -0.0\n    guide = mean_per - R\n    # ....................................\n    per1 = [f for f in per if f < guide]\n    per2 = [f for f in per if f > guide]\n    print(len(per1),'-',len(per2))\n    print('-------')\n    N = n_iter\n    for _ in range(N):\n        for i in range(len(per)):\n            per_guide = (per[i] + guide) / 2            \n            if per[i] <= guide:\n                per[i] = (per[i] *ks1[0]) - (per_guide *ks1[1])\n            else:\n                per[i] = (per[i] *ks2[0]) - (per_guide *ks2[1])\n    # .......................................................................\n    sns.set()\n    plt.figure(figsize=(5, 2))\n    plt.hist(per, bins=80)\n    plt.gca().set_facecolor('snow')\n    plt.suptitle('After | loan_paid_back', y=0.96, fontsize=11, c='navy')\n    # .......................................................................\n    min_per  = np.min(per);  print('Min:',  round(min_per, 7))\n    max_per  = np.max(per);  print('Max:',  round(max_per, 7))\n    mean_per = np.mean(per); print('Mean:', round(mean_per,7)); \n    # .......................................................................\n    print('- - - - - - - ', 'Cage '+FiN_import, '\\n')\n    # .......................................................................\n    sub_sample['loan_paid_back'] = per\n    return sub_sample \n    # df = direct_blend('Groups.csv','Group_19.csv',wts=[0.85,0.15])\n    # df_Cage = procedure_Cage('Groups.csv',n_iter=4,ks1=[1.002,0.001],ks2=[1.002,0.001])\n    # display ( df_Cage )\n    # .......................................................................\n\n\ndef display_distances(params):\n    files = [subm['name'] for subm in params['subm']]\n    distances = matrix_vs ( params['path'], files )            \n    display(distances)\n\n\ndef redirrect(full_FiN, short_FiN):\n    df = pd.read_csv(full_FiN)\n    df.to_csv(short_FiN, index=False)\n\n\ndef straight_blend(df1,df2,wts=[0.50,0.50],subm=''):\n    t = 'loan_paid_back'\n    df1[t] = df1[t]*wts[0] + df2[t]*wts[1]\n    if subm != \"\":\n        df1.to_csv(subm, index=False)\n        print(f'{subm} - ready to use')\n    return df1\n    \n\ndef direct_blend(subm_file_1, subm_file_2, wts=[0.50,0.50]):\n    df1 = pd.read_csv(subm_file_1)\n    df2 = pd.read_csv(subm_file_2)\n    return straight_blend(df1,df2,wts=wts)","metadata":{"_kg_hide-input":true,"execution":{"iopub.execute_input":"2025-11-10T14:27:56.803549Z","iopub.status.busy":"2025-11-10T14:27:56.803347Z","iopub.status.idle":"2025-11-10T14:27:59.203304Z","shell.execute_reply":"2025-11-10T14:27:59.20262Z"},"jupyter":{"source_hidden":true},"papermill":{"duration":2.403617,"end_time":"2025-11-10T14:27:59.204494","exception":false,"start_time":"2025-11-10T14:27:56.800877","status":"completed"},"tags":[]},"outputs":[],"execution_count":null},{"id":"9b765426","cell_type":"markdown","source":"## Group.1","metadata":{"papermill":{"duration":0.002219,"end_time":"2025-11-10T14:27:59.209141","exception":false,"start_time":"2025-11-10T14:27:59.206922","status":"completed"},"tags":[]}},{"id":"e0b91e16","cell_type":"code","source":"params = {\n      'path'     : '/kaggle/input/11-november-2025-ps-s5e11/submission ',            \n      'id_target': ['id',\"loan_paid_back\"],          \n      'type_sort': ['asc/desc',0.30,0.70 ],\n      'subwts'   : [ +0.04,+0.03, 0, -0.02,-0.05 ],\n      'subm'     : [    \n         { 'name': f'0.92664','weight':+0.03,'color':\"maroon\" },\n         { 'name': f'0.92684','weight':+0.03,'color':\"sienna\" },\n         { 'name': f'0.92722','weight':+0.03,'color':\"chocolate\" },\n         { 'name': f'0.92756','weight':+0.21,'color':\"sandybrown\" },\n         { 'name': f'0.92761','weight':+0.70,'color':\"yellow\" }, \n      ]  \n}\n\ndf_cross = h_blend(params, figures1=True, figures2=True, details=True)\n\ndisplay_distances(params)","metadata":{"execution":{"iopub.execute_input":"2025-11-10T14:27:59.214435Z","iopub.status.busy":"2025-11-10T14:27:59.214144Z","iopub.status.idle":"2025-11-10T14:28:44.997118Z","shell.execute_reply":"2025-11-10T14:28:44.996351Z"},"papermill":{"duration":45.787074,"end_time":"2025-11-10T14:28:44.998339","exception":false,"start_time":"2025-11-10T14:27:59.211265","status":"completed"},"tags":[]},"outputs":[],"execution_count":null},{"id":"4b9073bd","cell_type":"markdown","source":"## Submit","metadata":{"papermill":{"duration":0.003689,"end_time":"2025-11-10T14:28:45.00602","exception":false,"start_time":"2025-11-10T14:28:45.002331","status":"completed"},"tags":[]}},{"id":"366f08df","cell_type":"code","source":"df_cross.to_csv('submission.csv',index=False)\ndf_cross","metadata":{"execution":{"iopub.execute_input":"2025-11-10T14:28:45.0143Z","iopub.status.busy":"2025-11-10T14:28:45.014077Z","iopub.status.idle":"2025-11-10T14:28:45.471817Z","shell.execute_reply":"2025-11-10T14:28:45.47102Z"},"papermill":{"duration":0.463391,"end_time":"2025-11-10T14:28:45.473044","exception":false,"start_time":"2025-11-10T14:28:45.009653","status":"completed"},"tags":[]},"outputs":[],"execution_count":null}]}