{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":91722,"databundleVersionId":14262372,"sourceType":"competition"},{"sourceId":13059803,"sourceType":"datasetVersion","datasetId":8264672}],"dockerImageVersionId":31154,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom itertools import combinations\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import roc_auc_score\nimport xgboost as xgb\nfrom lightgbm import LGBMClassifier\nimport lightgbm as lgb\nfrom cuml.preprocessing.TargetEncoder import TargetEncoder\nimport warnings\nimport gc\nwarnings.filterwarnings('ignore')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"=\"*80)\nprint(\"LOADING DATA\")\nprint(\"=\"*80)\ntrain = pd.read_csv('/kaggle/input/playground-series-s5e11/train.csv')\ntest = pd.read_csv('/kaggle/input/playground-series-s5e11/test.csv')\norig = pd.read_csv('/kaggle/input/loan-prediction-dataset-2025/loan_dataset_20000.csv')\nsubmission = pd.read_csv('/kaggle/input/playground-series-s5e11/sample_submission.csv')\n\nprint(f'Train: {train.shape}, Test: {test.shape}, Orig: {orig.shape}')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def downcasting(data, verbose=True):\n    mem_before = data.memory_usage().sum() / 1024**2\n    if verbose:\n        print(f\"Memory: {mem_before:.2f} MB\", end=\" → \")\n            \n    for col in data.select_dtypes(include=[\"number\"]).columns:\n        if pd.api.types.is_integer_dtype(data[col]):\n            data[col] = pd.to_numeric(data[col], downcast=\"integer\")\n        elif pd.api.types.is_float_dtype(data[col]):\n            data[col] = pd.to_numeric(data[col], downcast=\"float\")\n    \n    mem_after = data.memory_usage().sum() / 1024**2\n    if verbose:\n        print(f\"{mem_after:.2f} MB (↓{(100 * (mem_before - mem_after) / mem_before):.1f}%)\")\n    return data\n\ntrain = downcasting(train)\ntest = downcasting(test)\norig = downcasting(orig)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ============================================================================\n# CONFIGURATION\n# ============================================================================\ntarget = 'loan_paid_back'\nCATS = ['gender', 'marital_status', 'education_level', 'employment_status', \n        'loan_purpose', 'grade_subgrade']\nNUMS = ['annual_income', 'debt_to_income_ratio', 'credit_score', \n        'loan_amount', 'interest_rate', 'age']","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print('\\n' + '='*80)\nprint('HIGH-VALUE FEATURE ENGINEERING')\nprint('='*80)\n\ntest[target] = -1\ncombine = pd.concat([train, test, orig], axis=0, ignore_index=True)\n\ncombine['financial_health'] = (combine['credit_score'] / 850) * (1 - combine['debt_to_income_ratio'])\ncombine['loan_burden'] = combine['loan_amount'] / (combine['annual_income'] + 1)\ncombine['monthly_burden'] = (combine['loan_amount'] * combine['interest_rate'] / 1200) / ((combine['annual_income'] / 12) + 1)\ncombine['credit_power'] = combine['credit_score'] / (combine['interest_rate'] + 0.1)\ncombine['income_efficiency'] = combine['annual_income'] * (1 - combine['debt_to_income_ratio'])\n\ncombine['high_risk'] = ((combine['debt_to_income_ratio'] > 0.4) & (combine['credit_score'] < 650)).astype(np.int8)\ncombine['low_risk'] = ((combine['debt_to_income_ratio'] < 0.3) & (combine['credit_score'] > 700)).astype(np.int8)\n\ncombine['grade_letter'] = combine['grade_subgrade'].str[0]\ncombine['grade_number'] = combine['grade_subgrade'].str[1].astype(int)\ngrade_map = {'A': 1, 'B': 2, 'C': 3, 'D': 4, 'E': 5, 'F': 6, 'G': 7}\ncombine['grade_rank'] = combine['grade_letter'].map(grade_map)\ncombine['grade_score'] = combine['grade_rank'] * 10 + combine['grade_number']\n\ncombine['log_income'] = np.log1p(combine['annual_income'])\ncombine['log_loan'] = np.log1p(combine['loan_amount'])\ncombine['log_credit'] = np.log1p(combine['credit_score'])\n\ncombine['credit_squared'] = combine['credit_score'] ** 2\ncombine['debt_squared'] = combine['debt_to_income_ratio'] ** 2\n\ncombine['income_credit'] = combine['log_income'] * combine['credit_score'] / 1000\ncombine['debt_loan'] = combine['debt_to_income_ratio'] * combine['log_loan']\ncombine['rate_burden'] = combine['interest_rate'] * combine['loan_burden']\n\ncombine['risk_score'] = (combine['debt_to_income_ratio'] * combine['interest_rate'] * 100) / (combine['credit_score'] + 1)\ncombine['affordability_score'] = (combine['annual_income'] / 12) / (combine['loan_amount'] * combine['interest_rate'] / 1200 + 1)\n\ncombine['age_income_ratio'] = combine['age'] / (combine['log_income'] + 1)\ncombine['credit_age_interaction'] = combine['credit_score'] * combine['age'] / 1000\n\nNEW_NUM_FEATURES = ['financial_health', 'loan_burden', 'monthly_burden', 'credit_power',\n                    'income_efficiency', 'log_income', 'log_loan', 'log_credit',\n                    'credit_squared', 'debt_squared', 'income_credit', 'debt_loan', \n                    'rate_burden', 'grade_number', 'grade_rank', 'grade_score',\n                    'high_risk', 'low_risk', 'risk_score', 'affordability_score',\n                    'age_income_ratio', 'credit_age_interaction']\n\nNEW_CAT_FEATURES = ['grade_letter']\n\nprint(f'Created {len(NEW_NUM_FEATURES)} high-value numeric features')\n\nCATS.append('grade_letter')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print('\\n' + '='*80)\nprint('FACTORIZATION')\nprint('='*80)\n\nCATS1 = []\nSIZES = {}\n\nfor c in NUMS + CATS:\n    n = c\n    if c in NUMS: \n        n = f\"{c}_cat\"\n        CATS1.append(n)\n    combine[n], _ = combine[c].factorize()\n    SIZES[n] = combine[n].max() + 1\n    combine[n] = combine[n].astype('int32')\n\nprint(f'Factorized {len(NUMS)} nums → {len(CATS1)} categorical versions')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print('\\n' + '='*80)\nprint('2-WAY INTERACTIONS')\nprint('='*80)\n\npairs = list(combinations(CATS + CATS1, 2))\nnew_cols = {}\nCATS2 = []\n\nfor c1, c2 in pairs:\n    name = \"_\".join(sorted((c1, c2)))\n    new_cols[name] = combine[c1] * SIZES[c2] + combine[c2]\n    CATS2.append(name)\n\nif new_cols:\n    new_df = pd.DataFrame(new_cols)         \n    combine = pd.concat([combine, new_df], axis=1) \n    del new_df\n    gc.collect()\n\nprint(f'Created {len(CATS2)} 2-way interactions')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print('\\n' + '='*80)\nprint('STRATEGIC 3-WAY INTERACTIONS')\nprint('='*80)\n\nCATS3 = []\nstrategic_3way = [\n    ('grade_subgrade', 'employment_status', 'loan_purpose'),\n    ('grade_subgrade', 'education_level', 'loan_purpose'),\n    ('employment_status', 'education_level', 'marital_status'),\n]\n\nfor c1, c2, c3 in strategic_3way:\n    if c1 in CATS and c2 in CATS and c3 in CATS:\n        name = f\"{c1}_{c2}_{c3}\"\n        combine[name] = (combine[c1].astype(str) + '_' + \n                        combine[c2].astype(str) + '_' + \n                        combine[c3].astype(str))\n        combine[name], _ = combine[name].factorize()\n        combine[name] = combine[name].astype('int32')\n        CATS3.append(name)\n\nprint(f'Created {len(CATS3)} strategic 3-way interactions')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print('\\n' + '='*80)\nprint('COUNT ENCODING')\nprint('='*80)\n\nCE = []\nCC = CATS + CATS1 + CATS2 + CATS3\n\nfor i, c in enumerate(CC):\n    if i % 20 == 0:\n        print(f'Progress: {i}/{len(CC)}', end='\\r')\n    tmp = combine.groupby(c)[target].count()\n    tmp = tmp.astype('int32')\n    tmp.name = f\"CE_{c}\"\n    CE.append(f\"CE_{c}\")\n    combine = combine.merge(tmp, on=c, how='left')\n\nprint(f'Created {len(CE)} count features                ')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ============================================================================\n# SPLIT DATA\n# ============================================================================\ntrain = combine.iloc[:len(train)].copy()\ntest = combine.iloc[len(train):len(train)+len(test)].copy()\norig = combine.iloc[-len(orig):].copy()\ndel combine\ngc.collect()\n\nprint(f'\\nTrain: {train.shape}, Test: {test.shape}, Orig: {orig.shape}')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ============================================================================\n# FEATURE SET\n# ============================================================================\nFEATURES = NUMS + CATS + CATS1 + CATS2 + CATS3 + CE + NEW_NUM_FEATURES\nprint(f'\\nTotal Features: {len(FEATURES)}')\n\nCATS_FINAL = [c for c in CATS if c not in (CATS1 + CATS2 + CATS3)]\nprint(f'Categorical features (non-TE): {len(CATS_FINAL)}')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ============================================================================\n# DATA LOADER FOR QUANTILE DMATRIX\n# ============================================================================\nclass IterLoadForDMatrix(xgb.core.DataIter):\n    def __init__(self, df=None, features=None, target=None, batch_size=256*1024):\n        self.features = features\n        self.target = target\n        self.df = df\n        self.it = 0 \n        self.batch_size = batch_size\n        self.batches = int(np.ceil(len(df) / self.batch_size))\n        super().__init__()\n    \n    def reset(self):\n        self.it = 0\n    \n    def next(self, input_data):\n        if self.it == self.batches:\n            return 0\n        \n        a = self.it * self.batch_size\n        b = min((self.it + 1) * self.batch_size, len(self.df))\n        dt = self.df.iloc[a:b]\n        input_data(data=dt[self.features], label=dt[self.target]) \n        self.it += 1\n        return 1","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print('\\n' + '='*80)\nprint('STAGE 1: INITIAL TRAINING WITH STRATIFIED CV')\nprint('='*80)\n\nFOLDS = 7\nSEED = 42\n\nparams_xgb = {\n    \"objective\": \"binary:logistic\",  \n    \"eval_metric\": \"auc\",           \n    \"learning_rate\": 0.0075,\n    \"max_depth\": 0,\n    \"subsample\": 0.76,\n    \"colsample_bytree\": 0.66,\n    \"seed\": SEED,\n    \"device\": \"cuda\",\n    \"grow_policy\": \"lossguide\", \n    \"max_leaves\": 34,          \n    'scale_pos_weight': 0.86,\n    \"min_child_weight\": 5,\n    'lambda': 6.5, \n    'alpha': 3.2,\n    'gamma': 0.55,\n}\n\noof_preds1 = np.zeros(len(train))\ntest_preds1 = np.zeros(len(test))\n\nskf = StratifiedKFold(n_splits=FOLDS, shuffle=True, random_state=SEED)\n\nfor fold, (train_idx, val_idx) in enumerate(skf.split(train, train[target])):\n    print(f'\\nFold {fold+1}/{FOLDS}')\n    \n    Xy_train = train.iloc[train_idx][FEATURES + [target]].copy()\n    Xy_more = orig[FEATURES + [target]].copy()\n    Xy_train = pd.concat([Xy_train, Xy_more], axis=0, ignore_index=True)\n    \n    X_valid = train.iloc[val_idx][FEATURES].copy()\n    y_valid = train.iloc[val_idx][target].copy()\n    X_test = test[FEATURES].copy()\n    \n    CC_TE = CATS1 + CATS2 + CATS3\n    print(f'Target encoding {len(CC_TE)} features...', end=' ')\n    \n    for c in CC_TE:\n        try:\n            TE = TargetEncoder(n_folds=10, smooth=12, split_method='random', stat='mean')\n            \n            result_train = TE.fit_transform(Xy_train[[c]], Xy_train[target])\n            if hasattr(result_train, 'values'):\n                Xy_train[c] = result_train.values.ravel().astype('float32')\n            else:\n                Xy_train[c] = result_train.ravel().astype('float32')\n            \n            result_valid = TE.transform(X_valid[[c]])\n            if hasattr(result_valid, 'values'):\n                X_valid[c] = result_valid.values.ravel().astype('float32')\n            else:\n                X_valid[c] = result_valid.ravel().astype('float32')\n            \n            result_test = TE.transform(X_test[[c]])\n            if hasattr(result_test, 'values'):\n                X_test[c] = result_test.values.ravel().astype('float32')\n            else:\n                X_test[c] = result_test.ravel().astype('float32')\n        except:\n            continue\n    \n    print('Done')\n    \n    for cat in CATS_FINAL:\n        if cat in Xy_train.columns:\n            Xy_train[cat] = Xy_train[cat].astype('category')\n            X_valid[cat] = X_valid[cat].astype('category')\n            X_test[cat] = X_test[cat].astype('category')\n    \n    Xy_train_iter = IterLoadForDMatrix(Xy_train, FEATURES, target)\n    dtrain = xgb.QuantileDMatrix(Xy_train_iter, enable_categorical=True, max_bin=256)\n    dval = xgb.DMatrix(X_valid, label=y_valid, enable_categorical=True)\n    dtest = xgb.DMatrix(X_test, enable_categorical=True)\n    \n    model = xgb.train(\n        params=params_xgb,\n        dtrain=dtrain,\n        num_boost_round=18000,\n        evals=[(dval, \"valid\")],\n        early_stopping_rounds=450,\n        verbose_eval=False\n    )\n    \n    oof_preds1[val_idx] = model.predict(dval, iteration_range=(0, model.best_iteration + 1))\n    test_preds1 += model.predict(dtest, iteration_range=(0, model.best_iteration + 1)) / FOLDS\n    \n    fold_auc = roc_auc_score(y_valid, oof_preds1[val_idx])\n    print(f'Fold {fold+1} AUC: {fold_auc:.5f} (Best iteration: {model.best_iteration})')\n    \n    del Xy_train, Xy_more, X_valid, X_test, dtrain, dval, dtest, model\n    gc.collect()\n\ncv_auc1 = roc_auc_score(train[target], oof_preds1)\nprint(f'\\n{\"=\"*80}')\nprint(f'XGB CV: {cv_auc1:.5f}')\nprint('='*80)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print('\\n' + '='*80)\nprint('STAGE 2: LGBM TRAINING')\nprint('='*80)\n\nparams_lgb = {\n    'objective': 'binary',\n    'metric': 'auc',\n    'boosting_type': 'gbdt',\n    'learning_rate': 0.0075,\n    'num_leaves': 34,\n    'max_depth': -1,\n    'min_child_samples': 23,\n    'subsample': 0.76,\n    'subsample_freq': 1,\n    'colsample_bytree': 0.66,\n    'reg_alpha': 3.2,\n    'reg_lambda': 6.5,\n    'min_split_gain': 0.55,\n    'random_state': SEED,\n    'n_jobs': -1,\n    'device': 'gpu',\n    'verbose': -1,\n}\n\noof_preds2 = np.zeros(len(train))\ntest_preds2 = np.zeros(len(test))\n\nfor fold, (train_idx, val_idx) in enumerate(skf.split(train, train[target])):\n    print(f'\\nFold {fold+1}/{FOLDS}')\n    \n    Xy_train = train.iloc[train_idx][FEATURES + [target]].copy()\n    Xy_more = orig[FEATURES + [target]].copy()\n    Xy_train = pd.concat([Xy_train, Xy_more], axis=0, ignore_index=True)\n    \n    X_valid = train.iloc[val_idx][FEATURES].copy()\n    y_valid = train.iloc[val_idx][target].copy()\n    X_test = test[FEATURES].copy()\n    \n    CC_TE = CATS1 + CATS2 + CATS3\n    print(f'Target encoding {len(CC_TE)} features...', end=' ')\n    \n    for c in CC_TE:\n        try:\n            TE = TargetEncoder(n_folds=10, smooth=12, split_method='random', stat='mean')\n            \n            result_train = TE.fit_transform(Xy_train[[c]], Xy_train[target])\n            if hasattr(result_train, 'values'):\n                Xy_train[c] = result_train.values.ravel().astype('float32')\n            else:\n                Xy_train[c] = result_train.ravel().astype('float32')\n            \n            result_valid = TE.transform(X_valid[[c]])\n            if hasattr(result_valid, 'values'):\n                X_valid[c] = result_valid.values.ravel().astype('float32')\n            else:\n                X_valid[c] = result_valid.ravel().astype('float32')\n            \n            result_test = TE.transform(X_test[[c]])\n            if hasattr(result_test, 'values'):\n                X_test[c] = result_test.values.ravel().astype('float32')\n            else:\n                X_test[c] = result_test.ravel().astype('float32')\n        except:\n            continue\n    \n    print('Done')\n    \n    model = LGBMClassifier(**params_lgb, n_estimators=18000)\n    \n    model.fit(\n        Xy_train[FEATURES], Xy_train[target],\n        eval_set=[(X_valid, y_valid)],\n        callbacks=[\n            lgb.early_stopping(stopping_rounds=450, verbose=False),\n            lgb.log_evaluation(period=0)\n        ]\n    )\n    \n    oof_preds2[val_idx] = model.predict_proba(X_valid)[:, 1]\n    test_preds2 += model.predict_proba(X_test)[:, 1] / FOLDS\n    \n    fold_auc = roc_auc_score(y_valid, oof_preds2[val_idx])\n    print(f'Fold {fold+1} AUC: {fold_auc:.5f}')\n    \n    del Xy_train, Xy_more, X_valid, X_test, model\n    gc.collect()\n\ncv_auc2 = roc_auc_score(train[target], oof_preds2)\nprint(f'\\n{\"=\"*80}')\nprint(f'LGBM CV: {cv_auc2:.5f}')\nprint('='*80)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print('\\n' + '='*80)\nprint('STAGE 3: PSEUDO-LABELING ON HIGH-CONFIDENCE TEST DATA')\nprint('='*80)\n\ninitial_test_preds = (test_preds1 + test_preds2) / 2\n\nconfidence_threshold_high = 0.95\nconfidence_threshold_low = 0.05\n\nhigh_conf_idx = (initial_test_preds >= confidence_threshold_high) | (initial_test_preds <= confidence_threshold_low)\nprint(f'High-confidence test samples: {high_conf_idx.sum()} / {len(test)} ({100*high_conf_idx.sum()/len(test):.2f}%)')\n\nif high_conf_idx.sum() > 1000:\n    pseudo_test = test[high_conf_idx].copy()\n    pseudo_test[target] = (initial_test_preds[high_conf_idx] > 0.5).astype(int)\n    \n    print(f'\\nRetraining with {len(pseudo_test)} pseudo-labeled samples...')\n    \n    oof_preds1_pl = np.zeros(len(train))\n    test_preds1_pl = np.zeros(len(test))\n    \n    for fold, (train_idx, val_idx) in enumerate(skf.split(train, train[target])):\n        print(f'\\nFold {fold+1}/{FOLDS}')\n        \n        Xy_train = train.iloc[train_idx][FEATURES + [target]].copy()\n        Xy_more = orig[FEATURES + [target]].copy()\n        Xy_pseudo = pseudo_test[FEATURES + [target]].copy()\n        Xy_train = pd.concat([Xy_train, Xy_more, Xy_pseudo], axis=0, ignore_index=True)\n        \n        X_valid = train.iloc[val_idx][FEATURES].copy()\n        y_valid = train.iloc[val_idx][target].copy()\n        X_test = test[FEATURES].copy()\n        \n        CC_TE = CATS1 + CATS2 + CATS3\n        print(f'Target encoding {len(CC_TE)} features...', end=' ')\n        \n        for c in CC_TE:\n            try:\n                TE = TargetEncoder(n_folds=10, smooth=12, split_method='random', stat='mean')\n                \n                result_train = TE.fit_transform(Xy_train[[c]], Xy_train[target])\n                if hasattr(result_train, 'values'):\n                    Xy_train[c] = result_train.values.ravel().astype('float32')\n                else:\n                    Xy_train[c] = result_train.ravel().astype('float32')\n                \n                result_valid = TE.transform(X_valid[[c]])\n                if hasattr(result_valid, 'values'):\n                    X_valid[c] = result_valid.values.ravel().astype('float32')\n                else:\n                    X_valid[c] = result_valid.ravel().astype('float32')\n                \n                result_test = TE.transform(X_test[[c]])\n                if hasattr(result_test, 'values'):\n                    X_test[c] = result_test.values.ravel().astype('float32')\n                else:\n                    X_test[c] = result_test.ravel().astype('float32')\n            except:\n                continue\n        \n        print('Done')\n        \n        for cat in CATS_FINAL:\n            if cat in Xy_train.columns:\n                Xy_train[cat] = Xy_train[cat].astype('category')\n                X_valid[cat] = X_valid[cat].astype('category')\n                X_test[cat] = X_test[cat].astype('category')\n        \n        Xy_train_iter = IterLoadForDMatrix(Xy_train, FEATURES, target)\n        dtrain = xgb.QuantileDMatrix(Xy_train_iter, enable_categorical=True, max_bin=256)\n        dval = xgb.DMatrix(X_valid, label=y_valid, enable_categorical=True)\n        dtest = xgb.DMatrix(X_test, enable_categorical=True)\n        \n        model = xgb.train(\n            params=params_xgb,\n            dtrain=dtrain,\n            num_boost_round=18000,\n            evals=[(dval, \"valid\")],\n            early_stopping_rounds=450,\n            verbose_eval=False\n        )\n        \n        oof_preds1_pl[val_idx] = model.predict(dval, iteration_range=(0, model.best_iteration + 1))\n        test_preds1_pl += model.predict(dtest, iteration_range=(0, model.best_iteration + 1)) / FOLDS\n        \n        fold_auc = roc_auc_score(y_valid, oof_preds1_pl[val_idx])\n        print(f'Fold {fold+1} AUC: {fold_auc:.5f}')\n        \n        del Xy_train, Xy_more, Xy_pseudo, X_valid, X_test, dtrain, dval, dtest, model\n        gc.collect()\n    \n    cv_auc1_pl = roc_auc_score(train[target], oof_preds1_pl)\n    print(f'\\nXGB with Pseudo-labeling CV: {cv_auc1_pl:.5f}')\n    \n    if cv_auc1_pl > cv_auc1:\n        print(f'Pseudo-labeling improved XGB: +{(cv_auc1_pl - cv_auc1):.5f}')\n        oof_preds1 = oof_preds1_pl\n        test_preds1 = test_preds1_pl\n        cv_auc1 = cv_auc1_pl\n    else:\n        print(f'Pseudo-labeling did not improve, keeping original')\nelse:\n    print('Not enough high-confidence samples for pseudo-labeling')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print('\\n' + '='*80)\nprint('FINAL ENSEMBLE OPTIMIZATION')\nprint('='*80)\n\nbest_weight = 0.5\nbest_score = 0\n\nfor w1 in np.arange(0.35, 0.66, 0.01):\n    oof_blend = w1 * oof_preds1 + (1 - w1) * oof_preds2\n    score = roc_auc_score(train[target], oof_blend)\n    if score > best_score:\n        best_score = score\n        best_weight = w1\n\nprint(f'Optimal weight: {best_weight:.3f} (XGB) / {1-best_weight:.3f} (LGBM)')\n\nfinal_oof = best_weight * oof_preds1 + (1 - best_weight) * oof_preds2\nfinal_test = best_weight * test_preds1 + (1 - best_weight) * test_preds2\n\nfinal_cv = roc_auc_score(train[target], final_oof)\n\nprint(f'\\nXGB CV: {cv_auc1:.5f}')\nprint(f'LGBM CV: {cv_auc2:.5f}')\nprint(f'Optimized Ensemble CV: {final_cv:.5f}')\nprint(f'Expected LB: {final_cv + 0.00016:.5f} - {final_cv + 0.00022:.5f}')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print('\\n' + '='*80)\nprint('CREATING VISUALIZATIONS')\nprint('='*80)\n\nfig, axes = plt.subplots(2, 2, figsize=(15, 12))\n\naxes[0, 0].hist(final_oof, bins=50, alpha=0.7, color='steelblue', edgecolor='black')\naxes[0, 0].axvline(final_oof.mean(), color='red', linestyle='--', linewidth=2)\naxes[0, 0].set_xlabel('Predicted Probability')\naxes[0, 0].set_ylabel('Frequency')\naxes[0, 0].set_title('OOF Predictions Distribution')\naxes[0, 0].grid(True, alpha=0.3)\n\naxes[0, 1].hist([oof_preds1, oof_preds2], bins=30, alpha=0.6, label=['XGB', 'LGBM'])\naxes[0, 1].set_xlabel('Predicted Probability')\naxes[0, 1].set_ylabel('Frequency')\naxes[0, 1].set_title('Model Predictions Comparison')\naxes[0, 1].legend()\naxes[0, 1].grid(True, alpha=0.3)\n\nmodel_names = ['XGB', 'LGBM', 'Ensemble']\nmodel_scores = [cv_auc1, cv_auc2, final_cv]\nbars = axes[1, 0].bar(model_names, model_scores, color=['steelblue', 'coral', 'green'], alpha=0.7, edgecolor='black')\nfor bar, score in zip(bars, model_scores):\n    height = bar.get_height()\n    axes[1, 0].text(bar.get_x() + bar.get_width()/2., height,\n                    f'{score:.5f}', ha='center', va='bottom', fontsize=11, fontweight='bold')\naxes[1, 0].set_ylabel('CV AUC Score')\naxes[1, 0].set_title('Model Performance Comparison')\naxes[1, 0].grid(True, alpha=0.3, axis='y')\naxes[1, 0].set_ylim([min(model_scores) - 0.0015, max(model_scores) + 0.0015])\n\nweights = [best_weight, 1 - best_weight]\ncolors = ['steelblue', 'coral']","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\n# ============================================================================\n# VISUALIZATION\n# ============================================================================\nprint('\\n' + '='*80)\nprint('CREATING VISUALIZATIONS')\nprint('='*80)\n\nfig, axes = plt.subplots(2, 2, figsize=(15, 12))\n\naxes[0, 0].hist(final_oof, bins=50, alpha=0.7, color='steelblue', edgecolor='black')\naxes[0, 0].axvline(final_oof.mean(), color='red', linestyle='--', linewidth=2)\naxes[0, 0].set_xlabel('Predicted Probability')\naxes[0, 0].set_ylabel('Frequency')\naxes[0, 0].set_title('OOF Predictions Distribution')\naxes[0, 0].grid(True, alpha=0.3)\n\naxes[0, 1].hist([oof_preds1, oof_preds2], bins=30, alpha=0.6, label=['XGB', 'LGBM'])\naxes[0, 1].set_xlabel('Predicted Probability')\naxes[0, 1].set_ylabel('Frequency')\naxes[0, 1].set_title('Model Predictions Comparison')\naxes[0, 1].legend()\naxes[0, 1].grid(True, alpha=0.3)\n\nmodel_names = ['XGB', 'LGBM', 'Ensemble']\nmodel_scores = [cv_auc1, cv_auc2, final_cv]\nbars = axes[1, 0].bar(model_names, model_scores, color=['steelblue', 'coral', 'green'], alpha=0.7, edgecolor='black')\nfor bar, score in zip(bars, model_scores):\n    height = bar.get_height()\n    axes[1, 0].text(bar.get_x() + bar.get_width()/2., height,\n                    f'{score:.5f}', ha='center', va='bottom', fontsize=11, fontweight='bold')\naxes[1, 0].set_ylabel('CV AUC Score')\naxes[1, 0].set_title('Model Performance Comparison')\naxes[1, 0].grid(True, alpha=0.3, axis='y')\naxes[1, 0].set_ylim([min(model_scores) - 0.0015, max(model_scores) + 0.0015])\n\nweights = [best_weight, 1 - best_weight]\ncolors = ['steelblue', 'coral']\naxes[1, 1].pie(weights, labels=['XGB', 'LGBM'], autopct='%1.1f%%', \n               colors=colors, startangle=90, textprops={'fontsize': 12, 'fontweight': 'bold'})\naxes[1, 1].set_title('Ensemble Weight Distribution')\n\nplt.tight_layout()\nplt.savefig('model_performance.png', dpi=300, bbox_inches='tight')\nprint('Saved: model_performance.png')\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-04T04:21:20.69783Z","iopub.execute_input":"2025-11-04T04:21:20.698026Z","iopub.status.idle":"2025-11-04T04:21:20.709229Z","shell.execute_reply.started":"2025-11-04T04:21:20.69801Z","shell.execute_reply":"2025-11-04T04:21:20.708116Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ============================================================================\n# SAVE\n# ============================================================================\nsubmission[target] = final_test\nsubmission.to_csv('submission.csv', index=False)\n\noof_submission = pd.DataFrame({\n    'id': train['id'],\n    target: final_oof\n})\noof_submission.to_csv(f'oof_predictions_{final_cv:.5f}.csv', index=False)\n\nprint(f'\\n{\"=\"*80}')\nprint('✅ SAVED: submission.csv')\nprint(f'✅ SAVED: oof_predictions_{final_cv:.5f}.csv')\nprint(f'✅ SAVED: model_performance.png')\nprint(f'\\n{\"=\"*80}')\nprint(f'FINAL CV SCORE: {final_cv:.5f}')\nprint(f'Expected LB: {final_cv + 0.00016:.5f} - {final_cv + 0.00022:.5f}')\nprint(f'Target: 0.928+')\nprint(f'Previous Best LB: 0.92677')\nprint(f'Expected Improvement: +{(final_cv + 0.00019 - 0.92677):.5f}')\nprint('='*80)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-04T04:21:20.709935Z","iopub.status.idle":"2025-11-04T04:21:20.710362Z","shell.execute_reply.started":"2025-11-04T04:21:20.710172Z","shell.execute_reply":"2025-11-04T04:21:20.710188Z"}},"outputs":[],"execution_count":null}]}