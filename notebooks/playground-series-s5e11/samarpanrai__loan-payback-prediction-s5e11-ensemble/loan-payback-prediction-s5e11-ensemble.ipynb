{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":91722,"databundleVersionId":14262372,"sourceType":"competition"}],"dockerImageVersionId":31153,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Loan Payback Prediction\nUsing ensemble technique to predict the loan payback. We will use three models (XGBoost, CatBoost, Random Forest) to stack them for the loan payback prediction. ","metadata":{}},{"cell_type":"markdown","source":"# 1: Data Loading and Initial Exploration\nImporting all the libraries needed for visualizations, model building, etc.","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split, cross_val_score\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\nfrom xgboost import XGBClassifier\nfrom catboost import CatBoostClassifier\nfrom sklearn.ensemble import StackingClassifier\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-10T08:46:13.635124Z","iopub.execute_input":"2025-11-10T08:46:13.635435Z","iopub.status.idle":"2025-11-10T08:46:16.368807Z","shell.execute_reply.started":"2025-11-10T08:46:13.635408Z","shell.execute_reply":"2025-11-10T08:46:16.36765Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Loading the data","metadata":{}},{"cell_type":"code","source":"train_df = pd.read_csv('/kaggle/input/playground-series-s5e11/train.csv')\ntest_df = pd.read_csv('/kaggle/input/playground-series-s5e11/test.csv')\n\nprint(\"Train shape:\", train_df.shape)\nprint(\"Test shape:\", test_df.shape)\nprint(\"\\nTrain columns:\", train_df.columns.tolist())\nprint(\"\\nMissing values in train:\", train_df.isnull().sum().sum())\nprint(\"Missing values in test:\", test_df.isnull().sum().sum())\n\nprint(\"\\nFirst few rows:\")\nprint(train_df.head())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-10T08:46:16.370551Z","iopub.execute_input":"2025-11-10T08:46:16.371083Z","iopub.status.idle":"2025-11-10T08:46:18.810202Z","shell.execute_reply.started":"2025-11-10T08:46:16.371049Z","shell.execute_reply":"2025-11-10T08:46:18.809022Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 2: Feature Engineering\nSome feature engineering by combining and making new features for model building that will make our prediction more accurate.","metadata":{}},{"cell_type":"code","source":"def create_features(df):\n    df = df.copy()\n    \n    # Creating new features\n    df['income_to_loan_ratio'] = df['annual_income'] / (df['loan_amount'] + 1)\n    df['debt_burden'] = df['annual_income'] * df['debt_to_income_ratio']\n    df['affordability_ratio'] = (df['annual_income'] / 12) / (df['loan_amount'] * df['interest_rate'] / 1200 + 1)\n    df['credit_income_ratio'] = df['credit_score'] / df['annual_income']\n    \n    # Creating risk score based on multiple factors\n    df['risk_score'] = (\n        df['debt_to_income_ratio'] * 0.3 + \n        (800 - df['credit_score']) / 800 * 0.3 + \n        df['interest_rate'] / 25 * 0.2 +\n        (df['loan_amount'] / df['annual_income']) * 0.2\n    )\n    \n    # Extracting subgrade as numerical feature\n    if 'grade_subgrade' in df.columns:\n        df['grade'] = df['grade_subgrade'].str[0]\n        df['subgrade_num'] = df['grade_subgrade'].str[1].astype(int)\n    \n    # Creating employment stability feature\n    employment_mapping = {\n        'Unemployed': 0,\n        'Student': 1,\n        'Self-employed': 2,\n        'Employed': 3,\n        'Retired': 2\n    }\n    df['employment_stability'] = df['employment_status'].map(employment_mapping)\n    \n    # Education level encoding\n    education_mapping = {\n        'High School': 1,\n        'Other': 2,\n        'Bachelor\\'s': 3,\n        'Master\\'s': 4,\n        'PhD': 5\n    }\n    df['education_num'] = df['education_level'].map(education_mapping)\n    \n    return df\n\n# Applying feature engineering\ntrain_df_eng = create_features(train_df)\ntest_df_eng = create_features(test_df)\n\nprint(\"New features created:\")\nnew_features = ['income_to_loan_ratio', 'debt_burden', 'affordability_ratio', \n               'credit_income_ratio', 'risk_score', 'employment_stability', 'education_num']\nprint(new_features)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-10T08:46:18.811033Z","iopub.execute_input":"2025-11-10T08:46:18.811284Z","iopub.status.idle":"2025-11-10T08:46:19.610464Z","shell.execute_reply.started":"2025-11-10T08:46:18.811263Z","shell.execute_reply":"2025-11-10T08:46:19.609514Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 3: Data Preprocessing and Encoding\nPreparing the data and identifying categorical features for model building. ","metadata":{}},{"cell_type":"code","source":"def preprocess_data(train_df, test_df):\n    # Selecting features for modeling\n    feature_columns = [\n        'annual_income', 'debt_to_income_ratio', 'credit_score', 'loan_amount', 'interest_rate',\n        'income_to_loan_ratio', 'debt_burden', 'affordability_ratio', 'credit_income_ratio', \n        'risk_score', 'employment_stability', 'education_num', 'subgrade_num'\n    ]\n    \n    categorical_cols = ['gender', 'marital_status', 'loan_purpose', 'grade']\n    \n    # Combining train and test for consistent encoding\n    combined = pd.concat([train_df, test_df], axis=0)\n    \n    # Labeling encode categorical variables\n    label_encoders = {}\n    for col in categorical_cols:\n        if col in combined.columns:\n            le = LabelEncoder()\n            combined[col] = le.fit_transform(combined[col].astype(str))\n            label_encoders[col] = le\n    \n    # Spliting back\n    train_processed = combined.iloc[:len(train_df)].copy()\n    test_processed = combined.iloc[len(train_df):].copy()\n    \n    # Preparing final feature set\n    all_features = feature_columns + categorical_cols\n    \n    X_train = train_processed[all_features]\n    y_train = train_processed['loan_paid_back']\n    X_test = test_processed[all_features]\n    \n    # Scale numerical features\n    scaler = StandardScaler()\n    numerical_features_to_scale = [f for f in all_features if f not in categorical_cols]\n    X_train[numerical_features_to_scale] = scaler.fit_transform(X_train[numerical_features_to_scale])\n    X_test[numerical_features_to_scale] = scaler.transform(X_test[numerical_features_to_scale])\n    \n    return X_train, y_train, X_test, scaler, label_encoders\n\nX_train, y_train, X_test, scaler, label_encoders = preprocess_data(train_df_eng, test_df_eng)\n\nprint(\"Training features shape:\", X_train.shape)\nprint(\"Test features shape:\", X_test.shape)\nprint(\"Features used:\", X_train.columns.tolist())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-10T08:46:19.612889Z","iopub.execute_input":"2025-11-10T08:46:19.613161Z","iopub.status.idle":"2025-11-10T08:46:21.098977Z","shell.execute_reply.started":"2025-11-10T08:46:19.61314Z","shell.execute_reply":"2025-11-10T08:46:21.097937Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 4: Model Building with Stacking Ensemble\nStacking is a machine learning ensemble technique that combines multiple base models to create a more accurate super model. In this case, we are using CatBoost,XGBoost & Random Forest.","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import roc_auc_score\n\n# Splitting data for validation\nX = X_train\ny = y_train\n\nX_train_split, X_val, y_train_split, y_val = train_test_split(\n    X, y, test_size=0.2, random_state=42, stratify=y\n)\n\nprint(f\"Training samples: {X_train_split.shape[0]}\")\nprint(f\"Validation samples: {X_val.shape[0]}\")\n\n# Simplified models with faster training\nxgb_model = XGBClassifier(\n    n_estimators=100, \n    max_depth=6,\n    learning_rate=0.1,\n    subsample=0.8,\n    colsample_bytree=0.8,\n    random_state=42,\n    eval_metric='logloss',\n    n_jobs=-1  # Use all cores\n)\n\ncat_model = CatBoostClassifier(\n    iterations=100, \n    depth=6,\n    learning_rate=0.1,\n    random_state=42,\n    verbose=False,\n    thread_count=-1  # Use all cores\n)\n\nrf_model = RandomForestClassifier(\n    n_estimators=50, \n    max_depth=10,\n    random_state=42,\n    n_jobs=-1  # Use all cores\n)\n\nprint(\"Training base models...\")\n\nprint(\"Training XGBoost...\", end=\" \")\nxgb_model.fit(X_train_split, y_train_split)\nxgb_val_pred = xgb_model.predict_proba(X_val)[:, 1]\nprint(\"✓\")\n\nprint(\"Training CatBoost...\", end=\" \")\ncat_model.fit(X_train_split, y_train_split)\ncat_val_pred = cat_model.predict_proba(X_val)[:, 1]\nprint(\"✓\")\n\nprint(\"Training Random Forest...\", end=\" \")\nrf_model.fit(X_train_split, y_train_split)\nrf_val_pred = rf_model.predict_proba(X_val)[:, 1]\nprint(\"✓\")\n\n# Creating meta-features for stacking\nmeta_features_val = np.column_stack([xgb_val_pred, cat_val_pred, rf_val_pred])\n\n# Simple meta-model (Logistic Regression)\nmeta_model = LogisticRegression(random_state=42, C=1.0)\nmeta_model.fit(meta_features_val, y_val)\n\nprint(\"Meta-model trained successfully!\")\n\n# Evaluating base models\nprint(\"\\nBase Model Performance (Validation AUC):\")\nprint(f\"XGBoost: {roc_auc_score(y_val, xgb_val_pred):.4f}\")\nprint(f\"CatBoost: {roc_auc_score(y_val, cat_val_pred):.4f}\")\nprint(f\"Random Forest: {roc_auc_score(y_val, rf_val_pred):.4f}\")\n\n# Ensemble performance\nensemble_val_pred = meta_model.predict_proba(meta_features_val)[:, 1]\nprint(f\"Stacking Ensemble: {roc_auc_score(y_val, ensemble_val_pred):.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-10T08:46:21.100092Z","iopub.execute_input":"2025-11-10T08:46:21.100492Z","iopub.status.idle":"2025-11-10T08:46:58.97535Z","shell.execute_reply.started":"2025-11-10T08:46:21.100464Z","shell.execute_reply":"2025-11-10T08:46:58.974376Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Final Model Training and Predictions","metadata":{}},{"cell_type":"code","source":"# Retraining base models on full training data\nprint(\"\\nRetraining models on full training data...\")\n\nprint(\"Training XGBoost on full data...\", end=\" \")\nxgb_model.fit(X_train, y_train)\nprint(\"✓\")\n\nprint(\"Training CatBoost on full data...\", end=\" \")\ncat_model.fit(X_train, y_train)\nprint(\"✓\")\n\nprint(\"Training Random Forest on full data...\", end=\" \")\nrf_model.fit(X_train, y_train)\nprint(\"✓\")\n\nprint(\"\\nGenerating test predictions...\")\n\nxgb_test_pred = xgb_model.predict_proba(X_test)[:, 1]\ncat_test_pred = cat_model.predict_proba(X_test)[:, 1]\nrf_test_pred = rf_model.predict_proba(X_test)[:, 1]\n\n# Creating meta-features for test set\nmeta_features_test = np.column_stack([xgb_test_pred, cat_test_pred, rf_test_pred])\n\n# Final ensemble predictions\nfinal_predictions = meta_model.predict_proba(meta_features_test)[:, 1]\n\nprint(\"All predictions generated!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-10T08:46:58.976387Z","iopub.execute_input":"2025-11-10T08:46:58.976852Z","iopub.status.idle":"2025-11-10T08:47:45.392082Z","shell.execute_reply.started":"2025-11-10T08:46:58.976822Z","shell.execute_reply":"2025-11-10T08:47:45.391126Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 5: EDA and Feature Understanding\nSome visualizations and understanding of the data","metadata":{}},{"cell_type":"code","source":"# Checking target distribution\nplt.figure(figsize=(8, 6))\nsns.countplot(x='loan_paid_back', data=train_df)\nplt.title('Target Variable Distribution')\nplt.show()\n\nprint(\"Target distribution:\")\nprint(train_df['loan_paid_back'].value_counts(normalize=True))\n\n# Checking correlation with numerical features\nnumerical_features = ['annual_income', 'debt_to_income_ratio', 'credit_score', 'loan_amount', 'interest_rate']\nplt.figure(figsize=(10, 8))\ncorr_matrix = train_df[numerical_features + ['loan_paid_back']].corr()\nsns.heatmap(corr_matrix, annot=True, cmap='coolwarm', center=0)\nplt.title('Correlation Matrix')\nplt.show()\n\n# Analyzing categorical features\ncategorical_features = ['gender', 'marital_status', 'education_level', 'employment_status', 'loan_purpose', 'grade_subgrade']\nfor col in categorical_features:\n    print(f\"\\n{col} distribution:\")\n    print(train_df[col].value_counts())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-10T08:47:45.393024Z","iopub.execute_input":"2025-11-10T08:47:45.393351Z","iopub.status.idle":"2025-11-10T08:47:46.376278Z","shell.execute_reply.started":"2025-11-10T08:47:45.393328Z","shell.execute_reply":"2025-11-10T08:47:46.37518Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### 1: Target Distribution with Context","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(15, 5))\n\nplt.subplot(1, 3, 1)\nloan_paid_counts = train_df['loan_paid_back'].value_counts()\ncolors = ['#ff6b6b', '#51cf66']\nplt.pie(loan_paid_counts.values, labels=['Not Paid (0)', 'Paid (1)'], autopct='%1.1f%%', \n        colors=colors, startangle=90)\nplt.title('Loan Repayment Distribution')\n\nplt.subplot(1, 3, 2)\n# Distribution by loan purpose\npurpose_paid = train_df.groupby('loan_purpose')['loan_paid_back'].mean().sort_values(ascending=False)\nsns.barplot(y=purpose_paid.index, x=purpose_paid.values, palette='viridis')\nplt.title('Repayment Rate by Loan Purpose')\nplt.xlabel('Repayment Rate')\n\nplt.subplot(1, 3, 3)\n# Distribution by employment status\nemployment_paid = train_df.groupby('employment_status')['loan_paid_back'].mean().sort_values(ascending=False)\nsns.barplot(y=employment_paid.index, x=employment_paid.values, palette='rocket')\nplt.title('Repayment Rate by Employment Status')\nplt.xlabel('Repayment Rate')\n\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-10T08:47:46.377194Z","iopub.execute_input":"2025-11-10T08:47:46.377517Z","iopub.status.idle":"2025-11-10T08:47:46.916334Z","shell.execute_reply.started":"2025-11-10T08:47:46.377491Z","shell.execute_reply":"2025-11-10T08:47:46.915348Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### 2: Key Numerical Features vs Target","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(16, 12))\n\nplt.subplot(2, 3, 1)\nsns.boxplot(x='loan_paid_back', y='credit_score', data=train_df, palette=colors)\nplt.title('Credit Score vs Loan Repayment')\n\nplt.subplot(2, 3, 2)\nsns.boxplot(x='loan_paid_back', y='annual_income', data=train_df, palette=colors)\nplt.title('Annual Income vs Loan Repayment')\n\nplt.subplot(2, 3, 3)\nsns.boxplot(x='loan_paid_back', y='debt_to_income_ratio', data=train_df, palette=colors)\nplt.title('Debt-to-Income Ratio vs Loan Repayment')\n\nplt.subplot(2, 3, 4)\nsns.boxplot(x='loan_paid_back', y='loan_amount', data=train_df, palette=colors)\nplt.title('Loan Amount vs Loan Repayment')\n\nplt.subplot(2, 3, 5)\nsns.boxplot(x='loan_paid_back', y='interest_rate', data=train_df, palette=colors)\nplt.title('Interest Rate vs Loan Repayment')\n\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-10T08:47:46.917433Z","iopub.execute_input":"2025-11-10T08:47:46.917718Z","iopub.status.idle":"2025-11-10T08:47:48.205152Z","shell.execute_reply.started":"2025-11-10T08:47:46.917698Z","shell.execute_reply":"2025-11-10T08:47:48.204322Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### 3: Risk Analysis by Key Features","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(16, 6))\n\n# risk segments based on credit score and debt ratio\ntrain_df_eng['risk_segment'] = pd.cut(train_df_eng['credit_score'], bins=[0, 600, 700, 800, 850], \n                                    labels=['Poor', 'Fair', 'Good', 'Excellent'])\ntrain_df_eng['debt_level'] = pd.cut(train_df_eng['debt_to_income_ratio'], bins=[0, 0.1, 0.2, 0.3, 1],\n                                  labels=['Low', 'Medium', 'High', 'Very High'])\n\nplt.subplot(1, 2, 1)\nrisk_repayment = train_df_eng.groupby('risk_segment')['loan_paid_back'].mean()\nsns.barplot(x=risk_repayment.index, y=risk_repayment.values, palette='RdYlGn_r')\nplt.title('Repayment Rate by Credit Score Segment')\nplt.ylabel('Repayment Rate')\nplt.xticks(rotation=45)\n\nplt.subplot(1, 2, 2)\ndebt_repayment = train_df_eng.groupby('debt_level')['loan_paid_back'].mean()\nsns.barplot(x=debt_repayment.index, y=debt_repayment.values, palette='RdYlGn_r')\nplt.title('Repayment Rate by Debt Level')\nplt.ylabel('Repayment Rate')\nplt.xticks(rotation=45)\n\nplt.tight_layout()\nplt.show()\n\n# Cleaning up temporary columns\ntrain_df_eng.drop(['risk_segment', 'debt_level'], axis=1, inplace=True, errors='ignore')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-10T08:47:48.208272Z","iopub.execute_input":"2025-11-10T08:47:48.208755Z","iopub.status.idle":"2025-11-10T08:47:48.65239Z","shell.execute_reply.started":"2025-11-10T08:47:48.208721Z","shell.execute_reply":"2025-11-10T08:47:48.651639Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### 4: Distribution Comparison","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(15, 10))\n\nplt.subplot(2, 2, 1)\nsns.violinplot(x='loan_paid_back', y='credit_score', data=train_df, palette=['red', 'green'])\nplt.title('Credit Score Distribution by Repayment Status')\n\nplt.subplot(2, 2, 2)\nsns.violinplot(x='loan_paid_back', y='annual_income', data=train_df, palette=['red', 'green'])\nplt.title('Income Distribution by Repayment Status')\n\nplt.subplot(2, 2, 3)\nsns.violinplot(x='loan_paid_back', y='debt_to_income_ratio', data=train_df, palette=['red', 'green'])\nplt.title('Debt Ratio Distribution by Repayment Status')\n\nplt.subplot(2, 2, 4)\nsns.violinplot(x='loan_paid_back', y='interest_rate', data=train_df, palette=['red', 'green'])\nplt.title('Interest Rate Distribution by Repayment Status')\n\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-10T08:47:48.653331Z","iopub.execute_input":"2025-11-10T08:47:48.653794Z","iopub.status.idle":"2025-11-10T08:47:55.076837Z","shell.execute_reply.started":"2025-11-10T08:47:48.653764Z","shell.execute_reply":"2025-11-10T08:47:55.075846Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### 5: Feature Relationships","metadata":{}},{"cell_type":"code","source":"sample_df = train_df.sample(1000, random_state=42) \n\n# pairplot with hue\nsns.pairplot(sample_df[['annual_income', 'credit_score', 'debt_to_income_ratio', \n                       'loan_amount', 'loan_paid_back']], \n             hue='loan_paid_back', palette=['red', 'green'], \n             diag_kind='kde', plot_kws={'alpha': 0.6})\nplt.suptitle('Feature Relationships Colored by Repayment Status', y=1.02)\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-10T08:47:55.077768Z","iopub.execute_input":"2025-11-10T08:47:55.078062Z","iopub.status.idle":"2025-11-10T08:48:00.085604Z","shell.execute_reply.started":"2025-11-10T08:47:55.078039Z","shell.execute_reply":"2025-11-10T08:48:00.084466Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### 6: Feature Distributions by Repayment Status","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(15, 10))\n\nplt.subplot(2, 2, 1)\nsns.kdeplot(data=train_df, x='credit_score', hue='loan_paid_back', palette=['red', 'green'], fill=True, alpha=0.6)\nplt.title('Credit Score Distribution by Repayment Status')\nplt.axvline(x=670, color='black', linestyle='--', alpha=0.5, label='Good Credit Threshold')\nplt.legend()\n\nplt.subplot(2, 2, 2)\nsns.kdeplot(data=train_df, x='annual_income', hue='loan_paid_back', palette=['red', 'green'], fill=True, alpha=0.6)\nplt.title('Income Distribution by Repayment Status')\nplt.xlabel('Annual Income ($)')\n\nplt.subplot(2, 2, 3)\nsns.kdeplot(data=train_df, x='debt_to_income_ratio', hue='loan_paid_back', palette=['red', 'green'], fill=True, alpha=0.6)\nplt.title('Debt-to-Income Ratio Distribution by Repayment Status')\n\nplt.subplot(2, 2, 4)\nsns.kdeplot(data=train_df, x='interest_rate', hue='loan_paid_back', palette=['red', 'green'], fill=True, alpha=0.6)\nplt.title('Interest Rate Distribution by Repayment Status')\n\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-10T08:48:00.086672Z","iopub.execute_input":"2025-11-10T08:48:00.08695Z","iopub.status.idle":"2025-11-10T08:48:11.718282Z","shell.execute_reply.started":"2025-11-10T08:48:00.086931Z","shell.execute_reply":"2025-11-10T08:48:11.717504Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### 7: Employment Status (Loan & Repayment performance)","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(12, 6))\n\n# creating employment status analysis\nemployment_analysis = train_df.groupby('employment_status').agg({\n    'loan_paid_back': ['count', 'mean']\n}).round(3)\nemployment_analysis.columns = ['total_loans', 'repayment_rate']\n\n# sorting by repayment rate\nemployment_analysis = employment_analysis.sort_values('repayment_rate')\n\n# horizontal stacked bar\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 6))\n\n# Bar 1: Total loans\nax1.barh(employment_analysis.index, employment_analysis['total_loans'], color='skyblue', alpha=0.7)\nax1.set_xlabel('Number of Loans')\nax1.set_title('Loan Volume by Employment Status')\nax1.grid(alpha=0.3, axis='x')\n\n# Bar 2: Repayment rate\ncolors = plt.cm.RdYlGn(employment_analysis['repayment_rate'])\nax2.barh(employment_analysis.index, employment_analysis['repayment_rate'], color=colors, alpha=0.7)\nax2.set_xlabel('Repayment Rate')\nax2.set_title('Repayment Performance by Employment Status')\nax2.set_xlim(0, 1)\nax2.grid(alpha=0.3, axis='x')\n\n# adding value labels\nfor i, (idx, row) in enumerate(employment_analysis.iterrows()):\n    ax1.text(row['total_loans'] + 10, i, f\"{row['total_loans']}\", va='center')\n    ax2.text(row['repayment_rate'] + 0.02, i, f\"{row['repayment_rate']:.1%}\", va='center')\n\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-10T08:50:22.091338Z","iopub.execute_input":"2025-11-10T08:50:22.091743Z","iopub.status.idle":"2025-11-10T08:50:22.604511Z","shell.execute_reply.started":"2025-11-10T08:50:22.09172Z","shell.execute_reply":"2025-11-10T08:50:22.603585Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### 8: Income vs Loan Amount vs Debt Ratio","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(12, 8))\n\nsample_data = train_df.sample(300, random_state=42)  # sample for clarity\n\n# bubble chart where bubble size = debt ratio\nscatter = plt.scatter(x=sample_data['annual_income'], \n                     y=sample_data['loan_amount'],\n                     s=sample_data['debt_to_income_ratio'] * 1000,  # scale bubble size\n                     c=sample_data['loan_paid_back'], \n                     cmap='RdYlGn', alpha=0.6)\n\nplt.colorbar(scatter, label='Loan Paid Back (0=No, 1=Yes)')\nplt.xlabel('Annual Income ($)')\nplt.ylabel('Loan Amount ($)')\nplt.title('Income vs Loan Amount\\n(Bubble Size = Debt-to-Income Ratio)')\nplt.grid(alpha=0.3)\n\n# Adding legend for bubble sizes\nfor ratio in [0.1, 0.3, 0.5]:\n    plt.scatter([], [], s=ratio * 1000, alpha=0.6, color='gray', \n               label=f'DTI: {ratio}')\nplt.legend(title='Debt Ratio', loc='upper right')\n\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-10T08:53:27.530426Z","iopub.execute_input":"2025-11-10T08:53:27.53145Z","iopub.status.idle":"2025-11-10T08:53:27.940756Z","shell.execute_reply.started":"2025-11-10T08:53:27.531415Z","shell.execute_reply":"2025-11-10T08:53:27.93964Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 6: Final Predictions and Submission\nFinal prediction for the competition and submission file","metadata":{}},{"cell_type":"code","source":"# submission file\nsubmission_df = pd.DataFrame({\n    'id': test_df['id'],\n    'loan_paid_back': final_predictions,\n})\n\nprint(\"Prediction Summary:\")\nprint(f\"Mean probability: {final_predictions.mean():.4f}\")\n\nsubmission_df.to_csv('/kaggle/working/submission.csv', index=False)\n\nprint(submission_df.head())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-10T08:48:11.719362Z","iopub.execute_input":"2025-11-10T08:48:11.719689Z","iopub.status.idle":"2025-11-10T08:48:12.311239Z","shell.execute_reply.started":"2025-11-10T08:48:11.719666Z","shell.execute_reply":"2025-11-10T08:48:12.310499Z"}},"outputs":[],"execution_count":null}]}