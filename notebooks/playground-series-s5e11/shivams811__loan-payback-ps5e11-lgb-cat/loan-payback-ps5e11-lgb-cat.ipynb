{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":91722,"databundleVersionId":14262372,"sourceType":"competition"}],"dockerImageVersionId":31153,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Importing Libraries","metadata":{}},{"cell_type":"code","source":"import warnings\nwarnings.filterwarnings(\"ignore\")\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.preprocessing import StandardScaler, OrdinalEncoder, OneHotEncoder\nfrom xgboost import XGBClassifier\nfrom catboost import CatBoostClassifier\nfrom sklearn.model_selection import StratifiedKFold, train_test_split\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.ensemble import StackingClassifier, StackingRegressor, VotingClassifier\nfrom sklearn.linear_model import LogisticRegression\nimport optuna\nfrom lightgbm import LGBMClassifier","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-04T10:49:56.134847Z","iopub.execute_input":"2025-11-04T10:49:56.135306Z","iopub.status.idle":"2025-11-04T10:49:56.14281Z","shell.execute_reply.started":"2025-11-04T10:49:56.135269Z","shell.execute_reply":"2025-11-04T10:49:56.141595Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Loading Data","metadata":{}},{"cell_type":"code","source":"train_df = pd.read_csv('/kaggle/input/playground-series-s5e11/train.csv')\ntest_df = pd.read_csv('/kaggle/input/playground-series-s5e11/test.csv')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-04T10:49:56.145346Z","iopub.execute_input":"2025-11-04T10:49:56.145775Z","iopub.status.idle":"2025-11-04T10:49:57.392167Z","shell.execute_reply.started":"2025-11-04T10:49:56.145743Z","shell.execute_reply":"2025-11-04T10:49:57.390667Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-04T10:49:57.392938Z","iopub.execute_input":"2025-11-04T10:49:57.393187Z","iopub.status.idle":"2025-11-04T10:49:57.41167Z","shell.execute_reply.started":"2025-11-04T10:49:57.393168Z","shell.execute_reply":"2025-11-04T10:49:57.41037Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Performing EDA","metadata":{}},{"cell_type":"code","source":"train_df.info()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-04T10:49:57.414341Z","iopub.execute_input":"2025-11-04T10:49:57.414652Z","iopub.status.idle":"2025-11-04T10:49:57.634754Z","shell.execute_reply.started":"2025-11-04T10:49:57.414625Z","shell.execute_reply":"2025-11-04T10:49:57.633713Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_df.describe()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-04T10:49:57.635584Z","iopub.execute_input":"2025-11-04T10:49:57.635852Z","iopub.status.idle":"2025-11-04T10:49:57.828007Z","shell.execute_reply.started":"2025-11-04T10:49:57.635831Z","shell.execute_reply":"2025-11-04T10:49:57.826979Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_df.isna().sum()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-04T10:49:57.829088Z","iopub.execute_input":"2025-11-04T10:49:57.829318Z","iopub.status.idle":"2025-11-04T10:49:58.022715Z","shell.execute_reply.started":"2025-11-04T10:49:57.829301Z","shell.execute_reply":"2025-11-04T10:49:58.021477Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_df.duplicated().sum()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-04T10:49:58.023661Z","iopub.execute_input":"2025-11-04T10:49:58.023983Z","iopub.status.idle":"2025-11-04T10:49:58.397773Z","shell.execute_reply.started":"2025-11-04T10:49:58.023961Z","shell.execute_reply":"2025-11-04T10:49:58.396524Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_df['loan_paid_back'].value_counts()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-04T10:49:58.398948Z","iopub.execute_input":"2025-11-04T10:49:58.399325Z","iopub.status.idle":"2025-11-04T10:49:58.41593Z","shell.execute_reply.started":"2025-11-04T10:49:58.399299Z","shell.execute_reply":"2025-11-04T10:49:58.414992Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"cat_cols = ['gender', 'marital_status', 'education_level', 'employment_status', 'loan_purpose', 'grade_subgrade']\nnum_cols = ['annual_income', 'debt_to_income_ratio', 'credit_score', 'loan_amount', 'interest_rate']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-04T10:49:58.419153Z","iopub.execute_input":"2025-11-04T10:49:58.419447Z","iopub.status.idle":"2025-11-04T10:49:58.441399Z","shell.execute_reply.started":"2025-11-04T10:49:58.419427Z","shell.execute_reply":"2025-11-04T10:49:58.439979Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\nnum_cols = ['annual_income', 'debt_to_income_ratio', 'credit_score',\n            'loan_amount', 'interest_rate']\n\nprint(\"\\n--- Numerical Columns Analysis ---\")\nfor col in num_cols:\n    print(f\"\\nðŸ”¹ {col}\")\n    \n    plt.figure(figsize=(10,4))\n    plt.subplot(1,2,1)\n    sns.histplot(train_df[col], kde=True)\n    plt.title(f\"Distribution of {col}\")\n    \n    plt.subplot(1,2,2)\n    sns.boxplot(x=train_df[col])\n    plt.title(f\"Boxplot of {col}\")\n    \n    plt.show()\n\ncat_cols = ['gender', 'marital_status', 'education_level',\n            'employment_status', 'loan_purpose', 'grade_subgrade']\n\nprint(\"\\n--- Categorical Columns Analysis ---\")\nfor col in cat_cols:\n    print(f\"\\nðŸ”¹ {col}\")\n    print(train_df[col].value_counts(normalize=True).head())\n    \n    plt.figure(figsize=(8,4))\n    sns.countplot(data=train_df, x=col, order=train_df[col].value_counts().index)\n    plt.title(f\"Countplot of {col}\")\n    plt.xticks(rotation=45)\n    plt.show()\n\nplt.figure(figsize=(8,6))\nsns.heatmap(train_df[num_cols + ['loan_paid_back']].corr(), annot=True, cmap='coolwarm')\nplt.title(\"Correlation Heatmap\")\nplt.show()\n\ntarget = 'loan_paid_back'\n\nfor col in num_cols:\n    plt.figure(figsize=(6,4))\n    sns.kdeplot(data=train_df, x=col, hue='loan_paid_back', fill=True)\n\n    plt.title(f\"{col} vs {target}\")\n    plt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-04T10:49:58.442625Z","iopub.execute_input":"2025-11-04T10:49:58.442993Z","iopub.status.idle":"2025-11-04T10:50:34.450827Z","shell.execute_reply.started":"2025-11-04T10:49:58.442964Z","shell.execute_reply":"2025-11-04T10:50:34.449724Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Feature Engineering\n### I reused a frequency + quantile-bin feature-generation function from this [notebook](https://www.kaggle.com/code/yousefelshahat2/simple-xgboost-only-competition-data-s5e11/notebook).","metadata":{}},{"cell_type":"code","source":"def create_frequency_features(df, df_test):\n    \"\"\"\n    Add frequency and binning features efficiently.\n\n    - For each categorical column, create <col>_freq = how often each value appears in train data.\n    - For numeric columns, split values into 5, 10, 15 quantile bins.\n    \"\"\"\n    # Pre-allocate DataFrames for new features to avoid fragmentation\n    freq_features_train = pd.DataFrame(index=df.index)\n    freq_features_test = pd.DataFrame(index=df_test.index)\n    bin_features_train = pd.DataFrame(index=df.index)\n    bin_features_test = pd.DataFrame(index=df_test.index)\n\n    for col in cols:\n        # --- Frequency encoding ---\n        freq = df[col].value_counts()\n        df[f\"{col}_freq\"] = df[col].map(freq)\n        freq_features_test[f\"{col}_freq\"] = df_test[col].map(freq).fillna(freq.mean())\n\n        # --- Quantile binning for numeric columns ---\n        if col in num:\n            for q in [5, 10, 15]:\n                try:\n                    train_bins, bins = pd.qcut(df[col], q=q, labels=False, retbins=True, duplicates=\"drop\")\n                    bin_features_train[f\"{col}_bin{q}\"] = train_bins\n                    bin_features_test[f\"{col}_bin{q}\"] = pd.cut(df_test[col], bins=bins, labels=False, include_lowest=True)\n                except Exception:\n                    bin_features_train[f\"{col}_bin{q}\"] = 0\n                    bin_features_test[f\"{col}_bin{q}\"] = 0\n\n    # Concatenate all new features at once\n    df = pd.concat([df, freq_features_train, bin_features_train], axis=1)\n    df_test = pd.concat([df_test, freq_features_test, bin_features_test], axis=1)\n\n    return df, df_test","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-04T10:50:34.45186Z","iopub.execute_input":"2025-11-04T10:50:34.452269Z","iopub.status.idle":"2025-11-04T10:50:34.461645Z","shell.execute_reply.started":"2025-11-04T10:50:34.45224Z","shell.execute_reply":"2025-11-04T10:50:34.460643Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"cols = train_df.drop(columns=[target,\"id\"]).columns.tolist()\nnum = [c for c in cols if train_df[c].dtype not in [\"object\",\"category\",\"bool\"]]\nprint(\"num: \", num)\nprint(\"cols: \", cols)\ntrain_df, test_df = create_frequency_features(train_df, test_df)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-04T10:50:34.462666Z","iopub.execute_input":"2025-11-04T10:50:34.462924Z","iopub.status.idle":"2025-11-04T10:50:36.940659Z","shell.execute_reply.started":"2025-11-04T10:50:34.462906Z","shell.execute_reply":"2025-11-04T10:50:36.939471Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"remove = [ \"interest_rate\", \n         \"employment_status_freq\", \"credit_score_bin5\",  \"loan_amount_bin5\",\n          \"debt_to_income_ratio_bin5\"]\ntrain_df, test_df = train_df.drop(columns = remove), test_df.drop(columns = remove)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-04T10:50:36.941815Z","iopub.execute_input":"2025-11-04T10:50:36.94209Z","iopub.status.idle":"2025-11-04T10:50:37.062018Z","shell.execute_reply.started":"2025-11-04T10:50:36.942068Z","shell.execute_reply":"2025-11-04T10:50:37.060752Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Handling Skewness","metadata":{}},{"cell_type":"code","source":"# for col in num_cols:\n#     print(f\"{col} skewness: {train_df[col].skew()}\")\n#     print(f\"{col} skewness: {test_df[col].skew()}\")\n\ntrain_df['annual_income_log'] = np.log1p(train_df['annual_income'])\ntrain_df['debt_to_income_ratio_log'] = np.log1p(train_df['debt_to_income_ratio'])\ntrain_df.drop(columns=['annual_income', 'debt_to_income_ratio'], inplace=True)\n\ntest_df['annual_income_log'] = np.log1p(test_df['annual_income'])\ntest_df['debt_to_income_ratio_log'] = np.log1p(test_df['debt_to_income_ratio'])\ntest_df.drop(columns=['annual_income', 'debt_to_income_ratio'], inplace=True)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-04T10:50:37.06299Z","iopub.execute_input":"2025-11-04T10:50:37.063527Z","iopub.status.idle":"2025-11-04T10:50:37.17894Z","shell.execute_reply.started":"2025-11-04T10:50:37.063342Z","shell.execute_reply":"2025-11-04T10:50:37.177777Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Encoding Categorical Features","metadata":{}},{"cell_type":"code","source":"education_order = [\n    \"Other\",\n    \"High School\",\n    \"Bachelor's\",\n    \"Master's\",\n    \"PhD\"\n]\ngrade_order = [\n    'A1','A2','A3','A4','A5',\n    'B1','B2','B3','B4','B5',\n    'C1','C2','C3','C4','C5',\n    'D1','D2','D3','D4','D5',\n    'E1','E2','E3','E4','E5',\n    'F1','F2','F3','F4','F5',\n]\nordinal_cols = ['education_level', 'grade_subgrade']\nordinal_categories = [education_order, grade_order]\n\nnominal_cols = ['gender', 'marital_status', 'employment_status', 'loan_purpose']\n\npreprocessor = ColumnTransformer([\n    ('ord', OrdinalEncoder(categories=ordinal_categories), ordinal_cols),\n    ('onehot', OneHotEncoder(drop='first', handle_unknown='ignore'), nominal_cols)\n], remainder='passthrough')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-04T10:50:37.179978Z","iopub.execute_input":"2025-11-04T10:50:37.18058Z","iopub.status.idle":"2025-11-04T10:50:37.188048Z","shell.execute_reply.started":"2025-11-04T10:50:37.180541Z","shell.execute_reply":"2025-11-04T10:50:37.187002Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X_train = train_df.drop(columns=['loan_paid_back', 'id'])\ny_train = train_df['loan_paid_back']\nX_test = test_df.drop(columns=['id'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-04T10:50:37.189161Z","iopub.execute_input":"2025-11-04T10:50:37.189625Z","iopub.status.idle":"2025-11-04T10:50:37.303878Z","shell.execute_reply.started":"2025-11-04T10:50:37.189599Z","shell.execute_reply":"2025-11-04T10:50:37.30256Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X_train_encoded = preprocessor.fit_transform(X_train)\nX_test_encoded = preprocessor.transform(X_test)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-04T10:50:37.304974Z","iopub.execute_input":"2025-11-04T10:50:37.305283Z","iopub.status.idle":"2025-11-04T10:50:39.19606Z","shell.execute_reply.started":"2025-11-04T10:50:37.305251Z","shell.execute_reply":"2025-11-04T10:50:39.195033Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"X_train_encoded shape:\", X_train_encoded.shape)\nprint(\"y_train shape:\", y_train.shape)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-04T10:50:39.197175Z","iopub.execute_input":"2025-11-04T10:50:39.197505Z","iopub.status.idle":"2025-11-04T10:50:39.202846Z","shell.execute_reply.started":"2025-11-04T10:50:39.197475Z","shell.execute_reply":"2025-11-04T10:50:39.201862Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Model Building & CV","metadata":{}},{"cell_type":"code","source":"xgb_params = {'n_estimators': 1250, 'max_depth': 3, 'learning_rate': 0.13510868166273501, 'subsample': 0.8794864404235258, 'colsample_bytree': 0.976543804857637, 'gamma': 0.2829961549131938, 'min_child_weight': 2, 'reg_alpha': 6.433167562715905, 'reg_lambda': 7.292109939548801}\nlgb_params = { 'verbosity':-1, 'n_estimators': 1942, 'max_depth': 3, 'learning_rate': 0.12093539056257775, 'subsample': 0.9643697539245966, 'colsample_bytree': 0.6138587381273723, 'min_child_weight': 4, 'reg_alpha': 3.9731738630617075, 'reg_lambda': 9.182017682059731}\ncat_params = { 'verbose':0, 'iterations': 2623, 'depth': 3, 'learning_rate': 0.16286923955599264, 'l2_leaf_reg': 0.7407588360827997, 'random_strength': 0.19727874622488412, 'bagging_temperature': 6.525351017328033, 'border_count': 250}\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-04T10:50:39.204008Z","iopub.execute_input":"2025-11-04T10:50:39.204334Z","iopub.status.idle":"2025-11-04T10:50:39.224603Z","shell.execute_reply.started":"2025-11-04T10:50:39.204305Z","shell.execute_reply":"2025-11-04T10:50:39.223622Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"xgb_model = XGBClassifier(\n    **xgb_params\n)\n\nlgb_model = LGBMClassifier(**lgb_params)\ncat_model = CatBoostClassifier(**cat_params)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-04T10:50:39.225665Z","iopub.execute_input":"2025-11-04T10:50:39.225947Z","iopub.status.idle":"2025-11-04T10:50:39.252185Z","shell.execute_reply.started":"2025-11-04T10:50:39.225927Z","shell.execute_reply":"2025-11-04T10:50:39.250961Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n\nroc_scores = []\n\n\nfor fold, (train_idx, val_idx) in enumerate(kf.split(X_train_encoded, y_train)):\n    print(f\"\\n----- Fold {fold + 1} -----\")\n\n    X_train, X_val = X_train_encoded[train_idx], X_train_encoded[val_idx]\n    y_trn, y_val = y_train[train_idx], y_train[val_idx]\n\n   \n    scaler = StandardScaler()\n    X_train_scaled = scaler.fit_transform(X_train)\n    X_val_scaled = scaler.transform(X_val)\n\n   \n    lgb_model.fit(X_train_scaled, y_trn)\n    cat_model.fit(X_train_scaled, y_trn)\n    \n\n\n    y_pred_proba = (lgb_model.predict_proba(X_val_scaled)[:, 1]+ cat_model.predict_proba(X_val_scaled)[:, 1])/2\n    roc = roc_auc_score(y_val, y_pred_proba)\n    roc_scores.append(roc)\n\n\n    print(f\"ROC-AUC (Fold {fold + 1}): {roc:.4f}\")\n\n\nprint(\"\\n========================\")\nprint(f\"Average ROC-AUC: {np.mean(roc_scores):.4f}\")\nprint(\"========================\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-04T10:50:39.253183Z","iopub.execute_input":"2025-11-04T10:50:39.253613Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Scaling Data","metadata":{}},{"cell_type":"code","source":"scaler = StandardScaler()\nX_train_encoded = scaler.fit_transform(X_train_encoded)\n\nX_test_encoded = scaler.transform(X_test_encoded)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Training on Complete Data","metadata":{}},{"cell_type":"code","source":"lgb_model.fit(X_train_encoded, y_train)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"cat_model.fit(X_train_encoded, y_train)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Submission","metadata":{}},{"cell_type":"code","source":"submission = pd.DataFrame({\n    'id':test_df['id'],\n    'loan_paid_back':(lgb_model.predict_proba(X_test_encoded)[:,1]+cat_model.predict_proba(X_test_encoded)[:,1])/2\n})\nsubmission.to_csv(\"submission.csv\", index=False)\n\nsubmission.head()","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}