{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.13"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":91722,"databundleVersionId":14262372,"sourceType":"competition"}],"dockerImageVersionId":31153,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false},"papermill":{"default_parameters":{},"duration":105.242032,"end_time":"2025-11-04T01:00:17.484139","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2025-11-04T00:58:32.242107","version":"2.6.0"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<div style=\"background-color:#e8f5e9; padding:10px; border-radius:5px; line-height:1.6;\">\n\n<h1 style=\"color:#1b5e20;\">CatBoost Model for Loan Payback Prediction</h1>\n\n<p>This notebook builds a <strong>simple and effective CatBoost model</strong> for predicting loan repayment probability.<br>\nIt aims to serve as a <strong>beginner-friendly baseline</strong> for the <em>Predicting Loan Payback</em> competition.</p>\n\n<h3 style=\"color:#2e7d32;\">ðŸ“‹ Workflow</h3>\n<ol>\n  <li>Import necessary libraries</li>\n  <li>Load and inspect the dataset</li>\n  <li>Handle missing values and encode categorical features</li>\n  <li>Train an XGBoost model</li>\n  <li>Evaluate model performance</li>\n  <li>Create submission file</li>\n</ol>\n\n<h3 style=\"color:#2e7d32;\">ðŸŽ¯ Goal</h3>\n<p>To provide a clear and reproducible baseline that can be easily extended with feature engineering or model tuning.</p>\n\n</div>\n","metadata":{"papermill":{"duration":0.00487,"end_time":"2025-11-04T00:58:36.849321","exception":false,"start_time":"2025-11-04T00:58:36.844451","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"\n\n<h2 style=\"text-align:center; color:#2e7d32; font-weight:700; margin-top:0;\">\n1. Import Libraries\n</h2>","metadata":{"papermill":{"duration":0.003667,"end_time":"2025-11-04T00:58:36.85712","exception":false,"start_time":"2025-11-04T00:58:36.853453","status":"completed"},"tags":[]}},{"cell_type":"code","source":"import os\nimport joblib\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler\nfrom sklearn.model_selection import train_test_split,KFold\n\nimport catboost as cb\nfrom catboost import CatBoostClassifier\n\nfrom sklearn.metrics import (\n    mean_squared_error,\n    mean_absolute_error,\n    r2_score,\n    accuracy_score,\n    precision_score,\n    recall_score,\n    f1_score,\n    roc_auc_score,\n    confusion_matrix,\n    ConfusionMatrixDisplay\n)\n\nimport shap\nimport math\n\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))  # Print dataset file paths","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2025-11-04T00:58:36.867259Z","iopub.status.busy":"2025-11-04T00:58:36.866267Z","iopub.status.idle":"2025-11-04T00:58:49.455604Z","shell.execute_reply":"2025-11-04T00:58:49.45457Z"},"papermill":{"duration":12.596009,"end_time":"2025-11-04T00:58:49.457125","exception":false,"start_time":"2025-11-04T00:58:36.861116","status":"completed"},"tags":[]},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<h2 style=\"text-align:center; color:#2e7d32; font-weight:700; margin-top:0;\">\n2. Load Dataset\n</h2>","metadata":{"papermill":{"duration":0.003717,"end_time":"2025-11-04T00:58:49.465121","exception":false,"start_time":"2025-11-04T00:58:49.461404","status":"completed"},"tags":[]}},{"cell_type":"code","source":"train = pd.read_csv(\"/kaggle/input/playground-series-s5e11/train.csv\")\npredict = pd.read_csv(\"/kaggle/input/playground-series-s5e11/test.csv\")","metadata":{"execution":{"iopub.execute_input":"2025-11-04T00:58:49.474548Z","iopub.status.busy":"2025-11-04T00:58:49.474035Z","iopub.status.idle":"2025-11-04T00:58:51.268823Z","shell.execute_reply":"2025-11-04T00:58:51.267862Z"},"papermill":{"duration":1.801414,"end_time":"2025-11-04T00:58:51.270475","exception":false,"start_time":"2025-11-04T00:58:49.469061","status":"completed"},"tags":[]},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<h2 style=\"text-align:center; color:#2e7d32; font-weight:700; margin-top:0;\">\n3. Data Overview\n</h2>\n","metadata":{"papermill":{"duration":0.003979,"end_time":"2025-11-04T00:58:51.279364","exception":false,"start_time":"2025-11-04T00:58:51.275385","status":"completed"},"tags":[]}},{"cell_type":"code","source":"cat_cols = train.select_dtypes(include='object').columns.tolist()\nif 'loan_paid_back' in cat_cols:\n    cat_cols.remove('loan_paid_back')\n\nsns.set(style=\"whitegrid\")\nnum_plots = len(cat_cols)\nnum_rows = math.ceil(num_plots / 2)\nfig, axes = plt.subplots(num_rows, 2, figsize=(12, 4*num_rows))\n\naxes = axes.flatten() if num_plots > 1 else [axes]\n\nfor idx, col in enumerate(cat_cols):\n    sns.countplot(data=train, x=col, hue='loan_paid_back', ax=axes[idx])\n    axes[idx].set_title(f'Relationship between {col} and loan_paid_back')\n    axes[idx].tick_params(axis='x', rotation=45)\n    axes[idx].legend(title='loan_paid_back')\n\nfor j in range(idx+1, len(axes)):\n    axes[j].set_visible(False)\n\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.execute_input":"2025-11-04T00:58:51.288264Z","iopub.status.busy":"2025-11-04T00:58:51.287961Z","iopub.status.idle":"2025-11-04T00:58:55.401219Z","shell.execute_reply":"2025-11-04T00:58:55.400172Z"},"papermill":{"duration":4.122273,"end_time":"2025-11-04T00:58:55.405533","exception":false,"start_time":"2025-11-04T00:58:51.28326","status":"completed"},"tags":[]},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<h2 style=\"text-align:center; color:#2e7d32; font-weight:700; margin-top:0;\">\n4. Data Preprocessing\n</h2>","metadata":{"papermill":{"duration":0.008335,"end_time":"2025-11-04T00:58:55.423156","exception":false,"start_time":"2025-11-04T00:58:55.414821","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# Create new features from grade_subgrade and remove unnecessary columns\ndef create_features(df):\n    df['grade'] = df['grade_subgrade'].str[0]\n    df['subgrade'] = df['grade_subgrade'].str[1:].astype(int)\n\n    return df\n\ntrain = create_features(train)\npredict = create_features(predict)","metadata":{"execution":{"iopub.execute_input":"2025-11-04T00:58:55.441838Z","iopub.status.busy":"2025-11-04T00:58:55.441517Z","iopub.status.idle":"2025-11-04T00:58:55.845715Z","shell.execute_reply":"2025-11-04T00:58:55.844596Z"},"papermill":{"duration":0.415468,"end_time":"2025-11-04T00:58:55.847465","exception":false,"start_time":"2025-11-04T00:58:55.431997","status":"completed"},"tags":[]},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def delete_features(df):\n    df = df.drop(columns=(['grade_subgrade','gender','marital_status']))   \n    return df\ntrain = delete_features(train)\npredict = delete_features(predict)","metadata":{"execution":{"iopub.execute_input":"2025-11-04T00:58:55.866464Z","iopub.status.busy":"2025-11-04T00:58:55.866111Z","iopub.status.idle":"2025-11-04T00:58:55.920404Z","shell.execute_reply":"2025-11-04T00:58:55.919439Z"},"papermill":{"duration":0.065676,"end_time":"2025-11-04T00:58:55.922123","exception":false,"start_time":"2025-11-04T00:58:55.856447","status":"completed"},"tags":[]},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# One-Hot Encoding\ndef one_hot_encode(df):\n    object_cols = df.select_dtypes(include=['object']).columns.tolist()\n    df = pd.get_dummies(df, columns=object_cols, drop_first=False)\n    return df\n\ntrain = one_hot_encode(train)\npredict = one_hot_encode(predict)\n\nmissing_cols = set(train.columns) - set(predict.columns)\nfor col in missing_cols:\n    predict[col] = 0\n\npredict = predict[train.columns]\npredict = predict.drop(columns=['loan_paid_back'])","metadata":{"execution":{"iopub.execute_input":"2025-11-04T00:58:55.94102Z","iopub.status.busy":"2025-11-04T00:58:55.940707Z","iopub.status.idle":"2025-11-04T00:58:56.429466Z","shell.execute_reply":"2025-11-04T00:58:56.428581Z"},"papermill":{"duration":0.500759,"end_time":"2025-11-04T00:58:56.431758","exception":false,"start_time":"2025-11-04T00:58:55.930999","status":"completed"},"tags":[]},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Convert boolean columns\n\ndef bool_to_int(df):\n    bool_columns = df.select_dtypes(include='bool').columns\n    for col in bool_columns:\n        df[col] = df[col].astype(int)\n    return df\n\ntrain = bool_to_int(train)\npredict = bool_to_int(predict)","metadata":{"execution":{"iopub.execute_input":"2025-11-04T00:58:56.452004Z","iopub.status.busy":"2025-11-04T00:58:56.451682Z","iopub.status.idle":"2025-11-04T00:58:56.531219Z","shell.execute_reply":"2025-11-04T00:58:56.530409Z"},"papermill":{"duration":0.090832,"end_time":"2025-11-04T00:58:56.53289","exception":false,"start_time":"2025-11-04T00:58:56.442058","status":"completed"},"tags":[]},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Add target mean encoding and count encoding features efficiently\n# This version avoids DataFrame fragmentation by concatenating columns at once\n\ndef add_target_count_features(train, predict, target_col, n_splits=10):\n    BASE = [c for c in train.columns if c not in [target_col]]\n    kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n\n    mean_features = pd.DataFrame(index=train.index)\n    count_features = pd.DataFrame(index=train.index)\n    mean_features_pred = pd.DataFrame(index=predict.index)\n    count_features_pred = pd.DataFrame(index=predict.index)\n\n    for col in BASE:\n        if train[col].isnull().all():\n            continue\n\n        # === Mean Encoding with K-Fold (leakage prevention) ===\n        mean_encoded = np.zeros(len(train))\n        for tr_idx, val_idx in kf.split(train):\n            tr_fold = train.iloc[tr_idx]\n            val_fold = train.iloc[val_idx]\n            mean_map = tr_fold.groupby(col)[target_col].mean()\n            mean_encoded[val_idx] = val_fold[col].map(mean_map)\n\n        mean_features[f'mean_{col}'] = mean_encoded\n\n        # Apply global mean mapping to prediction data\n        global_mean = train.groupby(col)[target_col].mean()\n        mean_features_pred[f'mean_{col}'] = predict[col].map(global_mean)\n\n        # === Count Encoding ===\n        count_map = train[col].value_counts().to_dict()\n        count_features[f'count_{col}'] = train[col].map(count_map)\n        count_features_pred[f'count_{col}'] = predict[col].map(count_map)\n\n    # === Concatenate all features at once to avoid fragmentation ===\n    train = pd.concat([train, mean_features, count_features], axis=1)\n    predict = pd.concat([predict, mean_features_pred, count_features_pred], axis=1)\n\n    # Defragment DataFrames for better performance\n    train = train.copy()\n    predict = predict.copy()\n\n    print(f\"{len(mean_features.columns) + len(count_features.columns)} features created!\")\n    return train, predict\n\n\ntrain, predict = add_target_count_features(train, predict, target_col='loan_paid_back')","metadata":{"execution":{"iopub.execute_input":"2025-11-04T00:58:56.552063Z","iopub.status.busy":"2025-11-04T00:58:56.551755Z","iopub.status.idle":"2025-11-04T00:59:20.360866Z","shell.execute_reply":"2025-11-04T00:59:20.359815Z"},"papermill":{"duration":23.820691,"end_time":"2025-11-04T00:59:20.362314","exception":false,"start_time":"2025-11-04T00:58:56.541623","status":"completed"},"tags":[]},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def split_data(df,test_size=0.2,random_state=42):\n    X = df.drop(columns=['id','loan_paid_back'])\n    y = df['loan_paid_back']\n\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)\n    return X_train, X_test, y_train, y_test\n\nX_train, X_test, y_train, y_test = split_data(train)\n\npredict_X = predict.copy()\npredict_X = predict_X.drop(columns=['id'])","metadata":{"execution":{"iopub.execute_input":"2025-11-04T00:59:20.381924Z","iopub.status.busy":"2025-11-04T00:59:20.381629Z","iopub.status.idle":"2025-11-04T00:59:21.17274Z","shell.execute_reply":"2025-11-04T00:59:21.17168Z"},"papermill":{"duration":0.802857,"end_time":"2025-11-04T00:59:21.174455","exception":false,"start_time":"2025-11-04T00:59:20.371598","status":"completed"},"tags":[]},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"\n<h2 style=\"text-align:center; color:#2e7d32; font-weight:700; margin-top:0;\">\n5. Model Training (XGBoost)\n</h2>\n","metadata":{"papermill":{"duration":0.008986,"end_time":"2025-11-04T00:59:21.192901","exception":false,"start_time":"2025-11-04T00:59:21.183915","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# === Function to build a CatBoost model ===\ndef build_catboost_model(iterations=1000, depth=5, learning_rate=0.1, random_state=37):\n\n    # Create a CatBoost classifier\n    model = CatBoostClassifier(\n        iterations=iterations,     # Number of boosting rounds\n        depth=depth,               # Depth of each decision tree\n        learning_rate=learning_rate,  # Learning rate for boosting\n        random_seed=random_state,     # Random seed for reproducibility\n        eval_metric=\"AUC\",            # Evaluation metric = AUC\n        loss_function=\"Logloss\",      # Binary classification loss function\n        verbose=False,                 # Suppress training output\n        allow_writing_files=False\n\n    )\n    return model  # Return the constructed model\n\n\n# === Build and train the model ===\ncatboost_model = build_catboost_model()   # Initialize the model with default parameters\ncatboost_model.fit(X_train, y_train)      # Train the model on training data (features and labels)","metadata":{"execution":{"iopub.execute_input":"2025-11-04T00:59:21.212098Z","iopub.status.busy":"2025-11-04T00:59:21.211741Z","iopub.status.idle":"2025-11-04T00:59:56.40757Z","shell.execute_reply":"2025-11-04T00:59:56.406624Z"},"papermill":{"duration":35.215096,"end_time":"2025-11-04T00:59:56.416883","exception":false,"start_time":"2025-11-04T00:59:21.201787","status":"completed"},"tags":[]},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def explain_model(model):\n    explainer = shap.Explainer(model)\n    shap_values = explainer(X_test)\n    \n    shap.plots.waterfall(shap_values[0])\n\n    shap.plots.beeswarm(shap_values)\n\nexplain_model(catboost_model)","metadata":{"execution":{"iopub.execute_input":"2025-11-04T00:59:56.435456Z","iopub.status.busy":"2025-11-04T00:59:56.435112Z","iopub.status.idle":"2025-11-04T01:00:13.292584Z","shell.execute_reply":"2025-11-04T01:00:13.291665Z"},"papermill":{"duration":16.868808,"end_time":"2025-11-04T01:00:13.294464","exception":false,"start_time":"2025-11-04T00:59:56.425656","status":"completed"},"tags":[]},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"\n<h2 style=\"text-align:center; color:#2e7d32; font-weight:700; margin-top:0;\">\n 6. Evaluation\n</h2>\n","metadata":{"papermill":{"duration":0.013245,"end_time":"2025-11-04T01:00:13.321884","exception":false,"start_time":"2025-11-04T01:00:13.308639","status":"completed"},"tags":[]}},{"cell_type":"code","source":"def evaluate_metrics(y_true, y_pred_proba):\n    results = []\n\n    y_pred = (y_pred_proba >= 0.5).astype(int)\n\n    def calculate_metrics(y_true, y_pred, y_pred_proba):\n        accuracy  = accuracy_score(y_true, y_pred)\n        precision = precision_score(y_true, y_pred, zero_division=0)\n        recall    = recall_score(y_true, y_pred)\n        f1        = f1_score(y_true, y_pred)\n        auc       = roc_auc_score(y_true, y_pred_proba)\n\n        return {\n            'Accuracy': accuracy,\n            'Precision': precision,\n            'Recall': recall,\n            'F1': f1,\n            'AUC': auc,\n        }\n\n    results.append(calculate_metrics(y_true, y_pred, y_pred_proba))\n    return pd.DataFrame(results)","metadata":{"execution":{"iopub.execute_input":"2025-11-04T01:00:13.349425Z","iopub.status.busy":"2025-11-04T01:00:13.349057Z","iopub.status.idle":"2025-11-04T01:00:13.355034Z","shell.execute_reply":"2025-11-04T01:00:13.354157Z"},"papermill":{"duration":0.021455,"end_time":"2025-11-04T01:00:13.356527","exception":false,"start_time":"2025-11-04T01:00:13.335072","status":"completed"},"tags":[]},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_predict_probs = catboost_model.predict_proba(X_test)[:, 1]\n\nthreshold = 0.5\ntrain_predict_binary = (train_predict_probs >= threshold).astype(int)\n\nresults = evaluate_metrics(y_test, train_predict_probs)\ndisplay(results)","metadata":{"execution":{"iopub.execute_input":"2025-11-04T01:00:13.384445Z","iopub.status.busy":"2025-11-04T01:00:13.384103Z","iopub.status.idle":"2025-11-04T01:00:13.748218Z","shell.execute_reply":"2025-11-04T01:00:13.747326Z"},"papermill":{"duration":0.380183,"end_time":"2025-11-04T01:00:13.749872","exception":false,"start_time":"2025-11-04T01:00:13.369689","status":"completed"},"tags":[]},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def plot_confusion(y_true, y_pred, normalize=False, title='Confusion Matrix', cmap=plt.cm.Blues):\n    cm = confusion_matrix(y_true, y_pred, normalize='true' if normalize else None)\n    disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n    disp.plot(cmap=cmap)\n    plt.title(title)\n    plt.show()\n\nplot_confusion(y_test, train_predict_binary, normalize=True, title='Normalized Confusion Matrix')","metadata":{"execution":{"iopub.execute_input":"2025-11-04T01:00:13.778747Z","iopub.status.busy":"2025-11-04T01:00:13.778437Z","iopub.status.idle":"2025-11-04T01:00:14.06737Z","shell.execute_reply":"2025-11-04T01:00:14.066405Z"},"papermill":{"duration":0.304811,"end_time":"2025-11-04T01:00:14.069039","exception":false,"start_time":"2025-11-04T01:00:13.764228","status":"completed"},"tags":[]},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"\n<h2 style=\"text-align:center; color:#2e7d32; font-weight:700; margin-top:0;\">\n 7. Submission\n</h2>\n","metadata":{"papermill":{"duration":0.014032,"end_time":"2025-11-04T01:00:14.097086","exception":false,"start_time":"2025-11-04T01:00:14.083054","status":"completed"},"tags":[]}},{"cell_type":"code","source":"predict_y_probs = catboost_model.predict_proba(predict_X)[:, 1]\npredict_df = pd.DataFrame(predict_y_probs, columns=['loan_paid_back'])\nsubmission = pd.concat([predict['id'], predict_df], axis=1)\n\ndisplay(submission.head())\nprint(submission.isnull().sum())","metadata":{"execution":{"iopub.execute_input":"2025-11-04T01:00:14.126502Z","iopub.status.busy":"2025-11-04T01:00:14.12588Z","iopub.status.idle":"2025-11-04T01:00:14.280501Z","shell.execute_reply":"2025-11-04T01:00:14.279395Z"},"papermill":{"duration":0.171007,"end_time":"2025-11-04T01:00:14.28206","exception":false,"start_time":"2025-11-04T01:00:14.111053","status":"completed"},"tags":[]},"outputs":[],"execution_count":null},{"cell_type":"code","source":"submission.to_csv('submission.csv', index=False)\nprint(\"Submission file saved as 'submission.csv'\")","metadata":{"execution":{"iopub.execute_input":"2025-11-04T01:00:14.312463Z","iopub.status.busy":"2025-11-04T01:00:14.311752Z","iopub.status.idle":"2025-11-04T01:00:14.881239Z","shell.execute_reply":"2025-11-04T01:00:14.880334Z"},"papermill":{"duration":0.586511,"end_time":"2025-11-04T01:00:14.882716","exception":false,"start_time":"2025-11-04T01:00:14.296205","status":"completed"},"tags":[]},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<div style=\"background-color:#e8f5e9; padding:10px; border-radius:5px;\">\n\n<h2 style=\"text-align:center; color:#2e7d32; font-weight:700; margin-top:0;\">\n8. Conclusion\n</h2>\n\n- This simple CatBoost model achieved solid baseline performance.  \n- The confusion matrix shows high precision and recall on positive cases.  \n- Future improvements could include:\n  - Hyperparameter tuning with Optuna  \n  - Feature scaling or interaction terms  \n  - Model calibration for better probability prediction  \n\nThis notebook can be a **good starting point** for anyone joining the *Predicting Loan Payback* competition.\n","metadata":{"papermill":{"duration":0.013944,"end_time":"2025-11-04T01:00:14.910815","exception":false,"start_time":"2025-11-04T01:00:14.896871","status":"completed"},"tags":[]}}]}