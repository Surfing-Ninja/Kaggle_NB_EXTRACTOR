{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":91722,"databundleVersionId":14262372,"sourceType":"competition"}],"dockerImageVersionId":31154,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"Solution generated by https://github.com/bogoconic1/Qgentic-AI","metadata":{}},{"cell_type":"code","source":"import os\nimport sys\nimport time\nimport json\nimport logging\nfrom pathlib import Path\nimport shutil\n\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn.model_selection import StratifiedKFold, train_test_split\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.preprocessing import QuantileTransformer, PowerTransformer, KBinsDiscretizer\n\nimport xgboost as xgb\nimport optuna  # tuning used only in FULL mode\n\n# -------------------------\n# Setup logging early\n# -------------------------\nBASE_DIR = Path(\"/kaggle/input/playground-series-s5e11\")\nOUTPUT_DIR = Path(\".\")\nOUTPUT_DIR.mkdir(parents=True, exist_ok=True)\nLOG_FILE = OUTPUT_DIR / \"code_8_1_v4.txt\"\nSUBMISSION_PATH = OUTPUT_DIR / \"submission_4.csv\"\n\nlogging.basicConfig(\n    level=logging.INFO,\n    format=\"%(asctime)s | %(levelname)s | %(message)s\",\n    handlers=[\n        logging.FileHandler(LOG_FILE, mode=\"w\", encoding=\"utf-8\"),\n        logging.StreamHandler(sys.stdout),\n    ],\n)\nprint(\"Log file initialized at %s\", LOG_FILE)\n\nHF_TOKEN = os.environ.get(\"HF_TOKEN\", \"\")\nprint(\"HF_TOKEN present: %s\", \"yes\" if HF_TOKEN else \"no\")\n\n# -------------------------\n# Device selection for XGBoost (purpose: choose CUDA if available)\n# -------------------------\ndef detect_cuda_available() -> bool:\n    exe = shutil.which(\"nvidia-smi\")\n    if exe is None:\n        return False\n    out = os.popen(f\"{exe} -L\").read().strip()\n    return len(out) > 0\n\nCUDA_AVAILABLE = detect_cuda_available()\nXGB_DEVICE = \"cuda:0\" if CUDA_AVAILABLE else \"cpu\"\nif CUDA_AVAILABLE:\n    print(\"CUDA detected. Using device='%s' with tree_method='hist'.\", XGB_DEVICE)\nelse:\n    print(\"CUDA not detected. Using CPU (device='cpu') with tree_method='hist'.\")\n\n# -------------------------\n# Competition schema\n# -------------------------\nTRAIN_PATH = BASE_DIR / \"train.csv\"\nTEST_PATH = BASE_DIR / \"test.csv\"\nSAMPLE_SUB_PATH = BASE_DIR / \"sample_submission.csv\"\n\nTARGET_COL = \"loan_paid_back\"   # binary classification; metric: ROC AUC\nID_COL = \"id\"\nFOLD_COL = \"fold\"\nMETA_COLS = {TARGET_COL, ID_COL, FOLD_COL}\n\n# Optional numeric columns for special transforms (if present)\nC_INCOME = \"annual_income\"\nC_DTI = \"debt_to_income_ratio\"\n\n# -------------------------\n# Load data (purpose: read CSVs; inputs: train/test paths)\n# -------------------------\ntrain = pd.read_csv(TRAIN_PATH)\ntest = pd.read_csv(TEST_PATH)\nsample_sub = pd.read_csv(SAMPLE_SUB_PATH)\nprint(\"Loaded data. Train shape: %s | Test shape: %s\", train.shape, test.shape)\nassert TARGET_COL in train.columns, f\"Missing target column '{TARGET_COL}' in train.csv\"\nassert ID_COL in train.columns and ID_COL in test.columns, \"Missing id column in train/test.\"\n\n# -------------------------\n# Typing helpers and encoders (purpose: reusable feature builders; inputs: DataFrames/Series)\n# -------------------------\ndef get_cat_num_cols(df: pd.DataFrame, target_col: str, id_col: str, exclude: set):\n    cols = [c for c in df.columns if c not in exclude]\n    cat_cols = [c for c in cols if df[c].dtype == \"object\" or str(df[c].dtype).startswith(\"category\")]\n    num_cols = [c for c in cols if c not in cat_cols]\n    return cat_cols, num_cols\n\ndef pick_top_cats(cat_cols, df, k=6, exclude: set = None):\n    exclude = exclude or set()\n    cands = []\n    for c in cat_cols:\n        if c in exclude:\n            continue\n        n_unique = df[c].nunique(dropna=True)\n        if 2 <= n_unique <= 200:\n            cands.append((c, n_unique))\n    cands.sort(key=lambda t: (-t[1], t[0]))\n    sel = [c for c, _ in cands[:k]]\n    if len(sel) < min(k, len(cat_cols)):\n        rest = [c for c in cat_cols if c not in sel and c not in exclude]\n        sel += rest[: (k - len(sel))]\n    return sel[:k]\n\ndef pick_top_nums(num_cols, df, k=5, exclude: set = None):\n    exclude = exclude or set()\n    stats = []\n    for c in num_cols:\n        if c in exclude:\n            continue\n        series = df[c]\n        if series.dtype.kind not in \"biufc\":\n            continue\n        nunq = series.nunique(dropna=True)\n        if nunq <= 2:\n            continue\n        var = series.var(skipna=True)\n        stats.append((c, 0.0 if pd.isna(var) else float(var)))\n    stats.sort(key=lambda t: -t[1])\n    return [c for c, _ in stats[:k]]\n\ndef add_missing_indicators(df: pd.DataFrame, exclude_cols):\n    for c in df.columns:\n        if c in exclude_cols:\n            continue\n        ind_name = f\"{c}__isna\"\n        if ind_name not in df.columns:\n            df[ind_name] = df[c].isna().astype(np.int8)\n    return df\n\ndef frequency_encode(train_pool: pd.DataFrame, series: pd.Series):\n    counts = train_pool[series.name].value_counts(dropna=False)\n    return counts.to_dict()\n\ndef compute_te_map(x: pd.Series, y: pd.Series, m: float = 10.0):\n    df = pd.DataFrame({\"x\": x, \"y\": y})\n    gr = df.groupby(\"x\")[\"y\"].agg([\"mean\", \"count\"])\n    global_mean = float(y.mean())\n    smooth = (gr[\"mean\"] * gr[\"count\"] + global_mean * m) / (gr[\"count\"] + m)\n    return smooth.to_dict(), global_mean\n\ndef oof_target_encode(train_pool_df, y, col, folds, m=10.0):\n    oof = pd.Series(index=train_pool_df.index, dtype=\"float32\")\n    for f, (tr_idx, va_idx) in folds.items():\n        tr_df = train_pool_df.loc[tr_idx]\n        tr_y = y.loc[tr_idx]\n        mp, gmean = compute_te_map(tr_df[col], tr_y, m)\n        oof.loc[va_idx] = train_pool_df.loc[va_idx, col].map(mp).fillna(gmean).astype(\"float32\")\n    full_map, full_gmean = compute_te_map(train_pool_df[col], y, m)\n    return oof, full_map, full_gmean\n\ndef compute_woe_map(x: pd.Series, y: pd.Series, eps: float = 0.5):\n    df = pd.DataFrame({\"x\": x, \"y\": y})\n    pos = df.groupby(\"x\")[\"y\"].sum(min_count=1)\n    cnt = df.groupby(\"x\")[\"y\"].count()\n    neg = cnt - pos\n    total_pos = float(pos.sum())\n    total_neg = float(neg.sum())\n    dist_pos = (pos + eps) / (total_pos + eps * len(pos))\n    dist_neg = (neg + eps) / (total_neg + eps * len(neg))\n    woe = np.log((dist_pos) / (dist_neg))\n    mapping = woe.to_dict()\n    iv = ((dist_pos - dist_neg) * woe).sum()\n    return mapping, float(iv)\n\ndef oof_woe_encode(train_pool_df, y, col, folds, eps=0.5):\n    oof = pd.Series(index=train_pool_df.index, dtype=\"float32\")\n    for f, (tr_idx, va_idx) in folds.items():\n        tr_df = train_pool_df.loc[tr_idx]\n        tr_y = y.loc[tr_idx]\n        mp, _iv = compute_woe_map(tr_df[col], tr_y, eps)\n        # Clip WOE values to stabilize\n        mp = {k: float(np.clip(v, -3.0, 3.0)) for k, v in mp.items()}\n        oof.loc[va_idx] = train_pool_df.loc[va_idx, col].map(mp).fillna(0.0).astype(\"float32\")\n    full_map, iv_full = compute_woe_map(train_pool_df[col], y, eps)\n    full_map = {k: float(np.clip(v, -3.0, 3.0)) for k, v in full_map.items()}\n    return oof, full_map, iv_full\n\ndef fit_kbins(train_pool_series, n_bins=10):\n    med = float(np.nanmedian(train_pool_series.values))\n    tr_vals = train_pool_series.fillna(med).values.reshape(-1, 1)\n    enc = KBinsDiscretizer(n_bins=n_bins, encode=\"ordinal\", strategy=\"quantile\")\n    enc.fit(tr_vals)\n    return enc, med\n\ndef transform_kbins(enc, med, series):\n    vals = series.fillna(med).values.reshape(-1, 1)\n    b = enc.transform(vals).astype(\"float32\").reshape(-1)\n    b = np.where(np.isfinite(b), b, -1.0)\n    return pd.Series(b, index=series.index, dtype=\"float32\")\n\ndef fit_rank_gaussian(train_pool_series, random_state=2025):\n    med = float(np.nanmedian(train_pool_series.values))\n    tr_vals = train_pool_series.fillna(med).values.reshape(-1, 1)\n    qt = QuantileTransformer(n_quantiles=min(1000, len(tr_vals)), output_distribution=\"normal\", random_state=random_state)\n    qt.fit(tr_vals)\n    return qt, med\n\ndef transform_rank_gaussian(qt, med, series):\n    vals = series.fillna(med).values.reshape(-1, 1)\n    out = qt.transform(vals).astype(\"float32\").reshape(-1)\n    return pd.Series(out, index=series.index, dtype=\"float32\")\n\ndef fit_yeojohnson(train_pool_series):\n    med = float(np.nanmedian(train_pool_series.values))\n    tr_vals = train_pool_series.fillna(med).values.reshape(-1, 1)\n    pt = PowerTransformer(method=\"yeo-johnson\", standardize=True)\n    pt.fit(tr_vals)\n    return pt, med\n\ndef transform_yeojohnson(pt, med, series):\n    vals = series.fillna(med).values.reshape(-1, 1)\n    out = pt.transform(vals).astype(\"float32\").reshape(-1)\n    return pd.Series(out, index=series.index, dtype=\"float32\")\n\ndef group_mean_deviation(train_pool_df, val_df, test_df, cat_cols, num_cols):\n    # Fit group means on train_pool and map to val/test; guard meta columns.\n    for c in cat_cols:\n        if c in META_COLS or c not in train_pool_df.columns:\n            continue\n        for n in num_cols:\n            if n in META_COLS or n not in train_pool_df.columns:\n                continue\n            gname = f\"{n}__gm_{c}\"\n            devname = f\"{n}__dev_{c}\"\n            grp = train_pool_df.groupby(c, observed=True)[n].mean()\n            global_mean = float(train_pool_df[n].mean())\n            train_pool_df[gname] = train_pool_df[c].map(grp).fillna(global_mean).astype(\"float32\")\n            val_df[gname] = val_df[c].map(grp).fillna(global_mean).astype(\"float32\")\n            test_df[gname] = test_df[c].map(grp).fillna(global_mean).astype(\"float32\")\n            train_pool_df[devname] = (train_pool_df[n] - train_pool_df[gname]).astype(\"float32\")\n            val_df[devname] = (val_df[n] - val_df[gname]).astype(\"float32\")\n            test_df[devname] = (test_df[n] - test_df[gname]).astype(\"float32\")\n    return train_pool_df, val_df, test_df\n\ndef group_percentile_feature(train_pool_df, val_df, test_df, group_col, value_col, feature_name, q=100):\n    if group_col not in train_pool_df.columns or value_col not in train_pool_df.columns:\n        print(\"Percentile feature skipped (missing): %s within %s\", value_col, group_col)\n        return train_pool_df, val_df, test_df\n    edges_dict = {}\n    for g, sub in train_pool_df[[group_col, value_col]].dropna().groupby(group_col, observed=True):\n        vals = sub[value_col].values\n        if len(vals) < 2:\n            continue\n        qs = np.linspace(0.0, 1.0, q + 1)\n        try_edges = np.quantile(vals, qs)\n        edges = try_edges.copy()\n        for i in range(1, len(edges)):\n            if edges[i] <= edges[i - 1]:\n                edges[i] = np.nextafter(edges[i - 1], float(\"inf\"))\n        edges_dict[g] = edges\n\n    def apply_edges(df_in: pd.DataFrame):\n        out = pd.Series(index=df_in.index, dtype=\"float32\")\n        out.iloc[:] = np.nan\n        for g, idx in df_in.groupby(group_col, observed=True).groups.items():\n            e = edges_dict.get(g, None)\n            if e is None:\n                out.loc[idx] = 0.5\n                continue\n            v = df_in.loc[idx, value_col].fillna(e[0]).values\n            bins = np.digitize(v, e[1:-1], right=True)\n            denom = max(1, len(e) - 2)\n            out.loc[idx] = bins.astype(\"float32\") / float(denom)\n        out.fillna(0.5, inplace=True)\n        return out\n\n    train_pool_df[feature_name] = apply_edges(train_pool_df[[group_col, value_col]].copy())\n    val_df[feature_name] = apply_edges(val_df[[group_col, value_col]].copy())\n    test_df[feature_name] = apply_edges(test_df[[group_col, value_col]].copy())\n    return train_pool_df, val_df, test_df\n\n# -------------------------\n# Global feature selections (purpose: choose candidate categorical and numeric columns)\n# -------------------------\nexclude_for_typing = {TARGET_COL, ID_COL, FOLD_COL}\nall_cat, all_num = get_cat_num_cols(train, TARGET_COL, ID_COL, exclude=exclude_for_typing)\nsel_cat = pick_top_cats(all_cat, train, k=6, exclude=META_COLS)\nsel_num_for_deviation = pick_top_nums(all_num, train, k=5, exclude=META_COLS)\ntransform_targets = [c for c in [C_INCOME, C_DTI] if c in train.columns]\nall_features_for_te = [c for c in (all_cat + all_num) if c not in META_COLS]\nprint(\"Selected categoricals (≤6): %s\", sel_cat)\nprint(\"Selected numeric for group-mean deviations (≤5): %s\", sel_num_for_deviation)\nprint(\"Numeric transform targets: %s\", transform_targets)\nprint(\"All features for target encoding (%d): %s\", len(all_features_for_te), all_features_for_te)\n\n# -------------------------\n# Preprocess for arbitrary held-out fold (purpose: per-fold encoders; inputs: train_df, test_df, held_out_fold)\n# -------------------------\ndef preprocess_for_outer_fold(train_df, test_df, held_out_fold, sel_cat, sel_num_for_deviation, transform_targets, all_features_for_te):\n    \"\"\"Fit encoders/transforms on train_pool=all folds except held_out_fold; apply to its validation and test.\"\"\"\n    if held_out_fold == -1:\n        tr_pool = train_df.copy()\n        va = train_df.iloc[0:0].copy()  # empty\n    else:\n        tr_pool = train_df.loc[train_df[FOLD_COL] != held_out_fold].copy()\n        va = train_df.loc[train_df[FOLD_COL] == held_out_fold].copy()\n    te = test_df.copy()\n    y_pool = tr_pool[TARGET_COL].astype(int)\n\n    # Inner folds based on existing assignment in tr_pool\n    inner_fold_ids = sorted(int(f) for f in tr_pool[FOLD_COL].unique().tolist())\n    inner_folds = {}\n    for f in inner_fold_ids:\n        inner_tr_idx = tr_pool.index[tr_pool[FOLD_COL] != f]\n        inner_va_idx = tr_pool.index[tr_pool[FOLD_COL] == f]\n        inner_folds[int(f)] = (inner_tr_idx, inner_va_idx)\n\n    # Frequency encoding\n    for c in sel_cat:\n        if c not in tr_pool.columns:\n            continue\n        mapping = frequency_encode(tr_pool, tr_pool[c])\n        tr_pool[f\"{c}__freq\"] = tr_pool[c].map(mapping).fillna(0).astype(\"float32\")\n        if len(va) > 0:\n            va[f\"{c}__freq\"] = va[c].map(mapping).fillna(0).astype(\"float32\")\n        te[f\"{c}__freq\"] = te[c].map(mapping).fillna(0).astype(\"float32\")\n\n    # OOF TE on ALL features (categorical + numerical)\n    for c in all_features_for_te:\n        if c not in tr_pool.columns:\n            continue\n        oof_te, te_map, te_g = oof_target_encode(tr_pool, y_pool, c, inner_folds, m=10.0)\n        tr_pool[f\"{c}__te_m10\"] = oof_te.astype(\"float32\")\n        if len(va) > 0:\n            va[f\"{c}__te_m10\"] = va[c].map(te_map).fillna(te_g).astype(\"float32\")\n        te[f\"{c}__te_m10\"] = te[c].map(te_map).fillna(te_g).astype(\"float32\")\n\n    # OOF WOE (clip WOE) - only for categorical features\n    for c in sel_cat:\n        if c not in tr_pool.columns:\n            continue\n        oof_woe, woe_map, _iv = oof_woe_encode(tr_pool, y_pool, c, inner_folds, eps=0.5)\n        tr_pool[f\"{c}__woe\"] = oof_woe.astype(\"float32\")\n        if len(va) > 0:\n            va[f\"{c}__woe\"] = va[c].map(woe_map).fillna(0.0).astype(\"float32\")\n        te[f\"{c}__woe\"] = te[c].map(woe_map).fillna(0.0).astype(\"float32\")\n\n    # Numeric transforms on income & DTI\n    for col in transform_targets:\n        if col not in tr_pool.columns:\n            continue\n        enc, med = fit_kbins(tr_pool[col], n_bins=10)\n        tr_pool[f\"{col}__qbin10\"] = transform_kbins(enc, med, tr_pool[col])\n        if len(va) > 0:\n            va[f\"{col}__qbin10\"] = transform_kbins(enc, med, va[col])\n        te[f\"{col}__qbin10\"] = transform_kbins(enc, med, te[col])\n\n        qt, med_q = fit_rank_gaussian(tr_pool[col])\n        tr_pool[f\"{col}__rgauss\"] = transform_rank_gaussian(qt, med_q, tr_pool[col])\n        if len(va) > 0:\n            va[f\"{col}__rgauss\"] = transform_rank_gaussian(qt, med_q, va[col])\n        te[f\"{col}__rgauss\"] = transform_rank_gaussian(qt, med_q, te[col])\n\n        pt, med_p = fit_yeojohnson(tr_pool[col])\n        tr_pool[f\"{col}__yeoj\"] = transform_yeojohnson(pt, med_p, tr_pool[col])\n        if len(va) > 0:\n            va[f\"{col}__yeoj\"] = transform_yeojohnson(pt, med_p, va[col])\n        te[f\"{col}__yeoj\"] = transform_yeojohnson(pt, med_p, te[col])\n\n    # Group mean deviations\n    tr_pool, va, te = group_mean_deviation(tr_pool, va, te, sel_cat, sel_num_for_deviation)\n\n    # Percentile features\n    if \"credit_score\" in tr_pool.columns and \"grade_subgrade\" in tr_pool.columns:\n        tr_pool, va, te = group_percentile_feature(tr_pool, va, te, \"grade_subgrade\", \"credit_score\", \"credit_score__pctl_in_grade\")\n    if \"credit_score\" in tr_pool.columns and \"education_level\" in tr_pool.columns:\n        tr_pool, va, te = group_percentile_feature(tr_pool, va, te, \"education_level\", \"credit_score\", \"credit_score__pctl_in_edu\")\n\n    # Missingness indicators\n    tr_pool = add_missing_indicators(tr_pool, exclude_cols=META_COLS)\n    if len(va) > 0:\n        va = add_missing_indicators(va, exclude_cols=META_COLS)\n    te = add_missing_indicators(te, exclude_cols={ID_COL})\n\n    # Feature list: original numeric (excluding raw categoricals/meta) + engineered blocks\n    excl = {TARGET_COL, ID_COL, FOLD_COL}\n    raw_cat, raw_num = get_cat_num_cols(train_df, TARGET_COL, ID_COL, exclude=excl)\n    raw_num_cols = [c for c in raw_num if c not in META_COLS]\n\n    eng_cols = [c for c in tr_pool.columns if (\n        c not in train_df.columns or\n        c.endswith(\"__freq\") or c.endswith(\"__te_m10\") or c.endswith(\"__woe\") or\n        \"__gm_\" in c or \"__dev_\" in c or\n        c.endswith(\"__qbin10\") or c.endswith(\"__rgauss\") or c.endswith(\"__yeoj\") or\n        c.endswith(\"__isna\") or\n        c.endswith(\"__pctl_in_grade\") or c.endswith(\"__pctl_in_edu\")\n    )]\n    feature_cols = sorted(set(raw_num_cols + eng_cols))\n    feature_cols = [c for c in feature_cols if (c not in META_COLS and not c.endswith(\"__iv\"))]\n\n    X_tr = tr_pool[feature_cols].copy()\n    y_tr = tr_pool[TARGET_COL].astype(int).copy()\n    if len(va) > 0:\n        X_va = va[feature_cols].copy()\n        y_va = va[TARGET_COL].astype(int).copy()\n    else:\n        X_va = va  # empty\n        y_va = va  # empty\n    X_te = te[feature_cols].copy()\n    return X_tr, y_tr, X_va, y_va, X_te, feature_cols\n\n# -------------------------\n# XGBoost params and trainers\n# -------------------------\ndef build_xgb_params(base_lr=0.05, n_estimators=1500, early_stopping_rounds=100):\n    params = dict(\n        booster=\"gbtree\",\n        objective=\"binary:logistic\",\n        eval_metric=\"auc\",\n        tree_method=\"hist\",\n        device=XGB_DEVICE,   # 'cuda:0' or 'cpu'\n        learning_rate=base_lr,\n        max_depth=6,\n        min_child_weight=8,\n        subsample=0.8,\n        colsample_bytree=0.8,\n        colsample_bylevel=0.8,\n        gamma=0.0,\n        reg_lambda=1.0,\n        reg_alpha=0.0,\n        max_bin=256,\n        grow_policy=\"depthwise\",\n        random_state=2025,\n        n_estimators=n_estimators,\n        n_jobs=0,\n        early_stopping_rounds=early_stopping_rounds,\n        verbosity=1,\n    )\n    return params\n\ndef train_xgb_single(X_tr, y_tr, X_va, y_va, params, label=\"baseline\"):\n    t0 = time.time()\n    clf = xgb.XGBClassifier(**params)\n    clf.fit(X_tr, y_tr, eval_set=[(X_va, y_va)], verbose=False)\n    best_it = getattr(clf, \"best_iteration\", None)\n    y_pred_va = clf.predict_proba(X_va, iteration_range=(0, best_it + 1) if best_it is not None else None)[:, 1]\n    val_auc = roc_auc_score(y_va, y_pred_va)\n    elapsed = time.time() - t0\n    print(\"XGB %s: val AUC=%.6f | best_iteration=%s | time=%.1fs\", label, val_auc, str(best_it), elapsed)\n    return clf, val_auc, best_it, elapsed\n\ndef optuna_tune_xgb(X_tr, y_tr, X_va, y_va, base_params, time_budget_sec=300):\n    print(\"Optuna tuning start (budget=%ds).\", time_budget_sec)\n    study = optuna.create_study(direction=\"maximize\", study_name=\"xgb_ps_s5e11_v4\")\n\n    def objective(trial: optuna.trial.Trial):\n        p = base_params.copy()\n        p.update({\n            \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.02, 0.12),\n            \"max_depth\": trial.suggest_int(\"max_depth\", 4, 9),\n            \"min_child_weight\": trial.suggest_float(\"min_child_weight\", 2.0, 12.0),\n            \"subsample\": trial.suggest_float(\"subsample\", 0.6, 1.0),\n            \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.6, 1.0),\n            \"colsample_bylevel\": trial.suggest_float(\"colsample_bylevel\", 0.6, 1.0),\n            \"reg_lambda\": trial.suggest_float(\"reg_lambda\", 0.5, 5.0, log=True),\n            \"reg_alpha\": trial.suggest_float(\"reg_alpha\", 0.0, 2.0),\n            \"gamma\": trial.suggest_float(\"gamma\", 0.0, 5.0),\n            \"max_bin\": trial.suggest_categorical(\"max_bin\", [128, 256, 512]),\n            \"n_estimators\": trial.suggest_int(\"n_estimators\", 600, 1500),\n        })\n        # Keep device and tree_method fixed\n        p[\"tree_method\"] = base_params[\"tree_method\"]\n        p[\"device\"] = base_params[\"device\"]\n        p[\"random_state\"] = 2025\n        p[\"early_stopping_rounds\"] = base_params[\"early_stopping_rounds\"]\n\n        model = xgb.XGBClassifier(**p)\n        model.fit(X_tr, y_tr, eval_set=[(X_va, y_va)], verbose=False)\n        best_it = getattr(model, \"best_iteration\", None)\n        y_pred = model.predict_proba(X_va, iteration_range=(0, best_it + 1) if best_it is not None else None)[:, 1]\n        auc = roc_auc_score(y_va, y_pred)\n        return auc\n\n    study.optimize(objective, n_trials=200, timeout=time_budget_sec, gc_after_trial=True)\n    best_params = study.best_params\n    best_value = study.best_value\n    print(\"Optuna best AUC=%.6f with params=%s\", best_value, json.dumps(best_params))\n\n    tuned_params = base_params.copy()\n    tuned_params.update(best_params)\n    # Retrain on the same fold-0 split to verify\n    model = xgb.XGBClassifier(**tuned_params)\n    t0 = time.time()\n    model.fit(X_tr, y_tr, eval_set=[(X_va, y_va)], verbose=False)\n    best_it = getattr(model, \"best_iteration\", None)\n    y_pred = model.predict_proba(X_va, iteration_range=(0, best_it + 1) if best_it is not None else None)[:, 1]\n    auc = roc_auc_score(y_va, y_pred)\n    elapsed = time.time() - t0\n    print(\"Tuned retrain: val AUC=%.6f | best_iteration=%s | retrain_time=%.1fs\", auc, str(best_it), elapsed)\n    return model, auc, best_it, tuned_params\n\n# -------------------------\n# CV trainer and final refit\n# -------------------------\ndef assign_outer_folds(df: pd.DataFrame, n_splits=5, seed=2025):\n    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=seed)\n    folds = np.full(len(df), -1, dtype=int)\n    for i, (_, va_idx) in enumerate(skf.split(df.drop(columns=[TARGET_COL]), df[TARGET_COL].values)):\n        folds[va_idx] = i\n    out = df.copy()\n    out[FOLD_COL] = folds\n    return out\n\ndef train_xgb_cv_and_predict(train_df, test_df, params, n_splits=5, debug=False):\n    print(\"Starting %d-fold CV training with per-fold encoders.\", n_splits)\n    train_df = assign_outer_folds(train_df, n_splits=n_splits, seed=2025)\n    oof = np.zeros(len(train_df), dtype=np.float32)\n    test_preds = []\n    fold_aucs = []\n    best_its = []\n\n    for f in range(n_splits):\n        print(\"Fold %d/%d: preprocessing (fit on train folds only).\", f+1, n_splits)\n        X_tr, y_tr, X_va, y_va, X_te, feats = preprocess_for_outer_fold(\n            train_df, test_df, held_out_fold=f,\n            sel_cat=sel_cat, sel_num_for_deviation=sel_num_for_deviation, transform_targets=transform_targets,\n            all_features_for_te=all_features_for_te\n        )\n        params_use = params.copy()\n        if debug:\n            # Downsample training to 1000 rows in DEBUG to save time\n            if len(X_tr) > 1000:\n                X_tr, _, y_tr, _ = train_test_split(X_tr, y_tr, test_size=(1.0 - 1000/len(X_tr)), stratify=y_tr, random_state=2025)\n            params_use[\"n_estimators\"] = min(200, params_use.get(\"n_estimators\", 1500))\n            params_use[\"early_stopping_rounds\"] = min(20, params_use.get(\"early_stopping_rounds\", 100))\n\n        print(\"Fold %d: training XGBoost.\", f+1)\n        clf = xgb.XGBClassifier(**params_use)\n        clf.fit(X_tr, y_tr, eval_set=[(X_va, y_va)], verbose=False)\n        best_it = getattr(clf, \"best_iteration\", None)\n        y_va_pred = clf.predict_proba(X_va, iteration_range=(0, best_it + 1) if best_it is not None else None)[:, 1]\n        fold_auc = roc_auc_score(y_va, y_va_pred)\n        fold_aucs.append(fold_auc)\n        oof[train_df.index[train_df[FOLD_COL] == f]] = y_va_pred\n        y_te_pred = clf.predict_proba(X_te, iteration_range=(0, best_it + 1) if best_it is not None else None)[:, 1]\n        test_preds.append(y_te_pred)\n        best_its.append(best_it if best_it is not None else params_use.get(\"n_estimators\", 1000))\n        print(\"Fold %d: AUC=%.6f | best_iteration=%s\", f+1, fold_auc, str(best_it))\n\n    oof_auc = roc_auc_score(train_df[TARGET_COL].values, oof)\n    y_test_cv = np.mean(np.vstack(test_preds), axis=0)\n    print(\"CV complete. OOF AUC=%.6f | per-fold AUCs=%s | median best_it=%d\",\n                 oof_auc, [round(a, 6) for a in fold_aucs], int(np.median(best_its)))\n    return y_test_cv, oof_auc, int(np.median(best_its)), feats\n\ndef refit_full_and_predict(train_df, test_df, params, debug=False):\n    print(\"Refit on all training data with inner OOF encoders; no held-out validation.\")\n    # Assign inner folds (for encoders) deterministically\n    train_df_full = assign_outer_folds(train_df, n_splits=5, seed=2025)\n    X_tr_full, y_tr_full, X_va_dummy, y_va_dummy, X_te_full, feats_full = preprocess_for_outer_fold(\n        train_df_full, test_df, held_out_fold=-1,\n        sel_cat=sel_cat, sel_num_for_deviation=sel_num_for_deviation, transform_targets=transform_targets,\n        all_features_for_te=all_features_for_te\n    )\n    params_use = params.copy()\n    if debug:\n        if len(X_tr_full) > 1000:\n            X_tr_full, _, y_tr_full, _ = train_test_split(X_tr_full, y_tr_full, test_size=(1.0 - 1000/len(X_tr_full)), stratify=y_tr_full, random_state=2025)\n        params_use[\"n_estimators\"] = min(200, params_use.get(\"n_estimators\", 1500))\n        params_use[\"early_stopping_rounds\"] = min(20, params_use.get(\"early_stopping_rounds\", 100))\n\n    # For full refit, use training data as eval_set just to track rounds; acceptable since encoders are fixed.\n    clf_full = xgb.XGBClassifier(**params_use)\n    clf_full.fit(X_tr_full, y_tr_full, eval_set=[(X_tr_full, y_tr_full)], verbose=False)\n    best_it_full = getattr(clf_full, \"best_iteration\", None)\n    y_test_full = clf_full.predict_proba(X_te_full, iteration_range=(0, best_it_full + 1) if best_it_full is not None else None)[:, 1]\n    print(\"Full refit complete. best_iteration=%s | n_features=%d\", str(best_it_full), X_tr_full.shape[1])\n    return y_test_full, best_it_full, feats_full\n\n# -------------------------\n# Main pipeline runs twice: DEBUG then FULL\n# -------------------------\ndef run_pipeline(DEBUG: bool):\n    mode = \"DEBUG\" if DEBUG else \"FULL\"\n    print(\"===== Running in %s mode =====\", mode)\n\n    # Create a single 5-fold assignment for baseline/tuning on fold 0\n    train_folds = assign_outer_folds(train.copy(), n_splits=5, seed=2025)\n    # Preprocess for fold 0 for baseline/tuning\n    X_tr0, y_tr0, X_va0, y_va0, X_te0, feats0 = preprocess_for_outer_fold(\n        train_folds, test.copy(), held_out_fold=0,\n        sel_cat=sel_cat, sel_num_for_deviation=sel_num_for_deviation, transform_targets=transform_targets,\n        all_features_for_te=all_features_for_te\n    )\n\n    # Baseline params (reduced trees in DEBUG)\n    if DEBUG:\n        base_params = build_xgb_params(base_lr=0.05, n_estimators=150, early_stopping_rounds=20)\n        # Downsample training to 1000 rows for the initial fold-0 baseline\n        if len(X_tr0) > 1000:\n            X_tr0, _, y_tr0, _ = train_test_split(X_tr0, y_tr0, test_size=(1.0 - 1000/len(X_tr0)), stratify=y_tr0, random_state=2025)\n    else:\n        base_params = build_xgb_params(base_lr=0.05, n_estimators=1500, early_stopping_rounds=100)\n\n    print(\"Baseline training on fold 0 (purpose: establish reference AUC).\")\n    model_base, auc_base, best_it_base, t_base = train_xgb_single(X_tr0, y_tr0, X_va0, y_va0, base_params, label=\"baseline-fold0\")\n\n    # Tuning only in FULL mode\n    if not DEBUG:\n        model_tuned, auc_tuned, best_it_tuned, tuned_params = optuna_tune_xgb(\n            X_tr0, y_tr0, X_va0, y_va0, base_params, time_budget_sec=300\n        )\n        if auc_tuned >= auc_base:\n            final_params = tuned_params\n            print(\"Selected tuned params (AUC=%.6f >= baseline %.6f).\", auc_tuned, auc_base)\n        else:\n            final_params = base_params\n            print(\"Selected baseline params (AUC=%.6f > tuned %.6f).\", auc_base, auc_tuned)\n    else:\n        final_params = base_params\n        print(\"DEBUG mode: tuning skipped; using baseline params.\")\n\n    # CV training + predictions\n    y_test_cv, oof_auc, median_best_it, feats_cv = train_xgb_cv_and_predict(\n        train.copy(), test.copy(), final_params, n_splits=5, debug=DEBUG\n    )\n\n    if DEBUG:\n        print(\"DEBUG mode: submission generation skipped per requirements.\")\n        return\n\n    # Full refit + predictions\n    y_test_full, best_it_full, feats_full = refit_full_and_predict(\n        train.copy(), test.copy(), final_params, debug=False\n    )\n\n    # Blend CV ensemble with full-refit model (simple mean)\n    y_test_final = 0.5 * y_test_cv + 0.5 * y_test_full\n    y_test_final = np.clip(y_test_final, 1e-9, 1 - 1e-9)\n\n    # Write submission\n    submission = pd.DataFrame({ID_COL: test[ID_COL].values, TARGET_COL: y_test_final})\n    submission.to_csv(SUBMISSION_PATH, index=False)\n    print(\"Submission written to %s\", SUBMISSION_PATH)\n\n    # Log prediction distribution\n    desc = pd.Series(y_test_final).describe(percentiles=[0.01, 0.05, 0.1, 0.5, 0.9, 0.95, 0.99])\n    print(\"Prediction distribution summary:\\n%s\", desc.to_string())\n    print(\"Run complete: OOF AUC=%.6f | median_best_it(CV)=%d | device=%s\", oof_auc, median_best_it, XGB_DEVICE)\n\n# -------------------------\n# Execute: DEBUG then FULL\n# -------------------------\nrun_pipeline(DEBUG=True)   # no submission\nrun_pipeline(DEBUG=False)  # produce submission_4.csv","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null}]}