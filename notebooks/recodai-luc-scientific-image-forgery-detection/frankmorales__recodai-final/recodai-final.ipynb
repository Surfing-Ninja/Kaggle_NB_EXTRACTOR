{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":113558,"databundleVersionId":14174843,"sourceType":"competition"},{"sourceId":13663605,"sourceType":"datasetVersion","datasetId":8670261}],"dockerImageVersionId":31193,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"This Jupyter Notebook contains Python code for **image forgery detection and localization**, primarily using a **U-Net** neural network architecture and **Error Level Analysis (ELA)** as a preprocessing step.\n\nThe overall goal is to predict a **pixel-wise mask** indicating forged regions, and output this mask in a **Run-Length Encoded (RLE)** format.\n\n---\n\n## ðŸ’» Code Sections Explained\n\nThe notebook is structured into setup, ELA computation, model definition, RLE implementation, inference, and visualization.\n\n### 1. Setup and Hyperparameters (Code Cell 1)\n\nThis section sets up the environment and defines key configuration values.\n\n* **Libraries:** Standard data science and deep learning libraries are imported: `os`, `gc`, `cv2`, `numpy`, `pandas`, and `torch` (including `torch.nn` and `torch.nn.functional`).\n* **Paths:** File paths for the pre-trained model (`recodai_model.pth`), test images, and the submission CSV template are defined.\n* **Hyperparameters:**\n    * `TARGET_SIZE = 256`: The input size for the images processed by the neural network.\n    * `DEVICE = 'cuda'`: Specifies the computation device (GPU, if available).\n    * `THR = 0.20`: **Threshold** for converting the model's probability output into a binary mask (pixels with probability > 0.20 are initially marked as forged).\n    * `MIN_A = 20`: **Minimum area** (in pixels) for a connected component to be kept as a valid forgery; smaller areas are considered noise and removed in post-processing.\n    * `MORPH_KERNEL = 5`: Size of the **morphological closing kernel** used for post-processing to smooth and connect nearby mask regions.\n\n### 2. Error Level Analysis (ELA) (`compute_ela` function)\n\nELA is a common technique in image forensics to highlight subtle compression differences in an image, which often exposes forged regions.\n\n* The function takes an image path (`p`), reads the image, and resizes it to `TARGET_SIZE` (256x256).\n* It then **re-saves the image with a standard JPEG quality (95%)** and immediately re-loads the re-saved image.\n* The **absolute difference** between the original and re-saved images (the \"error\") is calculated.\n* This error image is then averaged across color channels and scaled by 10 to enhance visibility (`e = np.mean(np.abs(...) * 10`). This ELA image serves as an additional input to the U-Net model.\n\n### 3. U-Net Model (`UNet` class)\n\nThe U-Net is a standard fully convolutional neural network used for **image segmentation** tasks, which is ideal for predicting a pixel-wise mask.\n\n* **Architecture:** It has an encoder-decoder structure with skip connections, forming a \"U\" shape.\n    * **Encoder (`self.e1`, `self.e2`, `self.bot`):** Reduces spatial dimensions (downsampling via `F.max_pool2d`) while increasing feature channels. The basic `block` consists of two `Conv2d` layers, each followed by `BatchNorm2d` and `ReLU` activation, with `Dropout(0.2)` in between the two convolutions.\n    * **Decoder (`self.up2`, `self.d2`, `self.up1`, `self.d1`):** Increases spatial dimensions (upsampling via `nn.ConvTranspose2d`) while decreasing feature channels.\n    * **Skip Connections (`torch.cat([d2,e2],1)` and `torch.cat([d1,e1],1)`):** Concatenates high-resolution feature maps from the encoder (`e1`, `e2`) with the upsampled feature maps in the decoder. This helps the model maintain fine spatial details crucial for accurate segmentation.\n* **Input/Output:** The model expects **4 input channels** (`in_c=4`): 3 for the resized image (RGB) and 1 for the ELA map. It outputs **1 channel** (`out_c=1`) representing the probability of forgery at each pixel.\n\n### 4. Run-Length Encoding (RLE) (`rle` function)\n\nRLE is a simple compression format used to efficiently encode the mask output, listing starting positions and lengths of consecutive \"forged\" pixels (runs of `1`s) in a flattened image.\n\n* The function flattens the 2D mask (transposed first, as is common in RLE definitions).\n* It finds the indices where the pixel value transitions (from 0 to 1 or 1 to 0).\n* These transition indices are used to generate the **start index** and **length** pairs for all forged regions.\n* If the mask is all zeros (`mask.sum() == 0`), it returns the string `\"authentic\"`.\n\n### 5. Inference and Post-Processing (Code Cell 1, continued)\n\n* **Data Prep:** Reads the test image, computes the ELA map, and prepares the combined 4-channel input tensor (RGB + ELA).\n* **Prediction:** The input is passed through the `model`.\n    * **Test-Time Augmentation (TTA):** The prediction is done twice: once with the original image (`p1`) and once with a **horizontally flipped** image (`p2`). The flipped prediction (`p2`) is then flipped back, and the two predictions are averaged (`prob = (p1 + p2) / 2`) to improve robustness.\n    * **Mask Generation:** The averaged probability map is thresholded (`prob > THR`) to create a binary mask.\n* **Post-Processing (Cleaning):**\n    * `cv2.GaussianBlur` and re-thresholding are used to smooth the mask boundaries.\n    * `cv2.connectedComponentsWithStats` identifies all distinct forgery regions.\n    * **Noise Removal:** Any connected component with an area less than `MIN_A` (20 pixels) is discarded, effectively removing small noise/artifacts.\n    * `cv2.morphologyEx(..., cv2.MORPH_CLOSE, ...)` applies **morphological closing** to fill small holes and connect close-by forgery regions, using a `5x5` ellipse kernel.\n    * The cleaned mask is **resized** to the original image's dimensions (`(w, h)`) using nearest-neighbor interpolation.\n* **RLE and Output:** The final mask is converted to an RLE string using `rle(final)` and saved to the `submission.csv` file.\n\n### 6. Validation and Visualization (Code Cells 1, 2, and 3)\n\n* **`validate` (in Code Cell 1):** Prints simple statistics about the final `submission.csv`, including the total number of submissions, authentic images, and the average number of RLE segments (pairs of start/length).\n* **`validate_and_print_rle` (in Code Cell 2):** A more robust validation function that checks the RLE string structure for common errors (e.g., missing brackets, non-integer values, odd number of elements) to ensure the submission format is correct.\n* **Visualization (Code Cell 3 and 4):**\n    * The original image is loaded.\n    * The RLE string from the generated submission is loaded and **decoded back into a binary mask** using `rle_decode`.\n    * Statistics (forged pixel count, percentage) are calculated.\n    * A visualization plot shows the **Original Image**, the **Binary Mask** from the RLE, and the **Forged Pixels Overlaid in Red** on the original image for visual inspection.\n\n---","metadata":{}},{"cell_type":"code","source":"# --------------------------------------------------------------\n# KAGGLE: FINAL INFERENCE â€” BALANCED RECALL + CLEAN MASKS\n# Model: /kaggle/input/rluc-sfic-st/recodai_model.pth\n# Target: 0.71â€“0.75 mIoU â†’ Top 10%\n# --------------------------------------------------------------\n\nimport os\nimport gc\nimport cv2\nimport numpy as np\nimport pandas as pd\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom tqdm.auto import tqdm\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# ------------------- PATHS -------------------\nMODEL_PATH = \"/kaggle/input/rluc-sfic-st/recodai_model.pth\"\nTEST_DIR   = \"/kaggle/input/recodai-luc-scientific-image-forgery-detection/test_images\"\nSUB_CSV    = \"/kaggle/input/recodai-luc-scientific-image-forgery-detection/sample_submission.csv\"\nOUT        = \"submission.csv\"\n\n# ------------------- BALANCED HYPERPARAMETERS -------------------\nTARGET_SIZE = 256\nDEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n\n# HYPERPARAMETERS\nTHR = 0.20          #  strong signals\nMIN_A = 20          #  noise\nMORPH_KERNEL = 5    # Light connection\n\n# ------------------- ELA (MEMORY SAFE) -------------------\ndef compute_ela(p):\n    try:\n        img = cv2.imread(p)\n        if img is None: return np.zeros((TARGET_SIZE, TARGET_SIZE), np.float32)\n        img = cv2.resize(img, (TARGET_SIZE, TARGET_SIZE))\n        _, enc = cv2.imencode('.jpg', img, [cv2.IMWRITE_JPEG_QUALITY, 95])\n        c = cv2.imdecode(enc, cv2.IMREAD_COLOR)\n        e = np.mean(np.abs(img.astype(np.float32) - c.astype(np.float32)), 2) * 10\n        del img, c, enc\n        return cv2.resize(e, (TARGET_SIZE, TARGET_SIZE)).astype(np.float32)\n    except:\n        return np.zeros((TARGET_SIZE, TARGET_SIZE), np.float32)\n\n# ------------------- MODEL -------------------\nclass UNet(nn.Module):\n    def __init__(self, in_c=4, out_c=1):\n        super().__init__()\n        def block(i,o): return nn.Sequential(\n            nn.Conv2d(i,o,3,1,1), nn.BatchNorm2d(o), nn.ReLU(),\n            nn.Dropout(0.2),\n            nn.Conv2d(o,o,3,1,1), nn.BatchNorm2d(o), nn.ReLU()\n        )\n        self.e1 = block(in_c,64); self.e2 = block(64,128); self.bot = block(128,256)\n        self.up2 = nn.ConvTranspose2d(256,128,2,2); self.d2 = block(256,128)\n        self.up1 = nn.ConvTranspose2d(128,64,2,2);  self.d1 = block(128,64)\n        self.out = nn.Conv2d(64,out_c,1)\n    def forward(self,x):\n        e1 = self.e1(x); p1 = F.max_pool2d(e1,2)\n        e2 = self.e2(p1); p2 = F.max_pool2d(e2,2)\n        b  = self.bot(p2)\n        d2 = self.up2(b); d2 = torch.cat([d2,e2],1); d2 = self.d2(d2)\n        d1 = self.up1(d2); d1 = torch.cat([d1,e1],1); d1 = self.d1(d1)\n        return self.out(d1)\n\n# ------------------- LOAD MODEL -------------------\nmodel = UNet().to(DEVICE)\nmodel.load_state_dict(torch.load(MODEL_PATH, map_location=DEVICE))\nmodel.eval()\nprint(f\"MODEL LOADED: {MODEL_PATH}\")\n\n# ------------------- RLE -------------------\ndef rle(mask):\n    if mask.sum() == 0: return \"authentic\"\n    p = mask.T.flatten()\n    p = np.concatenate([[0], p, [0]])\n    r = np.where(p[1:] != p[:-1])[0] + 1\n    r[1::2] -= r[::2]\n    return ','.join(map(str, r))\n\n# ------------------- INFERENCE LOOP (MEMORY SAFE) -------------------\nsub = pd.read_csv(SUB_CSV)\nsub['case_id'] = sub['case_id'].astype(str)\npaths = {os.path.splitext(f)[0]: os.path.join(TEST_DIR, f) \n         for f in os.listdir(TEST_DIR) if f.lower().endswith(('.png','.jpg','.jpeg','.tif','.tiff'))}\nsub['p'] = sub['case_id'].map(paths)\nsub = sub.dropna(subset=['p']).reset_index(drop=True)\n\nres = []\nkernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (MORPH_KERNEL, MORPH_KERNEL))\n\nprint(f\"Found {len(sub)} test images. Starting inference...\")\n\nfor idx, r in tqdm(sub.iterrows(), total=len(sub), desc=\"Predicting\"):\n    try:\n        img = cv2.cvtColor(cv2.imread(r['p']), cv2.COLOR_BGR2RGB)\n        h, w = img.shape[:2]\n        ela = compute_ela(r['p'])\n        x = cv2.resize(img, (TARGET_SIZE, TARGET_SIZE))\n        e = cv2.resize(ela, (TARGET_SIZE, TARGET_SIZE))\n        inp = np.concatenate([x, e[..., None]], -1) / 255.0\n        inp = torch.from_numpy(inp.transpose(2,0,1)).unsqueeze(0).float().to(DEVICE)\n\n        with torch.no_grad():\n            p1 = torch.sigmoid(model(inp)).cpu().numpy().squeeze()\n            inp_flip = torch.flip(inp, dims=[3])\n            p2 = torch.sigmoid(model(inp_flip)).cpu().numpy().squeeze()\n            p2 = np.flip(p2, axis=1)\n            prob = (p1 + p2) / 2\n\n        # --- HIGH RECALL + CLEAN POST-PROCESSING ---\n        mask = (prob > THR).astype(np.float32)\n        mask = cv2.GaussianBlur(mask, (3,3), 0)\n        mask = (mask > 0.5).astype(np.uint8)\n\n        n, lbl, stats, _ = cv2.connectedComponentsWithStats(mask, 4, cv2.CV_32S)\n        clean = np.zeros_like(mask)\n        for i in range(1, n):\n            if stats[i, 4] >= MIN_A:\n                clean[lbl == i] = 1\n        clean = cv2.morphologyEx(clean, cv2.MORPH_CLOSE, kernel)\n        final = cv2.resize(clean, (w, h), interpolation=cv2.INTER_NEAREST)\n\n        ann = f'[{rle(final)}]' if final.sum() > 0 else 'authentic'\n        res.append({'case_id': r['case_id'], 'annotation': ann})\n\n        # MEMORY CLEANUP\n        del img, ela, x, e, inp, p1, p2, prob, mask, clean, final\n        if idx % 10 == 0:\n            gc.collect()\n            torch.cuda.empty_cache()\n\n    except Exception as e:\n        print(f\"Error on {r['case_id']}: {e}\")\n        res.append({'case_id': r['case_id'], 'annotation': 'authentic'})\n\n# ------------------- SAVE -------------------\npd.DataFrame(res)[['case_id', 'annotation']].to_csv(OUT, index=False)\nprint(f\"SUBMISSION SAVED: {OUT}\")\n\n# ------------------- FINAL VALIDATION -------------------\ndef validate(df):\n    print(\"\\n\" + \"=\"*70)\n    print(\"   FINAL RLE VALIDATION\")\n    print(\"=\"*70)\n    total = len(df)\n    auth = df['annotation'].apply(lambda x: str(x).strip() == 'authentic').sum()\n    rle_df = df[df['annotation'].apply(lambda x: str(x).strip() != 'authentic')]\n    print(f\"Total: {total} | Authentic: {auth} | RLE: {len(rle_df)}\")\n    if len(rle_df) > 0:\n        pairs = [len(str(x).strip('[]').split(','))//2 for x in rle_df['annotation'] if '[' in str(x)]\n        if pairs:\n            print(f\"Avg RLE Pairs: {np.mean(pairs):.1f} | Max: {max(pairs)} | Min: {min(pairs)}\")\n    print(\"=\"*70)\n\nvalidate(pd.DataFrame(res))","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-11-10T06:15:52.885683Z","iopub.execute_input":"2025-11-10T06:15:52.88603Z","iopub.status.idle":"2025-11-10T06:16:59.134835Z","shell.execute_reply.started":"2025-11-10T06:15:52.886006Z","shell.execute_reply":"2025-11-10T06:16:59.133675Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def validate_and_print_rle(submission_df):\n    \"\"\"\n    Validates RLE output structure and prints debugging info.\n    Checks for:\n      1. Authentic/RLE count\n      2. Correct RLE format: even number of integers (start, length pairs)\n      3. RLE string starts with '[' and ends with ']'\n      4. All values are valid integers\n      5. NEW: Number of (start, length) segment pairs per RLE\n    \"\"\"\n    print(\"\\n\" + \"=\"*60)\n    print(\"   RLE OUTPUT VALIDATION CHECK + SEGMENT PAIR COUNT\")\n    print(\"=\"*60)\n\n    if 'annotation' not in submission_df.columns or 'case_id' not in submission_df.columns:\n        print(\"ERROR: Missing required columns: 'case_id' or 'annotation'\")\n        return\n\n    total = len(submission_df)\n    authentic_count = submission_df['annotation'].apply(lambda x: str(x).strip() == 'authentic').sum()\n    rle_rows = submission_df[submission_df['annotation'].apply(lambda x: str(x).strip() != 'authentic')].copy()\n\n    print(f\"Total Submissions       : {total}\")\n    print(f\"Authentic (No Forgery)  : {authentic_count}\")\n    print(f\"RLE Annotated (Forged)  : {len(rle_rows)}\")\n\n    if len(rle_rows) == 0:\n        print(\"No RLE annotations to validate.\")\n        print(\"=\"*60)\n        return\n\n    # Extract RLE numbers inside [ ]\n    def extract_rle_nums(rle_str):\n        rle_str = str(rle_str).strip()\n        if not (rle_str.startswith('[') and rle_str.endswith(']')):\n            return None\n        inner = rle_str[1:-1]\n        if not inner:\n            return []\n        return [x.strip() for x in inner.split(',') if x.strip()]\n\n    # Validation + pair counting\n    valid_rle = []\n    invalid_rle = []\n    pair_counts = []  # Store number of (start, len) pairs per valid RLE\n\n    for idx, row in rle_rows.iterrows():\n        case_id = row['case_id']\n        ann = row['annotation']\n        nums = extract_rle_nums(ann)\n        \n        if nums is None:\n            invalid_rle.append((case_id, ann, \"Missing [ ] brackets\"))\n            continue\n        if not all(x.isdigit() for x in nums):\n            invalid_rle.append((case_id, ann, \"Non-integer values\"))\n            continue\n        if len(nums) == 0:\n            invalid_rle.append((case_id, ann, \"Empty RLE\"))\n            continue\n        if len(nums) % 2 != 0:\n            invalid_rle.append((case_id, ann, f\"Odd number of elements: {len(nums)}\"))\n            continue\n        \n        # Count segment pairs\n        num_pairs = len(nums) // 2\n        pair_counts.append(num_pairs)\n\n        # Optional: check increasing starts\n        starts = [int(nums[i]) for i in range(0, len(nums), 2)]\n        if starts != sorted(starts):\n            invalid_rle.append((case_id, ann, \"Non-increasing start positions\"))\n        else:\n            valid_rle.append(case_id)\n\n    # Summary\n    print(f\"\\nRLE Validation Results:\")\n    print(f\"   Valid RLE     : {len(valid_rle)}\")\n    print(f\"   Invalid RLE   : {len(invalid_rle)}\")\n\n    if len(pair_counts) > 0:\n        total_pairs = sum(pair_counts)\n        avg_pairs = total_pairs / len(pair_counts)\n        max_pairs = max(pair_counts)\n        min_pairs = min(pair_counts)\n        print(f\"\\nSEGMENT PAIR STATISTICS (start, length):\")\n        print(f\"   Total Pairs   : {total_pairs}\")\n        print(f\"   Avg Pairs/RLE : {avg_pairs:.2f}\")\n        print(f\"   Min Pairs     : {min_pairs}\")\n        print(f\"   Max Pairs     : {max_pairs}\")\n    else:\n        print(f\"\\nNo valid RLE to compute pair statistics.\")\n\n    if len(invalid_rle) > 0:\n        print(f\"\\nFIRST 5 INVALID RLE EXAMPLES:\")\n        for case_id, ann, reason in invalid_rle[:5]:\n            print(f\"   case_id {case_id}: {reason}\")\n            print(f\"     â†’ {ann[:100]}{'...' if len(ann) > 100 else ''}\")\n        if len(invalid_rle) > 5:\n            print(f\"   ... and {len(invalid_rle) - 5} more.\")\n        print(f\"\\nFIX THESE BEFORE SUBMITTING!\")\n    else:\n        print(f\"ALL {len(valid_rle)} RLE STRINGS ARE VALID!\")\n    \n    print(\"=\"*60)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-10T06:16:59.136133Z","iopub.execute_input":"2025-11-10T06:16:59.13646Z","iopub.status.idle":"2025-11-10T06:16:59.153691Z","shell.execute_reply.started":"2025-11-10T06:16:59.136431Z","shell.execute_reply":"2025-11-10T06:16:59.152553Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"submission_df = pd.read_csv(\"submission.csv\")\nvalidate_and_print_rle(submission_df)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-10T06:16:59.154981Z","iopub.execute_input":"2025-11-10T06:16:59.155366Z","iopub.status.idle":"2025-11-10T06:16:59.186025Z","shell.execute_reply.started":"2025-11-10T06:16:59.155316Z","shell.execute_reply":"2025-11-10T06:16:59.185044Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import cv2\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n# Load the image\nimg_path = \"/kaggle/input/recodai-luc-scientific-image-forgery-detection/test_images/45.png\"\nimg = cv2.cvtColor(cv2.imread(img_path), cv2.COLOR_BGR2RGB)\n\nplt.figure(figsize=(10, 8))\nplt.imshow(img)\nplt.title(\"TEST IMAGE: 45.png â€” LOOK FOR FORGERY\", fontsize=16)\nplt.axis('off')\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-10T06:16:59.187714Z","iopub.execute_input":"2025-11-10T06:16:59.187965Z","iopub.status.idle":"2025-11-10T06:16:59.812868Z","shell.execute_reply.started":"2025-11-10T06:16:59.187946Z","shell.execute_reply":"2025-11-10T06:16:59.811687Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import cv2\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\n\n# ------------------- PATHS -------------------\nIMG_PATH = \"/kaggle/input/recodai-luc-scientific-image-forgery-detection/test_images/45.png\"\nSUBMISSION_CSV = \"submission.csv\"\n\n# ------------------- LOAD IMAGE -------------------\nimg = cv2.cvtColor(cv2.imread(IMG_PATH), cv2.COLOR_BGR2RGB)\nh, w = img.shape[:2]\n\n# ------------------- LOAD RLE FROM SUBMISSION -------------------\ndf = pd.read_csv(SUBMISSION_CSV)\ndf['case_id'] = df['case_id'].astype(str)\n\nprint(\"Available case_ids (as str):\", df['case_id'].tolist()[:10])\n\n# Search for '45' or '45.png'\nrow = df[df['case_id'] == '45']\nif len(row) == 0:\n    row = df[df['case_id'] == '45.png']\nif len(row) == 0:\n    raise ValueError(\"case_id '45' or '45.png' not found in submission.csv\")\n\nrle_str = row.iloc[0]['annotation']\ncase_id = row.iloc[0]['case_id']\nprint(f\"Found: case_id = {case_id} â†’ RLE loaded\")\n\n# ------------------- DECODE RLE -------------------\ndef rle_decode(rle_str, shape):\n    if rle_str == 'authentic' or not rle_str.startswith('['):\n        return np.zeros(shape, dtype=np.uint8)\n    rle_str = rle_str.strip('[]')\n    if not rle_str.strip():\n        return np.zeros(shape, dtype=np.uint8)\n    numbers = [int(x) for x in rle_str.split(',') if x.strip()]\n    if len(numbers) % 2 != 0:\n        print(\"Warning: Odd number of RLE values!\")\n        return np.zeros(shape, dtype=np.uint8)\n    mask = np.zeros(shape[0] * shape[1], dtype=np.uint8)\n    for i in range(0, len(numbers), 2):\n        start = numbers[i] - 1\n        length = numbers[i + 1]\n        if start + length <= len(mask):\n            mask[start:start + length] = 1\n    return mask.reshape(shape[1], shape[0]).T  # (H, W)\n\nmask = rle_decode(rle_str, (h, w))\n\n# ------------------- CALCULATE DYNAMIC STATS -------------------\npairs = len(rle_str.strip('[]').split(',')) // 2 if '[' in rle_str else 0\nforged_pixels = mask.sum()\nforged_pct = forged_pixels / (h * w) * 100\n\n# ------------------- VISUALIZE -------------------\nfig, axes = plt.subplots(1, 3, figsize=(21, 7))\n\naxes[0].imshow(img)\naxes[0].set_title(\"Original: 45.png\", fontsize=16)\naxes[0].axis('off')\n\naxes[1].imshow(mask, cmap='gray')\naxes[1].set_title(f\"Binary Mask ({pairs} RLE Segments)\", fontsize=16)  # DYNAMIC\naxes[1].axis('off')\n\noverlay = img.copy()\noverlay[mask == 1] = [255, 0, 0]\nblended = cv2.addWeighted(img, 0.7, overlay, 0.3, 0)\n\naxes[2].imshow(blended)\naxes[2].set_title(\"Forgery Detected (Red)\", fontsize=16)\naxes[2].axis('off')\n\nplt.suptitle(f\"RLE VISUALIZATION: {pairs} Forgery Segments\", fontsize=18, y=0.95)  # DYNAMIC\nplt.tight_layout()\nplt.show()\n\n# ------------------- DYNAMIC STATS -------------------\nprint(f\"\\nRLE STATS:\")\nprint(f\"   case_id: {case_id}\")\nprint(f\"   RLE (first 100): {rle_str[:100]}{'...' if len(rle_str) > 100 else ''}\")\nprint(f\"   Total RLE Pairs: {pairs}\")\nprint(f\"   Forged Pixels: {forged_pixels} ({forged_pct:.3f}% of image)\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-10T06:16:59.814004Z","iopub.execute_input":"2025-11-10T06:16:59.814298Z","iopub.status.idle":"2025-11-10T06:17:01.229776Z","shell.execute_reply.started":"2025-11-10T06:16:59.814275Z","shell.execute_reply":"2025-11-10T06:17:01.228705Z"}},"outputs":[],"execution_count":null}]}