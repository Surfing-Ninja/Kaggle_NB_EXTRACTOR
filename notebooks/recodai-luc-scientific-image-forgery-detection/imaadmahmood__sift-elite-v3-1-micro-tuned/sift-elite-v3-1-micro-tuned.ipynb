{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":113558,"databundleVersionId":14174843,"sourceType":"competition"}],"dockerImageVersionId":31154,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"\"\"\"\nüî• NUCLEAR OPTION: Multi-Detector Ensemble üî•\nGO BIG OR GO HOME\n\nStrategy:\n1. Run SIFT at TWO scales (original + 0.75x)\n2. Add ORB detector (different feature type)\n3. Union ALL detections (if ANY detector finds it ‚Üí include it)\n4. Aggressive mask expansion\n5. Lower all thresholds\n\nExpected: 0.310-0.325 OR spectacular failure to 0.25\n\"\"\"\n\nimport os\nimport json\nimport warnings\nwarnings.filterwarnings('ignore')\n\nimport numpy as np\nimport pandas as pd\nfrom PIL import Image\nfrom tqdm import tqdm\nimport cv2\nfrom scipy.ndimage import label as scipy_label, binary_fill_holes, binary_dilation\nfrom skimage.measure import regionprops\n\nclass Config:\n    BASE_PATH = '/kaggle/input/recodai-luc-scientific-image-forgery-detection'\n    TEST_IMAGES = os.path.join(BASE_PATH, 'test_images')\n    SAMPLE_SUB = os.path.join(BASE_PATH, 'sample_submission.csv')\n    \n    # AGGRESSIVE SIFT\n    SIFT_FEATURES = 8000  # Much more\n    SIFT_CONTRAST = 0.015  # Lower threshold\n    MATCH_RATIO = 0.82  # More permissive\n    MIN_MATCHES = 3  # Lower\n    RANSAC_THRESH = 6.0  # More permissive\n    MIN_DISPLACEMENT = 18  # Catch closer copies\n    \n    # ORB DETECTOR\n    ORB_FEATURES = 3000\n    ORB_MATCH_THRESHOLD = 50  # Hamming distance\n    \n    # MULTI-SCALE\n    SCALES = [1.0, 0.75]  # Run at original and 75% size\n    \n    # AGGRESSIVE THRESHOLDS\n    CONFIDENCE_THRESHOLD = 0.20  # Very low\n    MIN_MASK_PIXELS = 50  # Low\n    MIN_COVERAGE = 0.0002  # Low\n    MAX_COVERAGE = 0.50  # High\n    \n    # MASK GENERATION\n    CIRCLE_RADIUS = 20  # Large circles\n    USE_CLAHE = True\n\nconfig = Config()\n\nprint(\"=\"*80)\nprint(\"üî• NUCLEAR OPTION: Multi-Detector Ensemble\")\nprint(\"=\"*80)\nprint(\"Strategy: SIFT(2 scales) + ORB + Aggressive fusion\")\nprint(\"Risk Level: EXTREME\")\nprint(\"Expected: Jump to 0.31+ OR drop to 0.25\")\nprint(\"=\"*80 + \"\\n\")\n\ndef rle_encode(mask):\n    if mask.sum() == 0:\n        return []\n    dots = np.where(mask.T.flatten() == 1)[0]\n    run_lengths = []\n    prev = -2\n    for b in dots:\n        if b > prev + 1:\n            run_lengths.extend((b + 1, 0))\n        run_lengths[-1] += 1\n        prev = b\n    return run_lengths\n\ndef preprocess_image(img_array):\n    if len(img_array.shape) == 3:\n        gray = cv2.cvtColor(img_array, cv2.COLOR_RGB2GRAY)\n    else:\n        gray = img_array.copy()\n    \n    gray = cv2.normalize(gray, None, 0, 255, cv2.NORM_MINMAX).astype(np.uint8)\n    \n    if config.USE_CLAHE:\n        clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8, 8))\n        gray = clahe.apply(gray)\n    \n    return gray\n\nclass AggressiveSIFT:\n    \"\"\"SIFT with aggressive parameters\"\"\"\n    def __init__(self):\n        self.sift = cv2.SIFT_create(\n            nfeatures=config.SIFT_FEATURES,\n            contrastThreshold=config.SIFT_CONTRAST,\n            edgeThreshold=12\n        )\n    \n    def detect(self, gray):\n        h, w = gray.shape\n        kp, desc = self.sift.detectAndCompute(gray, None)\n        \n        if desc is None or len(desc) < config.MIN_MATCHES * 2:\n            return np.zeros((h, w), dtype=np.uint8), 0.0\n        \n        bf = cv2.BFMatcher(cv2.NORM_L2)\n        matches = bf.knnMatch(desc, desc, k=2)\n        \n        good = []\n        for m_n in matches:\n            if len(m_n) == 2:\n                m, n = m_n\n                if m.queryIdx != m.trainIdx and m.distance < config.MATCH_RATIO * n.distance:\n                    good.append(m)\n        \n        if len(good) < config.MIN_MATCHES:\n            return np.zeros((h, w), dtype=np.uint8), 0.0\n        \n        src_pts = np.float32([kp[m.queryIdx].pt for m in good])\n        dst_pts = np.float32([kp[m.trainIdx].pt for m in good])\n        \n        disp = np.linalg.norm(dst_pts - src_pts, axis=1)\n        valid = disp > config.MIN_DISPLACEMENT\n        \n        if valid.sum() < config.MIN_MATCHES:\n            return np.zeros((h, w), dtype=np.uint8), 0.0\n        \n        try:\n            M, inliers = cv2.findHomography(src_pts[valid], dst_pts[valid], \n                                          cv2.RANSAC, config.RANSAC_THRESH)\n            \n            if M is None or inliers is None or inliers.sum() < config.MIN_MATCHES:\n                return np.zeros((h, w), dtype=np.uint8), 0.0\n            \n            mask = np.zeros((h, w), dtype=np.uint8)\n            \n            for pt in src_pts[valid][inliers.flatten() > 0]:\n                x, y = int(pt[0]), int(pt[1])\n                if 0 <= x < w and 0 <= y < h:\n                    cv2.circle(mask, (x, y), config.CIRCLE_RADIUS, 1, -1)\n            \n            for pt in dst_pts[valid][inliers.flatten() > 0]:\n                x, y = int(pt[0]), int(pt[1])\n                if 0 <= x < w and 0 <= y < h:\n                    cv2.circle(mask, (x, y), config.CIRCLE_RADIUS, 1, -1)\n            \n            conf = min(1.0, inliers.sum() / 8.0)\n            return mask, conf\n        except:\n            return np.zeros((h, w), dtype=np.uint8), 0.0\n\nclass ORBDetector:\n    \"\"\"ORB detector for different feature type\"\"\"\n    def __init__(self):\n        self.orb = cv2.ORB_create(nfeatures=config.ORB_FEATURES)\n    \n    def detect(self, gray):\n        h, w = gray.shape\n        kp, desc = self.orb.detectAndCompute(gray, None)\n        \n        if desc is None or len(desc) < config.MIN_MATCHES * 2:\n            return np.zeros((h, w), dtype=np.uint8), 0.0\n        \n        bf = cv2.BFMatcher(cv2.NORM_HAMMING)\n        matches = bf.knnMatch(desc, desc, k=2)\n        \n        good = []\n        for m_n in matches:\n            if len(m_n) == 2:\n                m, n = m_n\n                if m.queryIdx != m.trainIdx and m.distance < config.ORB_MATCH_THRESHOLD:\n                    good.append(m)\n        \n        if len(good) < config.MIN_MATCHES:\n            return np.zeros((h, w), dtype=np.uint8), 0.0\n        \n        src_pts = np.float32([kp[m.queryIdx].pt for m in good])\n        dst_pts = np.float32([kp[m.trainIdx].pt for m in good])\n        \n        disp = np.linalg.norm(dst_pts - src_pts, axis=1)\n        valid = disp > config.MIN_DISPLACEMENT\n        \n        if valid.sum() < config.MIN_MATCHES:\n            return np.zeros((h, w), dtype=np.uint8), 0.0\n        \n        mask = np.zeros((h, w), dtype=np.uint8)\n        \n        for pt in src_pts[valid]:\n            x, y = int(pt[0]), int(pt[1])\n            if 0 <= x < w and 0 <= y < h:\n                cv2.circle(mask, (x, y), config.CIRCLE_RADIUS, 1, -1)\n        \n        for pt in dst_pts[valid]:\n            x, y = int(pt[0]), int(pt[1])\n            if 0 <= x < w and 0 <= y < h:\n                cv2.circle(mask, (x, y), config.CIRCLE_RADIUS, 1, -1)\n        \n        conf = min(1.0, valid.sum() / 10.0)\n        return mask, conf\n\nclass NuclearEnsemble:\n    \"\"\"Ensemble of all detectors with aggressive fusion\"\"\"\n    def __init__(self):\n        self.sift = AggressiveSIFT()\n        self.orb = ORBDetector()\n        print(\"‚úì Initialized: Aggressive SIFT + ORB\")\n    \n    def detect(self, image):\n        gray = preprocess_image(image)\n        h, w = image.shape[:2]\n        \n        all_masks = []\n        all_confs = []\n        \n        # Run SIFT at multiple scales\n        for scale in config.SCALES:\n            if scale != 1.0:\n                scaled_h, scaled_w = int(h * scale), int(w * scale)\n                scaled_gray = cv2.resize(gray, (scaled_w, scaled_h))\n            else:\n                scaled_gray = gray\n            \n            mask, conf = self.sift.detect(scaled_gray)\n            \n            # Scale back\n            if scale != 1.0 and mask.sum() > 0:\n                mask = cv2.resize(mask.astype(np.float32), (w, h))\n                mask = (mask > 0.5).astype(np.uint8)\n            \n            if mask.sum() > 0:\n                all_masks.append(mask)\n                all_confs.append(conf)\n        \n        # Run ORB\n        orb_mask, orb_conf = self.orb.detect(gray)\n        if orb_mask.sum() > 0:\n            all_masks.append(orb_mask)\n            all_confs.append(orb_conf)\n        \n        # UNION of all masks\n        if len(all_masks) == 0:\n            return np.zeros((h, w), dtype=np.uint8), 0.0\n        \n        combined = np.zeros((h, w), dtype=np.uint8)\n        for mask in all_masks:\n            combined = np.maximum(combined, mask)\n        \n        # Aggressive post-processing\n        combined = self.aggressive_refine(combined)\n        \n        final_conf = max(all_confs) if all_confs else 0.0\n        \n        return combined, final_conf\n    \n    def aggressive_refine(self, mask):\n        \"\"\"Aggressive mask expansion\"\"\"\n        if mask.sum() == 0:\n            return mask\n        \n        h, w = mask.shape\n        \n        # Aggressive dilation\n        kernel_large = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (7, 7))\n        mask = cv2.dilate(mask, kernel_large, iterations=2)\n        \n        # Close gaps\n        kernel_close = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (9, 9))\n        mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel_close, iterations=3)\n        \n        # Fill holes\n        mask = binary_fill_holes(mask).astype(np.uint8)\n        \n        # Remove only very small regions\n        labeled, _ = scipy_label(mask)\n        for region in regionprops(labeled):\n            if region.area < 30:  # Very small threshold\n                mask[labeled == region.label] = 0\n        \n        return mask\n\ndef generate_submission(detector):\n    print(\"\\nüöÄ Generating NUCLEAR submission...\")\n    \n    sample_sub = pd.read_csv(config.SAMPLE_SUB)\n    submissions = []\n    stats = {'authentic': 0, 'forged': 0}\n    \n    for case_id in tqdm(sample_sub['case_id'], desc=\"Processing\"):\n        try:\n            img = np.array(Image.open(os.path.join(config.TEST_IMAGES, f\"{case_id}.png\")))\n            mask, conf = detector.detect(img)\n            \n            is_forged = False\n            if conf > config.CONFIDENCE_THRESHOLD and mask.sum() >= config.MIN_MASK_PIXELS:\n                coverage = mask.sum() / (img.shape[0] * img.shape[1])\n                if config.MIN_COVERAGE < coverage < config.MAX_COVERAGE:\n                    is_forged = True\n            \n            if is_forged:\n                rle = rle_encode(mask)\n                if len(rle) > 0:\n                    annotation = json.dumps([int(x) for x in rle])\n                    stats['forged'] += 1\n                else:\n                    annotation = 'authentic'\n                    stats['authentic'] += 1\n            else:\n                annotation = 'authentic'\n                stats['authentic'] += 1\n            \n            submissions.append({'case_id': case_id, 'annotation': annotation})\n        except:\n            submissions.append({'case_id': case_id, 'annotation': 'authentic'})\n            stats['authentic'] += 1\n    \n    df = pd.DataFrame(submissions)\n    df.to_csv('submission.csv', index=False)\n    \n    print(f\"\\n‚úì Complete:\")\n    print(f\"  Forged: {stats['forged']} ({stats['forged']/len(df)*100:.1f}%)\")\n    print(f\"  Authentic: {stats['authentic']} ({stats['authentic']/len(df)*100:.1f}%)\")\n    print(\"\\n‚úì Saved: submission.csv\")\n\ndef main():\n    print(\"\\n\" + \"=\"*80)\n    print(\"üî• INITIALIZING NUCLEAR OPTION\")\n    print(\"=\"*80)\n    \n    detector = NuclearEnsemble()\n    generate_submission(detector)\n    \n    print(\"\\n\" + \"=\"*80)\n    print(\"üí£ NUCLEAR SUBMISSION READY\")\n    print(\"=\"*80)\n    print(\"\\nThis will either:\")\n    print(\"  ‚úÖ Jump to 0.31+ and beat the leaders\")\n    print(\"  ‚ùå Drop to 0.25 spectacular failure\")\n    print(\"\\nüé≤ GO BIG OR GO HOME! Submit and find out!\")\n    print(\"=\"*80 + \"\\n\")\n\nif __name__ == \"__main__\":\n    main()","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-11-07T08:02:20.808286Z","iopub.execute_input":"2025-11-07T08:02:20.808802Z","iopub.status.idle":"2025-11-07T08:03:05.137901Z","shell.execute_reply.started":"2025-11-07T08:02:20.808774Z","shell.execute_reply":"2025-11-07T08:03:05.137301Z"}},"outputs":[],"execution_count":null}]}