{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":113558,"databundleVersionId":14174843,"sourceType":"competition"}],"dockerImageVersionId":31153,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"id":"dc760d00","cell_type":"markdown","source":"\n# Scientific Image Forgery — **Exploratory Data Analysis (EDA)**\n\n**Goal:** Visualize and analyze forged regions (copy–move) in biomedical research images — no model training here.\n\n**What you'll get:**\n- Labeled overlays of forged regions (instances + bounding boxes)\n- Dataset sanity checks and descriptive statistics\n- Instance-level metrics (area %, bbox, aspect, compactness)\n- Saved overlays to disk for quick browsing\n- A qualitative \"copy–move\" signature peek via template matching\n  ","metadata":{}},{"id":"b57ec2b4","cell_type":"markdown","source":"\n## Table of Contents\n1. **Setup & Configuration**  \n2. **Data Loading Utilities**  \n3. **Index Dataset & Sanity Checks**  \n4. **Global Dataset Statistics** (counts, sizes, modes)  \n5. **Mask Structure & Quality Checks**  \n6. **Instance-Level Metrics** (area %, bbox, aspect, compactness)  \n7. **Labeled Visualizations** (single + grid + authentic vs forged)  \n8. **Copy–Move Signature Peek** (template matching)  \n9. **Analyst Summary & Next Steps**\n","metadata":{}},{"id":"5c71fbaf","cell_type":"markdown","source":"## 1) Setup & Configuration","metadata":{}},{"id":"0706ea7a","cell_type":"code","source":"import sys, os, platform\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nprint(\"Python:\", sys.version.split()[0])\nprint(\"OS:\", platform.platform())\nprint(\"NumPy:\", np.__version__)\nprint(\"Pandas:\", pd.__version__)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-23T20:10:18.679619Z","iopub.execute_input":"2025-10-23T20:10:18.680604Z","iopub.status.idle":"2025-10-23T20:10:18.689123Z","shell.execute_reply.started":"2025-10-23T20:10:18.680567Z","shell.execute_reply":"2025-10-23T20:10:18.687991Z"}},"outputs":[],"execution_count":null},{"id":"0fed76ed","cell_type":"code","source":"\nfrom pathlib import Path\n\nCOMP_DIR   = \"/kaggle/input/recodai-luc-scientific-image-forgery-detection\" \nTRAIN_DIR  = f\"{COMP_DIR}/train_images\"\nMASK_DIR   = f\"{COMP_DIR}/train_masks\"\nTEST_DIR   = f\"{COMP_DIR}/test_images\"  # unused here, EDA only\n\n# Outputs\nOUT_DIR     = \"/kaggle/working\"\nPREVIEW_DIR = f\"{OUT_DIR}/preview\"\nos.makedirs(PREVIEW_DIR, exist_ok=True)\n\n# Visualization and sampling params\nSEED                 = 42\nDISPLAY_SIZE         = 768          # resize for display/speed (square)\nGRID_SIZE            = 512          # size for grid thumbnails\nMAX_GRID_IMAGES      = 12           # limit how many to draw in grids\nTEMPLATE_MATCH_SCALE = 0.5          # downscale for template matching (speed)\nnp.random.seed(SEED)\n\nprint(\"TRAIN_DIR:\", TRAIN_DIR)\nprint(\"MASK_DIR :\", MASK_DIR)\nprint(\"PREVIEW to:\", PREVIEW_DIR)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-23T20:10:18.691072Z","iopub.execute_input":"2025-10-23T20:10:18.691635Z","iopub.status.idle":"2025-10-23T20:10:18.715755Z","shell.execute_reply.started":"2025-10-23T20:10:18.691598Z","shell.execute_reply":"2025-10-23T20:10:18.714546Z"}},"outputs":[],"execution_count":null},{"id":"47e0d1a1","cell_type":"markdown","source":"## 2) Data Loading Utilities","metadata":{}},{"id":"bdb8d4d3","cell_type":"code","source":"\nimport glob\nfrom PIL import Image\nimport cv2\n\ndef load_mask_npy(mask_path: str) -> np.ndarray:\n    \"\"\"\n    Load .npy mask which may be:\n      - (H, W): single mask\n      - (N, H, W): multiple instance masks -> OR them\n      - list/tuple/dict: extract arrays and OR them\n    Return: uint8 binary mask {0,1}\n    \"\"\"\n    m = np.load(mask_path, allow_pickle=True)\n\n    if isinstance(m, (list, tuple)):\n        arrs = []\n        for item in m:\n            item = np.asarray(item)\n            if item.ndim == 2:\n                arrs.append((item > 0).astype(np.uint8))\n            elif item.ndim == 3:\n                arrs.append(((item > 0).sum(axis=0) > 0).astype(np.uint8))\n        if len(arrs) == 0:\n            raise ValueError(f\"Unsupported mask list/tuple in {mask_path}\")\n        m = np.stack(arrs, axis=0)\n\n    if isinstance(m, dict):\n        key = \"masks\" if \"masks\" in m else list(m.keys())[0]\n        m = np.asarray(m[key])\n\n    m = np.asarray(m)\n    if m.ndim == 2:\n        mask = (m > 0).astype(np.uint8)\n    elif m.ndim == 3:\n        mask = ((m > 0).sum(axis=0) > 0).astype(np.uint8)\n    else:\n        raise ValueError(f\"Unsupported mask ndim {m.ndim} for {mask_path}\")\n    return mask\n\n\ndef load_mask_instances(mask_path: str) -> list:\n    \"\"\"\n    Return a list of instance masks (each [H,W] uint8 {0,1}).\n    If the .npy is (N,H,W) -> split along axis 0\n    If it's (H,W) -> split into connected components as instances\n    \"\"\"\n    from scipy import ndimage\n\n    raw = np.load(mask_path, allow_pickle=True)\n\n    def _to_list_of_masks(arr: np.ndarray) -> list:\n        arr = np.asarray(arr)\n        if arr.ndim == 2:\n            lab, n = ndimage.label(arr > 0)\n            return [(lab == k).astype(np.uint8) for k in range(1, n + 1)]\n        elif arr.ndim == 3:\n            return [((arr[i] > 0).astype(np.uint8)) for i in range(arr.shape[0])]\n        else:\n            raise ValueError(f\"Unsupported array ndim {arr.ndim}\")\n\n    if isinstance(raw, (list, tuple)):\n        out = []\n        for it in raw:\n            out.extend(_to_list_of_masks(np.asarray(it)))\n        return out\n\n    if isinstance(raw, dict):\n        key = \"masks\" if \"masks\" in raw else list(raw.keys())[0]\n        return _to_list_of_masks(np.asarray(raw[key]))\n\n    return _to_list_of_masks(np.asarray(raw))\n\n\ndef pil_to_np_rgb(img_pil: Image.Image) -> np.ndarray:\n    return np.array(img_pil.convert(\"RGB\"))\n\n\ndef resize_img_and_mask(img: Image.Image, mask: np.ndarray, size: int) -> tuple:\n    img_r  = img.resize((size, size), resample=Image.BILINEAR)\n    mask_r = Image.fromarray(mask).resize((size, size), resample=Image.NEAREST)\n    return img_r, np.array(mask_r, dtype=np.uint8)\n\n\ndef overlay_instances(img_rgb: np.ndarray, inst_masks: list, alpha: float = 0.38) -> np.ndarray:\n    \"\"\"\n    Semi-transparent color overlay per instance + labeled bounding boxes.\n    Returns an RGB uint8 image.\n    \"\"\"\n    H, W, _ = img_rgb.shape\n    out = img_rgb.astype(np.float32).copy()\n\n    rng = np.random.default_rng(1234)\n    colors = rng.integers(low=0, high=255, size=(max(1, len(inst_masks)), 3), dtype=np.uint8)\n\n    for idx, m in enumerate(inst_masks, start=1):\n        m = (m > 0).astype(np.uint8)\n        if m.shape != (H, W):\n            m = cv2.resize(m, (W, H), interpolation=cv2.INTER_NEAREST)\n        color = colors[(idx - 1) % len(colors)].astype(np.float32)\n\n        # Blend color on masked pixels\n        out[m == 1] = (1 - alpha) * out[m == 1] + alpha * color\n\n        # Bounding box & label\n        ys, xs = np.where(m == 1)\n        if len(xs) > 0:\n            x1, x2 = xs.min(), xs.max()\n            y1, y2 = ys.min(), ys.max()\n            cv2.rectangle(out, (x1, y1), (x2, y2), color=tuple(color.tolist()), thickness=2)\n            label = f\"inst {idx}\"\n            cv2.putText(out, label, (x1, max(0, y1 - 5)), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255,255,255), 2, cv2.LINE_AA)\n\n    return np.clip(out, 0, 255).astype(np.uint8)\n\n\ndef save_rgb(path: str, arr_rgb: np.ndarray):\n    Image.fromarray(arr_rgb.astype(np.uint8)).save(path)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-23T20:10:18.716989Z","iopub.execute_input":"2025-10-23T20:10:18.717404Z","iopub.status.idle":"2025-10-23T20:10:18.747387Z","shell.execute_reply.started":"2025-10-23T20:10:18.71736Z","shell.execute_reply":"2025-10-23T20:10:18.74616Z"}},"outputs":[],"execution_count":null},{"id":"729d90e2","cell_type":"markdown","source":"## 3) Index Dataset & Sanity Checks","metadata":{}},{"id":"3d016985","cell_type":"code","source":"\ndef build_items(train_dir: str, mask_dir: str):\n    items = []\n    for cls in [\"authentic\", \"forged\"]:\n        img_dir = f\"{train_dir}/{cls}\"\n        if not os.path.exists(img_dir):\n            continue\n        for p in glob.glob(os.path.join(img_dir, \"*\")):\n            case_id = Path(p).stem\n            mask_path = None\n            if cls == \"forged\":\n                cand = os.path.join(mask_dir, f\"{case_id}.npy\")\n                mask_path = cand if os.path.exists(cand) else None\n            items.append({\n                \"path\": p,\n                \"case_id\": case_id,\n                \"label\": 1 if cls == \"forged\" else 0,\n                \"mask_path\": mask_path\n            })\n    return items\n\nitems = build_items(TRAIN_DIR, MASK_DIR)\n\nn_total    = len(items)\nn_forged   = sum(x[\"label\"] == 1 for x in items)\nn_auth     = sum(x[\"label\"] == 0 for x in items)\nn_withmask = sum((x[\"label\"] == 1 and x[\"mask_path\"] is not None) for x in items)\n\nprint(f\"Total images: {n_total}\")\nprint(f\"Authentic   : {n_auth}\")\nprint(f\"Forged      : {n_forged}\")\nprint(f\"Forged with available masks (.npy): {n_withmask}\")\n\ndf = pd.DataFrame(items)\ndf.head()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-23T20:10:18.750052Z","iopub.execute_input":"2025-10-23T20:10:18.750377Z","iopub.status.idle":"2025-10-23T20:10:22.908773Z","shell.execute_reply.started":"2025-10-23T20:10:18.750354Z","shell.execute_reply":"2025-10-23T20:10:22.907771Z"}},"outputs":[],"execution_count":null},{"id":"d1716bec","cell_type":"markdown","source":"## 4) Global Dataset Statistics (sizes, modes, aspect)","metadata":{}},{"id":"abebf4c2","cell_type":"code","source":"\nfrom PIL import Image\n\ndims = []\nmodes = []\nfor it in items:\n    try:\n        img = Image.open(it[\"path\"])\n        dims.append(img.size)  # (W,H)\n        modes.append(img.mode)\n        img.close()\n    except Exception as e:\n        dims.append((None,None))\n        modes.append(\"ERR\")\n\ndim_df = pd.DataFrame(dims, columns=[\"width\",\"height\"])\ndf[\"width\"]  = dim_df[\"width\"].values\ndf[\"height\"] = dim_df[\"height\"].values\ndf[\"mode\"]   = modes\ndf[\"aspect\"] = (df[\"width\"] / df[\"height\"]).replace([np.inf, -np.inf], np.nan)\n\nprint(df[[\"label\",\"width\",\"height\",\"mode\",\"aspect\"]].describe(include=\"all\"))\n\nplt.figure(figsize=(6,4))\ndf[\"width\"].dropna().plot(kind=\"hist\", bins=30)\nplt.title(\"Image width distribution\"); plt.xlabel(\"pixels\"); plt.ylabel(\"count\")\nplt.show()\n\nplt.figure(figsize=(6,4))\ndf[\"height\"].dropna().plot(kind=\"hist\", bins=30)\nplt.title(\"Image height distribution\"); plt.xlabel(\"pixels\"); plt.ylabel(\"count\")\nplt.show()\n\nplt.figure(figsize=(6,4))\ndf[\"aspect\"].dropna().plot(kind=\"hist\", bins=30)\nplt.title(\"Aspect ratio (W/H)\"); plt.xlabel(\"ratio\"); plt.ylabel(\"count\")\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-23T20:10:22.909695Z","iopub.execute_input":"2025-10-23T20:10:22.909929Z","iopub.status.idle":"2025-10-23T20:11:08.239282Z","shell.execute_reply.started":"2025-10-23T20:10:22.909911Z","shell.execute_reply":"2025-10-23T20:11:08.238147Z"}},"outputs":[],"execution_count":null},{"id":"b6840d46","cell_type":"markdown","source":"## 5) Mask Structure & Quality Checks","metadata":{}},{"id":"a346e426","cell_type":"code","source":"\nimport cv2\n\nbad_shape = 0\nempty_mask = 0\ninstance_counts = []\nunion_area_px = []\nunion_area_pct = []\n\nforged_rows = df[df[\"label\"] == 1].copy()\nfor idx, row in forged_rows.iterrows():\n    if not row[\"mask_path\"]:\n        continue\n    img = Image.open(row[\"path\"]).convert(\"RGB\")\n    w, h = img.size\n    try:\n        mask_union = load_mask_npy(row[\"mask_path\"])\n    except Exception as e:\n        print(\"Mask load error:\", row[\"mask_path\"], e)\n        continue\n\n    if mask_union.shape != (h, w):\n        bad_shape += 1\n        mask_union = np.array(Image.fromarray(mask_union).resize((w, h), Image.NEAREST))\n\n    if mask_union.sum() == 0:\n        empty_mask += 1\n\n    insts = load_mask_instances(row[\"mask_path\"])\n    insts = [cv2.resize(m, (w, h), interpolation=cv2.INTER_NEAREST) if m.shape != (h, w) else m for m in insts]\n\n    instance_counts.append(len(insts))\n    union_area_px.append(int(mask_union.sum()))\n    union_area_pct.append(float(mask_union.sum() / (w * h)))\n\nprint(f\"Forged with mask shape mismatch (auto-resized): {bad_shape}\")\nprint(f\"Forged with empty union mask: {empty_mask}\")\n\nforged_rows[\"instances\"] = instance_counts + [np.nan] * (len(forged_rows) - len(instance_counts))\nforged_rows[\"union_area_px\"]  = union_area_px + [np.nan] * (len(forged_rows) - len(union_area_px))\nforged_rows[\"union_area_pct\"] = union_area_pct + [np.nan] * (len(forged_rows) - len(union_area_pct))\nforged_rows[\"\"\"case_id instances union_area_px union_area_pct\"\"\".split()].head()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-23T20:11:08.240437Z","iopub.execute_input":"2025-10-23T20:11:08.240752Z","iopub.status.idle":"2025-10-23T20:14:29.337039Z","shell.execute_reply.started":"2025-10-23T20:11:08.240728Z","shell.execute_reply":"2025-10-23T20:14:29.335764Z"}},"outputs":[],"execution_count":null},{"id":"d05d32af","cell_type":"markdown","source":"## 6) Instance-Level Metrics (distributions)","metadata":{}},{"id":"ae8a2587","cell_type":"code","source":"\nplt.figure(figsize=(6,4))\npd.Series([x for x in instance_counts if x is not None]).plot(kind=\"hist\", bins=20)\nplt.title(\"Distribution: number of forged instances per image\"); plt.xlabel(\"# instances\"); plt.ylabel(\"count\")\nplt.show()\n\nplt.figure(figsize=(6,4))\npd.Series([x for x in union_area_pct if x is not None]).plot(kind=\"hist\", bins=30)\nplt.title(\"Distribution: forged area as fraction of image\"); plt.xlabel(\"area fraction (0..1)\"); plt.ylabel(\"count\")\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-23T20:14:29.339243Z","iopub.execute_input":"2025-10-23T20:14:29.341459Z","iopub.status.idle":"2025-10-23T20:14:29.801791Z","shell.execute_reply.started":"2025-10-23T20:14:29.341398Z","shell.execute_reply":"2025-10-23T20:14:29.800741Z"}},"outputs":[],"execution_count":null},{"id":"e162d77f","cell_type":"code","source":"\ndef instance_metrics(img_w, img_h, m: np.ndarray):\n    ys, xs = np.where(m > 0)\n    if len(xs) == 0:\n        return None\n    x1, x2 = xs.min(), xs.max()\n    y1, y2 = ys.min(), ys.max()\n    w = x2 - x1 + 1\n    h = y2 - y1 + 1\n    area = int((m > 0).sum())\n    bbox_area = int(w * h)\n    area_pct = area / (img_w * img_h)\n    bbox_pct = bbox_area / (img_w * img_h)\n    m8 = (m > 0).astype(np.uint8) * 255\n    contours, _ = cv2.findContours(m8, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n    perim = sum(cv2.arcLength(c, True) for c in contours) if contours else 0.0\n    compactness = (perim * perim) / (area + 1e-6)\n    aspect = w / h if h > 0 else np.nan\n    return dict(area_px=area, area_pct=area_pct, bbox_area=bbox_area, bbox_pct=bbox_pct,\n                width=w, height=h, aspect=aspect, compactness=compactness,\n                x1=x1, y1=y1, x2=x2, y2=y2)\n\nrows = []\nfor it in items:\n    if it[\"label\"] != 1 or not it[\"mask_path\"]:\n        continue\n    img = Image.open(it[\"path\"]).convert(\"RGB\")\n    W, H = img.size\n    insts = load_mask_instances(it[\"mask_path\"])\n    insts = [cv2.resize(m, (W, H), interpolation=cv2.INTER_NEAREST) if m.shape != (H, W) else m for m in insts]\n\n    for k, m in enumerate(insts, start=1):\n        met = instance_metrics(W, H, m)\n        if met is None: \n            continue\n        rows.append({\n            \"case_id\": it[\"case_id\"],\n            \"instance_id\": k,\n            **met\n        })\n\ninst_df = pd.DataFrame(rows)\nprint(\"Instances:\", len(inst_df))\ninst_df.head()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-23T20:14:29.802756Z","iopub.execute_input":"2025-10-23T20:14:29.803063Z","iopub.status.idle":"2025-10-23T20:17:21.214494Z","shell.execute_reply.started":"2025-10-23T20:14:29.80303Z","shell.execute_reply":"2025-10-23T20:17:21.212579Z"}},"outputs":[],"execution_count":null},{"id":"371a459b","cell_type":"code","source":"\nplt.figure(figsize=(6,4))\ninst_df[\"area_pct\"].plot(kind=\"hist\", bins=30)\nplt.title(\"Instance area fraction distribution\"); plt.xlabel(\"area fraction (0..1)\"); plt.ylabel(\"count\")\nplt.show()\n\nplt.figure(figsize=(6,4))\ninst_df[\"aspect\"].replace([np.inf, -np.inf], np.nan).dropna().plot(kind=\"hist\", bins=30)\nplt.title(\"Instance bbox aspect ratio (W/H)\"); plt.xlabel(\"ratio\"); plt.ylabel(\"count\")\nplt.show()\n\nplt.figure(figsize=(6,4))\ninst_df[\"compactness\"].replace([np.inf, -np.inf], np.nan).dropna().plot(kind=\"hist\", bins=30)\nplt.title(\"Instance compactness (perimeter^2 / area)\"); plt.xlabel(\"compactness\"); plt.ylabel(\"count\")\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-23T20:17:21.216445Z","iopub.execute_input":"2025-10-23T20:17:21.216824Z","iopub.status.idle":"2025-10-23T20:17:22.075044Z","shell.execute_reply.started":"2025-10-23T20:17:21.2168Z","shell.execute_reply":"2025-10-23T20:17:22.074073Z"}},"outputs":[],"execution_count":null},{"id":"34648ee0","cell_type":"markdown","source":"## 7) Labeled Visualizations","metadata":{}},{"id":"9a5745c0","cell_type":"code","source":"\ndef show_forged_example(item: dict, display_size=DISPLAY_SIZE, save_prefix=None):\n    assert item[\"label\"] == 1 and item[\"mask_path\"] is not None\n    img = Image.open(item[\"path\"]).convert(\"RGB\")\n    W, H = img.size\n    union = load_mask_npy(item[\"mask_path\"])\n    if union.shape != (H, W):\n        union = np.array(Image.fromarray(union).resize((W, H), Image.NEAREST))\n    insts = load_mask_instances(item[\"mask_path\"])\n    insts = [cv2.resize(m, (W, H), interpolation=cv2.INTER_NEAREST) if m.shape != (H, W) else m for m in insts]\n\n    img_r, union_r = resize_img_and_mask(img, union, display_size)\n    img_np = pil_to_np_rgb(img_r)\n    overlay = overlay_instances(\n        img_np,\n        [cv2.resize(m, (display_size, display_size), interpolation=cv2.INTER_NEAREST) for m in insts]\n    )\n\n\n    # Side-by-side: original / union mask / overlay\n    plt.figure(figsize=(15,5))\n    plt.subplot(1,3,1); plt.imshow(img_np); plt.axis(\"off\"); plt.title(\"Original\")\n    plt.subplot(1,3,2); plt.imshow(union_r, cmap=\"gray\"); plt.axis(\"off\"); plt.title(\"Union mask\")\n    plt.subplot(1,3,3); plt.imshow(overlay); plt.axis(\"off\"); plt.title(f\"Overlay ({len(insts)} instance(s))\")\n    plt.tight_layout(); plt.show()\n\n    if save_prefix:\n        save_rgb(f\"{save_prefix}_original.png\", img_np)\n        Image.fromarray(union_r.astype(np.uint8) * 255).save(f\"{save_prefix}_mask.png\")\n        save_rgb(f\"{save_prefix}_overlay.png\", overlay)\n        print(\"Saved:\", f\"{save_prefix}_*.png\")\n\nforged_items = [it for it in items if it[\"label\"] == 1 and it[\"mask_path\"] is not None]\nif len(forged_items) == 0:\n    print(\"No forged items with masks to visualize.\")\nelse:\n    ex = np.random.choice(forged_items)\n    show_forged_example(ex, display_size=DISPLAY_SIZE, save_prefix=f\"{PREVIEW_DIR}/{Path(ex['path']).stem}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-23T20:18:49.876011Z","iopub.execute_input":"2025-10-23T20:18:49.87886Z","iopub.status.idle":"2025-10-23T20:18:51.421999Z","shell.execute_reply.started":"2025-10-23T20:18:49.878794Z","shell.execute_reply":"2025-10-23T20:18:51.420905Z"}},"outputs":[],"execution_count":null},{"id":"da7d40d4","cell_type":"code","source":"\ndef show_and_save_forged_grid(forged_list: list, n=MAX_GRID_IMAGES, tile_size=GRID_SIZE, cols=3, out_prefix=\"grid\"):\n    sel = forged_list[:n] if len(forged_list) <= n else list(np.random.choice(forged_list, n, replace=False))\n    rows = (len(sel) + cols - 1) // cols\n\n    plt.figure(figsize=(5 * cols, 5 * rows))\n    saved_paths = []\n    for i, it in enumerate(sel, 1):\n        img = Image.open(it[\"path\"]).convert(\"RGB\")\n        W, H = img.size\n        insts = load_mask_instances(it[\"mask_path\"])\n        insts = [cv2.resize(m, (W, H), interpolation=cv2.INTER_NEAREST) if m.shape != (H, W) else m for m in insts]\n\n        img_r = img.resize((tile_size, tile_size), resample=Image.BILINEAR)\n        over = overlay_instances(pil_to_np_rgb(img_r),\n                                 [cv2.resize(m, (tile_size, tile_size), interpolation=cv2.INTER_NEAREST) for m in insts])\n        ax = plt.subplot(rows, cols, i)\n        ax.imshow(over); ax.axis(\"off\")\n        ax.set_title(f\"{Path(it['path']).name}\\n{len(insts)} inst\")\n\n        save_path = f\"{PREVIEW_DIR}/{Path(it['path']).stem}_overlay.png\"\n        save_rgb(save_path, over)\n        saved_paths.append(save_path)\n\n    plt.tight_layout(); plt.show()\n    print(\"Saved overlays:\", len(saved_paths))\n    for p in saved_paths[:5]:\n        print(\" -\", p)\n    if len(saved_paths) > 5:\n        print(\" - ...\")\n\nif len(forged_items) > 0:\n    show_and_save_forged_grid(forged_items, n=MAX_GRID_IMAGES, tile_size=GRID_SIZE, cols=3, out_prefix=\"grid\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-23T20:19:05.821411Z","iopub.execute_input":"2025-10-23T20:19:05.822372Z","iopub.status.idle":"2025-10-23T20:19:09.402725Z","shell.execute_reply.started":"2025-10-23T20:19:05.822342Z","shell.execute_reply":"2025-10-23T20:19:09.401207Z"}},"outputs":[],"execution_count":null},{"id":"0820cbda","cell_type":"code","source":"\ndef show_auth_vs_forged(auth_list, forged_list, k=6, size=384):\n    k_auth = min(k, len(auth_list))\n    k_forg = min(k, len(forged_list))\n    sel_auth = auth_list[:k_auth] if len(auth_list) <= k_auth else list(np.random.choice(auth_list, k_auth, replace=False))\n    sel_forg = forged_list[:k_forg] if len(forged_list) <= k_forg else list(np.random.choice(forged_list, k_forg, replace=False))\n\n    cols = max(k_auth, k_forg, 1)\n    plt.figure(figsize=(4 * cols, 8))\n\n    # Row 1: authentic\n    for i, it in enumerate(sel_auth, 1):\n        img = Image.open(it[\"path\"]).convert(\"RGB\").resize((size, size), resample=Image.BILINEAR)\n        ax = plt.subplot(2, cols, i)\n        ax.imshow(img); ax.axis(\"off\")\n        ax.set_title(f\"Authentic\\n{Path(it['path']).name}\")\n\n    # Row 2: forged (overlay)\n    for i, it in enumerate(sel_forg, 1):\n        img = Image.open(it[\"path\"]).convert(\"RGB\").resize((size, size), resample=Image.BILINEAR)\n        insts = load_mask_instances(it[\"mask_path\"])\n        insts = [cv2.resize(m, (size, size), interpolation=cv2.INTER_NEAREST) for m in insts]\n        over  = overlay_instances(pil_to_np_rgb(img), insts)\n        ax = plt.subplot(2, cols, cols + i)\n        ax.imshow(over); ax.axis(\"off\")\n        ax.set_title(f\"Forged (overlay)\\n{Path(it['path']).name}\")\n\n    plt.tight_layout(); plt.show()\n\nauth_items = [it for it in items if it[\"label\"] == 0]\nif len(auth_items) > 0 and len(forged_items) > 0:\n    show_auth_vs_forged(auth_items, forged_items, k=6, size=384)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-23T20:19:31.14878Z","iopub.execute_input":"2025-10-23T20:19:31.149132Z","iopub.status.idle":"2025-10-23T20:19:33.375612Z","shell.execute_reply.started":"2025-10-23T20:19:31.149106Z","shell.execute_reply":"2025-10-23T20:19:33.373843Z"}},"outputs":[],"execution_count":null},{"id":"43580ea8","cell_type":"markdown","source":"## 8) Copy–Move Signature Peek (template matching, qualitative)","metadata":{}},{"id":"a9a2285b","cell_type":"code","source":"\ndef template_match_peek(item: dict, display_size=DISPLAY_SIZE, scale=TEMPLATE_MATCH_SCALE, max_inst=1):\n    assert item[\"label\"] == 1 and item[\"mask_path\"] is not None\n    img = Image.open(item[\"path\"]).convert(\"RGB\")\n    W, H = img.size\n    base = pil_to_np_rgb(img)\n\n    if scale != 1.0:\n        base_small = cv2.resize(base, (int(W*scale), int(H*scale)), interpolation=cv2.INTER_AREA)\n    else:\n        base_small = base.copy()\n\n    insts = load_mask_instances(item[\"mask_path\"])\n    insts = [cv2.resize(m, (W, H), interpolation=cv2.INTER_NEAREST) if m.shape != (H, W) else m for m in insts]\n    if len(insts) == 0:\n        print(\"No instances found for:\", item[\"case_id\"])\n        return\n\n    insts = insts[:max_inst]\n\n    vis = base_small.copy()\n    for k, m in enumerate(insts, start=1):\n        ys, xs = np.where(m > 0)\n        x1, x2 = xs.min(), xs.max()\n        y1, y2 = ys.min(), ys.max()\n        patch = base[y1:y2+1, x1:x2+1]\n        if patch.size == 0:\n            continue\n        if scale != 1.0:\n            patch = cv2.resize(patch, (int(patch.shape[1]*scale), int(patch.shape[0]*scale)), interpolation=cv2.INTER_AREA)\n\n        res = cv2.matchTemplate(base_small, patch, cv2.TM_CCOEFF_NORMED)\n        min_val, max_val, min_loc, max_loc = cv2.minMaxLoc(res)\n\n        ph, pw = patch.shape[:2]\n        top_left = max_loc\n        bottom_right = (top_left[0] + pw, top_left[1] + ph)\n\n        cv2.rectangle(vis, top_left, bottom_right, (255, 0, 0), 2)\n        cv2.putText(vis, f\"inst{k} score={max_val:.2f}\", (top_left[0], max(0, top_left[1]-5)),\n                    cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255,255,255), 2, cv2.LINE_AA)\n\n    base_disp = cv2.resize(base, (display_size, display_size), interpolation=cv2.INTER_AREA)\n    vis_disp  = cv2.resize(vis,  (display_size, display_size), interpolation=cv2.INTER_AREA)\n\n    plt.figure(figsize=(12,5))\n    plt.subplot(1,2,1); plt.imshow(base_disp); plt.axis(\"off\"); plt.title(\"Original\")\n    plt.subplot(1,2,2); plt.imshow(vis_disp);  plt.axis(\"off\"); plt.title(\"Template-match best hits\")\n    plt.tight_layout(); plt.show()\n\n    out_path = f\"{PREVIEW_DIR}/{Path(item['path']).stem}_tmatch.png\"\n    save_rgb(out_path, vis)\n    print(\"Saved:\", out_path)\n\n# Run on up to 2 random forged images\nif len(forged_items) > 0:\n    for ex in list(np.random.choice(forged_items, size=min(2, len(forged_items)), replace=False)):\n        template_match_peek(ex, display_size=DISPLAY_SIZE, scale=TEMPLATE_MATCH_SCALE, max_inst=1)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-23T20:19:42.496439Z","iopub.execute_input":"2025-10-23T20:19:42.497364Z","iopub.status.idle":"2025-10-23T20:19:43.883514Z","shell.execute_reply.started":"2025-10-23T20:19:42.49732Z","shell.execute_reply":"2025-10-23T20:19:43.88253Z"}},"outputs":[],"execution_count":null},{"id":"4b065c92","cell_type":"markdown","source":"## 9) Analyst Summary & Next Steps","metadata":{}},{"id":"f986e295","cell_type":"code","source":"\nfrom IPython.display import Markdown, display\n\ndef md(txt): display(Markdown(txt))\n\navg_inst = float(np.nanmean(forged_rows[\"instances\"])) if \"instances\" in locals() and \"instances\" in forged_rows.columns else float(\"nan\")\nmed_area = float(np.nanmedian(forged_rows[\"union_area_pct\"])) if \"union_area_pct\" in locals() and \"union_area_pct\" in forged_rows.columns else float(\"nan\")\n\nmd(f'''\n### Analyst Summary\n\n**Data balance**\n- Authentic images: **{int((df[\"label\"]==0).sum())}**\n- Forged images: **{int((df[\"label\"]==1).sum())}**\n- With masks available: **{int(((df[\"label\"]==1) & df[\"mask_path\"].notna()).sum())}**\n\n**Image geometry**\n- Width/height/aspect distributions shown above.\n- Consider standardizing input size (e.g., 512–1024) in modeling notebooks.\n\n**Masks & instances**\n- Avg. instances per forged image: **{avg_inst:.2f}**\n- Median forged area fraction (union): **{med_area:.4f}**\n- Shape mismatches were auto-resized; empty masks flagged in logs.\n\n**Instance shape**\n- Area fraction skews small → pixel-class imbalance likely.\n- Aspect ratio + compactness indicate diverse shapes (some elongated/fragmented).\n\n**Visual sanity**\n- Overlays align with expected duplicated regions.\n- Template-matching peek shows plausible duplicate hits (qualitative check).\n\n---\n\n### Recommendations (for future modeling)\n- **Sampling:** Oversample forged images / positive patches.\n- **Loss:** Combine **BCE + Dice**, consider **Focal** for small regions.\n- **Resolution:** Start 512, fine-tune 768–1024 for sharper boundaries.\n- **Augmentations:** Light affine/photometric; optional **synthetic copy–move** pasting.\n- **Post-processing:** Morphological cleanup + CC filtering.\n- **Evaluation:** Track pixel-F1 and the official image-level oF1 on a validation split.\n''')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-23T20:19:54.241203Z","iopub.execute_input":"2025-10-23T20:19:54.242509Z","iopub.status.idle":"2025-10-23T20:19:54.256358Z","shell.execute_reply.started":"2025-10-23T20:19:54.242442Z","shell.execute_reply":"2025-10-23T20:19:54.255153Z"}},"outputs":[],"execution_count":null}]}