{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":113558,"databundleVersionId":14174843,"isSourceIdPinned":false,"sourceType":"competition"},{"sourceId":13655676,"sourceType":"datasetVersion","datasetId":8681584}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# 1. Import packages and setup environment (CPU/GPU/TPU)","metadata":{}},{"cell_type":"code","source":"## For TPU environment (install missing packages / reinstall tensorflow to solve NaN topic during training / restart kernel)\n\nimport IPython\nimport tensorflow as tf\nIPython.display.clear_output() # Workaround for error messages leading to Failed notebook\n\nif len(tf.config.experimental.list_logical_devices('TPU')) > 0:\n    !pip install -q tensorflow-tpu -f https://storage.googleapis.com/libtpu-tf-releases/index.html --force-reinstall\n    !pip install -q pydot\n    !pip install -q -U keras-tuner\n    !pip install -q polars\n    !pip install -q pydicom\n    !pip install -q protobuf==5.29.5 # to solve tuner compatibility issue\n    IPython.Application.instance().kernel.do_shutdown(True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-08T15:30:11.990635Z","iopub.execute_input":"2025-11-08T15:30:11.991315Z","iopub.status.idle":"2025-11-08T15:30:28.328728Z","shell.execute_reply.started":"2025-11-08T15:30:11.991281Z","shell.execute_reply":"2025-11-08T15:30:28.327902Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"## Import packages\n\n# General purpose modules\nimport os\nimport math\nfrom tqdm import tqdm\nimport time\nfrom pathlib import Path\nfrom natsort import natsorted\nimport cv2\n\n# Data handling and visualization modules\nimport json\nimport numpy as np\nimport pandas as pd\nimport polars as pl\nimport matplotlib.pyplot as plt\nfrom matplotlib.pyplot import imshow\n\n# Skikit-learn preprocessing modules\nfrom sklearn.model_selection import StratifiedKFold\n\n# Tensorflow modules\nimport tensorflow as tf\nfrom tensorflow.keras import backend as K\nimport keras_tuner as kt","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-08T15:30:28.330013Z","iopub.execute_input":"2025-11-08T15:30:28.330609Z","iopub.status.idle":"2025-11-08T15:30:29.22973Z","shell.execute_reply.started":"2025-11-08T15:30:28.330588Z","shell.execute_reply":"2025-11-08T15:30:29.228868Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"## Detect hardware (CPU/GPU/TPU), setup environment and return appropriate distribution strategy\n\ntry:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver.connect(tpu='local') # set tpu is local as it should be available in the VM\n    print('✅ Running on TPU ', tpu.master())\nexcept:\n    print('❌ Using CPU/GPU')\n    tpu = None\n\nif tpu:\n    strategy = tf.distribute.TPUStrategy(tpu)\nelse:\n    strategy = tf.distribute.get_strategy() # default distribution strategy in Tensorflow. Works on CPU and single GPU.\n\nprint(\"REPLICAS: \", strategy.num_replicas_in_sync)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-08T15:30:29.230563Z","iopub.execute_input":"2025-11-08T15:30:29.23076Z","iopub.status.idle":"2025-11-08T15:30:29.46699Z","shell.execute_reply.started":"2025-11-08T15:30:29.230745Z","shell.execute_reply":"2025-11-08T15:30:29.466243Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 2. Load and explore data","metadata":{}},{"cell_type":"code","source":"## Preprocessing functions\n\nimage_size = 256 # input image size fo neural network model\nCLASSES = {0 : 'autentic', 1: 'forged'}\n\n# Pad and resize images (while retaining aspect ratio) and adjust coordinates accordingly\ndef pad_and_resize(image):\n    image_size_rows, image_size_cols, _ = image.shape\n    pad_size = max(image_size_rows, image_size_cols)\n    image_padded = tf.image.resize_with_crop_or_pad(image, pad_size, pad_size)\n    image_resized = tf.image.resize(image_padded, [image_size, image_size])\n    return image_resized\n\n# Zoom/rotate/translate images and adjust coordinates accordingly\ndef image_augmentation(image, augmentation=True):\n    if augmentation:\n        zoom_fac = np.random.uniform(0.0, 0.0)\n        rot_fac = np.random.uniform(-0.1, 0.1)\n        trans_fac = np.random.uniform(-0.05, 0.05)\n        z = tf.keras.layers.RandomZoom(height_factor=(zoom_fac, zoom_fac), fill_mode='constant', name='auglay1')(image)\n        z = tf.keras.layers.RandomRotation(factor=(rot_fac, rot_fac), fill_mode='constant', name='auglay2')(z)\n        image = tf.keras.layers.RandomTranslation(height_factor=(trans_fac, trans_fac), width_factor=(trans_fac, trans_fac),\n                                                  interpolation='nearest', fill_mode='constant', name='auglay3')(z)\n    return image\n\n# Preprocess image or masking (Padding and resizing to image_size x image_size x channel)\ndef preprocess_images(image, augmentation=False):\n    image_scaled = image.astype(dtype=np.float32)/255\n    image_aug = image_augmentation(image_scaled, augmentation=augmentation)\n    image_resized = pad_and_resize(image_aug)\n    image_resized = tf.cast(image_resized*255, dtype=tf.uint8)\n    return image_resized\n\n# Postprocess image or masking (Resizing and croping to original image/mask size)\ndef postprocess_images(image, orig_image):\n    image_scaled = tf.cast(image, dtype=np.float32)/255\n    image_size_rows, image_size_cols, _ = orig_image.shape\n    max_orig_size = max(image_size_rows, image_size_cols)\n    image_resized = tf.image.resize(image_scaled, [max_orig_size, max_orig_size])\n    image_padded = tf.image.resize_with_crop_or_pad(image_resized, image_size_rows, image_size_cols)\n    image_rescaled = tf.cast(image_padded*255, dtype=tf.uint8)\n    return image_rescaled","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-08T15:30:29.468557Z","iopub.execute_input":"2025-11-08T15:30:29.468776Z","iopub.status.idle":"2025-11-08T15:30:29.477007Z","shell.execute_reply.started":"2025-11-08T15:30:29.468758Z","shell.execute_reply":"2025-11-08T15:30:29.476357Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"## Load and preprocess images\n\nSUBMISSIONING = False\nfolder_path_au = Path(\"/kaggle/input/recodai-luc-scientific-image-forgery-detection/train_images/authentic\")\nfolder_path_fo = Path(\"/kaggle/input/recodai-luc-scientific-image-forgery-detection/train_images/forged\")\n\ndef load_images(folder_path):\n    images = []\n    labels = []\n    for file_path in tqdm(folder_path.glob(\"*.png\")):\n        image = cv2.imread(str(file_path))\n        if 'authentic' in str(folder_path):\n            label = np.zeros((image.shape[0], image.shape[1], 1))\n        else:\n            mask_filename = str(file_path).split('/')[-1].replace('.png', '.npy')\n            mask_raw = np.load('/kaggle/input/recodai-luc-scientific-image-forgery-detection/train_masks/' + mask_filename)\n            label = np.transpose(mask_raw, axes=[1,2,0])\n            label = np.sum(label, axis=2, keepdims=True)\n        if image is not None:\n            image = preprocess_images(image, False)\n            label = preprocess_images(label, False)\n            images.append(image)\n            labels.append(label)\n    images = np.stack(images, axis=0)\n    labels = np.stack(labels, axis=0)\n    return images, labels\n\ndef load_dataset():\n    images_au, labels_au = load_images(folder_path_au)\n    images_fo, labels_fo = load_images(folder_path_fo)\n    images = np.concatenate((images_au, images_fo), axis=0)\n    labels = np.concatenate((labels_au, labels_fo), axis=0)\n    return images, labels\n\nif not SUBMISSIONING:\n    trainval_images, trainval_labels = load_dataset()\nelse: # Dummy data for speeding up submission\n    trainval_images = np.ones((640,256,256,3))\n    trainval_labels = np.zeros((640,256,256,1))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-08T15:30:29.477647Z","iopub.execute_input":"2025-11-08T15:30:29.477874Z","iopub.status.idle":"2025-11-08T15:37:20.047404Z","shell.execute_reply.started":"2025-11-08T15:30:29.477848Z","shell.execute_reply":"2025-11-08T15:37:20.046779Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"## Spliting trainval data into train and validation data with StratifiedKFold\n\nskf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42) # Baseline 42\nbool_labels = (trainval_labels.sum(axis=(1,2,3))>0).astype(dtype=np.float32)\nfor fold, (train_idx, val_idx) in enumerate(skf.split(trainval_images, y=bool_labels)):\n    train_images, val_images = trainval_images[train_idx], trainval_images[val_idx]\n    train_labels, val_labels = trainval_labels[train_idx], trainval_labels[val_idx]\n    print(f\"✅ Fold {fold}: Train size = {len(train_idx)}, Val size = {len(val_idx)}\")\n    break  # Use only the first fold for now","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-08T15:37:20.048263Z","iopub.execute_input":"2025-11-08T15:37:20.048529Z","iopub.status.idle":"2025-11-08T15:37:20.678447Z","shell.execute_reply.started":"2025-11-08T15:37:20.048501Z","shell.execute_reply":"2025-11-08T15:37:20.677807Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"## Zoom/rotate/translate images and adjust labels accordingly (not yet integrated)\n\ndef image_augmentation_ds(image, label, augmentation=True):\n    if augmentation:\n        zoom_fac = np.random.uniform(-0.1, 0.1)\n        rot_fac = np.random.uniform(-0.1, 0.1)\n        trans_fac = np.random.uniform(-0.05, 0.05)\n        \n        x = tf.keras.layers.RandomZoom(height_factor=(zoom_fac, zoom_fac), fill_mode='constant', name='auglay1')(image)\n        x = tf.keras.layers.RandomRotation(factor=(rot_fac, rot_fac), fill_mode='constant', name='auglay2')(x)\n        image = tf.keras.layers.RandomTranslation(height_factor=(trans_fac, trans_fac), width_factor=(trans_fac, trans_fac),\n                                                  interpolation='nearest', fill_mode='constant', name='auglay3')(x)\n        \n        y = tf.keras.layers.RandomZoom(height_factor=(zoom_fac, zoom_fac), fill_mode='constant', name='auglay1')(label)\n        y = tf.keras.layers.RandomRotation(factor=(rot_fac, rot_fac), fill_mode='constant', name='auglay2')(y)\n        label = tf.keras.layers.RandomTranslation(height_factor=(trans_fac, trans_fac), width_factor=(trans_fac, trans_fac),\n                                              interpolation='nearest', fill_mode='constant', name='auglay3')(y)\n    return image, label","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-08T15:37:20.679258Z","iopub.execute_input":"2025-11-08T15:37:20.67958Z","iopub.status.idle":"2025-11-08T15:37:20.686324Z","shell.execute_reply.started":"2025-11-08T15:37:20.679553Z","shell.execute_reply":"2025-11-08T15:37:20.685663Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"## Create train and validation datasets\n\nSEED=42\nbatch_size=32\nbatch_size_val=32\n\ntrain_ds = tf.data.Dataset.from_tensor_slices((train_images, train_labels))\ntrain_ds = train_ds.shuffle(len(train_labels), seed=SEED).repeat().batch(batch_size, drop_remainder=True).prefetch(tf.data.AUTOTUNE) #map(lambda image, label: image_augmentation_ds(image, label)).\nval_ds = tf.data.Dataset.from_tensor_slices((val_images, val_labels))\nval_ds = val_ds.shuffle(len(val_labels)).batch(batch_size_val, drop_remainder=True).prefetch(tf.data.AUTOTUNE)\n\nprint('Size of train dataset: '+ str(len(train_labels)))\nprint('Number of batches in train dataset: '+ f'{len(train_labels)//batch_size}')\nprint('Size of validation dataset: '+ str(len(val_labels)))\nprint('Number of batches in val dataset: '+ f'{len(val_labels)//batch_size_val}')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-08T15:37:20.688475Z","iopub.execute_input":"2025-11-08T15:37:20.688934Z","iopub.status.idle":"2025-11-08T15:37:25.33172Z","shell.execute_reply.started":"2025-11-08T15:37:20.688905Z","shell.execute_reply":"2025-11-08T15:37:25.33101Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"## Check validation dataset batch dimensions\n\nfor X, y in val_ds.take(1):\n    print(X.shape)\n    print(y.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-08T15:37:25.33242Z","iopub.execute_input":"2025-11-08T15:37:25.332762Z","iopub.status.idle":"2025-11-08T15:37:25.390006Z","shell.execute_reply.started":"2025-11-08T15:37:25.332744Z","shell.execute_reply":"2025-11-08T15:37:25.389303Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 3. Explore Data","metadata":{}},{"cell_type":"code","source":"## Visualize data\n\ntrain_ds_vis = train_ds.unbatch() #.shuffle(2048,seed=43)\nnum_examples = 36\nnum_columns = 6\nnum_rows = math.ceil(num_examples/num_columns)\nplt.figure(figsize=(16, 16))\nfor i, (image, label) in enumerate(train_ds_vis.take(num_examples)):\n    if i == -1: # Set to 0 in case of interest\n        print(image.shape)\n        print('class id: '+str(label.numpy()))\n        print('class name: '+str(CLASSES[label.numpy()]))\n    bool_label = (label.numpy().sum()>0).astype(dtype=np.float32)\n    class_id = str(bool_label)\n    class_name = str(CLASSES[bool_label])\n    plt.subplot(num_rows, num_columns, i + 1)\n    plt.imshow(image)\n    if bool_label:\n        mask = np.ma.masked_where(label == 0, label*255)\n        plt.imshow(mask, cmap='Set1', alpha=0.5)\n    plt.title(f\"{class_name}({class_id})\", fontsize=10)\n    plt.suptitle(\"Examples from train dataset\")\n    plt.xticks([])\n    plt.yticks([])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-08T15:37:25.390793Z","iopub.execute_input":"2025-11-08T15:37:25.39105Z","iopub.status.idle":"2025-11-08T15:37:28.678885Z","shell.execute_reply.started":"2025-11-08T15:37:25.391022Z","shell.execute_reply":"2025-11-08T15:37:28.677815Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 4. Build and explore neural network","metadata":{}},{"cell_type":"code","source":"## Custom F1 function to handle imbalanced label classes\n\ndef f1_score(y_true, y_pred):\n    y_pred = tf.round(y_pred)  # Round predictions to 0 or 1\n    tp = K.sum(K.cast(y_true * y_pred, 'float'), axis=0)  # True positives\n    fp = K.sum(K.cast((1 - y_true) * y_pred, 'float'), axis=0)  # False positives\n    fn = K.sum(K.cast(y_true * (1 - y_pred), 'float'), axis=0)  # False negatives\n\n    precision = tp / (tp + fp + K.epsilon())  # Precision calculation\n    recall = tp / (tp + fn + K.epsilon())  # Recall calculation\n\n    f1 = 2 * precision * recall / (precision + recall + K.epsilon())  # F1 score\n    return K.mean(f1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-08T15:37:28.679983Z","iopub.execute_input":"2025-11-08T15:37:28.68021Z","iopub.status.idle":"2025-11-08T15:37:28.685755Z","shell.execute_reply.started":"2025-11-08T15:37:28.680193Z","shell.execute_reply":"2025-11-08T15:37:28.684906Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"## Custom F1 class to handle imbalanced label classes\n\n@tf.keras.utils.register_keras_serializable()\nclass CustomF1(tf.keras.metrics.Metric):\n    def __init__(self, name='cf1_score', **kwargs):\n        super().__init__(name=name, **kwargs)\n        self.f1_score_fn = f1_score\n        self.total = self.add_weight(shape=(), name=\"total\", initializer=\"zeros\")\n        self.count = self.add_weight(shape=(), name=\"count\", initializer=\"zeros\")\n    def update_state(self, y_true, y_pred, sample_weight=None):\n        y_true = tf.cast(tf.reshape(y_true, shape=(y_true.shape[0], -1)), dtype=tf.float32)\n        y_pred = tf.reshape(y_pred, shape=(y_pred.shape[0], -1))\n        metric = self.f1_score_fn(y_true, y_pred)\n        self.total.assign_add(metric)\n        self.count.assign_add(tf.cast(1, tf.float32))\n    def result(self):\n        return self.total / self.count","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-08T15:37:28.686645Z","iopub.execute_input":"2025-11-08T15:37:28.68691Z","iopub.status.idle":"2025-11-08T15:37:28.704011Z","shell.execute_reply.started":"2025-11-08T15:37:28.686889Z","shell.execute_reply":"2025-11-08T15:37:28.703365Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"## Weighted BCE function to handle imbalanced label classes\n\ntrue_freq = train_labels.sum()/np.size(train_labels)\n\n@tf.keras.utils.register_keras_serializable()\ndef weighted_binary_crossentropy(y_true, y_pred, zero_weight=true_freq, one_weight=1-true_freq):\n    y_true = tf.cast(y_true, dtype=tf.float32)\n    y_pred = tf.cast(y_pred, dtype=tf.float32)\n    # Clip predictions to avoid log(0)\n    epsilon = K.epsilon()\n    y_pred = K.clip(y_pred, epsilon, 1 - epsilon)\n    \n    # Compute binary cross-entropy\n    bce = -(y_true * K.log(y_pred) + (1 - y_true) * K.log(1 - y_pred))\n    \n    # Apply weights\n    weights = y_true * one_weight + (1 - y_true) * zero_weight\n    weighted_bce = weights * bce\n    return K.mean(weighted_bce)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-08T15:37:28.70471Z","iopub.execute_input":"2025-11-08T15:37:28.705474Z","iopub.status.idle":"2025-11-08T15:37:28.953028Z","shell.execute_reply.started":"2025-11-08T15:37:28.705456Z","shell.execute_reply":"2025-11-08T15:37:28.952407Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"The base network is a version of EfficientNet architecture (https://arxiv.org/pdf/1905.11946). The version number and the number of layers to retune are hyperparameters and can be tuned accordingly.","metadata":{}},{"cell_type":"markdown","source":"![](https://1.bp.blogspot.com/-Cdtb97FtgdA/XO3BHsB7oEI/AAAAAAAAEKE/bmtkonwgs8cmWyI5esVo8wJPnhPLQ5bGQCLcBGAs/s1600/image4.png)","metadata":{}},{"cell_type":"code","source":"## Network configuration and preprocessing layer\n\n# Network configurations\nbase_network = {4: \"enb0\",     # EfficientNetB0\n                5: \"enb1\",     # EfficientNetB1\n                6: \"enb2\",     # EfficientNetB2\n                7: \"enb3\",     # EfficientNetB3\n                8: \"enb4\",     # EfficientNetB4\n                9: \"env2b0\",   # EfficientNetV2B0\n                10: \"env2b1\",  # EfficientNetV2B1\n                11: \"env2b2\",  # EfficientNetV2B2\n                12: \"env2b3\",  # EfficientNetV2B3\n                13: \"env2s\"}   # EfficientNetV2S\n\n# Custom layer for preprocessing\n@tf.keras.utils.register_keras_serializable()\nclass Rescale(tf.keras.layers.Layer):\n    def __init__(self, **kwargs):\n        super(Rescale, self).__init__(**kwargs)\n    def call(self, inputs):\n        x = tf.cast(inputs, tf.float32)/255\n        return x\n\n@tf.keras.utils.register_keras_serializable()\nclass PreProcess(tf.keras.layers.Layer):\n    def __init__(self, base_network_type, **kwargs):\n        super(PreProcess, self).__init__(**kwargs)\n        if base_network_type < 9: self.preprocess_input = tf.keras.applications.efficientnet.preprocess_input\n        elif base_network_type >= 9: self.preprocess_input = tf.keras.applications.efficientnet_v2.preprocess_input\n        else: print('Wrong base network number have been choosen!!!')\n    def call(self, inputs):\n        return self.preprocess_input(inputs*255.0)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-08T15:37:28.953669Z","iopub.execute_input":"2025-11-08T15:37:28.953847Z","iopub.status.idle":"2025-11-08T15:37:28.960934Z","shell.execute_reply.started":"2025-11-08T15:37:28.953834Z","shell.execute_reply":"2025-11-08T15:37:28.960169Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def upsample(filters, size, norm_type='batchnorm', apply_dropout=False, name=None):\n  \"\"\" Upsamples an input: Conv2DTranspose => Batchnorm => Dropout => Relu\n      Args:\n        filters: number of filters\n        size: filter size\n        norm_type: Normalization type; either 'batchnorm' or 'instancenorm'.\n        apply_dropout: If True, adds the dropout layer\n    \n      Returns:\n        Upsample Sequential Model\"\"\"\n\n  initializer = tf.random_normal_initializer(0., 0.02)\n  result = tf.keras.Sequential(name=name)\n  result.add(\n      tf.keras.layers.Conv2DTranspose(filters, size, strides=2,\n                                      padding='same',\n                                      kernel_initializer=initializer,\n                                      use_bias=False))\n\n  if norm_type.lower() == 'batchnorm':\n    result.add(tf.keras.layers.BatchNormalization())\n  elif norm_type.lower() == 'instancenorm':\n    result.add(InstanceNormalization())\n\n  if apply_dropout:\n    result.add(tf.keras.layers.Dropout(0.5))\n\n  result.add(tf.keras.layers.ReLU())\n  return result","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-08T15:37:28.961712Z","iopub.execute_input":"2025-11-08T15:37:28.961964Z","iopub.status.idle":"2025-11-08T15:37:28.977806Z","shell.execute_reply.started":"2025-11-08T15:37:28.961946Z","shell.execute_reply":"2025-11-08T15:37:28.977121Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"    layer_names = ['block1b_add',          # 128x128x24\n                   'block2d_add',          # 64x64x32\n                   'block3d_add',          # 32x32x56\n                   #'block4f_add',          # 16x16x112\n                   'block5f_add',          # 16x16x160\n                   'block6h_add',          # 8x8x272\n                   'block7b_add',          # 8x8x448\n                   'top_activation',       # 8x8x1792\n                   ]\n    base_model_outputs = [base_model.get_layer(name).output for name in layer_names]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-08T16:33:25.32509Z","iopub.execute_input":"2025-11-08T16:33:25.325811Z","iopub.status.idle":"2025-11-08T16:33:25.331036Z","shell.execute_reply.started":"2025-11-08T16:33:25.325786Z","shell.execute_reply":"2025-11-08T16:33:25.3303Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"base_model_outputs","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-08T16:19:06.34108Z","iopub.execute_input":"2025-11-08T16:19:06.341843Z","iopub.status.idle":"2025-11-08T16:19:06.346766Z","shell.execute_reply.started":"2025-11-08T16:19:06.341818Z","shell.execute_reply":"2025-11-08T16:19:06.346075Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"## Build UNet Architecture with pre-trained EfficientNet encoder and pix2pix decoder\n\ndef build_network(hp):\n    # Select base model and corresponding preprocessing\n    base_network_type = 8 #hp.Int(name='base_network_type', min_value=4, max_value=13, step=1, default=7) # Choose Pretrained Network\n    if base_network_type == 4: base_model = tf.keras.applications.EfficientNetB0(\n        include_top=False, input_shape=[image_size, image_size, 3], weights='imagenet')\n    elif base_network_type == 5: base_model = tf.keras.applications.EfficientNetB1(\n        include_top=False, input_shape=[image_size, image_size, 3], weights='imagenet')\n    elif base_network_type == 6: base_model = tf.keras.applications.EfficientNetB2(\n        include_top=False, input_shape=[image_size, image_size, 3], weights='imagenet')\n    elif base_network_type == 7: base_model = tf.keras.applications.EfficientNetB3(\n        include_top=False, input_shape=[image_size, image_size, 3], weights='imagenet')\n    elif base_network_type == 8: base_model = tf.keras.applications.EfficientNetB4(\n        include_top=False, input_shape=[image_size, image_size, 3], weights='imagenet')\n    elif base_network_type == 9: base_model = tf.keras.applications.EfficientNetV2B0(\n        include_top=False, input_shape=[image_size, image_size, 3], weights='imagenet')\n    elif base_network_type == 10: base_model = tf.keras.applications.EfficientNetV2B1(\n        include_top=False, input_shape=[image_size, image_size, 3], weights='imagenet')\n    elif base_network_type == 11: base_model = tf.keras.applications.EfficientNetV2B2(\n        include_top=False, input_shape=[image_size, image_size, 3], weights='imagenet')\n    elif base_network_type == 12: base_model = tf.keras.applications.EfficientNetV2B3(\n        include_top=False, input_shape=[image_size, image_size, 3], weights='imagenet')\n    elif base_network_type == 13: base_model = tf.keras.applications.EfficientNetV2S(\n        include_top=False, input_shape=[image_size, image_size, 3], weights='imagenet')\n    else: print('Wrong base network number have been choosen!!!')\n    prepocessing = PreProcess(base_network_type=base_network_type, name='preprocessing')\n\n    # Choose base model layers to be trained\n    base_model.trainable = False # freeze base model layers\n    max_layer_nr = len(base_model.layers)\n    # (B0): all:238 / 2ab+:220 / 3ab+:191 / 4abc+:162 / 5abc+:118 / 6abcd+:75 / 7a+:16\n    # (B3): all:385 / 2ab+:355 / 3ab+:311 / 4abc+:267 / 5abc+:193 / 6abcd+:120 / 7a+:31\n    layer_id = 16 #hp.Choice(name='layer_id', values=[355, max_layer_nr, 311, 267, 193, 120, 31]) # layer number from the network shall be trained\n    print('Unfreeze base model layers from layer ' + str(base_model.layers[-layer_id]))\n    for layer in base_model.layers[-layer_id:]: # unfreeze choosen layers\n        layer.trainable = True\n\n    # Create the feature extraction model\n    layer_names = ['block1b_add',          # 128x128x24\n                   'block2d_add',          # 64x64x32\n                   'block3d_add',          # 32x32x56\n                   #'block4f_add',          # 16x16x112\n                   'block5f_add',          # 16x16x160\n                   #'block6h_add',          # 8x8x272\n                   #'block7b_add',          # 8x8x448\n                   'top_activation',       # 8x8x1792\n                   ]\n    base_model_outputs = [base_model.get_layer(name).output for name in layer_names]\n    down_stack = tf.keras.Model(inputs=base_model.input, outputs=base_model_outputs, name='downsampling')\n\n    # Create the upsampling model\n    up_stack = [upsample(160, 3, name='upsampling_block1'),  # 8x8 -> 16x16\n                upsample(56, 3, name='upsampling_block2'),  # 16x16 -> 32x32\n                upsample(32, 3, name='upsampling_block3'),  # 32x32 -> 64x64\n                upsample(24, 3, name='upsampling_block4'),   # 64x64 -> 128x128\n               ]\n\n    # define the sets of inputs\n    input_img = tf.keras.Input(shape=(image_size, image_size, 3), name='input_img')\n\n    # Cast, rescale and preprocess image tensors\n    x = Rescale(name='rescaling')(input_img)\n    x = prepocessing(x)\n    \n    # Downsampling through the model\n    skips = down_stack(x)\n    x = skips[-1]\n    skips = reversed(skips[:-1])\n\n    # Upsampling and establishing the skip connections\n    for i, (up, skip) in enumerate(zip(up_stack, skips)):\n        x = up(x)\n        x = tf.keras.layers.Concatenate(name=f'upsampling_concat{i+1}')([x, skip]) #Concatenate\n        \n    # This is the last layer of the model\n    out = tf.keras.layers.Conv2DTranspose(filters=1, activation='sigmoid', kernel_size=3, strides=2, padding='same', name='conv2dtrans')(x) # 128x128 -> 256x256\n\n    # define model\n    model = tf.keras.Model(inputs=input_img, outputs=out, name='LUC_UNET')\n\n    # define optimizer/loss and compile model\n    lr_tune = 5e-4 #hp.Float(name='learning_rate', min_value=1e-4, max_value=1e-2, sampling='log', default=1e-3)\n    optimizer = tf.keras.optimizers.Nadam(lr_tune)\n    loss = weighted_binary_crossentropy #WeightedBinaryCrossentropy()\n    metrics = CustomF1()\n    model.compile(optimizer=optimizer, loss=loss, metrics=[metrics], run_eagerly=False)\n    return model\n\nif not SUBMISSIONING:\n    with strategy.scope():\n        model = build_network(kt.HyperParameters())\nelse:\n    # Load pre-trained model for submission\n    model = tf.keras.models.load_model('/kaggle/input/luc-1xx/luc_1_0_0.h5')\n    print('Model weights have been loaded!')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-08T16:36:21.928805Z","iopub.execute_input":"2025-11-08T16:36:21.929109Z","iopub.status.idle":"2025-11-08T16:36:23.94298Z","shell.execute_reply.started":"2025-11-08T16:36:21.929089Z","shell.execute_reply":"2025-11-08T16:36:23.942345Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"## Explore model architecture\n\nmodel.summary(line_length=110)\n# tf.keras.utils.plot_model(model, to_file='model_architecture.png', show_shapes=True, show_dtype=False,\n#                           show_layer_names=True, show_layer_activations=True, show_trainable=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-08T16:36:25.459625Z","iopub.execute_input":"2025-11-08T16:36:25.459897Z","iopub.status.idle":"2025-11-08T16:36:25.493109Z","shell.execute_reply.started":"2025-11-08T16:36:25.459879Z","shell.execute_reply":"2025-11-08T16:36:25.492356Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 5. Training","metadata":{}},{"cell_type":"code","source":"## Training parameters\n\nepochs = 100\nsteps_per_epoch = len(train_labels)//batch_size\nTUNING = False and not SUBMISSIONING\nTRAINING = True and not SUBMISSIONING\nFINETUNING = False and not SUBMISSIONING","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-08T16:37:16.841582Z","iopub.execute_input":"2025-11-08T16:37:16.841867Z","iopub.status.idle":"2025-11-08T16:37:16.846205Z","shell.execute_reply.started":"2025-11-08T16:37:16.841848Z","shell.execute_reply":"2025-11-08T16:37:16.845592Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"## Tuner configurations\n\nif TUNING:\n    i_TunerTyp = 1 # Choose desired tuner type: {1: 'grid', 2: 'random', 3: 'hyper'}\n    TunerStr = {1: 'grid', 2: 'random', 3: 'hyper'}\n    \n    tuner_grid = kt.GridSearch(hypermodel=build_network, objective=kt.Objective(\"val_cf1_score\", direction=\"max\"),\n                               max_trials=15, max_consecutive_failed_trials=1,\n                               overwrite=True, directory=\"tuner\", project_name=\"LUC\", distribution_strategy = strategy)\n    \n    tuner_random = kt.RandomSearch(hypermodel=build_network, objective=kt.Objective(\"val_cf1_score\", direction=\"max\"),\n                                   max_trials=10, executions_per_trial=1,\n                                   overwrite=True, directory=\"tuner\", project_name=\"LUC\", distribution_strategy = strategy)\n    \n    tuner_hyper = kt.Hyperband(hypermodel=build_network, objective=kt.Objective(\"val_cf1_score\", direction=\"max\"),\n                               max_epochs=60, factor=4, hyperband_iterations=1,\n                               overwrite=True, directory=\"tuner\", project_name=\"LUC\", distribution_strategy = strategy)\n    \n    tuner = globals()[f'tuner_{TunerStr[i_TunerTyp]}']\n    tuner.search_space_summary()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-08T16:37:18.347715Z","iopub.execute_input":"2025-11-08T16:37:18.347992Z","iopub.status.idle":"2025-11-08T16:37:18.354004Z","shell.execute_reply.started":"2025-11-08T16:37:18.347972Z","shell.execute_reply":"2025-11-08T16:37:18.353169Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"## Train or tune model\n\n# Callback functions\nlr_scheduler = tf.keras.callbacks.ReduceLROnPlateau(factor=0.2, patience=5, verbose=1, monitor='val_cf1_score', mode='max')\nearly_stopping_cb = tf.keras.callbacks.EarlyStopping(patience=10, verbose=1, monitor='val_cf1_score', mode='max', restore_best_weights=True)\nlr_schedule = tf.keras.callbacks.LearningRateScheduler(lambda epoch: 1e-5 * 10**(epoch / 10)) # Find starting learning\n\n# Training\nif TRAINING or FINETUNING:\n    history = model.fit(train_ds, validation_data=val_ds, epochs=epochs, steps_per_epoch=steps_per_epoch,\n                        callbacks=[lr_scheduler, early_stopping_cb])\n\n# Tuning\nif TUNING:\n    tuner.search(train_ds, validation_data=val_ds, epochs=epochs, steps_per_epoch=steps_per_epoch,\n                 callbacks=[lr_scheduler, early_stopping_cb])\n    best_models = tuner.get_best_models(num_models=2)\n    model = best_models[0]\n    model.summary()\n    tuner.results_summary()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-08T16:37:20.534226Z","iopub.execute_input":"2025-11-08T16:37:20.534885Z","iopub.status.idle":"2025-11-08T16:43:58.303663Z","shell.execute_reply.started":"2025-11-08T16:37:20.534861Z","shell.execute_reply":"2025-11-08T16:43:58.302712Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"## Save weights of model after training/tuning/finetuning\n\nif TRAINING or TUNING or FINETUNING:\n    model.save('luc_1_1_0.h5', include_optimizer=False)\n    print('Model weights have been saved!')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 6. Evaluation","metadata":{}},{"cell_type":"code","source":"## Plot learning curves\n\nif TRAINING or FINETUNING:\n    history_fil = {key: history.history[key] for key in ['cf1_score', 'val_cf1_score']}\n    history_fil2 = {key: history.history[key] for key in ['loss', 'val_loss']}\n    history_fil3 = {key: history.history[key] for key in ['learning_rate']}\n    \n    pd.DataFrame(history_fil).plot()\n    plt.ylabel(\"Accuracy\")\n    plt.xlabel(\"epochs\")\n    pd.DataFrame(history_fil2).plot()\n    plt.ylabel(\"Loss\")\n    plt.xlabel(\"epochs\")\n    #plt.axis([10, len(history_fil2['val_loss']), 0, history_fil2['val_loss'][10]+0.1*history_fil2['val_loss'][10]])\n    pd.DataFrame(history_fil3).plot()\n    plt.ylabel(\"Learning rate\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-08T16:02:13.007237Z","iopub.execute_input":"2025-11-08T16:02:13.008038Z","iopub.status.idle":"2025-11-08T16:02:13.558129Z","shell.execute_reply.started":"2025-11-08T16:02:13.008012Z","shell.execute_reply":"2025-11-08T16:02:13.557532Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"## Compare predicted with ground true masks\n\ndef display(display_list):\n    plt.figure(figsize=(15, 15))\n    title = ['Input Image', 'True Mask', 'Predicted Mask']\n\n    for i in range(len(display_list)):\n        plt.subplot(1, len(display_list), i+1)\n        plt.title(title[i])\n        plt.imshow(tf.keras.utils.array_to_img(display_list[i]))\n        plt.axis('off')\n    plt.show()\n\ndef create_mask(pred_mask):\n    pred_mask = tf.cast(tf.math.greater(pred_mask, 0.5), dtype=tf.int8)\n    return pred_mask[0]\n\ndef show_predictions(dataset=None, num=1):\n    if dataset:\n        for image, mask in dataset.take(num):\n          pred_mask = model.predict(image, verbose=0)\n          display([image[0], mask[0], create_mask(pred_mask)])\n    else:\n        display([sample_image, sample_mask,\n                 create_mask(model.predict(sample_image[tf.newaxis, ...]))])\n\nshow_predictions(train_ds, 3)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-08T16:44:04.719987Z","iopub.execute_input":"2025-11-08T16:44:04.720652Z","iopub.status.idle":"2025-11-08T16:44:16.00619Z","shell.execute_reply.started":"2025-11-08T16:44:04.72063Z","shell.execute_reply":"2025-11-08T16:44:16.005634Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 7. Submission","metadata":{}},{"cell_type":"code","source":"## Utility: RLE encode \n\ndef _rle_one(arr):\n    \"\"\"Encode a single 2D binary mask into RLE list of pairs.\"\"\"\n    dots = np.where(arr.T.flatten() == 1)[0]\n    if len(dots) == 0:\n        return []\n    run_lengths = []\n    prev = -2\n    for b in dots:\n        if b > prev + 1:\n            run_lengths.extend((int(b) + 1, 0))\n        run_lengths[-1] += 1\n        prev = b\n    return run_lengths\n\ndef rle_encode(masks, fg_val=1):\n    return ';'.join(json.dumps(_rle_one(m)) for m in masks)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"## Test prediction & submission \n\nif SUBMISSIONING:\n    folder_path_test = Path(\"/kaggle/input/recodai-luc-scientific-image-forgery-detection/test_images\")\n    test_pred = {}\n    \n    for file_path in natsorted(folder_path_test.glob(\"*.png\")):\n        image_id = os.path.splitext(os.path.basename(file_path))[0]\n        image = cv2.imread(str(file_path))\n        orig_sizes = image[:,:,0:1]\n        image = preprocess_images(image, False)\n        image_tensor = tf.expand_dims(tf.convert_to_tensor(image), 0)\n        test_probs = model.predict(image_tensor, verbose=0)[0]\n        test_preds = (test_probs>0.5).astype(dtype=np.uint8)*255\n        pred_np = postprocess_images(test_preds, orig_sizes)[:,:,0].numpy()\n        pred_np = (pred_np>122).astype(dtype=np.uint8)\n        if pred_np.sum() == 0:\n            test_pred[image_id] = \"authentic\"\n        else:\n            rle = rle_encode([pred_np], fg_val=1)\n            test_pred[image_id] = rle\n    \n    submission_df = pd.DataFrame([{\"case_id\": k, \"annotation\": v} for k, v in test_pred.items()])\n    submission_df.to_csv(\"submission.csv\", index=False)\n    print(\"✅ submission.csv saved!\")\n    print(submission_df.head())   ","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 8. Experimental code (e.g. for debugging)","metadata":{}},{"cell_type":"code","source":"# ## Plot learning curves for definition of start leraning rate\n# lrs = 1e-5 * (10 ** (np.arange(len(history.history[\"loss\"])) / 10)) # Define the learning rate array\n# plt.figure(figsize=(10, 6)) # Set the figure size\n# plt.grid(True) # Set the grid\n# plt.semilogx(lrs, history.history[\"loss\"]) # Plot the loss in log scale\n# plt.tick_params('both', length=10, width=1, which='both') # Increase the tickmarks size\n# #plt.axis([1e-5, 1e-0, 0, 10]) # Set the plot boundaries","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-08T13:10:12.658666Z","iopub.execute_input":"2025-11-08T13:10:12.659525Z","iopub.status.idle":"2025-11-08T13:10:12.663125Z","shell.execute_reply.started":"2025-11-08T13:10:12.659502Z","shell.execute_reply":"2025-11-08T13:10:12.662157Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# max_x = 0\n# max_y = 0\n# max_z = 0\n# for image in labels_fo:\n#     if image.shape[0] > max_x:\n#         max_x = image.shape[0]\n#     if image.shape[1] > max_y:\n#         max_y = image.shape[1]  \n#     if image.shape[2] > max_z:\n#         max_z = image.shape[2]\n# print(max_x)\n# print(max_y)\n# print(max_z)","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}