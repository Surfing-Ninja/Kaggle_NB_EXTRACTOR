{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":113558,"databundleVersionId":14174843,"sourceType":"competition"},{"sourceId":4534,"sourceType":"modelInstanceVersion","modelInstanceId":3326,"modelId":986}],"dockerImageVersionId":31154,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## ðŸ§  DINOv2 Multi-Task Pipeline\n\nThis notebook implements a **multi-task architecture** based on **DINOv2** â€”  \na frozen vision backbone that powers two lightweight heads:  \n**Segmentation** (detecting manipulated regions) and  \n**Classification** (authentic vs forged).\n\n---\n\n### âš™ï¸ Architecture Overview\n- **Encoder** â†’ DINOv2-Base (frozen feature extractor)  \n- **Segmentation Head** â†’ compact Convâ€“ReLUâ€“Conv decoder  \n- **Classification Head** â†’ linear layer over the CLS token  \n- **Optimization** â†’ `AdamW` + `BCEWithLogitsLoss` / `CrossEntropyLoss`  \n- **Metrics** â†’ IoU, Dice, Pixel Accuracy  \n\n---\n\n### ðŸ”„ Pipeline Steps\n1. **Dataset Loading** â†’ authentic / forged images + mask files (`.npy`)  \n2. **Feature Extraction** â†’ DINOv2 encoder  \n3. **Segmentation** â†’ binary mask prediction of forged regions  \n4. **Classification** â†’ authenticity decision (A / F)  \n5. **Evaluation** â†’ IoU, Dice & Accuracy on validation set  \n\n---\n\n> ðŸ§© **Note:** The model runs in **Offline Kaggle** mode â€”  \n> DINOv2 is loaded from `/kaggle/input/dinov2/pytorch/base/1`.\n","metadata":{}},{"cell_type":"code","source":"import os, gc, math, random, json\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader\nfrom tqdm import tqdm\n\n# ----------------------------\n# Prepare datasets and loaders\n# ----------------------------\ntrain_cls_dataset = ForgeryClsDataset(train_auth, train_forg, IMG_SIZE)\nval_cls_dataset = ForgeryClsDataset(val_auth, val_forg, IMG_SIZE)\n\ntrain_cls_loader = DataLoader(\n    train_cls_dataset, batch_size=BATCH_CLS, shuffle=True, num_workers=2, pin_memory=True\n)\nval_cls_loader = DataLoader(\n    val_cls_dataset, batch_size=BATCH_CLS, shuffle=False, num_workers=2, pin_memory=True\n)\n\n# ----------------------------\n# SEGMENTATION TRAINING\n# ----------------------------\nseg_criterion = nn.BCEWithLogitsLoss()\nseg_optimizer = optim.AdamW(model.seg_head.parameters(), lr=LR_SEG, weight_decay=WEIGHT_DECAY)\n\nfor epoch in range(1, EPOCHS_SEG + 1):\n    model.train()\n    train_loss = 0.0\n\n    for imgs, masks in tqdm(train_seg_loader, desc=f\"[Seg] Epoch {epoch}/{EPOCHS_SEG}\"):\n        imgs, masks = imgs.to(device), masks.to(device)\n\n        logits = model.forward_seg(imgs)\n        loss = seg_criterion(logits, masks)\n\n        seg_optimizer.zero_grad()\n        loss.backward()\n        seg_optimizer.step()\n\n        train_loss += loss.item() * imgs.size(0)\n\n    train_loss /= len(train_seg_loader.dataset)\n\n    # ----------------------------\n    # Validation\n    # ----------------------------\n    model.eval()\n    val_loss, total_iou, total_dice, total_acc = 0.0, 0.0, 0.0, 0.0\n\n    with torch.no_grad():\n        for imgs, masks in val_seg_loader:\n            imgs, masks = imgs.to(device), masks.to(device)\n            logits = model.forward_seg(imgs)\n            loss = seg_criterion(logits, masks)\n            val_loss += loss.item() * imgs.size(0)\n\n            probs = torch.sigmoid(logits).cpu().numpy()\n            gts = masks.cpu().numpy()\n\n            for p, g in zip(probs, gts):\n                p = p[0]\n                g = g[0]\n                total_iou += iou_score(p, g)\n                total_dice += dice_score(p, g)\n                total_acc += pixel_acc(p, g)\n\n    n_val = len(val_seg_loader.dataset)\n    print(\n        f\"[Seg] Epoch {epoch} | train_loss={train_loss:.4f} | val_loss={val_loss/n_val:.4f} \"\n        f\"| IoU={total_iou/n_val:.3f} | Dice={total_dice/n_val:.3f} | Acc={total_acc/n_val:.3f}\"\n    )\n\n    torch.cuda.empty_cache()\n    gc.collect()\n\n# ----------------------------\n# CLASSIFICATION TRAINING\n# ----------------------------\ncls_criterion = nn.CrossEntropyLoss()\ncls_optimizer = optim.AdamW(model.cls_head.parameters(), lr=LR_CLS, weight_decay=WEIGHT_DECAY)\n\nfor epoch in range(1, EPOCHS_CLS + 1):\n    model.train()\n    train_loss = 0.0\n\n    for imgs, labels in tqdm(train_cls_loader, desc=f\"[Cls] Epoch {epoch}/{EPOCHS_CLS}\"):\n        imgs, labels = imgs.to(device), labels.to(device)\n\n        logits = model.forward_cls(imgs)\n        loss = cls_criterion(logits, labels)\n\n        cls_optimizer.zero_grad()\n        loss.backward()\n        cls_optimizer.step()\n\n        train_loss += loss.item() * imgs.size(0)\n\n    train_loss /= len(train_cls_loader.dataset)\n\n    # ----------------------------\n    # Validation\n    # ----------------------------\n    model.eval()\n    correct, total = 0, 0\n\n    with torch.no_grad():\n        for imgs, labels in val_cls_loader:\n            imgs, labels = imgs.to(device), labels.to(device)\n            logits = model.forward_cls(imgs)\n            preds = logits.argmax(dim=1)\n            correct += (preds == labels).sum().item()\n            total += labels.size(0)\n\n    print(f\"[Cls] Epoch {epoch} | train_loss={train_loss:.4f} | val_acc={100.0*correct/total:.2f}%\")\n\n    torch.cuda.empty_cache()\n    gc.collect()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"\nðŸš€ Inference & Submission Phase","metadata":{}},{"cell_type":"code","source":"def predict_mask_prob(img_pil):\n    \"\"\"Predict mask probability for a single PIL image\"\"\"\n    img = img_pil.convert(\"RGB\").resize((IMG_SIZE, IMG_SIZE), Image.BILINEAR)\n    x = torch.from_numpy(np.array(img, dtype=np.float32)/255.).permute(2,0,1)[None].to(device)\n    with torch.no_grad():\n        logits = model.forward_seg(x)\n        prob = torch.sigmoid(logits)[0,0].cpu().numpy()\n    return prob\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def tta_predict(img_pil):\n    \"\"\"Horizontal flip TTA prediction\"\"\"\n    prob = predict_mask_prob(img_pil)\n    img_flip = img_pil.transpose(Image.FLIP_LEFT_RIGHT)\n    prob_flip = predict_mask_prob(img_flip)\n    prob = 0.5 * (prob + prob_flip[:, ::-1])  # average TTA\n    return prob\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from skimage import measure\n\ndef post_process(mask, min_size=20):\n    \"\"\"Remove small blobs to reduce false positives\"\"\"\n    labeled = measure.label(mask)\n    new_mask = np.zeros_like(mask, dtype=np.uint8)\n    for region in measure.regionprops(labeled):\n        if region.area >= min_size:\n            coords = region.coords\n            new_mask[coords[:,0], coords[:,1]] = 1\n    return new_mask\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def rle_encode_numpy(mask):\n    \"\"\"Mask (2D numpy) to RLE list\"\"\"\n    pixels = mask.flatten(order='F')\n    pixels = np.concatenate([[0], pixels, [0]])\n    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n    runs[1::2] -= runs[::2]\n    return runs.tolist()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def binarize_mask(prob, thr=0.5):\n    \"\"\"Convert probability mask to binary mask\"\"\"\n    return (prob > thr).astype(np.uint8)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def write_submission(rows, sample_csv=\"sample_submission.csv\", out_csv=\"submission.csv\"):\n    sub = pd.DataFrame(rows, columns=[\"case_id\",\"annotation\"])\n    if os.path.exists(sample_csv):\n        ss = pd.read_csv(sample_csv)\n        ss[\"case_id\"] = ss[\"case_id\"].astype(str)\n        if not sub.empty:\n            sub[\"case_id\"] = sub[\"case_id\"].astype(str)\n            sub = ss[[\"case_id\"]].merge(sub, on=\"case_id\", how=\"left\")\n            sub[\"annotation\"] = sub[\"annotation\"].fillna(\"authentic\")\n        else:\n            sub = ss[[\"case_id\"]].copy()\n            sub[\"annotation\"] = \"authentic\"\n    sub.to_csv(out_csv, index=False)\n    print(\"Wrote submission:\", out_csv)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\n# Inference + Submission (segmentation -> RLE, sinon 'authentic')\n\ndef predict_mask_prob(img_pil):\n    img = img_pil.convert(\"RGB\").resize((IMG_SIZE, IMG_SIZE), Image.BILINEAR)\n    x = torch.from_numpy(np.array(img, dtype=np.float32)/255.).permute(2,0,1)[None].to(device)\n    with torch.no_grad():\n        logits = model.forward_seg(x)\n        prob = torch.sigmoid(logits)[0,0].cpu().numpy()\n    return prob\n\nTHR = 0.5\nrows = []\nif os.path.exists(TEST_DIR):\n    test_files = sorted(os.listdir(TEST_DIR))\n    print(\"Test images:\", len(test_files))\n    for fname in tqdm(test_files, desc=\"Inference\"):\n        case_id = Path(fname).stem\n        path = str(Path(TEST_DIR)/fname)\n        pil = Image.open(path).convert(\"RGB\")\n        ow, oh = pil.size\n\n        prob = predict_mask_prob(pil)  # IMG_SIZE x IMG_SIZE\n        # resize to original size\n        mask = cv2.resize(prob, (ow, oh), interpolation=cv2.INTER_NEAREST)\n        binm = (mask > THR).astype(np.uint8)\n\n        if binm.sum() == 0:\n            annot = \"authentic\"\n        else:\n            annot = rle_encode_numpy(binm)  # JSON list of [start,length,...]\n\n        rows.append({\"case_id\": case_id, \"annotation\": annot})\n\nsub = pd.DataFrame(rows, columns=[\"case_id\",\"annotation\"])\n\n# Aligne avec sample_submission\nif os.path.exists(SAMPLE_SUB):\n    ss = pd.read_csv(SAMPLE_SUB)\n    ss[\"case_id\"] = ss[\"case_id\"].astype(str)\n    if not sub.empty:\n        sub[\"case_id\"] = sub[\"case_id\"].astype(str)\n        sub = ss[[\"case_id\"]].merge(sub, on=\"case_id\", how=\"left\")\n        sub[\"annotation\"] = sub[\"annotation\"].fillna(\"authentic\")\n    else:\n        sub = ss[[\"case_id\"]].copy()\n        sub[\"annotation\"] = \"authentic\"\n\n# Sauvegarde\nOUT_PATH = \"submission.csv\"\nsub.to_csv(OUT_PATH, index=False)\nprint(\" Wrote submission:\", OUT_PATH)\nprint(sub.head())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-04T05:19:24.714702Z","iopub.execute_input":"2025-11-04T05:19:24.714952Z","iopub.status.idle":"2025-11-04T05:19:24.928937Z","shell.execute_reply.started":"2025-11-04T05:19:24.714936Z","shell.execute_reply":"2025-11-04T05:19:24.92799Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"\nðŸ–¼ï¸ Forgery Mask Visualization\n\n","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\n\n# Function: predict probability mask\n\ndef predict_mask_prob(img_pil):\n    \"\"\"Predict a pixel-wise probability mask for a given image.\"\"\"\n    img = img_pil.convert(\"RGB\").resize((IMG_SIZE, IMG_SIZE), Image.BILINEAR)\n    x = torch.from_numpy(np.array(img, dtype=np.float32) / 255.).permute(2, 0, 1)[None].to(device)\n    with torch.no_grad():\n        logits = model.forward_seg(x)\n        prob = torch.sigmoid(logits)[0, 0].cpu().numpy()\n    return prob\n\n# Visualization on random test images\n\nN_SHOW = 5  # number of test images to visualize\nTHR = 0.5   # threshold for binary mask\n\nif os.path.exists(TEST_DIR):\n    test_files = sorted(os.listdir(TEST_DIR))\n    samples = random.sample(test_files, min(N_SHOW, len(test_files)))\n\n    plt.figure(figsize=(14, N_SHOW * 4))\n    for i, fname in enumerate(samples, 1):\n        path = str(Path(TEST_DIR) / fname)\n        pil = Image.open(path).convert(\"RGB\")\n        ow, oh = pil.size\n\n        # Predict probability mask\n        prob = predict_mask_prob(pil)\n        mask_resized = cv2.resize(prob, (ow, oh), interpolation=cv2.INTER_NEAREST)\n        binary_mask = (mask_resized > THR).astype(np.uint8)\n\n        # Visualization: original / prob mask / overlay\n        plt.subplot(N_SHOW, 3, 3*(i-1)+1)\n        plt.imshow(pil)\n        plt.title(f\"Original - {fname}\")\n        plt.axis(\"off\")\n\n        plt.subplot(N_SHOW, 3, 3*(i-1)+2)\n        plt.imshow(mask_resized, cmap=\"viridis\")\n        plt.title(\"Probability Mask\")\n        plt.axis(\"off\")\n\n        plt.subplot(N_SHOW, 3, 3*(i-1)+3)\n        plt.imshow(pil)\n        plt.imshow(binary_mask, cmap=\"Reds\", alpha=0.4)\n        plt.title(\"Overlay Mask\")\n        plt.axis(\"off\")\n\n    plt.tight_layout()\n    plt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-04T05:20:15.752631Z","iopub.execute_input":"2025-11-04T05:20:15.75293Z","iopub.status.idle":"2025-11-04T05:20:17.137109Z","shell.execute_reply.started":"2025-11-04T05:20:15.752908Z","shell.execute_reply":"2025-11-04T05:20:17.13635Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"\nðŸ§© Authentic Image Mask Visualization\n\n","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\n# Function: predict mask on tensor batch\n\ndef predict_val_batch(model, loader, n_show=5, thr=0.5):\n    \"\"\"Display a few validation images with GT mask and predicted mask.\"\"\"\n    model.eval()\n    shown = 0\n\n    plt.figure(figsize=(12, n_show * 4))\n\n    with torch.no_grad():\n        for imgs, masks in loader:\n            imgs, masks = imgs.to(device), masks.to(device)\n            logits = model.forward_seg(imgs)\n            probs = torch.sigmoid(logits).cpu().numpy()\n            imgs_np = imgs.cpu().permute(0, 2, 3, 1).numpy()\n            gts = masks.cpu().numpy()\n\n            for j in range(len(imgs)):\n                if shown >= n_show:\n                    break\n\n                # Retrieve elements\n                img = np.clip(imgs_np[j], 0, 1)\n                gt = gts[j, 0]\n                prob = probs[j, 0]\n                pred_bin = (prob > thr).astype(np.uint8)\n\n                # Show three panels\n                plt.subplot(n_show, 3, 3 * shown + 1)\n                plt.imshow(img)\n                plt.title(\"Original\")\n                plt.axis(\"off\")\n\n                plt.subplot(n_show, 3, 3 * shown + 2)\n                plt.imshow(gt, cmap=\"gray\")\n                plt.title(\"Ground Truth\")\n                plt.axis(\"off\")\n\n                plt.subplot(n_show, 3, 3 * shown + 3)\n                plt.imshow(img)\n                plt.imshow(pred_bin, cmap=\"Reds\", alpha=0.4)\n                plt.title(\"Predicted Mask\")\n                plt.axis(\"off\")\n\n                shown += 1\n\n            if shown >= n_show:\n                break\n\n    plt.tight_layout()\n    plt.show()\n\n# Run visualization\npredict_val_batch(model, val_seg_loader, n_show=5, thr=0.5)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-04T05:20:20.591384Z","iopub.execute_input":"2025-11-04T05:20:20.591771Z","iopub.status.idle":"2025-11-04T05:20:23.286026Z","shell.execute_reply.started":"2025-11-04T05:20:20.591746Z","shell.execute_reply":"2025-11-04T05:20:23.284976Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"\nðŸ”¥ Forged Image Mask Visualization\n\n","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\ndef show_forged_examples(model, loader, n_show=5, thr=0.5):\n    \"\"\"Show only forged examples from validation set (mask not empty).\"\"\"\n    model.eval()\n    shown = 0\n\n    plt.figure(figsize=(12, n_show * 4))\n\n    with torch.no_grad():\n        for imgs, masks in loader:\n            imgs, masks = imgs.to(device), masks.to(device)\n            logits = model.forward_seg(imgs)\n            probs = torch.sigmoid(logits).cpu().numpy()\n            imgs_np = imgs.cpu().permute(0, 2, 3, 1).numpy()\n            gts = masks.cpu().numpy()\n\n            for j in range(len(imgs)):\n                gt = gts[j, 0]\n                if gt.sum() == 0:  # skip authentic images\n                    continue\n\n                img = np.clip(imgs_np[j], 0, 1)\n                prob = probs[j, 0]\n                pred_bin = (prob > thr).astype(np.uint8)\n\n                # 3 panels: original / GT / predicted\n                plt.subplot(n_show, 3, 3 * shown + 1)\n                plt.imshow(img)\n                plt.title(\"Original (Forged)\")\n                plt.axis(\"off\")\n\n                plt.subplot(n_show, 3, 3 * shown + 2)\n                plt.imshow(gt, cmap=\"gray\")\n                plt.title(\"Ground Truth Mask\")\n                plt.axis(\"off\")\n\n                plt.subplot(n_show, 3, 3 * shown + 3)\n                plt.imshow(img)\n                plt.imshow(pred_bin, cmap=\"Reds\", alpha=0.4)\n                plt.title(\"Predicted Mask\")\n                plt.axis(\"off\")\n\n                shown += 1\n                if shown >= n_show:\n                    break\n\n            if shown >= n_show:\n                break\n\n    plt.tight_layout()\n    plt.show()\n\n#  Run visualization\nshow_forged_examples(model, val_seg_loader, n_show=5, thr=0.5)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-04T05:20:29.573067Z","iopub.execute_input":"2025-11-04T05:20:29.574003Z","iopub.status.idle":"2025-11-04T05:21:10.655029Z","shell.execute_reply.started":"2025-11-04T05:20:29.573971Z","shell.execute_reply":"2025-11-04T05:21:10.653778Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}