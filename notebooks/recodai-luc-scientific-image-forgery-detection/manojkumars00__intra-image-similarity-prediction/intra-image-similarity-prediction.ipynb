{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":113558,"databundleVersionId":14174843,"sourceType":"competition"},{"sourceId":273328546,"sourceType":"kernelVersion"},{"sourceId":273199670,"sourceType":"kernelVersion"}],"dockerImageVersionId":31153,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Visualizing the training results.\n## Model Architecture\n- https://www.kaggle.com/code/manojkumars00/intra-image-similarity-with-self-correlation-arch/output\n\n## Baseline Training\n- 15 Epochs\n- Data Augumentation\n- - Horizantal & Vertical Flip\n- Metrics\n- - IOU : 0.5148\n  - Dice Coeff : 0.6797\n- https://www.kaggle.com/code/manojkumars00/intra-image-similarity-learning/notebook\n\n\n## Further Steps Planned\n- Synthetic Data Generation\n- Trying out Instance Segmentation ","metadata":{}},{"cell_type":"code","source":"from intra_image_similarity_with_self_correlation_arch import CmfdModel\n\nmodel = CmfdModel(encoder_name=\"nvidia/mit-b1\", apply_softmax=False)\nmodel_image_processor = model.image_processor","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-11-04T08:48:13.882273Z","iopub.execute_input":"2025-11-04T08:48:13.882563Z","iopub.status.idle":"2025-11-04T08:49:07.782952Z","shell.execute_reply.started":"2025-11-04T08:48:13.882541Z","shell.execute_reply":"2025-11-04T08:49:07.781903Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nfrom types import SimpleNamespace","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-04T08:49:07.784497Z","iopub.execute_input":"2025-11-04T08:49:07.785226Z","iopub.status.idle":"2025-11-04T08:49:07.789512Z","shell.execute_reply.started":"2025-11-04T08:49:07.785202Z","shell.execute_reply":"2025-11-04T08:49:07.788637Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"ckpt_path = \"/kaggle/input/intra-image-similarity-learning/checkpoints/best.pt\"\ncheckpoint = torch.load(ckpt_path, map_location=\"cpu\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-04T08:49:07.790433Z","iopub.execute_input":"2025-11-04T08:49:07.790775Z","iopub.status.idle":"2025-11-04T08:49:08.983233Z","shell.execute_reply.started":"2025-11-04T08:49:07.790756Z","shell.execute_reply":"2025-11-04T08:49:08.981862Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"for key, value in checkpoint.items():\n    print(key, type(value))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-04T08:49:08.985428Z","iopub.execute_input":"2025-11-04T08:49:08.985768Z","iopub.status.idle":"2025-11-04T08:49:08.99243Z","shell.execute_reply.started":"2025-11-04T08:49:08.985732Z","shell.execute_reply":"2025-11-04T08:49:08.991156Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Recreate config\ncfg = SimpleNamespace(**checkpoint[\"config\"])\n\nstate_dict = checkpoint[\"model\"]                      # this is an OrderedDict\nmissing, unexpected = model.load_state_dict(state_dict, strict=False)\nprint(\"Missing keys:\", missing)\nprint(\"Unexpected keys:\", unexpected)\n\nmodel.eval()\n\nprint(\"Model successfully loaded and ready for inference.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-04T08:49:08.993551Z","iopub.execute_input":"2025-11-04T08:49:08.994513Z","iopub.status.idle":"2025-11-04T08:49:09.083375Z","shell.execute_reply.started":"2025-11-04T08:49:08.99448Z","shell.execute_reply":"2025-11-04T08:49:09.082202Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nfrom PIL import Image\nimport numpy as np\n\nimport matplotlib.pyplot as plt\nimport torch.nn.functional as F\n\nimport os\nimport random\nfrom skimage import measure\n\nimport cv2\nfrom shapely.geometry import Polygon","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-04T08:49:09.08425Z","iopub.execute_input":"2025-11-04T08:49:09.084992Z","iopub.status.idle":"2025-11-04T08:49:09.23927Z","shell.execute_reply.started":"2025-11-04T08:49:09.084955Z","shell.execute_reply":"2025-11-04T08:49:09.238405Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def load_image(image_path):\n    image = Image.open(image_path).convert('RGB')\n    image = np.array(image)\n    return image\n\ndef load_mask(mask_path):\n    mask = np.load(mask_path)\n    mask = mask * np.arange(1, mask.shape[0] + 1)[:, None, None]\n    mask = mask.sum(axis=0)\n    mask = (mask>=1).astype('uint8')\n    return mask","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-04T08:49:09.240372Z","iopub.execute_input":"2025-11-04T08:49:09.241197Z","iopub.status.idle":"2025-11-04T08:49:09.24744Z","shell.execute_reply.started":"2025-11-04T08:49:09.241102Z","shell.execute_reply":"2025-11-04T08:49:09.24633Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def apply_model_pre_processor(image, mask):\n    enc = model_image_processor(\n        image,\n        segmentation_maps=mask,   \n        return_tensors=\"pt\"\n    )\n    return enc[\"pixel_values\"], enc[\"labels\"].squeeze(0).long()\n    ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-04T08:49:09.248512Z","iopub.execute_input":"2025-11-04T08:49:09.248868Z","iopub.status.idle":"2025-11-04T08:49:09.265046Z","shell.execute_reply.started":"2025-11-04T08:49:09.248838Z","shell.execute_reply":"2025-11-04T08:49:09.263992Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def plot_sample(image, mask, pred_mask):\n    # Read images\n    input_img = image\n    target_mask = mask\n    mask_img = pred_mask\n\n    # assume mask_img[0] is the binary mask\n    pred_mask = (pred_mask > 0.5).astype(np.uint8)\n\n    # find contours (boundaries) of forged areas\n    contours = measure.find_contours(pred_mask, level=0.5)\n\n    # Plot side-by-side\n    plt.figure(figsize=(12, 4))\n\n    plt.subplot(1, 3, 1)\n    plt.imshow(input_img)\n    plt.title(\"Model Input Image\")\n    plt.axis('off')\n\n    plt.subplot(1, 3, 2)\n    plt.imshow(target_mask)\n    plt.title(\"Target Mask With Predited Dot Overlay\")\n    plt.axis('off')\n\n    # draw contours over forged image\n    for contour in contours:\n        poly = Polygon(contour[:, ::-1]) \n        buffer_distance = 7  # pixels or coordinate units\n        buffered_poly = poly.buffer(buffer_distance)\n        \n        # Convert back to array for plotting\n        buffered_contour = np.array(buffered_poly.exterior.coords)\n        # plt.plot(contour[:, 1], contour[:, 0], color='red', linewidth=1)\n        plt.plot(buffered_contour[:, 0], buffered_contour[:, 1], color='red', linestyle='--')\n\n    plt.subplot(1, 3, 3)\n    plt.imshow(pred_mask, cmap='gray')\n    plt.title(\"Predicted Mask\")\n    plt.axis('off')\n\n    plt.tight_layout()\n    plt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-04T08:49:09.266002Z","iopub.execute_input":"2025-11-04T08:49:09.266271Z","iopub.status.idle":"2025-11-04T08:49:09.286108Z","shell.execute_reply.started":"2025-11-04T08:49:09.266251Z","shell.execute_reply":"2025-11-04T08:49:09.284909Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"authentic_images_dir = \"/kaggle/input/recodai-luc-scientific-image-forgery-detection/train_images/authentic\"\nforged_images_dir = \"/kaggle/input/recodai-luc-scientific-image-forgery-detection/train_images/forged\"\nforged_images_mask_dir = \"/kaggle/input/recodai-luc-scientific-image-forgery-detection/train_masks\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-04T08:49:09.288772Z","iopub.execute_input":"2025-11-04T08:49:09.289153Z","iopub.status.idle":"2025-11-04T08:49:09.30791Z","shell.execute_reply.started":"2025-11-04T08:49:09.289124Z","shell.execute_reply":"2025-11-04T08:49:09.306717Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"authentic_images_files = sorted(os.listdir(authentic_images_dir))\nforged_images_files = sorted(os.listdir(forged_images_dir))\nforged_images_mask_files = sorted(os.listdir(forged_images_mask_dir))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-04T08:49:09.308932Z","iopub.execute_input":"2025-11-04T08:49:09.309257Z","iopub.status.idle":"2025-11-04T08:49:09.42836Z","shell.execute_reply.started":"2025-11-04T08:49:09.309229Z","shell.execute_reply":"2025-11-04T08:49:09.427481Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Checking out the how the model learned on training data","metadata":{}},{"cell_type":"code","source":"for i in range(25):\n    image = load_image(f\"{forged_images_dir}/{forged_images_files[i]}\")\n    mask = load_mask(f\"{forged_images_mask_dir}/{forged_images_mask_files[i]}\")\n    \n    preocessed_image, preocessed_mask = apply_model_pre_processor(image, mask)\n    \n    with torch.no_grad():\n        pred_mask = model(preocessed_image)\n    \n    \n    prob_mask = F.softmax(pred_mask, dim=1)\n    binary_mask = torch.argmax(prob_mask, dim=1).unsqueeze(0)\n    \n    resized_mask = F.interpolate(binary_mask.float(), size=(image.shape[0], image.shape[1]), mode='nearest')\n    \n    resized_pred_mask = resized_mask.squeeze().cpu().numpy()\n    \n    plot_sample(image, mask, resized_pred_mask)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-04T08:49:09.42914Z","iopub.execute_input":"2025-11-04T08:49:09.429423Z","iopub.status.idle":"2025-11-04T08:50:17.334511Z","shell.execute_reply.started":"2025-11-04T08:49:09.4294Z","shell.execute_reply":"2025-11-04T08:50:17.333461Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}