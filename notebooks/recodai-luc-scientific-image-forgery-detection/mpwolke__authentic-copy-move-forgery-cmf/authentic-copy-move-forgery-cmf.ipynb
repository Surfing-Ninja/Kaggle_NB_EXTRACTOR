{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":113558,"databundleVersionId":14174843,"sourceType":"competition"}],"dockerImageVersionId":31153,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"Published on October 23, 2025. By Prata, Marília (mpwolke)","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n\nfrom matplotlib.gridspec import GridSpec\n\n#Two lines Required to Plot Plotly\nimport plotly.io as pio\npio.renderers.default = 'iframe'\n\nimport plotly.graph_objs as go\nimport plotly.offline as py\nimport plotly.express as px\n\n#Ignore warnings\nimport warnings\nwarnings.filterwarnings('ignore')\n\nfrom glob import glob\nfrom tqdm.notebook import tqdm\nimport os\nimport shutil\n\nimport tensorflow as tf\n\nimport cv2\nimport matplotlib.pyplot as plt\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-10-23T22:13:09.812155Z","iopub.execute_input":"2025-10-23T22:13:09.812464Z","iopub.status.idle":"2025-10-23T22:13:35.110638Z","shell.execute_reply.started":"2025-10-23T22:13:09.812437Z","shell.execute_reply":"2025-10-23T22:13:35.109015Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"_kg_hide-input":true,"_kg_hide-output":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## CMF (Copy Move Forgery) Kaggle Birds\n\n![](https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcQ2v_-Q4tpBmlU4W6YcLAHZ3hLmYWe9mYgSVQ&s)https://jivp-eurasipjournals.springeropen.com/articles/10.1186/s13640-019-0469-9","metadata":{}},{"cell_type":"markdown","source":"## Competition Citation\n\n@misc{recodai-luc-scientific-image-forgery-detection,\n    author = {João Phillipe Cardenuto and Daniel Moreira and Anderson Rocha and Sohier Dane and Addison Howard and Ashley Oldacre},\n    \n    title = {Recod.ai/LUC - Scientific Image Forgery Detection},\n    year = {2025},\n    \n    howpublished = {\\url{https://kaggle.com/competitions/recodai-luc-scientific-image-forgery-detection}},\n    note = {Kaggle}\n}","metadata":{}},{"cell_type":"markdown","source":"## About Competition\n\n\"Scientific images are central to published research, but not all of them are honest. Help protect science from fraudulent image manipulation by building models that can detect and segment copy-move forgeries in biomedical images.\"\n\nhttps://www.kaggle.com/competitions/recodai-luc-scientific-image-forgery-detection\n\n### Copy-move forgery detection technique\n\n A robust copy-move forgery detection technique based on discrete cosine transform and cellular automata\n\nAuthors: Gulnawaz Gani, Fasel Qadir\n\n\"**Copy Move Forgery (CMF)** is a type of digital image forgery in which an image region is copied and pasted to another location within the same image with malicious intent to misrepresent its meaning. To prevent misinterpretation of an image content, several **Copy Move Forgery Detection (CMFD)** methods have been proposed in the past. However, the existing methods show limited robustness on images altered with post-processing attacks such as noise addition, compression, blurring etc.\"\n\n\"In this paper, the authors proposed a robust method for detecting copy-move forgeries under different post-processing attacks. They used **Discrete Cosine Transform (DCT)** to extract features from each block. Next, Cellular Automata is employed to construct feature vectors based on the sign information of the DCT coefficients.\"\n\n\"Finally, feature vectors are matched using the kd-tree based nearest-neighbor searching method to find the duplicated areas in the image. Experimental results show that the proposed method performs exceptionally well relative to the other state-of-the-art methods from the literature even when an image is heavily affected by the post-processing attacks, in particular, JPEG compression and additive white Gaussian noise.\"\n\n\"Furthermore, experiments confirm the robustness of the proposed method against the range of combined attacks.\"\n\nhttps://www.sciencedirect.com/science/article/abs/pii/S2214212619307343","metadata":{}},{"cell_type":"markdown","source":"## Load sample_submission","metadata":{}},{"cell_type":"code","source":"sub = pd.read_csv('/kaggle/input/recodai-luc-scientific-image-forgery-detection/sample_submission.csv')\nsub.tail()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-23T22:16:42.456681Z","iopub.execute_input":"2025-10-23T22:16:42.457377Z","iopub.status.idle":"2025-10-23T22:16:42.5012Z","shell.execute_reply.started":"2025-10-23T22:16:42.457351Z","shell.execute_reply":"2025-10-23T22:16:42.499597Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Test images (only one image)","metadata":{}},{"cell_type":"code","source":"from PIL import Image\n\nimgs_dir = '../input/recodai-luc-scientific-image-forgery-detection/test_images/'\nImage.open(imgs_dir + '45.png')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-23T22:41:59.09214Z","iopub.execute_input":"2025-10-23T22:41:59.093244Z","iopub.status.idle":"2025-10-23T22:41:59.226539Z","shell.execute_reply.started":"2025-10-23T22:41:59.093191Z","shell.execute_reply":"2025-10-23T22:41:59.225541Z"},"_kg_hide-input":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import cv2\nimport glob","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-23T22:51:51.562227Z","iopub.execute_input":"2025-10-23T22:51:51.562515Z","iopub.status.idle":"2025-10-23T22:51:51.566318Z","shell.execute_reply.started":"2025-10-23T22:51:51.562496Z","shell.execute_reply":"2025-10-23T22:51:51.565611Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Authentic train images \n\nOnly with size 512.","metadata":{}},{"cell_type":"code","source":"def plotImages(tools,directory):\n    print(tools)\n    multipleImages = glob.glob(directory)\n    plt.rcParams['figure.figsize'] = (8, 8) #Original is 15,15. Since we have 18 veggies I decreased the size\n    plt.subplots_adjust(wspace=0, hspace=0)\n    i_ = 0\n    for l in multipleImages[:25]: #Original is 25\n        im = cv2.imread(l)\n        im = cv2.resize(im, (512, 512)) \n        plt.subplot(5, 5, i_+1) #.set_title(l)\n        plt.imshow(cv2.cvtColor(im, cv2.COLOR_BGR2RGB)); plt.axis('off')\n        i_ += 1\n\nplotImages(\"Authentic train images\",\"../input/recodai-luc-scientific-image-forgery-detection/train_images/authentic/**\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-23T22:56:36.725485Z","iopub.execute_input":"2025-10-23T22:56:36.725853Z","iopub.status.idle":"2025-10-23T22:56:39.846487Z","shell.execute_reply.started":"2025-10-23T22:56:36.725828Z","shell.execute_reply":"2025-10-23T22:56:39.84549Z"},"_kg_hide-input":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Forged train_images","metadata":{}},{"cell_type":"code","source":"def plotImages(tools,directory):\n    print(tools)\n    multipleImages = glob.glob(directory)\n    plt.rcParams['figure.figsize'] = (8, 8) #Original is 15,15. Since we have 18 veggies I decreased the size\n    plt.subplots_adjust(wspace=0, hspace=0)\n    i_ = 0\n    for l in multipleImages[:25]: #Original is 25\n        im = cv2.imread(l)\n        im = cv2.resize(im, (256, 256)) \n        plt.subplot(5, 5, i_+1) #.set_title(l)\n        plt.imshow(cv2.cvtColor(im, cv2.COLOR_BGR2RGB)); plt.axis('off')\n        i_ += 1\n\nplotImages(\"Forged train images\",\"../input/recodai-luc-scientific-image-forgery-detection/train_images/forged/**\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-23T22:53:55.113765Z","iopub.execute_input":"2025-10-23T22:53:55.114026Z","iopub.status.idle":"2025-10-23T22:53:56.922728Z","shell.execute_reply.started":"2025-10-23T22:53:55.114008Z","shell.execute_reply":"2025-10-23T22:53:56.921762Z"},"_kg_hide-input":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_img_dir = \"/kaggle/input/recodai-luc-scientific-image-forgery-detection/train_images/forged/\"\ntrain_mask_dir = \"/kaggle/input/recodai-luc-scientific-image-forgery-detection/train_masks/\"\n\ntrain_img_list = sorted(os.listdir(train_img_dir))\ntrain_mask_list =  sorted(os.listdir(train_mask_dir))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-23T23:54:09.356728Z","iopub.execute_input":"2025-10-23T23:54:09.357017Z","iopub.status.idle":"2025-10-23T23:54:09.367632Z","shell.execute_reply.started":"2025-10-23T23:54:09.356999Z","shell.execute_reply":"2025-10-23T23:54:09.366923Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"batch_size = 2","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-23T23:54:25.981193Z","iopub.execute_input":"2025-10-23T23:54:25.981469Z","iopub.status.idle":"2025-10-23T23:54:25.985217Z","shell.execute_reply.started":"2025-10-23T23:54:25.981451Z","shell.execute_reply":"2025-10-23T23:54:25.98442Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def load_img(img_dir , img_list):\n    \n    images = []\n    for i,image_name in enumerate(img_list):\n        \n        if(image_name.split('.')[1]=='npy', 'png'):\n            # if the file is numpy array\n            \n            image = np.load(img_dir + image_name)\n            images.append(image)\n        \n    images = np.array(images)\n        \n    return (images)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-23T23:55:09.347477Z","iopub.execute_input":"2025-10-23T23:55:09.347853Z","iopub.status.idle":"2025-10-23T23:55:09.352599Z","shell.execute_reply.started":"2025-10-23T23:55:09.347838Z","shell.execute_reply":"2025-10-23T23:55:09.35171Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#I forget who made that since I tried many Notebooks.\n\ndef imageLoader(img_dir , img_list , mask_dir , mask_list , batch_size):\n    \n    L = len(img_list)\n    \n    while True:\n        \n        batch_start = 0\n        batch_end = batch_size\n        \n        while batch_start < L:\n            \n            limit = min(batch_end , L)\n            \n            X = load_img(img_dir , img_list[batch_start:limit]) # load image\n            Y = load_img(mask_dir , mask_list[batch_start:limit]) # load mask\n            \n            yield(X,Y) # yields images - a tuple with 2 numpy arrays with batch_size samples\n            \n            batch_start += batch_size\n            batch_end += batch_size","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-23T23:55:40.486496Z","iopub.execute_input":"2025-10-23T23:55:40.486802Z","iopub.status.idle":"2025-10-23T23:55:40.491906Z","shell.execute_reply.started":"2025-10-23T23:55:40.486785Z","shell.execute_reply":"2025-10-23T23:55:40.491081Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_img_datagen = imageLoader(train_img_dir, train_img_list,  train_mask_dir, train_mask_list, batch_size)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-23T23:56:02.095377Z","iopub.execute_input":"2025-10-23T23:56:02.095659Z","iopub.status.idle":"2025-10-23T23:56:02.099748Z","shell.execute_reply.started":"2025-10-23T23:56:02.095638Z","shell.execute_reply":"2025-10-23T23:56:02.098875Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Cannot load file containing pickled data when allow_pickle=False","metadata":{}},{"cell_type":"code","source":"img, msk = train_img_datagen.__next__()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-23T23:56:16.35417Z","iopub.execute_input":"2025-10-23T23:56:16.354428Z","iopub.status.idle":"2025-10-23T23:56:16.385855Z","shell.execute_reply.started":"2025-10-23T23:56:16.354411Z","shell.execute_reply":"2025-10-23T23:56:16.384606Z"},"_kg_hide-output":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"img.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-23T23:57:35.901226Z","iopub.execute_input":"2025-10-23T23:57:35.902277Z","iopub.status.idle":"2025-10-23T23:57:35.907723Z","shell.execute_reply.started":"2025-10-23T23:57:35.902246Z","shell.execute_reply":"2025-10-23T23:57:35.906541Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"msk.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-23T23:57:22.04716Z","iopub.execute_input":"2025-10-23T23:57:22.047446Z","iopub.status.idle":"2025-10-23T23:57:22.052867Z","shell.execute_reply.started":"2025-10-23T23:57:22.047426Z","shell.execute_reply":"2025-10-23T23:57:22.051825Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import random\n\nimg_num = random.randint(0,img.shape[0]-1)\ntest_img=img[img_num]\n#test_mask=msk[img_num]\n#test_mask=np.argmax(test_mask, axis=3)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-23T23:59:34.672069Z","iopub.execute_input":"2025-10-23T23:59:34.672307Z","iopub.status.idle":"2025-10-23T23:59:34.67642Z","shell.execute_reply.started":"2025-10-23T23:59:34.67229Z","shell.execute_reply":"2025-10-23T23:59:34.675638Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install imgaug","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-24T00:04:30.156375Z","iopub.execute_input":"2025-10-24T00:04:30.157027Z","iopub.status.idle":"2025-10-24T00:04:39.795791Z","shell.execute_reply.started":"2025-10-24T00:04:30.157003Z","shell.execute_reply":"2025-10-24T00:04:39.794908Z"},"_kg_hide-output":true,"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# By Jocelyn Dumlao\n# the numpy bool deprecation warning in imgaug\nimport numpy as np\nnp.bool = bool\n\n# Define image dimensions\nIMG_WIDTH = 256\nIMG_HEIGHT = 256","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-24T00:05:15.17429Z","iopub.execute_input":"2025-10-24T00:05:15.174619Z","iopub.status.idle":"2025-10-24T00:05:15.179746Z","shell.execute_reply.started":"2025-10-24T00:05:15.17459Z","shell.execute_reply":"2025-10-24T00:05:15.178559Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#By Jocelyn Dumlao https://www.kaggle.com/code/jocelyndumlao/crosswalk-segmentation-u-net-model/notebook\n\ndef preprocess_image(image_path, mask_path, img_width=IMG_WIDTH, img_height=IMG_HEIGHT):\n    \"\"\"\n    Loads, preprocesses, and resizes an image and its corresponding mask.\n    \"\"\"\n    img = cv2.imread(image_path)\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n\n    # Resize images and masks\n    img = cv2.resize(img, (img_width, img_height))\n    mask = cv2.resize(mask, (img_width, img_height), interpolation=cv2.INTER_NEAREST) #Keep mask values discrete\n\n    # Normalize image pixels to be between 0 and 1\n    img = img / 255.0\n    mask = mask / 255.0  #Normalize the mask to 0 or 1 values\n\n    #Expand mask dimensions to be (IMG_WIDTH, IMG_HEIGHT, 1)\n    mask = np.expand_dims(mask, axis=-1)\n    return img, mask","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-24T00:05:49.407946Z","iopub.execute_input":"2025-10-24T00:05:49.408342Z","iopub.status.idle":"2025-10-24T00:05:49.418029Z","shell.execute_reply.started":"2025-10-24T00:05:49.408315Z","shell.execute_reply":"2025-10-24T00:05:49.416193Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#By Jocelyn Dumlao https://www.kaggle.com/code/jocelyndumlao/crosswalk-segmentation-u-net-model/notebook\n\n# data augmentation using imgaug\ntry:\n    import imgaug.augmenters as iaa\n    HAS_IMGAUG = True  # Flag to indicate imgaug is installed\nexcept ImportError:\n    print(\"imgaug is not installed. Data augmentation will be limited.\")\n    HAS_IMGAUG = False\n\ndef augment_data(image, mask):\n    \"\"\"Applies data augmentation to an image and its corresponding mask.\"\"\"\n    if HAS_IMGAUG:\n        # Define a sequence of augmentations\n        seq = iaa.Sequential([\n            iaa.Fliplr(0.5), # horizontal flips\n            iaa.Sometimes(0.5,\n                iaa.GaussianBlur(sigma=(0, 0.5))\n            ),\n            iaa.Sometimes(0.5,\n                iaa.Affine(\n                    scale={\"x\": (0.8, 1.2), \"y\": (0.8, 1.2)},\n                    translate_percent={\"x\": (-0.1, 0.1), \"y\": (-0.1, 0.1)},\n                    rotate=(-25, 25),\n                    shear=(-8, 8)\n                )\n            ),\n            iaa.Sometimes(0.5,\n                iaa.SomeOf((0, 5), [\n                    iaa.AdditiveGaussianNoise(scale=0.05*255),\n                    iaa.Add((-10, 10)),\n                    iaa.Multiply((0.5, 1.5)),\n                    iaa.ContrastNormalization((0.5, 2.0)),\n                    iaa.Grayscale(alpha=(0.0, 1.0))\n                ], random_order=True)\n            )\n        ])\n\n        # Convert image and mask to correct format for imgaug\n        image = np.uint8(image * 255)  # Scale back to 0-255\n        mask = np.uint8(mask * 255)  # Scale back to 0-255\n\n        # Apply augmentations. imgaug expects images with 3 channels for color augmentations\n        # If mask only has one channel, convert it to 3 channels\n        if mask.shape[-1] == 1:\n            mask = np.repeat(mask, 3, axis=-1)  # Convert single-channel mask to 3 channels\n\n        augmented_image = seq(image=image)\n        augmented_mask = seq(image=mask)\n\n        # Convert back to original format\n        augmented_image = augmented_image / 255.0\n        augmented_mask = augmented_mask[:,:,0] / 255.0 #Keep the first channel of the augmented mask and scale between 0 and 1\n        augmented_mask = np.expand_dims(augmented_mask, axis=-1)\n\n        return augmented_image, augmented_mask\n    else:\n        # If imgaug is not installed, return the original image and mask\n        return image, mask","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-24T00:06:35.721317Z","iopub.execute_input":"2025-10-24T00:06:35.721556Z","iopub.status.idle":"2025-10-24T00:06:36.076988Z","shell.execute_reply.started":"2025-10-24T00:06:35.721543Z","shell.execute_reply":"2025-10-24T00:06:36.075863Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#By Jocelyn Dumlao https://www.kaggle.com/code/jocelyndumlao/crosswalk-segmentation-u-net-model/notebook\n\n# Create a function to generate the dataset\ndef data_generator(image_paths, mask_paths, batch_size=32, augment=True):\n    \"\"\"\n    Generates batches of training data.\n    \"\"\"\n    num_samples = len(image_paths)\n    while True:\n        # Shuffle the data at the beginning of each epoch\n        combined_list = list(zip(image_paths, mask_paths))\n        random.shuffle(combined_list)\n        image_paths, mask_paths = zip(*combined_list)  # Unzip back into separate lists\n\n        for offset in range(0, num_samples, batch_size):\n            batch_images = []\n            batch_masks = []\n            batch_image_paths = image_paths[offset:offset + batch_size]\n            batch_mask_paths = mask_paths[offset:offset + batch_size]\n\n            for image_path, mask_path in zip(batch_image_paths, batch_mask_paths):\n                img, mask = preprocess_image(image_path, mask_path)\n                if augment:\n                    img, mask = augment_data(img, mask)\n\n                batch_images.append(img)\n                batch_masks.append(mask)\n\n            # Convert to numpy arrays\n            batch_images = np.array(batch_images, dtype=np.float32)  # Ensure float32 for images\n            batch_masks = np.array(batch_masks, dtype=np.float32)    # Ensure float32 for masks\n\n            yield batch_images, batch_masks","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-24T00:07:07.285565Z","iopub.execute_input":"2025-10-24T00:07:07.286955Z","iopub.status.idle":"2025-10-24T00:07:07.294369Z","shell.execute_reply.started":"2025-10-24T00:07:07.286925Z","shell.execute_reply":"2025-10-24T00:07:07.292932Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#By Jocelyn Dumlao https://www.kaggle.com/code/jocelyndumlao/crosswalk-segmentation-u-net-model/notebook\n\n# Define the base path to the dataset\nbase_path = '/kaggle/input/recodai-luc-scientific-image-forgery-detection/'\n\n# Define the environmental conditions\nconditions = ['authentic', 'forged']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-24T00:11:27.082633Z","iopub.execute_input":"2025-10-24T00:11:27.082979Z","iopub.status.idle":"2025-10-24T00:11:27.087897Z","shell.execute_reply.started":"2025-10-24T00:11:27.08296Z","shell.execute_reply":"2025-10-24T00:11:27.087035Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#By Jocelyn Dumlao https://www.kaggle.com/code/jocelyndumlao/crosswalk-segmentation-u-net-model/notebook\n\n# Create dictionaries to store image and mask paths for each condition\nimage_paths = {}\nmask_paths = {}\n\nfor condition in conditions:\n    image_paths[condition] = sorted(glob.glob(os.path.join(base_path, 'train_images', condition,'*.png')))\n    mask_paths = sorted(glob.glob(os.path.join(base_path,'train_masks', '*.npy')))\n\n# Verify the number of images and masks for each condition\nfor condition in conditions:\n    print(f\"Condition: {condition}\")\n    print(f\"  Number of images: {len(image_paths[condition])}\")\n    print(f\"  Number of masks: {len(mask_paths)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-24T00:14:47.196829Z","iopub.execute_input":"2025-10-24T00:14:47.197112Z","iopub.status.idle":"2025-10-24T00:14:47.223907Z","shell.execute_reply.started":"2025-10-24T00:14:47.197091Z","shell.execute_reply":"2025-10-24T00:14:47.222909Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Last attempt to display the npy masks.","metadata":{}},{"cell_type":"code","source":"input_dir = \"../input/recodai-luc-scientific-image-forgery-detection/train_images/forged/\"\nmask_dir = \"../input/recodai-luc-scientific-image-forgery-detection/train_masks\"\n#img_size = (160, 160)\n#num_classes = 3\nbatch_size = 16","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-24T01:00:44.673348Z","iopub.execute_input":"2025-10-24T01:00:44.673647Z","iopub.status.idle":"2025-10-24T01:00:44.678117Z","shell.execute_reply.started":"2025-10-24T01:00:44.673625Z","shell.execute_reply":"2025-10-24T01:00:44.677011Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# By Ammar Alhaj Ali https://www.kaggle.com/ammarnassanalhajali/image-segmentation-with-a-u-net-and-keras\n\ninput_img_paths = sorted(\n    [\n        os.path.join(input_dir, fname)\n        for fname in os.listdir(input_dir)\n        if fname.endswith(\".png\")\n    ]\n)\nmask_img_paths = sorted(\n    [\n        os.path.join(target_dir, fname)\n        for fname in os.listdir(mask_dir)\n        if fname.endswith(\".npy\") and not fname.startswith(\".\")\n    ]\n)\n\nprint(\"Number of samples:\", len(input_img_paths))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-24T01:01:14.702234Z","iopub.execute_input":"2025-10-24T01:01:14.702503Z","iopub.status.idle":"2025-10-24T01:01:14.71575Z","shell.execute_reply.started":"2025-10-24T01:01:14.702485Z","shell.execute_reply":"2025-10-24T01:01:14.714984Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#By Ammar Alhaj Ali https://www.kaggle.com/ammarnassanalhajali/image-segmentation-with-a-u-net-and-keras\n\nimport matplotlib.image as mpimg\n\n#Display sample of Image Dataset\ni = 4\nfigure, ax = plt.subplots(nrows=1,ncols=2,figsize=(8,8))\nax.ravel()[0].imshow(mpimg.imread(input_img_paths[i]))\nax.ravel()[0].set_title(\"Original image\")\nax.ravel()[0].set_axis_off()\n#ax.ravel()[1].imshow(mpimg.imread(target_img_paths[i]))\nimage_mask = np.load('../input/recodai-luc-scientific-image-forgery-detection/train_masks/10070.npy') #mpimg.imread\nax.ravel()[1].set_title(\"Mask\")\nax.ravel()[1].set_axis_off()\n#ax.ravel()[2].imshow(PIL.ImageOps.autocontrast(load_img(target_img_paths[i])))\n#ax.ravel()[2].set_title(\"Contrast of mask\")\n#ax.ravel()[2].set_axis_off()\nplt.tight_layout()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-24T01:10:00.195765Z","iopub.execute_input":"2025-10-24T01:10:00.196035Z","iopub.status.idle":"2025-10-24T01:10:00.481218Z","shell.execute_reply.started":"2025-10-24T01:10:00.196018Z","shell.execute_reply":"2025-10-24T01:10:00.480505Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## After 3h:18m, Not a single npy mask was displayed.","metadata":{}},{"cell_type":"markdown","source":"#Acknowledgements:\n\nJocelyn Dumlao https://www.kaggle.com/code/jocelyndumlao/crosswalk-segmentation-u-net-model/notebook\n\nAmmar Alhaj Ali https://www.kaggle.com/ammarnassanalhajali/image-segmentation-with-a-u-net-and-keras","metadata":{}}]}