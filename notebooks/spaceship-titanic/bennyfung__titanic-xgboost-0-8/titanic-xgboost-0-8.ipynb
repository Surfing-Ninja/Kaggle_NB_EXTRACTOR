{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2023-09-10T09:40:05.715175Z","iopub.execute_input":"2023-09-10T09:40:05.716216Z","iopub.status.idle":"2023-09-10T09:40:05.726641Z","shell.execute_reply.started":"2023-09-10T09:40:05.716164Z","shell.execute_reply":"2023-09-10T09:40:05.725258Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\nâ€‹\n<div style=\"color:#D81F26;\n           display:fill;\n           border-style: solid;\n           border-color:#C1C1C1;\n           font-size:14px;\n           font-family:Calibri;\n           background-color:#373737;\">\n<h2 style=\"text-align: center;\n           padding: 10px;\n           color:#FFFFFF;\">\n======= Spaceship Titanic =======\n</h2>\n</div>","metadata":{"papermill":{"duration":0.01324,"end_time":"2022-09-30T02:18:05.313426","exception":false,"start_time":"2022-09-30T02:18:05.300186","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"<img src=\"https://i.redd.it/starship-titanic-v0-onkq3aj6w1ja1.jpg?s=6bb053590c16f2d518b7958a5d5ce7c3861d95df\" length=400 width=400>","metadata":{}},{"cell_type":"markdown","source":"# 1. About this notebook","metadata":{}},{"cell_type":"markdown","source":"This notebooks is to show if AutoML can reach an performing model with less time and effort for model selection and hyperparameter tuning.  The most best-performing model algorithm with the most effective hyperparameters is tuned by the autoML algorithm automatically.   ","metadata":{}},{"cell_type":"markdown","source":"## 1.1. Summary\n\n* Assess the balance of the target label distribution to determine if oversampling is required during the modeling process.\n* Identify features that exhibit high cardinality.\n* Employ feature engineering techniques for Cabin, Age, and Total Spending.\n* Address missing values based on feature types by Imputation.\n* Utilize Correlation Analysis to examine interdependent features.\n* Manage outliers using the IRQ method and frequency distribution analysis.\n* Apply encoding to categorical features and scaling to numerical features.\n* Employ the AutoML algorithm FLAML for modeling, which automatically selects the optimal model and hyperparameters.","metadata":{}},{"cell_type":"markdown","source":"## 1.2 Data Attributes\n* <b>PassengerId</b> - A unique Id for each passenger. Each Id takes the form gggg_pp where gggg indicates a group the passenger is travelling with and pp is their number within the group. People in a group are often family members, but not always. <i>[Text]</i>\n* <b>HomePlanet</b> - The planet the passenger departed from, typically their planet of permanent residence. <i>[Categorical]</i>\n* <b>CryoSleep</b> - Indicates whether the passenger elected to be put into suspended animation for the duration of the voyage. Passengers in cryosleep are confined to their cabins. <i>[Boolean]</i>\n* <b>Cabin</b> - The cabin number where the passenger is staying. Takes the form deck/num/side, where side can be either P for Port or S for Starboard. <i>[Categorical]</i>\n* <b>Destination</b> - The planet the passenger will be debarking to. <i>[Categorical]</i>\n* <b>Age</b> - The age of the passenger. <i>[Numerical]</i>\n* <b>VIP</b> - Whether the passenger has paid for special VIP service during the voyage.\nRoomService, FoodCourt, ShoppingMall, Spa, VRDeck - Amount the passenger has billed at each of the Spaceship Titanic's many luxury amenities. <i>[Boolean]</i>\n* <b>RoomService, FoodCourt, ShoppingMall, Spa, VRDeck</b> - Amount the passenger has billed at each of the Spaceship Titanic's many luxury amenities. <i>[Numerical]</i>\n* <b>Name</b> - The first and last names of the passenger. <i>[Text]</i>\n* <b>Transported</b> - Whether the passenger was transported to another dimension. This is the target, the column you are trying to predict. <i>[Boolean]</i>\n","metadata":{}},{"cell_type":"markdown","source":"# 2. Setup","metadata":{}},{"cell_type":"markdown","source":"## 2.1. Package and Installation ","metadata":{}},{"cell_type":"code","source":"# Install  the FLAML package\n!pip install -q flaml\nfrom flaml import AutoML\nfrom xgboost import XGBClassifier\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom matplotlib.ticker import FuncFormatter\n%matplotlib inline\nimport seaborn as sns\nsns.set(style='darkgrid', font_scale=2)\n\nimport random\nfrom scipy.stats import uniform, randint\n\n# Suppress any warnings\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Sklearn\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import metrics\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split, RandomizedSearchCV, StratifiedKFold, GridSearchCV\nfrom sklearn import metrics\n\n# Category Encoders\nimport category_encoders as encoders\n","metadata":{"papermill":{"duration":1.807358,"end_time":"2022-09-30T02:18:07.134313","exception":false,"start_time":"2022-09-30T02:18:05.326955","status":"completed"},"tags":[],"_kg_hide-output":true,"execution":{"iopub.status.busy":"2023-09-10T09:40:05.731759Z","iopub.execute_input":"2023-09-10T09:40:05.732539Z","iopub.status.idle":"2023-09-10T09:40:19.410358Z","shell.execute_reply.started":"2023-09-10T09:40:05.732501Z","shell.execute_reply":"2023-09-10T09:40:19.408774Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 2.2. Load the Data","metadata":{}},{"cell_type":"code","source":"# Load the train and test data sets\n\ndf_train = pd.read_csv('../input/spaceship-titanic/train.csv')\ndf_test = pd.read_csv('../input/spaceship-titanic/test.csv')\ndf_test_index = df_test['PassengerId'].copy()\n\nprint('Size of data set - tran dataset : {}, test dataset : {}'.format(df_train.shape, df_test.shape))","metadata":{"papermill":{"duration":0.141978,"end_time":"2022-09-30T02:18:07.319563","exception":false,"start_time":"2022-09-30T02:18:07.177585","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-09-10T09:40:19.413325Z","iopub.execute_input":"2023-09-10T09:40:19.41385Z","iopub.status.idle":"2023-09-10T09:40:19.48381Z","shell.execute_reply.started":"2023-09-10T09:40:19.413802Z","shell.execute_reply":"2023-09-10T09:40:19.482514Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Preview the first 5 rows of the train and test data sets\n\nprint(df_train.head(5))\nprint('=' * 50)\nprint(df_test.head(5))","metadata":{"execution":{"iopub.status.busy":"2023-09-10T09:40:19.485487Z","iopub.execute_input":"2023-09-10T09:40:19.485882Z","iopub.status.idle":"2023-09-10T09:40:19.511948Z","shell.execute_reply.started":"2023-09-10T09:40:19.485847Z","shell.execute_reply":"2023-09-10T09:40:19.510632Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 3. Exploratory Data Analysis","metadata":{"papermill":{"duration":0.014125,"end_time":"2022-09-30T02:18:07.377279","exception":false,"start_time":"2022-09-30T02:18:07.363154","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# List of columns in the data set\ndf_train.info()","metadata":{"papermill":{"duration":0.054381,"end_time":"2022-09-30T02:18:07.490655","exception":false,"start_time":"2022-09-30T02:18:07.436274","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-09-10T09:40:19.515229Z","iopub.execute_input":"2023-09-10T09:40:19.515645Z","iopub.status.idle":"2023-09-10T09:40:19.540517Z","shell.execute_reply.started":"2023-09-10T09:40:19.515609Z","shell.execute_reply":"2023-09-10T09:40:19.539093Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 3.1. Distribution of Target Label\n\n<div style=\" background-color:#4b371c;text-align:left; padding: 13px 13px; border-radius: 8px; color: white; font-size: 16px\">\nTo check if the distribution of target feature (i.e. Transported) is balanced.  If it is not the case, we will do oversampling in the modelling process.  \n</div>","metadata":{}},{"cell_type":"code","source":"# check whether the data set is balanced\n\ndef auto_fmt (pct_value):\n    return '{:.0f}\\n({:.2f}%)'.format(df_train['Transported'].value_counts().sum()*pct_value/100,pct_value) \n\ndf_transported_count = df_train['Transported'].value_counts().rename_axis('Transported').reset_index(name='Counts')\n\nfig = plt.gcf()\nfig.set_size_inches(7,7)\nplt.pie(x=df_transported_count['Counts'], labels=df_transported_count['Transported'], autopct=auto_fmt, textprops={'fontsize': 18})\nplt.title('Distribution of Target Label (i.e. Transported)',  fontsize = 20)","metadata":{"execution":{"iopub.status.busy":"2023-09-10T09:40:19.542199Z","iopub.execute_input":"2023-09-10T09:40:19.542841Z","iopub.status.idle":"2023-09-10T09:40:19.713314Z","shell.execute_reply.started":"2023-09-10T09:40:19.542799Z","shell.execute_reply":"2023-09-10T09:40:19.711772Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\" background-color:#b22222;text-align:left; padding: 13px 13px; border-radius: 8px; color: white; font-size: 16px\">\nObservation: the distribution of target feature between Tranported and Non-transported target classes is in equal proportion.  There is no oversampling for this data set. \n</div>\n","metadata":{}},{"cell_type":"markdown","source":"# 3.2. Remove the Data Columns with Unique Identifiers or with Many Unique Values\n<div style=\" background-color:#4b371c;text-align:left; padding: 13px 13px; border-radius: 8px; color: white; font-size: 16px\">\nFeatures in predictive model are used to estimate an asscoiated likelihood of a target (i.e. Transported).  In other words, features shall have relevance to the target label.  If the features are with high Cabin or with many unique values, using them as features in predictve model can result in overfitting and non-predictive to new intances which the trained model has not seen prior.\n</div>","metadata":{}},{"cell_type":"code","source":"# To count no. of distinct values for each columns.\n\ncategorical_cols = ['HomePlanet','Destination','Cabin'] # Excluding Boolean features\n\n\ndf_distinct_counts = df_train[categorical_cols].nunique()/df_train[categorical_cols].count()\ndf_distinct_counts = df_distinct_counts.rename_axis('Feature').reset_index(name='Count')\n\n# Use the bar chart to display % of distinct values for each categorical feature\n\n# set the size of the chart\nplt.figure(figsize=(8, 6))\n\n# create a bar chart using Seaborn\nsns.barplot(x='Feature', y='Count', data=df_distinct_counts)\n\n# add x and y axes with labels\nplt.xlabel('Categorical Feature',  fontsize = 16)\nplt.ylabel('Counts of Distinct Value',  fontsize = 16)\nplt.title('% of Distinct Value for each Categorical Feature',  fontsize = 20)\n\n# create a function to format the y-axis as percentages\ndef to_percent(y, position):\n    return '{:.0%}'.format(y)\n\n# set the y-axis ticks as percentages\nformatter = FuncFormatter(to_percent)\nplt.gca().yaxis.set_major_formatter(formatter)\n\n# Set the font size of x-axis labels\nplt.xticks(fontsize=14)\nplt.yticks(fontsize=14)\n\n# display the chart\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-09-10T09:40:19.71532Z","iopub.execute_input":"2023-09-10T09:40:19.716164Z","iopub.status.idle":"2023-09-10T09:40:19.981653Z","shell.execute_reply.started":"2023-09-10T09:40:19.716117Z","shell.execute_reply":"2023-09-10T09:40:19.980656Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\n<div style=\" background-color:#b22222;text-align:left; padding: 13px 13px; border-radius: 8px; color: white; font-size: 16px\">\nObservation: From the bar chart above, the feature \"Cabin\" has high cardinality. We will further check if insight can be generated by feature engineering. \n</div>\n","metadata":{}},{"cell_type":"code","source":"# List out value count statistics for the feature \"Cabin\"\ndf_train[\"Cabin\"].value_counts()","metadata":{"execution":{"iopub.status.busy":"2023-09-10T09:40:19.983221Z","iopub.execute_input":"2023-09-10T09:40:19.983857Z","iopub.status.idle":"2023-09-10T09:40:19.998246Z","shell.execute_reply.started":"2023-09-10T09:40:19.983818Z","shell.execute_reply":"2023-09-10T09:40:19.996956Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\" background-color:#b22222;text-align:left; padding: 13px 13px; border-radius: 8px; color: white; font-size: 16px\">\nObservation: The first and last character in the Cabin may have predictive power to the target lablel. Let's keep this label for more feature engineering. \n</div>\n","metadata":{}},{"cell_type":"markdown","source":"# 3.3. Feature Engineering for Cabin\n<div style=\" background-color:#4b371c;text-align:left; padding: 13px 13px; border-radius: 8px; color: white; font-size: 16px\">\nFeature engineering is the process of creating new features or transforming existing features in a dataset to improve the performance of machine learning models. It involves selecting, extracting, or creating relevant features that can enhance the representation and predictive power of the data.\n</div>","metadata":{}},{"cell_type":"code","source":"# Cabin - The cabin number where the passenger is staying. Takes the form deck/num/side, where side can be either P for Port or S for Starboard.\ndf_train[['Deck','Num','Side']] = df_train.Cabin.str.split('/',expand=True)\ndf_test[['Deck','Num','Side']] = df_test.Cabin.str.split('/',expand=True)","metadata":{"execution":{"iopub.status.busy":"2023-09-10T09:40:19.9999Z","iopub.execute_input":"2023-09-10T09:40:20.000557Z","iopub.status.idle":"2023-09-10T09:40:20.043738Z","shell.execute_reply.started":"2023-09-10T09:40:20.00052Z","shell.execute_reply":"2023-09-10T09:40:20.042687Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Count of the distinct occurence for each new features of Deck, Num and Side\nprint('Distinct Count of Deck : {}'.format(df_train['Deck'].nunique()))\nprint('Distinct Count of Num : {}'.format(df_train['Num'].nunique()))\nprint('Distinct Count of Side : {}'.format(df_train['Side'].nunique()))","metadata":{"execution":{"iopub.status.busy":"2023-09-10T09:40:20.045114Z","iopub.execute_input":"2023-09-10T09:40:20.04567Z","iopub.status.idle":"2023-09-10T09:40:20.058505Z","shell.execute_reply.started":"2023-09-10T09:40:20.045633Z","shell.execute_reply":"2023-09-10T09:40:20.057189Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\" background-color:#b22222;text-align:left; padding: 13px 13px; border-radius: 8px; color: white; font-size: 16px\">\nObservation: The new features of Deck and Side may be useful for the prediction.  We will check the distribution of new features over the target labe of Transported. \n</div>\n","metadata":{}},{"cell_type":"code","source":"# Set the size of the chart\nplt.figure(figsize=(6, 5))\nplt.legend(fontsize=13)\n\n# Set the chart title, font size of the title, x-axis, and y-axis labels\nplt.title('Deck by Transported', fontsize=20)\nplt.xlabel('Deck', fontsize=16)\nplt.ylabel('Passanger Count', fontsize=16)\n\nplt.tick_params(axis='x', which='major', labelsize=14)\nplt.tick_params(axis='y', which='major', labelsize=14)\n\n# sns.countplot(df_train.Deck,hue=df_train.Transported)\nsns.countplot(df_train.Deck,hue=df_train.Transported)\n\n# Create a legend and set the font size\n# legend = plt.legend(title='Transported', labels=df_train.Transported, fontsize=20)\n# plt.setp(legend.get_texts(), fontsize='16')","metadata":{"execution":{"iopub.status.busy":"2023-09-10T09:40:20.063873Z","iopub.execute_input":"2023-09-10T09:40:20.064851Z","iopub.status.idle":"2023-09-10T09:40:20.463807Z","shell.execute_reply.started":"2023-09-10T09:40:20.064806Z","shell.execute_reply":"2023-09-10T09:40:20.462728Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Set the size of the chart\nplt.figure(figsize=(6, 5))\nplt.legend(fontsize=13)\n\n# Set the chart title, font size of the title, x-axis, and y-axis labels\nplt.title('Side by Transported', fontsize=20)\nplt.xlabel('Side', fontsize=16)\nplt.ylabel('Passanger Count', fontsize=16)\n\nplt.tick_params(axis='x', which='major', labelsize=14)\nplt.tick_params(axis='y', which='major', labelsize=14)\n\nsns.countplot(df_train.Side,hue=df_train.Transported)\n\n# Create a legend and set the font size\n# legend = plt.legend(title='Transported', labels=df_train.Transported, fontsize=20)\n# plt.setp(legend.get_texts(), fontsize='16')","metadata":{"execution":{"iopub.status.busy":"2023-09-10T09:40:20.465165Z","iopub.execute_input":"2023-09-10T09:40:20.466051Z","iopub.status.idle":"2023-09-10T09:40:20.743013Z","shell.execute_reply.started":"2023-09-10T09:40:20.466015Z","shell.execute_reply":"2023-09-10T09:40:20.741938Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\" background-color:#b22222;text-align:left; padding: 13px 13px; border-radius: 8px; color: white; font-size: 16px\">\nObservation: When closely examining the distribution of feature values by the target label, certain feature values exhibit discriminative capabilities towards the target label.\n</div>","metadata":{}},{"cell_type":"markdown","source":"# 3.4. Missing Value Replacement\n<div style=\" background-color:#4b371c;text-align:left; padding: 13px 13px; border-radius: 8px; color: white; font-size: 16px\">\nMissing value handling in machine learning refers to the process of addressing and managing data instances where one or more feature values are missing or unknown. Handling missing values is crucial because most machine learning algorithms cannot directly handle missing data\n</div>","metadata":{}},{"cell_type":"code","source":"# To count the no. of rows with missing values for each columns\n# print('No. of Rows with Missing Values by Columns (Training):')\n# print(df_train.isna().sum())\n\ndrop_cols = ['Num', 'Transported', 'Cabin', 'PassengerId', 'Name']\n\nplt.figure(figsize=(10, 6))\n\n# No. of missing values by features\ndf_train_missing = df_train.drop(columns = drop_cols).isna().sum()\n\n# Create a bar chart\ndf_train_missing.plot.bar()\n\n# Set the chart title and axis labels\nplt.title('Missing Values Count in Train Data Set', fontsize=20)\nplt.xlabel('Columns', fontsize=16)\nplt.ylabel('Count', fontsize=16)\n\nplt.tick_params(axis='x', which='major', labelsize=14)\nplt.tick_params(axis='y', which='major', labelsize=14)\n\n# Display the chart\nplt.show()\n\nprint('='*50)\n# print('No. of Rows with Missing Values by Columns (Validation):')\n# print(df_test.isna().sum())\n\nplt.figure(figsize=(10, 6))\n\n# No. of missing values by features\ndf_test_missing = df_train.drop(columns = drop_cols).isna().sum()\n\n# Create a bar chart\ndf_test_missing.plot.bar()\n\n# Set the chart title and axis labels\nplt.title('Missing Values Count', fontsize=20)\nplt.xlabel('Columns', fontsize=16)\nplt.ylabel('Count', fontsize=16)\n\nplt.tick_params(axis='x', which='major', labelsize=14)\nplt.tick_params(axis='y', which='major', labelsize=14)\n\n# Display the chart\nplt.show()","metadata":{"papermill":{"duration":0.035985,"end_time":"2022-09-30T02:18:07.712563","exception":false,"start_time":"2022-09-30T02:18:07.676578","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-09-10T09:40:20.744813Z","iopub.execute_input":"2023-09-10T09:40:20.745156Z","iopub.status.idle":"2023-09-10T09:40:21.421985Z","shell.execute_reply.started":"2023-09-10T09:40:20.745125Z","shell.execute_reply":"2023-09-10T09:40:21.420683Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\" background-color:#b22222;text-align:left; padding: 13px 13px; border-radius: 8px; color: white; font-size: 16px\">\nObservation: There are missing values present for each feature. To handle these missing values, we will employ different methods based on the nature of the missing value, the amount and pattern of missing values.\n</div>","metadata":{}},{"cell_type":"code","source":"df_train.set_index('PassengerId',inplace=True)\ndf_test.set_index('PassengerId',inplace=True)","metadata":{"papermill":{"duration":0.023717,"end_time":"2022-09-30T02:18:07.750862","exception":false,"start_time":"2022-09-30T02:18:07.727145","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-09-10T09:40:21.423383Z","iopub.execute_input":"2023-09-10T09:40:21.423717Z","iopub.status.idle":"2023-09-10T09:40:21.431361Z","shell.execute_reply.started":"2023-09-10T09:40:21.423672Z","shell.execute_reply":"2023-09-10T09:40:21.429982Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\" background-color:#006400;text-align:left; padding: 13px 13px; border-radius: 8px; color: white; font-size: 16px\">\nMissing Value Replacement - We will employ different methods for replacing missing values based on the type of feature. Specifically, for numerical features, we will utilize the mean and median as replacements, while for categorical features, we will use the mode.\n</div>","metadata":{"papermill":{"duration":0.01394,"end_time":"2022-09-30T02:18:07.779101","exception":false,"start_time":"2022-09-30T02:18:07.765161","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# df_train[['RoomService','FoodCourt','ShoppingMall','Spa','VRDeck']] = df_train[['RoomService','FoodCourt','ShoppingMall','Spa','VRDeck']].fillna(0)\n# df_test[['RoomService','FoodCourt','ShoppingMall','Spa','VRDeck']] = df_test[['RoomService','FoodCourt','ShoppingMall','Spa','VRDeck']].fillna(0)\n\ndf_train[['RoomService','FoodCourt','ShoppingMall','Spa','VRDeck']] \\\n    = df_train[['RoomService','FoodCourt','ShoppingMall','Spa','VRDeck']].fillna(df_train[['RoomService','FoodCourt','ShoppingMall','Spa','VRDeck']].median())\ndf_test[['RoomService','FoodCourt','ShoppingMall','Spa','VRDeck']] \\\n    = df_test[['RoomService','FoodCourt','ShoppingMall','Spa','VRDeck']].fillna(df_test[['RoomService','FoodCourt','ShoppingMall','Spa','VRDeck']].median())\n\n# df_train['Age'] =df_train['Age'].fillna(df_train['Age'].median())\n# df_test['Age'] =df_test['Age'].fillna(df_test['Age'].median())\n\ndf_train['Age'] =df_train['Age'].fillna(df_train['Age'].mean())\ndf_test['Age'] =df_test['Age'].fillna(df_test['Age'].mean())\n\ndf_train['VIP'] =df_train['VIP'].fillna(False)\ndf_test['VIP'] =df_test['VIP'].fillna(False)\n\n# df_train['HomePlanet'] =df_train['HomePlanet'].fillna('XXXXXX')\n# df_test['HomePlanet'] =df_test['HomePlanet'].fillna('XXXXXX')\n\ndf_train['HomePlanet'] =df_train['HomePlanet'].fillna(df_train['HomePlanet'].mode()[0])\ndf_test['HomePlanet'] =df_test['HomePlanet'].fillna(df_train['HomePlanet'].mode()[0])\n\n# df_train['Destination']=df_train['Destination'].fillna(\"XXXXXX\")\n# df_test['Destination']=df_test['Destination'].fillna(\"XXXXXX\")\n\ndf_train['Destination']=df_train['Destination'].fillna(df_train['Destination'].mode()[0])\ndf_test['Destination']=df_test['Destination'].fillna(df_train['Destination'].mode()[0])\n\ndf_train['CryoSleep'] =df_train['CryoSleep'].fillna(False)\ndf_test['CryoSleep'] =df_test['CryoSleep'].fillna(False)\n\n# df_train['Cabin'] =df_train['Cabin'].fillna('XXXXXX')\n# df_test['Cabin'] =df_test['Cabin'].fillna('XXXXXX')\n\ndf_train['Deck'] =df_train['Deck'].fillna(df_train['Deck'].mode()[0])\ndf_test['Deck'] =df_test['Deck'].fillna(df_train['Deck'].mode()[0])\n\ndf_train['Side'] =df_train['Side'].fillna(df_train['Side'].mode()[0])\ndf_test['Side'] =df_test['Side'].fillna(df_train['Side'].mode()[0])","metadata":{"papermill":{"duration":0.048567,"end_time":"2022-09-30T02:18:07.841969","exception":false,"start_time":"2022-09-30T02:18:07.793402","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-09-10T09:40:21.433196Z","iopub.execute_input":"2023-09-10T09:40:21.433541Z","iopub.status.idle":"2023-09-10T09:40:21.502188Z","shell.execute_reply.started":"2023-09-10T09:40:21.43351Z","shell.execute_reply":"2023-09-10T09:40:21.500777Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# To count the no. of rows with missing values for each columns\nprint('No. of Rows with Missing Values by Columns (Training):')\nprint(df_train.isna().sum())\nprint('No. of Rows with Missing Values by Columns (Testing):')\nprint(df_test.isna().sum())","metadata":{"execution":{"iopub.status.busy":"2023-09-10T09:40:21.504739Z","iopub.execute_input":"2023-09-10T09:40:21.505459Z","iopub.status.idle":"2023-09-10T09:40:21.530427Z","shell.execute_reply.started":"2023-09-10T09:40:21.505413Z","shell.execute_reply":"2023-09-10T09:40:21.529107Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\" background-color:#b22222;text-align:left; padding: 13px 13px; border-radius: 8px; color: white; font-size: 16px\">\nObservation: Missing values for key features required for modeling have been imputed.\n</div>","metadata":{}},{"cell_type":"markdown","source":"# 3.5. Feature Engineering for Total Spending and Age Groups\n<div style=\" background-color:#4b371c;text-align:left; padding: 13px 13px; border-radius: 8px; color: white; font-size: 16px\">\nFeature engineering is the process of creating new features or transforming existing features in a dataset to improve the performance of machine learning models. It involves selecting, extracting, or creating relevant features that can enhance the representation and predictive power of the data.\n</div>","metadata":{}},{"cell_type":"markdown","source":"<div style=\" background-color:#006400;text-align:left; padding: 13px 13px; border-radius: 8px; color: white; font-size: 16px\">\nTotal Spending from sum of Room Service, Foot Court, Shopping Mall, Spa and VR Deck\n</div>","metadata":{}},{"cell_type":"code","source":"df_train['total_spent']= df_train['RoomService']+ df_train['FoodCourt']+ df_train['ShoppingMall']+ df_train['Spa']+ df_train['VRDeck']\ndf_test['total_spent']=df_test['RoomService']+df_test['FoodCourt']+df_test['ShoppingMall']+df_test['Spa']+df_test['VRDeck']\n\nplt.figure(figsize=(10, 6))\n\n# Show histogram with bins of 25 using histplot\nsns.histplot(df_train['total_spent'], bins=25)\n\n# Set the chart title and axis labels\nplt.title('Histogram of Total Spending', fontsize = 20)\nplt.xlabel('Total Spending', fontsize=16)\nplt.ylabel('Frequency Count', fontsize=16)\n\n\nplt.tick_params(axis='x', which='major', labelsize=14)\nplt.tick_params(axis='y', which='major', labelsize=14)\n\n# Display the chart\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2023-09-10T09:40:21.531815Z","iopub.execute_input":"2023-09-10T09:40:21.532252Z","iopub.status.idle":"2023-09-10T09:40:21.912634Z","shell.execute_reply.started":"2023-09-10T09:40:21.532221Z","shell.execute_reply":"2023-09-10T09:40:21.911342Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\" background-color:#006400;text-align:left; padding: 13px 13px; border-radius: 8px; color: white; font-size: 16px\">\nTo convert the Age feature into discrete categories\n</div>","metadata":{}},{"cell_type":"code","source":"df_train['AgeGroup'] = 0\nfor i in range(6):\n    df_train.loc[(df_train.Age >= 10*i) & (df_train.Age < 10*(i + 1)), 'AgeGroup'] = i\n# Same for test data\ndf_test['AgeGroup'] = 0\nfor i in range(6):\n    df_test.loc[(df_test.Age >= 10*i) & (df_test.Age < 10*(i + 1)), 'AgeGroup'] = i","metadata":{"execution":{"iopub.status.busy":"2023-09-10T09:40:21.914358Z","iopub.execute_input":"2023-09-10T09:40:21.914768Z","iopub.status.idle":"2023-09-10T09:40:21.94009Z","shell.execute_reply.started":"2023-09-10T09:40:21.91472Z","shell.execute_reply":"2023-09-10T09:40:21.938719Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Set the size of the chart\nplt.figure(figsize=(10, 8))\nplt.legend(fontsize=13)\n\n# Set the chart title, font size of the title, x-axis, and y-axis labels\nplt.title('Age Group by Transported', fontsize=20)\nplt.xlabel('Age Group', fontsize=16)\nplt.ylabel('Passanger Count', fontsize=16)\n\nplt.tick_params(axis='x', which='major', labelsize=14)\nplt.tick_params(axis='y', which='major', labelsize=14)\n\nsns.countplot(df_train['AgeGroup'],hue=df_train.Transported)","metadata":{"execution":{"iopub.status.busy":"2023-09-10T09:40:21.941521Z","iopub.execute_input":"2023-09-10T09:40:21.942008Z","iopub.status.idle":"2023-09-10T09:40:22.324192Z","shell.execute_reply.started":"2023-09-10T09:40:21.941972Z","shell.execute_reply":"2023-09-10T09:40:22.322772Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 3.6. Coorelation Analysis\n<div style=\" background-color:#4b371c;text-align:left; padding: 13px 13px; border-radius: 8px; color: white; font-size: 16px\">\nCorrelation Analysis helps to determine the degree and direction of association between variables, providing insights into their linear dependence.\n</div>","metadata":{"papermill":{"duration":0.014074,"end_time":"2022-09-30T02:18:07.870682","exception":false,"start_time":"2022-09-30T02:18:07.856608","status":"completed"},"tags":[]}},{"cell_type":"code","source":"plt.figure(figsize=(15,15))\nsns.heatmap(df_train.corr(), annot=True, annot_kws={'fontsize': 16})\nplt.title('Correlation Analysis for Numerical Features')","metadata":{"papermill":{"duration":0.819419,"end_time":"2022-09-30T02:18:08.704446","exception":false,"start_time":"2022-09-30T02:18:07.885027","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-09-10T09:40:22.325859Z","iopub.execute_input":"2023-09-10T09:40:22.326264Z","iopub.status.idle":"2023-09-10T09:40:23.532014Z","shell.execute_reply.started":"2023-09-10T09:40:22.326229Z","shell.execute_reply":"2023-09-10T09:40:23.530763Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\" background-color:#b22222;text-align:left; padding: 13px 13px; border-radius: 8px; color: white; font-size: 16px\">\nObservation: Based on the correlation analysis conducted,the majority of variable pairs exhibit correlations within the range of +0.2 to -0.2. However, an exception is observed in the correlation between the variables \"Transported\" and \"CryoSleep,\" which demonstrates a correlation beyond this range. Nevertheless, it is to note that this correlation exhibits a moderate dependence between these two variables.\n</div>","metadata":{}},{"cell_type":"markdown","source":"# 3.7. Frequency Distribution for Categorical Features\n<div style=\" background-color:#4b371c;text-align:left; padding: 13px 13px; border-radius: 8px; color: white; font-size: 16px\">\nThe count chart of categorical features involves analyzing and visualizing the frequency distribution of each category within a categorical feature. It provides insights into the distribution and relative frequencies of different categories, allowing us to understand the composition of the data.\n</div>","metadata":{}},{"cell_type":"code","source":"categorical_cols = ['HomePlanet', 'Destination', 'VIP', 'Deck', 'Side', 'AgeGroup']\n\n# Count Chart for Categorical Features\nfig, axs = plt.subplots(4, 2, figsize=(16,24))\n\n# Set the font size of axis labels and tick labels\nfor ax in axs.flatten():\n    ax.tick_params(axis='both', which='both', labelsize=12)\n    # Set the size of y-label and x-label\n    ax.set_ylabel('Y-Label', fontsize=16)\n    ax.set_xlabel('X-Label', fontsize=16)\n         \nsns.countplot(df_train['HomePlanet'],hue=df_train.Transported, ax=axs[0][0])\nsns.countplot(df_train['Destination'],hue=df_train.Transported, ax=axs[0][1])\nsns.countplot(df_train['VIP'],hue=df_train.Transported, ax=axs[1][0])\nsns.countplot(df_train['Deck'],hue=df_train.Transported, ax=axs[1][1])\nsns.countplot(df_train['Side'],hue=df_train.Transported, ax=axs[2][0])\nsns.countplot(df_train['AgeGroup'],hue=df_train.Transported, ax=axs[2][1])\nsns.countplot(df_train['CryoSleep'],hue=df_train.Transported, ax=axs[3][0])\n\n\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2023-09-10T09:40:23.53362Z","iopub.execute_input":"2023-09-10T09:40:23.534034Z","iopub.status.idle":"2023-09-10T09:40:25.20868Z","shell.execute_reply.started":"2023-09-10T09:40:23.533998Z","shell.execute_reply":"2023-09-10T09:40:25.2071Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\" background-color:#b22222;text-align:left; padding: 13px 13px; border-radius: 8px; color: white; font-size: 16px\">\nObservation: Based on the distribution analysis, it appears that the features VIP and Side demonstrate lower discriminatory power towards the target label.\n</div>","metadata":{}},{"cell_type":"markdown","source":"# 3.8. Outlier Analysis and Histogram for Numerical Features\n<div style=\" background-color:#4b371c;text-align:left; padding: 13px 13px; border-radius: 8px; color: white; font-size: 16px\">\nHistogram distribution provides a visual representation of the distribution of a numerical feature. They help us understand the spread, central tendency, and shape of the data. By examining the histogram, we can identify patterns, outliers, and potential data issues, gaining insights into the data's characteristics.\n<br><br>\n    \nThe IRQ (Interquartile Range) method will be used for outlier handling in data analysis. It involves identifying and treating outliers based on the spread of the data as measured by the interquartile range. The interquartile range is a statistical measure that represents the range between the first quartile (25th percentile) and the third quartile (75th percentile) of a dataset. It captures the middle 50% of the data, excluding the most extreme values.\n</div>","metadata":{}},{"cell_type":"code","source":"# Set the IRQ method calculation\nnumerical_cols = ['RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck', 'total_spent']\nIRQ_dict = {}\n\nfor col in numerical_cols:\n        p75 = df_train[df_train[col] > 0][col].quantile(0.75)\n        p25 = df_train[df_train[col] > 0][col].quantile(0.25)\n        iqr = p75 - p25\n        upper_limit = p75 + (1.5 * iqr)\n        IRQ_dict[col] = upper_limit\n        print('===={} with Upper Limit {:6.1f}, P75 {:6.1f}, P25 {:6.1f}, {} Outlier Records ========'.format(col, upper_limit, p75, p25, df_train[df_train[col] > upper_limit]['Transported'].count()))\n#         df_train[col] = np.where (df_train[col] > upper_limit, upper_limit, df_train[col])\n        df_train[col] = df_train[col].apply(lambda x: upper_limit if x > upper_limit else x)\n        df_test[col] = df_test[col].apply(lambda x: upper_limit if x > upper_limit else x)\n","metadata":{"execution":{"iopub.status.busy":"2023-09-10T09:40:25.211032Z","iopub.execute_input":"2023-09-10T09:40:25.211965Z","iopub.status.idle":"2023-09-10T09:40:25.335634Z","shell.execute_reply.started":"2023-09-10T09:40:25.211912Z","shell.execute_reply":"2023-09-10T09:40:25.333041Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"numerical_cols = ['Age', 'RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck', 'total_spent']\n\n# Count Chart for Categorical Features\nfig, axs = plt.subplots(4, 2, figsize=(16,24))\n\n# Set the font size of axis labels and tick labels\nfor ax in axs.flatten():\n    ax.tick_params(axis='both', which='both', labelsize=12)\n    ax.set_ylabel('Count', fontsize=16)\n\nsubplot = sns.histplot(data=df_train, x='Age', bins=25, hue='Transported', ax=axs[0][0])     \nsubplot.set_xlabel('Age', fontsize=16)\n# subplot.set_title('Histogram for Age', fontsize=20)\n\nsubplot = sns.histplot(data=df_train, x='RoomService', bins=25, hue='Transported', ax=axs[0][1])     \nsubplot.set_xlabel('RoomService', fontsize=16)\n# subplot.set_title('Histogram for RoomService', fontsize=20)\n\nsubplot = sns.histplot(data=df_train, x='FoodCourt', bins=25, hue='Transported', ax=axs[1][0])     \nsubplot.set_xlabel('FoodCourt', fontsize=16)\n# subplot.set_title('Histogram for FoodCourt', fontsize=20)\n\nsubplot = sns.histplot(data=df_train, x='ShoppingMall', bins=25, hue='Transported', ax=axs[1][1])     \nsubplot.set_xlabel('ShoppingMall', fontsize=16)\n# subplot.set_title('Histogram for ShoppingMall', fontsize=20)\n\nsubplot = sns.histplot(data=df_train, x='Spa', bins=25, hue='Transported', ax=axs[2][0])     \nsubplot.set_xlabel('Spa', fontsize=16)\n# subplot.set_title('Histogram for Spa', fontsize=20)\n\nsubplot = sns.histplot(data=df_train, x='VRDeck', bins=25, hue='Transported', ax=axs[2][1])     \nsubplot.set_xlabel('VRDeck', fontsize=16)\n# subplot.set_title('Histogram for VRDeck', fontsize=20)\n\nsubplot = sns.histplot(data=df_train, x='total_spent', bins=25, hue='Transported', ax=axs[3][0])     \nsubplot.set_xlabel('total_spent', fontsize=16)\n# subplot.set_title('Histogram for total_spent', fontsize=20)\n\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2023-09-10T09:40:25.33799Z","iopub.execute_input":"2023-09-10T09:40:25.338579Z","iopub.status.idle":"2023-09-10T09:40:28.632897Z","shell.execute_reply.started":"2023-09-10T09:40:25.338501Z","shell.execute_reply":"2023-09-10T09:40:28.631579Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 3.9. CatBoostEncoding for Categorical Features\n<div style=\" background-color:#4b371c;text-align:left; padding: 13px 13px; border-radius: 8px; color: white; font-size: 16px\">\nCATBoostEncode, or CatBoostEncoder, is a categorical encoding technique specifically designed for the CatBoost algorithm. CatBoost is a gradient boosting algorithm that is known for its strong performance in handling categorical features. The CatBoostEncoder is a specialized encoding method that is compatible with the CatBoost algorithm and aims to effectively encode categorical variables for improved model performance.\n</div>","metadata":{"papermill":{"duration":0.023323,"end_time":"2022-09-30T02:18:55.101972","exception":false,"start_time":"2022-09-30T02:18:55.078649","status":"completed"},"tags":[]}},{"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\n\nimport category_encoders as encoders\nCATBoostENCODE = encoders.CatBoostEncoder()\n\ncategorical_cols = ['HomePlanet', 'Destination', 'VIP', 'Deck', 'Side', 'AgeGroup']\n\n# Use CatBoost to encode the categorical values\nencoder_train = CATBoostENCODE.fit_transform(df_train[categorical_cols], df_train['Transported'])\nencoded_df_train = pd.DataFrame(encoder_train)\nprint(encoded_df_train.head(5))\n\nencoder_test = CATBoostENCODE.transform(df_test[categorical_cols])\nencoded_df_test = pd.DataFrame(encoder_test)\nprint(encoded_df_test.head(5))\n\n","metadata":{"papermill":{"duration":0.11379,"end_time":"2022-09-30T02:18:55.239315","exception":false,"start_time":"2022-09-30T02:18:55.125525","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-09-10T09:40:28.634518Z","iopub.execute_input":"2023-09-10T09:40:28.634897Z","iopub.status.idle":"2023-09-10T09:40:28.763095Z","shell.execute_reply.started":"2023-09-10T09:40:28.634864Z","shell.execute_reply":"2023-09-10T09:40:28.761826Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 3.10. Robust Scaler\n<div style=\" background-color:#4b371c;text-align:left; padding: 13px 13px; border-radius: 8px; color: white; font-size: 16px\">\nThe RobustScaler is a data preprocessing technique available in the scikit-learn library in Python. It is used to scale numerical data in a robust manner, meaning it is less sensitive to the presence of outliers compared to other scaling methods like standardization or min-max scaling.\n</div>","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import RobustScaler\n\nnumerical_cols = ['Age', 'RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck', 'total_spent']\n\n# Create a RobustScaler object\nscaler = RobustScaler()\n\n# Extract the index\nindex = df_train.index\n\n# Fit the scaler to the data and transform it\nscaler_train = scaler.fit_transform(df_train[numerical_cols])\nscaler_df_train = pd.DataFrame(scaler_train, columns=numerical_cols)\n# Reassign the index to the scaled DataFrame\nscaler_df_train.index = index\nprint(scaler_df_train.head(5))\n\n# Extract the index\nindex = df_test.index\n\nscaler_test = scaler.transform(df_test[numerical_cols])\nscaler_df_test = pd.DataFrame(scaler_test, columns=numerical_cols)\n# Reassign the index to the scaled DataFrame\nscaler_df_test.index = index\nprint(scaler_df_test.head(5))","metadata":{"execution":{"iopub.status.busy":"2023-09-10T09:40:28.765055Z","iopub.execute_input":"2023-09-10T09:40:28.76542Z","iopub.status.idle":"2023-09-10T09:40:28.797666Z","shell.execute_reply.started":"2023-09-10T09:40:28.765386Z","shell.execute_reply":"2023-09-10T09:40:28.796466Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"drop_cols = categorical_cols + numerical_cols\n\ndf_train_2 = df_train.drop(columns=drop_cols).copy()\ndf_train_2 =pd.concat([df_train_2, encoded_df_train, scaler_df_train], axis=1)\n\n\ndf_test_2 = df_test.drop(columns=drop_cols).copy()\ndf_test_2 =pd.concat([df_test_2, encoded_df_test, scaler_df_test], axis=1)","metadata":{"execution":{"iopub.status.busy":"2023-09-10T09:40:28.799195Z","iopub.execute_input":"2023-09-10T09:40:28.799541Z","iopub.status.idle":"2023-09-10T09:40:28.820169Z","shell.execute_reply.started":"2023-09-10T09:40:28.799511Z","shell.execute_reply":"2023-09-10T09:40:28.819047Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 4. Modeling","metadata":{"papermill":{"duration":0.024892,"end_time":"2022-09-30T02:18:55.365782","exception":false,"start_time":"2022-09-30T02:18:55.34089","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"<div style=\" background-color:#006400;text-align:left; padding: 13px 13px; border-radius: 8px; color: white; font-size: 16px\">\nTo prepare the training data set\n</div>","metadata":{}},{"cell_type":"code","source":"# to drop categorical features with high cardinality and also the numerical feature \"Age\"\n\ndf_train_2= df_train_2.drop(['Num', 'Cabin', 'Name', 'AgeGroup'],axis=1)\ndf_test_2= df_test_2.drop(['Num', 'Cabin', 'Name', 'AgeGroup'],axis=1)\n\nprint(df_train_2.columns)\nprint(df_test_2.columns)","metadata":{"papermill":{"duration":0.040466,"end_time":"2022-09-30T02:18:55.430861","exception":false,"start_time":"2022-09-30T02:18:55.390395","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-09-10T09:40:28.822455Z","iopub.execute_input":"2023-09-10T09:40:28.822825Z","iopub.status.idle":"2023-09-10T09:40:28.837299Z","shell.execute_reply.started":"2023-09-10T09:40:28.822793Z","shell.execute_reply":"2023-09-10T09:40:28.836071Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train_2['Transported']=df_train_2['Transported'].replace({True:1,False:0})","metadata":{"papermill":{"duration":0.050721,"end_time":"2022-09-30T02:18:57.096076","exception":false,"start_time":"2022-09-30T02:18:57.045355","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-09-10T09:40:28.839153Z","iopub.execute_input":"2023-09-10T09:40:28.839485Z","iopub.status.idle":"2023-09-10T09:40:28.852212Z","shell.execute_reply.started":"2023-09-10T09:40:28.839454Z","shell.execute_reply":"2023-09-10T09:40:28.851138Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Convert the target label into Boolean feature\n\nX=df_train_2.drop('Transported',axis=1)\ny = df_train_2['Transported']\n\nX.columns","metadata":{"papermill":{"duration":0.047711,"end_time":"2022-09-30T02:18:57.180735","exception":false,"start_time":"2022-09-30T02:18:57.133024","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-09-10T09:40:28.858947Z","iopub.execute_input":"2023-09-10T09:40:28.859317Z","iopub.status.idle":"2023-09-10T09:40:28.871022Z","shell.execute_reply.started":"2023-09-10T09:40:28.859281Z","shell.execute_reply":"2023-09-10T09:40:28.869725Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\" background-color:#006400;text-align:left; padding: 13px 13px; border-radius: 8px; color: white; font-size: 16px\">\nBy splitting the dataset into separate training and test sets, we can train the model on the training set and evaluate its performance on the test set.\n</div>","metadata":{"papermill":{"duration":0.03676,"end_time":"2022-09-30T02:18:57.337112","exception":false,"start_time":"2022-09-30T02:18:57.300352","status":"completed"},"tags":[]}},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=0)","metadata":{"papermill":{"duration":0.050814,"end_time":"2022-09-30T02:18:57.42467","exception":false,"start_time":"2022-09-30T02:18:57.373856","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-09-10T09:40:28.872732Z","iopub.execute_input":"2023-09-10T09:40:28.87382Z","iopub.status.idle":"2023-09-10T09:40:28.884514Z","shell.execute_reply.started":"2023-09-10T09:40:28.873784Z","shell.execute_reply":"2023-09-10T09:40:28.88309Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 4.1. XGBoost\n","metadata":{"papermill":{"duration":0.039343,"end_time":"2022-09-30T02:18:57.500303","exception":false,"start_time":"2022-09-30T02:18:57.46096","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# Parameter Setup\np_folds = 3\np_iter = 100\np_estimators = 1000\np_learning_rate = 0.001\n\n# A parameter grid for XGBoost\nparams = {\n        'max_depth': randint(7, 12),\n        'gamma': uniform(0.0, 0.5),\n        'subsample': uniform(0.6, 1.0),\n        'colsample_bytree': uniform(0.6, 1.0),\n        'reg_alpha': uniform(0.0, 1.0),\n        'reg_lambda': uniform(0.0, 1.0),\n        'min_child_weight': randint(3, 7),\n        'scale_pos_weight': randint(1, 10)     \n        }","metadata":{"execution":{"iopub.status.busy":"2023-09-10T09:40:28.886525Z","iopub.execute_input":"2023-09-10T09:40:28.886868Z","iopub.status.idle":"2023-09-10T09:40:28.90237Z","shell.execute_reply.started":"2023-09-10T09:40:28.886837Z","shell.execute_reply":"2023-09-10T09:40:28.90113Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"xgb = XGBClassifier(learning_rate=p_learning_rate, n_estimators = p_estimators, objective='binary:logistic')","metadata":{"execution":{"iopub.status.busy":"2023-09-10T09:40:28.903928Z","iopub.execute_input":"2023-09-10T09:40:28.904329Z","iopub.status.idle":"2023-09-10T09:40:28.914027Z","shell.execute_reply.started":"2023-09-10T09:40:28.904295Z","shell.execute_reply":"2023-09-10T09:40:28.913045Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# folds = p_folds\n\n# skf = StratifiedKFold(n_splits=folds, shuffle = True, random_state = 1001)\n\nxg_model = RandomizedSearchCV(xgb, param_distributions=params, n_iter=p_iter, scoring='roc_auc', n_jobs=1, verbose=-1, random_state=1001 )\n\nxg_model.fit(X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2023-09-10T09:40:28.915209Z","iopub.execute_input":"2023-09-10T09:40:28.916001Z","iopub.status.idle":"2023-09-10T09:43:50.392266Z","shell.execute_reply.started":"2023-09-10T09:40:28.915863Z","shell.execute_reply":"2023-09-10T09:43:50.391097Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(xg_model.best_estimator_)\nprint(xg_model.best_params_)","metadata":{"execution":{"iopub.status.busy":"2023-09-10T09:43:50.393945Z","iopub.execute_input":"2023-09-10T09:43:50.394297Z","iopub.status.idle":"2023-09-10T09:43:50.406571Z","shell.execute_reply.started":"2023-09-10T09:43:50.394266Z","shell.execute_reply":"2023-09-10T09:43:50.405368Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Retrieve the best estimator and build the optimal model for analysis of Global Importance\nbest_xgb =XGBClassifier(**xg_model.best_estimator_.get_params())\nbest_xgb.fit(X_train,y_train)\naccuracy = best_xgb.score(X_test, y_test)\nprint('Accuracy of XGBoost : {}'.format(accuracy))","metadata":{"execution":{"iopub.status.busy":"2023-09-10T09:43:50.407915Z","iopub.execute_input":"2023-09-10T09:43:50.408401Z","iopub.status.idle":"2023-09-10T09:44:10.933922Z","shell.execute_reply.started":"2023-09-10T09:43:50.408367Z","shell.execute_reply":"2023-09-10T09:44:10.932449Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 4.2. Model Performance\n","metadata":{}},{"cell_type":"code","source":"p_train = best_xgb.predict(X_train)\np_test = best_xgb.predict(X_test)\np_train_proba = best_xgb.predict_proba(X_train)[:,1]\np_test_proba = best_xgb.predict_proba(X_test)[:,1]","metadata":{"execution":{"iopub.status.busy":"2023-09-10T09:44:10.935729Z","iopub.execute_input":"2023-09-10T09:44:10.936272Z","iopub.status.idle":"2023-09-10T09:44:12.31997Z","shell.execute_reply.started":"2023-09-10T09:44:10.936208Z","shell.execute_reply":"2023-09-10T09:44:12.318909Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predicted_test = pd.DataFrame(p_test)\npredicted_train = pd.DataFrame(p_train)\nprint('=============================================')\nprint('Scoring Metrics for XGBoost (Validation)')\nprint('=============================================')\nprint('Balanced Accuracy Score = {}'.format(metrics.balanced_accuracy_score(y_test, predicted_test)))\nprint('Accuracy Score = {}'.format(metrics.accuracy_score(y_test, predicted_test)))\nprint('Precision Score = {}'.format(metrics.precision_score(y_test, predicted_test)))\nprint('F1 Score = {}'.format(metrics.f1_score(y_test, predicted_test, labels=['0','1'])))\nprint('Recall Score = {}'.format(metrics.recall_score(y_test, predicted_test, labels=['0','1'])))\nprint('ROC AUC Score = {}'.format(metrics.roc_auc_score(y_test, predicted_test, labels=['0','1'])))\nprint('Confusion Matrix')\nprint('==================')\nprint(metrics.confusion_matrix(y_test, predicted_test))\nprint('==================')\nprint(metrics.classification_report(y_test, predicted_test, target_names=['0','1']))\nmetrics.ConfusionMatrixDisplay(metrics.confusion_matrix(y_test, predicted_test)).plot()\n\n\nprint('=============================================')\nprint('Scoring Metrics for XGBoost (Training)')\nprint('=============================================')\nprint('Balanced Accuracy Score = {}'.format(metrics.balanced_accuracy_score(y_train, predicted_train)))\nprint('Accuracy Score = {}'.format(metrics.accuracy_score(y_train, predicted_train)))\nprint('Precision Score = {}'.format(metrics.precision_score(y_train, predicted_train)))\nprint('F1 Score = {}'.format(metrics.f1_score(y_train, predicted_train)))\nprint('Recall Score = {}'.format(metrics.recall_score(y_train, predicted_train, labels=['0','1'])))\nprint('ROC AUC Score = {}'.format(metrics.roc_auc_score(y_train, predicted_train, labels=['0','1'])))\nprint('Confusion Matrix')\nprint('==================')\nprint(metrics.confusion_matrix(y_train, predicted_train))\nprint('==================')\nprint(metrics.classification_report(y_train, predicted_train, target_names=['0','1']))\nmetrics.ConfusionMatrixDisplay(metrics.confusion_matrix(y_train, predicted_train)).plot()\n\n\n\n\nprint('======= ROC Curve =======')\n\n\nfpr_train, tpr_train, _ = metrics.roc_curve(y_train, p_train_proba)\nfpr_test, tpr_test, _ = metrics.roc_curve(y_test, p_test_proba)\n\nroc_auc_train = metrics.roc_auc_score(y_train, predicted_train, labels=['0','1'])\nroc_auc_test = metrics.roc_auc_score(y_test, predicted_test, labels=['0','1'])\n\nfig, ax = plt.subplots(1, 1, figsize=(10, 10))    \nplt.plot(fpr_test, tpr_test, color='darkorange', label='ROC curve - Validation (area = %0.3f)' % roc_auc_test)\nplt.plot(fpr_train, tpr_train, color='darkblue', label='ROC curve - Training (area = %0.3f)' % roc_auc_train)\nplt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n# plt.xlim([0.0, 1.0])\n# plt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('ROC Curve')\nplt.legend(loc=\"lower right\")\n\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-09-10T09:44:12.321341Z","iopub.execute_input":"2023-09-10T09:44:12.321688Z","iopub.status.idle":"2023-09-10T09:44:13.209827Z","shell.execute_reply.started":"2023-09-10T09:44:12.321657Z","shell.execute_reply":"2023-09-10T09:44:13.208739Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 4.3. Submission","metadata":{"papermill":{"duration":0.037584,"end_time":"2022-09-30T02:22:43.574639","exception":false,"start_time":"2022-09-30T02:22:43.537055","status":"completed"},"tags":[]}},{"cell_type":"code","source":"y_pred = best_xgb.predict(df_test_2)\n\nsub=pd.DataFrame({'Transported':y_pred.astype(bool)})\nsub = pd.concat([df_test_index, sub], axis=1)\nsub.head()","metadata":{"papermill":{"duration":0.060763,"end_time":"2022-09-30T02:22:43.672245","exception":false,"start_time":"2022-09-30T02:22:43.611482","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-09-10T09:44:13.21129Z","iopub.execute_input":"2023-09-10T09:44:13.211663Z","iopub.status.idle":"2023-09-10T09:44:13.566954Z","shell.execute_reply.started":"2023-09-10T09:44:13.211629Z","shell.execute_reply":"2023-09-10T09:44:13.565786Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub.to_csv('/kaggle/working/submission.csv',index=False)\nprint('Submission Done!')","metadata":{"papermill":{"duration":0.052388,"end_time":"2022-09-30T02:22:43.763423","exception":false,"start_time":"2022-09-30T02:22:43.711035","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-09-10T09:44:13.568753Z","iopub.execute_input":"2023-09-10T09:44:13.56923Z","iopub.status.idle":"2023-09-10T09:44:13.589382Z","shell.execute_reply.started":"2023-09-10T09:44:13.569186Z","shell.execute_reply":"2023-09-10T09:44:13.588395Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}