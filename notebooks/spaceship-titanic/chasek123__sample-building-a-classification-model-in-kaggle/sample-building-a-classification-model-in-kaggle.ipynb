{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<hr style=\"height:.9px;border:none;color:#333;background-color:#333;\" />\n<hr style=\"height:.9px;border:none;color:#333;background-color:#333;\" />\n\n<br><h1>Sample Notebook | Building a Classification Model in Kaggle</h1>\nChase Kusterer<br>\nFaculty of Analytics<br>\nHult International Business School<br><br><br>\n\n<hr style=\"height:.9px;border:none;color:#333;background-color:#333;\" />\n<hr style=\"height:.9px;border:none;color:#333;background-color:#333;\" />\n\n<br>\n<h2>Purpose of this Script</h2>\nThis script is designed to demonstrate how to develop a model in Kaggle.\n<br><br><br>\n<hr style=\"height:.9px;border:none;color:#333;background-color:#333;\" /><br>","metadata":{"papermill":{"duration":0.008656,"end_time":"2023-02-21T04:32:23.015311","exception":false,"start_time":"2023-02-21T04:32:23.006655","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"Below is a starter code that comes with Jupyter Notebook.","metadata":{"papermill":{"duration":0.00448,"end_time":"2023-02-21T04:32:23.024665","exception":false,"start_time":"2023-02-21T04:32:23.020185","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","papermill":{"duration":0.023977,"end_time":"2023-02-21T04:32:23.053296","exception":false,"start_time":"2023-02-21T04:32:23.029319","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<hr style=\"height:.9px;border:none;color:#333;background-color:#333;\" /><br><br>\nYou will need to import any additional libraries. It's also a good idea to get rid of the cell above once you're used to Jupyter Notebook in Kaggle.<br>","metadata":{"papermill":{"duration":0.004442,"end_time":"2023-02-21T04:32:23.062733","exception":false,"start_time":"2023-02-21T04:32:23.058291","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# modeling library\nimport sklearn.linear_model                          # linear modeling in scikit-learn\n\n# other model building tools\nfrom sklearn.model_selection import train_test_split # train-test split\nfrom sklearn.metrics import roc_auc_score            # auc score","metadata":{"papermill":{"duration":1.341598,"end_time":"2023-02-21T04:32:24.409041","exception":false,"start_time":"2023-02-21T04:32:23.067443","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<hr style=\"height:.9px;border:none;color:#333;background-color:#333;\" /><br><br>\nMake sure to tell Python the path to your training data. If you have no idea what a path is, look to the left and find and hover over <em>Data&nbsp;>&nbsp;Input&nbsp;>&nbsp;spaceship-titanic</em>. A button should appear allowing you to copy the path to your clipboard.<br>","metadata":{"papermill":{"duration":0.005058,"end_time":"2023-02-21T04:32:24.419616","exception":false,"start_time":"2023-02-21T04:32:24.414558","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# importing the training dataset\npath             = \"/kaggle/input/spaceship-titanic/\"\ntraining_dataset = \"train.csv\"\n\n\n# reading in the .csv file with pandas\ntitanic_train    = pd.read_csv(filepath_or_buffer = path + training_dataset)\n\n\n# checking basic info about the dataset\ntitanic_train.info(verbose = True)","metadata":{"papermill":{"duration":0.072113,"end_time":"2023-02-21T04:32:24.496482","exception":false,"start_time":"2023-02-21T04:32:24.424369","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<hr style=\"height:.9px;border:none;color:#333;background-color:#333;\" /><br>\nThe test set is also available. Notice that there is no data for Transported (y-variable) in the test set. This is intentional.<br>","metadata":{"papermill":{"duration":0.004648,"end_time":"2023-02-21T04:32:24.506027","exception":false,"start_time":"2023-02-21T04:32:24.501379","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# importing the training dataset\npath             = \"/kaggle/input/spaceship-titanic/\"\ntesting_dataset  = 'test.csv'\n\n# importing the testing dataset\ntitanic_test = pd.read_csv(filepath_or_buffer = path + testing_dataset)\n\n# checking basic info about the dataset\ntitanic_test.info(verbose = True)","metadata":{"papermill":{"duration":0.049335,"end_time":"2023-02-21T04:32:24.560334","exception":false,"start_time":"2023-02-21T04:32:24.510999","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<hr style=\"height:.9px;border:none;color:#333;background-color:#333;\" /><br>\nYou may want to join the datasets together before feature engineering. This will help make things more efficient.<br>","metadata":{}},{"cell_type":"code","source":"titanic_train['set'] = 'Training'\ntitanic_test ['set'] = 'Testing'\n\n# concatenating both datasets together for mv and feature engineering\ntitanic_df = titanic_train.append(other = titanic_test)\n\n# resetting index to avoid problems later in the code\ntitanic_df.reset_index(drop = False,\n                       inplace = True)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<hr style=\"height:.9px;border:none;color:#333;background-color:#333;\" /><br>\nLet's look at correlations to find an x-variable to model with.<br>","metadata":{"papermill":{"duration":0.005017,"end_time":"2023-02-21T04:32:24.570678","exception":false,"start_time":"2023-02-21T04:32:24.565661","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# instantiating a correlation matrix\ntitanic_corr = titanic_train.corr(method = 'pearson').round(decimals = 2)\n\n# transforming correlations to absolute values\ntitanic_corr.loc[ : , 'Transported' ].apply(func = abs).sort_values(ascending = False)","metadata":{"papermill":{"duration":0.037642,"end_time":"2023-02-21T04:32:24.613658","exception":false,"start_time":"2023-02-21T04:32:24.576016","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<hr style=\"height:.9px;border:none;color:#333;background-color:#333;\" /><br>\nSince training and testing sets have already been developed for us, we can simply select the X-features we want to model with and we're good to go.<br>","metadata":{"papermill":{"duration":0.00512,"end_time":"2023-02-21T04:32:24.624463","exception":false,"start_time":"2023-02-21T04:32:24.619343","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# imputing in missing values for RoomService\ntitanic_df[ 'RoomService' ].fillna(value = 0, inplace = True)\n\n# setting explanatory variable(s) with most correlated x-variable\nx_train = titanic_df[ ['RoomService'] ][ titanic_df['set'] == 'Training' ]\n\n# setting response variable\ny_train = titanic_df[ 'Transported' ][ titanic_df['set']   == 'Training' ]","metadata":{"papermill":{"duration":0.015991,"end_time":"2023-02-21T04:32:24.645791","exception":false,"start_time":"2023-02-21T04:32:24.6298","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<hr style=\"height:.9px;border:none;color:#333;background-color:#333;\" /><br>\nEven though there's already a testing set, it's a good idea to build one on the training data to assess model performance and stability qualities.<br>","metadata":{}},{"cell_type":"code","source":"# developing training and validation sets\nx_train_1, x_train_2, y_train_1, y_train_2 = train_test_split(\n            x_train,\n            y_train.astype(dtype = 'int'),\n            random_state = 123,\n            test_size    = 0.25,\n            stratify     = y_train)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<hr style=\"height:.9px;border:none;color:#333;background-color:#333;\" /><br>\nBelow is a Logistic Regression model using scikit-learn. Note that as you explore additional scikit-learn models, the only things that need to change are the model name and the model type.<br>","metadata":{"papermill":{"duration":0.005209,"end_time":"2023-02-21T04:32:24.656603","exception":false,"start_time":"2023-02-21T04:32:24.651394","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# picking a model name\nmodel_name = \"Logistic Regression\"\n\n\n# INSTANTIATING a model object - CHANGE THIS AS NEEDED\nmodel = sklearn.linear_model.LogisticRegression()\n\n\n# FITTING to the training data\nmodel_fit = model.fit(x_train_1, y_train_1)\n\n\n# PREDICTING on the response variable\nmodel_train_pred = model_fit.predict(x_train_1)\nmodel_valid_pred = model_fit.predict(x_train_2)\n\n\n# SCORING the results (accuracy)\nmodel_train_score = model.score(x_train_1, y_train_1).round(4) # training accuracy\nmodel_valid_score = model.score(x_train_2, y_train_2).round(4) # validation accuracy\n\n# SCORING the results (auc)\nmodel_train_auc = roc_auc_score(y_true  = y_train_1,\n                                y_score = model_train_pred).round(decimals = 4)\n\nmodel_valid_auc = roc_auc_score(y_true  = y_train_2,\n                                y_score = model_valid_pred).round(decimals = 4)\n\n# displaying results\nprint('Training Accuracy:  ', model_train_score)\nprint('Validation Accuracy:', model_valid_score)\nprint('Training AUC:       ', model_train_auc)\nprint('Validation AUC:     ', model_valid_auc)","metadata":{"papermill":{"duration":0.034158,"end_time":"2023-02-21T04:32:24.696287","exception":false,"start_time":"2023-02-21T04:32:24.662129","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<hr style=\"height:.9px;border:none;color:#333;background-color:#333;\" />\n<hr style=\"height:.9px;border:none;color:#333;background-color:#333;\" /><br>\n\n<h2>Creating and Submitting Predictions</h2>\nIn this competition, your results should be submitted as a .csv file. This file should contain exactly two columns:<br><br>\n\n1. Id (from the test set)\n2. SalePrice (predictions from your model)\n\n<br>\nThe following code with do exactly that. Notice that all we need to do is apply the same X-variables (x_data) to the .predict step to generate our predictions.","metadata":{"papermill":{"duration":0.005405,"end_time":"2023-02-21T04:32:24.707676","exception":false,"start_time":"2023-02-21T04:32:24.702271","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# setting x_test\nx_test  = titanic_df[ ['RoomService'] ][ titanic_df['set'] == 'Testing' ]\n\n# PREDICTING on new data\nmodel_pred = model.predict(x_test)\n\n# checking results\nmodel_pred","metadata":{"papermill":{"duration":0.019818,"end_time":"2023-02-21T04:32:24.733143","exception":false,"start_time":"2023-02-21T04:32:24.713325","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<hr style=\"height:.9px;border:none;color:#333;background-color:#333;\" /><br>\nFrom here, we simply create a DataFrame with the original passenger ids (&nbsp;<em>PassengerId</em>&nbsp;) and the predicted values from the model (&nbsp;<em>Transported</em>&nbsp;).<br>","metadata":{"papermill":{"duration":0.005513,"end_time":"2023-02-21T04:32:24.744601","exception":false,"start_time":"2023-02-21T04:32:24.739088","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# saving predictions with their respective Ids from the test set\npredictions = pd.DataFrame(data = { 'PassengerId' : titanic_test['PassengerId'],\n                                    'Transported' : model_pred.astype(bool)               } )\n\n# checking the results\npredictions.head(n = 5)","metadata":{"papermill":{"duration":0.025754,"end_time":"2023-02-21T04:32:24.776225","exception":false,"start_time":"2023-02-21T04:32:24.750471","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<hr style=\"height:.9px;border:none;color:#333;background-color:#333;\" /><br>\nFinally, we save the DataFrame as a .csv file and we're ready to submit. This file will be available in the <em>/kaggle/working</em> directory.","metadata":{"papermill":{"duration":0.005849,"end_time":"2023-02-21T04:32:24.788295","exception":false,"start_time":"2023-02-21T04:32:24.782446","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# sending predictions to .csv file\npredictions.to_csv(path_or_buf = 'submission.csv',\n                   index = False)","metadata":{"papermill":{"duration":0.021386,"end_time":"2023-02-21T04:32:24.815839","exception":false,"start_time":"2023-02-21T04:32:24.794453","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<br>\n\n~~~\n\n  _    _                            _____          _ _             _ \n | |  | |                          / ____|        | (_)           | |\n | |__| | __ _ _ __  _ __  _   _  | |     ___   __| |_ _ __   __ _| |\n |  __  |/ _` | '_ \\| '_ \\| | | | | |    / _ \\ / _` | | '_ \\ / _` | |\n | |  | | (_| | |_) | |_) | |_| | | |___| (_) | (_| | | | | | (_| |_|\n |_|  |_|\\__,_| .__/| .__/ \\__, |  \\_____\\___/ \\__,_|_|_| |_|\\__, (_)\n              | |   | |     __/ |                             __/ |  \n              |_|   |_|    |___/                             |___/   \n\n~~~\n","metadata":{"papermill":{"duration":0.006064,"end_time":"2023-02-21T04:32:24.828411","exception":false,"start_time":"2023-02-21T04:32:24.822347","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"<br>","metadata":{"papermill":{"duration":0.005897,"end_time":"2023-02-21T04:32:24.840559","exception":false,"start_time":"2023-02-21T04:32:24.834662","status":"completed"},"tags":[]}}]}