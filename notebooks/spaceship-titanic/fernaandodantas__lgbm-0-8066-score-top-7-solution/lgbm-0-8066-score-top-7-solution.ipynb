{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":34377,"databundleVersionId":3220602,"sourceType":"competition"}],"dockerImageVersionId":30646,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **Libraries**","metadata":{}},{"cell_type":"code","source":"#Space titanic competition 0.80664 Score\n\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split,GridSearchCV,cross_val_score,StratifiedKFold\nimport xgboost as xgb\nimport category_encoders as ce\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.metrics import accuracy_score, roc_auc_score, precision_score, recall_score,f1_score, confusion_matrix\nfrom category_encoders import TargetEncoder\nfrom sklearn.impute import SimpleImputer,KNNImputer\nfrom lightgbm import LGBMClassifier\n\nimport warnings\n\nwarnings.filterwarnings(\"ignore\")","metadata":{"execution":{"iopub.status.busy":"2024-02-27T23:53:26.620319Z","iopub.execute_input":"2024-02-27T23:53:26.62086Z","iopub.status.idle":"2024-02-27T23:53:26.634217Z","shell.execute_reply.started":"2024-02-27T23:53:26.620816Z","shell.execute_reply":"2024-02-27T23:53:26.633115Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Let’s Start**\n","metadata":{}},{"cell_type":"markdown","source":"As you can see, after I loaded the dataset, I removed both the “Passenger Id” and “Name” columns. They are not going to provide any useful or important information to the prediction. Someone’s name or Id does not change the probability of being Transported.","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/spaceship-titanic/train.csv\")\n\n#After loading the dataset, I dropped the \"PassengerId\" and the \"Name\" column.\n\n#But why? Knowing a passengers name or Id will not provide any usefull information to the model.\n\n#Someone named \"James\" or with a certain Id number will not have a greater or lower chance of surviving.\n\n#So, I just removed both columns.\n\ndf.drop(columns=[\"PassengerId\",\"Name\"],inplace=True)","metadata":{"execution":{"iopub.status.busy":"2024-02-27T23:53:26.636377Z","iopub.execute_input":"2024-02-27T23:53:26.636702Z","iopub.status.idle":"2024-02-27T23:53:26.67437Z","shell.execute_reply.started":"2024-02-27T23:53:26.636674Z","shell.execute_reply":"2024-02-27T23:53:26.673442Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now, we are going to discuss a fundamental step I came across after trying to improve my score a thousand times. This step relies on exploring the “Cabin” column. Notice that the rows on the “Cabin” column follow a specific pattern. Something like this: “A/5/S”, “C/1/S”, “F/7/P”. And I decided to investigate it. So, to make things simple I split the rows of the “Cabin” into three columns based on both slashes (”/”) of the rows. For example, the “A/5/S” row would be transformed into three new columns: The first one is named “cabin_code” referring to the character behind the first slash (A). The second one named “id_cabin” refers to the character behind the second slash (5). The third one named “cabin_sector” refers to the character after the second slash (S). And we end up with three new columns.","metadata":{}},{"cell_type":"code","source":"#Splitting\n\ndf[[\"cabin_code\",\"id_cabin\",\"cabin_sector\"]] = df[\"Cabin\"].str.split(\"/\", n=2, expand=True)\n\ndf.head(4)","metadata":{"execution":{"iopub.status.busy":"2024-02-27T23:53:26.675771Z","iopub.execute_input":"2024-02-27T23:53:26.67608Z","iopub.status.idle":"2024-02-27T23:53:26.716186Z","shell.execute_reply.started":"2024-02-27T23:53:26.676053Z","shell.execute_reply":"2024-02-27T23:53:26.715009Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"First of all, I noticed that “cabin_code” only has 8 different characters which means that the cabins are, somehow, divided into 8 sections.","metadata":{}},{"cell_type":"code","source":"cabinss = df.cabin_code.value_counts(1).sort_index()\ncabinss","metadata":{"execution":{"iopub.status.busy":"2024-02-27T23:53:26.719156Z","iopub.execute_input":"2024-02-27T23:53:26.719897Z","iopub.status.idle":"2024-02-27T23:53:26.732637Z","shell.execute_reply.started":"2024-02-27T23:53:26.719853Z","shell.execute_reply":"2024-02-27T23:53:26.731501Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Also, I asked myself if passengers from a specific section had a higher chance of being transported or if this statement was not true. With the plot below we can conclude that passengers from the B and C sections have a greater chance of surviving and passengers from the E section have a lower chance of surviving.","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(12, 4.5))\n_= sns.countplot(data=df, x=\"cabin_code\", hue=\"Transported\", palette=\"coolwarm\")","metadata":{"execution":{"iopub.status.busy":"2024-02-27T23:53:26.734378Z","iopub.execute_input":"2024-02-27T23:53:26.734806Z","iopub.status.idle":"2024-02-27T23:53:27.071458Z","shell.execute_reply.started":"2024-02-27T23:53:26.734767Z","shell.execute_reply":"2024-02-27T23:53:27.07034Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"I did the same thing with the “cabin_sector” column and also noticed that there was a difference between the sectors. Passengers from the P sector have a lower chance of being transported, while in the S sector, the opposite happens.","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(10, 4.5))\n_= sns.countplot(data=df, x=\"cabin_sector\", hue=\"Transported\", palette=\"coolwarm\")","metadata":{"execution":{"iopub.status.busy":"2024-02-27T23:53:27.072966Z","iopub.execute_input":"2024-02-27T23:53:27.073424Z","iopub.status.idle":"2024-02-27T23:53:27.295914Z","shell.execute_reply.started":"2024-02-27T23:53:27.073383Z","shell.execute_reply":"2024-02-27T23:53:27.294755Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"This means that this exploration of the original “Cabin” column is worth it since new insights are being added to the model.\n\nNow, we can finally delete the “Cabin” column. It will not provide any useful information for the model anymore. We have already extracted everything useful from it.\n\nI also removed the “cabin_id” and the column that I had created. As I said before, the Id will not interfere with the model’s predictive ability.\n\nSo used: df.drop(columns=[“Cabin”,”id_cabin”], inplace=True) to drop both columns\n\nBefore splitting our data, the “Transported” column must be in a binary format. As you can see, I switched “True” for 1 and “False” for 0.\n\nBinary transformation: df[“Transported”] = df[“Transported”].map({True:1, False:0})\n\nI also removed every row that had missing values in the “cabin_code” column.","metadata":{}},{"cell_type":"code","source":"pop_id_cabin = df.pop(\"id_cabin\")\ndf.insert(3, 'id_cabin', pop_id_cabin)  # Insert column 'C' at the beginning\n\npop_id_cabin = df.pop(\"cabin_sector\")\ndf.insert(3, 'cabin_sector', pop_id_cabin)  # Insert column 'C' at the beg\n\npop_id_cabin = df.pop(\"cabin_code\")\ndf.insert(3, 'cabin_code', pop_id_cabin)  # Insert column 'C' at the beg","metadata":{"execution":{"iopub.status.busy":"2024-02-27T23:53:27.297955Z","iopub.execute_input":"2024-02-27T23:53:27.298803Z","iopub.status.idle":"2024-02-27T23:53:27.309774Z","shell.execute_reply.started":"2024-02-27T23:53:27.298761Z","shell.execute_reply":"2024-02-27T23:53:27.308497Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n#BINARY TRANSFORMATION\ndf[\"Transported\"] = df[\"Transported\"].map({True:1, False:0})\n\n\n#DROPPING COLUMNS\ndf.drop(columns=[\"Cabin\",\"id_cabin\"], inplace=True)\n\n\n#DROPPING NULLS\ndf.dropna(subset=[\"cabin_code\"], inplace=True)\n","metadata":{"execution":{"iopub.status.busy":"2024-02-27T23:53:27.310975Z","iopub.execute_input":"2024-02-27T23:53:27.311284Z","iopub.status.idle":"2024-02-27T23:53:27.330622Z","shell.execute_reply.started":"2024-02-27T23:53:27.311244Z","shell.execute_reply":"2024-02-27T23:53:27.329172Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now, we can finally split the data and proceed to develop our model.\n\nAfter splitting in train and test, I separated the test data into two categories: numerical and categorical. Why is that? We are going to perform different operations depending on the type of the variable. Categorical data must be encoded since most models are not able to understand categorical values and it must be converted to numerical values. Also, we are going to apply different techniques to fill the null values in our dataset, but I will talk more about it later on.","metadata":{}},{"cell_type":"markdown","source":"# **Splitting Data**","metadata":{}},{"cell_type":"code","source":"#Define X and y\n\nX = df.iloc[:,0:12]\ny = df[\"Transported\"]","metadata":{"execution":{"iopub.status.busy":"2024-02-27T23:53:27.334686Z","iopub.execute_input":"2024-02-27T23:53:27.335035Z","iopub.status.idle":"2024-02-27T23:53:27.345838Z","shell.execute_reply.started":"2024-02-27T23:53:27.335007Z","shell.execute_reply":"2024-02-27T23:53:27.344801Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Data splitting\n\nX_train, X_test, y_train, y_test = train_test_split(X,y,random_state=42,test_size=0.25)","metadata":{"execution":{"iopub.status.busy":"2024-02-27T23:53:27.3472Z","iopub.execute_input":"2024-02-27T23:53:27.347587Z","iopub.status.idle":"2024-02-27T23:53:27.359622Z","shell.execute_reply.started":"2024-02-27T23:53:27.347558Z","shell.execute_reply":"2024-02-27T23:53:27.358198Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Separate categorical and numerical\n\ncat_feat = np.array([coluna for coluna in X_train.columns if X_train[coluna].dtype.name == 'object'])\n\nnum_feat = np.array([coluna for coluna in X_train.columns if coluna not in cat_feat])","metadata":{"execution":{"iopub.status.busy":"2024-02-27T23:53:27.361067Z","iopub.execute_input":"2024-02-27T23:53:27.361534Z","iopub.status.idle":"2024-02-27T23:53:27.370169Z","shell.execute_reply.started":"2024-02-27T23:53:27.361491Z","shell.execute_reply":"2024-02-27T23:53:27.369045Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We can now create our pipeline. There are going to be two pipelines: one is going to handle the categorical data and the other one is going to handle numerical data. The missing values of the categorical data will be filled with the most frequent value (mode) and after the Target Encoder will be applied to transform categorical variables into numerical variables. The numerical data missing values will be filled with a strategy called K-nearest neighbors, which uses the Euclidean distance between the data points to find the best number to fill the missing values. If don’t know how this Pipeline technique works, I recommend you check my article about Pipelines. (\"https://medium.com/@fernandao.lacerda.dantas/boost-your-pipelines-with-columntransformer-b2c009db096f\")","metadata":{}},{"cell_type":"code","source":"#Categorical and numerical pipelines\n\n\ncat_pipe = Pipeline([(\"imputer_cat\", SimpleImputer(strategy=\"most_frequent\")),(\"encoder\", ce.TargetEncoder()),\n                    ])\n\nnum_pipe = Pipeline([(\"imputer_num\", KNNImputer(n_neighbors=3))])\n","metadata":{"execution":{"iopub.status.busy":"2024-02-27T23:53:27.371692Z","iopub.execute_input":"2024-02-27T23:53:27.372012Z","iopub.status.idle":"2024-02-27T23:53:27.380819Z","shell.execute_reply.started":"2024-02-27T23:53:27.371985Z","shell.execute_reply":"2024-02-27T23:53:27.379685Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"And with column transformer, we can attach both transformations to one variable that I named “transformer”. Observe that we also have to specify the type of data to which the pipeline will be applied to: “cat_pipe” will be applied to “cat_feat” and “num_pipe” will be applied to “num_feat”, meaning the categorical pipeline will take care of the categorical data and the numerical pipeline will take care of the numerical data.","metadata":{}},{"cell_type":"code","source":"#Using ColumnTransformer \n\n\ntransformer = ColumnTransformer([(\"num_trans\", num_pipe, num_feat),\n                            (\"cat_trans\", cat_pipe, cat_feat)])\n\n","metadata":{"execution":{"iopub.status.busy":"2024-02-27T23:53:27.382374Z","iopub.execute_input":"2024-02-27T23:53:27.382681Z","iopub.status.idle":"2024-02-27T23:53:27.391241Z","shell.execute_reply.started":"2024-02-27T23:53:27.382655Z","shell.execute_reply":"2024-02-27T23:53:27.390435Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"After finishing the pipelines, we have to apply the transformations to our data. We use “fit.transform” in the “X_train” data to make the model “learn” the transformations and apply “transform” in the “X_test” data.","metadata":{}},{"cell_type":"code","source":"# \".fit_transform\" in train data\"\n\n# \".transform\" in test data\"\n\nX_train_transformed = transformer.fit_transform(X_train, y_train)\nX_test_transformed = transformer.transform(X_test)\n","metadata":{"execution":{"iopub.status.busy":"2024-02-27T23:53:27.392623Z","iopub.execute_input":"2024-02-27T23:53:27.393178Z","iopub.status.idle":"2024-02-27T23:53:28.049249Z","shell.execute_reply.started":"2024-02-27T23:53:27.393148Z","shell.execute_reply":"2024-02-27T23:53:28.048351Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"In the next step, we are going to perform a Stratified Cross-Validation to select the best tree-based model we will use. We are going to try three models: LGBMClassifier, XGBoost and XGBoost (booster=”gblinear”). And based on the accuracy, the cross-validation will give the mean and the standard deviation of the performance of each model.","metadata":{}},{"cell_type":"markdown","source":"# **Cross Validation**","metadata":{}},{"cell_type":"code","source":"models = []\n\nmodels.append((\"xgb\",xgb.XGBClassifier()))\nmodels.append((\"xgbgblinear\",xgb.XGBClassifier(booster=\"gblinear\")))\nmodels.append((\"LGBM\",LGBMClassifier(verbose=-1)))\n\n\nprint(models)\n\nresults = dict()\n\nfor  name, model in models:\n    skf = StratifiedKFold(n_splits = 5, random_state=None)\n    cv_results = cross_val_score(model,X_train_transformed,y_train,cv=skf, scoring=\"accuracy\")\n    results[name]= (cv_results.mean(), cv_results.std())\n\nprint(\"name     results.mean     results.std\")\n\nfor key,value in results.items():\n    print(key,value)","metadata":{"execution":{"iopub.status.busy":"2024-02-27T23:53:28.050825Z","iopub.execute_input":"2024-02-27T23:53:28.051512Z","iopub.status.idle":"2024-02-27T23:53:30.15402Z","shell.execute_reply.started":"2024-02-27T23:53:28.051479Z","shell.execute_reply":"2024-02-27T23:53:30.153173Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We can see that LGBMClassifier had the best performance, therefore it will be the model used.","metadata":{}},{"cell_type":"code","source":"lgbmc = LGBMClassifier()\n","metadata":{"execution":{"iopub.status.busy":"2024-02-27T23:53:30.155407Z","iopub.execute_input":"2024-02-27T23:53:30.155996Z","iopub.status.idle":"2024-02-27T23:53:30.160153Z","shell.execute_reply.started":"2024-02-27T23:53:30.155964Z","shell.execute_reply":"2024-02-27T23:53:30.158989Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"However, the model itself will not be enough to provide great accuracy. Thus, we now have to perform what is called hyperparameter tuning to make the model more precise.\n\nWe set the parameters we want to test and using sklearn’s GridSearchCV we will obtain the best hyperparameters. GridSearchCV will test the parameters that we want and will show us the combination that has the best performance.","metadata":{}},{"cell_type":"markdown","source":"# **Hyperparameter Tunning**","metadata":{}},{"cell_type":"code","source":"\n\nlgbm_params = {\"n_estimators\":[100,200,300], \n               \"learning_rate\":[0.01,0.05,0.1,0.3],\n               \"num_leaves\":[20,50,80,100],\n              \"verbose\":[-1]}\n\n","metadata":{"execution":{"iopub.status.busy":"2024-02-27T23:53:30.161716Z","iopub.execute_input":"2024-02-27T23:53:30.16201Z","iopub.status.idle":"2024-02-27T23:53:30.169757Z","shell.execute_reply.started":"2024-02-27T23:53:30.161983Z","shell.execute_reply":"2024-02-27T23:53:30.168561Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"grid_search = GridSearchCV (estimator = lgbmc,\n                            param_grid = lgbm_params,\n                            n_jobs=-1,\n                            cv = 5,\n                            scoring=\"accuracy\",\n                           error_score='raise')\n                        ","metadata":{"execution":{"iopub.status.busy":"2024-02-27T23:53:30.171498Z","iopub.execute_input":"2024-02-27T23:53:30.171841Z","iopub.status.idle":"2024-02-27T23:53:30.181813Z","shell.execute_reply.started":"2024-02-27T23:53:30.171811Z","shell.execute_reply":"2024-02-27T23:53:30.180877Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"grid_result = grid_search.fit(X_train_transformed, y_train);\n\n\nfinal_model = lgbmc.set_params(**grid_result.best_params_)\n","metadata":{"execution":{"iopub.status.busy":"2024-02-27T23:53:30.183187Z","iopub.execute_input":"2024-02-27T23:53:30.183798Z","iopub.status.idle":"2024-02-27T23:55:14.584906Z","shell.execute_reply.started":"2024-02-27T23:53:30.183766Z","shell.execute_reply":"2024-02-27T23:55:14.5838Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"With the best model optimized, we can finally train our model and obtain our predictions.","metadata":{}},{"cell_type":"code","source":"\n#training the model\nfinal_model.fit(X_train_transformed, y_train)\n\n\n#predictions\ny_pred = final_model.predict(X_test_transformed)\n","metadata":{"execution":{"iopub.status.busy":"2024-02-27T23:55:14.586185Z","iopub.execute_input":"2024-02-27T23:55:14.58717Z","iopub.status.idle":"2024-02-27T23:55:14.764374Z","shell.execute_reply.started":"2024-02-27T23:55:14.587134Z","shell.execute_reply":"2024-02-27T23:55:14.763324Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"After obtaining our predictions, we have to test our model using metrics such as recall, precision, f1 score and accuracy. The data frame below shows us some of those metrics and we can conclude that the model is having a great performance.","metadata":{}},{"cell_type":"markdown","source":"# **Scores**","metadata":{}},{"cell_type":"code","source":"precision = precision_score(y_pred, y_test)\naccuracy = accuracy_score(y_pred, y_test)\nrecall = precision_score(y_pred, y_test)\nf1 = f1_score(y_pred, y_test)\n\nscore = []\nscore.append((\"precision\", precision))\nscore.append((\"accuracy\",accuracy))\nscore.append((\"recall\",recall))\nscore.append((\"f1\",f1))\n\nscore= pd.DataFrame(score)\nscore.rename(columns={0: \"Metric\", 1:\"Result\"}, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2024-02-27T23:55:14.765703Z","iopub.execute_input":"2024-02-27T23:55:14.766074Z","iopub.status.idle":"2024-02-27T23:55:14.785885Z","shell.execute_reply.started":"2024-02-27T23:55:14.766036Z","shell.execute_reply":"2024-02-27T23:55:14.784744Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Metrics obtained\n\ndisplay(score)","metadata":{"execution":{"iopub.status.busy":"2024-02-27T23:55:14.787395Z","iopub.execute_input":"2024-02-27T23:55:14.787702Z","iopub.status.idle":"2024-02-27T23:55:14.802472Z","shell.execute_reply.started":"2024-02-27T23:55:14.787676Z","shell.execute_reply":"2024-02-27T23:55:14.801387Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f\"Precision: {score.iloc[0,1]:.4f}\")\nprint(f\"Accuracy: {score.iloc[1,1]:.4f}\")\nprint(f\"F1_Score: {score.iloc[2,1]:.4f}\")\nprint(f\"Recall: {score.iloc[3,1]:.4f}\")","metadata":{"execution":{"iopub.status.busy":"2024-02-27T23:55:14.804008Z","iopub.execute_input":"2024-02-27T23:55:14.804437Z","iopub.status.idle":"2024-02-27T23:55:14.811137Z","shell.execute_reply.started":"2024-02-27T23:55:14.804398Z","shell.execute_reply":"2024-02-27T23:55:14.810158Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- Precision: 0.8470\n- Accuracy: 0.8112\n- F1_Score: 0.8470\n- Recall: 0.8163","metadata":{}},{"cell_type":"code","source":"confusions_matrix = confusion_matrix(y_pred, y_test)\n\nfrom sklearn.metrics import ConfusionMatrixDisplay\n\nconf_disp = ConfusionMatrixDisplay(confusion_matrix=confusions_matrix)\n\nconf_disp.plot()","metadata":{"execution":{"iopub.status.busy":"2024-02-27T23:55:14.817812Z","iopub.execute_input":"2024-02-27T23:55:14.81818Z","iopub.status.idle":"2024-02-27T23:55:15.215491Z","shell.execute_reply.started":"2024-02-27T23:55:14.818148Z","shell.execute_reply":"2024-02-27T23:55:15.214144Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Submission**","metadata":{}},{"cell_type":"code","source":"testecsv = pd.read_csv(\"/kaggle/input/spaceship-titanic/test.csv\")","metadata":{"execution":{"iopub.status.busy":"2024-02-27T23:55:15.217299Z","iopub.execute_input":"2024-02-27T23:55:15.217955Z","iopub.status.idle":"2024-02-27T23:55:15.242468Z","shell.execute_reply.started":"2024-02-27T23:55:15.217908Z","shell.execute_reply":"2024-02-27T23:55:15.241198Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"testecsv.head(6)","metadata":{"execution":{"iopub.status.busy":"2024-02-27T23:55:15.244434Z","iopub.execute_input":"2024-02-27T23:55:15.244799Z","iopub.status.idle":"2024-02-27T23:55:15.267933Z","shell.execute_reply.started":"2024-02-27T23:55:15.244767Z","shell.execute_reply":"2024-02-27T23:55:15.266816Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"testecsv[[\"cabin_code\",\"id_cabin\",\"cabin_sector\"]] = testecsv[\"Cabin\"].str.split(\"/\", n=2, expand=True)","metadata":{"execution":{"iopub.status.busy":"2024-02-27T23:55:15.269503Z","iopub.execute_input":"2024-02-27T23:55:15.270365Z","iopub.status.idle":"2024-02-27T23:55:15.286185Z","shell.execute_reply.started":"2024-02-27T23:55:15.270323Z","shell.execute_reply":"2024-02-27T23:55:15.284886Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"testecsv.drop(columns=[\"id_cabin\"], inplace=True)","metadata":{"execution":{"iopub.status.busy":"2024-02-27T23:55:15.287902Z","iopub.execute_input":"2024-02-27T23:55:15.288255Z","iopub.status.idle":"2024-02-27T23:55:15.294613Z","shell.execute_reply.started":"2024-02-27T23:55:15.288225Z","shell.execute_reply":"2024-02-27T23:55:15.29378Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_teste = testecsv.drop(columns=[\"PassengerId\",\"Cabin\",\"Name\"])\n","metadata":{"execution":{"iopub.status.busy":"2024-02-27T23:55:15.295951Z","iopub.execute_input":"2024-02-27T23:55:15.29626Z","iopub.status.idle":"2024-02-27T23:55:15.30554Z","shell.execute_reply.started":"2024-02-27T23:55:15.296232Z","shell.execute_reply":"2024-02-27T23:55:15.304355Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"testecsv.info()","metadata":{"execution":{"iopub.status.busy":"2024-02-27T23:55:15.307294Z","iopub.execute_input":"2024-02-27T23:55:15.307641Z","iopub.status.idle":"2024-02-27T23:55:15.324683Z","shell.execute_reply.started":"2024-02-27T23:55:15.307611Z","shell.execute_reply":"2024-02-27T23:55:15.32365Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = final_model","metadata":{"execution":{"iopub.status.busy":"2024-02-27T23:55:15.326469Z","iopub.execute_input":"2024-02-27T23:55:15.327049Z","iopub.status.idle":"2024-02-27T23:55:15.33147Z","shell.execute_reply.started":"2024-02-27T23:55:15.327017Z","shell.execute_reply":"2024-02-27T23:55:15.330314Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X.dropna(subset=[\"cabin_code\"], inplace=True)","metadata":{"execution":{"iopub.status.busy":"2024-02-27T23:55:15.332861Z","iopub.execute_input":"2024-02-27T23:55:15.333659Z","iopub.status.idle":"2024-02-27T23:55:15.346146Z","shell.execute_reply.started":"2024-02-27T23:55:15.333626Z","shell.execute_reply":"2024-02-27T23:55:15.345144Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = transformer.fit_transform(X,y)\nX_teste = transformer.transform(X_teste)","metadata":{"execution":{"iopub.status.busy":"2024-02-27T23:55:15.347308Z","iopub.execute_input":"2024-02-27T23:55:15.347955Z","iopub.status.idle":"2024-02-27T23:55:16.416286Z","shell.execute_reply.started":"2024-02-27T23:55:15.347914Z","shell.execute_reply":"2024-02-27T23:55:16.415421Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.fit(X, y)","metadata":{"execution":{"iopub.status.busy":"2024-02-27T23:55:16.417406Z","iopub.execute_input":"2024-02-27T23:55:16.418153Z","iopub.status.idle":"2024-02-27T23:55:16.638114Z","shell.execute_reply.started":"2024-02-27T23:55:16.41812Z","shell.execute_reply":"2024-02-27T23:55:16.637218Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_predz = model.predict(X_teste)","metadata":{"execution":{"iopub.status.busy":"2024-02-27T23:55:16.639151Z","iopub.execute_input":"2024-02-27T23:55:16.640048Z","iopub.status.idle":"2024-02-27T23:55:16.671166Z","shell.execute_reply.started":"2024-02-27T23:55:16.640014Z","shell.execute_reply":"2024-02-27T23:55:16.670157Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"subimisspace = pd.Series(index = testecsv[\"PassengerId\"].values, data = y_predz)","metadata":{"execution":{"iopub.status.busy":"2024-02-27T23:55:16.67232Z","iopub.execute_input":"2024-02-27T23:55:16.672619Z","iopub.status.idle":"2024-02-27T23:55:16.677638Z","shell.execute_reply.started":"2024-02-27T23:55:16.672593Z","shell.execute_reply":"2024-02-27T23:55:16.676583Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"subimisspace = subimisspace.reset_index()","metadata":{"execution":{"iopub.status.busy":"2024-02-27T23:55:16.679009Z","iopub.execute_input":"2024-02-27T23:55:16.679801Z","iopub.status.idle":"2024-02-27T23:55:16.692328Z","shell.execute_reply.started":"2024-02-27T23:55:16.679771Z","shell.execute_reply":"2024-02-27T23:55:16.691058Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"subimisspace = pd.DataFrame(subimisspace)\nsubimisspace","metadata":{"execution":{"iopub.status.busy":"2024-02-27T23:55:16.694025Z","iopub.execute_input":"2024-02-27T23:55:16.694653Z","iopub.status.idle":"2024-02-27T23:55:16.709389Z","shell.execute_reply.started":"2024-02-27T23:55:16.694622Z","shell.execute_reply":"2024-02-27T23:55:16.708433Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"subimisspace[0]=subimisspace[0].map({1:\"True\", 0:\"False\"})\n","metadata":{"execution":{"iopub.status.busy":"2024-02-27T23:55:16.710763Z","iopub.execute_input":"2024-02-27T23:55:16.711375Z","iopub.status.idle":"2024-02-27T23:55:16.719954Z","shell.execute_reply.started":"2024-02-27T23:55:16.711328Z","shell.execute_reply":"2024-02-27T23:55:16.718558Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"subimisspace.rename(columns = {\"index\":\"PassengerId\", 0:\"Transported\"}, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2024-02-27T23:55:16.721957Z","iopub.execute_input":"2024-02-27T23:55:16.722657Z","iopub.status.idle":"2024-02-27T23:55:16.731566Z","shell.execute_reply.started":"2024-02-27T23:55:16.722616Z","shell.execute_reply":"2024-02-27T23:55:16.730533Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"subimisspace.to_csv(\"testy.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2024-02-27T23:55:16.733739Z","iopub.execute_input":"2024-02-27T23:55:16.734648Z","iopub.status.idle":"2024-02-27T23:55:16.749752Z","shell.execute_reply.started":"2024-02-27T23:55:16.734605Z","shell.execute_reply":"2024-02-27T23:55:16.748575Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"subimisspace","metadata":{"execution":{"iopub.status.busy":"2024-02-27T23:55:16.7514Z","iopub.execute_input":"2024-02-27T23:55:16.752142Z","iopub.status.idle":"2024-02-27T23:55:16.764039Z","shell.execute_reply.started":"2024-02-27T23:55:16.752109Z","shell.execute_reply":"2024-02-27T23:55:16.762822Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The strategies that I mention in this article led me to a 0.80664 score in the competition and I am sure you can improve my model to achieve an even higher score with your knowledge!\n\nIf you enjoyed this article, don’t forget to support me or hit me with a follow!\n\nSee you in the next article!\n\n-Fernando Dantas ","metadata":{}}]}