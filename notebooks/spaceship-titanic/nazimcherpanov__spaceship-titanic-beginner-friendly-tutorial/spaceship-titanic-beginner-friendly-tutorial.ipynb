{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport numpy as np \nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns \nfrom sklearn.preprocessing import LabelEncoder, StandardScaler\nfrom sklearn.impute import KNNImputer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\nfrom xgboost import XGBClassifier\nfrom catboost import CatBoostClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import VotingClassifier\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-04-13T13:48:02.241564Z","iopub.execute_input":"2023-04-13T13:48:02.242258Z","iopub.status.idle":"2023-04-13T13:48:03.701296Z","shell.execute_reply.started":"2023-04-13T13:48:02.242218Z","shell.execute_reply":"2023-04-13T13:48:03.700284Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 1. **Importing Dataset**","metadata":{}},{"cell_type":"code","source":"# Load training data\ntrain = pd.read_csv('/kaggle/input/spaceship-titanic/train.csv')\n\n# Load test data\ntest = pd.read_csv('/kaggle/input/spaceship-titanic/test.csv')\n\n# Load sample submission data\nsample = pd.read_csv('/kaggle/input/spaceship-titanic/sample_submission.csv')","metadata":{"execution":{"iopub.status.busy":"2023-04-13T13:48:03.713286Z","iopub.execute_input":"2023-04-13T13:48:03.715522Z","iopub.status.idle":"2023-04-13T13:48:03.813597Z","shell.execute_reply.started":"2023-04-13T13:48:03.715484Z","shell.execute_reply":"2023-04-13T13:48:03.812501Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Display the first 5 rows of the training dataset to inspect the data\ntrain.head()","metadata":{"execution":{"iopub.status.busy":"2023-04-13T13:48:03.815378Z","iopub.execute_input":"2023-04-13T13:48:03.816147Z","iopub.status.idle":"2023-04-13T13:48:03.848398Z","shell.execute_reply.started":"2023-04-13T13:48:03.816105Z","shell.execute_reply":"2023-04-13T13:48:03.847415Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Call the describe method on the train dataset to get a summary of its numerical variables.\n# The T method transposes the output to display the summary statistics horizontally instead of vertically.\ntrain.describe().T","metadata":{"execution":{"iopub.status.busy":"2023-04-13T13:48:03.852018Z","iopub.execute_input":"2023-04-13T13:48:03.852776Z","iopub.status.idle":"2023-04-13T13:48:03.90084Z","shell.execute_reply.started":"2023-04-13T13:48:03.852739Z","shell.execute_reply":"2023-04-13T13:48:03.899169Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 2. **Data cleaning and Data transformation**","metadata":{}},{"cell_type":"code","source":"# Calculate the proportion of missing values in each column of the train DataFrame\ntrain.isna().mean()","metadata":{"execution":{"iopub.status.busy":"2023-04-13T13:48:03.902498Z","iopub.execute_input":"2023-04-13T13:48:03.903175Z","iopub.status.idle":"2023-04-13T13:48:03.923899Z","shell.execute_reply.started":"2023-04-13T13:48:03.903136Z","shell.execute_reply":"2023-04-13T13:48:03.916787Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Multiply the 'Transported' column of the 'train' DataFrame by 1\n# This is a common trick used to convert boolean values to 1 and 0, since \n# True * 1 = 1 and False * 1 = 0\ntrain['Transported'] = train['Transported']*1","metadata":{"execution":{"iopub.status.busy":"2023-04-13T13:48:03.928094Z","iopub.execute_input":"2023-04-13T13:48:03.928548Z","iopub.status.idle":"2023-04-13T13:48:03.937458Z","shell.execute_reply.started":"2023-04-13T13:48:03.928511Z","shell.execute_reply":"2023-04-13T13:48:03.936046Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Count the number of occurrences of each unique value in the 'HomePlanet' column of the 'train' DataFrame\ntrain['HomePlanet'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2023-04-13T13:48:03.938953Z","iopub.execute_input":"2023-04-13T13:48:03.940261Z","iopub.status.idle":"2023-04-13T13:48:03.954367Z","shell.execute_reply.started":"2023-04-13T13:48:03.940222Z","shell.execute_reply":"2023-04-13T13:48:03.95316Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Count the number of occurrences of each unique value in the 'Destination' column of the 'train' DataFrame\ntrain['Destination'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2023-04-13T13:48:03.956168Z","iopub.execute_input":"2023-04-13T13:48:03.956976Z","iopub.status.idle":"2023-04-13T13:48:03.967275Z","shell.execute_reply.started":"2023-04-13T13:48:03.956931Z","shell.execute_reply":"2023-04-13T13:48:03.96579Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def clean(df):\n    # Set up imputer and label encoder\n    imputer = KNNImputer(n_neighbors=2, weights=\"uniform\")\n    le = LabelEncoder()\n    \n    # Convert CryoSleep column to int\n    df['CryoSleep'] = df['CryoSleep']*1\n    \n    # Split Cabin column into Deck, Cabin_num, and Side columns\n    df[[\"Deck\", \"Cabin_num\", \"Side\"]] = df[\"Cabin\"].str.split(\"/\", expand=True)\n    \n    # Impute missing values in certain columns\n    df[['Age', 'RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck', 'CryoSleep', 'Cabin_num']] = imputer.fit_transform(df[['Age', 'RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck', 'CryoSleep', 'Cabin_num']])\n    \n    # Replace missing values in certain columns with specified values\n    vals, nls = ['HomePlanet', 'Destination', 'Deck', 'Side'], ['Earth', 'TRAPPIST-1e', 'F', 'P']\n    for i in range(len(vals)):\n        df[vals[i]].fillna(nls[i], inplace=True)\n    \n    # Encode certain columns using label encoder\n    for j in ['HomePlanet', 'Destination', 'Deck', 'Side']:    \n        df[j] = le.fit_transform(df[j].astype(str))\n    \n    # Return cleaned dataframe\n    return df","metadata":{"execution":{"iopub.status.busy":"2023-04-13T13:48:03.972608Z","iopub.execute_input":"2023-04-13T13:48:03.973272Z","iopub.status.idle":"2023-04-13T13:48:03.987628Z","shell.execute_reply.started":"2023-04-13T13:48:03.973236Z","shell.execute_reply":"2023-04-13T13:48:03.98627Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Clean the training data using the clean function\ntrain = clean(train)","metadata":{"execution":{"iopub.status.busy":"2023-04-13T13:48:03.991677Z","iopub.execute_input":"2023-04-13T13:48:03.992875Z","iopub.status.idle":"2023-04-13T13:48:04.98372Z","shell.execute_reply.started":"2023-04-13T13:48:03.992837Z","shell.execute_reply":"2023-04-13T13:48:04.982581Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Calculate the proportion of missing values in each column of the train DataFrame\ntrain.isna().mean()","metadata":{"execution":{"iopub.status.busy":"2023-04-13T13:48:04.988924Z","iopub.execute_input":"2023-04-13T13:48:04.991336Z","iopub.status.idle":"2023-04-13T13:48:05.009725Z","shell.execute_reply.started":"2023-04-13T13:48:04.991296Z","shell.execute_reply":"2023-04-13T13:48:05.008664Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Display the data types of each column in the train dataframe\ntrain.dtypes","metadata":{"execution":{"iopub.status.busy":"2023-04-13T13:48:05.010988Z","iopub.execute_input":"2023-04-13T13:48:05.011313Z","iopub.status.idle":"2023-04-13T13:48:05.020689Z","shell.execute_reply.started":"2023-04-13T13:48:05.011277Z","shell.execute_reply":"2023-04-13T13:48:05.019414Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Count the number of occurrences of each unique value in the 'HomePlanet' column of the 'train' DataFrame\ntrain['HomePlanet'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2023-04-13T13:48:05.027172Z","iopub.execute_input":"2023-04-13T13:48:05.027488Z","iopub.status.idle":"2023-04-13T13:48:05.042466Z","shell.execute_reply.started":"2023-04-13T13:48:05.027461Z","shell.execute_reply":"2023-04-13T13:48:05.041494Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Count the number of occurrences of each unique value in the 'Destination' column of the 'train' DataFrame\ntrain['Destination'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2023-04-13T13:48:05.043864Z","iopub.execute_input":"2023-04-13T13:48:05.049122Z","iopub.status.idle":"2023-04-13T13:48:05.05832Z","shell.execute_reply.started":"2023-04-13T13:48:05.049084Z","shell.execute_reply":"2023-04-13T13:48:05.056599Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 3. **Data Analysis and Vizualization**","metadata":{}},{"cell_type":"markdown","source":"* **PassengerId** - A unique Id for each passenger. Each Id takes the form gggg_pp where gggg indicates a group the passenger is travelling with and pp is their number within the group. People in a group are often family members, but not always.\n* **HomePlanet** - The planet the passenger departed from, typically their planet of permanent residence.\n* **CryoSleep** - Indicates whether the passenger elected to be put into suspended animation for the duration of the voyage. Passengers in cryosleep are confined to their cabins.\n* **Cabin** - The cabin number where the passenger is staying. Takes the form deck/num/side, where side can be either P for Port or S for Starboard.\n* **Destination** - The planet the passenger will be debarking to.\n* **Age** - The age of the passenger.\n* **VIP** - Whether the passenger has paid for special VIP service during the voyage.\n* **RoomService**, **FoodCourt**, **ShoppingMall**, **Spa**, **VRDeck** - Amount the passenger has billed at each of the Spaceship Titanic's many luxury amenities.\n* **Name** - The first and last names of the passenger.\n* **Transported** - Whether the passenger was transported to another dimension. This is the target, the column you are trying to predict.","metadata":{}},{"cell_type":"code","source":"# Create a new column called 'groupN' in the 'train' DataFrame\n# The values in this column will be calculated based on the 'PassengerId' column\ntrain['groupN'] = [\n    int(i.split('_')[0])  # Extract the first part of the string in 'PassengerId', which represents the group number\n    for i in train['PassengerId']  # For each value in the 'PassengerId' column\n]","metadata":{"execution":{"iopub.status.busy":"2023-04-13T13:48:05.060305Z","iopub.execute_input":"2023-04-13T13:48:05.064666Z","iopub.status.idle":"2023-04-13T13:48:05.083131Z","shell.execute_reply.started":"2023-04-13T13:48:05.064629Z","shell.execute_reply":"2023-04-13T13:48:05.082192Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Count the number of occurrences of each unique value in the 'groupN' column\nx = train['groupN'].value_counts()\n\n# Select the 'Age' column\ny = train['Age']\n\n# Select the 'Transported' column to use for hue\nhue = train['Transported']\n\n# Create a figure and axis object with a specified size\nfig, ax = plt.subplots(figsize=(10, 6))\n\n# Create a scatter plot with x and y as the coordinates, using hue for color coding\nsns.scatterplot(x=x, y=y, hue=hue, ax=ax)\n\n# Set the x-axis label\nax.set_xlabel('Group Count')\n\n# Set the y-axis label\nax.set_ylabel('Age')\n\n# Set the plot title\nax.set_title('Age vs. Group Count with Transported Status')\n\n# Add a legend to the plot\nax.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n\n# Display the plot\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-04-13T13:48:05.087563Z","iopub.execute_input":"2023-04-13T13:48:05.08983Z","iopub.status.idle":"2023-04-13T13:48:05.864639Z","shell.execute_reply.started":"2023-04-13T13:48:05.089792Z","shell.execute_reply":"2023-04-13T13:48:05.863599Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### **I can't see any correlation between the number of people in a group and other variables.**","metadata":{}},{"cell_type":"code","source":"# Create a figure and axis with a size of 10x6\nfig, ax = plt.subplots(figsize=(10, 6))\n\n# Create a stacked histogram with the Age column on the x-axis and Transported column as the hue\n# Use KDE (Kernel Density Estimation) to estimate the distribution of each group and display the result as a curve\nsns.histplot(x=train['Age'], hue=train['Transported'], ax=ax, kde=True, multiple=\"stack\")\n\n# Set the x-label to \"Age\"\nax.set_xlabel(\"Age\")\n# Set the y-label to \"Count\"\nax.set_ylabel(\"Count\")\n# Set the title to \"Distribution of Age by Transported\"\nax.set_title(\"Distribution of Age by Transported\")\n\n# Get the legend handles and labels\nhandles, labels = ax.get_legend_handles_labels()\n# Set the legend title to \"Transported\" and place it in the upper right corner\nax.legend(handles, labels, title=\"Transported\", loc=\"upper right\")\n\n# Display the plot\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-04-13T13:48:05.865773Z","iopub.execute_input":"2023-04-13T13:48:05.866102Z","iopub.status.idle":"2023-04-13T13:48:06.447102Z","shell.execute_reply.started":"2023-04-13T13:48:05.866073Z","shell.execute_reply":"2023-04-13T13:48:06.445992Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Multiply the 'VIP' column in the 'train' DataFrame by 1, which converts it to a numerical column\ntrain['VIP'] = train['VIP']*1\n\n# Set the style of the seaborn plots to 'darkgrid'\nsns.set(style='darkgrid')\n\n# Create a new figure with a size of 8x6 inches\nplt.figure(figsize=(8, 6)) \n\n# Create a countplot using the 'train' DataFrame, with 'VIP' on the x-axis and 'Transported' on the hue axis,\n# and use the 'husl' color palette\nsns.countplot(data=train, x='VIP', hue='Transported', palette='husl')\n\n# Set the x-axis label to 'VIP'\nplt.xlabel('VIP')\n\n# Set the y-axis label to 'Count'\nplt.ylabel('Count')\n\n# Set the title of the plot to 'Count of Transported by VIP status'\nplt.title('Count of Transported by VIP status')\n\n# Add a legend to the plot with the title 'Transported', location 'upper right', and labels 'No' and 'Yes'\nplt.legend(title='Transported', loc='upper right', labels=['No', 'Yes'])\n\n# Display the plot\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-04-13T13:48:06.448713Z","iopub.execute_input":"2023-04-13T13:48:06.44935Z","iopub.status.idle":"2023-04-13T13:48:06.764384Z","shell.execute_reply.started":"2023-04-13T13:48:06.449311Z","shell.execute_reply":"2023-04-13T13:48:06.763373Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# This code calculates the proportion of rows in the 'train' DataFrame\n# where the 'VIP' column is equal to 1.\n# It does this by first creating a Boolean array of True/False values,\n# where True indicates that the corresponding row has VIP=1.\n# Then, it takes the mean of this Boolean array, which is equal to the\n# proportion of True values, or the proportion of rows where VIP=1.\n(train['VIP'] == 1).mean()","metadata":{"execution":{"iopub.status.busy":"2023-04-13T13:48:06.765876Z","iopub.execute_input":"2023-04-13T13:48:06.766185Z","iopub.status.idle":"2023-04-13T13:48:06.774291Z","shell.execute_reply.started":"2023-04-13T13:48:06.766158Z","shell.execute_reply":"2023-04-13T13:48:06.773071Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Set figure size\nplt.figure(figsize=(8, 6))\n\n# Create count plot of CryoSleep with Transported as hue\nsns.countplot(data=train, x='CryoSleep', hue='Transported', palette='husl')\n\n# Set x and y labels\nplt.xlabel('CryoSleep')\nplt.ylabel('Count')\n\n# Set plot title\nplt.title('Count of Transported by CryoSleep')\n\n# Add legend to plot\nplt.legend(title='Transported', loc='upper right', labels=['No', 'Yes'])\n\n# Show plot\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-04-13T13:48:06.77624Z","iopub.execute_input":"2023-04-13T13:48:06.777113Z","iopub.status.idle":"2023-04-13T13:48:07.007464Z","shell.execute_reply.started":"2023-04-13T13:48:06.777077Z","shell.execute_reply":"2023-04-13T13:48:07.006469Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create a crosstab of the number of transported individuals from each home planet\ntransported_by_homeplanet = pd.crosstab(index=train['HomePlanet'], columns=train['Transported'])\n\n# Create a crosstab of the number of transported individuals to each destination\ntransported_by_destination = pd.crosstab(index=train['Destination'], columns=train['Transported'])\n\n# Plot a stacked bar chart of the number of transported individuals from each home planet\ntransported_by_homeplanet.plot(kind='bar', stacked=True)\n\n# Plot a stacked bar chart of the number of transported individuals to each destination\ntransported_by_destination.plot(kind='bar', stacked=True)","metadata":{"execution":{"iopub.status.busy":"2023-04-13T13:48:07.008971Z","iopub.execute_input":"2023-04-13T13:48:07.009292Z","iopub.status.idle":"2023-04-13T13:48:07.539118Z","shell.execute_reply.started":"2023-04-13T13:48:07.009256Z","shell.execute_reply":"2023-04-13T13:48:07.538118Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plot pairwise relationships between selected features\nsns.pairplot(train[['RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck', 'Transported']], \n             hue='Transported')\n             \n# 'hue' parameter specifies the column in the dataset that determines the color of the points\n# In this case, the points will be colored according to the 'Transported' column, which indicates \n# whether or not a person was transported to the vacation location via a special mode of transport. \n# The pairplot will show the pairwise relationships between the selected features, with different \n# colors indicating whether or not a person was transported.","metadata":{"execution":{"iopub.status.busy":"2023-04-13T13:48:07.54047Z","iopub.execute_input":"2023-04-13T13:48:07.541533Z","iopub.status.idle":"2023-04-13T13:48:24.761265Z","shell.execute_reply.started":"2023-04-13T13:48:07.541493Z","shell.execute_reply":"2023-04-13T13:48:24.760386Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Iterate over two features: 'Deck' and 'Side'\nfor i in ['Deck', 'Side']:\n    # Create countplot using Seaborn, with 'Transported' as hue\n    sns.countplot(x=i, hue='Transported', data=train)\n    \n    # Add title to plot with the feature name and 'vs Transported'\n    plt.title(f'{i} vs Transported')\n    \n    # Label x-axis with the feature name\n    plt.xlabel(i)\n    \n    # Label y-axis with 'Count'\n    plt.ylabel('Count')\n    \n    # Display the plot\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2023-04-13T13:48:24.762676Z","iopub.execute_input":"2023-04-13T13:48:24.763781Z","iopub.status.idle":"2023-04-13T13:48:25.245287Z","shell.execute_reply.started":"2023-04-13T13:48:24.763743Z","shell.execute_reply":"2023-04-13T13:48:25.244361Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create a figure with a specified size\nplt.figure(figsize=(8, 6))\n\n# Plot a histogram of the 'Cabin_num' variable from the 'train' dataset,\n# with different colors for the 'Transported' categories\nsns.histplot(x=train['Cabin_num'], hue=train['Transported'])\n\n# Set the title and axis labels for the plot\nplt.title('Distribution of Cabin Numbers')\nplt.xlabel('Cabin Number')\nplt.ylabel('Count')\n\n# Display the plot\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-04-13T13:48:25.24687Z","iopub.execute_input":"2023-04-13T13:48:25.247243Z","iopub.status.idle":"2023-04-13T13:48:25.626527Z","shell.execute_reply.started":"2023-04-13T13:48:25.247204Z","shell.execute_reply":"2023-04-13T13:48:25.625382Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 4. **Feature Engineering**","metadata":{}},{"cell_type":"code","source":"def sum_bills(df):\n    # Create a scaler object for later use\n    scaler = StandardScaler()\n    \n    # Calculate the average of the 'FoodCourt' and 'ShoppingMall' columns and add to the dataframe as a new column\n    df['good_places'] = df[['FoodCourt', 'ShoppingMall']].sum(axis=1)/2\n    \n    # Calculate the average of the 'RoomService', 'Spa', and 'VRDeck' columns and add to the dataframe as a new column\n    df['terube_places'] = df[['RoomService', 'Spa', 'VRDeck']].sum(axis=1)/3\n    \n    # Scale the new columns using the StandardScaler\n    # Uncomment the next two lines of code to scale the new columns\n#     df['good_places'] = scaler.fit_transform(df['good_places'].values.reshape(-1, 1))\n#     df['terube_places'] = scaler.fit_transform(df['terube_places'].values.reshape(-1, 1))\n    \n    # Return the modified dataframe\n    return df","metadata":{"execution":{"iopub.status.busy":"2023-04-13T13:48:25.627794Z","iopub.execute_input":"2023-04-13T13:48:25.628762Z","iopub.status.idle":"2023-04-13T13:48:25.635706Z","shell.execute_reply.started":"2023-04-13T13:48:25.628724Z","shell.execute_reply":"2023-04-13T13:48:25.634597Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = sum_bills(train)","metadata":{"execution":{"iopub.status.busy":"2023-04-13T13:48:25.637127Z","iopub.execute_input":"2023-04-13T13:48:25.637768Z","iopub.status.idle":"2023-04-13T13:48:25.648075Z","shell.execute_reply.started":"2023-04-13T13:48:25.637728Z","shell.execute_reply":"2023-04-13T13:48:25.646887Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def road(df):\n    # Create a label encoder instance\n    le = LabelEncoder()\n    \n    # Initialize an empty list to store road values\n    res = []\n    \n    # Loop through the HomePlanet column and append the concatenated string of HomePlanet and Destination to the res list\n    for ind, i in enumerate(df[\"HomePlanet\"]):\n        res.append(f'{i}-{df[\"Destination\"][ind]}')\n    \n    # Create a new column 'road' in the dataframe and encode the concatenated string values using the label encoder\n    df['road'] = res\n    df['road'] = le.fit_transform(df['road'])\n    \n    # Return the updated dataframe with the new 'road' column\n    return df","metadata":{"execution":{"iopub.status.busy":"2023-04-13T13:48:25.649362Z","iopub.execute_input":"2023-04-13T13:48:25.650171Z","iopub.status.idle":"2023-04-13T13:48:25.656303Z","shell.execute_reply.started":"2023-04-13T13:48:25.650134Z","shell.execute_reply":"2023-04-13T13:48:25.655613Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = road(train)","metadata":{"execution":{"iopub.status.busy":"2023-04-13T13:48:25.657506Z","iopub.execute_input":"2023-04-13T13:48:25.658537Z","iopub.status.idle":"2023-04-13T13:48:25.721233Z","shell.execute_reply.started":"2023-04-13T13:48:25.658376Z","shell.execute_reply":"2023-04-13T13:48:25.720377Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 5. **Modeling**","metadata":{}},{"cell_type":"markdown","source":"### **XGBoost**","metadata":{}},{"cell_type":"code","source":"# Get the column names of the training data\n# and store them in a list called \"columns\"\ncolumns = train.columns","metadata":{"execution":{"iopub.status.busy":"2023-04-13T13:48:25.722479Z","iopub.execute_input":"2023-04-13T13:48:25.722891Z","iopub.status.idle":"2023-04-13T13:48:25.727662Z","shell.execute_reply.started":"2023-04-13T13:48:25.722854Z","shell.execute_reply":"2023-04-13T13:48:25.726634Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# This line creates a list of features that will be used as input to a machine learning model.\nfeatures = ['CryoSleep', 'Age','good_places','terube_places','road', 'Deck', 'Cabin_num', 'Side']\n\n# This line specifies the target variable, which is the variable we want to predict using the features.\ntarget = 'Transported'\n\n# This line creates two new variables: X, which contains the feature data, and y, which contains the target variable data.\n# train is assumed to be a pandas DataFrame containing both the feature and target data.\nX = train[features]\ny = train[target]","metadata":{"execution":{"iopub.status.busy":"2023-04-13T13:48:25.728937Z","iopub.execute_input":"2023-04-13T13:48:25.73002Z","iopub.status.idle":"2023-04-13T13:48:25.739991Z","shell.execute_reply.started":"2023-04-13T13:48:25.729983Z","shell.execute_reply":"2023-04-13T13:48:25.738846Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Split the dataset into training and testing sets with a 70-30 ratio and a fixed random state for reproducibility\nX_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, test_size=0.3)\n\n# Define an XGBoost classifier with some hyperparameters\nxg = XGBClassifier(learning_rate=0.1, max_depth=3, n_estimators=200, gamma=0.2)\n\n# Create a pipeline with a StandardScaler and the XGBoost classifier\nmodel = Pipeline([\n    ('scaler', StandardScaler()),\n    ('xgb', xg)\n])\n\n# Fit the pipeline to the training data\nmodel.fit(X_train, y_train)\n\n# Predict the labels of the test data using the fitted pipeline\ny_pred = model.predict(X_test)","metadata":{"execution":{"iopub.status.busy":"2023-04-13T13:48:25.741211Z","iopub.execute_input":"2023-04-13T13:48:25.742808Z","iopub.status.idle":"2023-04-13T13:48:29.991869Z","shell.execute_reply.started":"2023-04-13T13:48:25.742613Z","shell.execute_reply":"2023-04-13T13:48:29.990761Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create a horizontal bar plot using Matplotlib's pyplot module\n# The horizontal bar plot will display the feature importances for the XGBoost model\n# The bar lengths will be determined by the feature importances, and the bars will be labeled with the corresponding feature names\nplt.barh(X_train.columns, model['xgb'].feature_importances_)","metadata":{"execution":{"iopub.status.busy":"2023-04-13T13:48:29.996225Z","iopub.execute_input":"2023-04-13T13:48:29.998156Z","iopub.status.idle":"2023-04-13T13:48:30.275023Z","shell.execute_reply.started":"2023-04-13T13:48:29.99812Z","shell.execute_reply":"2023-04-13T13:48:30.274144Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Creates a dictionary to store the metrics calculated below\nmetrics_dict = {\n    'Accuracy': accuracy_score(y_test, y_pred),   # Calculates the accuracy score using y_test (true values) and y_pred (predicted values) and adds it to the dictionary\n    'Precision': precision_score(y_test, y_pred), # Calculates the precision score using y_test and y_pred and adds it to the dictionary\n    'Recall': recall_score(y_test, y_pred),       # Calculates the recall score using y_test and y_pred and adds it to the dictionary\n    'F1': f1_score(y_test, y_pred),               # Calculates the F1 score using y_test and y_pred and adds it to the dictionary\n    'ROC AUC': roc_auc_score(y_test, y_pred)      # Calculates the ROC AUC score using y_test and y_pred and adds it to the dictionary\n}\n\n# Returns the dictionary containing all the computed metrics\nmetrics_dict","metadata":{"execution":{"iopub.status.busy":"2023-04-13T13:48:30.276406Z","iopub.execute_input":"2023-04-13T13:48:30.27846Z","iopub.status.idle":"2023-04-13T13:48:30.294715Z","shell.execute_reply.started":"2023-04-13T13:48:30.278407Z","shell.execute_reply":"2023-04-13T13:48:30.293658Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **CatBoost**","metadata":{}},{"cell_type":"code","source":"# This line creates a list of features that will be used as input to a machine learning model.\nfeatures = ['CryoSleep', 'Age','good_places','terube_places','road', 'Deck', 'Cabin_num', 'Side']\n\n# This line specifies the target variable, which is the variable we want to predict using the features.\ntarget = 'Transported'\n\n# This line creates two new variables: X, which contains the feature data, and y, which contains the target variable data.\n# train is assumed to be a pandas DataFrame containing both the feature and target data.\nX = train[features]\ny = train[target]","metadata":{"execution":{"iopub.status.busy":"2023-04-13T13:48:30.296242Z","iopub.execute_input":"2023-04-13T13:48:30.296673Z","iopub.status.idle":"2023-04-13T13:48:30.306112Z","shell.execute_reply.started":"2023-04-13T13:48:30.296637Z","shell.execute_reply":"2023-04-13T13:48:30.304923Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Split the dataset into training and testing sets, with a 70-30 split and a random seed of 42\nX_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, test_size=0.3)\n\n# Create a CatBoostClassifier model with 3000 iterations, using accuracy as the evaluation metric and with no verbosity\nmodel = CatBoostClassifier(iterations=3000, eval_metric='Accuracy', verbose=0)\n\n# Fit the model on the training data\nmodel.fit(X_train, y_train)\n\n# Make predictions on the test data using the trained model\ny_pred = model.predict(X_test)","metadata":{"execution":{"iopub.status.busy":"2023-04-13T13:48:30.307828Z","iopub.execute_input":"2023-04-13T13:48:30.308241Z","iopub.status.idle":"2023-04-13T13:48:40.169677Z","shell.execute_reply.started":"2023-04-13T13:48:30.308205Z","shell.execute_reply":"2023-04-13T13:48:40.168599Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Creates a dictionary to store the metrics calculated below\nmetrics_dict = {\n    'Accuracy': accuracy_score(y_test, y_pred),   # Calculates the accuracy score using y_test (true values) and y_pred (predicted values) and adds it to the dictionary\n    'Precision': precision_score(y_test, y_pred), # Calculates the precision score using y_test and y_pred and adds it to the dictionary\n    'Recall': recall_score(y_test, y_pred),       # Calculates the recall score using y_test and y_pred and adds it to the dictionary\n    'F1': f1_score(y_test, y_pred),               # Calculates the F1 score using y_test and y_pred and adds it to the dictionary\n    'ROC AUC': roc_auc_score(y_test, y_pred)      # Calculates the ROC AUC score using y_test and y_pred and adds it to the dictionary\n}\n\n# Returns the dictionary containing all the computed metrics\nmetrics_dict","metadata":{"execution":{"iopub.status.busy":"2023-04-13T13:48:40.171236Z","iopub.execute_input":"2023-04-13T13:48:40.171635Z","iopub.status.idle":"2023-04-13T13:48:40.190127Z","shell.execute_reply.started":"2023-04-13T13:48:40.171594Z","shell.execute_reply":"2023-04-13T13:48:40.189021Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **SVM**","metadata":{}},{"cell_type":"code","source":"# This line creates a list of features that will be used as input to a machine learning model.\nfeatures = ['CryoSleep', 'Age','good_places','terube_places','road', 'Deck', 'Cabin_num', 'Side']\n\n# This line specifies the target variable, which is the variable we want to predict using the features.\ntarget = 'Transported'\n\n# This line creates two new variables: X, which contains the feature data, and y, which contains the target variable data.\n# train is assumed to be a pandas DataFrame containing both the feature and target data.\nX = train[features]\ny = train[target]","metadata":{"execution":{"iopub.status.busy":"2023-04-13T13:48:40.191806Z","iopub.execute_input":"2023-04-13T13:48:40.192171Z","iopub.status.idle":"2023-04-13T13:48:40.208243Z","shell.execute_reply.started":"2023-04-13T13:48:40.192135Z","shell.execute_reply":"2023-04-13T13:48:40.207252Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Splitting the dataset into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42 ,test_size=0.3)\n\n# Creating a pipeline that first scales the data and then fits a Support Vector Machine (SVM) model\nmodel = Pipeline([\n    ('scaler', StandardScaler()),  # Standardizes the features by removing the mean and scaling to unit variance\n    ('svm', SVC(C=5, probability=True))  # SVM model with regularization parameter C=5 and probability estimates enabled\n])\n\n# Training the model on the training data\nmodel.fit(X_train, y_train)\n\n# Making predictions on the testing data using the trained model\ny_pred = model.predict(X_test)","metadata":{"execution":{"iopub.status.busy":"2023-04-13T13:48:40.209881Z","iopub.execute_input":"2023-04-13T13:48:40.210318Z","iopub.status.idle":"2023-04-13T13:48:46.06865Z","shell.execute_reply.started":"2023-04-13T13:48:40.210283Z","shell.execute_reply":"2023-04-13T13:48:46.063313Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Creates a dictionary to store the metrics calculated below\nmetrics_dict = {\n    'Accuracy': accuracy_score(y_test, y_pred),   # Calculates the accuracy score using y_test (true values) and y_pred (predicted values) and adds it to the dictionary\n    'Precision': precision_score(y_test, y_pred), # Calculates the precision score using y_test and y_pred and adds it to the dictionary\n    'Recall': recall_score(y_test, y_pred),       # Calculates the recall score using y_test and y_pred and adds it to the dictionary\n    'F1': f1_score(y_test, y_pred),               # Calculates the F1 score using y_test and y_pred and adds it to the dictionary\n    'ROC AUC': roc_auc_score(y_test, y_pred)      # Calculates the ROC AUC score using y_test and y_pred and adds it to the dictionary\n}\n\n# Returns the dictionary containing all the computed metrics\nmetrics_dict","metadata":{"execution":{"iopub.status.busy":"2023-04-13T13:48:46.070019Z","iopub.execute_input":"2023-04-13T13:48:46.071066Z","iopub.status.idle":"2023-04-13T13:48:46.090077Z","shell.execute_reply.started":"2023-04-13T13:48:46.071034Z","shell.execute_reply":"2023-04-13T13:48:46.088973Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **Voting**","metadata":{}},{"cell_type":"code","source":"# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, test_size=0.3)\n\n# Initialize an XGBoost classifier with some hyperparameters\nxg = XGBClassifier(learning_rate=0.1, max_depth=3, n_estimators=200, gamma=0.2)\n\n# Initialize a CatBoost classifier with some hyperparameters\nmodel1 = CatBoostClassifier(iterations=5000, eval_metric='Accuracy', verbose=0)\n\n# Initialize a pipeline with StandardScaler and XGBoost\nmodel2 = Pipeline([\n    ('scaler', StandardScaler()),\n    ('xgb', xg)\n])\n\n# Initialize a pipeline with StandardScaler and Support Vector Machine (SVM)\nmodel3 = Pipeline([\n    ('scaler', StandardScaler()),\n    ('svm', SVC(C=5, probability=True))\n])\n\n# Initialize a voting classifier with the three models as estimators\nmodel = VotingClassifier(estimators=[('cat', model1), ('xg', model2), ('svm', model3)], voting='soft')\n\n# Fit the voting classifier to the training data\nmodel.fit(X_train, y_train)\n\n# Use the fitted model to make predictions on the test data\ny_pred = model.predict(X_test)","metadata":{"execution":{"iopub.status.busy":"2023-04-13T13:48:46.096896Z","iopub.execute_input":"2023-04-13T13:48:46.097163Z","iopub.status.idle":"2023-04-13T13:49:09.993385Z","shell.execute_reply.started":"2023-04-13T13:48:46.097138Z","shell.execute_reply":"2023-04-13T13:49:09.992316Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Creates a dictionary to store the metrics calculated below\nmetrics_dict = {\n    'Accuracy': accuracy_score(y_test, y_pred),   # Calculates the accuracy score using y_test (true values) and y_pred (predicted values) and adds it to the dictionary\n    'Precision': precision_score(y_test, y_pred), # Calculates the precision score using y_test and y_pred and adds it to the dictionary\n    'Recall': recall_score(y_test, y_pred),       # Calculates the recall score using y_test and y_pred and adds it to the dictionary\n    'F1': f1_score(y_test, y_pred),               # Calculates the F1 score using y_test and y_pred and adds it to the dictionary\n    'ROC AUC': roc_auc_score(y_test, y_pred)      # Calculates the ROC AUC score using y_test and y_pred and adds it to the dictionary\n}\n\n# Returns the dictionary containing all the computed metrics\nmetrics_dict","metadata":{"execution":{"iopub.status.busy":"2023-04-13T13:49:09.994675Z","iopub.execute_input":"2023-04-13T13:49:09.99503Z","iopub.status.idle":"2023-04-13T13:49:10.013578Z","shell.execute_reply.started":"2023-04-13T13:49:09.99499Z","shell.execute_reply":"2023-04-13T13:49:10.012707Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 6. **Sumbission**","metadata":{}},{"cell_type":"code","source":"# Clean the data in the test variable\ntest = clean(test)\n\n# Calculate the total sum of bills in the cleaned test data\ntest = sum_bills(test)\n\n# Process the road data in the test variable\ntest = road(test)","metadata":{"execution":{"iopub.status.busy":"2023-04-13T13:49:10.015109Z","iopub.execute_input":"2023-04-13T13:49:10.015871Z","iopub.status.idle":"2023-04-13T13:49:10.260321Z","shell.execute_reply.started":"2023-04-13T13:49:10.015834Z","shell.execute_reply":"2023-04-13T13:49:10.259301Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# make predictions on the test data using the trained model\nsub_pred = model.predict(test[features])\n\n# convert the continuous prediction values to binary (True/False) values based on a threshold of 0.5\nsub_binary = [True if p >= 0.5 else False for p in sub_pred]","metadata":{"execution":{"iopub.status.busy":"2023-04-13T13:49:10.261804Z","iopub.execute_input":"2023-04-13T13:49:10.262198Z","iopub.status.idle":"2023-04-13T13:49:10.847371Z","shell.execute_reply.started":"2023-04-13T13:49:10.262159Z","shell.execute_reply":"2023-04-13T13:49:10.846401Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample['Transported'] = sub_binary","metadata":{"execution":{"iopub.status.busy":"2023-04-13T13:49:10.848725Z","iopub.execute_input":"2023-04-13T13:49:10.850784Z","iopub.status.idle":"2023-04-13T13:49:10.857024Z","shell.execute_reply.started":"2023-04-13T13:49:10.850742Z","shell.execute_reply":"2023-04-13T13:49:10.855869Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample['Transported'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2023-04-13T13:49:10.858862Z","iopub.execute_input":"2023-04-13T13:49:10.859266Z","iopub.status.idle":"2023-04-13T13:49:10.868876Z","shell.execute_reply.started":"2023-04-13T13:49:10.859228Z","shell.execute_reply":"2023-04-13T13:49:10.867594Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Export the 'sample' DataFrame to a CSV file named 'submission.csv' without including the index column.\nsample.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2023-04-13T13:49:10.870779Z","iopub.execute_input":"2023-04-13T13:49:10.87121Z","iopub.status.idle":"2023-04-13T13:49:10.883329Z","shell.execute_reply.started":"2023-04-13T13:49:10.871175Z","shell.execute_reply":"2023-04-13T13:49:10.882454Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **Thank You !**","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}