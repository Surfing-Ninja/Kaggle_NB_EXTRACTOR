{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-10-15T11:13:16.397076Z","iopub.execute_input":"2023-10-15T11:13:16.397544Z","iopub.status.idle":"2023-10-15T11:13:16.817598Z","shell.execute_reply.started":"2023-10-15T11:13:16.3975Z","shell.execute_reply":"2023-10-15T11:13:16.816601Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install darts --quiet\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom datetime import datetime, timedelta\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"execution":{"iopub.status.busy":"2023-10-15T11:13:16.819937Z","iopub.execute_input":"2023-10-15T11:13:16.820706Z","iopub.status.idle":"2023-10-15T11:13:37.816614Z","shell.execute_reply.started":"2023-10-15T11:13:16.820663Z","shell.execute_reply":"2023-10-15T11:13:37.81538Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train = pd.read_csv('/kaggle/input/store-sales-time-series-forecasting/train.csv')\ndisplay(df_train.head())","metadata":{"execution":{"iopub.status.busy":"2023-10-15T11:13:37.81816Z","iopub.execute_input":"2023-10-15T11:13:37.818487Z","iopub.status.idle":"2023-10-15T11:13:40.885673Z","shell.execute_reply.started":"2023-10-15T11:13:37.818458Z","shell.execute_reply":"2023-10-15T11:13:40.884645Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_holidays_events = pd.read_csv('/kaggle/input/store-sales-time-series-forecasting/holidays_events.csv')","metadata":{"execution":{"iopub.status.busy":"2023-10-15T11:13:40.887047Z","iopub.execute_input":"2023-10-15T11:13:40.887739Z","iopub.status.idle":"2023-10-15T11:13:40.900566Z","shell.execute_reply.started":"2023-10-15T11:13:40.88771Z","shell.execute_reply":"2023-10-15T11:13:40.89938Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_oil = pd.read_csv('/kaggle/input/store-sales-time-series-forecasting/oil.csv')","metadata":{"execution":{"iopub.status.busy":"2023-10-15T11:13:40.903269Z","iopub.execute_input":"2023-10-15T11:13:40.903652Z","iopub.status.idle":"2023-10-15T11:13:40.91395Z","shell.execute_reply.started":"2023-10-15T11:13:40.903624Z","shell.execute_reply":"2023-10-15T11:13:40.913142Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_stores = pd.read_csv('/kaggle/input/store-sales-time-series-forecasting/stores.csv')","metadata":{"execution":{"iopub.status.busy":"2023-10-15T11:13:40.915909Z","iopub.execute_input":"2023-10-15T11:13:40.916331Z","iopub.status.idle":"2023-10-15T11:13:40.927846Z","shell.execute_reply.started":"2023-10-15T11:13:40.916291Z","shell.execute_reply":"2023-10-15T11:13:40.92659Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_transactions = pd.read_csv('/kaggle/input/store-sales-time-series-forecasting/transactions.csv')","metadata":{"execution":{"iopub.status.busy":"2023-10-15T11:13:40.929329Z","iopub.execute_input":"2023-10-15T11:13:40.929817Z","iopub.status.idle":"2023-10-15T11:13:40.980376Z","shell.execute_reply.started":"2023-10-15T11:13:40.929773Z","shell.execute_reply":"2023-10-15T11:13:40.979441Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_test = pd.read_csv('/kaggle/input/store-sales-time-series-forecasting/test.csv')","metadata":{"execution":{"iopub.status.busy":"2023-10-15T11:13:40.982273Z","iopub.execute_input":"2023-10-15T11:13:40.983042Z","iopub.status.idle":"2023-10-15T11:13:41.013785Z","shell.execute_reply.started":"2023-10-15T11:13:40.983009Z","shell.execute_reply":"2023-10-15T11:13:41.013013Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"family_list = df_train['family'].unique()\nstore_list = df_stores['store_nbr'].unique()","metadata":{"execution":{"iopub.status.busy":"2023-10-15T11:13:41.014872Z","iopub.execute_input":"2023-10-15T11:13:41.01553Z","iopub.status.idle":"2023-10-15T11:13:41.174735Z","shell.execute_reply.started":"2023-10-15T11:13:41.015502Z","shell.execute_reply":"2023-10-15T11:13:41.173766Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_merged = pd.merge(df_train, df_stores, on ='store_nbr')\ntrain_merged = train_merged.sort_values([\"store_nbr\",\"family\",\"date\"])\ntrain_merged = train_merged.astype({\"store_nbr\":'str', \"family\":'str', \"city\":'str',\n                          \"state\":'str', \"type\":'str', \"cluster\":'str'})","metadata":{"execution":{"iopub.status.busy":"2023-10-15T11:13:41.175919Z","iopub.execute_input":"2023-10-15T11:13:41.176221Z","iopub.status.idle":"2023-10-15T11:13:46.097404Z","shell.execute_reply.started":"2023-10-15T11:13:41.176194Z","shell.execute_reply":"2023-10-15T11:13:46.096119Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip installl darts\nfrom darts import TimeSeries\nfrom tqdm import tqdm","metadata":{"execution":{"iopub.status.busy":"2023-10-15T11:13:46.098715Z","iopub.execute_input":"2023-10-15T11:13:46.099033Z","iopub.status.idle":"2023-10-15T11:13:48.473566Z","shell.execute_reply.started":"2023-10-15T11:13:46.099007Z","shell.execute_reply":"2023-10-15T11:13:48.472711Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"family_TS_dict = {}\n\nfor family in tqdm(family_list):\n    df_family = train_merged.loc[train_merged['family'] == family]\n\n    list_of_TS_family = TimeSeries.from_group_dataframe(\n                                df_family,\n                                time_col=\"date\",\n                                group_cols=[\"store_nbr\",\"family\"], # columns for grouping time series\n                                static_cols=[\"city\",\"state\",\"type\",\"cluster\"], # static covariates\n                                value_cols=\"sales\", # target\n                                fill_missing_dates=True, # filling missing dates, remember Dec 25th\n                                freq='D' # days\n                                )\n    for ts in list_of_TS_family:\n            ts = ts.astype(np.float32)\n    list_of_TS_family = sorted(list_of_TS_family, key=lambda ts: int(ts.static_covariates_values()[0,0]))\n    \n    family_TS_dict[family] = list_of_TS_family","metadata":{"execution":{"iopub.status.busy":"2023-10-15T11:13:48.475138Z","iopub.execute_input":"2023-10-15T11:13:48.476025Z","iopub.status.idle":"2023-10-15T11:14:16.475258Z","shell.execute_reply.started":"2023-10-15T11:13:48.475986Z","shell.execute_reply":"2023-10-15T11:14:16.474203Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from darts.dataprocessing import Pipeline\nfrom darts.dataprocessing.transformers import Scaler, StaticCovariatesTransformer, MissingValuesFiller, InvertibleMapper\nfrom sklearn.preprocessing import OrdinalEncoder","metadata":{"execution":{"iopub.status.busy":"2023-10-15T11:14:16.476833Z","iopub.execute_input":"2023-10-15T11:14:16.478163Z","iopub.status.idle":"2023-10-15T11:14:16.780583Z","shell.execute_reply.started":"2023-10-15T11:14:16.478121Z","shell.execute_reply":"2023-10-15T11:14:16.77957Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"family_pipeline_dict = {}\nfamily_TS_transformed_dict = {}\n\nfor key in tqdm(family_TS_dict):\n    train_filler = MissingValuesFiller(verbose=False, n_jobs=-1, name=\"Fill NAs\")\n    static_cov_transformer = StaticCovariatesTransformer(verbose=False, transformer_cat = OrdinalEncoder(), name=\"Encoder\")\n    log_transformer = InvertibleMapper(np.log1p, np.expm1, verbose=False, n_jobs=-1, name=\"Log-Transform\")   \n    train_scaler = Scaler(verbose=False, n_jobs=-1, name=\"Scaling\")\n\n    train_pipeline = Pipeline([train_filler,\n                             static_cov_transformer,\n                             log_transformer,\n                             train_scaler])\n\n    training_transformed = train_pipeline.fit_transform(family_TS_dict[key])\n    family_pipeline_dict[key] = train_pipeline\n    family_TS_transformed_dict[key] = training_transformed","metadata":{"execution":{"iopub.status.busy":"2023-10-15T11:14:16.784915Z","iopub.execute_input":"2023-10-15T11:14:16.785231Z","iopub.status.idle":"2023-10-15T11:14:58.554438Z","shell.execute_reply.started":"2023-10-15T11:14:16.785205Z","shell.execute_reply":"2023-10-15T11:14:58.553605Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from darts.utils.timeseries_generation import datetime_attribute_timeseries","metadata":{"execution":{"iopub.status.busy":"2023-10-15T11:14:58.555385Z","iopub.execute_input":"2023-10-15T11:14:58.555684Z","iopub.status.idle":"2023-10-15T11:14:58.560685Z","shell.execute_reply.started":"2023-10-15T11:14:58.555657Z","shell.execute_reply":"2023-10-15T11:14:58.559662Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"full_time_period = pd.date_range(start='2013-01-01', end='2017-08-31', freq='D')\n\nyear = datetime_attribute_timeseries(time_index = full_time_period, attribute='year')\nmonth = datetime_attribute_timeseries(time_index= full_time_period, attribute='month')\nday = datetime_attribute_timeseries(time_index = full_time_period, attribute='day')\ndayofyear = datetime_attribute_timeseries(time_index = full_time_period, attribute = 'dayofyear')\nweekday = datetime_attribute_timeseries(time_index = full_time_period , attribute='dayofweek')\nweekofyear = datetime_attribute_timeseries(time_index = full_time_period, attribute='weekofyear')\ntimesteps = TimeSeries.from_times_and_values(times = full_time_period,\n                                            values = np.arange(len(full_time_period)),\n                                            columns= ['linear_increase'])\n\ntime_cov = year.stack(month).stack(day).stack(dayofyear).stack(weekday).stack(weekofyear).stack(timesteps)\ntime_cov = time_cov.astype(np.float32)","metadata":{"execution":{"iopub.status.busy":"2023-10-15T11:14:58.561975Z","iopub.execute_input":"2023-10-15T11:14:58.56248Z","iopub.status.idle":"2023-10-15T11:14:58.620897Z","shell.execute_reply.started":"2023-10-15T11:14:58.562453Z","shell.execute_reply":"2023-10-15T11:14:58.620017Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"time_cov_scaler = Scaler(verbose=False, n_jobs=-1, name=\"Scaler\")\ntime_cov_train, time_cov_val = time_cov.split_before(pd.Timestamp('20170816'))\ntime_cov_scaler.fit(time_cov_train)\ntime_cov_transformed = time_cov_scaler.transform(time_cov)","metadata":{"execution":{"iopub.status.busy":"2023-10-15T11:14:58.622187Z","iopub.execute_input":"2023-10-15T11:14:58.62246Z","iopub.status.idle":"2023-10-15T11:14:58.661662Z","shell.execute_reply.started":"2023-10-15T11:14:58.622437Z","shell.execute_reply":"2023-10-15T11:14:58.660671Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from darts.models.filtering.moving_average_filter import MovingAverageFilter","metadata":{"execution":{"iopub.status.busy":"2023-10-15T11:14:58.662831Z","iopub.execute_input":"2023-10-15T11:14:58.663625Z","iopub.status.idle":"2023-10-15T11:15:20.440439Z","shell.execute_reply.started":"2023-10-15T11:14:58.663586Z","shell.execute_reply":"2023-10-15T11:15:20.439133Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"oil = TimeSeries.from_dataframe(df_oil, \n                                time_col = 'date', \n                                value_cols = ['dcoilwtico'],\n                                freq = 'D')\n\noil = oil.astype(np.float32)\n\n# Transform\noil_filler = MissingValuesFiller(verbose=False, n_jobs=-1, name=\"Filler\")\noil_scaler = Scaler(verbose=False, n_jobs=-1, name=\"Scaler\")\noil_pipeline = Pipeline([oil_filler, oil_scaler])\noil_transformed = oil_pipeline.fit_transform(oil)\n\n# Moving Averages for Oil Price\noil_moving_average_7 = MovingAverageFilter(window=7)\noil_moving_average_28 = MovingAverageFilter(window=28)\n\noil_moving_averages = []\nma_7 = oil_moving_average_7.filter(oil_transformed).astype(np.float32)\nma_7 = ma_7.with_columns_renamed(col_names=ma_7.components, col_names_new='oil_ma_7')\nma_28 = oil_moving_average_28.filter(oil_transformed).astype(np.float32)\nma_28 = ma_28.with_columns_renamed(col_names=ma_28.components, col_names_new='oil_ma_28')\noil_moving_averages = ma_7.stack(ma_28)","metadata":{"execution":{"iopub.status.busy":"2023-10-15T11:15:20.442049Z","iopub.execute_input":"2023-10-15T11:15:20.44266Z","iopub.status.idle":"2023-10-15T11:15:20.52815Z","shell.execute_reply.started":"2023-10-15T11:15:20.442602Z","shell.execute_reply":"2023-10-15T11:15:20.527049Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def holiday_list(df_stores):\n\n    listofseries = []\n    \n    for i in range(0,len(df_stores)):        \n            df_holiday_dummies = pd.DataFrame(columns=['date'])\n            df_holiday_dummies[\"date\"] = df_holidays_events[\"date\"]\n    \n            df_holiday_dummies[\"national_holiday\"] = np.where(((df_holidays_events[\"type\"] == \"Holiday\") & (df_holidays_events[\"locale\"] == \"National\")), 1, 0)\n\n            df_holiday_dummies[\"earthquake_relief\"] = np.where(df_holidays_events['description'].str.contains('Terremoto Manabi'), 1, 0)\n\n            df_holiday_dummies[\"christmas\"] = np.where(df_holidays_events['description'].str.contains('Navidad'), 1, 0)\n\n            df_holiday_dummies[\"football_event\"] = np.where(df_holidays_events['description'].str.contains('futbol'), 1, 0)\n\n            df_holiday_dummies[\"national_event\"] = np.where(((df_holidays_events[\"type\"] == \"Event\") & (df_holidays_events[\"locale\"] == \"National\") & (~df_holidays_events['description'].str.contains('Terremoto Manabi')) & (~df_holidays_events['description'].str.contains('futbol'))), 1, 0)\n\n            df_holiday_dummies[\"work_day\"] = np.where((df_holidays_events[\"type\"] == \"Work Day\"), 1, 0)\n\n            df_holiday_dummies[\"local_holiday\"] = np.where(((df_holidays_events[\"type\"] == \"Holiday\") & ((df_holidays_events[\"locale_name\"] == df_stores['state'][i]) | (df_holidays_events[\"locale_name\"] == df_stores['city'][i]))), 1, 0)\n                     \n            listofseries.append(df_holiday_dummies)\n\n    return listofseries","metadata":{"execution":{"iopub.status.busy":"2023-10-15T11:15:20.529483Z","iopub.execute_input":"2023-10-15T11:15:20.530041Z","iopub.status.idle":"2023-10-15T11:15:20.539612Z","shell.execute_reply.started":"2023-10-15T11:15:20.530006Z","shell.execute_reply":"2023-10-15T11:15:20.538375Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def remove_0_and_duplicates(holiday_list):\n\n    listofseries = []\n    \n    for i in range(0,len(holiday_list)):         \n            df_holiday_per_store = list_of_holidays_per_store[i].set_index('date')\n\n            df_holiday_per_store = df_holiday_per_store.loc[~(df_holiday_per_store==0).all(axis=1)]\n            \n            df_holiday_per_store = df_holiday_per_store.groupby('date').agg({'national_holiday':'max', 'earthquake_relief':'max', \n                                   'christmas':'max', 'football_event':'max', \n                                   'national_event':'max', 'work_day':'max', \n                                   'local_holiday':'max'}).reset_index()\n\n            listofseries.append(df_holiday_per_store)\n\n    return listofseries","metadata":{"execution":{"iopub.status.busy":"2023-10-15T11:15:20.540866Z","iopub.execute_input":"2023-10-15T11:15:20.54121Z","iopub.status.idle":"2023-10-15T11:15:20.556418Z","shell.execute_reply.started":"2023-10-15T11:15:20.541172Z","shell.execute_reply":"2023-10-15T11:15:20.555469Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def holiday_TS_list_54(holiday_list):\n    listofseries = []\n    \n    for i in range(0,54):\n            holidays_TS = TimeSeries.from_dataframe(list_of_holidays_per_store[i], \n                                        time_col = 'date',\n                                        fill_missing_dates=True,\n                                        fillna_value=0,\n                                        freq='D')\n            \n            holidays_TS = holidays_TS.slice(pd.Timestamp('20130101'),pd.Timestamp('20170831'))\n            holidays_TS = holidays_TS.astype(np.float32)\n            listofseries.append(holidays_TS)\n\n    return listofseries","metadata":{"execution":{"iopub.status.busy":"2023-10-15T11:15:20.558056Z","iopub.execute_input":"2023-10-15T11:15:20.559053Z","iopub.status.idle":"2023-10-15T11:15:20.57375Z","shell.execute_reply.started":"2023-10-15T11:15:20.559011Z","shell.execute_reply":"2023-10-15T11:15:20.572738Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"list_of_holidays_per_store = holiday_list(df_stores)\nlist_of_holidays_per_store = remove_0_and_duplicates(list_of_holidays_per_store)\nlist_of_holidays_store = holiday_TS_list_54(list_of_holidays_per_store)\n\nholidays_filler = MissingValuesFiller(verbose=False, n_jobs=-1, name=\"Filler\")\nholidays_scaler = Scaler(verbose=False, n_jobs=-1, name=\"Scaler\")\n\nholidays_pipeline = Pipeline([holidays_filler, holidays_scaler])\nholidays_transformed = holidays_pipeline.fit_transform(list_of_holidays_store)","metadata":{"execution":{"iopub.status.busy":"2023-10-15T11:15:20.575202Z","iopub.execute_input":"2023-10-15T11:15:20.576253Z","iopub.status.idle":"2023-10-15T11:15:22.469674Z","shell.execute_reply.started":"2023-10-15T11:15:20.576212Z","shell.execute_reply":"2023-10-15T11:15:22.468885Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_promotion = pd.concat([df_train, df_test], axis=0)\ndf_promotion = df_promotion.sort_values([\"store_nbr\",\"family\",\"date\"])\ndisplay(df_promotion.tail())\n\nfamily_promotion_dict = {}\n\nfor family in tqdm(family_list):\n    df_family = df_promotion.loc[df_promotion['family'] == family]\n\n    list_of_TS_promo = TimeSeries.from_group_dataframe(\n                                df_family,\n                                time_col=\"date\",\n                                group_cols=[\"store_nbr\",\"family\"],\n                                value_cols=\"onpromotion\",\n                                fill_missing_dates=True,\n                                freq='D')\n\n    for ts in list_of_TS_promo:\n        ts = ts.astype(np.float32)\n\n    family_promotion_dict[family] = list_of_TS_promo","metadata":{"execution":{"iopub.status.busy":"2023-10-15T11:15:22.47077Z","iopub.execute_input":"2023-10-15T11:15:22.471063Z","iopub.status.idle":"2023-10-15T11:15:54.66475Z","shell.execute_reply.started":"2023-10-15T11:15:22.471039Z","shell.execute_reply":"2023-10-15T11:15:54.663519Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"promotion_transformed_dict = {}\n\nfor key in tqdm(family_promotion_dict):\n    promo_filler = MissingValuesFiller(verbose=False, n_jobs=-1, name=\"Fill NAs\")\n    promo_scaler = Scaler(verbose=False, n_jobs=-1, name=\"Scaling\")\n\n    promo_pipeline = Pipeline([promo_filler,\n                             promo_scaler])\n\n    promotion_transformed = promo_pipeline.fit_transform(family_promotion_dict[key])\n\n    # Moving Averages for Promotion Family Dictionaries\n    promo_moving_average_7 = MovingAverageFilter(window=7)\n    promo_moving_average_28 = MovingAverageFilter(window=28)\n\n    promotion_covs = []\n\n    for ts in promotion_transformed:\n        ma_7 = promo_moving_average_7.filter(ts)\n        ma_7 = TimeSeries.from_series(ma_7.pd_series())  \n        ma_7 = ma_7.astype(np.float32)\n        ma_7 = ma_7.with_columns_renamed(col_names=ma_7.components, col_names_new=\"promotion_ma_7\")\n        ma_28 = promo_moving_average_28.filter(ts)\n        ma_28 = TimeSeries.from_series(ma_28.pd_series())  \n        ma_28 = ma_28.astype(np.float32)\n        ma_28 = ma_28.with_columns_renamed(col_names=ma_28.components, col_names_new=\"promotion_ma_28\")\n        promo_and_mas = ts.stack(ma_7).stack(ma_28)\n        promotion_covs.append(promo_and_mas)\n\n    promotion_transformed_dict[key] = promotion_covs","metadata":{"execution":{"iopub.status.busy":"2023-10-15T11:15:54.66611Z","iopub.execute_input":"2023-10-15T11:15:54.666414Z","iopub.status.idle":"2023-10-15T11:17:12.453394Z","shell.execute_reply.started":"2023-10-15T11:15:54.666389Z","shell.execute_reply":"2023-10-15T11:17:12.452183Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"general_covariates = time_cov_transformed.stack(oil_transformed).stack(oil_moving_averages)","metadata":{"execution":{"iopub.status.busy":"2023-10-15T11:17:12.454967Z","iopub.execute_input":"2023-10-15T11:17:12.455403Z","iopub.status.idle":"2023-10-15T11:17:12.470059Z","shell.execute_reply.started":"2023-10-15T11:17:12.455365Z","shell.execute_reply":"2023-10-15T11:17:12.468257Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"store_covariates_future = []\n\nfor store in range(0,len(store_list)):\n    stacked_covariates = holidays_transformed[store].stack(general_covariates)  \n    store_covariates_future.append(stacked_covariates)","metadata":{"execution":{"iopub.status.busy":"2023-10-15T11:17:12.471483Z","iopub.execute_input":"2023-10-15T11:17:12.472094Z","iopub.status.idle":"2023-10-15T11:17:12.611685Z","shell.execute_reply.started":"2023-10-15T11:17:12.472062Z","shell.execute_reply":"2023-10-15T11:17:12.610521Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"future_covariates_dict = {}\n\nfor key in tqdm(promotion_transformed_dict):\n    promotion_family = promotion_transformed_dict[key]\n    covariates_future = [promotion_family[i].stack(store_covariates_future[i]) for i in range(0,len(promotion_family))]\n    future_covariates_dict[key] = covariates_future","metadata":{"execution":{"iopub.status.busy":"2023-10-15T11:17:12.613186Z","iopub.execute_input":"2023-10-15T11:17:12.614011Z","iopub.status.idle":"2023-10-15T11:17:19.062956Z","shell.execute_reply.started":"2023-10-15T11:17:12.61398Z","shell.execute_reply":"2023-10-15T11:17:19.061529Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_transactions.sort_values(['store_nbr','date'], inplace= True)\n\nTS_transactions_list = TimeSeries.from_group_dataframe(\n                                df_transactions,\n                                time_col=\"date\",\n                                group_cols=[\"store_nbr\"],\n                                value_cols=\"transactions\",\n                                fill_missing_dates=True,\n                                freq='D')\n\ntransactions_list = []\n\nfor ts in TS_transactions_list:\n            series = TimeSeries.from_series(ts.pd_series())\n            series = series.astype(np.float32)\n            transactions_list.append(series)\n            \n# as the transactions dataframe have for store_nbr 24 transactions from 01-01-2013 but every store_nbr have data from 02-01-2013\ntransactions_list[24] = transactions_list[24].slice(start_ts=pd.Timestamp('20130102'), end_ts=pd.Timestamp('20170815'))\n\ntransactions_list_full = []\nfor ts in transactions_list:\n    if ts.start_time() > pd.Timestamp('20130101'):\n        end_time = (ts.start_time() - timedelta(days=1))\n        delta = end_time - pd.Timestamp('20130101')\n        zero_series = TimeSeries.from_times_and_values(\n                                  times=pd.date_range(start=pd.Timestamp('20130101'), \n                                  end=end_time, freq=\"D\"),\n                                  values=np.zeros(delta.days+1))\n        ts = zero_series.append(ts)\n        ts = ts.with_columns_renamed(col_names=ts.components, col_names_new=\"transactions\")\n        transactions_list_full.append(ts)\n\ntransactions_filler = MissingValuesFiller(verbose=False, n_jobs=-1, name=\"Filler\")\ntransactions_scaler = Scaler(verbose=False, n_jobs=-1, name=\"Scaler\")\n\ntransactions_pipeline = Pipeline([transactions_filler, transactions_scaler])\ntransactions_transformed = transactions_pipeline.fit_transform(transactions_list_full)","metadata":{"execution":{"iopub.status.busy":"2023-10-15T11:17:19.064677Z","iopub.execute_input":"2023-10-15T11:17:19.065573Z","iopub.status.idle":"2023-10-15T11:17:20.97255Z","shell.execute_reply.started":"2023-10-15T11:17:19.065542Z","shell.execute_reply":"2023-10-15T11:17:20.971702Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_indexes = pd.concat([df_train, df_test])\ndf_indexes = df_indexes.drop(['onpromotion'], axis=1)\ndf_indexes = df_indexes.sort_values(by=['store_nbr', 'family'])\ndf_indexes.date = pd.to_datetime(df_indexes.date)","metadata":{"execution":{"iopub.status.busy":"2023-10-15T11:17:20.973443Z","iopub.execute_input":"2023-10-15T11:17:20.973701Z","iopub.status.idle":"2023-10-15T11:17:22.748738Z","shell.execute_reply.started":"2023-10-15T11:17:20.973678Z","shell.execute_reply":"2023-10-15T11:17:22.747715Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_indexes = df_indexes.set_index('date')","metadata":{"execution":{"iopub.status.busy":"2023-10-15T11:17:22.75051Z","iopub.execute_input":"2023-10-15T11:17:22.751574Z","iopub.status.idle":"2023-10-15T11:17:22.834624Z","shell.execute_reply.started":"2023-10-15T11:17:22.751504Z","shell.execute_reply":"2023-10-15T11:17:22.833382Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"date_range = pd.date_range(start=df_indexes.index.min(), end=df_indexes.index.max(), freq='D')\ndf_indexes_filled = pd.DataFrame(columns=df_indexes.columns)\n\nfor family in tqdm(family_list):\n    for store in store_list:\n        temp_df = df_indexes.iloc[np.where((df_indexes.family == family) & (df_indexes.store_nbr == store))]\n        temp_df = temp_df.reindex(date_range).fillna({'id': np.nan, 'store_nbr': store, 'family': family, 'sales': np.nan})\n        df_indexes_filled = pd.concat([df_indexes, temp_df])\n        \ndf_indexes_filled","metadata":{"execution":{"iopub.status.busy":"2023-10-15T11:17:22.836092Z","iopub.execute_input":"2023-10-15T11:17:22.836446Z","iopub.status.idle":"2023-10-15T11:25:55.341783Z","shell.execute_reply.started":"2023-10-15T11:17:22.836412Z","shell.execute_reply":"2023-10-15T11:25:55.340613Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_indexes_filled.index.name = 'date'\ndf_indexes_filled = df_indexes_filled.reset_index()\ndf_indexes_filled = df_indexes_filled.sort_values(['store_nbr','family'])\ndf_indexes_filled = df_indexes_filled.drop_duplicates()\ndf_indexes_filled","metadata":{"execution":{"iopub.status.busy":"2023-10-15T11:25:55.342811Z","iopub.execute_input":"2023-10-15T11:25:55.343111Z","iopub.status.idle":"2023-10-15T11:25:57.15712Z","shell.execute_reply.started":"2023-10-15T11:25:55.343085Z","shell.execute_reply":"2023-10-15T11:25:57.156038Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"last_train_date = pd.to_datetime(df_train.date.max())","metadata":{"execution":{"iopub.status.busy":"2023-10-15T11:25:57.158792Z","iopub.execute_input":"2023-10-15T11:25:57.159236Z","iopub.status.idle":"2023-10-15T11:25:57.354051Z","shell.execute_reply.started":"2023-10-15T11:25:57.159196Z","shell.execute_reply":"2023-10-15T11:25:57.352965Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import gc","metadata":{"execution":{"iopub.status.busy":"2023-10-15T11:25:57.355476Z","iopub.execute_input":"2023-10-15T11:25:57.355932Z","iopub.status.idle":"2023-10-15T11:25:57.361717Z","shell.execute_reply.started":"2023-10-15T11:25:57.355893Z","shell.execute_reply":"2023-10-15T11:25:57.35995Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"del(df_train)\ndel(df_test)\ndel(df_stores)\ndel(df_holidays_events)\ndel(df_oil)\ndel(df_transactions)\ndel(df_indexes)\ndel(train_merged)\n\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2023-10-15T11:25:57.363181Z","iopub.execute_input":"2023-10-15T11:25:57.364345Z","iopub.status.idle":"2023-10-15T11:25:58.379599Z","shell.execute_reply.started":"2023-10-15T11:25:57.364301Z","shell.execute_reply":"2023-10-15T11:25:58.378557Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from darts.models import LightGBMModel","metadata":{"execution":{"iopub.status.busy":"2023-10-15T11:25:58.380952Z","iopub.execute_input":"2023-10-15T11:25:58.381256Z","iopub.status.idle":"2023-10-15T11:25:58.385855Z","shell.execute_reply.started":"2023-10-15T11:25:58.38123Z","shell.execute_reply":"2023-10-15T11:25:58.384657Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def lgbm_predictions(model_params, val_df_size = 0):\n    l_train_date = last_train_date - np.timedelta64(val_df_size, 'D')\n    local_df_indexes = df_indexes_filled.iloc[np.where(df_indexes_filled.date > l_train_date)]\n    \n    submission_kaggle_list = []    \n    cnt = 1\n    \n    for params in model_params:\n        LGBM_Models_Submission = {}\n        display(\"Training...\")\n            \n        # Fit Model\n        print(f'Start fit model {cnt}')\n        for family in tqdm(family_list):    \n            sales_family = family_TS_transformed_dict[family]\n            # training_data: represents the number of sales in the training sample minus the sales for the val\n            training_data = [ts[:1688-val_df_size] for ts in sales_family]\n            # TCN_covariates: represents the future covariates associated with the target product family\n            TCN_covariates = future_covariates_dict[family]\n            # train_sliced: represents the number of sales associated with the target product family.\n            # slice_intersect: function that you can see used simply ensures that the components span the same time interval. \n            # In the case of different time intervals an error message will appear if we try to combine them.\n            train_sliced = [training_data[i].slice_intersect(TCN_covariates[i]) for i in range(0,len(training_data))]\n            \n\n            LGBM_Model_Submission = LightGBMModel(lags = params[\"lags\"],\n                                                  lags_future_covariates = params[\"lags_future_covariates\"],\n                                                  lags_past_covariates = params[\"lags_past_covariates\"],\n                                                  output_chunk_length=1,\n                                                  random_state=2022,\n                                                  gpu_use_dp= \"false\")\n\n\n            LGBM_Model_Submission.fit(series=train_sliced, \n                                  future_covariates=TCN_covariates,\n                                  # transactions_transformed: the past covariates do not need to be indexed on the target \n                                  # family because there is only one global `TimeSeries` per store.\n                                  past_covariates=transactions_transformed)\n\n            LGBM_Models_Submission[family] = LGBM_Model_Submission\n\n        display(\"Predictions...\")\n        LGBM_Forecasts_Families_Submission = {}\n\n        # Predict\n        print(f'Start predict model {cnt}')\n        for family in tqdm(family_list):\n            sales_family = family_TS_transformed_dict[family]\n            training_data = [ts[:1688-val_df_size] for ts in sales_family]\n            LGBM_covariates = future_covariates_dict[family]\n            train_sliced = [training_data[i].slice_intersect(TCN_covariates[i]) for i in range(0,len(training_data))]\n\n            forecast_LGBM = LGBM_Models_Submission[family].predict(\n                                                  n = 16 + val_df_size,\n                                                  series=train_sliced,\n                                                  future_covariates=LGBM_covariates,\n                                                  past_covariates=transactions_transformed\n                                                 )\n\n            LGBM_Forecasts_Families_Submission[family] = forecast_LGBM\n\n        # Transform Back\n        print(f'Start transform Back {cnt}')\n        LGBM_Forecasts_Families_back_Submission = {}\n\n        for family in tqdm(family_list):\n            LGBM_Forecasts_Families_back_Submission[family] = family_pipeline_dict[family].inverse_transform(LGBM_Forecasts_Families_Submission[family], partial=True)\n        print(f'Start Prepare Submission {cnt}')\n        for family in tqdm(LGBM_Forecasts_Families_back_Submission):\n            for n in range(0,len(LGBM_Forecasts_Families_back_Submission[family])):\n                if (family_TS_dict[family][n].univariate_values()[-21:] == 0).all():\n                    LGBM_Forecasts_Families_back_Submission[family][n] = LGBM_Forecasts_Families_back_Submission[family][n].map(lambda x: x * 0)\n\n        listofseries = []\n\n        for store in tqdm(range(0,54)):\n            for family in family_list:\n                oneforecast = LGBM_Forecasts_Families_back_Submission[family][store].pd_dataframe()\n                oneforecast.columns = ['y_pred']\n                listofseries.append(oneforecast)\n\n        df_forecasts = pd.concat(listofseries) \n        df_forecasts.reset_index(drop=True, inplace=True)\n\n        # No Negative Forecasts\n        print(f'Start No Negative Forecasts {cnt}')\n        df_forecasts[df_forecasts < 0] = 0\n        forecasts_kaggle = pd.concat([local_df_indexes['id'], df_forecasts.set_index(local_df_indexes.index)], axis=1)\n        forecasts_kaggle = forecasts_kaggle.reset_index(drop=True)\n\n        # Submission\n        print(f'Start Submission {cnt}')\n        submission_kaggle_list.append(forecasts_kaggle)\n        cnt += 1\n    \n    return submission_kaggle_list, local_df_indexes","metadata":{"execution":{"iopub.status.busy":"2023-10-15T11:25:58.388439Z","iopub.execute_input":"2023-10-15T11:25:58.388911Z","iopub.status.idle":"2023-10-15T11:25:58.40635Z","shell.execute_reply.started":"2023-10-15T11:25:58.38884Z","shell.execute_reply":"2023-10-15T11:25:58.405133Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_params = [\n    {\"lags\" : 63, \"lags_future_covariates\" : (14,1), \"lags_past_covariates\" : [-16,-17,-18,-19,-20,-21,-22]},\n    {\"lags\" : 7, \"lags_future_covariates\" : (16,1), \"lags_past_covariates\" : [-16,-17,-18,-19,-20,-21,-22]},  \n    {\"lags\" : 31, \"lags_future_covariates\" : (14,1), \"lags_past_covariates\" : [-16,-17,-18,-19,-20,-21,-22]},\n    {\"lags\" : 365, \"lags_future_covariates\" : (14,1), \"lags_past_covariates\" : [-16,-17,-18,-19,-20,-21,-22]}, \n    {\"lags\" : 730, \"lags_future_covariates\" : (14,1), \"lags_past_covariates\" : [-16,-17,-18,-19,-20,-21,-22]}, \n    {\"lags\" : 1095, \"lags_future_covariates\" : (14,1), \"lags_past_covariates\" : [-16,-17,-18,-19,-20,-21,-22]}\n]","metadata":{"execution":{"iopub.status.busy":"2023-10-15T11:25:58.408549Z","iopub.execute_input":"2023-10-15T11:25:58.409037Z","iopub.status.idle":"2023-10-15T11:25:58.423149Z","shell.execute_reply.started":"2023-10-15T11:25:58.408995Z","shell.execute_reply":"2023-10-15T11:25:58.42178Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission_kaggle_list, clipped_indexes = lgbm_predictions(model_params)","metadata":{"execution":{"iopub.status.busy":"2023-10-15T11:25:58.425929Z","iopub.execute_input":"2023-10-15T11:25:58.426323Z","iopub.status.idle":"2023-10-15T12:23:20.656553Z","shell.execute_reply.started":"2023-10-15T11:25:58.426295Z","shell.execute_reply":"2023-10-15T12:23:20.654698Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submissions = submission_kaggle_list[0].copy()\nsubmissions = submissions.rename(columns={'y_pred': 'y_pred_0'})\n\nif len(submission_kaggle_list) > 1:\n    for i in range(1, len(submission_kaggle_list)):\n        y_pred = submission_kaggle_list[i]\n        y_pred = y_pred.rename(columns={'y_pred': f'y_pred_{i}'})\n        submissions = pd.concat([submissions, y_pred.drop(['id'], axis=1)], axis=1)\n\nsubmissions['sales'] = submissions.loc[:, submissions.columns!='id'].mean(axis=1)\nsubmissions.head()","metadata":{"execution":{"iopub.status.busy":"2023-10-15T12:23:20.665375Z","iopub.execute_input":"2023-10-15T12:23:20.665786Z","iopub.status.idle":"2023-10-15T12:23:20.70946Z","shell.execute_reply.started":"2023-10-15T12:23:20.665749Z","shell.execute_reply":"2023-10-15T12:23:20.707914Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission = submissions[['id', 'sales']]\nsubmission = submission.sort_values('id')\nsubmission.id = submission.id.astype('int32')\nsubmission.head()","metadata":{"execution":{"iopub.status.busy":"2023-10-15T12:23:20.710791Z","iopub.execute_input":"2023-10-15T12:23:20.711153Z","iopub.status.idle":"2023-10-15T12:23:20.727633Z","shell.execute_reply.started":"2023-10-15T12:23:20.711125Z","shell.execute_reply":"2023-10-15T12:23:20.726213Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission.to_csv('/kaggle/working/submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2023-10-15T12:23:20.729498Z","iopub.execute_input":"2023-10-15T12:23:20.72985Z","iopub.status.idle":"2023-10-15T12:23:20.814815Z","shell.execute_reply.started":"2023-10-15T12:23:20.729807Z","shell.execute_reply":"2023-10-15T12:23:20.81369Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}