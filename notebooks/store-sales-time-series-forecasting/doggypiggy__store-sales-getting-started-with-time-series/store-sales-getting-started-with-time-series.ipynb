{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Store Sales - Getting Started with Time Series\n\n#### Thanks for checking out my Notebook! Feel free to copy and edit on you own : )\n\n#### Getting started with Time Series might seem *overwhelming* with so many new concepts.\n\n#### I made this notebook to illustarte a simple work flow for solving a typical Time Series problem.\n\n#### The solution is mostly taken from [Andrej Marinchenko](https://www.kaggle.com/code/andrej0marinchenko/hyperparamaters), [BIZEN](https://www.kaggle.com/code/hiro5299834/store-sales-ridge-voting-bagging-et-bagging-rf), and [KDJ2020](https://www.kaggle.com/code/dkomyagin/simple-ts-ridge-rf/notebook).\n\n#### I clenaed up their code and reformated some plots to make the notebook shorter and easier to read.\n\n#### If it's helpful to your learning process, please upvote so that more people can see it.\n\n#### All comments and feedbacks are welcome!\n\n#### If you need more explanations about some theories, feel free to check out this [Kaggle Course](https://www.kaggle.com/learn/time-series).\n\n#### Note: it will take a bit more than 30 minutes to run the entire notebook.","metadata":{}},{"cell_type":"markdown","source":"# Setting Things Up","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom matplotlib import pyplot as plt, rcParams, style\nimport seaborn as sns\nfrom plotly import express as px, graph_objects as go\nrcParams['figure.figsize'] = (10, 6)\n\nfrom statsmodels.tsa.deterministic import DeterministicProcess, CalendarFourier\nfrom statsmodels.graphics.tsaplots import plot_pacf\nfrom sklearn.preprocessing import RobustScaler, StandardScaler, Normalizer, MinMaxScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression, Ridge\nfrom sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor, BaggingRegressor\n\nimport gc\ngc.enable()\nfrom warnings import filterwarnings, simplefilter\nfilterwarnings('ignore')\nsimplefilter('ignore')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-08-20T17:27:59.661036Z","iopub.execute_input":"2022-08-20T17:27:59.661434Z","iopub.status.idle":"2022-08-20T17:27:59.668785Z","shell.execute_reply.started":"2022-08-20T17:27:59.661395Z","shell.execute_reply":"2022-08-20T17:27:59.668157Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Train and Test Data","metadata":{}},{"cell_type":"code","source":"train = pd.read_csv('../input/store-sales-time-series-forecasting/train.csv',\n                    parse_dates = ['date'], infer_datetime_format = True,\n                    dtype = {'store_nbr' : 'category',\n                             'family' : 'category'},\n                   usecols = ['date', 'store_nbr', 'family', 'sales'])\n\ntrain['date'] = train.date.dt.to_period('D')\ntrain = train.set_index(['date', 'store_nbr', 'family']).sort_index()\ntrain.head()","metadata":{"execution":{"iopub.status.busy":"2022-08-20T17:28:02.281997Z","iopub.execute_input":"2022-08-20T17:28:02.282399Z","iopub.status.idle":"2022-08-20T17:28:05.529897Z","shell.execute_reply.started":"2022-08-20T17:28:02.28237Z","shell.execute_reply":"2022-08-20T17:28:05.529031Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test = pd.read_csv('../input/store-sales-time-series-forecasting/test.csv',\n                   parse_dates = ['date'], infer_datetime_format = True)\ntest['date'] = test.date.dt.to_period('D')\ntest = test.set_index(['date', 'store_nbr', 'family']).sort_values('id')\ntest.head()","metadata":{"execution":{"iopub.status.busy":"2022-08-20T17:28:05.531291Z","iopub.execute_input":"2022-08-20T17:28:05.531505Z","iopub.status.idle":"2022-08-20T17:28:05.573443Z","shell.execute_reply.started":"2022-08-20T17:28:05.531479Z","shell.execute_reply":"2022-08-20T17:28:05.572816Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Oil Data","metadata":{}},{"cell_type":"code","source":"# Using the full date range\ncalendar = pd.DataFrame(index = pd.date_range('2013-01-01', '2017-08-31')).to_period('D')\noil = pd.read_csv('../input/store-sales-time-series-forecasting/oil.csv',\n                  parse_dates = ['date'], infer_datetime_format = True,\n                  index_col = 'date').to_period('D')\noil['avg_oil'] = oil['dcoilwtico'].rolling(7).mean()\ncalendar = calendar.join(oil.avg_oil)\ncalendar['avg_oil'].fillna(method = 'ffill', inplace = True)\ncalendar.dropna(inplace = True)\ncalendar.head()","metadata":{"execution":{"iopub.status.busy":"2022-08-20T17:28:07.4072Z","iopub.execute_input":"2022-08-20T17:28:07.407519Z","iopub.status.idle":"2022-08-20T17:28:07.431899Z","shell.execute_reply.started":"2022-08-20T17:28:07.407487Z","shell.execute_reply":"2022-08-20T17:28:07.431362Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plotting oil price\n_ = sns.lineplot(data = oil.dcoilwtico.to_timestamp())","metadata":{"execution":{"iopub.status.busy":"2022-08-20T17:28:09.449113Z","iopub.execute_input":"2022-08-20T17:28:09.449687Z","iopub.status.idle":"2022-08-20T17:28:09.883922Z","shell.execute_reply.started":"2022-08-20T17:28:09.44964Z","shell.execute_reply":"2022-08-20T17:28:09.883076Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plotting the partial autocorrelation function\n_ = plot_pacf(calendar.avg_oil, lags = 12)","metadata":{"execution":{"iopub.status.busy":"2022-08-20T17:28:09.966868Z","iopub.execute_input":"2022-08-20T17:28:09.967209Z","iopub.status.idle":"2022-08-20T17:28:10.265269Z","shell.execute_reply.started":"2022-08-20T17:28:09.967157Z","shell.execute_reply":"2022-08-20T17:28:10.26451Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Adding lages based on the auto correlation plot above (up to 5 will be reasonable)\nn_lags = 3\nfor l in range(1, n_lags + 1) :\n    calendar[f'oil_lags_{l}'] = calendar.avg_oil.shift(l)\ncalendar.dropna(inplace = True)\ncalendar.head()","metadata":{"execution":{"iopub.status.busy":"2022-08-20T17:28:13.230519Z","iopub.execute_input":"2022-08-20T17:28:13.23112Z","iopub.status.idle":"2022-08-20T17:28:13.269324Z","shell.execute_reply.started":"2022-08-20T17:28:13.231087Z","shell.execute_reply":"2022-08-20T17:28:13.268509Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Checking the correlation plot with different lags\nlag1, lag2, lag3 = 'oil_lags_1', 'oil_lags_2', 'oil_lags_3'\n\nfig = plt.figure(figsize=(18,6))\nplt.subplot(1,3,1)\nsns.regplot(x = calendar[lag1], y = calendar.avg_oil)\nplt.title(f'corr {calendar.avg_oil.corr(calendar[lag1])}')\nplt.subplot(1,3,2)\nsns.regplot(x = calendar[lag2], y = calendar.avg_oil)\nplt.title(f'corr {calendar.avg_oil.corr(calendar[lag2])}')\nplt.subplot(1,3,3)\nsns.regplot(x = calendar[lag3], y = calendar.avg_oil)\nplt.title(f'corr {calendar.avg_oil.corr(calendar[lag3])}');","metadata":{"execution":{"iopub.status.busy":"2022-08-20T17:28:14.843168Z","iopub.execute_input":"2022-08-20T17:28:14.843761Z","iopub.status.idle":"2022-08-20T17:28:16.278792Z","shell.execute_reply.started":"2022-08-20T17:28:14.843723Z","shell.execute_reply":"2022-08-20T17:28:16.277718Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Holiday Data","metadata":{}},{"cell_type":"code","source":"hol = pd.read_csv('../input/store-sales-time-series-forecasting/holidays_events.csv',\n                  parse_dates = ['date'], infer_datetime_format = True,\n                  index_col = 'date').to_period('D')\nhol = hol[hol.locale == 'National'] # Only taking National holiday so there's no false positive.\nhol = hol.groupby(hol.index).first() # Removing duplicated holiday at the same date\nhol.head()","metadata":{"execution":{"iopub.status.busy":"2022-08-20T17:28:18.447651Z","iopub.execute_input":"2022-08-20T17:28:18.447961Z","iopub.status.idle":"2022-08-20T17:28:18.471586Z","shell.execute_reply.started":"2022-08-20T17:28:18.447931Z","shell.execute_reply":"2022-08-20T17:28:18.471109Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Feature Engineering\ncalendar = calendar.join(hol) # Joining calendar with holiday dataset\ncalendar['dofw'] = calendar.index.dayofweek # Weekly day\ncalendar['wd'] = 1\ncalendar.loc[calendar.dofw > 4, 'wd'] = 0 # If it's saturday or sunday then it's not workday\ncalendar.loc[calendar.type == 'Work Day', 'wd'] = 1 # If it's Work Day event then it's a workday\ncalendar.loc[calendar.type == 'Transfer', 'wd'] = 0 # If it's Transfer event then it's not a workday\ncalendar.loc[calendar.type == 'Bridge', 'wd'] = 0 # If it's Bridge event then it's not a workday\ncalendar.loc[(calendar.type == 'Holiday') & (calendar.transferred == False), 'wd'] = 0 # If it's holiday and the holiday is not transferred then it's holiday\ncalendar.loc[(calendar.type == 'Holiday') & (calendar.transferred == True), 'wd'] = 1 # If it's holiday and transferred then it's not holiday\ncalendar = pd.get_dummies(calendar, columns = ['dofw'], drop_first = True) # One-hot encoding (Make sure to drop one of the columns by 'drop_first = True')\ncalendar = pd.get_dummies(calendar, columns = ['type']) # One-hot encoding for type holiday (No need to drop one of the columns because there's a \"No holiday\" already)\ncalendar.drop(['locale', 'locale_name', 'description', 'transferred'], axis = 1, inplace = True) # Unused columns\ncalendar.head()","metadata":{"execution":{"iopub.status.busy":"2022-08-20T17:28:20.197247Z","iopub.execute_input":"2022-08-20T17:28:20.197711Z","iopub.status.idle":"2022-08-20T17:28:20.233861Z","shell.execute_reply.started":"2022-08-20T17:28:20.197669Z","shell.execute_reply":"2022-08-20T17:28:20.233267Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Visualization - Sales of Each Product","metadata":{}},{"cell_type":"code","source":"y = train.unstack(['store_nbr', 'family']).loc['2013':'2017']\nfamily = {c[2] for c in train.index}\nfor f in family :\n    ax = y.loc(axis = 1)['sales', :, f].plot(legend = None)\n    ax.set_title(f)","metadata":{"execution":{"iopub.status.busy":"2022-08-20T17:28:22.872484Z","iopub.execute_input":"2022-08-20T17:28:22.873106Z","iopub.status.idle":"2022-08-20T17:29:05.2445Z","shell.execute_reply.started":"2022-08-20T17:28:22.873072Z","shell.execute_reply":"2022-08-20T17:29:05.243639Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Defining the Training Date","metadata":{}},{"cell_type":"code","source":"# Start and end of training date (based on plots above)\nsdate = '2017-04-30' \nedate = '2017-08-15'","metadata":{"execution":{"iopub.status.busy":"2022-08-20T17:29:15.145518Z","iopub.execute_input":"2022-08-20T17:29:15.145853Z","iopub.status.idle":"2022-08-20T17:29:15.149633Z","shell.execute_reply.started":"2022-08-20T17:29:15.145817Z","shell.execute_reply":"2022-08-20T17:29:15.148845Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Adding a feature for school fluctuations\nschool_season = [] \nfor i, r in calendar.iterrows() :\n    if i.month in [4, 5, 8, 9] :\n        school_season.append(1)\n    else :\n        school_season.append(0)\ncalendar['school_season'] = school_season\ncalendar.head()","metadata":{"execution":{"iopub.status.busy":"2022-08-20T17:29:23.502403Z","iopub.execute_input":"2022-08-20T17:29:23.502682Z","iopub.status.idle":"2022-08-20T17:29:23.592701Z","shell.execute_reply.started":"2022-08-20T17:29:23.502656Z","shell.execute_reply":"2022-08-20T17:29:23.591884Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Deterministic Process","metadata":{}},{"cell_type":"code","source":"y = train.unstack(['store_nbr', 'family']).loc[sdate:edate]\nfourier = CalendarFourier(freq = 'W', order = 3)\ndp = DeterministicProcess(index = y.index,\n                          order = 1,\n                          seasonal = False,\n                          constant = False,\n                          additional_terms = [fourier],\n                          drop = True)\nx = dp.in_sample()\nx = x.join(calendar)\nx.head()","metadata":{"execution":{"iopub.status.busy":"2022-08-20T17:29:26.811825Z","iopub.execute_input":"2022-08-20T17:29:26.812105Z","iopub.status.idle":"2022-08-20T17:29:27.548332Z","shell.execute_reply.started":"2022-08-20T17:29:26.812078Z","shell.execute_reply":"2022-08-20T17:29:27.547612Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Predicting for the next 16 days\nx_test = dp.out_of_sample(steps = 16)\nx_test = x_test.join(calendar)\nx_test.head()","metadata":{"execution":{"iopub.status.busy":"2022-08-20T17:29:29.846255Z","iopub.execute_input":"2022-08-20T17:29:29.846538Z","iopub.status.idle":"2022-08-20T17:29:29.87529Z","shell.execute_reply.started":"2022-08-20T17:29:29.846507Z","shell.execute_reply":"2022-08-20T17:29:29.87464Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Linear and SVR Model","metadata":{}},{"cell_type":"code","source":"# Using LinearRegression and SVR to make a generalized line\nfrom joblib import Parallel, delayed\nfrom tqdm.auto import tqdm\nfrom sklearn.metrics import mean_squared_log_error as msle\nfrom sklearn.model_selection import TimeSeriesSplit\nfrom sklearn.svm import SVR\nfrom sklearn.multioutput import MultiOutputRegressor\nfrom sklearn.metrics import mean_absolute_error as mae\n\nlnr = LinearRegression(fit_intercept = True, n_jobs = -1, normalize = True)\nlnr.fit(x, y)\n\nyfit_lnr = pd.DataFrame(lnr.predict(x), index = x.index, columns = y.columns).clip(0.)\nypred_lnr = pd.DataFrame(lnr.predict(x_test), index = x_test.index, columns = y.columns).clip(0.)\n\nsvr = MultiOutputRegressor(SVR(C = 0.2, kernel = 'rbf'), n_jobs = -1)\nsvr.fit(x, y)\n\nyfit_svr = pd.DataFrame(svr.predict(x), index = x.index, columns = y.columns).clip(0.)\nypred_svr = pd.DataFrame(svr.predict(x_test), index = x_test.index, columns = y.columns).clip(0.)\n\nyfit_mean = pd.DataFrame(np.mean([yfit_svr.values, yfit_lnr.values], axis = 0), index = x.index, columns = y.columns).clip(0.)\nypred_mean = pd.DataFrame(np.mean([ypred_lnr.values, ypred_svr.values], axis = 0), index = x_test.index, columns = y.columns).clip(0.)\n\ny_ = y.stack(['store_nbr', 'family'])\ny_['lnr'] = yfit_lnr.stack(['store_nbr', 'family'])['sales']\ny_['svr'] = yfit_svr.stack(['store_nbr', 'family'])['sales']\ny_['mean'] = yfit_mean.stack(['store_nbr', 'family'])['sales']\n\nprint('LNR RMSLE :', np.sqrt(msle(y, yfit_lnr)))\nprint('SVR RMSLE :', np.sqrt(msle(y, yfit_svr)))\nprint('Mean RMSLE :', np.sqrt(msle(y, yfit_mean)),'\\n')\n\nprint('LNR MAE :', mae(y, yfit_lnr))\nprint('SVR MAE :', mae(y, yfit_svr))\nprint('Mean MAE :', mae(y, yfit_mean))","metadata":{"execution":{"iopub.status.busy":"2022-08-20T17:29:38.03423Z","iopub.execute_input":"2022-08-20T17:29:38.034695Z","iopub.status.idle":"2022-08-20T17:29:44.998714Z","shell.execute_reply.started":"2022-08-20T17:29:38.034656Z","shell.execute_reply":"2022-08-20T17:29:44.997583Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Concatenating linear regression's prediction with the training data (blending)\nymean = yfit_lnr.append(ypred_lnr)\nschool = ymean.loc(axis = 1)['sales', :, 'SCHOOL AND OFFICE SUPPLIES']\nymean = ymean.join(school.shift(1), rsuffix = 'lag1') # I'm also adding school lag for its yearly cycle.\nx = x.loc['2017-05-01':]\nx = x.join(ymean) # Concatenating linear result\nx_test = x_test.join(ymean)\ny = y.loc['2017-05-01':]","metadata":{"execution":{"iopub.status.busy":"2022-08-20T17:19:48.19887Z","iopub.execute_input":"2022-08-20T17:19:48.199139Z","iopub.status.idle":"2022-08-20T17:19:48.271435Z","shell.execute_reply.started":"2022-08-20T17:19:48.19911Z","shell.execute_reply":"2022-08-20T17:19:48.270621Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Final Model","metadata":{}},{"cell_type":"code","source":"from joblib import Parallel, delayed\nimport warnings\n\n# Import necessary library\nfrom sklearn.linear_model import Ridge, LinearRegression, ElasticNet\nfrom sklearn.svm import SVR\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.ensemble import ExtraTreesRegressor\nfrom sklearn.ensemble import BaggingRegressor\nfrom sklearn.ensemble import VotingRegressor\n\n# SEED for reproducible result\nSEED = 5\n\nclass CustomRegressor():\n    \n    def __init__(self, n_jobs=-1, verbose=0):\n        \n        self.n_jobs = n_jobs\n        self.verbose = verbose\n        \n        self.estimators_ = None\n        \n    def _estimator_(self, X, y):\n    \n        warnings.simplefilter(action='ignore', category=FutureWarning)\n        \n        if y.name[2] == 'SCHOOL AND OFFICE SUPPLIES': # SCHOOL AND OFFICE SUPPLIES has weird trend, we use decision tree instead.\n            r1 = ExtraTreesRegressor(n_estimators = 225, n_jobs=-1, random_state=SEED)\n            r2 = RandomForestRegressor(n_estimators = 225, n_jobs=-1, random_state=SEED)\n            b1 = BaggingRegressor(base_estimator=r1,\n                                  n_estimators=10,\n                                  n_jobs=-1,\n                                  random_state=SEED)\n            b2 = BaggingRegressor(base_estimator=r2,\n                                  n_estimators=10,\n                                  n_jobs=-1,\n                                  random_state=SEED)\n            model = VotingRegressor([('et', b1), ('rf', b2)]) # Averaging the result\n        else:\n            ridge = Ridge(fit_intercept=True, solver='auto', alpha=0.75, normalize=True, random_state=SEED)\n            svr = SVR(C = 0.2, kernel = 'rbf')\n            \n            model = VotingRegressor([('ridge', ridge), ('svr', svr)]) # Averaging result\n        model.fit(X, y)\n\n        return model\n\n    def fit(self, X, y):\n        from tqdm.auto import tqdm\n        \n        \n        if self.verbose == 0 :\n            self.estimators_ = Parallel(n_jobs=self.n_jobs, \n                                  verbose=0,\n                                  )(delayed(self._estimator_)(X, y.iloc[:, i]) for i in range(y.shape[1]))\n        else :\n            print('Fit Progress')\n            self.estimators_ = Parallel(n_jobs=self.n_jobs, \n                                  verbose=0,\n                                  )(delayed(self._estimator_)(X, y.iloc[:, i]) for i in tqdm(range(y.shape[1])))\n        return\n    \n    def predict(self, X):\n        from tqdm.auto import tqdm\n        if self.verbose == 0 :\n            y_pred = Parallel(n_jobs=self.n_jobs, \n                              verbose=0)(delayed(e.predict)(X) for e in self.estimators_)\n        else :\n            print('Predict Progress')\n            y_pred = Parallel(n_jobs=self.n_jobs, \n                              verbose=0)(delayed(e.predict)(X) for e in tqdm(self.estimators_))\n        \n        return np.stack(y_pred, axis=1)","metadata":{"execution":{"iopub.status.busy":"2022-08-16T00:52:36.496967Z","iopub.execute_input":"2022-08-16T00:52:36.497871Z","iopub.status.idle":"2022-08-16T00:52:36.514492Z","shell.execute_reply.started":"2022-08-16T00:52:36.497828Z","shell.execute_reply":"2022-08-16T00:52:36.513721Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nmodel = CustomRegressor(n_jobs=-1, verbose=1)\nmodel.fit(x, y)\ny_pred = pd.DataFrame(model.predict(x), index=x.index, columns=y.columns)","metadata":{"execution":{"iopub.status.busy":"2022-08-16T00:52:37.979092Z","iopub.execute_input":"2022-08-16T00:52:37.979702Z","iopub.status.idle":"2022-08-16T00:53:29.939898Z","shell.execute_reply.started":"2022-08-16T00:52:37.979658Z","shell.execute_reply":"2022-08-16T00:53:29.939279Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Evaluation","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import mean_squared_log_error\ny_pred = y_pred.stack(['store_nbr', 'family']).clip(0.)\ny_ = y.stack(['store_nbr', 'family']).clip(0.)\n\ny_['pred'] = y_pred.values\nprint(y_.groupby('family').apply(lambda r : np.sqrt(np.sqrt(mean_squared_log_error(r['sales'], r['pred'])))))\nprint('RMSLE : ', np.sqrt(np.sqrt(msle(y_['sales'], y_['pred']))))","metadata":{"execution":{"iopub.status.busy":"2021-12-23T02:17:39.38475Z","iopub.status.idle":"2021-12-23T02:17:39.385268Z","shell.execute_reply.started":"2021-12-23T02:17:39.384986Z","shell.execute_reply":"2021-12-23T02:17:39.385014Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_sub = pd.DataFrame(model.predict(x_test), index = x_test.index, columns = y.columns).clip(0.)\ny_sub.head()","metadata":{"execution":{"iopub.status.busy":"2021-12-23T02:17:39.388966Z","iopub.status.idle":"2021-12-23T02:17:39.389446Z","shell.execute_reply.started":"2021-12-23T02:17:39.389192Z","shell.execute_reply":"2021-12-23T02:17:39.389217Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_sub = y_sub.stack(['store_nbr', 'family'])\ny_sub.head()","metadata":{"execution":{"iopub.status.busy":"2021-12-23T02:17:39.390808Z","iopub.status.idle":"2021-12-23T02:17:39.391297Z","shell.execute_reply.started":"2021-12-23T02:17:39.391022Z","shell.execute_reply":"2021-12-23T02:17:39.391048Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Submission","metadata":{}},{"cell_type":"code","source":"sub = pd.read_csv('../input/store-sales-time-series-forecasting/sample_submission.csv')\nsub['sales'] = y_sub.values\nsub.head()\nsub.to_csv('submission.csv', index = False)","metadata":{"execution":{"iopub.status.busy":"2021-12-23T02:17:39.392778Z","iopub.status.idle":"2021-12-23T02:17:39.393272Z","shell.execute_reply.started":"2021-12-23T02:17:39.392997Z","shell.execute_reply":"2021-12-23T02:17:39.393021Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Don't forget to submit the result to the contest!\n\n#### Also, please upvote to support my work : )","metadata":{}}]}