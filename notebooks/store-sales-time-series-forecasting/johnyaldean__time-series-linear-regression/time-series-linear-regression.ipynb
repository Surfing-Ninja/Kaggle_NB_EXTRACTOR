{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":29781,"databundleVersionId":2887556,"sourceType":"competition"},{"sourceId":2484624,"sourceType":"datasetVersion","datasetId":1169793},{"sourceId":7453023,"sourceType":"datasetVersion","datasetId":3434640},{"sourceId":7453379,"sourceType":"datasetVersion","datasetId":3516702},{"sourceId":2871499,"sourceType":"datasetVersion","datasetId":1718779},{"sourceId":3023917,"sourceType":"datasetVersion","datasetId":1852008},{"sourceId":3567503,"sourceType":"datasetVersion","datasetId":2143014},{"sourceId":7397307,"sourceType":"datasetVersion","datasetId":4291469},{"sourceId":7453416,"sourceType":"datasetVersion","datasetId":3432334},{"sourceId":1228449,"sourceType":"datasetVersion","datasetId":695144},{"sourceId":4367430,"sourceType":"datasetVersion","datasetId":2568490}],"dockerImageVersionId":30635,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n\ndf = pd.read_csv(\n    \"../input/ts-course-data/book_sales.csv\",\n    index_col='Date',\n    parse_dates=['Date'],\n).drop('Paperback', axis=1)\n\ndf2 = pd.read_csv('/kaggle/input/renewable-power-plants/renewable_power_plants_DK.csv')\n\ndf3 = pd.read_csv('/kaggle/input/national-generation-capacity/national_generation_capacity_stacked.csv')\n\ndf.head()\n\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-01-22T08:00:49.007332Z","iopub.execute_input":"2024-01-22T08:00:49.007828Z","iopub.status.idle":"2024-01-22T08:00:49.502816Z","shell.execute_reply.started":"2024-01-22T08:00:49.007792Z","shell.execute_reply":"2024-01-22T08:00:49.501672Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\n\ndf['Time'] = np.arange(len(df.index))\n\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2024-01-22T08:00:49.505124Z","iopub.execute_input":"2024-01-22T08:00:49.50597Z","iopub.status.idle":"2024-01-22T08:00:49.517888Z","shell.execute_reply.started":"2024-01-22T08:00:49.505924Z","shell.execute_reply":"2024-01-22T08:00:49.516845Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\nplt.style.use(\"seaborn-whitegrid\")\nplt.rc(\n    \"figure\",\n    autolayout=True,\n    figsize=(11, 4),\n    titlesize=18,\n    titleweight='bold',\n)\nplt.rc(\n    \"axes\",\n    labelweight=\"bold\",\n    labelsize=\"large\",\n    titleweight=\"bold\",\n    titlesize=16,\n    titlepad=10,\n)\n%config InlineBackend.figure_format = 'retina'\n\nfig, ax = plt.subplots()\nax.plot('Time', 'Hardcover', data=df, color='0.75')\nax = sns.regplot(x='Time', y='Hardcover', data=df, ci=None, scatter_kws=dict(color='0.25'))\nax.set_title('Time Plot of Hardcover Sales')","metadata":{"execution":{"iopub.status.busy":"2024-01-22T08:00:49.519389Z","iopub.execute_input":"2024-01-22T08:00:49.519751Z","iopub.status.idle":"2024-01-22T08:00:50.361332Z","shell.execute_reply.started":"2024-01-22T08:00:49.519686Z","shell.execute_reply":"2024-01-22T08:00:50.360262Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['Lag_1'] = df['Hardcover'].shift(1)\ndf = df.reindex(columns=['Hardcover', 'Lag_1'])\n\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2024-01-22T08:00:50.363071Z","iopub.execute_input":"2024-01-22T08:00:50.363422Z","iopub.status.idle":"2024-01-22T08:00:50.377836Z","shell.execute_reply.started":"2024-01-22T08:00:50.363383Z","shell.execute_reply":"2024-01-22T08:00:50.376349Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Plot data and a linear regression model fit.","metadata":{}},{"cell_type":"code","source":"fig, ax = plt.subplots()\nax = sns.regplot(x='Lag_1', y='Hardcover', data=df, ci=None, scatter_kws=dict(color='0.25'))\nax.set_aspect('equal')\nax.set_title('Lag Plot of Hardcover Sales');","metadata":{"execution":{"iopub.status.busy":"2024-01-22T08:00:50.380856Z","iopub.execute_input":"2024-01-22T08:00:50.381221Z","iopub.status.idle":"2024-01-22T08:00:51.131589Z","shell.execute_reply.started":"2024-01-22T08:00:50.38119Z","shell.execute_reply":"2024-01-22T08:00:51.130448Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from pathlib import Path\nfrom warnings import simplefilter\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\n\nsimplefilter(\"ignore\")  # ignore warnings to clean up output cells\n\n# Set Matplotlib defaults\nplt.style.use(\"seaborn-whitegrid\")\nplt.rc(\"figure\", autolayout=True, figsize=(11, 4))\nplt.rc(\n    \"axes\",\n    labelweight=\"bold\",\n    labelsize=\"large\",\n    titleweight=\"bold\",\n    titlesize=14,\n    titlepad=10,\n)\nplot_params = dict(\n    color=\"0.75\",\n    style=\".-\",\n    markeredgecolor=\"0.25\",\n    markerfacecolor=\"0.25\",\n    legend=False,\n)\n%config InlineBackend.figure_format = 'retina'\n\n\n# Load Tunnel Traffic dataset\ndata_dir = Path(\"../input/ts-course-data\")\ntunnel = pd.read_csv(data_dir / \"tunnel.csv\", parse_dates=[\"Day\"])\n\n# Create a time series in Pandas by setting the index to a date\n# column. We parsed \"Day\" as a date type by using `parse_dates` when\n# loading the data.\ntunnel = tunnel.set_index(\"Day\")\n\n# By default, Pandas creates a `DatetimeIndex` with dtype `Timestamp`\n# (equivalent to `np.datetime64`, representing a time series as a\n# sequence of measurements taken at single moments. A `PeriodIndex`,\n# on the other hand, represents a time series as a sequence of\n# quantities accumulated over periods of time. Periods are often\n# easier to work with, so that's what we'll use in this course.\ntunnel = tunnel.to_period()\n\ntunnel.head()","metadata":{"execution":{"iopub.status.busy":"2024-01-22T08:00:51.133517Z","iopub.execute_input":"2024-01-22T08:00:51.134005Z","iopub.status.idle":"2024-01-22T08:00:51.166509Z","shell.execute_reply.started":"2024-01-22T08:00:51.133963Z","shell.execute_reply":"2024-01-22T08:00:51.165303Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/load-wind-and-solar-prices-in-hourly-resolution/time_series_15min_singleindex.csv')\ndf.head()\ndf.info()","metadata":{"execution":{"iopub.status.busy":"2024-01-22T08:00:51.16799Z","iopub.execute_input":"2024-01-22T08:00:51.168427Z","iopub.status.idle":"2024-01-22T08:00:53.612311Z","shell.execute_reply.started":"2024-01-22T08:00:51.168395Z","shell.execute_reply":"2024-01-22T08:00:53.61127Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = tunnel.copy()\n\ndf['Time'] = np.arange(len(tunnel.index))\n\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2024-01-22T08:00:53.613545Z","iopub.execute_input":"2024-01-22T08:00:53.613926Z","iopub.status.idle":"2024-01-22T08:00:53.644767Z","shell.execute_reply.started":"2024-01-22T08:00:53.613894Z","shell.execute_reply":"2024-01-22T08:00:53.643541Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"np.arange(len(tunnel.index))","metadata":{"execution":{"iopub.status.busy":"2024-01-22T08:00:53.646317Z","iopub.execute_input":"2024-01-22T08:00:53.646808Z","iopub.status.idle":"2024-01-22T08:00:53.657851Z","shell.execute_reply.started":"2024-01-22T08:00:53.646774Z","shell.execute_reply":"2024-01-22T08:00:53.656753Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.linear_model import LinearRegression\n\n# Training data\nX = df.loc[:, ['Time']]  # features\ny = df.loc[:, 'NumVehicles']  # target\n\n# Train the model\nmodel = LinearRegression()\nmodel.fit(X, y)\n\n# Store the fitted values as a time series with the same time index as\n# the training data\ny_pred = pd.Series(model.predict(X), index=X.index)","metadata":{"execution":{"iopub.status.busy":"2024-01-22T08:00:53.659632Z","iopub.execute_input":"2024-01-22T08:00:53.66036Z","iopub.status.idle":"2024-01-22T08:00:53.675982Z","shell.execute_reply.started":"2024-01-22T08:00:53.660327Z","shell.execute_reply":"2024-01-22T08:00:53.674745Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ax = y.plot(**plot_params)\nax = y_pred.plot(ax=ax, linewidth=3)\nax.set_title('Time Plot of Tunnel Traffic')","metadata":{"execution":{"iopub.status.busy":"2024-01-22T08:00:53.677785Z","iopub.execute_input":"2024-01-22T08:00:53.678239Z","iopub.status.idle":"2024-01-22T08:00:54.573198Z","shell.execute_reply.started":"2024-01-22T08:00:53.678188Z","shell.execute_reply":"2024-01-22T08:00:54.572259Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}