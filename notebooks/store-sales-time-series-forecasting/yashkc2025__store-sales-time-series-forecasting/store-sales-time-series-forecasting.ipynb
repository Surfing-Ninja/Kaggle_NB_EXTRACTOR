{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[]},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":29781,"databundleVersionId":2887556,"sourceType":"competition"}],"dockerImageVersionId":30804,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## üìà Introduction\n\nWelcome to my notebook for the **\"Store Sales - Time Series Forecasting\"** competition on Kaggle!\n\nIn this competition, we're working with sales data from **Corporaci√≥n Favorita**, a large grocery retailer in Ecuador. The task is to build a model that accurately predicts **unit sales** for thousands of items across multiple stores.\n\nThis challenge is a great opportunity to explore **time-series forecasting**, practice working with real-world retail data, and apply machine learning to a problem with real business impact. Accurate forecasts help retailers reduce overstock, minimize food waste, and ensure products are available when customers need them.\n\nThroughout this notebook, I‚Äôll walk through:\n\n- üßπ Data exploration and preprocessing  \n- üß† Feature engineering and modeling  \n- üìä Evaluation and results  \n- ‚úÖ Submission to the competition","metadata":{}},{"cell_type":"markdown","source":"## Import Data","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport plotly.graph_objs as go\nimport seaborn as sns","metadata":{"id":"8SeDtflQFJVk","outputId":"7f17625b-d3e5-40cd-a247-acc7f4a04788","trusted":true,"execution":{"iopub.status.busy":"2025-04-06T12:39:36.658137Z","iopub.execute_input":"2025-04-06T12:39:36.658547Z","iopub.status.idle":"2025-04-06T12:39:37.455588Z","shell.execute_reply.started":"2025-04-06T12:39:36.658512Z","shell.execute_reply":"2025-04-06T12:39:37.454493Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# reading files\ndef read_csv(path):\n    return pd.read_csv(\"/kaggle/input/store-sales-time-series-forecasting/\" + path)\n\ndata_holidays = read_csv(\"holidays_events.csv\")\ndata_oil = read_csv(\"oil.csv\")\ndata_stores = read_csv(\"stores.csv\")\ndata_transactions = read_csv(\"transactions.csv\")\ndata_train = read_csv(\"train.csv\")\ndata_test = read_csv(\"test.csv\")","metadata":{"id":"_wHSlEJXGJyb","trusted":true,"execution":{"iopub.status.busy":"2025-04-06T12:39:10.149344Z","iopub.execute_input":"2025-04-06T12:39:10.149997Z","iopub.status.idle":"2025-04-06T12:39:13.53855Z","shell.execute_reply.started":"2025-04-06T12:39:10.149935Z","shell.execute_reply":"2025-04-06T12:39:13.537507Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# setting up columns to proper date format\ndata_oil['date'] = pd.to_datetime(data_oil['date'])\ndata_holidays['date'] = pd.to_datetime(data_holidays['date'])\ndata_train['date'] = pd.to_datetime(data_train['date'])\ndata_test['date'] = pd.to_datetime(data_test['date'])\ndata_transactions['date'] = pd.to_datetime(data_transactions['date'])\n\n# only keeping rows after 2013-01-01\ndata_train = data_train[data_train['date'] > '2013-01-01']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T12:39:13.539713Z","iopub.execute_input":"2025-04-06T12:39:13.540026Z","iopub.status.idle":"2025-04-06T12:39:14.010429Z","shell.execute_reply.started":"2025-04-06T12:39:13.539987Z","shell.execute_reply":"2025-04-06T12:39:14.009293Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Analysis","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport matplotlib.pyplot as plt\n\n# Prepare KPI data using the correct DataFrame name\nkpi_labels = [\n    'Number of Stores',\n    'Number of Different Products',\n    'Window Start Date',\n    'Window End Date',\n    '# Rows in Training Set',\n    '# Date Points in Train Dataset'\n]\n\nkpi_values = [\n    data_train['store_nbr'].nunique(),\n    data_train['family'].nunique(),\n    str(data_train['date'].min().date()),  # Format date nicely\n    str(data_train['date'].max().date()),\n    f\"{data_train.shape[0]:,}\",  # Comma separator for large numbers\n    data_train['date'].nunique()\n]\n\nkpi_df = pd.DataFrame({'KPI': kpi_labels, 'Value': kpi_values})\n\n# Plotting\nfig, ax = plt.subplots(figsize=(7, 4))\nax.axis('off')\nax.set_title(\"BASIC KPIs of TRAIN DATA\", fontsize=14, fontweight='bold', pad=20)\n\n# Create the table\ntable = ax.table(cellText=kpi_df.values, colLabels=kpi_df.columns, cellLoc='left', loc='center')\n\n# Style the table\ntable.auto_set_font_size(False)\ntable.set_fontsize(11)\ntable.scale(1.2, 1.4)\n\n# Bold header row\nfor (row, col), cell in table.get_celld().items():\n    if row == 0:\n        cell.set_text_props(weight='bold', color='white')\n        cell.set_facecolor('#40466e')\n    else:\n        cell.set_facecolor('#f1f1f2')\n\nplt.tight_layout()\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T12:26:31.052659Z","iopub.execute_input":"2025-04-06T12:26:31.053146Z","iopub.status.idle":"2025-04-06T12:26:31.578321Z","shell.execute_reply.started":"2025-04-06T12:26:31.053105Z","shell.execute_reply":"2025-04-06T12:26:31.576997Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\n# Prepare data\ntrain_aux = data_train[['date', 'sales', 'onpromotion']].groupby('date').mean().reset_index()\n\n# Plot using Matplotlib\nplt.figure(figsize=(12, 6))\nplt.plot(train_aux['date'], train_aux['sales'], color='blue', label='Average Sales')\n\nplt.title('Avg Sales by Date for All Stores and Products')\nplt.xlabel('Date')\nplt.ylabel('Avg Unit Sold')\nplt.xticks(rotation=45)\nplt.tight_layout()\nplt.grid(True)\nplt.legend()\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T12:28:36.601851Z","iopub.execute_input":"2025-04-06T12:28:36.602308Z","iopub.status.idle":"2025-04-06T12:28:37.317089Z","shell.execute_reply.started":"2025-04-06T12:28:36.602268Z","shell.execute_reply":"2025-04-06T12:28:37.315873Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"- Overall, sales show an increasing trend.\n- Over the past two years (since July 2015), the trend has been relatively stable (almost stationary time series).\n- A clear weekly seasonality is present, repeating every 7 days.\n- Sales are consistently higher on weekends, with peaks on Saturdays and Sundays.\n- On January 1st each year, sales drop to zero as supermarkets are closed.\n","metadata":{}},{"cell_type":"markdown","source":"## Sales Distribution","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(10,5))\nplt.hist(data_train['sales'], bins=50, color='skyblue', edgecolor='black')\nplt.title('Sales Distribution')\nplt.xlabel('Sales')\nplt.ylabel('Frequency')\nplt.grid(True)\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T12:33:19.373042Z","iopub.execute_input":"2025-04-06T12:33:19.373539Z","iopub.status.idle":"2025-04-06T12:33:19.827374Z","shell.execute_reply.started":"2025-04-06T12:33:19.373504Z","shell.execute_reply":"2025-04-06T12:33:19.826303Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Store Type Distribution","metadata":{}},{"cell_type":"code","source":"data_stores['type'].value_counts().plot(kind='bar', title='Store Type Distribution', color='purple')\nplt.xlabel('Store Type')\nplt.ylabel('Count')\nplt.grid(True)\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T12:33:59.593403Z","iopub.execute_input":"2025-04-06T12:33:59.593882Z","iopub.status.idle":"2025-04-06T12:33:59.819618Z","shell.execute_reply.started":"2025-04-06T12:33:59.593842Z","shell.execute_reply":"2025-04-06T12:33:59.818204Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Transactions Trend Over Time","metadata":{}},{"cell_type":"code","source":"trans_by_date = data_transactions.groupby('date')['transactions'].sum().reset_index()\n\nplt.figure(figsize=(14,6))\nplt.plot(trans_by_date['date'], trans_by_date['transactions'], color='green')\nplt.title('Total Transactions Over Time')\nplt.xlabel('Date')\nplt.ylabel('Transactions')\nplt.grid(True)\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T12:34:36.023818Z","iopub.execute_input":"2025-04-06T12:34:36.024288Z","iopub.status.idle":"2025-04-06T12:34:36.406862Z","shell.execute_reply.started":"2025-04-06T12:34:36.024244Z","shell.execute_reply":"2025-04-06T12:34:36.405511Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Oil Price Over Time","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(14,6))\nplt.plot(data_oil['date'], data_oil['dcoilwtico'], color='orange')\nplt.title('Oil Prices Over Time')\nplt.xlabel('Date')\nplt.ylabel('Oil Price (WTI)')\nplt.grid(True)\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T12:34:56.327964Z","iopub.execute_input":"2025-04-06T12:34:56.32837Z","iopub.status.idle":"2025-04-06T12:34:56.62531Z","shell.execute_reply.started":"2025-04-06T12:34:56.328338Z","shell.execute_reply":"2025-04-06T12:34:56.624227Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Sales Distribution on Holidays","metadata":{}},{"cell_type":"code","source":"# Ensure datetime\ndata_train['date'] = pd.to_datetime(data_train['date'])\ndata_holidays['date'] = pd.to_datetime(data_holidays['date'])\n\n# Filter only non-transferred holidays\nvalid_holidays = data_holidays[data_holidays['transferred'] == False].copy()\n\n# Aggregate daily sales\ndaily_sales = data_train.groupby('date')['sales'].sum().reset_index()\n\n# Merge holidays into sales\nsales_with_holidays = pd.merge(daily_sales, valid_holidays, on='date', how='left')\nsales_with_holidays['is_holiday'] = sales_with_holidays['type'].notnull()\n\n# Compare average sales: holiday vs non-holiday\navg_sales_comparison = sales_with_holidays.groupby('is_holiday')['sales'].mean()\n\n# Average sales by holiday type\navg_sales_by_type = sales_with_holidays[sales_with_holidays['is_holiday']] \\\n                    .groupby('type')['sales'].mean().sort_values(ascending=False)\n\n# Plotting both charts side by side\nfig, axes = plt.subplots(1, 2, figsize=(14, 6))\n\n# Left: Avg Sales Holiday vs Non-Holiday\naxes[0].bar(['Non-Holiday', 'Holiday'], avg_sales_comparison.values, color=['skyblue', 'salmon'])\naxes[0].set_title('Avg Sales: Holiday vs Non-Holiday')\naxes[0].set_ylabel('Average Sales')\naxes[0].grid(True)\n\n# Right: Avg Sales by Holiday Type\navg_sales_by_type.plot(kind='bar', ax=axes[1], color='teal')\naxes[1].set_title('Avg Sales by Holiday Type')\naxes[1].set_ylabel('Average Sales')\naxes[1].tick_params(axis='x', rotation=45)\naxes[1].grid(True)\n\nplt.tight_layout()\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T12:36:11.098318Z","iopub.execute_input":"2025-04-06T12:36:11.098742Z","iopub.status.idle":"2025-04-06T12:36:11.767031Z","shell.execute_reply.started":"2025-04-06T12:36:11.098668Z","shell.execute_reply":"2025-04-06T12:36:11.76586Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Avg Sales vs Store Number","metadata":{}},{"cell_type":"code","source":"# Ensure store number is same type for merging\ndata_train['store_nbr'] = data_train['store_nbr'].astype(int)\ndata_stores['store_nbr'] = data_stores['store_nbr'].astype(int)\n\n# Step 1: Compute average sales per store\navg_sales_store = data_train.groupby('store_nbr')['sales'].mean().reset_index()\n\n# Step 2: Merge with store metadata to get 'type'\navg_sales_store = avg_sales_store.merge(data_stores[['store_nbr', 'type']], on='store_nbr', how='left')\n\n# Step 3: Plot\nplt.figure(figsize=(12,6))\nsns.scatterplot(data=avg_sales_store, x='store_nbr', y='sales', hue='type', palette='Set2', s=100, edgecolor='black')\n\nplt.title('Average Sales vs Store Number (Colored by Store Type)')\nplt.xlabel('Store Number')\nplt.ylabel('Average Sales')\nplt.grid(True)\nplt.legend(title='Store Type', bbox_to_anchor=(1.05, 1), loc='upper left')\nplt.tight_layout()\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T12:39:40.874061Z","iopub.execute_input":"2025-04-06T12:39:40.874776Z","iopub.status.idle":"2025-04-06T12:39:41.471885Z","shell.execute_reply.started":"2025-04-06T12:39:40.874724Z","shell.execute_reply":"2025-04-06T12:39:41.47085Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Avg Sales vs On promotion in each city displaying number of stores","metadata":{}},{"cell_type":"code","source":"# Step 1: Merge data_train with store info to get city\ndata_train_city = data_train.merge(data_stores[['store_nbr', 'city']], on='store_nbr', how='left')\n\n# Step 2: Aggregate avg sales, avg onpromotion, number of stores per city\ncity_summary = data_train_city.groupby('city').agg({\n    'sales': 'mean',\n    'onpromotion': 'mean'\n}).reset_index()\n\nstore_counts = data_stores.groupby('city')['store_nbr'].nunique().reset_index()\nstore_counts.rename(columns={'store_nbr': 'num_stores'}, inplace=True)\n\n# Step 3: Merge store counts into city summary\ncity_summary = city_summary.merge(store_counts, on='city')\n\n# Step 4: Bubble plot\nplt.figure(figsize=(14, 8))\nsns.scatterplot(\n    data=city_summary,\n    x='onpromotion',\n    y='sales',\n    size='num_stores',\n    hue='city',\n    sizes=(100, 1000),\n    alpha=0.7,\n    palette='tab10',\n    legend=False,\n    edgecolor='black'\n)\n\n# Add labels to each point\nfor i, row in city_summary.iterrows():\n    plt.text(row['onpromotion'] + 0.02, row['sales'], row['city'], fontsize=9)\n\nplt.title('Avg Sales vs Avg Onpromotion per City (Bubble Size = #Stores)')\nplt.xlabel('Average Onpromotion')\nplt.ylabel('Average Sales')\nplt.grid(True)\nplt.tight_layout()\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T12:40:38.512767Z","iopub.execute_input":"2025-04-06T12:40:38.513208Z","iopub.status.idle":"2025-04-06T12:40:39.482687Z","shell.execute_reply.started":"2025-04-06T12:40:38.51317Z","shell.execute_reply":"2025-04-06T12:40:39.481655Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Average Sales vs Store Number","metadata":{}},{"cell_type":"code","source":"data_train['store_nbr'] = data_train['store_nbr'].astype(int)\ndata_stores['store_nbr'] = data_stores['store_nbr'].astype(int)\n\n# Step 1: Compute average sales per store\navg_sales_store = data_train.groupby('store_nbr')['sales'].mean().reset_index()\n\n# Step 2: Merge with store metadata to get 'type'\navg_sales_store = avg_sales_store.merge(data_stores[['store_nbr', 'type']], on='store_nbr', how='left')\n\n# Step 3: Plot\nplt.figure(figsize=(12,6))\nsns.scatterplot(data=avg_sales_store, x='store_nbr', y='sales', hue='type', palette='Set2', s=100, edgecolor='black')\n\nplt.title('Average Sales vs Store Number (Colored by Store Type)')\nplt.xlabel('Store Number')\nplt.ylabel('Average Sales')\nplt.grid(True)\nplt.legend(title='Store Type', bbox_to_anchor=(1.05, 1), loc='upper left')\nplt.tight_layout()\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T12:40:07.127821Z","iopub.execute_input":"2025-04-06T12:40:07.128281Z","iopub.status.idle":"2025-04-06T12:40:07.648821Z","shell.execute_reply.started":"2025-04-06T12:40:07.128229Z","shell.execute_reply":"2025-04-06T12:40:07.647846Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Processing Data","metadata":{}},{"cell_type":"markdown","source":"### üõ†Ô∏è `process_data()` Function Breakdown\n\n1. **Selective Column Filtering**:\n   - Keeps only necessary columns for training and test datasets.\n   - Columns differ slightly based on whether `is_test=True`.\n\n2. **Merging External Data**:\n   - Merges oil prices (`data_oil`) and holiday information (`data_holidays`) using the `date` column as the key.\n   - Renames:\n     - `\"dcoilwtico\"` to `\"crude_price\"`\n     - `\"type\"` to `\"day_type\"`\n\n3. **Handling Missing Holiday Data**:\n   - Fills missing `day_type` with `\"Work Day\"`.\n   - Fills missing `transferred` values with `False`.\n\n4. **Holiday Flag Creation**:\n   - Adds a binary feature `is_holiday`:\n     - `1` if the date is a valid, non-transferred holiday.\n     - `0` otherwise.\n\n5. **Promotion Encoding**:\n   - Converts `onpromotion` values to binary:\n     - `0` if it‚Äôs `0.0`, else `1`.\n\n6. **Sequential Day Encoding**:\n   - Generates a new feature `day_number`:\n     - Encodes unique dates into sequential integers using `pd.factorize()`.\n\n7. **Crude Price Imputation**:\n   - Fills missing crude oil prices using **forward fill** method.\n\n8. **One-Hot Encoding for Product Family**:\n   - Applies one-hot encoding to the `family` column.\n   - Merges new binary columns back into the dataset.\n   - Drops the original `family` column.\n\n9. **Final Cleanup**:\n   - Drops unused columns: `day_type`, `transferred`, `date`.\n   - Removes any remaining rows with missing values.","metadata":{}},{"cell_type":"code","source":"def process_data(df : pd.DataFrame, is_test = False):\n    # coulumns that we want to keep\n    col_train = [ 'date', 'family', 'onpromotion', 'sales', 'store_nbr', 'id']\n    col_test = [ 'date', 'family', 'onpromotion', 'store_nbr', 'id']\n    col_holidays = ['date', 'type', 'transferred']\n\n    if is_test:\n        col_df = col_test\n    else:\n        col_df = col_train\n    \n    # merge to form our dataset\n    df = df[col_df].merge(data_oil,'left','date').merge(data_holidays[col_holidays],'left', 'date').rename(columns={'type': 'day_type', 'dcoilwtico' : 'crude_price'})\n\n    df['day_type'] = df['day_type'].fillna('Work Day')\n    df['transferred'] = df['transferred'].fillna(False)\n\n    # only keep holidays that are not transferred. i.e true holidays\n    df['is_holiday'] = np.where(\n        (df['day_type'] == 'Work Day'), 0,\n        np.where(\n            (df['day_type'].isin(['Holiday', 'Additional', 'Event', 'Transfer', 'Bridge'])) &\n            (df['transferred'] == False),\n            1,\n            0\n        )\n    )\n    \n    # where onpromotion is 0.0 change it to 0 else 1\n    df['onpromotion'] = np.where(df['onpromotion'] == 0.0, 0, 1)\n    \n    # new column with index starting from 1 if date is same then keep\n    # df['day_number'] = range(1, len(df) + 1)\n    \n    df['day_number'] = pd.factorize(df['date'])[0] + 1\n    df = df.drop(['day_type', 'transferred', 'date'], axis=1)\n\n    # wherever crude price is NaN fill it with last valid value\n    df['crude_price'] = df['crude_price'].fillna(method='ffill')\n\n    # encode product family to one-hot encoding\n    family_encoding = pd.get_dummies(df['family'], prefix='family').astype(int)\n    df = pd.concat([df, family_encoding], axis=1)\n\n    # drop family as it is no more needed\n    df = df.drop(['family'], axis=1)\n\n    # drop 'na' rows if still left\n    df = df.dropna()\n    \n    return df","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"data_train = process_data(data_train)\ndata_test = process_data(data_test, is_test=True)\n\ndata_train.head()","metadata":{"id":"v_oITrdkGyWA","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import xgboost as xgb\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.metrics import mean_squared_error, r2_score\n\ntrain_X = data_train.drop(['sales'], axis=1)\ntrain_y = data_train['sales']\n\n# replace becuae xgboost doesnt work when headers have \" \"\ntrain_X.columns = [col.replace(\" \", \"_\").replace(\"-\", \"_\") for col in train_X.columns]\ndata_test.columns = [col.replace(\" \", \"_\").replace(\"-\", \"_\") for col in data_test.columns]\n\n# find optimal base score\nlog_mean_target = np.log1p(train_y.mean())\nprint(log_mean_target)\n\n# Initialize the XGBoost model\nxgb_model = xgb.XGBRegressor(objective='count:poisson',  n_estimators=100, base_score = log_mean_target)\n\n# Train the model\nxgb_model.fit(train_X, train_y)\n\n# Make predictions on the test set\npredict_y_xg = xgb_model.predict(data_test)\n\nprint(predict_y_xg)","metadata":{"id":"8PEoOMenW1Ak","outputId":"012b76a1-ca5e-4e36-a4d7-7a8d5b7cf7fc","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"end_data = data_test[['id']].copy()  # Copy the 'id' column as a DataFrame\nend_data['sales'] = predict_y_xg  # Add the predicted sales as a new column\n\n# Save to a CSV file\nend_data.to_csv('/kaggle/working/submission.csv', index=False)","metadata":{"id":"ZnnTO0Z7HXjZ","outputId":"3f4e3939-5755-43e7-e25e-ab3a8b9bef21","trusted":true},"outputs":[],"execution_count":null}]}