{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":29781,"databundleVersionId":2887556,"sourceType":"competition"},{"sourceId":1913,"sourceType":"datasetVersion","datasetId":1057},{"sourceId":636393,"sourceType":"datasetVersion","datasetId":312121},{"sourceId":1530572,"sourceType":"datasetVersion","datasetId":902411},{"sourceId":1577914,"sourceType":"datasetVersion","datasetId":902131}],"dockerImageVersionId":30761,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<img height=100 width=1000 src=\"https://cdn.educba.com/academy/wp-content/uploads/2020/05/Time-Series-Analysis.jpg\" />","metadata":{}},{"cell_type":"markdown","source":"> #  **1.Introduction to Time Series**","metadata":{}},{"cell_type":"markdown","source":"### Every organization, whether in finance, healthcare, retail, or any other industry, faces significant challenges such as market volatility, technological disruptions, economic recessions, inflation, labor unrest, and shifts in regulatory policies. These factors introduce a level of risk and uncertainty that companies must navigate daily. To manage and mitigate these risks, organizations rely on forecasting methods to predict potential future events and trends, allowing them to make informed decisions and prepare for potential adverse outcomes.\n\n### There are several methods of forecasting, each suited to different types of data and scenarios. Among the most commonly used methods are:\n\n### * Regression Models:  Utilize the relationship between dependent and independent variables to make predictions.\n### * Data Mining Methods: Involve extracting patterns and insights from large datasets to predict future events.\n### * Time Series Analysis: Focuses on analyzing data points collected or recorded at specific time intervals to identify patterns and forecast future trends.","metadata":{}},{"cell_type":"markdown","source":"> # **2. What is Time Series?**","metadata":{}},{"cell_type":"markdown","source":"### A time series is a sequence of data points, typically consisting of successive measurements made over a time interval. Time series data is unique in that it is time-dependent, meaning the order of the data points is crucial. Examples of time series data include stock prices, daily temperatures, monthly sales data, and more. Analyzing time series data involves various techniques like decomposition, smoothing, and forecasting.\n\n### Intervals of the Time Series Data\n\n#### 1.  Yearly :- GDP , Macro-economic series\n#### 2. Quarterly :- Revenue of a company.\n#### 3. Monthly:- Sales, Expenditure, salary\n#### 4. Weekly:- Demand , Price of Petrol and diesal\n#### 5. Daily:- Closing price of stock, sensex value, daily transaction of ATM machine\n#### 6. Hourly:- AAQI\n","metadata":{}},{"cell_type":"markdown","source":"> # **3. What is Not a Time Series?**","metadata":{}},{"cell_type":"markdown","source":"### Not all datasets that contain a time component are considered time series data. A dataset is not a time series if the order of the data does not matter or if there is no dependency on time. For example, a dataset containing survey responses from different days is not a time series if the responses themselves are independent of time. Similarly, a collection of images taken at different times but with no temporal relationship is not a time series.","metadata":{}},{"cell_type":"markdown","source":"> # **4. Features of Time Series Data**","metadata":{}},{"cell_type":"markdown","source":"### Time series data exhibits several unique features:\n\n* ### Trend: The general direction in which the data is moving over time.\n* ### Seasonality: Patterns that repeat at regular intervals due to seasonal factors.\n* ### Cyclicity: Patterns that occur at irregular intervals, often due to economic or business cycles.\n* ### Noise: Random variations in the data that do not have any underlying pattern.\n* ### Stationarity: A property where statistical parameters (mean, variance) do not change over time.","metadata":{}},{"cell_type":"markdown","source":"<img height=100 width=1000 src=\"https://images.prismic.io/turing/6596deb5531ac2845a271fbe_Components_of_time_series_analysis_11zon_62bdcb0ac7.webp?auto=format,compress\" />","metadata":{}},{"cell_type":"markdown","source":"> # **5.Time Series Assumptions**","metadata":{}},{"cell_type":"markdown","source":"### Some of the most common assumptions made for time series are based on the common sense. But always Keep in mind one thing\n\n> ### Very long range forecasts does not work well !!\n\n* ###  Forecast is done by keeping in mind that the market and the other conditions are not going to change in the future.\n* ### There will be not any change in the market.\n* ### But the change is gradual and not a drastic change.\n* ### Situations like recession in 2008 US market will send the forecasts into a tizzy.\n* ### Events like demonetization would throw the forecasts into disarray\n* ### Based on the data available , we should not try to forecast for more than a few periods ahead.","metadata":{}},{"cell_type":"markdown","source":"> # **6. Time Series Types**","metadata":{}},{"cell_type":"markdown","source":"## Time series data can be categorized into different types based on its properties:\n\n* ### Univariate Time Series: A series with a single variable, such as daily temperature.\n* ### Multivariate Time Series: A series with multiple interdependent variables, like weather data containing temperature, humidity, and pressure.\n* ### Regular vs. Irregular Time Series: Regular time series data is recorded at consistent time intervals, whereas irregular time series data is recorded at inconsistent intervals.\n* ### Stationary vs. Non-Stationary Time Series: A stationary time series has constant mean and variance over time, whereas a non-stationary series does not.","metadata":{}},{"cell_type":"code","source":"#Libraries \nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport calendar\nimport datetime\nimport plotly.express as px\nimport plotly.figure_factory as ff\nimport plotly.offline as offline\nimport plotly.graph_objs as go\nimport plotly.io as pio \nfrom plotly.subplots import make_subplots\nfrom learntools.time_series.style import *\nfrom pathlib import Path\n\nfrom statsmodels.tsa.deterministic import CalendarFourier, DeterministicProcess\nfrom statsmodels.tsa.stattools import adfuller\n\nfrom sklearn.metrics import mean_absolute_error,mean_absolute_error, confusion_matrix \nfrom sklearn.preprocessing import LabelEncoder, OneHotEncoder, MinMaxScaler,OrdinalEncoder,OneHotEncoder\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.model_selection import train_test_split\nfrom xgboost import XGBRegressor\n\nimport keras \nfrom keras.layers import Dense, Dropout, LSTM \nfrom keras.callbacks import EarlyStopping \nfrom keras.models import Sequential ","metadata":{"execution":{"iopub.status.busy":"2024-09-01T06:46:28.190644Z","iopub.execute_input":"2024-09-01T06:46:28.191173Z","iopub.status.idle":"2024-09-01T06:46:47.57289Z","shell.execute_reply.started":"2024-09-01T06:46:28.191129Z","shell.execute_reply":"2024-09-01T06:46:47.571734Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> # **7-How to import data ?**","metadata":{}},{"cell_type":"markdown","source":"### First, we import all the datasets needed for this kernel. The required time series column is imported as a datetime column using **parse_dates** parameter and is also selected as index of the dataframe using **index_col** parameter.","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/time-series-data/daily-min-temperatures.csv\", parse_dates=True , index_col=\"Date\")\ndf","metadata":{"execution":{"iopub.status.busy":"2024-09-01T06:46:47.575265Z","iopub.execute_input":"2024-09-01T06:46:47.57594Z","iopub.status.idle":"2024-09-01T06:46:47.62966Z","shell.execute_reply.started":"2024-09-01T06:46:47.575898Z","shell.execute_reply":"2024-09-01T06:46:47.628526Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"temp = go.Scatter(x=df.index, y=df['Temp'], mode='lines', name='Temperature')\n\n# Layout settings\nlayout = go.Layout(\n    title='Temperature',\n    xaxis_title='date',\n    yaxis_title='meantemp',\n    legend=dict(x=0, y=1.0),\n    margin=dict(l=80, r=80, t=40, b=40),\n    height=500,\n    width=1100,\n)\n\n# Combine the traces and layout\nfig = go.Figure(data=temp, layout=layout)\n\n# Display the plot\npio.show(fig)","metadata":{"execution":{"iopub.status.busy":"2024-09-01T06:46:47.630811Z","iopub.execute_input":"2024-09-01T06:46:47.631205Z","iopub.status.idle":"2024-09-01T06:46:48.02145Z","shell.execute_reply.started":"2024-09-01T06:46:47.631157Z","shell.execute_reply":"2024-09-01T06:46:48.0202Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### If we want to predict the temperature for the next few months, we will try to look at the past values and try to gauge and extract the pattern. Here we observe a pattern within each year indicating a seasonal effect. Such observations will help us in predicting future values.\n\n### **Note: We have used only one variable here , Temp (the temperature of the past 19 years).**\n\n### Hence this is called as the Univariate Time Series Analysis/Forecasting.","metadata":{}},{"cell_type":"code","source":"df2 = pd.read_csv(\"/kaggle/input/daily-climate-time-series-data/DailyDelhiClimateTrain.csv\", parse_dates=True , index_col=\"date\")\ndf2","metadata":{"execution":{"iopub.status.busy":"2024-09-01T06:46:48.024347Z","iopub.execute_input":"2024-09-01T06:46:48.02476Z","iopub.status.idle":"2024-09-01T06:46:48.058036Z","shell.execute_reply.started":"2024-09-01T06:46:48.024721Z","shell.execute_reply":"2024-09-01T06:46:48.056757Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = make_subplots(rows=2, cols=2, subplot_titles=(\"Temperature\", \"Humidity\", \"Pressure\", \"Wind Speed\"))\n\n# Temperature plot\nfig.add_trace(\n    go.Scatter(x=df2.index, y=df2['meantemp'], mode='lines', name='Temperature', line=dict(color='red')),\n    row=1, col=1\n)\n\n# Humidity plot\nfig.add_trace(\n    go.Scatter(x=df2.index, y=df2['humidity'], mode='lines', name='Humidity', line=dict(color='blue')),\n    row=1, col=2\n)\n\n# Pressure plot\nfig.add_trace(\n    go.Scatter(x=df2.index, y=df2['wind_speed'], mode='lines', name='Pressure', line=dict(color='green')),\n    row=2, col=1\n)\n\n# Wind Speed plot\nfig.add_trace(\n    go.Scatter(x=df2.index, y=df2['meanpressure'], mode='lines', name='Wind Speed', line=dict(color='orange')),\n    row=2, col=2\n)\n\n# Update layout\nfig.update_layout(\n    title='Weather Data Subplots',\n    height=800,\n    width=1100,\n    showlegend=False  # Set to False if you don't want a shared legend\n)\n\n# Display the plot\npio.show(fig)","metadata":{"execution":{"iopub.status.busy":"2024-09-01T06:46:48.059184Z","iopub.execute_input":"2024-09-01T06:46:48.059534Z","iopub.status.idle":"2024-09-01T06:46:48.428347Z","shell.execute_reply.started":"2024-09-01T06:46:48.059498Z","shell.execute_reply":"2024-09-01T06:46:48.427066Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **Note: We have used four variable here , (meantemp/humidity/wind_speed/meanpressure) .**\n### Hence this is called as the Multivariate Time Series Analysis/Forecasting.\n\n","metadata":{}},{"cell_type":"markdown","source":"> # **8-Missing Values**","metadata":{}},{"cell_type":"markdown","source":"### Missing DataÂ¶\n#### 1. No missing data is allowed in time series as data is ordered.\n#### 2. It is simply not possible to shift the series to fill in the gaps.\n\n### Reasons for missing data :\n#### 1) Data is not collected or recorded\n#### 2) Data never existed\n#### 3) Data corruption\n\n### Mark missing values:\n### * NaN is the default missing value marker for reasons of computational speed and convenience.\n### * We can easily detect this value with data of different types: floating point, integer, Boolean and general object.\n### * However, the Python None will arise and we wish to also consider that missing.\n### * To make detecting missing values easier across different array dtypes, pandas provides functions, isna() and notna(), which are also methods on Series and DataFrame objects.","metadata":{}},{"cell_type":"markdown","source":"> # **9-Handling Missing Values**","metadata":{}},{"cell_type":"markdown","source":"### **1. Understanding Missing Data in Time Series**\n Nature of Time Series Data: Time series data is sequential and ordered, meaning missing values can disrupt patterns and dependencies between observations.\n Challenges: Unlike other types of data, you cannot simply reorder or remove time series data without potentially losing important temporal information.\n\n### **2. Strategies for Handling Missing Values in Time Series**\n1. Forward Fill (Propagation of the Last Observation)\nMethod: Replace NaN values with the last available non-missing value.\nUsage: Suitable when the missing values are assumed to be the same as the previous recorded values.\n<div style=\"color:white;display:fill;border-radius:8px;\n            background-color:#323232;font-size:150%;\n            font-family:Nexa;letter-spacing:0.5px\">\n    <p style=\"padding: 8px;color:white;\"><b>df['column_name'].fillna(method='ffill', inplace=True)</b></p>\n</div>\n\n2. Backward Fill (Propagation of the Next Observation)\nMethod: Replace NaN values with the next available non-missing value.\nUsage: Used when the missing values are assumed to be the same as the subsequent recorded values.\n<div style=\"color:white;display:fill;border-radius:8px;\n            background-color:#323232;font-size:150%;\n            font-family:Nexa;letter-spacing:0.5px\">\n    <p style=\"padding: 8px;color:white;\"><b>df['column_name'].fillna(method='bfill', inplace=True)</b></p>\n</div>\n\n\n### **3. Interpolate Missing Values**\nMethod: Interpolation involves estimating the missing values based on nearby data points. Common methods include linear, polynomial, and spline interpolation.\nUsage: Useful when the data is expected to have a smooth trend between missing points.\n<div style=\"color:white;display:fill;border-radius:8px;\n            background-color:#323232;font-size:150%;\n            font-family:Nexa;letter-spacing:0.5px\">\n    <p style=\"padding: 8px;color:white;\"><b>df['column_name'].interpolate(method='linear', inplace=True)  # Linear interpolation</b></p>\n</div>\n\n<div style=\"color:white;display:fill;border-radius:8px;\n            background-color:#323232;font-size:150%;\n            font-family:Nexa;letter-spacing:0.5px\">\n    <p style=\"padding: 8px;color:white;\"><b>df['column_name'].interpolate(method='time', inplace=True) # Time-based interpolation</b></p>\n</div>\n\n### **4. Mean, Median, or Mode Imputation**\n\nMethod: Replace NaN values with the mean, median, or mode of the entire series or a rolling window.\nUsage: Best for data with low variance and no strong trends or seasonality.\n<div style=\"color:white;display:fill;border-radius:8px;\n            background-color:#323232;font-size:150%;\n            font-family:Nexa;letter-spacing:0.5px\">\n    <p style=\"padding: 8px;color:white;\"><b>df['column_name'].fillna(df['column_name'].mean(), inplace=True)  # Mean Imputation</b></p>\n</div>\n\n\n<div style=\"color:white;display:fill;border-radius:8px;\n            background-color:#323232;font-size:150%;\n            font-family:Nexa;letter-spacing:0.5px\">\n    <p style=\"padding: 8px;color:white;\"><b>df['column_name'].fillna(df['column_name'].median(), inplace=True)  # Median Imputation</b></p>\n</div>\n\n\n### **5. Using Moving Averages**\nMethod: Replace NaN values with the average of neighboring values over a fixed window.\nUsage: Effective for smoothing out short-term fluctuations and highlighting longer-term trends. \n <div style=\"color:white;display:fill;border-radius:8px;\n            background-color:#323232;font-size:150%;\n            font-family:Nexa;letter-spacing:0.5px\">\n    <p style=\"padding: 8px;color:white;\"><b>df['column_name'].fillna(df['column_name'].rolling(window=3, min_periods=1).mean(), inplace=True)</b></p>\n</div>\n \n \n### **6. Model-Based Imputation (e.g., KNN, Regression, ARIMA)**\nMethod: Use statistical or machine learning models to predict missing values based on other available data points. Models like K-Nearest Neighbors (KNN), regression, or even time series models like ARIMA can be used.\nUsage: Suitable for complex datasets where relationships between variables can help predict missing values.\nImplementation: Requires more advanced techniques and libraries such as scikit-learn.\n\n\n#### **7. Dropping Missing Values**\nMethod: Simply remove rows or columns with missing values.\nUsage: Only suitable when missing data is minimal and does not significantly affect the dataset.\n<div style=\"color:white;display:fill;border-radius:8px;\n            background-color:#323232;font-size:150%;\n            font-family:Nexa;letter-spacing:0.5px\">\n    <p style=\"padding: 8px;color:white;\"><b>df.dropna(inplace=True)</b></p>\n</div>","metadata":{}},{"cell_type":"markdown","source":"> # **10.Time Series Accuracy and Frequency**","metadata":{}},{"cell_type":"markdown","source":"#### Time Series forecast models can both make predictions and provide a confidence interval for those predictions.\n\n#### Forecast Range\n\n### Confidence intervals provide an upper and lower expectation for the real observation.\n#### These are useful for assessing the range of real possible outcomes for a prediction and for better understanding the skill of the model.\n#### For example, the ARIMA implementation in the statsmodel python library can be used to fit an ARIMA model. It returns an ARIMAResults object.\n\n\n\n### The object provides the forecast() function returns three values:\n\n#### 1) Forecast: The forecasted value in the\n#### 2) Standard Error of the model:\n#### 3) Confidence Interval: The 95% confidence interval for the forecast\n\n#### The error in the forecast is the difference between the actual value and the forecast.\n#### Two popular accuracy measures are RMSE and MAPE.\n\n\n### Forecast Requirements: \n#### A time series model must contain a key time column that contains unique values, input columns, and at least one predictable column.\n\n#### Time series data often requires cleaning, scaling, and even transformation\n\n#### Frequency: Data may be provided at a frequency that is too high to model or is unvenly spread through time requiring resampling for use in models.\n\n#### Outliers: Data may contain corrupt or extreme outlier values that need to be identified and handled.\n\n#### Frequency: \n*  ####  Frequencies may be too granular or not granular enough to get insights.\n*  #### The pandas library in Pyhton provides the capability to increase or decrease the sampling frequency of the time series data.\n\n\n#### Resampling:\n* #### Resampling may be required if the data is not available at the same frequency that you want to make predictions.\n* #### Resampling may be required to provide additional structure or insight into the learning problem for supervised learning models.\n\n\n#### Up-sampling:\n* #### Increase the frequencies of the sample, example: months to days\n* #### Care may be needed in deciding how the fine-grained observations are calculated using interpolation.\n\n\n#### **The function, resample() available in the pandas library works on the Series and DataFrame objects.**\n","metadata":{}},{"cell_type":"code","source":"shampoo = pd.read_csv(\"/kaggle/input/time-series-data/shampoo.csv\", parse_dates= True, index_col=\"Month\")\nshampoo.head(20)","metadata":{"execution":{"iopub.status.busy":"2024-09-01T06:46:48.430236Z","iopub.execute_input":"2024-09-01T06:46:48.430695Z","iopub.status.idle":"2024-09-01T06:46:48.451283Z","shell.execute_reply.started":"2024-09-01T06:46:48.430646Z","shell.execute_reply":"2024-09-01T06:46:48.450229Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nfrom datetime import datetime\n\n# Define a date parser function\ndef parser(x):\n    return datetime.strptime('1900-' + x, '%Y-%m-%d')  # Adjust the format if necessary\n\n# Read the CSV file with the corrected date parser\nshampoo_df = pd.read_csv(\n    '/kaggle/input/time-series-data/shampoo.csv', \n    header=0, \n    index_col=0, \n    parse_dates=True, \n    date_parser=parser\n)\n\n# Ensure the index is a DatetimeIndex\nshampoo_df.index = pd.to_datetime(shampoo_df.index)\n\n# Resample the data to daily frequency\nupsampled_ts = shampoo_df.resample('D').mean()\n\n# Display the first 36 rows\nprint(upsampled_ts.head(20))","metadata":{"execution":{"iopub.status.busy":"2024-09-01T06:46:48.45254Z","iopub.execute_input":"2024-09-01T06:46:48.452877Z","iopub.status.idle":"2024-09-01T06:46:48.479543Z","shell.execute_reply.started":"2024-09-01T06:46:48.452842Z","shell.execute_reply":"2024-09-01T06:46:48.478496Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Inference:\n#### We observe that the resample() function has created the rows by putting NaN values as new values for dates other than day 01.\n\n#### Next we can interpolate the missing values at this new frequency. The function, interpolate() of pandas library is used to interpolate the missing values. We use a linear interpolation which draws a straight line between available data, on the first day of the month and fills in values at the chosen frequency from this line.","metadata":{}},{"cell_type":"code","source":"interpolated = upsampled_ts.interpolate(method = 'linear')\ninterpolated.plot()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-09-01T06:46:48.48078Z","iopub.execute_input":"2024-09-01T06:46:48.481156Z","iopub.status.idle":"2024-09-01T06:46:49.300926Z","shell.execute_reply.started":"2024-09-01T06:46:48.481118Z","shell.execute_reply":"2024-09-01T06:46:49.299624Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Accuracy measures \n\n#### We would have used several models such as moving average, exponential smoothing, etc. before selecting the best model.\n\n#### The model selection may depend on the chosen forecasting accuracy measure such as:\n\n#### Mean Absolute Error, MAE = (1/n) (|Y1 - F1| + |Y2- F2| + ... + |Yn - Fn|)\n#### Mean Absolute Percentage Error, MAPE = (1/n) ((|Y1 - F1|/Y1) + (|Y2 - F2|/Y2) + ... + (|Yn- Fn|/Yn) * 100)\n#### Mean Squared Error, MSE = (1/n) ((Y1 - F1)^2 + (Y2- F2)^2 + ... + (Yn - Fn)^2)\n#### Root Mean Square Error, RMSE = square root of MSE\n#### where n is the number of observations Yn is the actual value of Y at time n Fn is the corresponding forecasted value. RMSE and MAPE are two most popular accuracy measures of forecasting.","metadata":{}},{"cell_type":"markdown","source":"### **Define functions to calculate MAE and MAPE**","metadata":{}},{"cell_type":"code","source":"def MAE(y,yhat):\n    diff = np.abs(np.array(y)-np.array(yhat))\n    try:\n        mae =  round(np.mean(np.fabs(diff)),3)\n    except:\n        print(\"Error while calculating\")\n        mae = np.nan\n    return mae","metadata":{"execution":{"iopub.status.busy":"2024-09-01T06:46:49.302316Z","iopub.execute_input":"2024-09-01T06:46:49.30271Z","iopub.status.idle":"2024-09-01T06:46:49.309478Z","shell.execute_reply.started":"2024-09-01T06:46:49.302672Z","shell.execute_reply":"2024-09-01T06:46:49.307892Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def MAPE(y, yhat): \n    y, yhat = np.array(y), np.array(yhat)\n    try:\n        mape =  round(np.mean(np.abs((y - yhat) / y)) * 100,2)\n    except:\n        print(\"Observed values are empty\")\n        mape = np.nan\n    return mape","metadata":{"execution":{"iopub.status.busy":"2024-09-01T06:46:49.312896Z","iopub.execute_input":"2024-09-01T06:46:49.313394Z","iopub.status.idle":"2024-09-01T06:46:49.320963Z","shell.execute_reply.started":"2024-09-01T06:46:49.313349Z","shell.execute_reply":"2024-09-01T06:46:49.31997Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Read the CSV file without the 'squeeze' parameter\nfemale_birth_series = pd.read_csv(\n    '/kaggle/input/time-series-data/daily-total-female-births.csv', \n    header=0, \n    index_col=0, \n    parse_dates=True\n)\n\n# Convert to Series if necessary (if only one column)\nif female_birth_series.shape[1] == 1:\n    female_birth_series = female_birth_series.squeeze()\n\n# Compute rolling mean with a window of 3\nrolling = female_birth_series.rolling(window=3)  # Arbitrarily chosen window size\nrolling_mean = rolling.mean()\n\n# Plot original series and rolling mean\nfemale_birth_series.plot(label='Original Series')\nrolling_mean.plot(color='red', label='Rolling Mean')\nplt.legend()\nplt.show()\n\n# Zoomed plot of original and rolling mean dataset\nfemale_birth_series[:100].plot(label='Original Series')\nrolling_mean[:100].plot(color='red', label='Rolling Mean')\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-09-01T06:46:49.32242Z","iopub.execute_input":"2024-09-01T06:46:49.322803Z","iopub.status.idle":"2024-09-01T06:46:50.597385Z","shell.execute_reply.started":"2024-09-01T06:46:49.322756Z","shell.execute_reply":"2024-09-01T06:46:50.596254Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **Why Compare Rolling Mean and Original Series?**\n\n### **Trend Analysis:**\n#### Original Series: Can be noisy and difficult to interpret due to short-term fluctuations.\n#### Rolling Mean: Helps in identifying the underlying trend by filtering out the noise. It reveals the general direction or pattern of the data over time.\n\n### **Smoothing Effect:**\n#### Original Series: Displays the raw data, which might show daily variations and irregularities.\n#### Rolling Mean: Smooths out these variations by averaging data points, making it easier to observe trends without the interference of random fluctuations.\n\n### **Pattern Recognition:**\n#### Original Series: Shows the immediate changes and patterns in the data.\n#### Rolling Mean: Helps in understanding the broader patterns and trends by averaging out short-term volatility. This can be useful for identifying long-term trends or seasonal patterns.","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import mean_squared_error, mean_absolute_error as MAE, mean_absolute_percentage_error as MAPE\n\n# Assuming you have already read the CSV and computed rolling mean\ny_df = pd.DataFrame({'Observed': female_birth_series.values, 'Predicted': rolling_mean})\ny_df.dropna(axis=0, inplace=True)\nprint(y_df.tail())\n\n# Compute RMSE\nrmse = np.sqrt(mean_squared_error(y_df.Observed, y_df.Predicted))\nprint(\"\\n\\n Accuracy measures \")\nprint('RMSE: %.3f' % rmse)\n\n# Compute MAE\nmae = MAE(y_df.Observed, y_df.Predicted)\nprint('MAE: %d' % int(mae))\n\n# Compute MAPE\nmape = MAPE(y_df.Observed, y_df.Predicted)\nprint('MAPE: %.3f' % mape)","metadata":{"execution":{"iopub.status.busy":"2024-09-01T06:46:50.599192Z","iopub.execute_input":"2024-09-01T06:46:50.599669Z","iopub.status.idle":"2024-09-01T06:46:50.614053Z","shell.execute_reply.started":"2024-09-01T06:46:50.599623Z","shell.execute_reply":"2024-09-01T06:46:50.612773Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}