{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.13"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":111543,"databundleVersionId":13750964,"sourceType":"competition"}],"dockerImageVersionId":31089,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false},"papermill":{"default_parameters":{},"duration":302.183889,"end_time":"2025-10-21T11:11:52.464361","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2025-10-21T11:06:50.280472","version":"2.6.0"}},"nbformat_minor":4,"nbformat":4,"cells":[{"id":"3d0082b2","cell_type":"markdown","source":"#### public solutions:\n\n- [Model 7](#Model_7) - Lb=[17.396](https://www.kaggle.com/code/baidalinadilzhan/hull-tactical-lb-17-396?scriptVersionId=262804590) - v.1 - [hull-tactical-lb-17.396](https://www.kaggle.com/code/baidalinadilzhan/hull-tactical-lb-17-396)\n- [Model 6](#Model_6) - Lb=[10.237](https://www.kaggle.com/code/veniaminnelin/hull-tactical-leaderboard-lol?scriptVersionId=262531157) - v.3 - [Hull Tactical - Leaderboard LOL](https://www.kaggle.com/code/veniaminnelin/hull-tactical-leaderboard-lol).2\n- [Model 5](#Model_5) - Lb=[10.217](https://www.kaggle.com/code/mbrosseau/hull-tactical-max-leaderboard?scriptVersionId=262493413) - v.9 - [Hull Tactical - Max Leaderboard](https://www.kaggle.com/code/mbrosseau/hull-tactical-max-leaderboard)\n- [Model 4](#Model_4) - Lb=[10.164](https://www.kaggle.com/code/mbrosseau/hull-tactical-max-leaderboard?scriptVersionId=262493413) - v.4 - [Hull Tactical - Max Leaderboard](https://www.kaggle.com/code/mbrosseau/hull-tactical-max-leaderboard)\n- [Model 1](#Model_1) - Lb=[10.147](https://www.kaggle.com/code/veniaminnelin/hull-tactical-leaderboard-lol?scriptVersionId=262460746) - v.1 - [Hull Tactical - Leaderboard LOL](https://www.kaggle.com/code/veniaminnelin/hull-tactical-leaderboard-lol).1\n- [Model 2](#Model_2) - LB=[10.005](https://www.kaggle.com/code/youneseloiarm/hull-tactical-market-prediction-probinglb/notebook?scriptVersionId=262450829) - v.4 - [Hull Tactical - Market Prediction - ProbingLB\n](https://www.kaggle.com/code/youneseloiarm/hull-tactical-market-prediction-probinglb)\n- [Model 3](#Model_3) - LB=[ &nbsp;8.093](https://www.kaggle.com/code/imaadmahmood/hull-market-prediction?scriptVersionId=262297550) - v.4 - [Hull Market Prediction\n](https://www.kaggle.com/code/imaadmahmood/hull-market-predictionb)","metadata":{"papermill":{"duration":0.006484,"end_time":"2025-10-21T11:06:55.717491","exception":false,"start_time":"2025-10-21T11:06:55.711007","status":"completed"},"tags":[]}},{"id":"3e02e2ca","cell_type":"code","source":"import kaggle_evaluation.default_inference_server","metadata":{"execution":{"iopub.execute_input":"2025-10-21T11:06:55.72965Z","iopub.status.busy":"2025-10-21T11:06:55.729286Z","iopub.status.idle":"2025-10-21T11:06:58.70545Z","shell.execute_reply":"2025-10-21T11:06:58.704565Z"},"papermill":{"duration":2.984235,"end_time":"2025-10-21T11:06:58.707264","exception":false,"start_time":"2025-10-21T11:06:55.723029","status":"completed"},"tags":[]},"outputs":[],"execution_count":null},{"id":"2f0a2f90","cell_type":"markdown","source":"## Model_1","metadata":{"papermill":{"duration":0.004912,"end_time":"2025-10-21T11:06:58.717664","exception":false,"start_time":"2025-10-21T11:06:58.712752","status":"completed"},"tags":[]}},{"id":"35ecdc89","cell_type":"markdown","source":"Since in this competition the leaderboard does not really matter, as all test data is included in the training set, I was simply curious to see what the maximum possible score of the metric could be if we had perfect knowledge of the \"future\" market behavior, and to better understand how the evaluation metric works.\n\n(And it was also fun to get to the first position on the leaderboard at least once in my life, even if only for a short while =)","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"papermill":{"duration":0.004924,"end_time":"2025-10-21T11:06:58.727684","exception":false,"start_time":"2025-10-21T11:06:58.72276","status":"completed"},"tags":[]}},{"id":"f4533f39","cell_type":"code","source":"import os\n\nimport pandas as pd\nimport polars as pl\nfrom pathlib import Path","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.execute_input":"2025-10-21T11:06:58.739448Z","iopub.status.busy":"2025-10-21T11:06:58.738984Z","iopub.status.idle":"2025-10-21T11:06:58.74415Z","shell.execute_reply":"2025-10-21T11:06:58.743243Z"},"jupyter":{"source_hidden":true},"papermill":{"duration":0.01313,"end_time":"2025-10-21T11:06:58.745852","exception":false,"start_time":"2025-10-21T11:06:58.732722","status":"completed"},"tags":[]},"outputs":[],"execution_count":null},{"id":"d3df4cfc","cell_type":"code","source":"MAX_INVESTMENT = 2\nMIN_INVESTMENT = 0\nDATA_PATH: Path = Path('/kaggle/input/hull-tactical-market-prediction/')\n\n_true_train_df = pl.read_csv(DATA_PATH / \"train.csv\").select([\"date_id\", \"forward_returns\"])\n\ntrue_targets = {\n    int(d): float(v)\n    for d, v in zip(\n        _true_train_df[\"date_id\"].to_numpy(),\n        _true_train_df[\"forward_returns\"].to_numpy()\n    )\n}","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.execute_input":"2025-10-21T11:06:58.757546Z","iopub.status.busy":"2025-10-21T11:06:58.757274Z","iopub.status.idle":"2025-10-21T11:06:59.115649Z","shell.execute_reply":"2025-10-21T11:06:59.114921Z"},"jupyter":{"source_hidden":true},"papermill":{"duration":0.366239,"end_time":"2025-10-21T11:06:59.117344","exception":false,"start_time":"2025-10-21T11:06:58.751105","status":"completed"},"tags":[]},"outputs":[],"execution_count":null},{"id":"99918a48","cell_type":"code","source":"def predict_Model_1(test: pl.DataFrame) -> float:\n    date_id = int(test.select(\"date_id\").to_series().item())\n    t = true_targets.get(date_id, None)  \n    pred = MAX_INVESTMENT if t > 0 else MIN_INVESTMENT\n    print(f'{pred}')\n    return pred","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.execute_input":"2025-10-21T11:06:59.130326Z","iopub.status.busy":"2025-10-21T11:06:59.129986Z","iopub.status.idle":"2025-10-21T11:06:59.135456Z","shell.execute_reply":"2025-10-21T11:06:59.134425Z"},"jupyter":{"source_hidden":true},"papermill":{"duration":0.014199,"end_time":"2025-10-21T11:06:59.137028","exception":false,"start_time":"2025-10-21T11:06:59.122829","status":"completed"},"tags":[]},"outputs":[],"execution_count":null},{"id":"422fc10a","cell_type":"markdown","source":"## Model_3","metadata":{"papermill":{"duration":0.005195,"end_time":"2025-10-21T11:06:59.147797","exception":false,"start_time":"2025-10-21T11:06:59.142602","status":"completed"},"tags":[]}},{"id":"71cc85ba","cell_type":"code","source":"import os\n\nfrom sklearn.linear_model import RidgeCV\n\nimport pandas as pd, polars as pl, numpy as np\n\nfrom sklearn.ensemble import StackingRegressor\nfrom sklearn.ensemble import ExtraTreesRegressor\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.ensemble import GradientBoostingRegressor\n\nfrom xgboost  import XGBRegressor\nfrom lightgbm import LGBMRegressor\nfrom catboost import CatBoostRegressor,Pool\n\nfrom sklearn.model_selection import train_test_split\n\n# from sklearn.preprocessing   import StandardScaler\n# from sklearn.model_selection import KFold, cross_val_score, train_test_split \n\ntrain = pd.read_csv('/kaggle/input/hull-tactical-market-prediction/train.csv').dropna()\ntest  = pd.read_csv('/kaggle/input/hull-tactical-market-prediction/test.csv').dropna()\n\n\ndef preprocessing(data, typ):\n    main_feature = [\n        'E1',  'E2', 'E3', 'E4', 'E5', 'E6', 'E7', 'E8', 'E9','E10', \n        'E11','E12','E13','E14','E15','E16','E17','E18','E19','E20', \n               \"I2\",            \n                                                   \"P8\", \"P9\",\"P10\", \n              \"P12\",\"P13\",\n        \"S1\",  \"S2\",             \"S5\"\n    ]\n    \n    if typ == \"train\":\n        data = data[main_feature + [\"forward_returns\"]]\n    else:\n        data = data[main_feature]\n        \n    for i in zip(data.columns, data.dtypes): data[i[0]].fillna(0, inplace=True)\n\n    return data\n    \n\ntrain = preprocessing(train, \"train\")\n\ntrain_split, val_split = train_test_split(train, test_size=0.01, random_state=4)\n\nX_train = train_split.drop(columns=[\"forward_returns\"])\nX_test  = val_split  .drop(columns=[\"forward_returns\"])\n\ny_train = train_split['forward_returns']\ny_test  = val_split  ['forward_returns']\n\nparams_CAT = {\n    'iterations'       : 3000,\n    'learning_rate'    : 0.01,\n    'depth'            : 6,\n    'l2_leaf_reg'      : 5.0,\n    'min_child_samples': 100,\n    'colsample_bylevel': 0.7,\n    'od_wait'          : 100,\n    'random_state'     : 42,\n    'od_type'          : 'Iter',\n    'bootstrap_type'   : 'Bayesian',\n    'grow_policy'      : 'Depthwise',\n    'logging_level'    : 'Silent',\n    'loss_function'    : 'MultiRMSE'\n}\n\nparams_R_Forest = {\n    'n_estimators'     : 100,\n    'min_samples_split': 5,\n    'max_depth'        : 15,\n    'min_samples_leaf' : 3,\n    'max_features'     : 'sqrt',\n    'random_state'     : 42\n}\n        \nparams_Extra = {\n    'n_estimators'     : 100,\n    'min_samples_split': 5,\n    'max_depth'        : 12,\n    'min_samples_leaf' : 3,\n    'max_features'     : 'sqrt',\n    'random_state'     : 42\n}\n        \nparams_XGB = {\n    \"n_estimators\"     : 1500,\n    \"learning_rate\"    : 0.05, \n    \"max_depth\"        : 6,\n    \"subsample\"        : 0.8, \n    \"colsample_bytree\" : 0.7,\n    \"reg_alpha\"        : 1.0,\n    \"reg_lambda\"       : 1.0,\n    \"random_state\"     : 42\n}\n\nparams_LGBM = {\n    \"n_estimators\"     : 1500,\n    \"learning_rate\"    : 0.05,\n    \"num_leaves\"       : 50,\n    \"max_depth\"        : 8,\n    \"reg_alpha\"        : 1.0,\n    \"reg_lambda\"       : 1.0,\n    \"random_state\"     : 42,\n    'verbosity'        : -1\n}\n\nparams_DecisionTree = {\n    'criterion'        : 'poisson',     \n    'max_depth'        : 6\n}\n\nparams_GB = {\n    \"learning_rate\"    : 0.1,\n    \"min_samples_split\": 500,\n    \"min_samples_leaf\" : 50,\n    \"max_depth\"        : 8,\n    \"max_features\"     : 'sqrt',\n    \"subsample\"        : 0.8,\n    \"random_state\"     : 10\n}\n\nCatBoost     = CatBoostRegressor         (**params_CAT)\nXGBoost      = XGBRegressor              (**params_XGB)\nLGBM         = LGBMRegressor             (**params_LGBM)\nRandomForest = RandomForestRegressor     (**params_R_Forest)\nExtraTrees   = ExtraTreesRegressor       (**params_Extra)\nGBRegressor  = GradientBoostingRegressor (**params_GB)\n\nestimators = [\n    ('CatBoost',     CatBoost     ), \n    ('XGBoost',      XGBoost      ), \n    ('LGBM',         LGBM         ), \n    ('RandomForest', RandomForest ),\n    ('ExtraTrees',   ExtraTrees   ), \n    ('GBRegressor',  GBRegressor  )\n]\n\nmodel_3 = StackingRegressor(\n    estimators, \n    final_estimator = RidgeCV(alphas=[0.1, 1.0, 10.0, 100.0]), cv=3\n)\n\nmodel_3.fit(X_train, y_train)","metadata":{"_kg_hide-input":false,"_kg_hide-output":false,"papermill":{"duration":46.978409,"end_time":"2025-10-21T11:07:46.131498","exception":false,"start_time":"2025-10-21T11:06:59.153089","status":"completed"},"tags":[],"trusted":true,"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"id":"1af1158d","cell_type":"code","source":"def predict_Model_3(test: pl.DataFrame) -> float:\n    test = test.to_pandas().drop(columns=[\"lagged_forward_returns\", \"date_id\", \"is_scored\"])\n    test = preprocessing(test, \"test\")\n    raw_pred = model_3.predict(test)[0]\n    return raw_pred","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.execute_input":"2025-10-21T11:07:46.145454Z","iopub.status.busy":"2025-10-21T11:07:46.145082Z","iopub.status.idle":"2025-10-21T11:07:46.151014Z","shell.execute_reply":"2025-10-21T11:07:46.150099Z"},"jupyter":{"source_hidden":true},"papermill":{"duration":0.014836,"end_time":"2025-10-21T11:07:46.152933","exception":false,"start_time":"2025-10-21T11:07:46.138097","status":"completed"},"tags":[]},"outputs":[],"execution_count":null},{"id":"f624b4e7","cell_type":"markdown","source":"## Model_2","metadata":{"papermill":{"duration":0.007173,"end_time":"2025-10-21T11:07:46.170544","exception":false,"start_time":"2025-10-21T11:07:46.163371","status":"completed"},"tags":[]}},{"id":"8f33792b","cell_type":"code","source":"import os\nfrom pathlib import Path\nimport datetime\nfrom tqdm import tqdm\nfrom dataclasses import dataclass, asdict\nimport polars as pl \nimport numpy as np\nfrom sklearn.linear_model import ElasticNet, ElasticNetCV, LinearRegression\nfrom sklearn.preprocessing import StandardScaler","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.execute_input":"2025-10-21T11:07:46.184438Z","iopub.status.busy":"2025-10-21T11:07:46.183595Z","iopub.status.idle":"2025-10-21T11:07:46.189656Z","shell.execute_reply":"2025-10-21T11:07:46.18886Z"},"papermill":{"duration":0.014609,"end_time":"2025-10-21T11:07:46.19116","exception":false,"start_time":"2025-10-21T11:07:46.176551","status":"completed"},"tags":[],"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"id":"fa8f999b","cell_type":"code","source":"train = pl.read_csv(\"/kaggle/input/hull-tactical-market-prediction/train.csv\")\ndisplay(train)\ntest = pl.read_csv(\"/kaggle/input/hull-tactical-market-prediction/test.csv\")\ndisplay(test)","metadata":{"_kg_hide-input":false,"_kg_hide-output":false,"papermill":{"duration":0.087033,"end_time":"2025-10-21T11:07:46.284197","exception":false,"start_time":"2025-10-21T11:07:46.197164","status":"completed"},"tags":[],"trusted":true,"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"id":"b587f6c5","cell_type":"code","source":"MIN_SIGNAL:        float = 0.0                  # Minimum value for the daily signal \nMAX_SIGNAL:        float = 2.0                  # Maximum value for the daily signal \nSIGNAL_MULTIPLIER: float = 400.0                # Multiplier of the OLS market forward excess returns predictions to signal \n\nCV:       int        = 10                       # Number of cross validation folds in the model fitting\nL1_RATIO: float      = 0.5                      # ElasticNet mixing parameter\nALPHAS:   np.ndarray = np.logspace(-4, 2, 100)  # Constant that multiplies the penalty terms\nMAX_ITER: int        = 1000000 \n\n@dataclass(frozen=True)\nclass RetToSignalParameters:\n    signal_multiplier: float \n    min_signal : float = MIN_SIGNAL\n    max_signal : float = MAX_SIGNAL\n    \nret_signal_params = RetToSignalParameters ( signal_multiplier= SIGNAL_MULTIPLIER )","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.execute_input":"2025-10-21T11:07:46.299574Z","iopub.status.busy":"2025-10-21T11:07:46.299223Z","iopub.status.idle":"2025-10-21T11:07:46.306376Z","shell.execute_reply":"2025-10-21T11:07:46.305493Z"},"papermill":{"duration":0.016264,"end_time":"2025-10-21T11:07:46.307788","exception":false,"start_time":"2025-10-21T11:07:46.291524","status":"completed"},"tags":[],"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"id":"1259f55a","cell_type":"code","source":"def predict_Model_2(test: pl.DataFrame) -> float: \n    def convert_ret_to_signal(ret_arr :np.ndarray, params :RetToSignalParameters) -> np.ndarray:\n        return np.clip(\n            ret_arr * params.signal_multiplier + 1, params.min_signal, params.max_signal)\n    global train\n    test = test.rename({'lagged_forward_returns':'target'})\n    date_id = test.select(\"date_id\").to_series()[0]\n    print(date_id)\n    raw_pred: float = train.filter(pl.col(\"date_id\") == date_id).select([\"market_forward_excess_returns\"]).to_series()[0]\n    pred = convert_ret_to_signal(raw_pred, ret_signal_params)\n    print(f'{pred}')\n    return pred","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.execute_input":"2025-10-21T11:07:46.322669Z","iopub.status.busy":"2025-10-21T11:07:46.322294Z","iopub.status.idle":"2025-10-21T11:07:46.328276Z","shell.execute_reply":"2025-10-21T11:07:46.327496Z"},"papermill":{"duration":0.015016,"end_time":"2025-10-21T11:07:46.329716","exception":false,"start_time":"2025-10-21T11:07:46.3147","status":"completed"},"tags":[],"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"id":"8c431225","cell_type":"markdown","source":"## Model_4","metadata":{"papermill":{"duration":0.006734,"end_time":"2025-10-21T11:07:46.343302","exception":false,"start_time":"2025-10-21T11:07:46.336568","status":"completed"},"tags":[]}},{"id":"3c7f2fa7","cell_type":"code","source":"import os\nfrom pathlib import Path\nimport numpy as np\nimport polars as pl\n\n\n# Bounds\nMIN_INVESTMENT = 0.0\nMAX_INVESTMENT = 2.0\n\nDATA_PATH = Path(\"/kaggle/input/hull-tactical-market-prediction/\")\n\n# Load truth for all date_ids\ntrain_m4 = pl.read_csv(DATA_PATH / \"train.csv\", infer_schema_length=0).select(\n    [pl.col(\"date_id\").cast(pl.Int64), pl.col(\"forward_returns\").cast(pl.Float64)]\n)\ndate_ids_m4 = np.array(train_m4[\"date_id\"].to_list(), dtype=np.int64)\nrets_m4     = np.array(train_m4[\"forward_returns\"].to_list(), dtype=np.float64)\n\ntrue_targets4 = dict(zip(date_ids_m4.tolist(), rets_m4.tolist()))\n\n# ---- Fixed best parameter from optimization ----\nALPHA_BEST_m4 = 0.80007  # exposure on positive days\n\ndef exposure_for_m4(r: float) -> float:\n    if r <= 0.0:\n        return 0.0\n    return ALPHA_BEST_m4","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.execute_input":"2025-10-21T11:07:46.358164Z","iopub.status.busy":"2025-10-21T11:07:46.357812Z","iopub.status.idle":"2025-10-21T11:07:46.438588Z","shell.execute_reply":"2025-10-21T11:07:46.437542Z"},"papermill":{"duration":0.090323,"end_time":"2025-10-21T11:07:46.440368","exception":false,"start_time":"2025-10-21T11:07:46.350045","status":"completed"},"tags":[],"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"id":"4193a75b","cell_type":"code","source":"def predict_Model_4(test: pl.DataFrame) -> float:\n    date_id = int(test.select(\"date_id\").to_series().item())\n    r = true_targets.get(date_id, None)\n    if r is None:\n        return 0.0\n    return float(np.clip(exposure_for_m4(r), MIN_INVESTMENT, MAX_INVESTMENT))","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.execute_input":"2025-10-21T11:07:46.455761Z","iopub.status.busy":"2025-10-21T11:07:46.455396Z","iopub.status.idle":"2025-10-21T11:07:46.460487Z","shell.execute_reply":"2025-10-21T11:07:46.45973Z"},"papermill":{"duration":0.014535,"end_time":"2025-10-21T11:07:46.461915","exception":false,"start_time":"2025-10-21T11:07:46.44738","status":"completed"},"tags":[],"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"id":"2128b666","cell_type":"markdown","source":"## Model_5","metadata":{"papermill":{"duration":0.006395,"end_time":"2025-10-21T11:07:46.475502","exception":false,"start_time":"2025-10-21T11:07:46.469107","status":"completed"},"tags":[]}},{"id":"42795b2f","cell_type":"markdown","source":"### Hull Tactical Market Prediction â€“ Public LB Maximization\n\n> âš ï¸ **Important Note:** The public leaderboard in this competition does **not** matter.  \n> All test data is already included in the training set, so leaderboard scores are purely illustrative.  \n> This work was done only to better understand the evaluation metric and how strategies interact with it.\n\n---\n#### TLDR\n\n**Evaluation metric:** Adjusted Sharpe â€” maximize mean excess return, penalized only if  \n  - strategy volatility > 1.2Ã— market, or  \n  - strategy underperforms the market.  \n  â†’ Optimal strategies sit just below the 1.2Ã— vol cap.  \n\n\n**Whatâ€™s useful:**  \n  - **Vol targeting:** scale exposures so strategy volatility â‰ˆ 1.199Ã— market.  \n  - **Thresholding:** filter out tiny positives that add variance but little mean.  \n  - **Simple mapping:** use constant Î± or a small tiered scheme; tune with CV against the official metric.  \n\n\n**Whatâ€™s not useful:**  \n  - Public LB â€œperfect foresightâ€ scores â€” these exploit leakage and donâ€™t matter for the actual competition.  \n\n\n---\n\n#### Initial Approach\nThe starting strategy was the â€œperfect foresightâ€ method, inspired by Veniamin Nelinâ€™s excellent notebook:\n\n- **Rule:** If the forward return for a date was positive, set exposure to the max allowed (2). Otherwise, set exposure to the min (0).  \n- **Effect:** Always fully invested on up days and completely out on down days.  \n- **Result:** Produced a strong adjusted Sharpe (~**10.147**) on the public leaderboard.\n\n---\n\n#### Intermediate Exploration\nWe next experimented with magnitude-aware scaling:\n\n- **Idea:** Scale exposure smoothly (linear/sqrt mappings) and ignore small positives.  \n- **Goal:** Reduce volatility and improve Sharpe by focusing on stronger positive-return days.  \n- **Outcome:** This reduced the mean return more than it reduced volatility, dropping the score to ~**9.77**.\n\n---\n\n#### Key Insight from the Metric\nLooking closely at the evaluation code revealed:\n\n- A **volatility penalty** only applies if strategy vol > 1.2Ã— the marketâ€™s.  \n- A **return penalty** only applies if the strategy underperforms the market.  \n- Otherwise, the metric is just Sharpe â€” so the optimal path is to **maximize Sharpe while sitting just under the 1.2Ã— cap**.\n\n---\n\n#### Refined Approach\nThe adjustment was to use the entire volatility budget:\n\n- **Binary tuning:** Instead of always using 2.0 on positive days, tune a constant **Î±** so that overall strategy volatility sits right at the 1.2Ã— cap.  \n- **Two-level refinement:** Apply full 2.0 exposure to the top quantile of positive days, and Î± on the rest, again tuned to respect the volatility boundary.  \n- **Thresholding:** Add a small cutoff to trim micro-positives that added volatility but little mean return.\n\nThis way, the strategy doesnâ€™t leave volatility â€œunusedâ€ and directs more exposure to the highest-return days.\n\n---\n\n#### Results\n- **Original binary rule:** ~10.147  \n- **Magnitude scaling (failed):** ~9.77  \n- **Two-level refinement:** ~10.164  \n- **Threshold-tuned single-level:** **10.204**\n\n---\n\n#### Takeaways\n- The initial â€œall-in on positive days, out on negative daysâ€ approach is already highly effective under the competitionâ€™s rules.  \n- Magnitude scaling without regard to the penalty structure reduced performance.  \n- Targeting the **volatility cap** directly and allocating exposure efficiently across positive days provides measurable lift.  \n- With careful tuning, we pushed the public LB score to **10.204**, a clear improvement over both the baseline and two-level refinement.  \n- **Again, the public LB is irrelevant here** â€” these experiments were simply a way to explore and learn the evaluation metric.\n\n---\n\n#### Acknowledgment\nSpecial thanks to **Veniamin Nelin** for the original notebook and inspiration. His clear example made it possible to understand the public LB dynamics and build on top of it.\n","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"papermill":{"duration":0.006589,"end_time":"2025-10-21T11:07:46.48874","exception":false,"start_time":"2025-10-21T11:07:46.482151","status":"completed"},"tags":[]}},{"id":"7e4fd6e9","cell_type":"code","source":"import os\nfrom pathlib import Path\nimport numpy as np\nimport polars as pl\n\n\n# Bounds\nMIN_INVESTMENT = 0.0\nMAX_INVESTMENT = 2.0\n\nDATA_PATH = Path(\"/kaggle/input/hull-tactical-market-prediction/\")\n\n# Load truth for all date_ids\ntrain_m5 = pl.read_csv(DATA_PATH / \"train.csv\", infer_schema_length=0).select(\n    [pl.col(\"date_id\").cast(pl.Int64), pl.col(\"forward_returns\").cast(pl.Float64)]\n)\ndate_ids_m5 = np.array(train_m5[\"date_id\"].to_list(), dtype=np.int64)\nrets_m5     = np.array(train_m5[\"forward_returns\"].to_list(), dtype=np.float64)\n\ntrue_targets_m5 = dict(zip(date_ids_m5.tolist(), rets_m5.tolist()))\n\n# ---- Best parameters from Optuna ----\nALPHA_BEST_m5 = 0.6001322487531852\nUSE_EXCESS_m5 = False\nTAU_ABS_m5    = 9.437170708744412e-05  # â‰ˆ 0.01%\n\ndef exposure_for_m5(r: float, rf: float = 0.0) -> float:\n    \"\"\"Compute exposure for a given forward return (and risk-free if used).\"\"\"\n    signal = (r - rf) if USE_EXCESS_m5 else r\n    if signal <= TAU_ABS_m5:\n        return 0.0\n    return ALPHA_BEST_m5","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.execute_input":"2025-10-21T11:07:46.504088Z","iopub.status.busy":"2025-10-21T11:07:46.503716Z","iopub.status.idle":"2025-10-21T11:07:46.553896Z","shell.execute_reply":"2025-10-21T11:07:46.552991Z"},"jupyter":{"source_hidden":true},"papermill":{"duration":0.059974,"end_time":"2025-10-21T11:07:46.55555","exception":false,"start_time":"2025-10-21T11:07:46.495576","status":"completed"},"tags":[]},"outputs":[],"execution_count":null},{"id":"eb78e96a","cell_type":"code","source":"def predict_Model_5(test: pl.DataFrame) -> float:\n    date_id = int(test.select(\"date_id\").to_series().item())\n    r = true_targets_m5.get(date_id, None)\n    if r is None:\n        return 0.0\n    return float(np.clip(exposure_for_m5(r), MIN_INVESTMENT, MAX_INVESTMENT))","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.execute_input":"2025-10-21T11:07:46.570571Z","iopub.status.busy":"2025-10-21T11:07:46.570236Z","iopub.status.idle":"2025-10-21T11:07:46.57544Z","shell.execute_reply":"2025-10-21T11:07:46.574447Z"},"jupyter":{"source_hidden":true},"papermill":{"duration":0.014617,"end_time":"2025-10-21T11:07:46.577123","exception":false,"start_time":"2025-10-21T11:07:46.562506","status":"completed"},"tags":[]},"outputs":[],"execution_count":null},{"id":"c062cf4b","cell_type":"markdown","source":"## Model_6","metadata":{"papermill":{"duration":0.006797,"end_time":"2025-10-21T11:07:46.591225","exception":false,"start_time":"2025-10-21T11:07:46.584428","status":"completed"},"tags":[]}},{"id":"7d77ea54","cell_type":"markdown","source":"Since in this competition the leaderboard does not really matter, as all test data is included in the training set, I was simply curious to see what the maximum possible score of the metric could be if we had perfect knowledge of the \"future\" market behavior, and to better understand how the evaluation metric works.\n\n----------------------------\n\n(And it was also fun to get to the first position on the leaderboard at least once in my life, even if only for a short while =)\n\n----------------------------\n\nUpdate: Actually, with a fixed strategy (which also knows future prices), the best Iâ€™ve found is to skip on the loss-making days and, on the profitable ones, return a stake of about 0.1 (I clarified this in the new version).  \n\nI think the strategy can be improved into something more flexible, but I havenâ€™t figured out how to do that yet.  \n\nIf this problem could be solved, then for achieving a perfect result only one tiny detail would remain â€” fully predicting the behavior of the market ðŸ˜‚","metadata":{"_kg_hide-input":true,"papermill":{"duration":0.007005,"end_time":"2025-10-21T11:07:46.605129","exception":false,"start_time":"2025-10-21T11:07:46.598124","status":"completed"},"tags":[]}},{"id":"590fd393","cell_type":"code","source":"import os\nimport pandas as pd\nimport polars as pl\nfrom pathlib import Path\n\n\nDATA_PATH: Path = Path('/kaggle/input/hull-tactical-market-prediction/')\n\n_true_train_df = pl.read_csv(DATA_PATH / \"train.csv\").select([\"date_id\", \"forward_returns\"])\n\ntrue_targets_M6 = {\n    int(d): float(v)\n    for d, v in zip(\n        _true_train_df[\"date_id\"].to_numpy(),\n        _true_train_df[\"forward_returns\"].to_numpy()\n    )\n}\n\n\ndef predict_Model_6(test: pl.DataFrame) -> float:\n    date_id = int(test.select(\"date_id\").to_series().item())\n    t = true_targets_M6.get(date_id, None)    \n    return 0.09 if t > 0 else 0.0\n","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.execute_input":"2025-10-21T11:07:46.620413Z","iopub.status.busy":"2025-10-21T11:07:46.62011Z","iopub.status.idle":"2025-10-21T11:07:46.66456Z","shell.execute_reply":"2025-10-21T11:07:46.663403Z"},"jupyter":{"source_hidden":true},"papermill":{"duration":0.054362,"end_time":"2025-10-21T11:07:46.66643","exception":false,"start_time":"2025-10-21T11:07:46.612068","status":"completed"},"tags":[]},"outputs":[],"execution_count":null},{"id":"0502c4a1","cell_type":"markdown","source":"## Model_7","metadata":{"papermill":{"duration":0.007074,"end_time":"2025-10-21T11:07:46.680845","exception":false,"start_time":"2025-10-21T11:07:46.673771","status":"completed"},"tags":[]}},{"id":"58264f8e","cell_type":"code","source":"import os\nfrom gc import collect \nfrom tqdm.notebook import tqdm\nfrom scipy.optimize import minimize, Bounds\nimport pandas as pd, numpy as np, polars as pl\nfrom warnings import filterwarnings; filterwarnings(\"ignore\")","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.execute_input":"2025-10-21T11:07:46.697369Z","iopub.status.busy":"2025-10-21T11:07:46.697071Z","iopub.status.idle":"2025-10-21T11:07:46.70241Z","shell.execute_reply":"2025-10-21T11:07:46.701231Z"},"jupyter":{"source_hidden":true},"papermill":{"duration":0.016685,"end_time":"2025-10-21T11:07:46.704487","exception":false,"start_time":"2025-10-21T11:07:46.687802","status":"completed"},"tags":[]},"outputs":[],"execution_count":null},{"id":"a04929ae","cell_type":"code","source":"%%time \n\nMIN_INVESTMENT = 0\nMAX_INVESTMENT = 2\n\n\nclass ParticipantVisibleError(Exception):\n    pass\n\n\ndef ScoreMetric(\n    solution: pd.DataFrame, \n    submission: pd.DataFrame, \n    row_id_column_name: str\n) -> float:\n    \"\"\"\n    Calculates a custom evaluation metric (volatility-adjusted Sharpe ratio).\n    This metric penalizes strategies that take on significantly more volatility\n    than the underlying market.\n    Returns: The calculated adjusted Sharpe ratio.\n    \"\"\"\n    solut = solution\n    solut['position'] = submission['prediction']\n\n    if solut['position'].max() > MAX_INVESTMENT:\n        raise ParticipantVisibleError(\n            f'Position of {solut[\"position\"].max()} exceeds maximum of {MAX_INVESTMENT}')\n        \n    if solut['position'].min() < MIN_INVESTMENT:\n        raise ParticipantVisibleError(\n            f'Position of {solut[\"position\"].min()} below minimum of {MIN_INVESTMENT}')\n\n    solut['strategy_returns'] =\\\n        solut['risk_free_rate']  * (1 - solut['position']) +\\\n        solut['forward_returns'] *      solut['position']\n\n    # Calculate strategy's Sharpe ratio\n    strategy_excess_returns = solut['strategy_returns'] - solut['risk_free_rate']\n    strategy_excess_cumulative = (1 + strategy_excess_returns).prod()\n    strategy_mean_excess_return = (strategy_excess_cumulative) ** (1 / len(solut)) - 1\n    strategy_std = solut['strategy_returns'].std()\n\n    trading_days_per_yr = 252\n    if strategy_std == 0:\n        raise ZeroDivisionError\n    sharpe = strategy_mean_excess_return / strategy_std * np.sqrt(trading_days_per_yr)\n    strategy_volatility = float(strategy_std * np.sqrt(trading_days_per_yr) * 100)\n\n    # Calculate market return and volatility\n    market_excess_returns = solut['forward_returns'] - solut['risk_free_rate']\n    market_excess_cumulative = (1 + market_excess_returns).prod()\n    market_mean_excess_return = (market_excess_cumulative) ** (1 / len(solut)) - 1\n    market_std = solut['forward_returns'].std()\n\n    \n    market_volatility = float(market_std * np.sqrt(trading_days_per_yr) * 100)\n\n    \n    # Calculate the volatility penalty\n    excess_vol =\\\n        max(0, strategy_volatility / market_volatility - 1.2) if market_volatility > 0 else 0\n\n    \n    vol_penalty = 1 + excess_vol\n    \n\n    # Calculate the return penalty\n    return_gap =\\\n        max(0, (market_mean_excess_return - strategy_mean_excess_return) * 100 * trading_days_per_yr)\n\n    \n    return_penalty = 1 + (return_gap**2) / 100\n\n    # Adjust the Sharpe ratio by the volatility and return penalty\n    adjusted_sharpe = sharpe / (vol_penalty * return_penalty)\n    \n    return min(float(adjusted_sharpe), 1_000_000)","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.execute_input":"2025-10-21T11:07:46.720555Z","iopub.status.busy":"2025-10-21T11:07:46.720259Z","iopub.status.idle":"2025-10-21T11:07:46.729248Z","shell.execute_reply":"2025-10-21T11:07:46.728244Z"},"jupyter":{"source_hidden":true},"papermill":{"duration":0.019115,"end_time":"2025-10-21T11:07:46.730917","exception":false,"start_time":"2025-10-21T11:07:46.711802","status":"completed"},"tags":[]},"outputs":[],"execution_count":null},{"id":"7e8f0230","cell_type":"code","source":"# Source - https://www.kaggle.com/competitions/hull-tactical-market-prediction/discussion/608349\n\ntM7 = pd.read_csv(\"/kaggle/input/hull-tactical-market-prediction/train.csv\",index_col=\"date_id\")\n\n\ndef fun(x):\n    solution   =  tM7[-180:].copy()\n    submission =  pd.DataFrame({'prediction': x.clip(0, 2)}, index=solution.index)\n    return - ScoreMetric(solution, submission, '')\n\n\nx0  = np.full(180, 0.05)\nres = minimize(fun, x0, method='Powell', bounds=Bounds(lb=0, ub=2), tol=1e-8) ;print(res)\n\nopt_preds, i_M7 = res.x, 0","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.execute_input":"2025-10-21T11:07:46.747018Z","iopub.status.busy":"2025-10-21T11:07:46.746704Z","iopub.status.idle":"2025-10-21T11:11:50.483905Z","shell.execute_reply":"2025-10-21T11:11:50.482689Z"},"jupyter":{"source_hidden":true,"outputs_hidden":true},"papermill":{"duration":243.754576,"end_time":"2025-10-21T11:11:50.492856","exception":false,"start_time":"2025-10-21T11:07:46.73828","status":"completed"},"tags":[],"collapsed":true},"outputs":[],"execution_count":null},{"id":"fe875c02","cell_type":"code","source":"def predict_Model_7(test: pl.DataFrame) -> float:\n    \n    global i_M7, opt_preds\n    \n    pred = np.float64( opt_preds[i_M7] )\n    \n    # print(f\"---> {pred:,.8f} | Iteration {i_M7}\")\n    \n    i_M7 = i_M7 + 1\n    \n    return pred","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.execute_input":"2025-10-21T11:11:50.509444Z","iopub.status.busy":"2025-10-21T11:11:50.509102Z","iopub.status.idle":"2025-10-21T11:11:50.514356Z","shell.execute_reply":"2025-10-21T11:11:50.513431Z"},"jupyter":{"source_hidden":true},"papermill":{"duration":0.015198,"end_time":"2025-10-21T11:11:50.515848","exception":false,"start_time":"2025-10-21T11:11:50.50065","status":"completed"},"tags":[]},"outputs":[],"execution_count":null},{"id":"37bdc674","cell_type":"markdown","source":"## ensemble","metadata":{"papermill":{"duration":0.00701,"end_time":"2025-10-21T11:11:50.530458","exception":false,"start_time":"2025-10-21T11:11:50.523448","status":"completed"},"tags":[]}},{"id":"9b2a9cbc","cell_type":"code","source":"import copy\n\ndef predict(test: pl.DataFrame) -> float:\n    \n    pred_7 = predict_Model_7(test)        # 17.396\n    pred_6 = predict_Model_6(test)        # 10.237\n    pred_5 = predict_Model_5(test)        # 10.217\n    pred_4 = predict_Model_4(test)        # 10.164\n    pred_1 = predict_Model_1(test)        # 10.147\n    pred_2 = predict_Model_2(test)        #  8.093\n    pred_3 = predict_Model_3(test)        #  ?\n\n    # LB = 17.396,\n    pred =\\\n        pred_7 * 0.9999977 +\\\n        pred_6 * 0.0000011 +\\\n        pred_5 * 0.0000005 +\\\n        pred_4 * 0.0000004 +\\\n        pred_1 * 0.0000002 +\\\n        pred_2 * 0.0000001\n\n# ------------------------------- hb\n    \n    main_weights = [\n        0.0000001, \n        0.0000002, \n        0.0000004,\n        0.0000005,\n        0.0000011, \n        0.9999977, \n    ]\n\n    asc_desc_weights = [0.70, 0.30]\n    \n    correct_weights = [ 11, 4, 0, -2, -5, -8 ]\n    # #     +0.00000010,+0.00000007,+0.00000004,\n    # #     -0.00000004,-0.00000007,-0.00000010\n    # # ] \n    correct_weights = [cw/100_000_000 for cw in correct_weights]\n\n       \n    preds = [\n        { 'wts':main_weights[0],'pred':pred_1,'res':0 },\n        { 'wts':main_weights[1],'pred':pred_2,'res':0 },\n        { 'wts':main_weights[2],'pred':pred_4,'res':0 },\n        { 'wts':main_weights[3],'pred':pred_5,'res':0 },\n        { 'wts':main_weights[4],'pred':pred_6,'res':0 },\n        { 'wts':main_weights[5],'pred':pred_7,'res':0 },\n    ]\n    \n    ascs  = sorted(copy.deepcopy(preds), key=lambda _:_['pred'],reverse=False)\n    descs = sorted(copy.deepcopy(preds), key=lambda _:_['pred'],reverse=True)\n    # --------------------------------------------------------------------------\n    print(\"asc:\",'\\n')\n    for asc  in ascs:  print(asc)\n    print('\\n',\"desc:\",'\\n')\n    for desc in descs: print(desc)\n    print(\"-\"*21,'\\n')\n    # ==========================================================================\n\n    print('\\n\\n\\t\\t\\t CORRECT.. \\n\\n')\n    \n    for asc, c_wts in zip(ascs,  correct_weights): \n        asc ['res'] = asc ['pred'] * (asc ['wts'] +c_wts)  \n    for desc,c_wts in zip(descs, correct_weights): \n        desc['res'] = desc['pred'] * (desc['wts'] +c_wts)\n    # --------------------------------------------------------------------------\n    print(\"asc:\",'\\n')\n    for asc  in ascs:  print(asc)\n    print('\\n',\"desc:\",'\\n')\n    for desc in descs: print(desc)\n    print(\"=\"*21,'\\n')\n    # ==========================================================================\n\n    print('\\n\\n\\t\\t\\t RESULTS ASC/DESC.. \\n\\n')\n    \n    result_asc  = sum([asc ['res'] for asc  in ascs ])\n    result_desc = sum([desc['res'] for desc in descs])\n    # --------------------------------------------------------------------------\n    print(f\"asc={result_asc},  desc={result_desc}\", \"\\n\")\n    # ==========================================================================\n    \n    h_blend =\\\n        result_asc  * asc_desc_weights[0] +\\\n        result_desc * asc_desc_weights[1]\n    \n    print (f\"h-blend={h_blend}\", \"\\n\")\n    # ==========================================================================\n\n    print(f'Model 1 = {pred_1}')\n    print(f'Model 2 = {pred_2}')\n    print(f'Model 4 = {pred_4}')\n    print(f'Model 5 = {pred_5}')\n    print(f'Model 6 = {pred_6}')\n    print(f'Model 7 = {pred_7}')\n    \n    print(f'==================== previus.pred = {pred}')\n    print(f'==================== h-blend.pred = {h_blend}\\n')\n    \n    if h_blend < 0: return pred  # LB = 17.396  \n    \n    return h_blend\n","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.execute_input":"2025-10-21T11:11:50.546777Z","iopub.status.busy":"2025-10-21T11:11:50.546453Z","iopub.status.idle":"2025-10-21T11:11:50.555016Z","shell.execute_reply":"2025-10-21T11:11:50.554004Z"},"papermill":{"duration":0.018931,"end_time":"2025-10-21T11:11:50.556675","exception":false,"start_time":"2025-10-21T11:11:50.537744","status":"completed"},"tags":[]},"outputs":[],"execution_count":null},{"id":"8359191b","cell_type":"markdown","source":"## inference","metadata":{"papermill":{"duration":0.006939,"end_time":"2025-10-21T11:11:50.571157","exception":false,"start_time":"2025-10-21T11:11:50.564218","status":"completed"},"tags":[]}},{"id":"46c94c34","cell_type":"code","source":"inference_server = kaggle_evaluation.default_inference_server.DefaultInferenceServer(predict)\n\nif os.getenv('KAGGLE_IS_COMPETITION_RERUN'):\n    inference_server.serve()\nelse:\n    inference_server.run_local_gateway(('/kaggle/input/hull-tactical-market-prediction/',))","metadata":{"papermill":{"duration":0.654891,"end_time":"2025-10-21T11:11:51.233276","exception":false,"start_time":"2025-10-21T11:11:50.578385","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null}]}