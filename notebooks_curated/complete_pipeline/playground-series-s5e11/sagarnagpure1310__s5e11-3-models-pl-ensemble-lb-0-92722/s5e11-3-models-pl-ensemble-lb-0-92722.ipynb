{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":91722,"databundleVersionId":14262372,"sourceType":"competition"},{"sourceId":13059803,"sourceType":"datasetVersion","datasetId":8264672}],"dockerImageVersionId":31154,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **Core Implementations**","metadata":{}},{"cell_type":"markdown","source":"## **Imports & Configuration**","metadata":{}},{"cell_type":"code","source":"import warnings\nwarnings.filterwarnings('ignore')\n\nimport pandas as pd\nimport numpy as np\nfrom itertools import combinations\nfrom sklearn.model_selection import StratifiedKFold, KFold\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.base import BaseEstimator, TransformerMixin\nfrom sklearn.linear_model import LogisticRegression\nfrom xgboost import XGBClassifier\nfrom catboost import CatBoostClassifier, Pool\nfrom lightgbm import LGBMClassifier, log_evaluation, early_stopping\nfrom scipy.optimize import minimize\nimport gc\n\npd.set_option('display.max_columns', None)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## **Load Data**","metadata":{}},{"cell_type":"code","source":"print(\"Loading data...\")\ntry:\n    train = pd.read_csv('/kaggle/input/playground-series-s5e11/train.csv')\n    test = pd.read_csv('/kaggle/input/playground-series-s5e11/test.csv')\n    orig = pd.read_csv('/kaggle/input/loan-prediction-dataset-2025/loan_dataset_20000.csv')\n    sample_submission = pd.read_csv('/kaggle/input/playground-series-s5e11/sample_submission.csv')\nexcept FileNotFoundError:\n    print(\"Data files not found. Please check file paths.\")\n\nprint(f'Initial Train Shape: {train.shape}')\nprint(f'Initial Test Shape: {test.shape}')\nprint(f'Initial Orig Shape: {orig.shape}')\n\nTARGET = 'loan_paid_back'\nBASE = [col for col in train.columns if col not in ['id', TARGET]]\nCATS = ['gender', 'marital_status', 'education_level', 'employment_status', 'loan_purpose', 'grade_subgrade']\nNUMS = [col for col in BASE if col not in CATS]","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## **Domain-Specific Feature Engineering**","metadata":{}},{"cell_type":"code","source":"print(\"\\nCreating domain-specific features...\")\nDOMAIN = []\n\nfor df in [train, test, orig]:\n    if 'loan_amount' in df.columns and 'annual_income' in df.columns:\n        df['loan_to_income_ratio'] = df['loan_amount'] / (df['annual_income'] + 1e-6)\n    \n    if 'credit_score' in df.columns and 'loan_amount' in df.columns:\n        df['credit_score_to_loan_ratio'] = df['credit_score'] / (df['loan_amount'] + 1e-6)\n    \n    if 'annual_income' in df.columns:\n        df['income_per_month'] = df['annual_income'] / 12\n    \n    if 'loan_amount' in df.columns and 'loan_term_months' in df.columns:\n        df['loan_per_month'] = df['loan_amount'] / (df['loan_term_months'] + 1e-6)\n        \n        if 'income_per_month' in df.columns:\n            df['income_after_loan'] = df['income_per_month'] - df['loan_per_month']\n    \n    if 'credit_score' in df.columns and 'annual_income' in df.columns:\n        df['credit_score_x_income'] = df['credit_score'] * df['annual_income']\n    \n    if 'loan_term_months' in df.columns and 'credit_score' in df.columns:\n        df['loan_term_x_credit_score'] = df['loan_term_months'] * df['credit_score']\n\nDOMAIN = ['loan_to_income_ratio', 'loan_per_month', 'income_per_month', \n          'income_after_loan', 'credit_score_x_income', 'credit_score_to_loan_ratio',\n          'loan_term_x_credit_score']\n\nprint(f'{len(DOMAIN)} DOMAIN Features created.')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## **Aggregation Features (Categorical × Numerical)**","metadata":{}},{"cell_type":"code","source":"print(\"\\nCreating aggregation features...\")\nAGG = []\n\nAGG_NUMS = [\n    'annual_income', 'loan_amount', 'credit_score', 'loan_term_months',\n    'loan_to_income_ratio', 'loan_per_month', 'income_after_loan', 'credit_score_to_loan_ratio'\n]\n\nAGG_CATS = ['grade_subgrade', 'employment_status', 'education_level', 'loan_purpose', 'marital_status']\n\nfor df in [train, test, orig]:\n    for cat in AGG_CATS:\n        if cat not in df.columns: \n            continue\n        \n        for num in AGG_NUMS:\n            if num not in df.columns: \n                continue\n            \n            interaction_name = f'{cat}_x_{num}'\n            \n            # Mean aggregation\n            new_col_mean = f'agg_mean_{interaction_name}'\n            if new_col_mean not in AGG: \n                AGG.append(new_col_mean)\n            mean_map = df.groupby(cat)[num].transform('mean')\n            df[new_col_mean] = mean_map\n            \n            # Standard deviation aggregation\n            new_col_std = f'agg_std_{interaction_name}'\n            if new_col_std not in AGG: \n                AGG.append(new_col_std)\n            std_map = df.groupby(cat)[num].transform('std')\n            df[new_col_std] = std_map\n\n            # Difference from category mean\n            new_col_diff = f'agg_diff_{interaction_name}'\n            if new_col_diff not in AGG: \n                AGG.append(new_col_diff)\n            df[new_col_diff] = df[num] - df[new_col_mean]\n\nprint(f'{len(AGG)} AGG Features created (unique).')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## **Bigram Interaction Features**","metadata":{}},{"cell_type":"code","source":"print(\"\\nCreating bigram interaction features...\")\nINTER = []\n\nTE_BASE = [col for col in BASE if col not in ['annual_income', 'loan_amount']]\n\nfor col1, col2 in combinations(TE_BASE, 2):\n    new_col_name = f'{col1}_{col2}'\n    INTER.append(new_col_name)\n    \n    for df in [train, test, orig]:\n        if col1 in df.columns and col2 in df.columns:\n            df[new_col_name] = df[col1].astype(str) + '_' + df[col2].astype(str)\n\nprint(f'{len(INTER)} INTER Features created.')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## **Rounding Features**","metadata":{}},{"cell_type":"code","source":"print(\"\\nCreating rounding features...\")\nROUND = []\n\nrounding_levels = {'1s': 0, '10s': -1}\n\nfor col in ['annual_income', 'loan_amount']:\n    for suffix, level in rounding_levels.items():\n        new_col_name = f'{col}_ROUND_{suffix}'\n        ROUND.append(new_col_name)\n        \n        for df in [train, test, orig]:\n            if col in df.columns:\n                df[new_col_name] = df[col].round(level).astype(int)\n\nprint(f'{len(ROUND)} ROUND Features created.')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## **External Data Features (ORIG)**","metadata":{}},{"cell_type":"code","source":"print(\"\\nCreating ORIG (external data) features...\")\nORIG = []\n\nif 'loan_paid_back' not in orig.columns:\n    print(\"WARNING: 'loan_paid_back' target column not in 'orig' dataset. Skipping ORIG features.\")\nelse:\n    for col in BASE:\n        if col in orig.columns:\n            # Mean target encoding from external dataset\n            mean_map = orig.groupby(col)[TARGET].mean()\n            new_mean_col_name = f\"orig_mean_{col}\"\n            mean_map.name = new_mean_col_name\n            \n            train = train.merge(mean_map, on=col, how='left')\n            test = test.merge(mean_map, on=col, how='left')\n            orig = orig.merge(mean_map, on=col, how='left')\n            ORIG.append(new_mean_col_name)\n            \n            # Count encoding from external dataset\n            count_map = orig.groupby(col).size().reset_index(name=f\"orig_count_{col}\")\n            new_count_col_name = f\"orig_count_{col}\"\n            \n            train = train.merge(count_map, on=col, how='left')\n            test = test.merge(count_map, on=col, how='left')\n            orig = orig.merge(count_map, on=col, how='left')\n            ORIG.append(new_count_col_name)\n\nprint(f'{len(ORIG)} ORIG Features created.')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## **Feature Consolidation and Data Setup**","metadata":{}},{"cell_type":"code","source":"print(\"\\nSetting up data for training...\")\n\nFEATURES = BASE + ORIG + INTER + ROUND + DOMAIN + AGG\n\ncommon_features_train = [col for col in FEATURES if col in train.columns]\ncommon_features_orig = [col for col in FEATURES if col in orig.columns]\ncommon_features_test = [col for col in FEATURES if col in test.columns]\n\n# Find features that exist in all three datasets\nFINAL_FEATURES = list(set(common_features_train) & set(common_features_orig) & set(common_features_test))\n\nprint(f'Total common features used: {len(FINAL_FEATURES)}')\n\n# Prepare datasets\norig_train = orig[common_features_orig + [TARGET]].copy()\ntrain_data = train[common_features_train + [TARGET, 'id']].copy()\n\norig_train = orig_train[FINAL_FEATURES + [TARGET]]\ntrain_data = train_data[FINAL_FEATURES + [TARGET, 'id']]\nX_test_final = test[FINAL_FEATURES].copy()\n\n# Concatenate training data with external data\nX = pd.concat([train_data[FINAL_FEATURES], orig_train[FINAL_FEATURES]], ignore_index=True)\ny = pd.concat([train_data[TARGET], orig_train[TARGET]], ignore_index=True)\n\ntrain_ids = train_data['id']\noof_preds_shape = len(train_data)\n\nprint(f'Combined X Shape: {X.shape}')\nprint(f'Combined y Shape: {y.shape}')\nprint(f'Final Test X Shape: {X_test_final.shape}')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## **Cross-Validation Setup and Hyperparameters**","metadata":{}},{"cell_type":"code","source":"N_SPLITS = 5\nskf = StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=42)\nCATS_FINAL = [col for col in CATS if col in FINAL_FEATURES]\n\n# XGBoost Parameters\nparams_xgb = {\n    'objective': 'binary:logistic',\n    'eval_metric': 'auc',\n    'max_depth': 8,\n    'colsample_bytree': 0.4,\n    'subsample': 0.6,\n    'n_estimators': 10000,\n    'learning_rate': 0.01,\n    'early_stopping_rounds': 200,\n    'random_state': 42,\n    'n_jobs': -1,\n    'enable_categorical': True,\n    'device': 'cuda',\n}\n\n# CatBoost Parameters\nparams_cat = {\n    'iterations': 10000,\n    'learning_rate': 0.01,\n    'depth': 8,\n    'l2_leaf_reg': 2.5,\n    'random_strength': 1.0,\n    'bagging_temperature': 0.5,\n    'border_count': 128,\n    'task_type': 'GPU',\n    'loss_function': 'Logloss',\n    'eval_metric': 'AUC',\n    'random_seed': 42,\n    'verbose': False,\n    'early_stopping_rounds': 200,\n}\n\n# LightGBM Parameters\nparams_lgbm = {\n    'objective': 'binary',\n    'metric': 'auc',\n    'n_estimators': 10000,\n    'learning_rate': 0.01,\n    'num_leaves': 48,\n    'max_depth': 8,\n    'subsample': 0.7,\n    'colsample_bytree': 0.5,\n    'reg_alpha': 0.1,\n    'reg_lambda': 0.1,\n    'random_state': 42,\n    'n_jobs': -1,\n    'device': 'gpu',\n}","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## **Target Encoder Class (Custom Implementation)**","metadata":{}},{"cell_type":"code","source":"class TargetEncoder(BaseEstimator, TransformerMixin):\n    def __init__(self, cols_to_encode, aggs=['mean'], cv=5, smooth='auto', drop_original=False):\n        self.cols_to_encode = cols_to_encode\n        self.aggs = aggs\n        self.cv = cv\n        self.smooth = smooth\n        self.drop_original = drop_original\n        self.mappings_ = {}\n        self.global_stats_ = {}\n    \n    def fit(self, X, y):\n        temp_df = X.copy()\n        temp_df['target'] = y\n        \n        for agg_func in self.aggs:\n            self.global_stats_[agg_func] = y.agg(agg_func)\n        \n        for col in self.cols_to_encode:\n            self.mappings_[col] = {}\n            for agg_func in self.aggs:\n                if col not in temp_df.columns: \n                    continue\n                mapping = temp_df.groupby(col)['target'].agg(agg_func)\n                self.mappings_[col][agg_func] = mapping\n        return self\n    \n    def transform(self, X):\n        X_transformed = X.copy()\n        \n        for col in self.cols_to_encode:\n            if col not in X.columns: \n                continue\n            for agg_func in self.aggs:\n                if agg_func not in self.mappings_.get(col, {}): \n                    continue\n                new_col_name = f'TE_{col}_{agg_func}'\n                map_series = self.mappings_[col][agg_func]\n                X_transformed[new_col_name] = X[col].map(map_series)\n                X_transformed[new_col_name].fillna(self.global_stats_[agg_func], inplace=True)\n        \n        if self.drop_original:\n            cols_to_drop = [c for c in self.cols_to_encode if c in X_transformed.columns]\n            X_transformed.drop(columns=cols_to_drop, inplace=True)\n        \n        return X_transformed\n    \n    def fit_transform(self, X, y):\n        self.fit(X, y)\n        encoded_features = pd.DataFrame(index=X.index)\n        kf = KFold(n_splits=self.cv, shuffle=True, random_state=42)\n        \n        for train_idx, val_idx in kf.split(X, y):\n            X_train, y_train = X.iloc[train_idx], y.iloc[train_idx]\n            X_val = X.iloc[val_idx]\n            temp_df_train = X_train.copy()\n            temp_df_train['target'] = y_train\n            \n            for col in self.cols_to_encode:\n                if col not in temp_df_train.columns: \n                    continue\n                for agg_func in self.aggs:\n                    new_col_name = f'TE_{col}_{agg_func}'\n                    fold_global_stat = y_train.agg(agg_func)\n                    mapping = temp_df_train.groupby(col)['target'].agg(agg_func)\n                    \n                    if agg_func == 'mean':\n                        counts = temp_df_train.groupby(col)['target'].count()\n                        m = self.smooth\n                        \n                        if self.smooth == 'auto':\n                            variance_between = mapping.var()\n                            avg_variance_within = temp_df_train.groupby(col)['target'].var().mean()\n                            if variance_between > 0 and not pd.isna(avg_variance_within):\n                                m = avg_variance_within / variance_between\n                            else:\n                                m = 0\n                        \n                        smoothed_mapping = (counts * mapping + m * fold_global_stat) / (counts + m)\n                        encoded_values = X_val[col].map(smoothed_mapping)\n                    else:\n                        encoded_values = X_val[col].map(mapping)\n                    \n                    encoded_features.loc[X_val.index, new_col_name] = encoded_values.fillna(fold_global_stat)\n        \n        X_transformed = X.copy()\n        for col in encoded_features.columns:\n            X_transformed[col] = encoded_features[col]\n        \n        if self.drop_original:\n            cols_to_drop = [c for c in self.cols_to_encode if c in X_transformed.columns]\n            X_transformed.drop(columns=cols_to_drop, inplace=True)\n        \n        return X_transformed","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## **Training Level 1 Models - Initialize Arrays**","metadata":{}},{"cell_type":"code","source":"print('\\n' + '='*80)\nprint('TRAINING Level 1 Models (XGB + CAT + LGBM) on Combined Data')\nprint('='*80)\n\noof_preds_xgb = np.zeros(len(X))\ntest_preds_xgb = np.zeros(len(X_test_final))\noof_preds_cat = np.zeros(len(X))\ntest_preds_cat = np.zeros(len(X_test_final))\noof_preds_lgbm = np.zeros(len(X))\ntest_preds_lgbm = np.zeros(len(X_test_final))\n\nTE_INTER_FINAL = [col for col in INTER if col in FINAL_FEATURES]\nTE_ROUND_FINAL = [col for col in ROUND if col in FINAL_FEATURES]","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## **Fold Loop - Target Encoding Step**","metadata":{}},{"cell_type":"code","source":"for fold, (train_idx, val_idx) in enumerate(skf.split(X, y), 1):\n    print(f'\\n--- Fold {fold}/{N_SPLITS} ---')\n    \n    X_train, X_val = X.iloc[train_idx].copy(), X.iloc[val_idx].copy()\n    y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n    X_test_fold = X_test_final.copy()\n\n    # Target encoding for interaction features\n    TE = TargetEncoder(cols_to_encode=TE_INTER_FINAL, cv=5, smooth=1.0, aggs=['mean'], drop_original=True)\n    X_train = TE.fit_transform(X_train, y_train)\n    X_val = TE.transform(X_val)\n    X_test_fold = TE.transform(X_test_fold)\n\n    # Target encoding for rounding features\n    TE2 = TargetEncoder(cols_to_encode=TE_ROUND_FINAL, cv=5, smooth=1.0, aggs=['mean'], drop_original=False)\n    X_train = TE2.fit_transform(X_train, y_train)\n    X_val = TE2.transform(X_val)\n    X_test_fold = TE2.transform(X_test_fold)\n    \n    # Target encoding for categorical features\n    TE3 = TargetEncoder(cols_to_encode=CATS_FINAL, cv=5, smooth=1.0, aggs=['mean'], drop_original=False)\n    X_train = TE3.fit_transform(X_train, y_train)\n    X_val = TE3.transform(X_val)\n    X_test_fold = TE3.transform(X_test_fold)\n    \n    # Fill NA values\n    X_train = X_train.fillna(0)\n    X_val = X_val.fillna(0)\n    X_test_fold = X_test_fold.fillna(0)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## **Fold Loop - XGBoost Training**","metadata":{}},{"cell_type":"code","source":"    # XGBoost training\n    print(\"Training XGBoost...\")\n    X_train_xgb = X_train.copy()\n    X_val_xgb = X_val.copy()\n    X_test_xgb = X_test_fold.copy()\n    \n    # Convert categorical columns\n    for col in CATS_FINAL:\n        if col in X_train_xgb.columns:\n            X_train_xgb[col] = X_train_xgb[col].astype('category')\n            X_val_xgb[col] = X_val_xgb[col].astype('category')\n            X_test_xgb[col] = X_test_xgb[col].astype('category')\n    \n    model_xgb = XGBClassifier(**params_xgb)\n    model_xgb.fit(X_train_xgb, y_train, eval_set=[(X_val_xgb, y_val)], verbose=False)\n    \n    oof_preds_xgb[val_idx] = model_xgb.predict_proba(X_val_xgb)[:, 1]\n    test_preds_xgb += model_xgb.predict_proba(X_test_xgb)[:, 1] / N_SPLITS\n    fold_score_xgb = roc_auc_score(y_val, oof_preds_xgb[val_idx])\n    print(f'XGBoost AUC: {fold_score_xgb:.5f}')\n    \n    del model_xgb, X_train_xgb, X_val_xgb, X_test_xgb\n    gc.collect()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## **Fold Loop - CatBoost Training**","metadata":{}},{"cell_type":"code","source":"    # CatBoost training\n    print(\"Training CatBoost...\")\n    X_train_cat = X_train.copy()\n    X_val_cat = X_val.copy()\n    X_test_cat = X_test_fold.copy()\n    \n    # Convert to string for CatBoost\n    for cat in CATS_FINAL:\n        if cat in X_train_cat.columns:\n            X_train_cat[cat] = X_train_cat[cat].astype(str)\n            X_val_cat[cat] = X_val_cat[cat].astype(str)\n            X_test_cat[cat] = X_test_cat[cat].astype(str)\n    \n    cat_features_indices = [i for i, col in enumerate(X_train_cat.columns) if col in CATS_FINAL]\n    \n    train_pool = Pool(X_train_cat, y_train, cat_features=cat_features_indices)\n    valid_pool = Pool(X_val_cat, y_val, cat_features=cat_features_indices)\n    test_pool = Pool(X_test_cat, cat_features=cat_features_indices)\n    \n    model_cat = CatBoostClassifier(**params_cat)\n    model_cat.fit(train_pool, eval_set=valid_pool)\n    \n    oof_preds_cat[val_idx] = model_cat.predict_proba(valid_pool)[:, 1]\n    test_preds_cat += model_cat.predict_proba(test_pool)[:, 1] / N_SPLITS\n    fold_score_cat = roc_auc_score(y_val, oof_preds_cat[val_idx])\n    print(f'CatBoost AUC: {fold_score_cat:.5f}')\n    \n    del model_cat, X_train_cat, X_val_cat, X_test_cat, train_pool, valid_pool, test_pool\n    gc.collect()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## **Fold Loop - LightGBM Training**","metadata":{}},{"cell_type":"code","source":"    # LightGBM training\n    print(\"Training LightGBM...\")\n    X_train_lgbm = X_train.copy()\n    X_val_lgbm = X_val.copy()\n    X_test_lgbm = X_test_fold.copy()\n    \n    for col in CATS_FINAL:\n        if col in X_train_lgbm.columns:\n            X_train_lgbm[col] = X_train_lgbm[col].astype('category')\n            X_val_lgbm[col] = X_val_lgbm[col].astype('category')\n            X_test_lgbm[col] = X_test_lgbm[col].astype('category')\n    \n    model_lgbm = LGBMClassifier(**params_lgbm)\n    model_lgbm.fit(X_train_lgbm, y_train,\n                   eval_set=[(X_val_lgbm, y_val)],\n                   eval_metric='auc',\n                   callbacks=[\n                       early_stopping(200, verbose=False),\n                       log_evaluation(period=0)\n                   ])\n    \n    oof_preds_lgbm[val_idx] = model_lgbm.predict_proba(X_val_lgbm)[:, 1]\n    test_preds_lgbm += model_lgbm.predict_proba(X_test_lgbm)[:, 1] / N_SPLITS\n    fold_score_lgbm = roc_auc_score(y_val, oof_preds_lgbm[val_idx])\n    print(f'LightGBM AUC: {fold_score_lgbm:.5f}')\n    \n    del model_lgbm, X_train_lgbm, X_val_lgbm, X_test_lgbm\n    gc.collect()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## **Evaluate Level 1 Models**","metadata":{}},{"cell_type":"code","source":"cv_xgb = roc_auc_score(y, oof_preds_xgb)\ncv_cat = roc_auc_score(y, oof_preds_cat)\ncv_lgbm = roc_auc_score(y, oof_preds_lgbm)\n\nprint(f'\\n{\"=\"*80}')\nprint('Level 1 Model OOF Scores (on Combined Data):')\nprint(f'XGBoost Overall CV: {cv_xgb:.5f}')\nprint(f'CatBoost Overall CV: {cv_cat:.5f}')\nprint(f'LightGBM Overall CV: {cv_lgbm:.5f}')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## **Level 2 Stacking - Create Meta-Features**","metadata":{}},{"cell_type":"code","source":"print('\\n' + '='*80)\nprint('ENSEMBLE (Level 2 Stacking with Meta-Model)')\nprint('='*80)\n\n# Create meta-training data from OOF predictions\nX_meta_train = np.vstack([oof_preds_xgb, oof_preds_cat, oof_preds_lgbm]).T\ny_meta_train = y\n\n# Create meta-test data from averaged test predictions\nX_meta_test = np.vstack([test_preds_xgb, test_preds_cat, test_preds_lgbm]).T","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## **Train Meta-Model and Generate Final Predictions**","metadata":{}},{"cell_type":"code","source":"print(\"Training meta-model (Logistic Regression)...\")\nmeta_model = LogisticRegression(C=0.1, solver='lbfgs', random_state=42, n_jobs=-1)\nmeta_model.fit(X_meta_train, y_meta_train)\nprint(\"Meta-model trained.\")\n\n# Get final predictions\noof_preds = meta_model.predict_proba(X_meta_train)[:, 1]\ntest_preds = meta_model.predict_proba(X_meta_test)[:, 1]\n\n# Calculate final scores\noverall_auc = roc_auc_score(y, oof_preds)\nprint(f'\\nFinal Ensemble CV (Combined): {overall_auc:.5f}')\n\n# Slice OOF to original train size\noof_preds_orig_train = oof_preds[:oof_preds_shape]\ny_orig_train = y.iloc[:oof_preds_shape]\noverall_auc_orig_train = roc_auc_score(y_orig_train, oof_preds_orig_train)\nprint(f'Final Ensemble CV (Original Train Only): {overall_auc_orig_train:.5f}')\n\nprint(f'Expected LB (Estimate): {overall_auc_orig_train + 0.00016:.5f} - {overall_auc_orig_train + 0.00022:.5f}')\nprint('='*80)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## **Save Submission Files**","metadata":{}},{"cell_type":"code","source":"print(\"Saving submission and OOF files...\")\n\nsubmission_df = pd.DataFrame({'id': test['id'], TARGET: test_preds})\nsubmission_df.to_csv('submission.csv', index=False)\n\noof_df = pd.DataFrame({'id': train_ids, TARGET: oof_preds_orig_train})\noof_df.to_csv(f'oof_predictions_{overall_auc_orig_train:.5f}.csv', index=False)\n\nprint(f'\\n✅ submission.csv saved')\nprint(f'✅ oof_predictions_{overall_auc_orig_train:.5f}.csv saved')\nprint(\"\\nProcess completed successfully.\")","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}